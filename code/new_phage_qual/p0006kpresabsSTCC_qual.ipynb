{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0006kpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0006kpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "248    1\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>...</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>CAGAAAAGCGT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  \\\n",
       "0     107            1              1              1               1   \n",
       "1     109            1              1              1               1   \n",
       "2     115            1              1              1               1   \n",
       "3  120335            1              1              1               1   \n",
       "4  120337            1              1              1               1   \n",
       "\n",
       "   TATTATGTTAATG  TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  ...  \\\n",
       "0              1            1             1               1            1  ...   \n",
       "1              1            1             1               1            1  ...   \n",
       "2              1            1             1               1            1  ...   \n",
       "3              1            1             1               1            1  ...   \n",
       "4              1            1             1               1            1  ...   \n",
       "\n",
       "   GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                  0                                                     \n",
       "1                                                  0                                                     \n",
       "2                                                  0                                                     \n",
       "3                                                  0                                                     \n",
       "4                                                  0                                                     \n",
       "\n",
       "   CTTTTTCACCTGT  CTTGTGAATTTAG  \\\n",
       "0              1              1   \n",
       "1              1              1   \n",
       "2              1              1   \n",
       "3              1              1   \n",
       "4              1              1   \n",
       "\n",
       "   CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG  CGCCATTATGTT  \\\n",
       "0                                                  1              0   \n",
       "1                                                  1              0   \n",
       "2                                                  1              1   \n",
       "3                                                  1              0   \n",
       "4                                                  1              0   \n",
       "\n",
       "   CAGAAAAGCGT  ACAATTACTATATTT  ST  CC  pheno  \n",
       "0            1                1   5   5      1  \n",
       "1            1                1   8   8      0  \n",
       "2            1                1   5   5      1  \n",
       "3            1                1   5   5      1  \n",
       "4            1                1   5   5      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>...</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>CAGAAAAGCGT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  TATTATGTTAATG  \\\n",
       "0            1              1              1               1              1   \n",
       "1            1              1              1               1              1   \n",
       "2            1              1              1               1              1   \n",
       "3            1              1              1               1              1   \n",
       "4            1              1              1               1              1   \n",
       "\n",
       "   TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  GAGTCCTGTT  ...  \\\n",
       "0            1             1               1            1           1  ...   \n",
       "1            1             1               1            1           1  ...   \n",
       "2            1             1               1            1           1  ...   \n",
       "3            1             1               1            1           1  ...   \n",
       "4            1             1               1            1           1  ...   \n",
       "\n",
       "   GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                  0                                                     \n",
       "1                                                  0                                                     \n",
       "2                                                  0                                                     \n",
       "3                                                  0                                                     \n",
       "4                                                  0                                                     \n",
       "\n",
       "   CTTTTTCACCTGT  CTTGTGAATTTAG  \\\n",
       "0              1              1   \n",
       "1              1              1   \n",
       "2              1              1   \n",
       "3              1              1   \n",
       "4              1              1   \n",
       "\n",
       "   CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG  CGCCATTATGTT  \\\n",
       "0                                                  1              0   \n",
       "1                                                  1              0   \n",
       "2                                                  1              1   \n",
       "3                                                  1              0   \n",
       "4                                                  1              0   \n",
       "\n",
       "   CAGAAAAGCGT  ACAATTACTATATTT  ST  CC  pheno  \n",
       "0            1                1   5   5      1  \n",
       "1            1                1   8   8      0  \n",
       "2            1                1   5   5      1  \n",
       "3            1                1   5   5      1  \n",
       "4            1                1   5   5      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 21) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS383     1\n",
       "1       NRS254     1\n",
       "2       NRS218     1\n",
       "3       NRS215     0\n",
       "4    BCH-SA-14     2\n",
       "..         ...   ...\n",
       "112     NRS227     1\n",
       "113     NRS272     1\n",
       "114   CFBRSa24     0\n",
       "115   CFBRSa74     0\n",
       "116     NRS271     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 672us/step - loss: 4.0506 - accuracy: 0.3185 - val_loss: 2.3332 - val_accuracy: 0.4188\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 268us/step - loss: 1.7695 - accuracy: 0.3889 - val_loss: 1.5487 - val_accuracy: 0.3590\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 1.5525 - accuracy: 0.4074 - val_loss: 1.2757 - val_accuracy: 0.3504\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 1.1765 - accuracy: 0.4074 - val_loss: 1.1998 - val_accuracy: 0.4444\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 1.1466 - accuracy: 0.5148 - val_loss: 1.1958 - val_accuracy: 0.4359\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.1541 - accuracy: 0.4407 - val_loss: 1.1699 - val_accuracy: 0.4017\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 1.1403 - accuracy: 0.4481 - val_loss: 1.1885 - val_accuracy: 0.4103\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 1.2766 - accuracy: 0.4296 - val_loss: 1.1560 - val_accuracy: 0.4017\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 1.2649 - accuracy: 0.4593 - val_loss: 1.2621 - val_accuracy: 0.4615\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 1.1815 - accuracy: 0.4370 - val_loss: 1.2706 - val_accuracy: 0.4615\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 337us/step - loss: 1.1427 - accuracy: 0.4630 - val_loss: 1.1519 - val_accuracy: 0.4615\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0798 - accuracy: 0.4667 - val_loss: 1.1628 - val_accuracy: 0.4359\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.1193 - accuracy: 0.4741 - val_loss: 1.1484 - val_accuracy: 0.4274\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0900 - accuracy: 0.4926 - val_loss: 1.1315 - val_accuracy: 0.4017\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.1382 - accuracy: 0.4519 - val_loss: 1.1455 - val_accuracy: 0.4274\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0885 - accuracy: 0.4667 - val_loss: 1.1234 - val_accuracy: 0.4444\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.1405 - accuracy: 0.4630 - val_loss: 1.1286 - val_accuracy: 0.4274\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0865 - accuracy: 0.4444 - val_loss: 1.1174 - val_accuracy: 0.4530\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 1.2286 - accuracy: 0.4963 - val_loss: 1.1763 - val_accuracy: 0.4444\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 1.2428 - accuracy: 0.4407 - val_loss: 1.3323 - val_accuracy: 0.5043\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 1.1639 - accuracy: 0.4741 - val_loss: 1.1642 - val_accuracy: 0.4615\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.1738 - accuracy: 0.4778 - val_loss: 1.2096 - val_accuracy: 0.4188\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.1106 - accuracy: 0.4815 - val_loss: 1.1258 - val_accuracy: 0.4872\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.1384 - accuracy: 0.4778 - val_loss: 1.1948 - val_accuracy: 0.4786\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.0894 - accuracy: 0.4926 - val_loss: 1.1863 - val_accuracy: 0.4444\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0903 - accuracy: 0.5111 - val_loss: 1.1031 - val_accuracy: 0.4957\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0952 - accuracy: 0.4963 - val_loss: 1.1997 - val_accuracy: 0.4530\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 1.2147 - accuracy: 0.4889 - val_loss: 1.1651 - val_accuracy: 0.4615\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 1.1445 - accuracy: 0.4630 - val_loss: 1.3042 - val_accuracy: 0.4615\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 1.2819 - accuracy: 0.5185 - val_loss: 1.2706 - val_accuracy: 0.5470\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.2534 - accuracy: 0.4963 - val_loss: 1.1655 - val_accuracy: 0.5128\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.0755 - accuracy: 0.4852 - val_loss: 1.0917 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.0125 - accuracy: 0.5111 - val_loss: 1.1608 - val_accuracy: 0.4872\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0551 - accuracy: 0.5037 - val_loss: 1.0667 - val_accuracy: 0.5043\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0158 - accuracy: 0.5407 - val_loss: 1.1196 - val_accuracy: 0.4872\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0704 - accuracy: 0.5111 - val_loss: 1.1095 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0476 - accuracy: 0.5259 - val_loss: 1.1334 - val_accuracy: 0.5385\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.1175 - accuracy: 0.5407 - val_loss: 1.1519 - val_accuracy: 0.4530\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0403 - accuracy: 0.5148 - val_loss: 1.1384 - val_accuracy: 0.4530\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.1256 - accuracy: 0.5185 - val_loss: 1.2228 - val_accuracy: 0.4786\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.1362 - accuracy: 0.4926 - val_loss: 1.0963 - val_accuracy: 0.5299\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.1103 - accuracy: 0.5185 - val_loss: 1.1108 - val_accuracy: 0.5128\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 1.0690 - accuracy: 0.5222 - val_loss: 1.0648 - val_accuracy: 0.5128\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.0197 - accuracy: 0.5407 - val_loss: 1.0850 - val_accuracy: 0.4359\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9927 - accuracy: 0.4926 - val_loss: 1.0371 - val_accuracy: 0.4957\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.0037 - accuracy: 0.5481 - val_loss: 1.0382 - val_accuracy: 0.5128\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.0245 - accuracy: 0.5519 - val_loss: 1.1156 - val_accuracy: 0.4957\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.0850 - accuracy: 0.5333 - val_loss: 1.1392 - val_accuracy: 0.5812\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.0154 - accuracy: 0.5333 - val_loss: 1.0810 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.0569 - accuracy: 0.5333 - val_loss: 1.0337 - val_accuracy: 0.5128\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.0592 - accuracy: 0.5296 - val_loss: 1.1738 - val_accuracy: 0.5214\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 1.0777 - accuracy: 0.5667 - val_loss: 1.2917 - val_accuracy: 0.4957\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 1.2439 - accuracy: 0.5519 - val_loss: 1.1548 - val_accuracy: 0.5470\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.1718 - accuracy: 0.5630 - val_loss: 1.4217 - val_accuracy: 0.4786\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.2145 - accuracy: 0.5444 - val_loss: 1.1102 - val_accuracy: 0.5385\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.0091 - accuracy: 0.5519 - val_loss: 1.0539 - val_accuracy: 0.5470\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9730 - accuracy: 0.5556 - val_loss: 1.0528 - val_accuracy: 0.5470\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.0802 - accuracy: 0.5815 - val_loss: 1.0018 - val_accuracy: 0.5470\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.1486 - accuracy: 0.5556 - val_loss: 1.3851 - val_accuracy: 0.5726\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.3213 - accuracy: 0.5704 - val_loss: 1.0340 - val_accuracy: 0.5556\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 424us/step - loss: 1.0108 - accuracy: 0.5667 - val_loss: 1.2086 - val_accuracy: 0.5556\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 1.2304 - accuracy: 0.5852 - val_loss: 1.0089 - val_accuracy: 0.5128\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 1.1912 - accuracy: 0.5630 - val_loss: 1.4814 - val_accuracy: 0.4615\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1274 - accuracy: 0.5815 - val_loss: 1.1396 - val_accuracy: 0.5299\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 692us/step - loss: 0.9843 - accuracy: 0.6185 - val_loss: 1.1297 - val_accuracy: 0.4957\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 394us/step - loss: 1.0596 - accuracy: 0.5630 - val_loss: 1.2037 - val_accuracy: 0.4957\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 1.3487 - accuracy: 0.6148 - val_loss: 1.1802 - val_accuracy: 0.5214\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 1.1092 - accuracy: 0.5704 - val_loss: 1.0656 - val_accuracy: 0.5556\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 1.0080 - accuracy: 0.5704 - val_loss: 1.0249 - val_accuracy: 0.5214\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9228 - accuracy: 0.5444 - val_loss: 1.0090 - val_accuracy: 0.5641\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9047 - accuracy: 0.5519 - val_loss: 0.9603 - val_accuracy: 0.5470\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.9082 - accuracy: 0.5519 - val_loss: 0.9602 - val_accuracy: 0.5556\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9102 - accuracy: 0.5778 - val_loss: 0.9745 - val_accuracy: 0.5043\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9315 - accuracy: 0.5519 - val_loss: 0.9612 - val_accuracy: 0.5385\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9134 - accuracy: 0.5704 - val_loss: 0.9690 - val_accuracy: 0.5128\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8838 - accuracy: 0.5741 - val_loss: 0.9421 - val_accuracy: 0.5726\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.9957 - accuracy: 0.6111 - val_loss: 1.1391 - val_accuracy: 0.5556\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 255us/step - loss: 1.2148 - accuracy: 0.6148 - val_loss: 1.1311 - val_accuracy: 0.5214\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 362us/step - loss: 0.9671 - accuracy: 0.5741 - val_loss: 1.0979 - val_accuracy: 0.5897\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9607 - accuracy: 0.6000 - val_loss: 0.9653 - val_accuracy: 0.5470\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9512 - accuracy: 0.6370 - val_loss: 0.9613 - val_accuracy: 0.5299\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9125 - accuracy: 0.6000 - val_loss: 0.9466 - val_accuracy: 0.5470\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9006 - accuracy: 0.5778 - val_loss: 1.0006 - val_accuracy: 0.4957\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.9118 - accuracy: 0.5926 - val_loss: 1.0746 - val_accuracy: 0.4957\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8611 - accuracy: 0.6222 - val_loss: 0.9750 - val_accuracy: 0.5214\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9083 - accuracy: 0.5926 - val_loss: 0.9744 - val_accuracy: 0.5128\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9022 - accuracy: 0.5926 - val_loss: 1.0332 - val_accuracy: 0.5214\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8805 - accuracy: 0.6333 - val_loss: 0.9297 - val_accuracy: 0.5641\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8525 - accuracy: 0.6370 - val_loss: 0.9371 - val_accuracy: 0.5726\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8631 - accuracy: 0.6222 - val_loss: 1.0176 - val_accuracy: 0.5726\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 366us/step - loss: 0.8912 - accuracy: 0.6481 - val_loss: 0.9734 - val_accuracy: 0.5385\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.9778 - accuracy: 0.6222 - val_loss: 1.0307 - val_accuracy: 0.6154\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.9063 - accuracy: 0.6778 - val_loss: 1.1032 - val_accuracy: 0.5128\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.1012 - accuracy: 0.6037 - val_loss: 1.0742 - val_accuracy: 0.5726\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9278 - accuracy: 0.6222 - val_loss: 1.2078 - val_accuracy: 0.4872\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 1.1103 - accuracy: 0.6556 - val_loss: 0.9878 - val_accuracy: 0.5385\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9905 - accuracy: 0.6037 - val_loss: 1.0201 - val_accuracy: 0.5385\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9006 - accuracy: 0.5889 - val_loss: 0.9387 - val_accuracy: 0.5726\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.9392 - accuracy: 0.6370 - val_loss: 0.9306 - val_accuracy: 0.5812\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8225 - accuracy: 0.6667 - val_loss: 0.9229 - val_accuracy: 0.5556\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8454 - accuracy: 0.6370 - val_loss: 0.9853 - val_accuracy: 0.4957\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8687 - accuracy: 0.6444 - val_loss: 0.9900 - val_accuracy: 0.5385\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8784 - accuracy: 0.6444 - val_loss: 0.9269 - val_accuracy: 0.5556\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9290 - accuracy: 0.6296 - val_loss: 0.9832 - val_accuracy: 0.5726\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0251 - accuracy: 0.6407 - val_loss: 1.0261 - val_accuracy: 0.5556\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 389us/step - loss: 0.8911 - accuracy: 0.6074 - val_loss: 0.9597 - val_accuracy: 0.5299\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8436 - accuracy: 0.6556 - val_loss: 0.9419 - val_accuracy: 0.5641\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8521 - accuracy: 0.6370 - val_loss: 0.9737 - val_accuracy: 0.5983\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8394 - accuracy: 0.6148 - val_loss: 0.9600 - val_accuracy: 0.5385\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8482 - accuracy: 0.6259 - val_loss: 1.0101 - val_accuracy: 0.5214\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8792 - accuracy: 0.6444 - val_loss: 0.9272 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8488 - accuracy: 0.6593 - val_loss: 1.0057 - val_accuracy: 0.6068\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 446us/step - loss: 0.8864 - accuracy: 0.6407 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9374 - accuracy: 0.6593 - val_loss: 0.9525 - val_accuracy: 0.5641\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9258 - accuracy: 0.6519 - val_loss: 0.9827 - val_accuracy: 0.5556\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.0106 - accuracy: 0.6407 - val_loss: 0.9723 - val_accuracy: 0.5214\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8879 - accuracy: 0.6333 - val_loss: 0.9763 - val_accuracy: 0.5897\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8812 - accuracy: 0.6296 - val_loss: 0.9340 - val_accuracy: 0.5812\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8762 - accuracy: 0.6778 - val_loss: 0.9860 - val_accuracy: 0.5128\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8212 - accuracy: 0.6519 - val_loss: 0.9303 - val_accuracy: 0.5385\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8966 - accuracy: 0.6630 - val_loss: 0.9207 - val_accuracy: 0.5726\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9086 - accuracy: 0.6296 - val_loss: 0.9395 - val_accuracy: 0.5641\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9374 - accuracy: 0.6593 - val_loss: 0.9207 - val_accuracy: 0.5556\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8962 - accuracy: 0.6593 - val_loss: 0.9862 - val_accuracy: 0.5641\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 422us/step - loss: 0.9281 - accuracy: 0.6444 - val_loss: 0.9006 - val_accuracy: 0.5641\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.8294 - accuracy: 0.6667 - val_loss: 0.9319 - val_accuracy: 0.5385\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8362 - accuracy: 0.6593 - val_loss: 0.9228 - val_accuracy: 0.5897\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.7996 - accuracy: 0.6778 - val_loss: 0.9553 - val_accuracy: 0.5470\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8475 - accuracy: 0.6667 - val_loss: 1.0282 - val_accuracy: 0.5726\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9138 - accuracy: 0.6630 - val_loss: 1.0538 - val_accuracy: 0.5812\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9698 - accuracy: 0.6741 - val_loss: 1.0112 - val_accuracy: 0.5556\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8891 - accuracy: 0.6481 - val_loss: 0.9238 - val_accuracy: 0.5897\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7773 - accuracy: 0.6519 - val_loss: 0.9128 - val_accuracy: 0.5812\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8136 - accuracy: 0.6963 - val_loss: 1.1277 - val_accuracy: 0.5641\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.9047 - accuracy: 0.6593 - val_loss: 1.0612 - val_accuracy: 0.5983\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 552us/step - loss: 0.9771 - accuracy: 0.6630 - val_loss: 0.9868 - val_accuracy: 0.5641\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7894 - accuracy: 0.6741 - val_loss: 0.9096 - val_accuracy: 0.5385\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7852 - accuracy: 0.6519 - val_loss: 0.9322 - val_accuracy: 0.5812\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8418 - accuracy: 0.6407 - val_loss: 0.9214 - val_accuracy: 0.5726\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.7910 - accuracy: 0.6630 - val_loss: 0.9702 - val_accuracy: 0.5726\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.7913 - accuracy: 0.6815 - val_loss: 0.9196 - val_accuracy: 0.5470\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7791 - accuracy: 0.6630 - val_loss: 0.9220 - val_accuracy: 0.6068\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8135 - accuracy: 0.6667 - val_loss: 0.9530 - val_accuracy: 0.6239\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0733 - accuracy: 0.6630 - val_loss: 0.9752 - val_accuracy: 0.5897\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9143 - accuracy: 0.6185 - val_loss: 0.9782 - val_accuracy: 0.6068\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8811 - accuracy: 0.6481 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8450 - accuracy: 0.6556 - val_loss: 0.9956 - val_accuracy: 0.5897\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8204 - accuracy: 0.6556 - val_loss: 0.9272 - val_accuracy: 0.5812\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.7692 - accuracy: 0.6556 - val_loss: 0.9263 - val_accuracy: 0.5385\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.7767 - accuracy: 0.6778 - val_loss: 0.9592 - val_accuracy: 0.5641\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7780 - accuracy: 0.6667 - val_loss: 0.9049 - val_accuracy: 0.5641\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7581 - accuracy: 0.6667 - val_loss: 0.9038 - val_accuracy: 0.5470\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7537 - accuracy: 0.6630 - val_loss: 0.9070 - val_accuracy: 0.5385\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7529 - accuracy: 0.6704 - val_loss: 0.9789 - val_accuracy: 0.5641\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8448 - accuracy: 0.6667 - val_loss: 0.9146 - val_accuracy: 0.5897\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8776 - accuracy: 0.6593 - val_loss: 0.9022 - val_accuracy: 0.5983\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7481 - accuracy: 0.6704 - val_loss: 0.9576 - val_accuracy: 0.6325\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9350 - accuracy: 0.6741 - val_loss: 0.9354 - val_accuracy: 0.6239\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0138 - accuracy: 0.6630 - val_loss: 1.3190 - val_accuracy: 0.4957\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9544 - accuracy: 0.6481 - val_loss: 0.9960 - val_accuracy: 0.5214\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8644 - accuracy: 0.6296 - val_loss: 0.9924 - val_accuracy: 0.5812\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8246 - accuracy: 0.6444 - val_loss: 0.8995 - val_accuracy: 0.5641\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7624 - accuracy: 0.6630 - val_loss: 0.9623 - val_accuracy: 0.5470\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.7330 - accuracy: 0.6926 - val_loss: 0.9038 - val_accuracy: 0.6410\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.7561 - accuracy: 0.6778 - val_loss: 0.9056 - val_accuracy: 0.5556\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.7773 - accuracy: 0.6741 - val_loss: 0.9429 - val_accuracy: 0.6325\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7921 - accuracy: 0.6556 - val_loss: 1.0231 - val_accuracy: 0.5556\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8748 - accuracy: 0.6926 - val_loss: 1.1183 - val_accuracy: 0.5983\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0103 - accuracy: 0.6815 - val_loss: 0.9316 - val_accuracy: 0.6068\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8700 - accuracy: 0.6556 - val_loss: 0.9264 - val_accuracy: 0.6325\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8092 - accuracy: 0.6519 - val_loss: 1.0059 - val_accuracy: 0.5897\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8866 - accuracy: 0.6630 - val_loss: 1.0988 - val_accuracy: 0.5214\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7412 - accuracy: 0.6667 - val_loss: 0.9801 - val_accuracy: 0.6410\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8882 - accuracy: 0.6778 - val_loss: 1.0947 - val_accuracy: 0.5641\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 1.1070 - accuracy: 0.6630 - val_loss: 1.1548 - val_accuracy: 0.5983\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9685 - accuracy: 0.6630 - val_loss: 0.9685 - val_accuracy: 0.5641\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7971 - accuracy: 0.6667 - val_loss: 0.9266 - val_accuracy: 0.6154\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7450 - accuracy: 0.6519 - val_loss: 0.9246 - val_accuracy: 0.6154\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7903 - accuracy: 0.6852 - val_loss: 0.8964 - val_accuracy: 0.5897\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.7766 - accuracy: 0.6704 - val_loss: 0.9964 - val_accuracy: 0.5641\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.8378 - accuracy: 0.6630 - val_loss: 0.9466 - val_accuracy: 0.6154\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8497 - accuracy: 0.6630 - val_loss: 1.1502 - val_accuracy: 0.5641\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7816 - accuracy: 0.7000 - val_loss: 1.0698 - val_accuracy: 0.6068\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9543 - accuracy: 0.6741 - val_loss: 0.9273 - val_accuracy: 0.5641\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7949 - accuracy: 0.6926 - val_loss: 0.9342 - val_accuracy: 0.6154\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.9032 - accuracy: 0.6556 - val_loss: 1.1271 - val_accuracy: 0.5556\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8425 - accuracy: 0.6667 - val_loss: 1.0955 - val_accuracy: 0.5641\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8399 - accuracy: 0.6741 - val_loss: 1.0221 - val_accuracy: 0.5641\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8802 - accuracy: 0.6481 - val_loss: 1.1154 - val_accuracy: 0.5983\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.0429 - accuracy: 0.6481 - val_loss: 1.0983 - val_accuracy: 0.5043\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 1.0956 - accuracy: 0.6333 - val_loss: 0.9764 - val_accuracy: 0.5641\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.9504 - accuracy: 0.6852 - val_loss: 1.0529 - val_accuracy: 0.5214\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 363us/step - loss: 0.8455 - accuracy: 0.6667 - val_loss: 0.9829 - val_accuracy: 0.5897\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.8413 - accuracy: 0.6556 - val_loss: 0.9569 - val_accuracy: 0.5983\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.7618 - accuracy: 0.6704 - val_loss: 0.9471 - val_accuracy: 0.5812\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7502 - accuracy: 0.6815 - val_loss: 0.9185 - val_accuracy: 0.5897\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 275us/step - loss: 0.7280 - accuracy: 0.6815 - val_loss: 0.9325 - val_accuracy: 0.6068\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7356 - accuracy: 0.7037 - val_loss: 0.9400 - val_accuracy: 0.5556\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7943 - accuracy: 0.6556 - val_loss: 0.9141 - val_accuracy: 0.6325\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7264 - accuracy: 0.7000 - val_loss: 0.9236 - val_accuracy: 0.5897\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7254 - accuracy: 0.6852 - val_loss: 0.9130 - val_accuracy: 0.6068\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7318 - accuracy: 0.6815 - val_loss: 0.9263 - val_accuracy: 0.5983\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.7351 - accuracy: 0.6926 - val_loss: 0.9393 - val_accuracy: 0.5641\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7272 - accuracy: 0.6926 - val_loss: 0.9228 - val_accuracy: 0.6325\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7724 - accuracy: 0.6926 - val_loss: 0.9262 - val_accuracy: 0.5726\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7598 - accuracy: 0.6815 - val_loss: 0.8974 - val_accuracy: 0.6410\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7529 - accuracy: 0.6889 - val_loss: 0.9038 - val_accuracy: 0.6325\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8210 - accuracy: 0.6963 - val_loss: 0.9301 - val_accuracy: 0.6068\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7472 - accuracy: 0.6704 - val_loss: 0.9495 - val_accuracy: 0.6154\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7772 - accuracy: 0.6741 - val_loss: 0.9166 - val_accuracy: 0.5897\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7232 - accuracy: 0.7037 - val_loss: 0.9216 - val_accuracy: 0.6154\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7159 - accuracy: 0.7000 - val_loss: 0.9162 - val_accuracy: 0.5897\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7315 - accuracy: 0.6852 - val_loss: 0.9952 - val_accuracy: 0.5385\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7388 - accuracy: 0.6889 - val_loss: 0.9752 - val_accuracy: 0.5470\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7559 - accuracy: 0.6852 - val_loss: 0.9278 - val_accuracy: 0.6068\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7137 - accuracy: 0.6889 - val_loss: 0.9161 - val_accuracy: 0.5983\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7229 - accuracy: 0.6926 - val_loss: 0.9131 - val_accuracy: 0.6410\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7155 - accuracy: 0.7074 - val_loss: 0.9341 - val_accuracy: 0.5641\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7304 - accuracy: 0.6593 - val_loss: 0.9615 - val_accuracy: 0.5726\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8025 - accuracy: 0.6741 - val_loss: 0.9171 - val_accuracy: 0.6410\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.7417 - accuracy: 0.6630 - val_loss: 0.9144 - val_accuracy: 0.6154\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 267us/step - loss: 0.7513 - accuracy: 0.6963 - val_loss: 0.9952 - val_accuracy: 0.5470\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 364us/step - loss: 0.9982 - accuracy: 0.6556 - val_loss: 0.9672 - val_accuracy: 0.6325\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 1.2467 - accuracy: 0.6926 - val_loss: 1.2764 - val_accuracy: 0.6154\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 338us/step - loss: 1.0759 - accuracy: 0.6741 - val_loss: 0.9707 - val_accuracy: 0.5299\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8428 - accuracy: 0.6704 - val_loss: 0.9134 - val_accuracy: 0.6154\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.7414 - accuracy: 0.6741 - val_loss: 0.9701 - val_accuracy: 0.5470\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.7916 - accuracy: 0.6889 - val_loss: 0.9363 - val_accuracy: 0.6410\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7180 - accuracy: 0.7037 - val_loss: 0.9473 - val_accuracy: 0.5983\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.7171 - accuracy: 0.6852 - val_loss: 0.9121 - val_accuracy: 0.5897\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.7024 - accuracy: 0.7000 - val_loss: 0.9267 - val_accuracy: 0.5983\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.7104 - accuracy: 0.6963 - val_loss: 0.9468 - val_accuracy: 0.5556\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7284 - accuracy: 0.6852 - val_loss: 0.9053 - val_accuracy: 0.6154\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7340 - accuracy: 0.6815 - val_loss: 0.9215 - val_accuracy: 0.6325\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7483 - accuracy: 0.6852 - val_loss: 0.9289 - val_accuracy: 0.5897\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7029 - accuracy: 0.7000 - val_loss: 0.9291 - val_accuracy: 0.5470\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7095 - accuracy: 0.6926 - val_loss: 0.9215 - val_accuracy: 0.6068\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.7143 - accuracy: 0.6926 - val_loss: 0.9157 - val_accuracy: 0.5983\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7238 - accuracy: 0.6963 - val_loss: 0.9648 - val_accuracy: 0.5299\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7419 - accuracy: 0.6778 - val_loss: 0.9126 - val_accuracy: 0.6239\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6990 - accuracy: 0.6926 - val_loss: 0.9193 - val_accuracy: 0.5983\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7116 - accuracy: 0.7000 - val_loss: 0.9152 - val_accuracy: 0.6325\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7210 - accuracy: 0.6926 - val_loss: 0.9183 - val_accuracy: 0.6154\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7078 - accuracy: 0.7000 - val_loss: 0.9276 - val_accuracy: 0.5897\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.7109 - accuracy: 0.6889 - val_loss: 0.9183 - val_accuracy: 0.6239\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7128 - accuracy: 0.6963 - val_loss: 0.9394 - val_accuracy: 0.6154\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7073 - accuracy: 0.7111 - val_loss: 0.9440 - val_accuracy: 0.5983\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7649 - accuracy: 0.6741 - val_loss: 0.9689 - val_accuracy: 0.5812\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7539 - accuracy: 0.6667 - val_loss: 0.9869 - val_accuracy: 0.5470\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.7399 - accuracy: 0.6778 - val_loss: 0.9509 - val_accuracy: 0.6068\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7200 - accuracy: 0.6778 - val_loss: 1.0168 - val_accuracy: 0.5128\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7412 - accuracy: 0.7074 - val_loss: 0.9849 - val_accuracy: 0.6325\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9185 - accuracy: 0.62 - 0s 149us/step - loss: 0.8404 - accuracy: 0.7111 - val_loss: 0.9370 - val_accuracy: 0.5812\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8680 - accuracy: 0.6778 - val_loss: 1.0141 - val_accuracy: 0.6325\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8106 - accuracy: 0.6852 - val_loss: 0.9116 - val_accuracy: 0.5897\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9061 - accuracy: 0.6852 - val_loss: 0.9195 - val_accuracy: 0.6154\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7748 - accuracy: 0.6667 - val_loss: 0.9415 - val_accuracy: 0.5385\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7122 - accuracy: 0.7000 - val_loss: 0.9167 - val_accuracy: 0.5641\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6991 - accuracy: 0.6815 - val_loss: 0.9363 - val_accuracy: 0.5556\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7026 - accuracy: 0.7037 - val_loss: 0.9436 - val_accuracy: 0.5385\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6981 - accuracy: 0.6889 - val_loss: 0.9200 - val_accuracy: 0.5470\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6989 - accuracy: 0.6852 - val_loss: 0.9206 - val_accuracy: 0.5641\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7060 - accuracy: 0.6963 - val_loss: 0.9321 - val_accuracy: 0.5385\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7037 - accuracy: 0.6889 - val_loss: 0.9342 - val_accuracy: 0.5812\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7210 - accuracy: 0.6815 - val_loss: 0.9095 - val_accuracy: 0.5812\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7416 - accuracy: 0.6926 - val_loss: 0.9838 - val_accuracy: 0.5214\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7948 - accuracy: 0.6778 - val_loss: 0.9780 - val_accuracy: 0.5897\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7511 - accuracy: 0.6889 - val_loss: 1.1512 - val_accuracy: 0.5214\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8450 - accuracy: 0.7037 - val_loss: 1.0267 - val_accuracy: 0.5812\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8224 - accuracy: 0.6630 - val_loss: 1.0424 - val_accuracy: 0.5043\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6882 - accuracy: 0.7185 - val_loss: 0.9317 - val_accuracy: 0.5897\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7412 - accuracy: 0.6889 - val_loss: 0.9122 - val_accuracy: 0.5983\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8471 - accuracy: 0.6926 - val_loss: 0.9342 - val_accuracy: 0.6239\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8089 - accuracy: 0.6741 - val_loss: 0.9757 - val_accuracy: 0.5983\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9123 - accuracy: 0.6889 - val_loss: 0.9577 - val_accuracy: 0.6325\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8366 - accuracy: 0.6556 - val_loss: 0.9482 - val_accuracy: 0.6068\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7895 - accuracy: 0.7000 - val_loss: 0.9716 - val_accuracy: 0.6154\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6910 - accuracy: 0.7148 - val_loss: 1.0268 - val_accuracy: 0.5043\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7405 - accuracy: 0.7037 - val_loss: 0.9264 - val_accuracy: 0.5897\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8161 - accuracy: 0.6778 - val_loss: 0.9583 - val_accuracy: 0.5983\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9330 - accuracy: 0.7000 - val_loss: 1.0055 - val_accuracy: 0.6239\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7579 - accuracy: 0.6852 - val_loss: 0.9560 - val_accuracy: 0.5470\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.7148 - accuracy: 0.7037 - val_loss: 0.9560 - val_accuracy: 0.5470\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7677 - accuracy: 0.6556 - val_loss: 1.0114 - val_accuracy: 0.5299\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7410 - accuracy: 0.6926 - val_loss: 0.9577 - val_accuracy: 0.5385\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7044 - accuracy: 0.6926 - val_loss: 0.9615 - val_accuracy: 0.5556\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.7231 - accuracy: 0.6815 - val_loss: 0.9674 - val_accuracy: 0.5812\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7036 - accuracy: 0.7037 - val_loss: 1.0641 - val_accuracy: 0.5128\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 327us/step - loss: 0.7545 - accuracy: 0.6889 - val_loss: 0.9540 - val_accuracy: 0.5897\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 307us/step - loss: 0.7165 - accuracy: 0.7111 - val_loss: 1.0402 - val_accuracy: 0.5128\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7584 - accuracy: 0.6852 - val_loss: 0.9306 - val_accuracy: 0.5812\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.6996 - accuracy: 0.6815 - val_loss: 0.9243 - val_accuracy: 0.6325\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7063 - accuracy: 0.6926 - val_loss: 0.9375 - val_accuracy: 0.6239\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.7173 - accuracy: 0.6889 - val_loss: 0.9410 - val_accuracy: 0.5470\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.7056 - accuracy: 0.6926 - val_loss: 0.9391 - val_accuracy: 0.5897\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7232 - accuracy: 0.6963 - val_loss: 0.9502 - val_accuracy: 0.5385\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.6865 - accuracy: 0.7074 - val_loss: 0.9219 - val_accuracy: 0.5897\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6989 - accuracy: 0.7185 - val_loss: 0.9306 - val_accuracy: 0.5641\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7873 - accuracy: 0.6889 - val_loss: 1.0197 - val_accuracy: 0.5726\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.7518 - accuracy: 0.7074 - val_loss: 1.0431 - val_accuracy: 0.5128\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.7740 - accuracy: 0.6963 - val_loss: 0.9571 - val_accuracy: 0.5983\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.7236 - accuracy: 0.7037 - val_loss: 0.9301 - val_accuracy: 0.5897\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6866 - accuracy: 0.7074 - val_loss: 0.9365 - val_accuracy: 0.5641\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.6860 - accuracy: 0.7037 - val_loss: 0.9473 - val_accuracy: 0.5299\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7008 - accuracy: 0.6852 - val_loss: 0.9479 - val_accuracy: 0.5983\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7444 - accuracy: 0.6926 - val_loss: 1.0005 - val_accuracy: 0.5299\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7503 - accuracy: 0.7037 - val_loss: 0.9637 - val_accuracy: 0.5897\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7842 - accuracy: 0.7000 - val_loss: 0.9416 - val_accuracy: 0.5556\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.7532 - accuracy: 0.7037 - val_loss: 1.0057 - val_accuracy: 0.5983\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 268us/step - loss: 0.8304 - accuracy: 0.6889 - val_loss: 0.9436 - val_accuracy: 0.5470\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7296 - accuracy: 0.7000 - val_loss: 0.9624 - val_accuracy: 0.5299\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6911 - accuracy: 0.7000 - val_loss: 0.9470 - val_accuracy: 0.5385\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.7173 - accuracy: 0.7000 - val_loss: 0.9483 - val_accuracy: 0.5983\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7573 - accuracy: 0.6741 - val_loss: 0.9357 - val_accuracy: 0.5983\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7184 - accuracy: 0.6926 - val_loss: 0.9478 - val_accuracy: 0.6154\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7081 - accuracy: 0.7074 - val_loss: 0.9953 - val_accuracy: 0.5299\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8177 - accuracy: 0.6852 - val_loss: 1.0185 - val_accuracy: 0.5983\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8801 - accuracy: 0.6889 - val_loss: 0.9427 - val_accuracy: 0.5726\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7700 - accuracy: 0.6741 - val_loss: 0.9701 - val_accuracy: 0.5983\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8585 - accuracy: 0.6963 - val_loss: 1.0508 - val_accuracy: 0.5556\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7607 - accuracy: 0.6778 - val_loss: 1.0308 - val_accuracy: 0.5470\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.7651 - accuracy: 0.6815 - val_loss: 1.0126 - val_accuracy: 0.5043\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7126 - accuracy: 0.7000 - val_loss: 0.9586 - val_accuracy: 0.5897\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7877 - accuracy: 0.7037 - val_loss: 0.9873 - val_accuracy: 0.5128\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8154 - accuracy: 0.6815 - val_loss: 0.9853 - val_accuracy: 0.5983\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8853 - accuracy: 0.7000 - val_loss: 1.0373 - val_accuracy: 0.5556\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8309 - accuracy: 0.6630 - val_loss: 1.0812 - val_accuracy: 0.4701\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7596 - accuracy: 0.6852 - val_loss: 0.9965 - val_accuracy: 0.5897\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 494us/step - loss: 0.7158 - accuracy: 0.6889 - val_loss: 0.9435 - val_accuracy: 0.5812\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.6878 - accuracy: 0.7074 - val_loss: 0.9747 - val_accuracy: 0.5299\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6809 - accuracy: 0.6889 - val_loss: 0.9358 - val_accuracy: 0.5897\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 78us/step - loss: 0.7145 - accuracy: 0.6815 - val_loss: 0.9358 - val_accuracy: 0.5897\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8767 - accuracy: 0.7037 - val_loss: 1.0904 - val_accuracy: 0.5983\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8377 - accuracy: 0.6963 - val_loss: 1.0983 - val_accuracy: 0.4701\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8629 - accuracy: 0.6667 - val_loss: 1.0094 - val_accuracy: 0.5897\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7583 - accuracy: 0.6926 - val_loss: 1.0467 - val_accuracy: 0.4786\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.7775 - accuracy: 0.6852 - val_loss: 0.9648 - val_accuracy: 0.5812\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7638 - accuracy: 0.6778 - val_loss: 0.9784 - val_accuracy: 0.5385\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6854 - accuracy: 0.6926 - val_loss: 0.9455 - val_accuracy: 0.5470\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6852 - accuracy: 0.7074 - val_loss: 0.9414 - val_accuracy: 0.5812\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6800 - accuracy: 0.7148 - val_loss: 1.0291 - val_accuracy: 0.5214\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8462 - accuracy: 0.6852 - val_loss: 0.9781 - val_accuracy: 0.5897\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7180 - accuracy: 0.6889 - val_loss: 0.9766 - val_accuracy: 0.5470\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7042 - accuracy: 0.7037 - val_loss: 0.9610 - val_accuracy: 0.5556\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6812 - accuracy: 0.6889 - val_loss: 0.9515 - val_accuracy: 0.5812\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6987 - accuracy: 0.7000 - val_loss: 1.0303 - val_accuracy: 0.5043\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.7354 - accuracy: 0.6852 - val_loss: 0.9928 - val_accuracy: 0.5812\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7763 - accuracy: 0.7000 - val_loss: 0.9616 - val_accuracy: 0.5385\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6942 - accuracy: 0.6926 - val_loss: 0.9390 - val_accuracy: 0.5897\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 383us/step - loss: 0.7115 - accuracy: 0.7037 - val_loss: 0.9529 - val_accuracy: 0.5812\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 372us/step - loss: 0.7120 - accuracy: 0.6926 - val_loss: 0.9610 - val_accuracy: 0.5299\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6865 - accuracy: 0.7111 - val_loss: 0.9523 - val_accuracy: 0.5812\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6810 - accuracy: 0.7074 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.7772 - accuracy: 0.7000 - val_loss: 1.0131 - val_accuracy: 0.5897\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.7825 - accuracy: 0.6815 - val_loss: 0.9420 - val_accuracy: 0.5641\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.7339 - accuracy: 0.7037 - val_loss: 0.9514 - val_accuracy: 0.5726\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.6987 - accuracy: 0.6963 - val_loss: 0.9587 - val_accuracy: 0.5983\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 472us/step - loss: 0.7002 - accuracy: 0.7074 - val_loss: 0.9473 - val_accuracy: 0.5556\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6760 - accuracy: 0.7074 - val_loss: 0.9408 - val_accuracy: 0.5812\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6897 - accuracy: 0.7000 - val_loss: 0.9482 - val_accuracy: 0.5897\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.7087 - accuracy: 0.7074 - val_loss: 1.1087 - val_accuracy: 0.5214\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7133 - accuracy: 0.6778 - val_loss: 0.9932 - val_accuracy: 0.5983\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.7515 - accuracy: 0.6815 - val_loss: 0.9742 - val_accuracy: 0.5385\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7347 - accuracy: 0.6963 - val_loss: 0.9525 - val_accuracy: 0.5641\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9817 - accuracy: 0.6667 - val_loss: 0.9705 - val_accuracy: 0.6154\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9473 - accuracy: 0.6963 - val_loss: 1.0513 - val_accuracy: 0.5897\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7404 - accuracy: 0.7111 - val_loss: 1.0781 - val_accuracy: 0.5128\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8094 - accuracy: 0.6593 - val_loss: 0.9685 - val_accuracy: 0.6068\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7054 - accuracy: 0.6963 - val_loss: 0.9435 - val_accuracy: 0.5897\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 442us/step - loss: 0.6798 - accuracy: 0.7111 - val_loss: 0.9403 - val_accuracy: 0.5812\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 279us/step - loss: 0.6928 - accuracy: 0.7000 - val_loss: 0.9823 - val_accuracy: 0.5641\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.7064 - accuracy: 0.6815 - val_loss: 0.9524 - val_accuracy: 0.5897\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6813 - accuracy: 0.7000 - val_loss: 0.9940 - val_accuracy: 0.5556\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.6979 - accuracy: 0.6963 - val_loss: 0.9455 - val_accuracy: 0.5897\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 407us/step - loss: 0.6797 - accuracy: 0.7000 - val_loss: 0.9415 - val_accuracy: 0.5983\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.6660 - accuracy: 0.6963 - val_loss: 0.9397 - val_accuracy: 0.5983\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6731 - accuracy: 0.7074 - val_loss: 0.9908 - val_accuracy: 0.5556\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7356 - accuracy: 0.7111 - val_loss: 0.9832 - val_accuracy: 0.5897\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7213 - accuracy: 0.6963 - val_loss: 1.0170 - val_accuracy: 0.5470\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7556 - accuracy: 0.6926 - val_loss: 1.0791 - val_accuracy: 0.5385\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8700 - accuracy: 0.6815 - val_loss: 0.9599 - val_accuracy: 0.5812\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8590 - accuracy: 0.6741 - val_loss: 0.9660 - val_accuracy: 0.5897\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7982 - accuracy: 0.6889 - val_loss: 0.9768 - val_accuracy: 0.5726\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6805 - accuracy: 0.6889 - val_loss: 0.9519 - val_accuracy: 0.5897\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6976 - accuracy: 0.7037 - val_loss: 0.9942 - val_accuracy: 0.5641\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.7134 - accuracy: 0.6926 - val_loss: 0.9679 - val_accuracy: 0.5897\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7399 - accuracy: 0.6815 - val_loss: 0.9601 - val_accuracy: 0.5897\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7264 - accuracy: 0.7111 - val_loss: 0.9899 - val_accuracy: 0.5641\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7549 - accuracy: 0.6963 - val_loss: 0.9924 - val_accuracy: 0.5897\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.7947 - accuracy: 0.6963 - val_loss: 1.0107 - val_accuracy: 0.6154\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7242 - accuracy: 0.6963 - val_loss: 0.9720 - val_accuracy: 0.5641\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6694 - accuracy: 0.7037 - val_loss: 1.0071 - val_accuracy: 0.5641\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6790 - accuracy: 0.7037 - val_loss: 0.9777 - val_accuracy: 0.5897\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7461 - accuracy: 0.7111 - val_loss: 0.9610 - val_accuracy: 0.5897\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6964 - accuracy: 0.7074 - val_loss: 1.0022 - val_accuracy: 0.5897\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7142 - accuracy: 0.7111 - val_loss: 1.0080 - val_accuracy: 0.5470\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7573 - accuracy: 0.6889 - val_loss: 0.9964 - val_accuracy: 0.5983\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7522 - accuracy: 0.7000 - val_loss: 0.9727 - val_accuracy: 0.5556\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6939 - accuracy: 0.7074 - val_loss: 0.9678 - val_accuracy: 0.5983\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7013 - accuracy: 0.6852 - val_loss: 0.9607 - val_accuracy: 0.5726\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7159 - accuracy: 0.7148 - val_loss: 0.9720 - val_accuracy: 0.5897\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8262 - accuracy: 0.6704 - val_loss: 0.9511 - val_accuracy: 0.5983\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7966 - accuracy: 0.6889 - val_loss: 1.0797 - val_accuracy: 0.5556\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7703 - accuracy: 0.6852 - val_loss: 0.9872 - val_accuracy: 0.5641\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7491 - accuracy: 0.6815 - val_loss: 0.9999 - val_accuracy: 0.5983\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7038 - accuracy: 0.6889 - val_loss: 1.1689 - val_accuracy: 0.5128\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8557 - accuracy: 0.6889 - val_loss: 1.0268 - val_accuracy: 0.5897\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7657 - accuracy: 0.6852 - val_loss: 0.9693 - val_accuracy: 0.6068\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7090 - accuracy: 0.7074 - val_loss: 0.9607 - val_accuracy: 0.5983\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6841 - accuracy: 0.7000 - val_loss: 0.9561 - val_accuracy: 0.5983\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6839 - accuracy: 0.7037 - val_loss: 0.9633 - val_accuracy: 0.5897\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6603 - accuracy: 0.6926 - val_loss: 0.9560 - val_accuracy: 0.5983\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6806 - accuracy: 0.7037 - val_loss: 1.0036 - val_accuracy: 0.5385\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6584 - accuracy: 0.7000 - val_loss: 0.9820 - val_accuracy: 0.5897\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6978 - accuracy: 0.7074 - val_loss: 0.9724 - val_accuracy: 0.5726\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6627 - accuracy: 0.7037 - val_loss: 0.9795 - val_accuracy: 0.5897\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7060 - accuracy: 0.6963 - val_loss: 0.9560 - val_accuracy: 0.5812\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6733 - accuracy: 0.6852 - val_loss: 0.9693 - val_accuracy: 0.5897\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6935 - accuracy: 0.6852 - val_loss: 1.0371 - val_accuracy: 0.5128\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7142 - accuracy: 0.6926 - val_loss: 0.9910 - val_accuracy: 0.5983\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6933 - accuracy: 0.6963 - val_loss: 1.0196 - val_accuracy: 0.5299\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6872 - accuracy: 0.6889 - val_loss: 0.9755 - val_accuracy: 0.5897\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6765 - accuracy: 0.6778 - val_loss: 0.9944 - val_accuracy: 0.5726\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7671 - accuracy: 0.7111 - val_loss: 0.9672 - val_accuracy: 0.5726\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6828 - accuracy: 0.6889 - val_loss: 0.9824 - val_accuracy: 0.5897\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6941 - accuracy: 0.7000 - val_loss: 0.9875 - val_accuracy: 0.5385\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6699 - accuracy: 0.7037 - val_loss: 0.9929 - val_accuracy: 0.5897\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7293 - accuracy: 0.6963 - val_loss: 0.9776 - val_accuracy: 0.5556\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6766 - accuracy: 0.6852 - val_loss: 0.9749 - val_accuracy: 0.6068\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6608 - accuracy: 0.7148 - val_loss: 0.9780 - val_accuracy: 0.5983\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6611 - accuracy: 0.7111 - val_loss: 0.9812 - val_accuracy: 0.6068\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6763 - accuracy: 0.6778 - val_loss: 0.9961 - val_accuracy: 0.5983\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7174 - accuracy: 0.7037 - val_loss: 0.9695 - val_accuracy: 0.5983\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6922 - accuracy: 0.6741 - val_loss: 0.9688 - val_accuracy: 0.5983\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7479 - accuracy: 0.7074 - val_loss: 1.0114 - val_accuracy: 0.5812\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6940 - accuracy: 0.6926 - val_loss: 1.0295 - val_accuracy: 0.5214\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6695 - accuracy: 0.7111 - val_loss: 0.9844 - val_accuracy: 0.5897\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6795 - accuracy: 0.7148 - val_loss: 0.9760 - val_accuracy: 0.5897\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7163 - accuracy: 0.7185 - val_loss: 0.9894 - val_accuracy: 0.5812\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6902 - accuracy: 0.6778 - val_loss: 0.9852 - val_accuracy: 0.5556\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6701 - accuracy: 0.6963 - val_loss: 1.1316 - val_accuracy: 0.5470\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 72us/step - loss: 0.7966 - accuracy: 0.6889 - val_loss: 1.0082 - val_accuracy: 0.5812\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7287 - accuracy: 0.6815 - val_loss: 0.9789 - val_accuracy: 0.5726\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7083 - accuracy: 0.6963 - val_loss: 0.9899 - val_accuracy: 0.5385\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6849 - accuracy: 0.6963 - val_loss: 0.9765 - val_accuracy: 0.5726\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6733 - accuracy: 0.7074 - val_loss: 0.9884 - val_accuracy: 0.5983\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6774 - accuracy: 0.7185 - val_loss: 0.9943 - val_accuracy: 0.5385\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6612 - accuracy: 0.7111 - val_loss: 0.9695 - val_accuracy: 0.5983\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6541 - accuracy: 0.7111 - val_loss: 0.9686 - val_accuracy: 0.5983\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6583 - accuracy: 0.6963 - val_loss: 0.9993 - val_accuracy: 0.5385\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6902 - accuracy: 0.6741 - val_loss: 0.9737 - val_accuracy: 0.5983\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6569 - accuracy: 0.7074 - val_loss: 1.0122 - val_accuracy: 0.5128\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6480 - accuracy: 0.7296 - val_loss: 0.9892 - val_accuracy: 0.5983\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6789 - accuracy: 0.7000 - val_loss: 0.9813 - val_accuracy: 0.5983\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6435 - accuracy: 0.7074 - val_loss: 0.9799 - val_accuracy: 0.5983\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6470 - accuracy: 0.7185 - val_loss: 0.9893 - val_accuracy: 0.6154\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6637 - accuracy: 0.7185 - val_loss: 0.9817 - val_accuracy: 0.5983\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6763 - accuracy: 0.7037 - val_loss: 0.9865 - val_accuracy: 0.5897\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6690 - accuracy: 0.7259 - val_loss: 0.9992 - val_accuracy: 0.5897\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7063 - accuracy: 0.7037 - val_loss: 0.9802 - val_accuracy: 0.6154\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6537 - accuracy: 0.7148 - val_loss: 0.9801 - val_accuracy: 0.6068\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6595 - accuracy: 0.6889 - val_loss: 0.9819 - val_accuracy: 0.5983\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6905 - accuracy: 0.7111 - val_loss: 0.9918 - val_accuracy: 0.5556\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6650 - accuracy: 0.7074 - val_loss: 0.9767 - val_accuracy: 0.5897\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6418 - accuracy: 0.6889 - val_loss: 0.9846 - val_accuracy: 0.5897\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6439 - accuracy: 0.6963 - val_loss: 0.9786 - val_accuracy: 0.5726\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6488 - accuracy: 0.7074 - val_loss: 0.9967 - val_accuracy: 0.5812\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7031 - accuracy: 0.7037 - val_loss: 1.0032 - val_accuracy: 0.5983\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7379 - accuracy: 0.7185 - val_loss: 0.9970 - val_accuracy: 0.5726\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6904 - accuracy: 0.6889 - val_loss: 0.9959 - val_accuracy: 0.5812\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6587 - accuracy: 0.7000 - val_loss: 0.9859 - val_accuracy: 0.5897\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6540 - accuracy: 0.7222 - val_loss: 0.9826 - val_accuracy: 0.5726\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6587 - accuracy: 0.7000 - val_loss: 0.9861 - val_accuracy: 0.5726\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6661 - accuracy: 0.7074 - val_loss: 0.9902 - val_accuracy: 0.5983\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6800 - accuracy: 0.7148 - val_loss: 0.9923 - val_accuracy: 0.6239\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7425 - accuracy: 0.7111 - val_loss: 1.0012 - val_accuracy: 0.5897\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6711 - accuracy: 0.7111 - val_loss: 1.0017 - val_accuracy: 0.5812\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6754 - accuracy: 0.7148 - val_loss: 1.0426 - val_accuracy: 0.5641\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6896 - accuracy: 0.6889 - val_loss: 1.0434 - val_accuracy: 0.6068\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6998 - accuracy: 0.7148 - val_loss: 1.0073 - val_accuracy: 0.5470\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6803 - accuracy: 0.6926 - val_loss: 0.9842 - val_accuracy: 0.5983\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6478 - accuracy: 0.6963 - val_loss: 1.0137 - val_accuracy: 0.5983\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6490 - accuracy: 0.7296 - val_loss: 0.9841 - val_accuracy: 0.5812\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6407 - accuracy: 0.6963 - val_loss: 0.9878 - val_accuracy: 0.5726\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6414 - accuracy: 0.6926 - val_loss: 0.9861 - val_accuracy: 0.6154\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6455 - accuracy: 0.7111 - val_loss: 0.9893 - val_accuracy: 0.6068\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6446 - accuracy: 0.7148 - val_loss: 0.9897 - val_accuracy: 0.6068\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6641 - accuracy: 0.7185 - val_loss: 0.9892 - val_accuracy: 0.6068\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6543 - accuracy: 0.7185 - val_loss: 0.9900 - val_accuracy: 0.6068\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6425 - accuracy: 0.7037 - val_loss: 0.9900 - val_accuracy: 0.6068\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6720 - accuracy: 0.6963 - val_loss: 0.9845 - val_accuracy: 0.6068\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7005 - accuracy: 0.7148 - val_loss: 1.0228 - val_accuracy: 0.5726\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6818 - accuracy: 0.7148 - val_loss: 0.9983 - val_accuracy: 0.6068\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7471 - accuracy: 0.6926 - val_loss: 1.0596 - val_accuracy: 0.6068\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7102 - accuracy: 0.7222 - val_loss: 1.1041 - val_accuracy: 0.5214\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6870 - accuracy: 0.7000 - val_loss: 1.0142 - val_accuracy: 0.6068\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7024 - accuracy: 0.7148 - val_loss: 1.0306 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6666 - accuracy: 0.7074 - val_loss: 1.0013 - val_accuracy: 0.6068\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6593 - accuracy: 0.7111 - val_loss: 1.1057 - val_accuracy: 0.5470\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6647 - accuracy: 0.7296 - val_loss: 1.0169 - val_accuracy: 0.6154\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6637 - accuracy: 0.7074 - val_loss: 1.0339 - val_accuracy: 0.5556\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6834 - accuracy: 0.7111 - val_loss: 1.0366 - val_accuracy: 0.6068\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6860 - accuracy: 0.7000 - val_loss: 1.0191 - val_accuracy: 0.5726\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6465 - accuracy: 0.7111 - val_loss: 0.9975 - val_accuracy: 0.5983\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6466 - accuracy: 0.7000 - val_loss: 1.0317 - val_accuracy: 0.5897\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6920 - accuracy: 0.7037 - val_loss: 0.9964 - val_accuracy: 0.5983\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6537 - accuracy: 0.7000 - val_loss: 0.9956 - val_accuracy: 0.5726\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6763 - accuracy: 0.7037 - val_loss: 1.0015 - val_accuracy: 0.5983\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6373 - accuracy: 0.7148 - val_loss: 1.0418 - val_accuracy: 0.5214\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6415 - accuracy: 0.7148 - val_loss: 1.0025 - val_accuracy: 0.6068\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6413 - accuracy: 0.7148 - val_loss: 1.0055 - val_accuracy: 0.6068\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6386 - accuracy: 0.7148 - val_loss: 0.9998 - val_accuracy: 0.6154\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6323 - accuracy: 0.7111 - val_loss: 1.0110 - val_accuracy: 0.5641\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6443 - accuracy: 0.7074 - val_loss: 1.0003 - val_accuracy: 0.6068\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6918 - accuracy: 0.7222 - val_loss: 1.0012 - val_accuracy: 0.6239\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7817 - accuracy: 0.7037 - val_loss: 1.0678 - val_accuracy: 0.5897\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6976 - accuracy: 0.7333 - val_loss: 1.0358 - val_accuracy: 0.5812\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6427 - accuracy: 0.7148 - val_loss: 1.0118 - val_accuracy: 0.6068\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6474 - accuracy: 0.7111 - val_loss: 1.0226 - val_accuracy: 0.6068\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6511 - accuracy: 0.7111 - val_loss: 1.0108 - val_accuracy: 0.5812\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6303 - accuracy: 0.7222 - val_loss: 1.0063 - val_accuracy: 0.6068\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6558 - accuracy: 0.7111 - val_loss: 1.0327 - val_accuracy: 0.6154\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6498 - accuracy: 0.7037 - val_loss: 1.0210 - val_accuracy: 0.5641\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6380 - accuracy: 0.7222 - val_loss: 1.0498 - val_accuracy: 0.5812\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6607 - accuracy: 0.7074 - val_loss: 1.0109 - val_accuracy: 0.6239\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6464 - accuracy: 0.7037 - val_loss: 1.0498 - val_accuracy: 0.5812\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6510 - accuracy: 0.6852 - val_loss: 1.0214 - val_accuracy: 0.6068\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6426 - accuracy: 0.7000 - val_loss: 1.0212 - val_accuracy: 0.6068\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6502 - accuracy: 0.7037 - val_loss: 1.0095 - val_accuracy: 0.5897\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6278 - accuracy: 0.7259 - val_loss: 1.0208 - val_accuracy: 0.5726\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6324 - accuracy: 0.6963 - val_loss: 1.0194 - val_accuracy: 0.6068\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6462 - accuracy: 0.7037 - val_loss: 1.0602 - val_accuracy: 0.5897\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7312 - accuracy: 0.7185 - val_loss: 1.0204 - val_accuracy: 0.5556\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6538 - accuracy: 0.7111 - val_loss: 1.0404 - val_accuracy: 0.6154\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7017 - accuracy: 0.7074 - val_loss: 1.0090 - val_accuracy: 0.5983\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6496 - accuracy: 0.7037 - val_loss: 1.0247 - val_accuracy: 0.6239\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6313 - accuracy: 0.7037 - val_loss: 1.0298 - val_accuracy: 0.5983\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6262 - accuracy: 0.7148 - val_loss: 1.0142 - val_accuracy: 0.6154\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6299 - accuracy: 0.7148 - val_loss: 1.0214 - val_accuracy: 0.6068\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6352 - accuracy: 0.7074 - val_loss: 1.0192 - val_accuracy: 0.5897\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6328 - accuracy: 0.7259 - val_loss: 1.0163 - val_accuracy: 0.6154\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6309 - accuracy: 0.7111 - val_loss: 1.0218 - val_accuracy: 0.6154\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6374 - accuracy: 0.7111 - val_loss: 1.0412 - val_accuracy: 0.5897\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6398 - accuracy: 0.7148 - val_loss: 1.0216 - val_accuracy: 0.6068\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6336 - accuracy: 0.7222 - val_loss: 1.0181 - val_accuracy: 0.6068\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6274 - accuracy: 0.7074 - val_loss: 1.0297 - val_accuracy: 0.6068\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6714 - accuracy: 0.7000 - val_loss: 1.0454 - val_accuracy: 0.5983\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6426 - accuracy: 0.7037 - val_loss: 1.0407 - val_accuracy: 0.5470\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6485 - accuracy: 0.7148 - val_loss: 1.0221 - val_accuracy: 0.6068\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6325 - accuracy: 0.7222 - val_loss: 1.0282 - val_accuracy: 0.5556\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6332 - accuracy: 0.7259 - val_loss: 1.0165 - val_accuracy: 0.5983\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6235 - accuracy: 0.7222 - val_loss: 1.0228 - val_accuracy: 0.5983\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6297 - accuracy: 0.7111 - val_loss: 1.0377 - val_accuracy: 0.6154\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6334 - accuracy: 0.7259 - val_loss: 1.0341 - val_accuracy: 0.5812\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6379 - accuracy: 0.7111 - val_loss: 1.0435 - val_accuracy: 0.6068\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.6498 - accuracy: 0.7074 - val_loss: 1.0451 - val_accuracy: 0.6068\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.7374 - accuracy: 0.7037 - val_loss: 1.0439 - val_accuracy: 0.5983\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.6788 - accuracy: 0.7074 - val_loss: 1.0265 - val_accuracy: 0.6068\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7077 - accuracy: 0.7259 - val_loss: 1.0348 - val_accuracy: 0.5897\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6215 - accuracy: 0.7148 - val_loss: 1.1099 - val_accuracy: 0.5641\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6553 - accuracy: 0.7037 - val_loss: 1.0357 - val_accuracy: 0.6068\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6395 - accuracy: 0.7074 - val_loss: 1.0330 - val_accuracy: 0.5897\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6307 - accuracy: 0.6963 - val_loss: 1.0305 - val_accuracy: 0.6068\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6251 - accuracy: 0.7037 - val_loss: 1.0281 - val_accuracy: 0.6068\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6272 - accuracy: 0.7185 - val_loss: 1.0235 - val_accuracy: 0.6068\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6287 - accuracy: 0.6963 - val_loss: 1.0406 - val_accuracy: 0.6239\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6726 - accuracy: 0.7111 - val_loss: 1.0464 - val_accuracy: 0.6068\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6344 - accuracy: 0.7074 - val_loss: 1.0436 - val_accuracy: 0.6154\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6472 - accuracy: 0.7111 - val_loss: 1.0145 - val_accuracy: 0.6154\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6655 - accuracy: 0.7074 - val_loss: 1.0492 - val_accuracy: 0.6154\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6333 - accuracy: 0.7259 - val_loss: 1.0574 - val_accuracy: 0.5983\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7236 - accuracy: 0.7037 - val_loss: 1.0631 - val_accuracy: 0.6068\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7042 - accuracy: 0.7111 - val_loss: 1.0166 - val_accuracy: 0.5983\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6762 - accuracy: 0.7148 - val_loss: 1.0747 - val_accuracy: 0.6154\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7132 - accuracy: 0.7111 - val_loss: 1.1541 - val_accuracy: 0.5556\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7683 - accuracy: 0.6963 - val_loss: 1.0852 - val_accuracy: 0.5812\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6712 - accuracy: 0.7148 - val_loss: 1.0918 - val_accuracy: 0.5726\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7216 - accuracy: 0.7000 - val_loss: 1.1041 - val_accuracy: 0.6068\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7372 - accuracy: 0.7148 - val_loss: 1.0374 - val_accuracy: 0.5812\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6437 - accuracy: 0.7111 - val_loss: 1.1714 - val_accuracy: 0.5214\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7118 - accuracy: 0.7074 - val_loss: 1.1169 - val_accuracy: 0.5983\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7378 - accuracy: 0.7037 - val_loss: 1.0507 - val_accuracy: 0.5641\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7189 - accuracy: 0.6889 - val_loss: 1.0529 - val_accuracy: 0.5812\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7246 - accuracy: 0.7185 - val_loss: 1.0698 - val_accuracy: 0.6068\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7197 - accuracy: 0.6963 - val_loss: 1.0499 - val_accuracy: 0.5299\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7901 - accuracy: 0.7074 - val_loss: 1.0992 - val_accuracy: 0.5983\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7118 - accuracy: 0.7296 - val_loss: 1.1065 - val_accuracy: 0.4957\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6347 - accuracy: 0.6926 - val_loss: 1.0342 - val_accuracy: 0.5983\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6265 - accuracy: 0.7111 - val_loss: 1.0391 - val_accuracy: 0.5983\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6149 - accuracy: 0.7148 - val_loss: 1.0474 - val_accuracy: 0.5897\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6290 - accuracy: 0.7037 - val_loss: 1.0359 - val_accuracy: 0.6239\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6564 - accuracy: 0.7222 - val_loss: 1.0583 - val_accuracy: 0.5812\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6771 - accuracy: 0.7111 - val_loss: 1.0423 - val_accuracy: 0.6154\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6390 - accuracy: 0.7037 - val_loss: 1.0316 - val_accuracy: 0.6154\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6451 - accuracy: 0.6926 - val_loss: 1.0344 - val_accuracy: 0.6325\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6841 - accuracy: 0.7296 - val_loss: 1.0590 - val_accuracy: 0.6239\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6173 - accuracy: 0.7222 - val_loss: 1.0812 - val_accuracy: 0.5385\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6330 - accuracy: 0.7037 - val_loss: 1.0478 - val_accuracy: 0.6239\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6180 - accuracy: 0.7148 - val_loss: 1.0912 - val_accuracy: 0.5726\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6826 - accuracy: 0.6852 - val_loss: 1.0385 - val_accuracy: 0.6068\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6298 - accuracy: 0.7037 - val_loss: 1.0372 - val_accuracy: 0.5385\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6211 - accuracy: 0.6815 - val_loss: 1.0393 - val_accuracy: 0.5641\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6191 - accuracy: 0.7037 - val_loss: 1.0321 - val_accuracy: 0.6154\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6376 - accuracy: 0.7259 - val_loss: 1.0326 - val_accuracy: 0.6325\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6428 - accuracy: 0.7111 - val_loss: 1.1446 - val_accuracy: 0.5641\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7355 - accuracy: 0.7000 - val_loss: 1.1541 - val_accuracy: 0.5983\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7774 - accuracy: 0.7222 - val_loss: 1.0542 - val_accuracy: 0.6068\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 92us/step - loss: 0.6422 - accuracy: 0.7037 - val_loss: 1.0482 - val_accuracy: 0.5897\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6575 - accuracy: 0.7074 - val_loss: 1.0529 - val_accuracy: 0.6239\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6276 - accuracy: 0.7111 - val_loss: 1.0658 - val_accuracy: 0.5726\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6365 - accuracy: 0.7148 - val_loss: 1.0422 - val_accuracy: 0.6154\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6064 - accuracy: 0.7370 - val_loss: 1.0688 - val_accuracy: 0.5470\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6359 - accuracy: 0.7111 - val_loss: 1.0394 - val_accuracy: 0.6154\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6251 - accuracy: 0.7296 - val_loss: 1.0570 - val_accuracy: 0.5983\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6130 - accuracy: 0.7037 - val_loss: 1.0593 - val_accuracy: 0.6325\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6206 - accuracy: 0.7185 - val_loss: 1.0496 - val_accuracy: 0.5641\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6249 - accuracy: 0.7222 - val_loss: 1.0450 - val_accuracy: 0.6068\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6521 - accuracy: 0.7074 - val_loss: 1.0487 - val_accuracy: 0.6154\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6348 - accuracy: 0.7111 - val_loss: 1.0424 - val_accuracy: 0.5726\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6376 - accuracy: 0.7037 - val_loss: 1.0410 - val_accuracy: 0.5983\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6161 - accuracy: 0.7333 - val_loss: 1.0702 - val_accuracy: 0.6154\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6233 - accuracy: 0.7185 - val_loss: 1.0430 - val_accuracy: 0.6154\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6357 - accuracy: 0.7222 - val_loss: 1.0558 - val_accuracy: 0.5897\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6749 - accuracy: 0.7037 - val_loss: 1.0744 - val_accuracy: 0.6325\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6727 - accuracy: 0.7222 - val_loss: 1.0573 - val_accuracy: 0.6325\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6052 - accuracy: 0.7259 - val_loss: 1.0950 - val_accuracy: 0.5726\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6220 - accuracy: 0.7037 - val_loss: 1.0492 - val_accuracy: 0.6154\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6084 - accuracy: 0.7296 - val_loss: 1.0437 - val_accuracy: 0.6154\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6139 - accuracy: 0.7185 - val_loss: 1.0549 - val_accuracy: 0.5897\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6228 - accuracy: 0.7148 - val_loss: 1.0927 - val_accuracy: 0.6068\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6252 - accuracy: 0.7111 - val_loss: 1.0917 - val_accuracy: 0.5983\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6598 - accuracy: 0.7000 - val_loss: 1.1186 - val_accuracy: 0.5812\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6474 - accuracy: 0.6963 - val_loss: 1.0595 - val_accuracy: 0.5812\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7244 - accuracy: 0.6741 - val_loss: 1.2034 - val_accuracy: 0.5812\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6669 - accuracy: 0.7074 - val_loss: 1.0521 - val_accuracy: 0.5726\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6202 - accuracy: 0.7259 - val_loss: 1.0636 - val_accuracy: 0.6154\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6244 - accuracy: 0.7111 - val_loss: 1.0577 - val_accuracy: 0.6068\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6207 - accuracy: 0.7222 - val_loss: 1.0527 - val_accuracy: 0.5726\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6360 - accuracy: 0.7111 - val_loss: 1.0514 - val_accuracy: 0.6154\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6215 - accuracy: 0.7222 - val_loss: 1.1011 - val_accuracy: 0.5812\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6287 - accuracy: 0.7185 - val_loss: 1.0576 - val_accuracy: 0.6325\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6322 - accuracy: 0.7222 - val_loss: 1.0605 - val_accuracy: 0.5812\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6115 - accuracy: 0.7222 - val_loss: 1.0394 - val_accuracy: 0.6325\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6092 - accuracy: 0.7185 - val_loss: 1.0536 - val_accuracy: 0.5812\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6129 - accuracy: 0.7148 - val_loss: 1.0430 - val_accuracy: 0.6068\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6148 - accuracy: 0.6926 - val_loss: 1.0560 - val_accuracy: 0.6068\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7125 - accuracy: 0.7259 - val_loss: 1.0995 - val_accuracy: 0.6239\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6840 - accuracy: 0.6926 - val_loss: 1.0584 - val_accuracy: 0.5983\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6452 - accuracy: 0.7111 - val_loss: 1.0537 - val_accuracy: 0.6325\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6001 - accuracy: 0.7185 - val_loss: 1.0717 - val_accuracy: 0.5641\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6440 - accuracy: 0.7148 - val_loss: 1.0765 - val_accuracy: 0.6154\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6432 - accuracy: 0.7074 - val_loss: 1.0757 - val_accuracy: 0.6154\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6371 - accuracy: 0.7222 - val_loss: 1.0556 - val_accuracy: 0.5641\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6120 - accuracy: 0.7148 - val_loss: 1.0653 - val_accuracy: 0.6068\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6297 - accuracy: 0.7111 - val_loss: 1.0736 - val_accuracy: 0.5812\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 308us/step - loss: 0.6213 - accuracy: 0.7259 - val_loss: 1.0587 - val_accuracy: 0.5812\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6257 - accuracy: 0.7037 - val_loss: 1.0768 - val_accuracy: 0.5726\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6270 - accuracy: 0.7148 - val_loss: 1.0767 - val_accuracy: 0.5726\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6623 - accuracy: 0.7148 - val_loss: 1.0470 - val_accuracy: 0.5897\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7039 - accuracy: 0.7000 - val_loss: 1.0597 - val_accuracy: 0.6068\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7509 - accuracy: 0.7037 - val_loss: 1.1018 - val_accuracy: 0.6239\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6414 - accuracy: 0.7333 - val_loss: 1.2257 - val_accuracy: 0.5385\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7033 - accuracy: 0.7111 - val_loss: 1.1273 - val_accuracy: 0.6154\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8219 - accuracy: 0.7111 - val_loss: 1.1291 - val_accuracy: 0.5897\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6844 - accuracy: 0.7148 - val_loss: 1.1628 - val_accuracy: 0.5128\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6440 - accuracy: 0.7185 - val_loss: 1.0730 - val_accuracy: 0.6154\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6221 - accuracy: 0.7111 - val_loss: 1.0802 - val_accuracy: 0.5897\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6300 - accuracy: 0.7185 - val_loss: 1.0747 - val_accuracy: 0.6154\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6504 - accuracy: 0.7000 - val_loss: 1.0685 - val_accuracy: 0.5641\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6608 - accuracy: 0.7185 - val_loss: 1.0599 - val_accuracy: 0.6325\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6175 - accuracy: 0.7259 - val_loss: 1.0663 - val_accuracy: 0.5726\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6274 - accuracy: 0.7222 - val_loss: 1.0864 - val_accuracy: 0.6239\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6269 - accuracy: 0.7111 - val_loss: 1.0841 - val_accuracy: 0.6154\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6282 - accuracy: 0.7185 - val_loss: 1.0721 - val_accuracy: 0.5726\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6080 - accuracy: 0.7222 - val_loss: 1.0847 - val_accuracy: 0.5983\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6042 - accuracy: 0.7000 - val_loss: 1.0625 - val_accuracy: 0.6154\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6170 - accuracy: 0.7185 - val_loss: 1.0722 - val_accuracy: 0.6068\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6177 - accuracy: 0.7481 - val_loss: 1.0744 - val_accuracy: 0.6154\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6175 - accuracy: 0.7222 - val_loss: 1.0576 - val_accuracy: 0.6154\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5999 - accuracy: 0.7222 - val_loss: 1.0585 - val_accuracy: 0.6068\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5935 - accuracy: 0.7185 - val_loss: 1.0725 - val_accuracy: 0.5983\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6183 - accuracy: 0.7148 - val_loss: 1.0775 - val_accuracy: 0.6325\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6373 - accuracy: 0.7222 - val_loss: 1.1114 - val_accuracy: 0.5726\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6441 - accuracy: 0.7148 - val_loss: 1.0726 - val_accuracy: 0.6239\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6296 - accuracy: 0.7000 - val_loss: 1.0716 - val_accuracy: 0.6068\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6167 - accuracy: 0.7074 - val_loss: 1.0692 - val_accuracy: 0.6154\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6004 - accuracy: 0.7222 - val_loss: 1.0690 - val_accuracy: 0.5897\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5923 - accuracy: 0.7333 - val_loss: 1.0758 - val_accuracy: 0.6068\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6058 - accuracy: 0.7185 - val_loss: 1.0668 - val_accuracy: 0.6239\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6075 - accuracy: 0.7370 - val_loss: 1.0735 - val_accuracy: 0.5641\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6224 - accuracy: 0.7037 - val_loss: 1.0739 - val_accuracy: 0.6239\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6177 - accuracy: 0.7148 - val_loss: 1.0861 - val_accuracy: 0.6239\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6479 - accuracy: 0.7111 - val_loss: 1.0821 - val_accuracy: 0.5812\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6221 - accuracy: 0.7222 - val_loss: 1.0640 - val_accuracy: 0.6154\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6128 - accuracy: 0.7185 - val_loss: 1.0914 - val_accuracy: 0.6068\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6117 - accuracy: 0.7185 - val_loss: 1.0813 - val_accuracy: 0.6068\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5909 - accuracy: 0.7444 - val_loss: 1.0961 - val_accuracy: 0.5641\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6332 - accuracy: 0.7185 - val_loss: 1.1129 - val_accuracy: 0.5983\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6307 - accuracy: 0.7222 - val_loss: 1.0665 - val_accuracy: 0.6239\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7301 - accuracy: 0.7222 - val_loss: 1.1410 - val_accuracy: 0.6239\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6922 - accuracy: 0.7185 - val_loss: 1.0845 - val_accuracy: 0.5385\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6440 - accuracy: 0.7148 - val_loss: 1.0890 - val_accuracy: 0.6239\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6311 - accuracy: 0.7222 - val_loss: 1.0821 - val_accuracy: 0.5812\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6055 - accuracy: 0.7111 - val_loss: 1.0557 - val_accuracy: 0.6154\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6267 - accuracy: 0.7185 - val_loss: 1.0605 - val_accuracy: 0.5812\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5898 - accuracy: 0.7259 - val_loss: 1.0868 - val_accuracy: 0.5812\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5966 - accuracy: 0.7259 - val_loss: 1.0778 - val_accuracy: 0.6239\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6144 - accuracy: 0.7037 - val_loss: 1.0772 - val_accuracy: 0.6154\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6277 - accuracy: 0.7296 - val_loss: 1.0924 - val_accuracy: 0.6325\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6051 - accuracy: 0.7407 - val_loss: 1.0817 - val_accuracy: 0.5983\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5986 - accuracy: 0.7111 - val_loss: 1.0827 - val_accuracy: 0.6325\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6318 - accuracy: 0.7185 - val_loss: 1.0788 - val_accuracy: 0.5897\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6197 - accuracy: 0.7370 - val_loss: 1.0818 - val_accuracy: 0.5897\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6061 - accuracy: 0.7222 - val_loss: 1.0788 - val_accuracy: 0.6068\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5939 - accuracy: 0.7222 - val_loss: 1.0822 - val_accuracy: 0.5983\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6015 - accuracy: 0.7222 - val_loss: 1.0847 - val_accuracy: 0.6068\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6003 - accuracy: 0.7222 - val_loss: 1.0914 - val_accuracy: 0.5983\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 77us/step - loss: 0.5970 - accuracy: 0.7185 - val_loss: 1.0958 - val_accuracy: 0.6239\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5953 - accuracy: 0.7333 - val_loss: 1.0828 - val_accuracy: 0.6068\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5946 - accuracy: 0.7259 - val_loss: 1.0847 - val_accuracy: 0.6239\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6015 - accuracy: 0.7370 - val_loss: 1.0784 - val_accuracy: 0.6154\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6144 - accuracy: 0.7185 - val_loss: 1.0707 - val_accuracy: 0.6325\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.59 - 0s 107us/step - loss: 0.6015 - accuracy: 0.7222 - val_loss: 1.0982 - val_accuracy: 0.5897\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6003 - accuracy: 0.7185 - val_loss: 1.0936 - val_accuracy: 0.6239\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6071 - accuracy: 0.7222 - val_loss: 1.1060 - val_accuracy: 0.5641\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6009 - accuracy: 0.7185 - val_loss: 1.0836 - val_accuracy: 0.6068\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5911 - accuracy: 0.7333 - val_loss: 1.0884 - val_accuracy: 0.6068\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5897 - accuracy: 0.7407 - val_loss: 1.0772 - val_accuracy: 0.6154\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6077 - accuracy: 0.7222 - val_loss: 1.0871 - val_accuracy: 0.5983\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6001 - accuracy: 0.7259 - val_loss: 1.0744 - val_accuracy: 0.6154\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6305 - accuracy: 0.6926 - val_loss: 1.0863 - val_accuracy: 0.6239\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6438 - accuracy: 0.7407 - val_loss: 1.0799 - val_accuracy: 0.6239\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6354 - accuracy: 0.7037 - val_loss: 1.0928 - val_accuracy: 0.6154\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5984 - accuracy: 0.7259 - val_loss: 1.0768 - val_accuracy: 0.6154\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6157 - accuracy: 0.7259 - val_loss: 1.0867 - val_accuracy: 0.5556\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5968 - accuracy: 0.7259 - val_loss: 1.0817 - val_accuracy: 0.6154\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6179 - accuracy: 0.7148 - val_loss: 1.0743 - val_accuracy: 0.6239\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6666 - accuracy: 0.7222 - val_loss: 1.1293 - val_accuracy: 0.6068\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6307 - accuracy: 0.7222 - val_loss: 1.0959 - val_accuracy: 0.5897\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5963 - accuracy: 0.7222 - val_loss: 1.0936 - val_accuracy: 0.5641\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5955 - accuracy: 0.7185 - val_loss: 1.0927 - val_accuracy: 0.6068\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6112 - accuracy: 0.7074 - val_loss: 1.0919 - val_accuracy: 0.6325\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6221 - accuracy: 0.7222 - val_loss: 1.0856 - val_accuracy: 0.5897\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6232 - accuracy: 0.7259 - val_loss: 1.1315 - val_accuracy: 0.5897\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6331 - accuracy: 0.7296 - val_loss: 1.0853 - val_accuracy: 0.6154\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6144 - accuracy: 0.7037 - val_loss: 1.1000 - val_accuracy: 0.6068\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6151 - accuracy: 0.7296 - val_loss: 1.0887 - val_accuracy: 0.5726\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.5992 - accuracy: 0.7185 - val_loss: 1.1021 - val_accuracy: 0.6154\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.5842 - accuracy: 0.7222 - val_loss: 1.0862 - val_accuracy: 0.6239\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5888 - accuracy: 0.7370 - val_loss: 1.0889 - val_accuracy: 0.5812\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5946 - accuracy: 0.7333 - val_loss: 1.1032 - val_accuracy: 0.5812\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5910 - accuracy: 0.7259 - val_loss: 1.0845 - val_accuracy: 0.6239\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5853 - accuracy: 0.7333 - val_loss: 1.0944 - val_accuracy: 0.5897\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5795 - accuracy: 0.7444 - val_loss: 1.1089 - val_accuracy: 0.6239\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6270 - accuracy: 0.7148 - val_loss: 1.0955 - val_accuracy: 0.5812\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6035 - accuracy: 0.7259 - val_loss: 1.0806 - val_accuracy: 0.6154\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6142 - accuracy: 0.7259 - val_loss: 1.0919 - val_accuracy: 0.5897\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.5816 - accuracy: 0.7519 - val_loss: 1.1170 - val_accuracy: 0.5641\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5972 - accuracy: 0.7296 - val_loss: 1.0972 - val_accuracy: 0.5812\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5927 - accuracy: 0.7333 - val_loss: 1.0913 - val_accuracy: 0.6068\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.5980 - accuracy: 0.7296 - val_loss: 1.1022 - val_accuracy: 0.5983\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5999 - accuracy: 0.7259 - val_loss: 1.1281 - val_accuracy: 0.5726\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.5893 - accuracy: 0.7333 - val_loss: 1.1014 - val_accuracy: 0.6154\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.5916 - accuracy: 0.7333 - val_loss: 1.0981 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.5929 - accuracy: 0.7259 - val_loss: 1.0952 - val_accuracy: 0.5983\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.5943 - accuracy: 0.7222 - val_loss: 1.1171 - val_accuracy: 0.5897\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.5944 - accuracy: 0.7333 - val_loss: 1.0875 - val_accuracy: 0.6068\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6488 - accuracy: 0.7259 - val_loss: 1.1163 - val_accuracy: 0.5983\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6178 - accuracy: 0.7296 - val_loss: 1.1212 - val_accuracy: 0.5470\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.5954 - accuracy: 0.7481 - val_loss: 1.1027 - val_accuracy: 0.6325\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5967 - accuracy: 0.7370 - val_loss: 1.1151 - val_accuracy: 0.5726\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6191 - accuracy: 0.7296 - val_loss: 1.1276 - val_accuracy: 0.6239\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6106 - accuracy: 0.7185 - val_loss: 1.1014 - val_accuracy: 0.5897\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.5985 - accuracy: 0.7444 - val_loss: 1.0906 - val_accuracy: 0.6410\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.5900 - accuracy: 0.7370 - val_loss: 1.1218 - val_accuracy: 0.5385\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6110 - accuracy: 0.7407 - val_loss: 1.1311 - val_accuracy: 0.6239\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6208 - accuracy: 0.7296 - val_loss: 1.1083 - val_accuracy: 0.6068\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.5928 - accuracy: 0.7481 - val_loss: 1.0922 - val_accuracy: 0.6154\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.5963 - accuracy: 0.7296 - val_loss: 1.1315 - val_accuracy: 0.5812\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6106 - accuracy: 0.7148 - val_loss: 1.1170 - val_accuracy: 0.6068\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5780 - accuracy: 0.7407 - val_loss: 1.1301 - val_accuracy: 0.5385\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6155 - accuracy: 0.7222 - val_loss: 1.0950 - val_accuracy: 0.6154\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6120 - accuracy: 0.7074 - val_loss: 1.0825 - val_accuracy: 0.5983\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6026 - accuracy: 0.7296 - val_loss: 1.1266 - val_accuracy: 0.6154\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6092 - accuracy: 0.7185 - val_loss: 1.1020 - val_accuracy: 0.5983\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5929 - accuracy: 0.7259 - val_loss: 1.1139 - val_accuracy: 0.5726\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5813 - accuracy: 0.7370 - val_loss: 1.1060 - val_accuracy: 0.5812\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5801 - accuracy: 0.7370 - val_loss: 1.1055 - val_accuracy: 0.6325\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5971 - accuracy: 0.7259 - val_loss: 1.1194 - val_accuracy: 0.5983\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6019 - accuracy: 0.7407 - val_loss: 1.1081 - val_accuracy: 0.6239\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6366 - accuracy: 0.7444 - val_loss: 1.1048 - val_accuracy: 0.6154\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5925 - accuracy: 0.7333 - val_loss: 1.0911 - val_accuracy: 0.5983\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5919 - accuracy: 0.7370 - val_loss: 1.1071 - val_accuracy: 0.6325\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5780 - accuracy: 0.7519 - val_loss: 1.1158 - val_accuracy: 0.5983\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5896 - accuracy: 0.7407 - val_loss: 1.1113 - val_accuracy: 0.6154\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5710 - accuracy: 0.7407 - val_loss: 1.0946 - val_accuracy: 0.6239\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5885 - accuracy: 0.7407 - val_loss: 1.0957 - val_accuracy: 0.5726\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5870 - accuracy: 0.7296 - val_loss: 1.0968 - val_accuracy: 0.6068\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5817 - accuracy: 0.7556 - val_loss: 1.1210 - val_accuracy: 0.6239\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5882 - accuracy: 0.7148 - val_loss: 1.1041 - val_accuracy: 0.6239\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5820 - accuracy: 0.7296 - val_loss: 1.0999 - val_accuracy: 0.6154\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5859 - accuracy: 0.7333 - val_loss: 1.1186 - val_accuracy: 0.6154\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5881 - accuracy: 0.7296 - val_loss: 1.0897 - val_accuracy: 0.6068\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5734 - accuracy: 0.7556 - val_loss: 1.1015 - val_accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5751 - accuracy: 0.7407 - val_loss: 1.1161 - val_accuracy: 0.6068\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5863 - accuracy: 0.7296 - val_loss: 1.1178 - val_accuracy: 0.5983\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5821 - accuracy: 0.7370 - val_loss: 1.1249 - val_accuracy: 0.6068\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5823 - accuracy: 0.7333 - val_loss: 1.1281 - val_accuracy: 0.5726\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5877 - accuracy: 0.7333 - val_loss: 1.1307 - val_accuracy: 0.6239\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6235 - accuracy: 0.7370 - val_loss: 1.1204 - val_accuracy: 0.5641\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6786 - accuracy: 0.7370 - val_loss: 1.1067 - val_accuracy: 0.6068\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6369 - accuracy: 0.7370 - val_loss: 1.1329 - val_accuracy: 0.6068\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6228 - accuracy: 0.7296 - val_loss: 1.1921 - val_accuracy: 0.5641\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6644 - accuracy: 0.7037 - val_loss: 1.1324 - val_accuracy: 0.6239\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6450 - accuracy: 0.7148 - val_loss: 1.1251 - val_accuracy: 0.5641\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6219 - accuracy: 0.7111 - val_loss: 1.1085 - val_accuracy: 0.6154\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5946 - accuracy: 0.7481 - val_loss: 1.1312 - val_accuracy: 0.5641\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5906 - accuracy: 0.7296 - val_loss: 1.1197 - val_accuracy: 0.6239\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 1.0896 - val_accuracy: 0.6325\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5765 - accuracy: 0.7444 - val_loss: 1.1131 - val_accuracy: 0.5983\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5788 - accuracy: 0.7444 - val_loss: 1.1224 - val_accuracy: 0.6325\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5766 - accuracy: 0.7370 - val_loss: 1.1067 - val_accuracy: 0.6239\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6012 - accuracy: 0.7407 - val_loss: 1.1177 - val_accuracy: 0.5726\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5891 - accuracy: 0.7333 - val_loss: 1.1089 - val_accuracy: 0.5983\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5866 - accuracy: 0.7481 - val_loss: 1.1205 - val_accuracy: 0.6068\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5973 - accuracy: 0.7296 - val_loss: 1.1048 - val_accuracy: 0.5897\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6338 - accuracy: 0.7222 - val_loss: 1.1254 - val_accuracy: 0.5726\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7697 - accuracy: 0.7185 - val_loss: 1.1989 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6816 - accuracy: 0.7333 - val_loss: 1.1450 - val_accuracy: 0.5470\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7171 - accuracy: 0.7000 - val_loss: 1.1291 - val_accuracy: 0.6325\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7260 - accuracy: 0.7296 - val_loss: 1.1687 - val_accuracy: 0.6154\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6461 - accuracy: 0.7444 - val_loss: 1.1518 - val_accuracy: 0.5470\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6072 - accuracy: 0.7333 - val_loss: 1.1009 - val_accuracy: 0.5812\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5848 - accuracy: 0.7222 - val_loss: 1.1193 - val_accuracy: 0.5897\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5827 - accuracy: 0.7185 - val_loss: 1.1086 - val_accuracy: 0.6154\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5951 - accuracy: 0.7481 - val_loss: 1.1073 - val_accuracy: 0.5897\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.6226 - accuracy: 0.7296 - val_loss: 1.1198 - val_accuracy: 0.6239\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5850 - accuracy: 0.7148 - val_loss: 1.1025 - val_accuracy: 0.6154\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5695 - accuracy: 0.7630 - val_loss: 1.1013 - val_accuracy: 0.6068\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5819 - accuracy: 0.7444 - val_loss: 1.1087 - val_accuracy: 0.6154\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5849 - accuracy: 0.7333 - val_loss: 1.1375 - val_accuracy: 0.6068\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6548 - accuracy: 0.7148 - val_loss: 1.1074 - val_accuracy: 0.5983\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6283 - accuracy: 0.7185 - val_loss: 1.1021 - val_accuracy: 0.5299\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6037 - accuracy: 0.7481 - val_loss: 1.0918 - val_accuracy: 0.6154\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5649 - accuracy: 0.7630 - val_loss: 1.1393 - val_accuracy: 0.5299\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5819 - accuracy: 0.7370 - val_loss: 1.1030 - val_accuracy: 0.5897\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5673 - accuracy: 0.7481 - val_loss: 1.1107 - val_accuracy: 0.5726\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5796 - accuracy: 0.7296 - val_loss: 1.1133 - val_accuracy: 0.6154\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5922 - accuracy: 0.7333 - val_loss: 1.0995 - val_accuracy: 0.6068\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5609 - accuracy: 0.7630 - val_loss: 1.1405 - val_accuracy: 0.5897\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5874 - accuracy: 0.7296 - val_loss: 1.1137 - val_accuracy: 0.6325\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5897 - accuracy: 0.7333 - val_loss: 1.1305 - val_accuracy: 0.5385\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5833 - accuracy: 0.7370 - val_loss: 1.0968 - val_accuracy: 0.6325\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5724 - accuracy: 0.7593 - val_loss: 1.1102 - val_accuracy: 0.6068\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5728 - accuracy: 0.7481 - val_loss: 1.1087 - val_accuracy: 0.6325\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5779 - accuracy: 0.7407 - val_loss: 1.1273 - val_accuracy: 0.5897\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5768 - accuracy: 0.7148 - val_loss: 1.1399 - val_accuracy: 0.6068\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5802 - accuracy: 0.7333 - val_loss: 1.1522 - val_accuracy: 0.5897\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5895 - accuracy: 0.7370 - val_loss: 1.1132 - val_accuracy: 0.6068\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5843 - accuracy: 0.7481 - val_loss: 1.1174 - val_accuracy: 0.6068\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5729 - accuracy: 0.7407 - val_loss: 1.1106 - val_accuracy: 0.6239\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5660 - accuracy: 0.7519 - val_loss: 1.1304 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5681 - accuracy: 0.7407 - val_loss: 1.1176 - val_accuracy: 0.5983\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5805 - accuracy: 0.7333 - val_loss: 1.1193 - val_accuracy: 0.5983\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5736 - accuracy: 0.7370 - val_loss: 1.1232 - val_accuracy: 0.6239\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5782 - accuracy: 0.7370 - val_loss: 1.1138 - val_accuracy: 0.5983\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5658 - accuracy: 0.7370 - val_loss: 1.1165 - val_accuracy: 0.5641\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5864 - accuracy: 0.7296 - val_loss: 1.1133 - val_accuracy: 0.5812\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5650 - accuracy: 0.7481 - val_loss: 1.1124 - val_accuracy: 0.5726\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5870 - accuracy: 0.7148 - val_loss: 1.1168 - val_accuracy: 0.6239\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5877 - accuracy: 0.7222 - val_loss: 1.1325 - val_accuracy: 0.5897\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5718 - accuracy: 0.7444 - val_loss: 1.1174 - val_accuracy: 0.6068\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5608 - accuracy: 0.7556 - val_loss: 1.1259 - val_accuracy: 0.5897\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5766 - accuracy: 0.7370 - val_loss: 1.1136 - val_accuracy: 0.6068\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5730 - accuracy: 0.7519 - val_loss: 1.1132 - val_accuracy: 0.6154\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5721 - accuracy: 0.7370 - val_loss: 1.1144 - val_accuracy: 0.5983\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5637 - accuracy: 0.7370 - val_loss: 1.0981 - val_accuracy: 0.6325\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5771 - accuracy: 0.7333 - val_loss: 1.1318 - val_accuracy: 0.5812\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 316us/step - loss: 0.5777 - accuracy: 0.7444 - val_loss: 1.1183 - val_accuracy: 0.5983\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5716 - accuracy: 0.7481 - val_loss: 1.1121 - val_accuracy: 0.6154\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5849 - accuracy: 0.7296 - val_loss: 1.1155 - val_accuracy: 0.6239\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5766 - accuracy: 0.7444 - val_loss: 1.1381 - val_accuracy: 0.5812\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5764 - accuracy: 0.7333 - val_loss: 1.1458 - val_accuracy: 0.5726\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5705 - accuracy: 0.7407 - val_loss: 1.1424 - val_accuracy: 0.6154\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5706 - accuracy: 0.7296 - val_loss: 1.1338 - val_accuracy: 0.6068\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5747 - accuracy: 0.7370 - val_loss: 1.1144 - val_accuracy: 0.6154\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5690 - accuracy: 0.7333 - val_loss: 1.1432 - val_accuracy: 0.6239\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5677 - accuracy: 0.7407 - val_loss: 1.1117 - val_accuracy: 0.5983\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5661 - accuracy: 0.7444 - val_loss: 1.1270 - val_accuracy: 0.6239\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5646 - accuracy: 0.7556 - val_loss: 1.1291 - val_accuracy: 0.6325\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5877 - accuracy: 0.7444 - val_loss: 1.1228 - val_accuracy: 0.6154\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5677 - accuracy: 0.7370 - val_loss: 1.1238 - val_accuracy: 0.6239\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5692 - accuracy: 0.7407 - val_loss: 1.1393 - val_accuracy: 0.6239\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5617 - accuracy: 0.7481 - val_loss: 1.1379 - val_accuracy: 0.5897\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6009 - accuracy: 0.7259 - val_loss: 1.1347 - val_accuracy: 0.5897\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5789 - accuracy: 0.7444 - val_loss: 1.1356 - val_accuracy: 0.6068\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6187 - accuracy: 0.7148 - val_loss: 1.1125 - val_accuracy: 0.6239\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5814 - accuracy: 0.7407 - val_loss: 1.1174 - val_accuracy: 0.6068\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5720 - accuracy: 0.7481 - val_loss: 1.1115 - val_accuracy: 0.6325\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5682 - accuracy: 0.7333 - val_loss: 1.1311 - val_accuracy: 0.6325\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5748 - accuracy: 0.7259 - val_loss: 1.1324 - val_accuracy: 0.5726\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5951 - accuracy: 0.7222 - val_loss: 1.1153 - val_accuracy: 0.6239\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5799 - accuracy: 0.7556 - val_loss: 1.1411 - val_accuracy: 0.6154\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5837 - accuracy: 0.7333 - val_loss: 1.1524 - val_accuracy: 0.6068\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5618 - accuracy: 0.7444 - val_loss: 1.1337 - val_accuracy: 0.6239\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5576 - accuracy: 0.7519 - val_loss: 1.1432 - val_accuracy: 0.6239\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5790 - accuracy: 0.7370 - val_loss: 1.1217 - val_accuracy: 0.6154\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5589 - accuracy: 0.7593 - val_loss: 1.1375 - val_accuracy: 0.6239\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5702 - accuracy: 0.7519 - val_loss: 1.1530 - val_accuracy: 0.6325\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5909 - accuracy: 0.7296 - val_loss: 1.1181 - val_accuracy: 0.6325\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5674 - accuracy: 0.7593 - val_loss: 1.1326 - val_accuracy: 0.6239\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5637 - accuracy: 0.7444 - val_loss: 1.1530 - val_accuracy: 0.6154\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5745 - accuracy: 0.7444 - val_loss: 1.1218 - val_accuracy: 0.6325\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5860 - accuracy: 0.7259 - val_loss: 1.1388 - val_accuracy: 0.5556\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5709 - accuracy: 0.7481 - val_loss: 1.1154 - val_accuracy: 0.6239\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5618 - accuracy: 0.7407 - val_loss: 1.1240 - val_accuracy: 0.6154\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5634 - accuracy: 0.7444 - val_loss: 1.1274 - val_accuracy: 0.6154\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5748 - accuracy: 0.7444 - val_loss: 1.1261 - val_accuracy: 0.5897\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5682 - accuracy: 0.7296 - val_loss: 1.1420 - val_accuracy: 0.6068\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5906 - accuracy: 0.7370 - val_loss: 1.1705 - val_accuracy: 0.6154\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6407 - accuracy: 0.7296 - val_loss: 1.1691 - val_accuracy: 0.6068\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6234 - accuracy: 0.7296 - val_loss: 1.1525 - val_accuracy: 0.5812\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5755 - accuracy: 0.7444 - val_loss: 1.1120 - val_accuracy: 0.6325\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6132 - accuracy: 0.7407 - val_loss: 1.1480 - val_accuracy: 0.5812\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7182 - accuracy: 0.6926 - val_loss: 1.5931 - val_accuracy: 0.5726\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7695 - accuracy: 0.6963 - val_loss: 1.1563 - val_accuracy: 0.5812\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7287 - accuracy: 0.6778 - val_loss: 1.2803 - val_accuracy: 0.5812\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6506 - accuracy: 0.7148 - val_loss: 1.1445 - val_accuracy: 0.5812\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6073 - accuracy: 0.7074 - val_loss: 1.1444 - val_accuracy: 0.5726\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5644 - accuracy: 0.7407 - val_loss: 1.1417 - val_accuracy: 0.5983\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5632 - accuracy: 0.7407 - val_loss: 1.1382 - val_accuracy: 0.6325\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5677 - accuracy: 0.7519 - val_loss: 1.1314 - val_accuracy: 0.6068\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.5591 - accuracy: 0.7444 - val_loss: 1.1442 - val_accuracy: 0.6410\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5695 - accuracy: 0.7370 - val_loss: 1.1224 - val_accuracy: 0.6154\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5839 - accuracy: 0.7444 - val_loss: 1.1258 - val_accuracy: 0.6239\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6319 - accuracy: 0.7370 - val_loss: 1.1531 - val_accuracy: 0.6154\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5726 - accuracy: 0.7444 - val_loss: 1.1515 - val_accuracy: 0.6154\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5710 - accuracy: 0.7444 - val_loss: 1.1556 - val_accuracy: 0.6154\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5638 - accuracy: 0.7519 - val_loss: 1.1278 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5693 - accuracy: 0.7556 - val_loss: 1.1199 - val_accuracy: 0.6239\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5645 - accuracy: 0.7444 - val_loss: 1.1321 - val_accuracy: 0.5556\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5803 - accuracy: 0.7333 - val_loss: 1.1296 - val_accuracy: 0.6325\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5684 - accuracy: 0.7556 - val_loss: 1.1630 - val_accuracy: 0.5983\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5652 - accuracy: 0.7519 - val_loss: 1.1313 - val_accuracy: 0.6239\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5838 - accuracy: 0.7407 - val_loss: 1.1521 - val_accuracy: 0.5897\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5703 - accuracy: 0.7185 - val_loss: 1.1318 - val_accuracy: 0.6325\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5612 - accuracy: 0.7481 - val_loss: 1.1401 - val_accuracy: 0.6154\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5687 - accuracy: 0.7333 - val_loss: 1.1641 - val_accuracy: 0.6154\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5580 - accuracy: 0.7444 - val_loss: 1.1372 - val_accuracy: 0.5812\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5730 - accuracy: 0.7481 - val_loss: 1.1280 - val_accuracy: 0.5897\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5648 - accuracy: 0.7370 - val_loss: 1.1321 - val_accuracy: 0.6154\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5629 - accuracy: 0.7556 - val_loss: 1.1312 - val_accuracy: 0.6325\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5873 - accuracy: 0.7370 - val_loss: 1.1347 - val_accuracy: 0.6068\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5780 - accuracy: 0.7259 - val_loss: 1.1466 - val_accuracy: 0.6068\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5684 - accuracy: 0.7519 - val_loss: 1.1297 - val_accuracy: 0.5812\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5866 - accuracy: 0.7333 - val_loss: 1.1329 - val_accuracy: 0.6154\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5648 - accuracy: 0.7556 - val_loss: 1.1240 - val_accuracy: 0.6239\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5552 - accuracy: 0.7556 - val_loss: 1.1303 - val_accuracy: 0.6410\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5541 - accuracy: 0.7519 - val_loss: 1.1340 - val_accuracy: 0.6410\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5568 - accuracy: 0.7593 - val_loss: 1.1399 - val_accuracy: 0.6325\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5644 - accuracy: 0.7519 - val_loss: 1.1312 - val_accuracy: 0.6410\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5632 - accuracy: 0.7407 - val_loss: 1.1162 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5946 - accuracy: 0.7519 - val_loss: 1.1373 - val_accuracy: 0.6410\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6260 - accuracy: 0.7407 - val_loss: 1.1522 - val_accuracy: 0.6239\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5966 - accuracy: 0.7407 - val_loss: 1.2399 - val_accuracy: 0.5385\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6129 - accuracy: 0.7333 - val_loss: 1.1898 - val_accuracy: 0.6325\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6092 - accuracy: 0.7556 - val_loss: 1.1559 - val_accuracy: 0.5726\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5795 - accuracy: 0.7407 - val_loss: 1.1477 - val_accuracy: 0.5897\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5614 - accuracy: 0.7407 - val_loss: 1.1231 - val_accuracy: 0.5812\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5593 - accuracy: 0.7444 - val_loss: 1.1246 - val_accuracy: 0.6068\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5618 - accuracy: 0.7407 - val_loss: 1.1563 - val_accuracy: 0.6068\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5690 - accuracy: 0.7444 - val_loss: 1.1510 - val_accuracy: 0.5897\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5609 - accuracy: 0.7370 - val_loss: 1.1474 - val_accuracy: 0.6154\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5619 - accuracy: 0.7407 - val_loss: 1.1328 - val_accuracy: 0.6325\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5636 - accuracy: 0.7407 - val_loss: 1.1302 - val_accuracy: 0.5897\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5537 - accuracy: 0.7630 - val_loss: 1.1415 - val_accuracy: 0.6154\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5583 - accuracy: 0.7296 - val_loss: 1.1520 - val_accuracy: 0.6154\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5781 - accuracy: 0.7407 - val_loss: 1.1439 - val_accuracy: 0.6068\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5607 - accuracy: 0.7556 - val_loss: 1.1270 - val_accuracy: 0.6154\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5631 - accuracy: 0.7407 - val_loss: 1.1293 - val_accuracy: 0.6325\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5573 - accuracy: 0.7519 - val_loss: 1.1466 - val_accuracy: 0.6154\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5576 - accuracy: 0.7593 - val_loss: 1.1382 - val_accuracy: 0.6068\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5686 - accuracy: 0.7444 - val_loss: 1.1414 - val_accuracy: 0.6325\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5712 - accuracy: 0.7481 - val_loss: 1.1451 - val_accuracy: 0.6325\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5916 - accuracy: 0.7519 - val_loss: 1.1217 - val_accuracy: 0.6068\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5560 - accuracy: 0.7370 - val_loss: 1.1577 - val_accuracy: 0.5983\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5768 - accuracy: 0.7519 - val_loss: 1.1493 - val_accuracy: 0.6325\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5746 - accuracy: 0.7407 - val_loss: 1.1312 - val_accuracy: 0.5897\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5865 - accuracy: 0.7333 - val_loss: 1.1307 - val_accuracy: 0.6410\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5876 - accuracy: 0.7370 - val_loss: 1.1234 - val_accuracy: 0.6239\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6129 - accuracy: 0.7333 - val_loss: 1.1524 - val_accuracy: 0.6239\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6271 - accuracy: 0.7481 - val_loss: 1.1799 - val_accuracy: 0.6154\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6454 - accuracy: 0.7296 - val_loss: 1.2500 - val_accuracy: 0.5641\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6060 - accuracy: 0.7519 - val_loss: 1.1791 - val_accuracy: 0.6325\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5952 - accuracy: 0.7481 - val_loss: 1.1425 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5590 - accuracy: 0.7444 - val_loss: 1.1615 - val_accuracy: 0.6154\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5710 - accuracy: 0.7444 - val_loss: 1.1426 - val_accuracy: 0.5897\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5649 - accuracy: 0.7333 - val_loss: 1.1337 - val_accuracy: 0.6325\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5511 - accuracy: 0.7519 - val_loss: 1.1694 - val_accuracy: 0.5983\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5679 - accuracy: 0.7444 - val_loss: 1.1570 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3baab748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 68us/step\n",
      "over-sampling test accuracy: 60.68%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 2, 2, 2, 0, 2, 1, 0, 0, 1, 2, 2, 1, 2, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 2, 2, 1, 2, 1, 0, 1, 2, 1, 2,\n",
       "       1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 1,\n",
       "       0, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 1, 2,\n",
       "       0, 0, 2, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS383     1     1\n",
       "1       NRS254     1     1\n",
       "2       NRS218     1     1\n",
       "3       NRS215     0     0\n",
       "4    BCH-SA-14     2     1\n",
       "..         ...   ...   ...\n",
       "112     NRS227     1     2\n",
       "113     NRS272     1     2\n",
       "114   CFBRSa24     0     0\n",
       "115   CFBRSa74     0     1\n",
       "116     NRS271     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.134787</td>\n",
       "      <td>0.581356</td>\n",
       "      <td>0.283858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491630</td>\n",
       "      <td>0.497916</td>\n",
       "      <td>0.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324922</td>\n",
       "      <td>0.594283</td>\n",
       "      <td>0.080795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758227</td>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.072182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388507</td>\n",
       "      <td>0.602946</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.025057</td>\n",
       "      <td>0.046394</td>\n",
       "      <td>0.928549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.053057</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>0.785694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.636068</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.003632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.248718</td>\n",
       "      <td>0.619990</td>\n",
       "      <td>0.131292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.100933</td>\n",
       "      <td>0.158095</td>\n",
       "      <td>0.740971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.134787  0.581356  0.283858\n",
       "1    0.491630  0.497916  0.010454\n",
       "2    0.324922  0.594283  0.080795\n",
       "3    0.758227  0.169591  0.072182\n",
       "4    0.388507  0.602946  0.008547\n",
       "..        ...       ...       ...\n",
       "112  0.025057  0.046394  0.928549\n",
       "113  0.053057  0.161249  0.785694\n",
       "114  0.636068  0.360300  0.003632\n",
       "115  0.248718  0.619990  0.131292\n",
       "116  0.100933  0.158095  0.740971\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.7738 - accuracy: 0.7333 - val_loss: 1.1911 - val_accuracy: 0.6239\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7790 - accuracy: 0.7333 - val_loss: 1.2449 - val_accuracy: 0.6068\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9486 - accuracy: 0.7222 - val_loss: 1.2078 - val_accuracy: 0.5812\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.2028 - accuracy: 0.7074 - val_loss: 1.7212 - val_accuracy: 0.5897\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.1186 - accuracy: 0.7000 - val_loss: 1.7170 - val_accuracy: 0.4872\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9649 - accuracy: 0.7111 - val_loss: 1.3942 - val_accuracy: 0.6068\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8776 - accuracy: 0.7407 - val_loss: 1.1752 - val_accuracy: 0.6068\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6086 - accuracy: 0.7407 - val_loss: 1.1733 - val_accuracy: 0.6068\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6417 - accuracy: 0.7407 - val_loss: 1.1769 - val_accuracy: 0.6154\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.5597 - accuracy: 0.7407 - val_loss: 1.1672 - val_accuracy: 0.6154\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5611 - accuracy: 0.7444 - val_loss: 1.1666 - val_accuracy: 0.5897\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5428 - accuracy: 0.7519 - val_loss: 1.1444 - val_accuracy: 0.6068\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5426 - accuracy: 0.7481 - val_loss: 1.1582 - val_accuracy: 0.6068\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5244 - accuracy: 0.7519 - val_loss: 1.1558 - val_accuracy: 0.6154\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5812 - accuracy: 0.7444 - val_loss: 1.1616 - val_accuracy: 0.5983\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5362 - accuracy: 0.7481 - val_loss: 1.1552 - val_accuracy: 0.5983\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5261 - accuracy: 0.7630 - val_loss: 1.1659 - val_accuracy: 0.5983\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5510 - accuracy: 0.7481 - val_loss: 1.1695 - val_accuracy: 0.6068\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5429 - accuracy: 0.7481 - val_loss: 1.1598 - val_accuracy: 0.5812\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5429 - accuracy: 0.7481 - val_loss: 1.1649 - val_accuracy: 0.6154\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5420 - accuracy: 0.7630 - val_loss: 1.1773 - val_accuracy: 0.5897\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5498 - accuracy: 0.7370 - val_loss: 1.1652 - val_accuracy: 0.5897\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5419 - accuracy: 0.7630 - val_loss: 1.1861 - val_accuracy: 0.5897\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5489 - accuracy: 0.7593 - val_loss: 1.1811 - val_accuracy: 0.6068\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5532 - accuracy: 0.7519 - val_loss: 1.1599 - val_accuracy: 0.6068\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5368 - accuracy: 0.7481 - val_loss: 1.1693 - val_accuracy: 0.6239\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5398 - accuracy: 0.7481 - val_loss: 1.1642 - val_accuracy: 0.6154\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5351 - accuracy: 0.7667 - val_loss: 1.1639 - val_accuracy: 0.6239\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5297 - accuracy: 0.7556 - val_loss: 1.1687 - val_accuracy: 0.6154\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5261 - accuracy: 0.7519 - val_loss: 1.1675 - val_accuracy: 0.6239\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5263 - accuracy: 0.7481 - val_loss: 1.1795 - val_accuracy: 0.6068\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5363 - accuracy: 0.7481 - val_loss: 1.1731 - val_accuracy: 0.6068\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5265 - accuracy: 0.7667 - val_loss: 1.1659 - val_accuracy: 0.6068\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5226 - accuracy: 0.7519 - val_loss: 1.1710 - val_accuracy: 0.6154\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5277 - accuracy: 0.7519 - val_loss: 1.1725 - val_accuracy: 0.6239\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5263 - accuracy: 0.7481 - val_loss: 1.1696 - val_accuracy: 0.6154\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5503 - accuracy: 0.7444 - val_loss: 1.2320 - val_accuracy: 0.5812\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5456 - accuracy: 0.7444 - val_loss: 1.1715 - val_accuracy: 0.6154\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5286 - accuracy: 0.7370 - val_loss: 1.1793 - val_accuracy: 0.6154\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5270 - accuracy: 0.7630 - val_loss: 1.1719 - val_accuracy: 0.6239\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5475 - accuracy: 0.7593 - val_loss: 1.1771 - val_accuracy: 0.6068\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5816 - accuracy: 0.7519 - val_loss: 1.2402 - val_accuracy: 0.6154\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6083 - accuracy: 0.7556 - val_loss: 1.2076 - val_accuracy: 0.5897\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6000 - accuracy: 0.7407 - val_loss: 1.1839 - val_accuracy: 0.6154\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5507 - accuracy: 0.7481 - val_loss: 1.1838 - val_accuracy: 0.5983\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6033 - accuracy: 0.7481 - val_loss: 1.2392 - val_accuracy: 0.6154\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6294 - accuracy: 0.7556 - val_loss: 1.1909 - val_accuracy: 0.5983\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5718 - accuracy: 0.7556 - val_loss: 1.1766 - val_accuracy: 0.6154\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5287 - accuracy: 0.7519 - val_loss: 1.1866 - val_accuracy: 0.6068\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5241 - accuracy: 0.7481 - val_loss: 1.1674 - val_accuracy: 0.6239\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5262 - accuracy: 0.7519 - val_loss: 1.1610 - val_accuracy: 0.6239\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5279 - accuracy: 0.7519 - val_loss: 1.1653 - val_accuracy: 0.6154\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5218 - accuracy: 0.7630 - val_loss: 1.1680 - val_accuracy: 0.6239\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5573 - accuracy: 0.7444 - val_loss: 1.1833 - val_accuracy: 0.5983\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5410 - accuracy: 0.7630 - val_loss: 1.1871 - val_accuracy: 0.6154\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.5357 - accuracy: 0.7407 - val_loss: 1.1854 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5308 - accuracy: 0.7407 - val_loss: 1.1713 - val_accuracy: 0.6154\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5252 - accuracy: 0.7593 - val_loss: 1.1744 - val_accuracy: 0.6068\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5264 - accuracy: 0.7556 - val_loss: 1.1906 - val_accuracy: 0.6068\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5179 - accuracy: 0.7481 - val_loss: 1.2044 - val_accuracy: 0.6154\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5757 - accuracy: 0.7407 - val_loss: 1.2000 - val_accuracy: 0.5983\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5286 - accuracy: 0.7481 - val_loss: 1.1785 - val_accuracy: 0.6239\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5462 - accuracy: 0.7593 - val_loss: 1.1809 - val_accuracy: 0.6154\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5207 - accuracy: 0.7481 - val_loss: 1.1880 - val_accuracy: 0.6068\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5238 - accuracy: 0.7556 - val_loss: 1.1907 - val_accuracy: 0.6068\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5241 - accuracy: 0.7407 - val_loss: 1.1837 - val_accuracy: 0.6154\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5347 - accuracy: 0.7556 - val_loss: 1.1882 - val_accuracy: 0.6154\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5380 - accuracy: 0.7519 - val_loss: 1.1878 - val_accuracy: 0.5983\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5414 - accuracy: 0.7481 - val_loss: 1.1806 - val_accuracy: 0.6068\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5398 - accuracy: 0.7593 - val_loss: 1.1831 - val_accuracy: 0.6239\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5348 - accuracy: 0.7407 - val_loss: 1.1888 - val_accuracy: 0.6154\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5872 - accuracy: 0.7593 - val_loss: 1.2074 - val_accuracy: 0.5897\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5302 - accuracy: 0.7556 - val_loss: 1.2010 - val_accuracy: 0.6154\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5449 - accuracy: 0.7444 - val_loss: 1.2299 - val_accuracy: 0.5812\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5740 - accuracy: 0.7407 - val_loss: 1.1910 - val_accuracy: 0.5897\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5271 - accuracy: 0.7444 - val_loss: 1.1880 - val_accuracy: 0.6239\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5455 - accuracy: 0.7556 - val_loss: 1.1940 - val_accuracy: 0.6068\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5595 - accuracy: 0.7519 - val_loss: 1.2358 - val_accuracy: 0.5812\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6005 - accuracy: 0.7481 - val_loss: 1.2445 - val_accuracy: 0.6068\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6018 - accuracy: 0.7407 - val_loss: 1.1872 - val_accuracy: 0.6068\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5969 - accuracy: 0.7519 - val_loss: 1.1907 - val_accuracy: 0.5983\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6170 - accuracy: 0.7333 - val_loss: 1.2722 - val_accuracy: 0.6068\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6457 - accuracy: 0.7481 - val_loss: 1.2055 - val_accuracy: 0.5897\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5498 - accuracy: 0.7481 - val_loss: 1.1957 - val_accuracy: 0.6154\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5362 - accuracy: 0.7519 - val_loss: 1.1818 - val_accuracy: 0.6154\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5520 - accuracy: 0.7407 - val_loss: 1.1678 - val_accuracy: 0.5983\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5441 - accuracy: 0.7593 - val_loss: 1.1768 - val_accuracy: 0.5983\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5323 - accuracy: 0.7519 - val_loss: 1.2196 - val_accuracy: 0.5812\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5801 - accuracy: 0.7296 - val_loss: 1.2226 - val_accuracy: 0.6068\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5780 - accuracy: 0.7556 - val_loss: 1.3052 - val_accuracy: 0.5128\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.5767 - accuracy: 0.7407 - val_loss: 1.2288 - val_accuracy: 0.5897\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6126 - accuracy: 0.7444 - val_loss: 1.2805 - val_accuracy: 0.5556\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5325 - accuracy: 0.7704 - val_loss: 1.2236 - val_accuracy: 0.6068\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5667 - accuracy: 0.7593 - val_loss: 1.4516 - val_accuracy: 0.5470\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6743 - accuracy: 0.7333 - val_loss: 1.2214 - val_accuracy: 0.6154\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5705 - accuracy: 0.7704 - val_loss: 1.2975 - val_accuracy: 0.5641\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6048 - accuracy: 0.7444 - val_loss: 1.2052 - val_accuracy: 0.6068\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5562 - accuracy: 0.7630 - val_loss: 1.1853 - val_accuracy: 0.6068\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5301 - accuracy: 0.7481 - val_loss: 1.1865 - val_accuracy: 0.6154\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5217 - accuracy: 0.7481 - val_loss: 1.1883 - val_accuracy: 0.6068\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5406 - accuracy: 0.7593 - val_loss: 1.1882 - val_accuracy: 0.5897\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5360 - accuracy: 0.7407 - val_loss: 1.1865 - val_accuracy: 0.5897\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.5328 - accuracy: 0.7667 - val_loss: 1.2042 - val_accuracy: 0.5983\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5634 - accuracy: 0.7593 - val_loss: 1.2037 - val_accuracy: 0.6068\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.5213 - accuracy: 0.7667 - val_loss: 1.1877 - val_accuracy: 0.5812\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5861 - accuracy: 0.7593 - val_loss: 1.2507 - val_accuracy: 0.6068\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6789 - accuracy: 0.7556 - val_loss: 1.2292 - val_accuracy: 0.5726\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5822 - accuracy: 0.7481 - val_loss: 1.2277 - val_accuracy: 0.5983\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5434 - accuracy: 0.7481 - val_loss: 1.2099 - val_accuracy: 0.6154\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5263 - accuracy: 0.7556 - val_loss: 1.1852 - val_accuracy: 0.6068\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5316 - accuracy: 0.7556 - val_loss: 1.1879 - val_accuracy: 0.5897\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5236 - accuracy: 0.7519 - val_loss: 1.1966 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5196 - accuracy: 0.7593 - val_loss: 1.1911 - val_accuracy: 0.5812\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5148 - accuracy: 0.7481 - val_loss: 1.2062 - val_accuracy: 0.5897\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.5369 - accuracy: 0.7407 - val_loss: 1.1839 - val_accuracy: 0.5983\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5274 - accuracy: 0.7519 - val_loss: 1.1864 - val_accuracy: 0.6068\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.5323 - accuracy: 0.7556 - val_loss: 1.1909 - val_accuracy: 0.6068\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.5507 - accuracy: 0.7593 - val_loss: 1.1961 - val_accuracy: 0.5983\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6028 - accuracy: 0.7556 - val_loss: 1.2735 - val_accuracy: 0.6154\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6067 - accuracy: 0.7519 - val_loss: 1.2559 - val_accuracy: 0.5641\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6039 - accuracy: 0.7444 - val_loss: 1.2149 - val_accuracy: 0.6154\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5284 - accuracy: 0.7556 - val_loss: 1.2087 - val_accuracy: 0.5897\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5236 - accuracy: 0.7630 - val_loss: 1.2031 - val_accuracy: 0.6154\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5480 - accuracy: 0.7519 - val_loss: 1.1926 - val_accuracy: 0.5983\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5183 - accuracy: 0.7593 - val_loss: 1.1894 - val_accuracy: 0.5983\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5200 - accuracy: 0.7704 - val_loss: 1.2544 - val_accuracy: 0.5556\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5808 - accuracy: 0.7519 - val_loss: 1.2437 - val_accuracy: 0.5726\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6504 - accuracy: 0.7370 - val_loss: 1.1984 - val_accuracy: 0.5897\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6396 - accuracy: 0.7370 - val_loss: 1.2003 - val_accuracy: 0.6239\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.5645 - accuracy: 0.7519 - val_loss: 1.1921 - val_accuracy: 0.6068\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.5268 - accuracy: 0.7630 - val_loss: 1.2282 - val_accuracy: 0.6068\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 417us/step - loss: 0.5833 - accuracy: 0.7444 - val_loss: 1.1823 - val_accuracy: 0.5897\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.5570 - accuracy: 0.7481 - val_loss: 1.1859 - val_accuracy: 0.5983\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5364 - accuracy: 0.7630 - val_loss: 1.1971 - val_accuracy: 0.6239\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5570 - accuracy: 0.7444 - val_loss: 1.2422 - val_accuracy: 0.5812\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5283 - accuracy: 0.7593 - val_loss: 1.2079 - val_accuracy: 0.6154\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5392 - accuracy: 0.7556 - val_loss: 1.2080 - val_accuracy: 0.5983\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.5353 - accuracy: 0.7481 - val_loss: 1.1909 - val_accuracy: 0.6068\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7083 - accuracy: 0.7333 - val_loss: 1.2336 - val_accuracy: 0.6068\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6187 - accuracy: 0.7630 - val_loss: 1.2351 - val_accuracy: 0.5641\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5784 - accuracy: 0.7444 - val_loss: 1.2108 - val_accuracy: 0.6068\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5918 - accuracy: 0.7481 - val_loss: 1.2186 - val_accuracy: 0.5897\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5200 - accuracy: 0.7593 - val_loss: 1.2005 - val_accuracy: 0.6068\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.5217 - accuracy: 0.7519 - val_loss: 1.2117 - val_accuracy: 0.5983\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5385 - accuracy: 0.7630 - val_loss: 1.1900 - val_accuracy: 0.6154\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5205 - accuracy: 0.7481 - val_loss: 1.1908 - val_accuracy: 0.6068\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5252 - accuracy: 0.7519 - val_loss: 1.2307 - val_accuracy: 0.5897\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5589 - accuracy: 0.7667 - val_loss: 1.2517 - val_accuracy: 0.6068\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5856 - accuracy: 0.7481 - val_loss: 1.2292 - val_accuracy: 0.5897\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5458 - accuracy: 0.7704 - val_loss: 1.2399 - val_accuracy: 0.6068\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6040 - accuracy: 0.7481 - val_loss: 1.2279 - val_accuracy: 0.5983\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5702 - accuracy: 0.7519 - val_loss: 1.2048 - val_accuracy: 0.6154\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5404 - accuracy: 0.7556 - val_loss: 1.2036 - val_accuracy: 0.5983\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5580 - accuracy: 0.7556 - val_loss: 1.2376 - val_accuracy: 0.5812\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6253 - accuracy: 0.7556 - val_loss: 1.2479 - val_accuracy: 0.5812\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5991 - accuracy: 0.7593 - val_loss: 1.4036 - val_accuracy: 0.5641\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8159 - accuracy: 0.7185 - val_loss: 1.3610 - val_accuracy: 0.6154\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6133 - accuracy: 0.7333 - val_loss: 1.3291 - val_accuracy: 0.5214\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6168 - accuracy: 0.7444 - val_loss: 1.2212 - val_accuracy: 0.5897\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5508 - accuracy: 0.7444 - val_loss: 1.2201 - val_accuracy: 0.6154\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5391 - accuracy: 0.7481 - val_loss: 1.2061 - val_accuracy: 0.6325\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5289 - accuracy: 0.7519 - val_loss: 1.2213 - val_accuracy: 0.5983\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5391 - accuracy: 0.7556 - val_loss: 1.2229 - val_accuracy: 0.6068\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5533 - accuracy: 0.7333 - val_loss: 1.2169 - val_accuracy: 0.5983\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.5466 - accuracy: 0.7630 - val_loss: 1.2045 - val_accuracy: 0.5897\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.5616 - accuracy: 0.7481 - val_loss: 1.2645 - val_accuracy: 0.5812\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5514 - accuracy: 0.7519 - val_loss: 1.2284 - val_accuracy: 0.5812\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5620 - accuracy: 0.7741 - val_loss: 1.1999 - val_accuracy: 0.5897\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5561 - accuracy: 0.7481 - val_loss: 1.2119 - val_accuracy: 0.6239\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5249 - accuracy: 0.7333 - val_loss: 1.2120 - val_accuracy: 0.6068\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5159 - accuracy: 0.7593 - val_loss: 1.2046 - val_accuracy: 0.5983\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5449 - accuracy: 0.7519 - val_loss: 1.2035 - val_accuracy: 0.5556\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5192 - accuracy: 0.7407 - val_loss: 1.1938 - val_accuracy: 0.5983\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5296 - accuracy: 0.7519 - val_loss: 1.2143 - val_accuracy: 0.6068\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5595 - accuracy: 0.7519 - val_loss: 1.3210 - val_accuracy: 0.5556\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7193 - accuracy: 0.7481 - val_loss: 1.5616 - val_accuracy: 0.6068\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8832 - accuracy: 0.7370 - val_loss: 1.2509 - val_accuracy: 0.5385\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6139 - accuracy: 0.7519 - val_loss: 1.1958 - val_accuracy: 0.6239\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5586 - accuracy: 0.7444 - val_loss: 1.1916 - val_accuracy: 0.6068\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5363 - accuracy: 0.7481 - val_loss: 1.2057 - val_accuracy: 0.6068\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5226 - accuracy: 0.7519 - val_loss: 1.2034 - val_accuracy: 0.5812\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5315 - accuracy: 0.7630 - val_loss: 1.2101 - val_accuracy: 0.6068\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5435 - accuracy: 0.7593 - val_loss: 1.2078 - val_accuracy: 0.5983\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5364 - accuracy: 0.7519 - val_loss: 1.1845 - val_accuracy: 0.5983\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5160 - accuracy: 0.7593 - val_loss: 1.1788 - val_accuracy: 0.5897\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5276 - accuracy: 0.7519 - val_loss: 1.1914 - val_accuracy: 0.6154\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5156 - accuracy: 0.7556 - val_loss: 1.2061 - val_accuracy: 0.6154\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5373 - accuracy: 0.7556 - val_loss: 1.1955 - val_accuracy: 0.6068\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5153 - accuracy: 0.7667 - val_loss: 1.2035 - val_accuracy: 0.6154\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5206 - accuracy: 0.7667 - val_loss: 1.2091 - val_accuracy: 0.6239\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5400 - accuracy: 0.7556 - val_loss: 1.2133 - val_accuracy: 0.6068\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5222 - accuracy: 0.7630 - val_loss: 1.1941 - val_accuracy: 0.6239\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5305 - accuracy: 0.7593 - val_loss: 1.2094 - val_accuracy: 0.6068\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5248 - accuracy: 0.7519 - val_loss: 1.1947 - val_accuracy: 0.5983\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5241 - accuracy: 0.7630 - val_loss: 1.2006 - val_accuracy: 0.5983\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5061 - accuracy: 0.7556 - val_loss: 1.1974 - val_accuracy: 0.6154\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5252 - accuracy: 0.7556 - val_loss: 1.2036 - val_accuracy: 0.5812\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5482 - accuracy: 0.7481 - val_loss: 1.2091 - val_accuracy: 0.6068\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5320 - accuracy: 0.7630 - val_loss: 1.2002 - val_accuracy: 0.6068\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5423 - accuracy: 0.7481 - val_loss: 1.1999 - val_accuracy: 0.6239\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5227 - accuracy: 0.7481 - val_loss: 1.1966 - val_accuracy: 0.6068\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5198 - accuracy: 0.7593 - val_loss: 1.1970 - val_accuracy: 0.6239\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5211 - accuracy: 0.7667 - val_loss: 1.2049 - val_accuracy: 0.6154\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5352 - accuracy: 0.7444 - val_loss: 1.2022 - val_accuracy: 0.5897\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5596 - accuracy: 0.7519 - val_loss: 1.2187 - val_accuracy: 0.6068\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5473 - accuracy: 0.7519 - val_loss: 1.2441 - val_accuracy: 0.6068\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5988 - accuracy: 0.7370 - val_loss: 1.2443 - val_accuracy: 0.5641\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5284 - accuracy: 0.7630 - val_loss: 1.2086 - val_accuracy: 0.6239\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5392 - accuracy: 0.7407 - val_loss: 1.2062 - val_accuracy: 0.5983\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5212 - accuracy: 0.7556 - val_loss: 1.1972 - val_accuracy: 0.6068\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5189 - accuracy: 0.7519 - val_loss: 1.2013 - val_accuracy: 0.5641\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5216 - accuracy: 0.7481 - val_loss: 1.1971 - val_accuracy: 0.5983\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5323 - accuracy: 0.7593 - val_loss: 1.2071 - val_accuracy: 0.6154\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5239 - accuracy: 0.7519 - val_loss: 1.2053 - val_accuracy: 0.5983\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5180 - accuracy: 0.7519 - val_loss: 1.1956 - val_accuracy: 0.5983\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 463us/step - loss: 0.5136 - accuracy: 0.7667 - val_loss: 1.2015 - val_accuracy: 0.6068\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5116 - accuracy: 0.7630 - val_loss: 1.2080 - val_accuracy: 0.6068\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5364 - accuracy: 0.7593 - val_loss: 1.2352 - val_accuracy: 0.5641\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.5343 - accuracy: 0.7481 - val_loss: 1.2096 - val_accuracy: 0.6154\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.5528 - accuracy: 0.7444 - val_loss: 1.2145 - val_accuracy: 0.5897\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.5232 - accuracy: 0.7556 - val_loss: 1.2092 - val_accuracy: 0.5983\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.5123 - accuracy: 0.7444 - val_loss: 1.2035 - val_accuracy: 0.5897\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5306 - accuracy: 0.7519 - val_loss: 1.2325 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5282 - accuracy: 0.7630 - val_loss: 1.2016 - val_accuracy: 0.6068\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5378 - accuracy: 0.7556 - val_loss: 1.2160 - val_accuracy: 0.5897\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5270 - accuracy: 0.7481 - val_loss: 1.2147 - val_accuracy: 0.6154\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5258 - accuracy: 0.7630 - val_loss: 1.2028 - val_accuracy: 0.6154\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5208 - accuracy: 0.7704 - val_loss: 1.2221 - val_accuracy: 0.5983\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5343 - accuracy: 0.7556 - val_loss: 1.2192 - val_accuracy: 0.6068\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5523 - accuracy: 0.7593 - val_loss: 1.2888 - val_accuracy: 0.5897\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5292 - accuracy: 0.7593 - val_loss: 1.2223 - val_accuracy: 0.6154\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5455 - accuracy: 0.7444 - val_loss: 1.2505 - val_accuracy: 0.5556\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5802 - accuracy: 0.7593 - val_loss: 1.2895 - val_accuracy: 0.6154\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6809 - accuracy: 0.7519 - val_loss: 1.2269 - val_accuracy: 0.5726\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6237 - accuracy: 0.7556 - val_loss: 1.4537 - val_accuracy: 0.6068\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8992 - accuracy: 0.7333 - val_loss: 1.2442 - val_accuracy: 0.5641\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.5793 - accuracy: 0.7593 - val_loss: 1.2209 - val_accuracy: 0.5983\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5435 - accuracy: 0.7481 - val_loss: 1.2192 - val_accuracy: 0.6154\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5307 - accuracy: 0.7481 - val_loss: 1.2093 - val_accuracy: 0.6239\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5255 - accuracy: 0.7481 - val_loss: 1.2079 - val_accuracy: 0.6068\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5136 - accuracy: 0.7444 - val_loss: 1.2117 - val_accuracy: 0.6068\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5170 - accuracy: 0.7593 - val_loss: 1.1988 - val_accuracy: 0.5983\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5325 - accuracy: 0.7593 - val_loss: 1.2083 - val_accuracy: 0.6154\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5322 - accuracy: 0.7519 - val_loss: 1.2075 - val_accuracy: 0.5983\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5212 - accuracy: 0.7556 - val_loss: 1.2066 - val_accuracy: 0.5897\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5133 - accuracy: 0.7556 - val_loss: 1.2268 - val_accuracy: 0.6239\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5297 - accuracy: 0.7519 - val_loss: 1.2250 - val_accuracy: 0.5726\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5285 - accuracy: 0.7481 - val_loss: 1.2203 - val_accuracy: 0.5983\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5536 - accuracy: 0.7630 - val_loss: 1.2132 - val_accuracy: 0.6068\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5319 - accuracy: 0.7667 - val_loss: 1.2123 - val_accuracy: 0.6154\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5253 - accuracy: 0.7407 - val_loss: 1.2040 - val_accuracy: 0.6154\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.5089 - accuracy: 0.7630 - val_loss: 1.2149 - val_accuracy: 0.5983\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.5266 - accuracy: 0.7667 - val_loss: 1.2087 - val_accuracy: 0.6239\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.5385 - accuracy: 0.7704 - val_loss: 1.2658 - val_accuracy: 0.5470\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.5210 - accuracy: 0.7630 - val_loss: 1.2076 - val_accuracy: 0.6154\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.5212 - accuracy: 0.7481 - val_loss: 1.2000 - val_accuracy: 0.5470\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.5246 - accuracy: 0.7481 - val_loss: 1.2296 - val_accuracy: 0.5983\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 979us/step - loss: 0.5356 - accuracy: 0.7667 - val_loss: 1.2113 - val_accuracy: 0.6068\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.5371 - accuracy: 0.7519 - val_loss: 1.2508 - val_accuracy: 0.5726\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.5595 - accuracy: 0.7407 - val_loss: 1.2129 - val_accuracy: 0.6239\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5220 - accuracy: 0.7741 - val_loss: 1.2100 - val_accuracy: 0.5983\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5133 - accuracy: 0.7556 - val_loss: 1.2095 - val_accuracy: 0.6239\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.5173 - accuracy: 0.7556 - val_loss: 1.2150 - val_accuracy: 0.6239\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.5323 - accuracy: 0.7593 - val_loss: 1.2401 - val_accuracy: 0.5983\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5235 - accuracy: 0.7741 - val_loss: 1.2341 - val_accuracy: 0.6068\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5640 - accuracy: 0.7481 - val_loss: 1.2593 - val_accuracy: 0.5556\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5316 - accuracy: 0.7741 - val_loss: 1.2530 - val_accuracy: 0.6154\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.5381 - accuracy: 0.7667 - val_loss: 1.2347 - val_accuracy: 0.5983\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5268 - accuracy: 0.7481 - val_loss: 1.2423 - val_accuracy: 0.5641\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.5540 - accuracy: 0.7444 - val_loss: 1.2826 - val_accuracy: 0.5726\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6194 - accuracy: 0.7556 - val_loss: 1.6251 - val_accuracy: 0.5299\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7609 - accuracy: 0.7333 - val_loss: 1.2349 - val_accuracy: 0.5726\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6852 - accuracy: 0.7444 - val_loss: 1.2391 - val_accuracy: 0.6068\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.7945 - accuracy: 0.6815 - val_loss: 2.8650 - val_accuracy: 0.5470\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 1.0077 - accuracy: 0.6963 - val_loss: 1.5262 - val_accuracy: 0.5043\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8942 - accuracy: 0.7000 - val_loss: 1.2520 - val_accuracy: 0.5470\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6198 - accuracy: 0.7296 - val_loss: 1.2359 - val_accuracy: 0.6154\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5731 - accuracy: 0.7296 - val_loss: 1.2253 - val_accuracy: 0.5983\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5599 - accuracy: 0.7481 - val_loss: 1.2047 - val_accuracy: 0.5983\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.5363 - accuracy: 0.7593 - val_loss: 1.2147 - val_accuracy: 0.5983\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5454 - accuracy: 0.7593 - val_loss: 1.2286 - val_accuracy: 0.6068\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5214 - accuracy: 0.7444 - val_loss: 1.2301 - val_accuracy: 0.6239\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5350 - accuracy: 0.7407 - val_loss: 1.2190 - val_accuracy: 0.5983\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5466 - accuracy: 0.7630 - val_loss: 1.2177 - val_accuracy: 0.6154\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5319 - accuracy: 0.7593 - val_loss: 1.2111 - val_accuracy: 0.5983\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5494 - accuracy: 0.7556 - val_loss: 1.2033 - val_accuracy: 0.6068\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5245 - accuracy: 0.7593 - val_loss: 1.2152 - val_accuracy: 0.6068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5469 - accuracy: 0.7556 - val_loss: 1.2099 - val_accuracy: 0.6154\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5333 - accuracy: 0.7593 - val_loss: 1.2101 - val_accuracy: 0.6154\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5266 - accuracy: 0.7741 - val_loss: 1.2368 - val_accuracy: 0.5983\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.5646 - accuracy: 0.7593 - val_loss: 1.2277 - val_accuracy: 0.5897\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5228 - accuracy: 0.7593 - val_loss: 1.2507 - val_accuracy: 0.5983\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5261 - accuracy: 0.7556 - val_loss: 1.2235 - val_accuracy: 0.6154\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5256 - accuracy: 0.7444 - val_loss: 1.2244 - val_accuracy: 0.5556\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.5295 - accuracy: 0.7407 - val_loss: 1.2195 - val_accuracy: 0.5983\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5568 - accuracy: 0.7593 - val_loss: 1.2176 - val_accuracy: 0.6068\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6897 - accuracy: 0.7630 - val_loss: 1.2345 - val_accuracy: 0.6068\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5458 - accuracy: 0.7556 - val_loss: 1.2212 - val_accuracy: 0.5897\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5426 - accuracy: 0.7481 - val_loss: 1.2590 - val_accuracy: 0.5812\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5368 - accuracy: 0.7630 - val_loss: 1.2279 - val_accuracy: 0.6154\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5534 - accuracy: 0.7407 - val_loss: 1.2347 - val_accuracy: 0.6068\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.5214 - accuracy: 0.7556 - val_loss: 1.2161 - val_accuracy: 0.6154\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.5142 - accuracy: 0.7630 - val_loss: 1.2370 - val_accuracy: 0.5983\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5192 - accuracy: 0.7593 - val_loss: 1.2266 - val_accuracy: 0.6068\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5228 - accuracy: 0.7556 - val_loss: 1.2243 - val_accuracy: 0.6068\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.5196 - accuracy: 0.7667 - val_loss: 1.2143 - val_accuracy: 0.6068\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5096 - accuracy: 0.7519 - val_loss: 1.2078 - val_accuracy: 0.5897\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5154 - accuracy: 0.7481 - val_loss: 1.2127 - val_accuracy: 0.6068\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5214 - accuracy: 0.7556 - val_loss: 1.2156 - val_accuracy: 0.5897\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.5245 - accuracy: 0.7630 - val_loss: 1.2097 - val_accuracy: 0.6068\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5168 - accuracy: 0.7481 - val_loss: 1.2125 - val_accuracy: 0.5983\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.5073 - accuracy: 0.7593 - val_loss: 1.2104 - val_accuracy: 0.6068\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.5364 - accuracy: 0.7593 - val_loss: 1.2289 - val_accuracy: 0.5983\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.5221 - accuracy: 0.7519 - val_loss: 1.2098 - val_accuracy: 0.5897\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.5091 - accuracy: 0.7630 - val_loss: 1.2131 - val_accuracy: 0.5897\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.5088 - accuracy: 0.7556 - val_loss: 1.2108 - val_accuracy: 0.5897\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 355us/step - loss: 0.5185 - accuracy: 0.7667 - val_loss: 1.2123 - val_accuracy: 0.6068\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.5372 - accuracy: 0.7556 - val_loss: 1.2310 - val_accuracy: 0.5983\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5292 - accuracy: 0.7519 - val_loss: 1.2083 - val_accuracy: 0.5726\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5087 - accuracy: 0.7593 - val_loss: 1.2082 - val_accuracy: 0.5897\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5339 - accuracy: 0.7481 - val_loss: 1.2088 - val_accuracy: 0.6068\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5202 - accuracy: 0.7481 - val_loss: 1.2104 - val_accuracy: 0.5897\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5130 - accuracy: 0.7630 - val_loss: 1.2119 - val_accuracy: 0.5726\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5112 - accuracy: 0.7519 - val_loss: 1.2358 - val_accuracy: 0.5812\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8460 - accuracy: 0.7333 - val_loss: 1.3961 - val_accuracy: 0.6068\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0373 - accuracy: 0.7370 - val_loss: 1.4220 - val_accuracy: 0.6154\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7675 - accuracy: 0.7259 - val_loss: 1.2083 - val_accuracy: 0.5641\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5590 - accuracy: 0.7593 - val_loss: 1.2388 - val_accuracy: 0.6154\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5504 - accuracy: 0.7630 - val_loss: 1.2203 - val_accuracy: 0.6239\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5457 - accuracy: 0.7593 - val_loss: 1.2240 - val_accuracy: 0.5983\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5420 - accuracy: 0.7630 - val_loss: 1.2030 - val_accuracy: 0.6068\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5184 - accuracy: 0.7519 - val_loss: 1.2131 - val_accuracy: 0.6068\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5276 - accuracy: 0.7667 - val_loss: 1.1994 - val_accuracy: 0.6239\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 114us/step - loss: 0.5218 - accuracy: 0.7593 - val_loss: 1.2362 - val_accuracy: 0.5726\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5595 - accuracy: 0.7556 - val_loss: 1.2101 - val_accuracy: 0.6154\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.5292 - accuracy: 0.7667 - val_loss: 1.2167 - val_accuracy: 0.5983\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5282 - accuracy: 0.7593 - val_loss: 1.2196 - val_accuracy: 0.5983\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.5201 - accuracy: 0.7593 - val_loss: 1.2152 - val_accuracy: 0.6154\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.5160 - accuracy: 0.7519 - val_loss: 1.2159 - val_accuracy: 0.5983\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 273us/step - loss: 0.5135 - accuracy: 0.7630 - val_loss: 1.2181 - val_accuracy: 0.5983\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.5258 - accuracy: 0.7481 - val_loss: 1.2178 - val_accuracy: 0.6068\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.5507 - accuracy: 0.7593 - val_loss: 1.2303 - val_accuracy: 0.5726\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6768 - accuracy: 0.7556 - val_loss: 1.3060 - val_accuracy: 0.6154\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6487 - accuracy: 0.7556 - val_loss: 1.2561 - val_accuracy: 0.5470\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5819 - accuracy: 0.7481 - val_loss: 1.3528 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7371 - accuracy: 0.7222 - val_loss: 1.2780 - val_accuracy: 0.5641\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8692 - accuracy: 0.7111 - val_loss: 1.3140 - val_accuracy: 0.6068\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6234 - accuracy: 0.7407 - val_loss: 1.2691 - val_accuracy: 0.5641\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6284 - accuracy: 0.7259 - val_loss: 1.2115 - val_accuracy: 0.6068\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5449 - accuracy: 0.7259 - val_loss: 1.2051 - val_accuracy: 0.6239\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.5287 - accuracy: 0.7556 - val_loss: 1.1916 - val_accuracy: 0.6239\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5561 - accuracy: 0.7370 - val_loss: 1.2086 - val_accuracy: 0.5983\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5456 - accuracy: 0.7556 - val_loss: 1.2014 - val_accuracy: 0.6068\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5455 - accuracy: 0.7370 - val_loss: 1.2415 - val_accuracy: 0.5812\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5208 - accuracy: 0.7593 - val_loss: 1.2082 - val_accuracy: 0.5897\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5171 - accuracy: 0.7519 - val_loss: 1.2030 - val_accuracy: 0.6154\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5456 - accuracy: 0.7519 - val_loss: 1.2131 - val_accuracy: 0.6154\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.5500 - accuracy: 0.7556 - val_loss: 1.2132 - val_accuracy: 0.5983\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.5447 - accuracy: 0.7630 - val_loss: 1.2018 - val_accuracy: 0.6068\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5339 - accuracy: 0.7481 - val_loss: 1.2185 - val_accuracy: 0.6068\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5086 - accuracy: 0.7704 - val_loss: 1.2119 - val_accuracy: 0.5897\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5167 - accuracy: 0.7556 - val_loss: 1.2112 - val_accuracy: 0.5983\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5209 - accuracy: 0.7667 - val_loss: 1.2101 - val_accuracy: 0.5983\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.5511 - accuracy: 0.7481 - val_loss: 1.2144 - val_accuracy: 0.5897\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5424 - accuracy: 0.7519 - val_loss: 1.2034 - val_accuracy: 0.5897\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5174 - accuracy: 0.7444 - val_loss: 1.2205 - val_accuracy: 0.5983\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.5266 - accuracy: 0.7630 - val_loss: 1.2219 - val_accuracy: 0.6239\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.5376 - accuracy: 0.7519 - val_loss: 1.2251 - val_accuracy: 0.6068\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.5101 - accuracy: 0.7630 - val_loss: 1.2234 - val_accuracy: 0.6154\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.5282 - accuracy: 0.7630 - val_loss: 1.2203 - val_accuracy: 0.5983\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.5743 - accuracy: 0.7778 - val_loss: 1.2142 - val_accuracy: 0.6239\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5267 - accuracy: 0.7593 - val_loss: 1.2246 - val_accuracy: 0.6068\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5210 - accuracy: 0.7667 - val_loss: 1.2100 - val_accuracy: 0.6068\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.5197 - accuracy: 0.7667 - val_loss: 1.2130 - val_accuracy: 0.5812\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5131 - accuracy: 0.7407 - val_loss: 1.1993 - val_accuracy: 0.6068\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5089 - accuracy: 0.7667 - val_loss: 1.2017 - val_accuracy: 0.6068\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5143 - accuracy: 0.7481 - val_loss: 1.2035 - val_accuracy: 0.5897\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5059 - accuracy: 0.7704 - val_loss: 1.2111 - val_accuracy: 0.6068\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5269 - accuracy: 0.7519 - val_loss: 1.2217 - val_accuracy: 0.5983\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5164 - accuracy: 0.7667 - val_loss: 1.2086 - val_accuracy: 0.6068\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5111 - accuracy: 0.7556 - val_loss: 1.2089 - val_accuracy: 0.5983\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5135 - accuracy: 0.7667 - val_loss: 1.2224 - val_accuracy: 0.6154\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5231 - accuracy: 0.7630 - val_loss: 1.2243 - val_accuracy: 0.5897\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5350 - accuracy: 0.7667 - val_loss: 1.2151 - val_accuracy: 0.5812\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.5298 - accuracy: 0.7593 - val_loss: 1.2285 - val_accuracy: 0.5983\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.5407 - accuracy: 0.7630 - val_loss: 1.2169 - val_accuracy: 0.6154\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5045 - accuracy: 0.7593 - val_loss: 1.2241 - val_accuracy: 0.6154\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5211 - accuracy: 0.7630 - val_loss: 1.2173 - val_accuracy: 0.5983\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5553 - accuracy: 0.7593 - val_loss: 1.2395 - val_accuracy: 0.5726\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5339 - accuracy: 0.7630 - val_loss: 1.2249 - val_accuracy: 0.5983\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.5251 - accuracy: 0.7519 - val_loss: 1.2352 - val_accuracy: 0.5897\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5145 - accuracy: 0.7556 - val_loss: 1.2315 - val_accuracy: 0.5812\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.5083 - accuracy: 0.7593 - val_loss: 1.2248 - val_accuracy: 0.5897\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5209 - accuracy: 0.7667 - val_loss: 1.2372 - val_accuracy: 0.5641\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5328 - accuracy: 0.7630 - val_loss: 1.2037 - val_accuracy: 0.6154\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.5162 - accuracy: 0.7481 - val_loss: 1.2142 - val_accuracy: 0.5983\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.5162 - accuracy: 0.7667 - val_loss: 1.2120 - val_accuracy: 0.5983\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5022 - accuracy: 0.7704 - val_loss: 1.2215 - val_accuracy: 0.5556\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.5263 - accuracy: 0.7593 - val_loss: 1.2108 - val_accuracy: 0.5812\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5214 - accuracy: 0.7630 - val_loss: 1.2185 - val_accuracy: 0.5812\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5530 - accuracy: 0.7444 - val_loss: 1.2347 - val_accuracy: 0.5812\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5426 - accuracy: 0.7556 - val_loss: 1.2162 - val_accuracy: 0.5897\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5885 - accuracy: 0.7444 - val_loss: 1.2330 - val_accuracy: 0.5897\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6130 - accuracy: 0.7593 - val_loss: 1.2515 - val_accuracy: 0.6154\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5660 - accuracy: 0.7593 - val_loss: 1.2352 - val_accuracy: 0.5641\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.5279 - accuracy: 0.7593 - val_loss: 1.2180 - val_accuracy: 0.6068\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5179 - accuracy: 0.7593 - val_loss: 1.2321 - val_accuracy: 0.6154\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.5148 - accuracy: 0.7630 - val_loss: 1.2292 - val_accuracy: 0.6068\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.5182 - accuracy: 0.7667 - val_loss: 1.2150 - val_accuracy: 0.6068\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5293 - accuracy: 0.7444 - val_loss: 1.2312 - val_accuracy: 0.5897\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.5349 - accuracy: 0.7370 - val_loss: 1.2258 - val_accuracy: 0.5983\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5285 - accuracy: 0.7630 - val_loss: 1.2419 - val_accuracy: 0.6068\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5290 - accuracy: 0.7630 - val_loss: 1.2263 - val_accuracy: 0.5983\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5097 - accuracy: 0.7593 - val_loss: 1.2355 - val_accuracy: 0.6068\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5226 - accuracy: 0.7593 - val_loss: 1.2253 - val_accuracy: 0.5897\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5177 - accuracy: 0.7444 - val_loss: 1.2445 - val_accuracy: 0.6239\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5254 - accuracy: 0.7519 - val_loss: 1.2234 - val_accuracy: 0.6068\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5111 - accuracy: 0.7556 - val_loss: 1.2096 - val_accuracy: 0.6068\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.5081 - accuracy: 0.7593 - val_loss: 1.2145 - val_accuracy: 0.5983\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5079 - accuracy: 0.7667 - val_loss: 1.2150 - val_accuracy: 0.6068\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.5314 - accuracy: 0.7556 - val_loss: 1.2251 - val_accuracy: 0.6325\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5088 - accuracy: 0.7519 - val_loss: 1.2243 - val_accuracy: 0.5983\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5141 - accuracy: 0.7556 - val_loss: 1.2184 - val_accuracy: 0.6154\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.5066 - accuracy: 0.7593 - val_loss: 1.2259 - val_accuracy: 0.6068\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.5191 - accuracy: 0.7593 - val_loss: 1.2186 - val_accuracy: 0.6154\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5255 - accuracy: 0.7519 - val_loss: 1.2400 - val_accuracy: 0.5983\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5295 - accuracy: 0.7556 - val_loss: 1.2226 - val_accuracy: 0.6154\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5311 - accuracy: 0.7593 - val_loss: 1.2209 - val_accuracy: 0.5983\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5239 - accuracy: 0.7519 - val_loss: 1.2420 - val_accuracy: 0.5897\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5257 - accuracy: 0.7556 - val_loss: 1.2190 - val_accuracy: 0.6154\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5054 - accuracy: 0.7593 - val_loss: 1.2141 - val_accuracy: 0.5812\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5027 - accuracy: 0.7667 - val_loss: 1.2224 - val_accuracy: 0.5897\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5215 - accuracy: 0.7481 - val_loss: 1.2181 - val_accuracy: 0.5897\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5179 - accuracy: 0.7370 - val_loss: 1.2328 - val_accuracy: 0.6239\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5239 - accuracy: 0.7444 - val_loss: 1.2277 - val_accuracy: 0.6068\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5154 - accuracy: 0.7593 - val_loss: 1.2136 - val_accuracy: 0.6068\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5127 - accuracy: 0.7519 - val_loss: 1.2284 - val_accuracy: 0.5983\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5354 - accuracy: 0.7667 - val_loss: 1.2275 - val_accuracy: 0.5983\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6143 - accuracy: 0.7481 - val_loss: 1.2650 - val_accuracy: 0.6154\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6077 - accuracy: 0.7630 - val_loss: 1.2484 - val_accuracy: 0.5726\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7211 - accuracy: 0.7444 - val_loss: 1.3706 - val_accuracy: 0.6068\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7295 - accuracy: 0.7519 - val_loss: 1.2540 - val_accuracy: 0.5726\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8313 - accuracy: 0.7333 - val_loss: 1.4275 - val_accuracy: 0.6154\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 168us/step - loss: 0.9419 - accuracy: 0.7444 - val_loss: 1.2286 - val_accuracy: 0.6239\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6038 - accuracy: 0.7667 - val_loss: 1.2533 - val_accuracy: 0.5641\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.5456 - accuracy: 0.7519 - val_loss: 1.2200 - val_accuracy: 0.6068\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5549 - accuracy: 0.7444 - val_loss: 1.2030 - val_accuracy: 0.6154\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5085 - accuracy: 0.7704 - val_loss: 1.1963 - val_accuracy: 0.5983\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.5225 - accuracy: 0.7630 - val_loss: 1.2026 - val_accuracy: 0.5897\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.5102 - accuracy: 0.7630 - val_loss: 1.2099 - val_accuracy: 0.6068\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5170 - accuracy: 0.7667 - val_loss: 1.2114 - val_accuracy: 0.5897\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5081 - accuracy: 0.7778 - val_loss: 1.2124 - val_accuracy: 0.5983\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.5648 - accuracy: 0.7667 - val_loss: 1.2127 - val_accuracy: 0.6068\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.5425 - accuracy: 0.7407 - val_loss: 1.2077 - val_accuracy: 0.5897\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.78 - 0s 141us/step - loss: 0.5225 - accuracy: 0.7556 - val_loss: 1.2215 - val_accuracy: 0.6068\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5170 - accuracy: 0.7556 - val_loss: 1.2168 - val_accuracy: 0.5983\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.5145 - accuracy: 0.7630 - val_loss: 1.2195 - val_accuracy: 0.5897\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.5411 - accuracy: 0.7630 - val_loss: 1.2159 - val_accuracy: 0.5897\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.5285 - accuracy: 0.7630 - val_loss: 1.2149 - val_accuracy: 0.5897\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.5076 - accuracy: 0.7630 - val_loss: 1.2091 - val_accuracy: 0.6068\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.5071 - accuracy: 0.7630 - val_loss: 1.2042 - val_accuracy: 0.5983\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5121 - accuracy: 0.7519 - val_loss: 1.1972 - val_accuracy: 0.5983\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5089 - accuracy: 0.7593 - val_loss: 1.2028 - val_accuracy: 0.6068\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.5050 - accuracy: 0.7407 - val_loss: 1.2119 - val_accuracy: 0.6239\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5035 - accuracy: 0.7556 - val_loss: 1.2046 - val_accuracy: 0.5983\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5087 - accuracy: 0.7704 - val_loss: 1.2112 - val_accuracy: 0.5897\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5338 - accuracy: 0.7593 - val_loss: 1.2165 - val_accuracy: 0.5897\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6099 - accuracy: 0.7630 - val_loss: 1.3039 - val_accuracy: 0.5983\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6292 - accuracy: 0.7444 - val_loss: 1.2363 - val_accuracy: 0.5726\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6226 - accuracy: 0.7444 - val_loss: 1.2270 - val_accuracy: 0.5983\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5507 - accuracy: 0.7370 - val_loss: 1.2209 - val_accuracy: 0.6239\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5201 - accuracy: 0.7444 - val_loss: 1.2164 - val_accuracy: 0.6068\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5230 - accuracy: 0.7444 - val_loss: 1.2087 - val_accuracy: 0.6154\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5053 - accuracy: 0.7481 - val_loss: 1.1997 - val_accuracy: 0.5983\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5055 - accuracy: 0.7593 - val_loss: 1.2018 - val_accuracy: 0.6068\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5138 - accuracy: 0.7556 - val_loss: 1.2083 - val_accuracy: 0.5983\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5102 - accuracy: 0.7593 - val_loss: 1.2213 - val_accuracy: 0.6068\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5124 - accuracy: 0.7593 - val_loss: 1.2127 - val_accuracy: 0.6068\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5198 - accuracy: 0.7630 - val_loss: 1.2119 - val_accuracy: 0.5983\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5269 - accuracy: 0.7519 - val_loss: 1.2098 - val_accuracy: 0.6068\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5092 - accuracy: 0.7593 - val_loss: 1.2049 - val_accuracy: 0.6068\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5134 - accuracy: 0.7630 - val_loss: 1.2205 - val_accuracy: 0.5983\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5286 - accuracy: 0.7667 - val_loss: 1.2288 - val_accuracy: 0.5897\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5253 - accuracy: 0.7593 - val_loss: 1.2173 - val_accuracy: 0.6068\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5176 - accuracy: 0.7519 - val_loss: 1.2471 - val_accuracy: 0.5726\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5434 - accuracy: 0.7519 - val_loss: 1.2258 - val_accuracy: 0.6154\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5282 - accuracy: 0.7593 - val_loss: 1.2354 - val_accuracy: 0.5812\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5215 - accuracy: 0.7481 - val_loss: 1.2230 - val_accuracy: 0.6068\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5232 - accuracy: 0.7444 - val_loss: 1.2109 - val_accuracy: 0.5897\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5050 - accuracy: 0.7630 - val_loss: 1.2197 - val_accuracy: 0.6068\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5108 - accuracy: 0.7630 - val_loss: 1.2275 - val_accuracy: 0.5983\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.5254 - accuracy: 0.7667 - val_loss: 1.2348 - val_accuracy: 0.5812\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.5512 - accuracy: 0.7556 - val_loss: 1.2447 - val_accuracy: 0.5641\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.5130 - accuracy: 0.7630 - val_loss: 1.2348 - val_accuracy: 0.6154\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5370 - accuracy: 0.7556 - val_loss: 1.2263 - val_accuracy: 0.5983\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5092 - accuracy: 0.7667 - val_loss: 1.2184 - val_accuracy: 0.5812\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.5215 - accuracy: 0.7481 - val_loss: 1.2046 - val_accuracy: 0.6154\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.5042 - accuracy: 0.7630 - val_loss: 1.2208 - val_accuracy: 0.6154\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5078 - accuracy: 0.7593 - val_loss: 1.2221 - val_accuracy: 0.6154\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5110 - accuracy: 0.7556 - val_loss: 1.2275 - val_accuracy: 0.6154\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5077 - accuracy: 0.7630 - val_loss: 1.2163 - val_accuracy: 0.6154\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5060 - accuracy: 0.7556 - val_loss: 1.2410 - val_accuracy: 0.5897\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5066 - accuracy: 0.7630 - val_loss: 1.2147 - val_accuracy: 0.6154\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.5142 - accuracy: 0.7519 - val_loss: 1.2351 - val_accuracy: 0.5983\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5281 - accuracy: 0.7593 - val_loss: 1.2132 - val_accuracy: 0.6239\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5008 - accuracy: 0.7704 - val_loss: 1.2343 - val_accuracy: 0.5897\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5173 - accuracy: 0.7630 - val_loss: 1.2290 - val_accuracy: 0.6154\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5522 - accuracy: 0.7630 - val_loss: 1.2513 - val_accuracy: 0.5726\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5392 - accuracy: 0.7333 - val_loss: 1.2169 - val_accuracy: 0.6154\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5156 - accuracy: 0.7519 - val_loss: 1.2206 - val_accuracy: 0.6068\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5045 - accuracy: 0.7704 - val_loss: 1.2330 - val_accuracy: 0.6154\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5089 - accuracy: 0.7556 - val_loss: 1.2193 - val_accuracy: 0.6154\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5043 - accuracy: 0.7593 - val_loss: 1.2171 - val_accuracy: 0.5983\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5043 - accuracy: 0.7630 - val_loss: 1.2200 - val_accuracy: 0.5983\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5196 - accuracy: 0.7667 - val_loss: 1.2740 - val_accuracy: 0.5726\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5656 - accuracy: 0.7815 - val_loss: 1.2497 - val_accuracy: 0.6154\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5574 - accuracy: 0.7370 - val_loss: 1.2493 - val_accuracy: 0.5983\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5338 - accuracy: 0.7593 - val_loss: 1.2428 - val_accuracy: 0.6154\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5486 - accuracy: 0.7704 - val_loss: 1.2286 - val_accuracy: 0.5983\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5113 - accuracy: 0.7630 - val_loss: 1.2229 - val_accuracy: 0.5983\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5257 - accuracy: 0.7593 - val_loss: 1.2289 - val_accuracy: 0.5983\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5377 - accuracy: 0.7667 - val_loss: 1.2305 - val_accuracy: 0.6154\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.4981 - accuracy: 0.7630 - val_loss: 1.2309 - val_accuracy: 0.6154\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.5325 - accuracy: 0.7556 - val_loss: 1.2096 - val_accuracy: 0.6154\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5074 - accuracy: 0.7481 - val_loss: 1.2276 - val_accuracy: 0.6325\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5074 - accuracy: 0.7556 - val_loss: 1.2236 - val_accuracy: 0.6068\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5086 - accuracy: 0.7333 - val_loss: 1.2232 - val_accuracy: 0.5983\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5153 - accuracy: 0.7741 - val_loss: 1.2312 - val_accuracy: 0.6068\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5170 - accuracy: 0.7519 - val_loss: 1.2333 - val_accuracy: 0.6154\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5036 - accuracy: 0.7630 - val_loss: 1.2221 - val_accuracy: 0.6068\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5025 - accuracy: 0.7444 - val_loss: 1.2226 - val_accuracy: 0.6239\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5105 - accuracy: 0.7556 - val_loss: 1.2263 - val_accuracy: 0.6154\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5040 - accuracy: 0.7593 - val_loss: 1.2348 - val_accuracy: 0.5897\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5019 - accuracy: 0.7667 - val_loss: 1.2106 - val_accuracy: 0.6154\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5126 - accuracy: 0.7556 - val_loss: 1.2459 - val_accuracy: 0.5726\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5401 - accuracy: 0.7333 - val_loss: 1.2289 - val_accuracy: 0.6154\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5107 - accuracy: 0.7630 - val_loss: 1.2273 - val_accuracy: 0.6325\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5117 - accuracy: 0.7593 - val_loss: 1.2252 - val_accuracy: 0.6154\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5131 - accuracy: 0.7667 - val_loss: 1.2457 - val_accuracy: 0.5897\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5200 - accuracy: 0.7593 - val_loss: 1.2324 - val_accuracy: 0.6154\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5246 - accuracy: 0.7519 - val_loss: 1.2237 - val_accuracy: 0.6154\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5388 - accuracy: 0.7519 - val_loss: 1.2289 - val_accuracy: 0.6068\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.5180 - accuracy: 0.7556 - val_loss: 1.2190 - val_accuracy: 0.6239\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5262 - accuracy: 0.7556 - val_loss: 1.2937 - val_accuracy: 0.6154\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6512 - accuracy: 0.7481 - val_loss: 1.5108 - val_accuracy: 0.5299\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6898 - accuracy: 0.7481 - val_loss: 1.4080 - val_accuracy: 0.6239\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6823 - accuracy: 0.7593 - val_loss: 1.2594 - val_accuracy: 0.5812\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6449 - accuracy: 0.7704 - val_loss: 1.5402 - val_accuracy: 0.6154\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7991 - accuracy: 0.7556 - val_loss: 1.3503 - val_accuracy: 0.5385\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5882 - accuracy: 0.7333 - val_loss: 1.2572 - val_accuracy: 0.6068\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5594 - accuracy: 0.7593 - val_loss: 1.2710 - val_accuracy: 0.5812\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5789 - accuracy: 0.7593 - val_loss: 1.2305 - val_accuracy: 0.6239\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5150 - accuracy: 0.7667 - val_loss: 1.2162 - val_accuracy: 0.6325\n",
      "Epoch 554/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 88us/step - loss: 0.4986 - accuracy: 0.7704 - val_loss: 1.2147 - val_accuracy: 0.6154\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5211 - accuracy: 0.7667 - val_loss: 1.2271 - val_accuracy: 0.5897\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5084 - accuracy: 0.7593 - val_loss: 1.2130 - val_accuracy: 0.6325\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5220 - accuracy: 0.7370 - val_loss: 1.2273 - val_accuracy: 0.6068\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5026 - accuracy: 0.7630 - val_loss: 1.2243 - val_accuracy: 0.5983\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5290 - accuracy: 0.7630 - val_loss: 1.2100 - val_accuracy: 0.6068\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5095 - accuracy: 0.7667 - val_loss: 1.2258 - val_accuracy: 0.6154\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5254 - accuracy: 0.7444 - val_loss: 1.2188 - val_accuracy: 0.6154\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5049 - accuracy: 0.7704 - val_loss: 1.2296 - val_accuracy: 0.5812\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5090 - accuracy: 0.7519 - val_loss: 1.2106 - val_accuracy: 0.6154\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5290 - accuracy: 0.7444 - val_loss: 1.2240 - val_accuracy: 0.5897\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5097 - accuracy: 0.7556 - val_loss: 1.2209 - val_accuracy: 0.5897\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.4991 - accuracy: 0.7481 - val_loss: 1.2208 - val_accuracy: 0.5983\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.4990 - accuracy: 0.7481 - val_loss: 1.2198 - val_accuracy: 0.5897\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5079 - accuracy: 0.7667 - val_loss: 1.2096 - val_accuracy: 0.6239\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.4965 - accuracy: 0.7741 - val_loss: 1.2212 - val_accuracy: 0.6068\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5057 - accuracy: 0.7593 - val_loss: 1.2151 - val_accuracy: 0.6154\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5156 - accuracy: 0.7593 - val_loss: 1.2194 - val_accuracy: 0.5983\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5041 - accuracy: 0.7593 - val_loss: 1.2298 - val_accuracy: 0.6068\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.4995 - accuracy: 0.7519 - val_loss: 1.2228 - val_accuracy: 0.6068\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5123 - accuracy: 0.7593 - val_loss: 1.2239 - val_accuracy: 0.6068\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5097 - accuracy: 0.7481 - val_loss: 1.2332 - val_accuracy: 0.6154\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5096 - accuracy: 0.7444 - val_loss: 1.2221 - val_accuracy: 0.5641\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5210 - accuracy: 0.7593 - val_loss: 1.2434 - val_accuracy: 0.5983\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5221 - accuracy: 0.7593 - val_loss: 1.2386 - val_accuracy: 0.6068\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5544 - accuracy: 0.7481 - val_loss: 1.2569 - val_accuracy: 0.5897\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5730 - accuracy: 0.7333 - val_loss: 1.2332 - val_accuracy: 0.5983\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5780 - accuracy: 0.7556 - val_loss: 1.2484 - val_accuracy: 0.5812\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5861 - accuracy: 0.7481 - val_loss: 1.2314 - val_accuracy: 0.5983\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5070 - accuracy: 0.7630 - val_loss: 1.2346 - val_accuracy: 0.6154\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.5112 - accuracy: 0.7630 - val_loss: 1.2129 - val_accuracy: 0.6154\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.5150 - accuracy: 0.7444 - val_loss: 1.2202 - val_accuracy: 0.5983\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5440 - accuracy: 0.7630 - val_loss: 1.2390 - val_accuracy: 0.5983\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6549 - accuracy: 0.7296 - val_loss: 1.2216 - val_accuracy: 0.5983\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5320 - accuracy: 0.7667 - val_loss: 1.2208 - val_accuracy: 0.6068\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5263 - accuracy: 0.7444 - val_loss: 1.2459 - val_accuracy: 0.6068\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5547 - accuracy: 0.7556 - val_loss: 1.2363 - val_accuracy: 0.6154\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5028 - accuracy: 0.7593 - val_loss: 1.2368 - val_accuracy: 0.6068\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.81 - 0s 87us/step - loss: 0.5139 - accuracy: 0.7593 - val_loss: 1.2176 - val_accuracy: 0.6239\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5267 - accuracy: 0.7593 - val_loss: 1.2795 - val_accuracy: 0.5556\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6120 - accuracy: 0.7704 - val_loss: 1.3651 - val_accuracy: 0.6068\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6636 - accuracy: 0.7370 - val_loss: 1.2715 - val_accuracy: 0.5726\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5682 - accuracy: 0.7704 - val_loss: 1.2394 - val_accuracy: 0.6239\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5108 - accuracy: 0.7556 - val_loss: 1.2424 - val_accuracy: 0.6154\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5081 - accuracy: 0.7667 - val_loss: 1.2150 - val_accuracy: 0.5983\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5319 - accuracy: 0.7556 - val_loss: 1.2196 - val_accuracy: 0.6068\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5163 - accuracy: 0.7630 - val_loss: 1.2379 - val_accuracy: 0.6068\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5171 - accuracy: 0.7667 - val_loss: 1.2301 - val_accuracy: 0.5897\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5371 - accuracy: 0.7667 - val_loss: 1.2336 - val_accuracy: 0.6239\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5202 - accuracy: 0.7556 - val_loss: 1.2466 - val_accuracy: 0.6154\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5495 - accuracy: 0.7630 - val_loss: 1.2271 - val_accuracy: 0.5897\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5255 - accuracy: 0.7630 - val_loss: 1.2230 - val_accuracy: 0.5983\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5043 - accuracy: 0.7741 - val_loss: 1.2068 - val_accuracy: 0.5983\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4991 - accuracy: 0.7741 - val_loss: 1.2928 - val_accuracy: 0.5556\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5481 - accuracy: 0.7778 - val_loss: 1.2515 - val_accuracy: 0.6068\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5543 - accuracy: 0.7444 - val_loss: 1.2762 - val_accuracy: 0.5726\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5252 - accuracy: 0.7741 - val_loss: 1.2538 - val_accuracy: 0.6239\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5206 - accuracy: 0.7593 - val_loss: 1.3039 - val_accuracy: 0.5470\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6163 - accuracy: 0.7667 - val_loss: 1.2983 - val_accuracy: 0.6068\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7662 - accuracy: 0.7630 - val_loss: 1.2234 - val_accuracy: 0.5983\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8325 - accuracy: 0.7185 - val_loss: 1.2518 - val_accuracy: 0.5897\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6037 - accuracy: 0.7444 - val_loss: 1.2865 - val_accuracy: 0.5726\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5646 - accuracy: 0.7593 - val_loss: 1.2267 - val_accuracy: 0.6154\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5540 - accuracy: 0.7519 - val_loss: 1.2214 - val_accuracy: 0.6068\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5193 - accuracy: 0.7519 - val_loss: 1.2025 - val_accuracy: 0.5983\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5570 - accuracy: 0.7481 - val_loss: 1.2058 - val_accuracy: 0.5983\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5353 - accuracy: 0.7593 - val_loss: 1.2211 - val_accuracy: 0.6154\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5488 - accuracy: 0.7852 - val_loss: 1.2388 - val_accuracy: 0.5897\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5295 - accuracy: 0.7630 - val_loss: 1.2040 - val_accuracy: 0.5983\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5029 - accuracy: 0.7630 - val_loss: 1.2198 - val_accuracy: 0.5897\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5097 - accuracy: 0.7667 - val_loss: 1.2131 - val_accuracy: 0.5897\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5129 - accuracy: 0.7593 - val_loss: 1.2048 - val_accuracy: 0.6068\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5016 - accuracy: 0.7630 - val_loss: 1.2245 - val_accuracy: 0.5983\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5114 - accuracy: 0.7593 - val_loss: 1.2072 - val_accuracy: 0.5897\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.4995 - accuracy: 0.7704 - val_loss: 1.2126 - val_accuracy: 0.5983\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5049 - accuracy: 0.7593 - val_loss: 1.2126 - val_accuracy: 0.5983\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.4999 - accuracy: 0.7593 - val_loss: 1.2197 - val_accuracy: 0.6068\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5052 - accuracy: 0.7667 - val_loss: 1.2276 - val_accuracy: 0.5983\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5266 - accuracy: 0.7778 - val_loss: 1.2367 - val_accuracy: 0.5983\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.5111 - accuracy: 0.7556 - val_loss: 1.2262 - val_accuracy: 0.5897\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4956 - accuracy: 0.7704 - val_loss: 1.2402 - val_accuracy: 0.5983\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5675 - accuracy: 0.7519 - val_loss: 1.2319 - val_accuracy: 0.6068\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5061 - accuracy: 0.7593 - val_loss: 1.2222 - val_accuracy: 0.6239\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5240 - accuracy: 0.7593 - val_loss: 1.2535 - val_accuracy: 0.5556\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5495 - accuracy: 0.7556 - val_loss: 1.2269 - val_accuracy: 0.6239\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5417 - accuracy: 0.7556 - val_loss: 1.2463 - val_accuracy: 0.5983\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5318 - accuracy: 0.7667 - val_loss: 1.2265 - val_accuracy: 0.5983\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5191 - accuracy: 0.7630 - val_loss: 1.2437 - val_accuracy: 0.5983\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5523 - accuracy: 0.7630 - val_loss: 1.2275 - val_accuracy: 0.5983\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5270 - accuracy: 0.7481 - val_loss: 1.2297 - val_accuracy: 0.6068\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5094 - accuracy: 0.7667 - val_loss: 1.2400 - val_accuracy: 0.5983\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5115 - accuracy: 0.7630 - val_loss: 1.2475 - val_accuracy: 0.5726\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.5502 - accuracy: 0.7667 - val_loss: 1.2353 - val_accuracy: 0.5897\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6074 - accuracy: 0.7556 - val_loss: 1.2378 - val_accuracy: 0.6068\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.5506 - accuracy: 0.7593 - val_loss: 1.2854 - val_accuracy: 0.5641\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5384 - accuracy: 0.7407 - val_loss: 1.2264 - val_accuracy: 0.6154\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.5029 - accuracy: 0.7741 - val_loss: 1.2316 - val_accuracy: 0.5897\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.5066 - accuracy: 0.7593 - val_loss: 1.2320 - val_accuracy: 0.5983\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5329 - accuracy: 0.7556 - val_loss: 1.2484 - val_accuracy: 0.5812\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5387 - accuracy: 0.7481 - val_loss: 1.2415 - val_accuracy: 0.6154\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5248 - accuracy: 0.7593 - val_loss: 1.2346 - val_accuracy: 0.5897\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5088 - accuracy: 0.7593 - val_loss: 1.2347 - val_accuracy: 0.6154\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.5001 - accuracy: 0.7704 - val_loss: 1.2310 - val_accuracy: 0.5983\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.5247 - accuracy: 0.7630 - val_loss: 1.2281 - val_accuracy: 0.6068\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.4998 - accuracy: 0.7556 - val_loss: 1.2299 - val_accuracy: 0.6154\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5007 - accuracy: 0.7667 - val_loss: 1.2362 - val_accuracy: 0.6068\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5258 - accuracy: 0.7704 - val_loss: 1.2408 - val_accuracy: 0.5897\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5070 - accuracy: 0.7815 - val_loss: 1.2310 - val_accuracy: 0.6154\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5291 - accuracy: 0.7519 - val_loss: 1.4742 - val_accuracy: 0.5556\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6781 - accuracy: 0.7556 - val_loss: 1.3148 - val_accuracy: 0.6068\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 97us/step - loss: 0.5550 - accuracy: 0.7444 - val_loss: 1.2578 - val_accuracy: 0.5641\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5356 - accuracy: 0.7556 - val_loss: 1.2620 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.4956 - accuracy: 0.7667 - val_loss: 1.2478 - val_accuracy: 0.6154\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5258 - accuracy: 0.7704 - val_loss: 1.2304 - val_accuracy: 0.6068\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5098 - accuracy: 0.7593 - val_loss: 1.2387 - val_accuracy: 0.6068\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5154 - accuracy: 0.7630 - val_loss: 1.2327 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5069 - accuracy: 0.7593 - val_loss: 1.2235 - val_accuracy: 0.5812\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4989 - accuracy: 0.7556 - val_loss: 1.2275 - val_accuracy: 0.5897\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5018 - accuracy: 0.7593 - val_loss: 1.2270 - val_accuracy: 0.5897\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5120 - accuracy: 0.7593 - val_loss: 1.2285 - val_accuracy: 0.6068\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5415 - accuracy: 0.7444 - val_loss: 1.2774 - val_accuracy: 0.5726\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5320 - accuracy: 0.7630 - val_loss: 1.2630 - val_accuracy: 0.5983\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5386 - accuracy: 0.7667 - val_loss: 1.2630 - val_accuracy: 0.5641\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5946 - accuracy: 0.7444 - val_loss: 1.2440 - val_accuracy: 0.6239\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5567 - accuracy: 0.7481 - val_loss: 1.2401 - val_accuracy: 0.5897\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5139 - accuracy: 0.7519 - val_loss: 1.2509 - val_accuracy: 0.5983\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5131 - accuracy: 0.7630 - val_loss: 1.2446 - val_accuracy: 0.5812\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5559 - accuracy: 0.7444 - val_loss: 1.2397 - val_accuracy: 0.5897\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5442 - accuracy: 0.7630 - val_loss: 1.2363 - val_accuracy: 0.5983\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5062 - accuracy: 0.7630 - val_loss: 1.2073 - val_accuracy: 0.6068\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5294 - accuracy: 0.7556 - val_loss: 1.2189 - val_accuracy: 0.5726\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.5062 - accuracy: 0.7704 - val_loss: 1.2399 - val_accuracy: 0.5983\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 366us/step - loss: 0.5177 - accuracy: 0.7593 - val_loss: 1.2547 - val_accuracy: 0.6068\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.5075 - accuracy: 0.7481 - val_loss: 1.2308 - val_accuracy: 0.5897\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.5141 - accuracy: 0.7481 - val_loss: 1.2310 - val_accuracy: 0.6239\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5074 - accuracy: 0.7667 - val_loss: 1.2300 - val_accuracy: 0.5897\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.5052 - accuracy: 0.7667 - val_loss: 1.2285 - val_accuracy: 0.5983\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.4987 - accuracy: 0.7593 - val_loss: 1.2487 - val_accuracy: 0.5897\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5040 - accuracy: 0.7630 - val_loss: 1.2349 - val_accuracy: 0.5812\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.5018 - accuracy: 0.7667 - val_loss: 1.2440 - val_accuracy: 0.6068\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.5112 - accuracy: 0.7630 - val_loss: 1.2541 - val_accuracy: 0.6068\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.5318 - accuracy: 0.7556 - val_loss: 1.2705 - val_accuracy: 0.5641\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 406us/step - loss: 0.4982 - accuracy: 0.7630 - val_loss: 1.2507 - val_accuracy: 0.6068\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5028 - accuracy: 0.7593 - val_loss: 1.2435 - val_accuracy: 0.5897\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5022 - accuracy: 0.7667 - val_loss: 1.2529 - val_accuracy: 0.5897\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5083 - accuracy: 0.7667 - val_loss: 1.2685 - val_accuracy: 0.5641\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.5045 - accuracy: 0.7704 - val_loss: 1.2658 - val_accuracy: 0.5983\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.5629 - accuracy: 0.7556 - val_loss: 1.2724 - val_accuracy: 0.5726\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.5089 - accuracy: 0.7630 - val_loss: 1.2557 - val_accuracy: 0.5897\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5308 - accuracy: 0.7593 - val_loss: 1.2299 - val_accuracy: 0.5897\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.5040 - accuracy: 0.7741 - val_loss: 1.2219 - val_accuracy: 0.5983\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5076 - accuracy: 0.7593 - val_loss: 1.2316 - val_accuracy: 0.5812\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4981 - accuracy: 0.7630 - val_loss: 1.2227 - val_accuracy: 0.5897\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5197 - accuracy: 0.7519 - val_loss: 1.2282 - val_accuracy: 0.6068\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5104 - accuracy: 0.7667 - val_loss: 1.2580 - val_accuracy: 0.5726\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5272 - accuracy: 0.7630 - val_loss: 1.2547 - val_accuracy: 0.6154\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5215 - accuracy: 0.7519 - val_loss: 1.2953 - val_accuracy: 0.5726\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5684 - accuracy: 0.7667 - val_loss: 1.2510 - val_accuracy: 0.6154\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.5264 - accuracy: 0.7556 - val_loss: 1.2570 - val_accuracy: 0.5983\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5112 - accuracy: 0.7444 - val_loss: 1.2736 - val_accuracy: 0.5641\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5424 - accuracy: 0.7519 - val_loss: 1.2521 - val_accuracy: 0.6239\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5032 - accuracy: 0.7593 - val_loss: 1.2450 - val_accuracy: 0.6068\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5134 - accuracy: 0.7630 - val_loss: 1.2504 - val_accuracy: 0.5726\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5251 - accuracy: 0.7630 - val_loss: 1.2469 - val_accuracy: 0.6239\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5189 - accuracy: 0.7630 - val_loss: 1.2543 - val_accuracy: 0.5812\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5354 - accuracy: 0.7556 - val_loss: 1.2470 - val_accuracy: 0.5726\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5526 - accuracy: 0.7407 - val_loss: 1.3088 - val_accuracy: 0.6068\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5908 - accuracy: 0.7630 - val_loss: 1.2780 - val_accuracy: 0.5641\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5815 - accuracy: 0.7593 - val_loss: 1.2600 - val_accuracy: 0.5897\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6243 - accuracy: 0.7593 - val_loss: 1.2675 - val_accuracy: 0.5726\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5980 - accuracy: 0.7667 - val_loss: 1.2684 - val_accuracy: 0.5897\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5298 - accuracy: 0.7481 - val_loss: 1.2630 - val_accuracy: 0.5983\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5187 - accuracy: 0.7519 - val_loss: 1.2413 - val_accuracy: 0.5897\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5085 - accuracy: 0.7667 - val_loss: 1.2706 - val_accuracy: 0.6239\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5590 - accuracy: 0.7519 - val_loss: 1.2635 - val_accuracy: 0.5897\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5800 - accuracy: 0.7741 - val_loss: 1.2982 - val_accuracy: 0.6068\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6240 - accuracy: 0.7519 - val_loss: 1.2809 - val_accuracy: 0.5641\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5812 - accuracy: 0.7593 - val_loss: 1.2541 - val_accuracy: 0.5897\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.4876 - accuracy: 0.7704 - val_loss: 1.2502 - val_accuracy: 0.6154\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.5203 - accuracy: 0.7519 - val_loss: 1.2399 - val_accuracy: 0.5812\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5065 - accuracy: 0.7519 - val_loss: 1.2555 - val_accuracy: 0.5897\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5201 - accuracy: 0.7667 - val_loss: 1.2596 - val_accuracy: 0.6154\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5071 - accuracy: 0.7481 - val_loss: 1.2444 - val_accuracy: 0.5726\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5100 - accuracy: 0.7556 - val_loss: 1.2439 - val_accuracy: 0.6068\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5201 - accuracy: 0.7704 - val_loss: 1.2737 - val_accuracy: 0.5641\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5930 - accuracy: 0.7519 - val_loss: 1.2505 - val_accuracy: 0.6068\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5519 - accuracy: 0.7630 - val_loss: 1.2681 - val_accuracy: 0.6068\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5185 - accuracy: 0.7593 - val_loss: 1.2680 - val_accuracy: 0.6068\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5002 - accuracy: 0.7667 - val_loss: 1.2667 - val_accuracy: 0.6154\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5152 - accuracy: 0.7704 - val_loss: 1.2601 - val_accuracy: 0.5812\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5017 - accuracy: 0.7519 - val_loss: 1.2580 - val_accuracy: 0.5897\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5100 - accuracy: 0.7741 - val_loss: 1.2542 - val_accuracy: 0.6068\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5318 - accuracy: 0.7370 - val_loss: 1.2533 - val_accuracy: 0.6068\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.4997 - accuracy: 0.7556 - val_loss: 1.2439 - val_accuracy: 0.5983\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4969 - accuracy: 0.7630 - val_loss: 1.2579 - val_accuracy: 0.5897\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5086 - accuracy: 0.7444 - val_loss: 1.2458 - val_accuracy: 0.6068\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.5006 - accuracy: 0.7630 - val_loss: 1.2459 - val_accuracy: 0.5897\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.5046 - accuracy: 0.7630 - val_loss: 1.2534 - val_accuracy: 0.6239\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.4947 - accuracy: 0.7704 - val_loss: 1.2623 - val_accuracy: 0.6068\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5192 - accuracy: 0.7556 - val_loss: 1.2557 - val_accuracy: 0.5983\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.5094 - accuracy: 0.7593 - val_loss: 1.2468 - val_accuracy: 0.5983\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5726 - accuracy: 0.7593 - val_loss: 1.2440 - val_accuracy: 0.5897\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5623 - accuracy: 0.7630 - val_loss: 1.2595 - val_accuracy: 0.5812\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5066 - accuracy: 0.7519 - val_loss: 1.2565 - val_accuracy: 0.6154\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.4966 - accuracy: 0.7667 - val_loss: 1.2615 - val_accuracy: 0.6068\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5040 - accuracy: 0.7593 - val_loss: 1.2557 - val_accuracy: 0.5897\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.4966 - accuracy: 0.7519 - val_loss: 1.2495 - val_accuracy: 0.5897\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5114 - accuracy: 0.7556 - val_loss: 1.2674 - val_accuracy: 0.5897\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5032 - accuracy: 0.7741 - val_loss: 1.2652 - val_accuracy: 0.6154\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5138 - accuracy: 0.7630 - val_loss: 1.2641 - val_accuracy: 0.5726\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5106 - accuracy: 0.7667 - val_loss: 1.2656 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5374 - accuracy: 0.7593 - val_loss: 1.2600 - val_accuracy: 0.5812\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5061 - accuracy: 0.7593 - val_loss: 1.2608 - val_accuracy: 0.6154\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5089 - accuracy: 0.7593 - val_loss: 1.2609 - val_accuracy: 0.5983\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5115 - accuracy: 0.7667 - val_loss: 1.2631 - val_accuracy: 0.6068\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5239 - accuracy: 0.7556 - val_loss: 1.2876 - val_accuracy: 0.5556\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5575 - accuracy: 0.7630 - val_loss: 1.3337 - val_accuracy: 0.6154\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5837 - accuracy: 0.7593 - val_loss: 1.3275 - val_accuracy: 0.5385\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6136 - accuracy: 0.7407 - val_loss: 1.4563 - val_accuracy: 0.5983\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.3188 - accuracy: 0.6963 - val_loss: 2.7277 - val_accuracy: 0.5556\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 83us/step - loss: 0.9391 - accuracy: 0.7185 - val_loss: 1.2429 - val_accuracy: 0.5641\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7174 - accuracy: 0.7556 - val_loss: 1.2967 - val_accuracy: 0.5812\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5000 - accuracy: 0.7778 - val_loss: 1.2464 - val_accuracy: 0.6239\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5068 - accuracy: 0.7704 - val_loss: 1.2209 - val_accuracy: 0.5983\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5333 - accuracy: 0.7593 - val_loss: 1.2139 - val_accuracy: 0.6154\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5020 - accuracy: 0.7593 - val_loss: 1.2161 - val_accuracy: 0.6154\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5001 - accuracy: 0.7704 - val_loss: 1.2062 - val_accuracy: 0.6239\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5000 - accuracy: 0.7556 - val_loss: 1.2099 - val_accuracy: 0.6154\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5042 - accuracy: 0.7667 - val_loss: 1.2199 - val_accuracy: 0.6239\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5111 - accuracy: 0.7593 - val_loss: 1.2210 - val_accuracy: 0.5983\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5085 - accuracy: 0.7593 - val_loss: 1.2254 - val_accuracy: 0.6068\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5022 - accuracy: 0.7630 - val_loss: 1.2250 - val_accuracy: 0.5983\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5149 - accuracy: 0.7667 - val_loss: 1.2455 - val_accuracy: 0.5983\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5028 - accuracy: 0.7519 - val_loss: 1.2433 - val_accuracy: 0.6154\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.5549 - accuracy: 0.7556 - val_loss: 1.2321 - val_accuracy: 0.5897\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5570 - accuracy: 0.7556 - val_loss: 1.2523 - val_accuracy: 0.5983\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6972 - accuracy: 0.7593 - val_loss: 1.2453 - val_accuracy: 0.5812\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5799 - accuracy: 0.7593 - val_loss: 1.2535 - val_accuracy: 0.5726\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5921 - accuracy: 0.7407 - val_loss: 1.2334 - val_accuracy: 0.6239\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6919 - accuracy: 0.7407 - val_loss: 1.2831 - val_accuracy: 0.6154\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7915 - accuracy: 0.7593 - val_loss: 1.3530 - val_accuracy: 0.6068\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6073 - accuracy: 0.7630 - val_loss: 1.3067 - val_accuracy: 0.5641\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5941 - accuracy: 0.7519 - val_loss: 1.2346 - val_accuracy: 0.6239\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5117 - accuracy: 0.7667 - val_loss: 1.2239 - val_accuracy: 0.5983\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.5331 - accuracy: 0.7630 - val_loss: 1.2008 - val_accuracy: 0.5983\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5016 - accuracy: 0.7630 - val_loss: 1.1971 - val_accuracy: 0.6239\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4943 - accuracy: 0.7630 - val_loss: 1.1998 - val_accuracy: 0.6239\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.4974 - accuracy: 0.7667 - val_loss: 1.2098 - val_accuracy: 0.5983\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.4973 - accuracy: 0.7630 - val_loss: 1.2077 - val_accuracy: 0.6068\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.5091 - accuracy: 0.7556 - val_loss: 1.2251 - val_accuracy: 0.5812\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5161 - accuracy: 0.7704 - val_loss: 1.2147 - val_accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5164 - accuracy: 0.7556 - val_loss: 1.2156 - val_accuracy: 0.6154\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.4979 - accuracy: 0.7704 - val_loss: 1.2052 - val_accuracy: 0.5983\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5029 - accuracy: 0.7704 - val_loss: 1.2221 - val_accuracy: 0.6068\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5080 - accuracy: 0.7556 - val_loss: 1.2265 - val_accuracy: 0.6154\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5072 - accuracy: 0.7519 - val_loss: 1.2189 - val_accuracy: 0.6068\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.4929 - accuracy: 0.7704 - val_loss: 1.2019 - val_accuracy: 0.6154\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5085 - accuracy: 0.7370 - val_loss: 1.2123 - val_accuracy: 0.6068\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4978 - accuracy: 0.7667 - val_loss: 1.2184 - val_accuracy: 0.5983\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5116 - accuracy: 0.7630 - val_loss: 1.2164 - val_accuracy: 0.5983\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5078 - accuracy: 0.7593 - val_loss: 1.2253 - val_accuracy: 0.5812\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5087 - accuracy: 0.7593 - val_loss: 1.2203 - val_accuracy: 0.5897\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4997 - accuracy: 0.7630 - val_loss: 1.2079 - val_accuracy: 0.6068\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5018 - accuracy: 0.7704 - val_loss: 1.2134 - val_accuracy: 0.6068\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5056 - accuracy: 0.7667 - val_loss: 1.2199 - val_accuracy: 0.5897\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5248 - accuracy: 0.7519 - val_loss: 1.2470 - val_accuracy: 0.5897\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5367 - accuracy: 0.7593 - val_loss: 1.2364 - val_accuracy: 0.6068\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5314 - accuracy: 0.7593 - val_loss: 1.2437 - val_accuracy: 0.5812\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5516 - accuracy: 0.7667 - val_loss: 1.2340 - val_accuracy: 0.6068\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5261 - accuracy: 0.7556 - val_loss: 1.2359 - val_accuracy: 0.5983\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.5077 - accuracy: 0.7593 - val_loss: 1.2613 - val_accuracy: 0.6154\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.5328 - accuracy: 0.7704 - val_loss: 1.2441 - val_accuracy: 0.5726\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5134 - accuracy: 0.7630 - val_loss: 1.2513 - val_accuracy: 0.6239\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5073 - accuracy: 0.7630 - val_loss: 1.2593 - val_accuracy: 0.5897\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.5030 - accuracy: 0.7667 - val_loss: 1.2319 - val_accuracy: 0.6068\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.5188 - accuracy: 0.7481 - val_loss: 1.2341 - val_accuracy: 0.6154\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.5031 - accuracy: 0.7519 - val_loss: 1.2353 - val_accuracy: 0.6239\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.5284 - accuracy: 0.7556 - val_loss: 1.2371 - val_accuracy: 0.5812\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.5048 - accuracy: 0.7704 - val_loss: 1.2338 - val_accuracy: 0.5983\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5008 - accuracy: 0.7667 - val_loss: 1.2376 - val_accuracy: 0.6154\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5738 - accuracy: 0.7519 - val_loss: 1.2480 - val_accuracy: 0.5726\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5914 - accuracy: 0.7519 - val_loss: 1.2503 - val_accuracy: 0.5812\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5423 - accuracy: 0.7704 - val_loss: 1.2894 - val_accuracy: 0.6154\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.5241 - accuracy: 0.7667 - val_loss: 1.2654 - val_accuracy: 0.5983\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5368 - accuracy: 0.7481 - val_loss: 1.2594 - val_accuracy: 0.5983\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.5053 - accuracy: 0.7556 - val_loss: 1.2450 - val_accuracy: 0.5983\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5006 - accuracy: 0.7593 - val_loss: 1.2460 - val_accuracy: 0.6068\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.4936 - accuracy: 0.7704 - val_loss: 1.2493 - val_accuracy: 0.6068\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 408us/step - loss: 0.4970 - accuracy: 0.7778 - val_loss: 1.2561 - val_accuracy: 0.5983\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.4929 - accuracy: 0.7667 - val_loss: 1.2501 - val_accuracy: 0.6068\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.4972 - accuracy: 0.7556 - val_loss: 1.2625 - val_accuracy: 0.5897\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5006 - accuracy: 0.7593 - val_loss: 1.2591 - val_accuracy: 0.5983\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5101 - accuracy: 0.7556 - val_loss: 1.2692 - val_accuracy: 0.5897\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.4997 - accuracy: 0.7667 - val_loss: 1.2672 - val_accuracy: 0.5897\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.4976 - accuracy: 0.7667 - val_loss: 1.2642 - val_accuracy: 0.5983\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.4975 - accuracy: 0.7741 - val_loss: 1.2594 - val_accuracy: 0.6068\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.4928 - accuracy: 0.7667 - val_loss: 1.2547 - val_accuracy: 0.6068\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.4962 - accuracy: 0.7519 - val_loss: 1.2578 - val_accuracy: 0.5983\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4963 - accuracy: 0.7593 - val_loss: 1.2576 - val_accuracy: 0.5897\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.4913 - accuracy: 0.7667 - val_loss: 1.2601 - val_accuracy: 0.6068\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.4949 - accuracy: 0.7704 - val_loss: 1.2546 - val_accuracy: 0.6154\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.4982 - accuracy: 0.7667 - val_loss: 1.2760 - val_accuracy: 0.6239\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.5097 - accuracy: 0.7593 - val_loss: 1.2801 - val_accuracy: 0.5641\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.4994 - accuracy: 0.7630 - val_loss: 1.2609 - val_accuracy: 0.5812\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5396 - accuracy: 0.7519 - val_loss: 1.2704 - val_accuracy: 0.5726\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5277 - accuracy: 0.7630 - val_loss: 1.2373 - val_accuracy: 0.6239\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5271 - accuracy: 0.7667 - val_loss: 1.2427 - val_accuracy: 0.5983\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5063 - accuracy: 0.7778 - val_loss: 1.2501 - val_accuracy: 0.6239\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.4990 - accuracy: 0.7556 - val_loss: 1.2496 - val_accuracy: 0.5897\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5057 - accuracy: 0.7593 - val_loss: 1.2589 - val_accuracy: 0.5983\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4946 - accuracy: 0.7667 - val_loss: 1.2710 - val_accuracy: 0.5812\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5092 - accuracy: 0.7704 - val_loss: 1.2440 - val_accuracy: 0.5812\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4999 - accuracy: 0.7667 - val_loss: 1.2503 - val_accuracy: 0.5897\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4964 - accuracy: 0.7593 - val_loss: 1.2552 - val_accuracy: 0.5812\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5090 - accuracy: 0.7593 - val_loss: 1.2442 - val_accuracy: 0.5556\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5071 - accuracy: 0.7593 - val_loss: 1.2448 - val_accuracy: 0.5897\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4958 - accuracy: 0.7667 - val_loss: 1.2541 - val_accuracy: 0.6239\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4973 - accuracy: 0.7704 - val_loss: 1.2642 - val_accuracy: 0.5812\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5266 - accuracy: 0.7519 - val_loss: 1.2531 - val_accuracy: 0.5897\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5110 - accuracy: 0.7593 - val_loss: 1.2548 - val_accuracy: 0.6068\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.5111 - accuracy: 0.7556 - val_loss: 1.2433 - val_accuracy: 0.5470\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5003 - accuracy: 0.7593 - val_loss: 1.2497 - val_accuracy: 0.5812\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5044 - accuracy: 0.7481 - val_loss: 1.2527 - val_accuracy: 0.5983\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4967 - accuracy: 0.7556 - val_loss: 1.2474 - val_accuracy: 0.6154\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.4987 - accuracy: 0.7481 - val_loss: 1.2485 - val_accuracy: 0.5897\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4988 - accuracy: 0.7630 - val_loss: 1.2640 - val_accuracy: 0.5897\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5170 - accuracy: 0.7444 - val_loss: 1.2540 - val_accuracy: 0.5897\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4990 - accuracy: 0.7704 - val_loss: 1.2523 - val_accuracy: 0.5983\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5031 - accuracy: 0.7481 - val_loss: 1.2490 - val_accuracy: 0.6068\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5199 - accuracy: 0.7407 - val_loss: 1.2634 - val_accuracy: 0.5897\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 147us/step - loss: 0.5026 - accuracy: 0.7593 - val_loss: 1.2489 - val_accuracy: 0.5983\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.4922 - accuracy: 0.7593 - val_loss: 1.2600 - val_accuracy: 0.6068\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5033 - accuracy: 0.7519 - val_loss: 1.2483 - val_accuracy: 0.5897\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5172 - accuracy: 0.7704 - val_loss: 1.2487 - val_accuracy: 0.5812\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5141 - accuracy: 0.7593 - val_loss: 1.2573 - val_accuracy: 0.5812\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5264 - accuracy: 0.7667 - val_loss: 1.2653 - val_accuracy: 0.5812\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5178 - accuracy: 0.7556 - val_loss: 1.2638 - val_accuracy: 0.6068\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5114 - accuracy: 0.7556 - val_loss: 1.2445 - val_accuracy: 0.6154\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5086 - accuracy: 0.7593 - val_loss: 1.2586 - val_accuracy: 0.5812\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.4984 - accuracy: 0.7667 - val_loss: 1.2527 - val_accuracy: 0.5897\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5190 - accuracy: 0.7444 - val_loss: 1.2595 - val_accuracy: 0.6068\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5233 - accuracy: 0.7630 - val_loss: 1.2898 - val_accuracy: 0.6239\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.5202 - accuracy: 0.7630 - val_loss: 1.2582 - val_accuracy: 0.5726\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.5163 - accuracy: 0.7630 - val_loss: 1.2436 - val_accuracy: 0.5983\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5036 - accuracy: 0.7593 - val_loss: 1.2526 - val_accuracy: 0.6154\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4981 - accuracy: 0.7630 - val_loss: 1.2462 - val_accuracy: 0.5983\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5053 - accuracy: 0.7593 - val_loss: 1.2487 - val_accuracy: 0.5983\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.4940 - accuracy: 0.7741 - val_loss: 1.2535 - val_accuracy: 0.5897\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5025 - accuracy: 0.7667 - val_loss: 1.2496 - val_accuracy: 0.5983\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5376 - accuracy: 0.7593 - val_loss: 1.3090 - val_accuracy: 0.5556\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5822 - accuracy: 0.7519 - val_loss: 1.3940 - val_accuracy: 0.6154\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5890 - accuracy: 0.7519 - val_loss: 1.2736 - val_accuracy: 0.5641\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5556 - accuracy: 0.7519 - val_loss: 1.2486 - val_accuracy: 0.6068\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5513 - accuracy: 0.7407 - val_loss: 1.2320 - val_accuracy: 0.5983\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5176 - accuracy: 0.7593 - val_loss: 1.2421 - val_accuracy: 0.5726\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5867 - accuracy: 0.7519 - val_loss: 1.4542 - val_accuracy: 0.6068\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0099 - accuracy: 0.7519 - val_loss: 1.3502 - val_accuracy: 0.5897\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5940 - accuracy: 0.7481 - val_loss: 1.3207 - val_accuracy: 0.5556\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5516 - accuracy: 0.7593 - val_loss: 1.3377 - val_accuracy: 0.6068\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5811 - accuracy: 0.7556 - val_loss: 1.2862 - val_accuracy: 0.5641\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6392 - accuracy: 0.7481 - val_loss: 1.2510 - val_accuracy: 0.6154\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5570 - accuracy: 0.7481 - val_loss: 1.2640 - val_accuracy: 0.5812\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5627 - accuracy: 0.7630 - val_loss: 1.2598 - val_accuracy: 0.6154\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6087 - accuracy: 0.7593 - val_loss: 1.2204 - val_accuracy: 0.5726\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5333 - accuracy: 0.7667 - val_loss: 1.2314 - val_accuracy: 0.5983\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5242 - accuracy: 0.7333 - val_loss: 1.2262 - val_accuracy: 0.6154\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.5086 - accuracy: 0.7667 - val_loss: 1.2453 - val_accuracy: 0.6154\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.5233 - accuracy: 0.7593 - val_loss: 1.2229 - val_accuracy: 0.5812\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.5442 - accuracy: 0.7630 - val_loss: 1.2323 - val_accuracy: 0.5726\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5279 - accuracy: 0.7593 - val_loss: 1.2132 - val_accuracy: 0.5897\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5235 - accuracy: 0.7704 - val_loss: 1.2177 - val_accuracy: 0.6068\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5181 - accuracy: 0.7481 - val_loss: 1.2260 - val_accuracy: 0.5983\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4985 - accuracy: 0.7593 - val_loss: 1.2152 - val_accuracy: 0.6239\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4977 - accuracy: 0.7741 - val_loss: 1.2392 - val_accuracy: 0.5726\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5302 - accuracy: 0.7667 - val_loss: 1.2069 - val_accuracy: 0.5983\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.5106 - accuracy: 0.7481 - val_loss: 1.2284 - val_accuracy: 0.5897\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.5105 - accuracy: 0.7630 - val_loss: 1.2135 - val_accuracy: 0.5983\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5542 - accuracy: 0.7556 - val_loss: 1.2186 - val_accuracy: 0.5983\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5788 - accuracy: 0.7630 - val_loss: 1.2304 - val_accuracy: 0.5983\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5198 - accuracy: 0.7630 - val_loss: 1.2229 - val_accuracy: 0.5897\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5102 - accuracy: 0.7630 - val_loss: 1.2456 - val_accuracy: 0.6154\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4991 - accuracy: 0.7593 - val_loss: 1.2561 - val_accuracy: 0.5726\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5434 - accuracy: 0.7481 - val_loss: 1.2124 - val_accuracy: 0.5983\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5287 - accuracy: 0.7630 - val_loss: 1.2147 - val_accuracy: 0.5812\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5567 - accuracy: 0.7593 - val_loss: 1.2361 - val_accuracy: 0.6068\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5056 - accuracy: 0.7593 - val_loss: 1.2202 - val_accuracy: 0.6325\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.4982 - accuracy: 0.7630 - val_loss: 1.2210 - val_accuracy: 0.5983\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5035 - accuracy: 0.7704 - val_loss: 1.2369 - val_accuracy: 0.5726\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5477 - accuracy: 0.7704 - val_loss: 1.2288 - val_accuracy: 0.5726\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5063 - accuracy: 0.7630 - val_loss: 1.2107 - val_accuracy: 0.6239\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5016 - accuracy: 0.7519 - val_loss: 1.2248 - val_accuracy: 0.5897\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4988 - accuracy: 0.7630 - val_loss: 1.2263 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4975 - accuracy: 0.7667 - val_loss: 1.2256 - val_accuracy: 0.5983\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5014 - accuracy: 0.7667 - val_loss: 1.2246 - val_accuracy: 0.5812\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4980 - accuracy: 0.7667 - val_loss: 1.2343 - val_accuracy: 0.5983\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5190 - accuracy: 0.7667 - val_loss: 1.2362 - val_accuracy: 0.6068\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5264 - accuracy: 0.7593 - val_loss: 1.2365 - val_accuracy: 0.6068\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5167 - accuracy: 0.7667 - val_loss: 1.2405 - val_accuracy: 0.5983\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5034 - accuracy: 0.7704 - val_loss: 1.2247 - val_accuracy: 0.5983\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4949 - accuracy: 0.7630 - val_loss: 1.2416 - val_accuracy: 0.5897\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5019 - accuracy: 0.7593 - val_loss: 1.2434 - val_accuracy: 0.6239\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5087 - accuracy: 0.7778 - val_loss: 1.2300 - val_accuracy: 0.5983\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5212 - accuracy: 0.7630 - val_loss: 1.2617 - val_accuracy: 0.6068\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5496 - accuracy: 0.7630 - val_loss: 1.2824 - val_accuracy: 0.5726\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5009 - accuracy: 0.7556 - val_loss: 1.2638 - val_accuracy: 0.6154\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5339 - accuracy: 0.7407 - val_loss: 1.2433 - val_accuracy: 0.6068\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5011 - accuracy: 0.7667 - val_loss: 1.2300 - val_accuracy: 0.5897\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5129 - accuracy: 0.7667 - val_loss: 1.2422 - val_accuracy: 0.6154\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5043 - accuracy: 0.7778 - val_loss: 1.2298 - val_accuracy: 0.5983\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.5004 - accuracy: 0.7593 - val_loss: 1.2406 - val_accuracy: 0.5812\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.4986 - accuracy: 0.7556 - val_loss: 1.2404 - val_accuracy: 0.5897\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.4985 - accuracy: 0.7667 - val_loss: 1.2478 - val_accuracy: 0.5726\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 282us/step - loss: 0.5124 - accuracy: 0.7556 - val_loss: 1.2464 - val_accuracy: 0.5897\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.5070 - accuracy: 0.7593 - val_loss: 1.2426 - val_accuracy: 0.5641\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 351us/step - loss: 0.5050 - accuracy: 0.7630 - val_loss: 1.2332 - val_accuracy: 0.5812\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.5114 - accuracy: 0.7556 - val_loss: 1.2301 - val_accuracy: 0.5897\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5210 - accuracy: 0.7556 - val_loss: 1.2372 - val_accuracy: 0.5897\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5120 - accuracy: 0.7593 - val_loss: 1.2275 - val_accuracy: 0.5983\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4969 - accuracy: 0.7741 - val_loss: 1.2419 - val_accuracy: 0.5812\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4955 - accuracy: 0.7741 - val_loss: 1.2358 - val_accuracy: 0.6154\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4987 - accuracy: 0.7741 - val_loss: 1.2597 - val_accuracy: 0.5812\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5212 - accuracy: 0.7704 - val_loss: 1.2518 - val_accuracy: 0.5726\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5170 - accuracy: 0.7481 - val_loss: 1.2427 - val_accuracy: 0.5641\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5155 - accuracy: 0.7630 - val_loss: 1.2271 - val_accuracy: 0.6068\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5066 - accuracy: 0.7630 - val_loss: 1.2516 - val_accuracy: 0.5726\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5531 - accuracy: 0.7630 - val_loss: 1.2547 - val_accuracy: 0.5726\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5047 - accuracy: 0.7630 - val_loss: 1.2320 - val_accuracy: 0.6154\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.4972 - accuracy: 0.7667 - val_loss: 1.2307 - val_accuracy: 0.6068\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.4997 - accuracy: 0.7481 - val_loss: 1.2409 - val_accuracy: 0.5897\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5071 - accuracy: 0.7333 - val_loss: 1.2504 - val_accuracy: 0.5726\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.5262 - accuracy: 0.7704 - val_loss: 1.2559 - val_accuracy: 0.5726\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.5035 - accuracy: 0.7704 - val_loss: 1.2380 - val_accuracy: 0.6154\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5003 - accuracy: 0.7630 - val_loss: 1.2499 - val_accuracy: 0.5983\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.5125 - accuracy: 0.7593 - val_loss: 1.2206 - val_accuracy: 0.6068\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5022 - accuracy: 0.7630 - val_loss: 1.2204 - val_accuracy: 0.5812\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5035 - accuracy: 0.7704 - val_loss: 1.2306 - val_accuracy: 0.5897\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5046 - accuracy: 0.7667 - val_loss: 1.2218 - val_accuracy: 0.5812\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5152 - accuracy: 0.7704 - val_loss: 1.2357 - val_accuracy: 0.6068\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4978 - accuracy: 0.7630 - val_loss: 1.2379 - val_accuracy: 0.5726\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5048 - accuracy: 0.7704 - val_loss: 1.2183 - val_accuracy: 0.6239\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 115us/step - loss: 0.5011 - accuracy: 0.7667 - val_loss: 1.2222 - val_accuracy: 0.6068\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5024 - accuracy: 0.7667 - val_loss: 1.2146 - val_accuracy: 0.5897\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5038 - accuracy: 0.7667 - val_loss: 1.2274 - val_accuracy: 0.6068\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5108 - accuracy: 0.7444 - val_loss: 1.2241 - val_accuracy: 0.5983\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.5029 - accuracy: 0.7667 - val_loss: 1.2309 - val_accuracy: 0.5897\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5050 - accuracy: 0.7593 - val_loss: 1.2258 - val_accuracy: 0.6239\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.5001 - accuracy: 0.7481 - val_loss: 1.2337 - val_accuracy: 0.5983\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.62%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34786560e-01, 5.81355750e-01, 2.83857700e-01],\n",
       "       [4.91629700e-01, 4.97916130e-01, 1.04541680e-02],\n",
       "       [3.24921550e-01, 5.94283340e-01, 8.07951700e-02],\n",
       "       [7.58227100e-01, 1.69591040e-01, 7.21818060e-02],\n",
       "       [3.88507400e-01, 6.02945570e-01, 8.54699600e-03],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [9.79144400e-01, 2.08521080e-02, 3.45880040e-06],\n",
       "       [7.65052900e-03, 3.59286110e-03, 9.88756600e-01],\n",
       "       [1.59875780e-04, 1.27847340e-04, 9.99712300e-01],\n",
       "       [1.81753820e-05, 4.53804530e-04, 9.99528050e-01],\n",
       "       [6.74196960e-01, 3.22848980e-01, 2.95411380e-03],\n",
       "       [1.34261770e-05, 7.67990600e-05, 9.99909760e-01],\n",
       "       [8.47269800e-02, 6.71719500e-01, 2.43553490e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [3.88507400e-01, 6.02945570e-01, 8.54699600e-03],\n",
       "       [1.08321466e-01, 3.19265630e-01, 5.72412850e-01],\n",
       "       [1.19599120e-01, 2.91120200e-04, 8.80109800e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.10355760e-04, 4.99324600e-04, 9.98790300e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.19518000e-01, 2.80079400e-01, 4.02542380e-04],\n",
       "       [7.43131700e-01, 2.23642870e-01, 3.32254470e-02],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [9.94789500e-01, 5.20087600e-03, 9.59681800e-06],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [6.42949700e-01, 9.87264400e-02, 2.58323880e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.81753820e-05, 4.53804530e-04, 9.99528050e-01],\n",
       "       [7.65052900e-03, 3.59286110e-03, 9.88756600e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [8.82509800e-02, 1.98333620e-01, 7.13415400e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [4.85438530e-01, 4.11709130e-01, 1.02852310e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [3.86836240e-03, 2.74763900e-06, 9.96128900e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [3.88507400e-01, 6.02945570e-01, 8.54699600e-03],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.06120130e-01, 2.92254240e-01, 1.62565140e-03],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [8.47269800e-02, 6.71719500e-01, 2.43553490e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [3.27343230e-02, 6.92020900e-02, 8.98063600e-01],\n",
       "       [7.72398900e-01, 2.27600980e-01, 9.47710600e-08],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [9.92602900e-01, 2.72390710e-03, 4.67322440e-03],\n",
       "       [1.34261770e-05, 7.67990600e-05, 9.99909760e-01],\n",
       "       [3.01524340e-01, 2.30615100e-01, 4.67860600e-01],\n",
       "       [7.72398900e-01, 2.27600980e-01, 9.47710600e-08],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.72398900e-01, 2.27600980e-01, 9.47710600e-08],\n",
       "       [7.17717630e-04, 3.90936700e-03, 9.95372950e-01],\n",
       "       [1.91623530e-05, 1.42676780e-04, 9.99838100e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.00933366e-01, 1.58095340e-01, 7.40971300e-01],\n",
       "       [8.47269800e-02, 6.71719500e-01, 2.43553490e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [4.73105100e-01, 4.90159030e-01, 3.67358700e-02],\n",
       "       [1.72664420e-03, 6.17122650e-03, 9.92102100e-01],\n",
       "       [3.88507400e-01, 6.02945570e-01, 8.54699600e-03],\n",
       "       [8.82509800e-02, 1.98333620e-01, 7.13415400e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [5.22645900e-01, 4.71767660e-01, 5.58650960e-03],\n",
       "       [4.68586400e-01, 4.22753190e-01, 1.08660460e-01],\n",
       "       [6.25625700e-03, 4.06718630e-03, 9.89676540e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [4.01405340e-03, 7.32741000e-03, 9.88658600e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [1.81753820e-05, 4.53804530e-04, 9.99528050e-01],\n",
       "       [2.50572040e-02, 4.63942200e-02, 9.28548600e-01],\n",
       "       [7.43342640e-01, 7.20994400e-02, 1.84557910e-01],\n",
       "       [2.56751500e-01, 7.38729950e-01, 4.51856340e-03],\n",
       "       [7.19518000e-01, 2.80079400e-01, 4.02542380e-04],\n",
       "       [7.58227100e-01, 1.69591040e-01, 7.21818060e-02],\n",
       "       [4.75732200e-01, 5.24267140e-01, 6.08881100e-07],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.08321466e-01, 3.19265630e-01, 5.72412850e-01],\n",
       "       [7.10355760e-04, 4.99324600e-04, 9.98790300e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [4.75732200e-01, 5.24267140e-01, 6.08881100e-07],\n",
       "       [1.00933366e-01, 1.58095340e-01, 7.40971300e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.19518000e-01, 2.80079400e-01, 4.02542380e-04],\n",
       "       [6.74196960e-01, 3.22848980e-01, 2.95411380e-03],\n",
       "       [1.00933366e-01, 1.58095340e-01, 7.40971300e-01],\n",
       "       [3.24921550e-01, 5.94283340e-01, 8.07951700e-02],\n",
       "       [8.47269800e-02, 6.71719500e-01, 2.43553490e-01],\n",
       "       [7.72398900e-01, 2.27600980e-01, 9.47710600e-08],\n",
       "       [1.34261770e-05, 7.67990600e-05, 9.99909760e-01],\n",
       "       [3.88507400e-01, 6.02945570e-01, 8.54699600e-03],\n",
       "       [9.41394700e-02, 4.70469000e-01, 4.35391550e-01],\n",
       "       [1.00933366e-01, 1.58095340e-01, 7.40971300e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [7.72398900e-01, 2.27600980e-01, 9.47710600e-08],\n",
       "       [2.98862960e-02, 5.71892080e-02, 9.12924500e-01],\n",
       "       [4.91629700e-01, 4.97916130e-01, 1.04541680e-02],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.59875780e-04, 1.27847340e-04, 9.99712300e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [7.19518000e-01, 2.80079400e-01, 4.02542380e-04],\n",
       "       [1.34261770e-05, 7.67990600e-05, 9.99909760e-01],\n",
       "       [2.50572040e-02, 4.63942200e-02, 9.28548600e-01],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.08321466e-01, 3.19265630e-01, 5.72412850e-01],\n",
       "       [7.19518000e-01, 2.80079400e-01, 4.02542380e-04],\n",
       "       [4.51219260e-01, 4.50653700e-01, 9.81270750e-02],\n",
       "       [2.50572040e-02, 4.63942200e-02, 9.28548600e-01],\n",
       "       [5.30568440e-02, 1.61249340e-01, 7.85693800e-01],\n",
       "       [6.36068000e-01, 3.60300450e-01, 3.63160830e-03],\n",
       "       [2.48717840e-01, 6.19990350e-01, 1.31291820e-01],\n",
       "       [1.00933366e-01, 1.58095340e-01, 7.40971300e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594784133245671"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594784133245671"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0    BCH-SA-11     2\n",
       "1       NRS161     1\n",
       "2    BCH-SA-14     2\n",
       "3    BCH-SA-11     2\n",
       "4     CFBRSa49     1\n",
       "..         ...   ...\n",
       "112     NRS064     2\n",
       "113     NRS266     2\n",
       "114     NRS222     0\n",
       "115       GA27     2\n",
       "116      GA984     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 480us/step - loss: 4.3294 - accuracy: 0.3148 - val_loss: 4.5637 - val_accuracy: 0.3077\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 3.0343 - accuracy: 0.3444 - val_loss: 2.0698 - val_accuracy: 0.3590\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 2.0185 - accuracy: 0.3333 - val_loss: 1.9301 - val_accuracy: 0.3590\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.9052 - accuracy: 0.3370 - val_loss: 2.2624 - val_accuracy: 0.3590\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.6080 - accuracy: 0.3778 - val_loss: 1.7821 - val_accuracy: 0.3761\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 2.2293 - accuracy: 0.3704 - val_loss: 1.6243 - val_accuracy: 0.4103\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.5061 - accuracy: 0.3852 - val_loss: 1.8551 - val_accuracy: 0.4017\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.5506 - accuracy: 0.4000 - val_loss: 1.5340 - val_accuracy: 0.3932\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.3467 - accuracy: 0.4185 - val_loss: 1.4595 - val_accuracy: 0.4274\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.3941 - accuracy: 0.3926 - val_loss: 1.6664 - val_accuracy: 0.4103\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.4525 - accuracy: 0.3852 - val_loss: 1.4337 - val_accuracy: 0.3761\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.2861 - accuracy: 0.4000 - val_loss: 1.4130 - val_accuracy: 0.4017\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.2897 - accuracy: 0.4148 - val_loss: 1.4050 - val_accuracy: 0.3846\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.4302 - accuracy: 0.4222 - val_loss: 1.4433 - val_accuracy: 0.4188\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.2491 - accuracy: 0.4148 - val_loss: 1.1727 - val_accuracy: 0.4188\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.2265 - accuracy: 0.4593 - val_loss: 1.2690 - val_accuracy: 0.4359\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.1682 - accuracy: 0.4667 - val_loss: 1.2790 - val_accuracy: 0.4786\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 1.2285 - accuracy: 0.4889 - val_loss: 1.2331 - val_accuracy: 0.4274\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1725 - accuracy: 0.4593 - val_loss: 1.1122 - val_accuracy: 0.4701\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.1705 - accuracy: 0.4963 - val_loss: 1.3705 - val_accuracy: 0.4530\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.2680 - accuracy: 0.4926 - val_loss: 1.2088 - val_accuracy: 0.5385\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 1.1061 - accuracy: 0.5111 - val_loss: 1.1379 - val_accuracy: 0.4957\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.1361 - accuracy: 0.5111 - val_loss: 1.0866 - val_accuracy: 0.5128\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.0825 - accuracy: 0.5259 - val_loss: 1.0629 - val_accuracy: 0.5385\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.2331 - accuracy: 0.5481 - val_loss: 1.1724 - val_accuracy: 0.5556\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.1166 - accuracy: 0.5519 - val_loss: 1.1592 - val_accuracy: 0.5812\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0655 - accuracy: 0.5741 - val_loss: 1.0662 - val_accuracy: 0.5299\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0871 - accuracy: 0.5407 - val_loss: 1.4035 - val_accuracy: 0.5299\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.2176 - accuracy: 0.5407 - val_loss: 1.3715 - val_accuracy: 0.5641\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.1983 - accuracy: 0.5481 - val_loss: 1.1210 - val_accuracy: 0.5043\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.1540 - accuracy: 0.4963 - val_loss: 1.3065 - val_accuracy: 0.5470\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.2200 - accuracy: 0.5593 - val_loss: 1.3572 - val_accuracy: 0.5556\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 1.3239 - accuracy: 0.5111 - val_loss: 1.4701 - val_accuracy: 0.4957\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.3536 - accuracy: 0.4926 - val_loss: 1.3964 - val_accuracy: 0.4957\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 1.1787 - accuracy: 0.5074 - val_loss: 1.1263 - val_accuracy: 0.6239\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.2057 - accuracy: 0.5148 - val_loss: 1.0758 - val_accuracy: 0.5812\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.1357 - accuracy: 0.5519 - val_loss: 1.2908 - val_accuracy: 0.5641\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 1.3996 - accuracy: 0.5481 - val_loss: 1.7144 - val_accuracy: 0.5812\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.4381 - accuracy: 0.5481 - val_loss: 1.6575 - val_accuracy: 0.5983\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.3981 - accuracy: 0.5296 - val_loss: 1.2738 - val_accuracy: 0.5556\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.1685 - accuracy: 0.4630 - val_loss: 1.0673 - val_accuracy: 0.4615\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.1198 - accuracy: 0.4852 - val_loss: 1.1562 - val_accuracy: 0.5726\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0547 - accuracy: 0.5407 - val_loss: 0.9578 - val_accuracy: 0.5983\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0232 - accuracy: 0.5444 - val_loss: 1.1730 - val_accuracy: 0.5641\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0816 - accuracy: 0.5407 - val_loss: 1.1097 - val_accuracy: 0.5812\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0283 - accuracy: 0.5333 - val_loss: 1.0860 - val_accuracy: 0.5299\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 392us/step - loss: 1.1082 - accuracy: 0.5333 - val_loss: 1.2027 - val_accuracy: 0.5470\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0653 - accuracy: 0.4963 - val_loss: 0.9655 - val_accuracy: 0.5043\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0704 - accuracy: 0.5148 - val_loss: 1.4186 - val_accuracy: 0.5897\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.2425 - accuracy: 0.5556 - val_loss: 1.1021 - val_accuracy: 0.5641\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0372 - accuracy: 0.5704 - val_loss: 1.2084 - val_accuracy: 0.5897\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1122 - accuracy: 0.5593 - val_loss: 1.0174 - val_accuracy: 0.5641\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0307 - accuracy: 0.5407 - val_loss: 0.9655 - val_accuracy: 0.5641\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9819 - accuracy: 0.5370 - val_loss: 0.9369 - val_accuracy: 0.6154\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0161 - accuracy: 0.5481 - val_loss: 1.2845 - val_accuracy: 0.5726\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.1206 - accuracy: 0.5296 - val_loss: 0.9531 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9802 - accuracy: 0.5370 - val_loss: 0.9441 - val_accuracy: 0.5385\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1004 - accuracy: 0.5259 - val_loss: 1.2760 - val_accuracy: 0.5897\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 1.0918 - accuracy: 0.5593 - val_loss: 0.9482 - val_accuracy: 0.6239\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.1067 - accuracy: 0.5704 - val_loss: 1.3662 - val_accuracy: 0.6068\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 1.3313 - accuracy: 0.5778 - val_loss: 1.3574 - val_accuracy: 0.5641\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 1.3269 - accuracy: 0.5593 - val_loss: 1.3284 - val_accuracy: 0.6154\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.6934 - accuracy: 0.5593 - val_loss: 2.3621 - val_accuracy: 0.5897\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.7861 - accuracy: 0.5667 - val_loss: 2.1071 - val_accuracy: 0.5983\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.5809 - accuracy: 0.5296 - val_loss: 1.5000 - val_accuracy: 0.5043\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.1574 - accuracy: 0.4630 - val_loss: 1.2162 - val_accuracy: 0.4188\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.3279 - accuracy: 0.4333 - val_loss: 1.2534 - val_accuracy: 0.5983\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.1272 - accuracy: 0.5407 - val_loss: 1.3101 - val_accuracy: 0.6154\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0590 - accuracy: 0.5296 - val_loss: 1.0091 - val_accuracy: 0.5726\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.1013 - accuracy: 0.5370 - val_loss: 1.0685 - val_accuracy: 0.5726\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.3306 - accuracy: 0.5296 - val_loss: 1.1161 - val_accuracy: 0.6410\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1065 - accuracy: 0.5519 - val_loss: 1.3551 - val_accuracy: 0.6154\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.1452 - accuracy: 0.5519 - val_loss: 1.0528 - val_accuracy: 0.6496\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9949 - accuracy: 0.5556 - val_loss: 0.9511 - val_accuracy: 0.5897\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.0110 - accuracy: 0.5556 - val_loss: 1.0522 - val_accuracy: 0.6496\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 1.0092 - accuracy: 0.5481 - val_loss: 1.0055 - val_accuracy: 0.5556\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.1734 - accuracy: 0.5815 - val_loss: 1.4522 - val_accuracy: 0.4786\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.3687 - accuracy: 0.5333 - val_loss: 1.3160 - val_accuracy: 0.5641\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.1505 - accuracy: 0.5667 - val_loss: 0.9865 - val_accuracy: 0.6154\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.0552 - accuracy: 0.5630 - val_loss: 1.0930 - val_accuracy: 0.6410\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0181 - accuracy: 0.5815 - val_loss: 0.9394 - val_accuracy: 0.5812\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0736 - accuracy: 0.5667 - val_loss: 0.9663 - val_accuracy: 0.5897\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.0060 - accuracy: 0.5444 - val_loss: 0.9848 - val_accuracy: 0.6496\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0527 - accuracy: 0.5519 - val_loss: 1.0789 - val_accuracy: 0.5983\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.9763 - accuracy: 0.5593 - val_loss: 0.9484 - val_accuracy: 0.6239\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.1037 - accuracy: 0.5444 - val_loss: 1.1374 - val_accuracy: 0.5983\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 1.0888 - accuracy: 0.5370 - val_loss: 1.0401 - val_accuracy: 0.6154\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.0073 - accuracy: 0.5519 - val_loss: 1.0618 - val_accuracy: 0.6410\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 1.2887 - accuracy: 0.5593 - val_loss: 2.0263 - val_accuracy: 0.6154\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 340us/step - loss: 1.4957 - accuracy: 0.5741 - val_loss: 1.4137 - val_accuracy: 0.6154\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.1666 - accuracy: 0.5296 - val_loss: 1.0462 - val_accuracy: 0.5043\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.2417 - accuracy: 0.4963 - val_loss: 1.4149 - val_accuracy: 0.5043\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.2648 - accuracy: 0.5667 - val_loss: 1.1689 - val_accuracy: 0.5726\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0252 - accuracy: 0.5815 - val_loss: 1.0547 - val_accuracy: 0.6068\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.2067 - accuracy: 0.5593 - val_loss: 1.1597 - val_accuracy: 0.5983\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.0768 - accuracy: 0.5704 - val_loss: 1.0055 - val_accuracy: 0.5812\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.1663 - accuracy: 0.5593 - val_loss: 1.1940 - val_accuracy: 0.6581\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.2474 - accuracy: 0.5704 - val_loss: 1.4310 - val_accuracy: 0.6496\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.1404 - accuracy: 0.5704 - val_loss: 0.9379 - val_accuracy: 0.5812\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9964 - accuracy: 0.4963 - val_loss: 1.0401 - val_accuracy: 0.5983\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.0160 - accuracy: 0.5741 - val_loss: 0.9789 - val_accuracy: 0.6410\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9450 - accuracy: 0.5963 - val_loss: 0.9106 - val_accuracy: 0.6068\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9396 - accuracy: 0.5926 - val_loss: 0.9369 - val_accuracy: 0.6154\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9328 - accuracy: 0.5926 - val_loss: 0.9187 - val_accuracy: 0.6325\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.0337 - accuracy: 0.5667 - val_loss: 1.3183 - val_accuracy: 0.6154\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.2268 - accuracy: 0.5926 - val_loss: 1.2502 - val_accuracy: 0.6068\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.0327 - accuracy: 0.5852 - val_loss: 0.9143 - val_accuracy: 0.6154\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9646 - accuracy: 0.5889 - val_loss: 0.9576 - val_accuracy: 0.6239\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9585 - accuracy: 0.6037 - val_loss: 0.9015 - val_accuracy: 0.6154\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0342 - accuracy: 0.5704 - val_loss: 1.0274 - val_accuracy: 0.6496\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9987 - accuracy: 0.5963 - val_loss: 0.9071 - val_accuracy: 0.6239\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0065 - accuracy: 0.5815 - val_loss: 0.9474 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9274 - accuracy: 0.6185 - val_loss: 0.9003 - val_accuracy: 0.6154\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9464 - accuracy: 0.6000 - val_loss: 1.0817 - val_accuracy: 0.6496\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0565 - accuracy: 0.5852 - val_loss: 1.1267 - val_accuracy: 0.6239\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9718 - accuracy: 0.5963 - val_loss: 0.9276 - val_accuracy: 0.6068\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0020 - accuracy: 0.5815 - val_loss: 1.1635 - val_accuracy: 0.6325\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0556 - accuracy: 0.5889 - val_loss: 1.0026 - val_accuracy: 0.6496\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9580 - accuracy: 0.6037 - val_loss: 0.9294 - val_accuracy: 0.5983\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9609 - accuracy: 0.6000 - val_loss: 1.0086 - val_accuracy: 0.6496\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9777 - accuracy: 0.5741 - val_loss: 0.9842 - val_accuracy: 0.6325\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9980 - accuracy: 0.6111 - val_loss: 0.9576 - val_accuracy: 0.5726\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9665 - accuracy: 0.5926 - val_loss: 0.9266 - val_accuracy: 0.6154\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9698 - accuracy: 0.5963 - val_loss: 1.3480 - val_accuracy: 0.6068\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.2288 - accuracy: 0.6000 - val_loss: 1.2302 - val_accuracy: 0.5812\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.6949 - accuracy: 0.43 - 0s 133us/step - loss: 1.1974 - accuracy: 0.5593 - val_loss: 1.2701 - val_accuracy: 0.6154\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.1663 - accuracy: 0.5926 - val_loss: 1.5089 - val_accuracy: 0.6239\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.2559 - accuracy: 0.5778 - val_loss: 1.1555 - val_accuracy: 0.6581\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0509 - accuracy: 0.5963 - val_loss: 1.0002 - val_accuracy: 0.6239\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.1951 - accuracy: 0.5926 - val_loss: 1.5610 - val_accuracy: 0.6410\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.2200 - accuracy: 0.5815 - val_loss: 1.2377 - val_accuracy: 0.5983\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0658 - accuracy: 0.5519 - val_loss: 1.0783 - val_accuracy: 0.5897\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1847 - accuracy: 0.5741 - val_loss: 1.2736 - val_accuracy: 0.5641\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1739 - accuracy: 0.6111 - val_loss: 1.0803 - val_accuracy: 0.4957\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9850 - accuracy: 0.5481 - val_loss: 1.0716 - val_accuracy: 0.5043\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0558 - accuracy: 0.5148 - val_loss: 0.9607 - val_accuracy: 0.5128\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0348 - accuracy: 0.6111 - val_loss: 1.1642 - val_accuracy: 0.5897\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.1430 - accuracy: 0.6037 - val_loss: 1.0126 - val_accuracy: 0.6154\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9320 - accuracy: 0.6037 - val_loss: 0.9270 - val_accuracy: 0.6325\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0168 - accuracy: 0.5926 - val_loss: 1.3310 - val_accuracy: 0.6068\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.3440 - accuracy: 0.5815 - val_loss: 1.3470 - val_accuracy: 0.6239\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0215 - accuracy: 0.5778 - val_loss: 1.0004 - val_accuracy: 0.5726\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0610 - accuracy: 0.5481 - val_loss: 1.2747 - val_accuracy: 0.6325\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0768 - accuracy: 0.5519 - val_loss: 0.9989 - val_accuracy: 0.6068\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9925 - accuracy: 0.5296 - val_loss: 0.8949 - val_accuracy: 0.6410\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9263 - accuracy: 0.6037 - val_loss: 0.9859 - val_accuracy: 0.6496\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9268 - accuracy: 0.5778 - val_loss: 0.8945 - val_accuracy: 0.5385\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9297 - accuracy: 0.5593 - val_loss: 0.9700 - val_accuracy: 0.6581\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9664 - accuracy: 0.6000 - val_loss: 0.9442 - val_accuracy: 0.6325\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0037 - accuracy: 0.5963 - val_loss: 1.1056 - val_accuracy: 0.6581\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9756 - accuracy: 0.6111 - val_loss: 0.8894 - val_accuracy: 0.6154\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9273 - accuracy: 0.6037 - val_loss: 0.9344 - val_accuracy: 0.6410\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9410 - accuracy: 0.6148 - val_loss: 0.9190 - val_accuracy: 0.6410\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9038 - accuracy: 0.6222 - val_loss: 0.8922 - val_accuracy: 0.6239\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9242 - accuracy: 0.5815 - val_loss: 0.9071 - val_accuracy: 0.6496\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9151 - accuracy: 0.6370 - val_loss: 0.9812 - val_accuracy: 0.5726\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9868 - accuracy: 0.5556 - val_loss: 0.9634 - val_accuracy: 0.6581\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9223 - accuracy: 0.5963 - val_loss: 0.9014 - val_accuracy: 0.6239\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9380 - accuracy: 0.6259 - val_loss: 0.9688 - val_accuracy: 0.5812\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9577 - accuracy: 0.6148 - val_loss: 0.9203 - val_accuracy: 0.6581\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9180 - accuracy: 0.5741 - val_loss: 1.1599 - val_accuracy: 0.6239\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0184 - accuracy: 0.6037 - val_loss: 0.9127 - val_accuracy: 0.5983\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.0001 - accuracy: 0.5926 - val_loss: 1.1556 - val_accuracy: 0.6239\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.0592 - accuracy: 0.5852 - val_loss: 1.0659 - val_accuracy: 0.6581\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9469 - accuracy: 0.6259 - val_loss: 0.9693 - val_accuracy: 0.6068\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.1418 - accuracy: 0.6185 - val_loss: 1.1246 - val_accuracy: 0.6496\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9489 - accuracy: 0.6074 - val_loss: 0.9583 - val_accuracy: 0.5897\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.1303 - accuracy: 0.5778 - val_loss: 1.4637 - val_accuracy: 0.6239\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.3000 - accuracy: 0.6000 - val_loss: 1.3213 - val_accuracy: 0.6581\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0764 - accuracy: 0.5926 - val_loss: 0.9228 - val_accuracy: 0.5983\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9784 - accuracy: 0.5852 - val_loss: 0.9349 - val_accuracy: 0.5726\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9297 - accuracy: 0.6000 - val_loss: 0.9446 - val_accuracy: 0.6325\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9384 - accuracy: 0.6074 - val_loss: 0.9212 - val_accuracy: 0.5214\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9349 - accuracy: 0.5407 - val_loss: 1.1060 - val_accuracy: 0.5726\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1270 - accuracy: 0.5444 - val_loss: 1.3214 - val_accuracy: 0.5214\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0381 - accuracy: 0.5852 - val_loss: 0.8823 - val_accuracy: 0.6239\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0411 - accuracy: 0.6037 - val_loss: 1.1171 - val_accuracy: 0.6410\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0300 - accuracy: 0.6222 - val_loss: 1.1461 - val_accuracy: 0.6410\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9845 - accuracy: 0.5926 - val_loss: 0.8964 - val_accuracy: 0.6068\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9351 - accuracy: 0.6185 - val_loss: 0.9434 - val_accuracy: 0.6239\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9536 - accuracy: 0.6148 - val_loss: 1.0226 - val_accuracy: 0.6239\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9292 - accuracy: 0.5815 - val_loss: 0.9550 - val_accuracy: 0.5812\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9670 - accuracy: 0.6074 - val_loss: 0.9292 - val_accuracy: 0.5897\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9213 - accuracy: 0.6148 - val_loss: 1.0261 - val_accuracy: 0.5983\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9427 - accuracy: 0.5963 - val_loss: 1.0302 - val_accuracy: 0.6068\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9976 - accuracy: 0.6037 - val_loss: 0.9249 - val_accuracy: 0.5983\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9327 - accuracy: 0.6259 - val_loss: 1.0093 - val_accuracy: 0.6410\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0655 - accuracy: 0.5889 - val_loss: 1.1118 - val_accuracy: 0.6752\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9931 - accuracy: 0.6037 - val_loss: 0.9878 - val_accuracy: 0.6154\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0755 - accuracy: 0.6037 - val_loss: 1.3379 - val_accuracy: 0.6581\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.2103 - accuracy: 0.6148 - val_loss: 1.2786 - val_accuracy: 0.6752\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0369 - accuracy: 0.6074 - val_loss: 0.9020 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9330 - accuracy: 0.6111 - val_loss: 0.8963 - val_accuracy: 0.6496\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8849 - accuracy: 0.6296 - val_loss: 0.9346 - val_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8911 - accuracy: 0.5704 - val_loss: 0.8774 - val_accuracy: 0.6496\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8853 - accuracy: 0.6148 - val_loss: 1.0900 - val_accuracy: 0.6667\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0093 - accuracy: 0.5926 - val_loss: 1.0550 - val_accuracy: 0.6667\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9323 - accuracy: 0.5852 - val_loss: 0.8749 - val_accuracy: 0.6239\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9005 - accuracy: 0.6296 - val_loss: 0.9882 - val_accuracy: 0.6581\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9152 - accuracy: 0.6407 - val_loss: 0.9144 - val_accuracy: 0.6325\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8850 - accuracy: 0.6185 - val_loss: 0.9323 - val_accuracy: 0.6410\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8867 - accuracy: 0.6148 - val_loss: 0.8777 - val_accuracy: 0.6496\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8838 - accuracy: 0.6074 - val_loss: 0.8785 - val_accuracy: 0.6496\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8915 - accuracy: 0.6111 - val_loss: 1.0020 - val_accuracy: 0.6752\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9713 - accuracy: 0.6407 - val_loss: 1.0870 - val_accuracy: 0.6667\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.9851 - accuracy: 0.5741 - val_loss: 0.9309 - val_accuracy: 0.5897\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0339 - accuracy: 0.6185 - val_loss: 1.1293 - val_accuracy: 0.5983\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0162 - accuracy: 0.6000 - val_loss: 0.8976 - val_accuracy: 0.6410\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9649 - accuracy: 0.6000 - val_loss: 1.2383 - val_accuracy: 0.6239\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1141 - accuracy: 0.6037 - val_loss: 1.1458 - val_accuracy: 0.5897\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.1271 - accuracy: 0.5852 - val_loss: 0.9473 - val_accuracy: 0.6068\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9238 - accuracy: 0.5778 - val_loss: 0.9447 - val_accuracy: 0.6239\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.9022 - accuracy: 0.6000 - val_loss: 0.8816 - val_accuracy: 0.6410\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8884 - accuracy: 0.6296 - val_loss: 0.9097 - val_accuracy: 0.6667\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8854 - accuracy: 0.6407 - val_loss: 0.8680 - val_accuracy: 0.6752\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8990 - accuracy: 0.6296 - val_loss: 0.9584 - val_accuracy: 0.6838\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9596 - accuracy: 0.6185 - val_loss: 0.9614 - val_accuracy: 0.6838\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9918 - accuracy: 0.6111 - val_loss: 1.0705 - val_accuracy: 0.6154\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0325 - accuracy: 0.6148 - val_loss: 0.9899 - val_accuracy: 0.5897\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9474 - accuracy: 0.5963 - val_loss: 1.0076 - val_accuracy: 0.6239\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9986 - accuracy: 0.6222 - val_loss: 1.0993 - val_accuracy: 0.6496\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9550 - accuracy: 0.6148 - val_loss: 0.8754 - val_accuracy: 0.6410\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0423 - accuracy: 0.6222 - val_loss: 1.4345 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.1001 - accuracy: 0.6185 - val_loss: 1.0103 - val_accuracy: 0.5983\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1763 - accuracy: 0.5704 - val_loss: 1.1606 - val_accuracy: 0.6154\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.4206 - accuracy: 0.6185 - val_loss: 2.4135 - val_accuracy: 0.6068\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.8084 - accuracy: 0.5889 - val_loss: 2.2472 - val_accuracy: 0.5983\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.6310 - accuracy: 0.5704 - val_loss: 1.6642 - val_accuracy: 0.6325\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1667 - accuracy: 0.5407 - val_loss: 1.1771 - val_accuracy: 0.4530\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.1855 - accuracy: 0.5222 - val_loss: 1.2008 - val_accuracy: 0.6581\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0468 - accuracy: 0.6148 - val_loss: 1.2462 - val_accuracy: 0.6410\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9861 - accuracy: 0.6185 - val_loss: 0.8817 - val_accuracy: 0.6239\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9211 - accuracy: 0.6185 - val_loss: 0.9988 - val_accuracy: 0.6752\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9245 - accuracy: 0.6222 - val_loss: 0.9604 - val_accuracy: 0.6154\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9073 - accuracy: 0.5926 - val_loss: 0.9397 - val_accuracy: 0.5897\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9379 - accuracy: 0.6185 - val_loss: 0.9113 - val_accuracy: 0.6068\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8880 - accuracy: 0.6333 - val_loss: 0.9528 - val_accuracy: 0.6154\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8848 - accuracy: 0.6111 - val_loss: 0.9012 - val_accuracy: 0.6410\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8915 - accuracy: 0.6333 - val_loss: 0.8777 - val_accuracy: 0.6239\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8692 - accuracy: 0.6222 - val_loss: 0.9586 - val_accuracy: 0.6667\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8908 - accuracy: 0.6296 - val_loss: 0.8939 - val_accuracy: 0.6154\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8854 - accuracy: 0.6296 - val_loss: 0.9097 - val_accuracy: 0.6325\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8839 - accuracy: 0.6259 - val_loss: 0.9202 - val_accuracy: 0.6325\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8714 - accuracy: 0.6259 - val_loss: 0.8709 - val_accuracy: 0.6496\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8647 - accuracy: 0.6481 - val_loss: 0.9103 - val_accuracy: 0.6581\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8702 - accuracy: 0.6519 - val_loss: 0.9061 - val_accuracy: 0.6581\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8660 - accuracy: 0.6333 - val_loss: 0.9153 - val_accuracy: 0.6239\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8878 - accuracy: 0.6148 - val_loss: 0.8726 - val_accuracy: 0.6239\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9200 - accuracy: 0.6185 - val_loss: 1.0701 - val_accuracy: 0.6667\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9549 - accuracy: 0.6370 - val_loss: 1.0385 - val_accuracy: 0.6496\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9267 - accuracy: 0.6037 - val_loss: 0.9481 - val_accuracy: 0.6154\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0013 - accuracy: 0.6148 - val_loss: 1.0260 - val_accuracy: 0.5897\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9681 - accuracy: 0.6000 - val_loss: 1.0675 - val_accuracy: 0.6496\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9797 - accuracy: 0.5778 - val_loss: 1.0950 - val_accuracy: 0.6581\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9523 - accuracy: 0.5889 - val_loss: 0.8720 - val_accuracy: 0.6068\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8885 - accuracy: 0.6148 - val_loss: 0.9185 - val_accuracy: 0.6496\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8684 - accuracy: 0.6296 - val_loss: 0.8688 - val_accuracy: 0.6581\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9038 - accuracy: 0.6296 - val_loss: 0.8737 - val_accuracy: 0.6410\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9165 - accuracy: 0.6259 - val_loss: 1.0077 - val_accuracy: 0.6667\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9407 - accuracy: 0.6444 - val_loss: 0.9665 - val_accuracy: 0.6752\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8930 - accuracy: 0.5963 - val_loss: 0.8634 - val_accuracy: 0.6410\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8931 - accuracy: 0.6296 - val_loss: 0.9289 - val_accuracy: 0.6325\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8798 - accuracy: 0.6370 - val_loss: 0.8712 - val_accuracy: 0.6410\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8886 - accuracy: 0.5926 - val_loss: 0.9928 - val_accuracy: 0.6581\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8927 - accuracy: 0.6333 - val_loss: 0.8637 - val_accuracy: 0.6325\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8758 - accuracy: 0.6407 - val_loss: 0.9291 - val_accuracy: 0.6496\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8653 - accuracy: 0.6148 - val_loss: 0.8864 - val_accuracy: 0.6239\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8587 - accuracy: 0.6074 - val_loss: 0.8856 - val_accuracy: 0.6667\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8613 - accuracy: 0.6556 - val_loss: 0.8855 - val_accuracy: 0.6496\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8649 - accuracy: 0.6556 - val_loss: 0.8831 - val_accuracy: 0.6667\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8666 - accuracy: 0.6222 - val_loss: 0.8671 - val_accuracy: 0.6325\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0995 - accuracy: 0.6296 - val_loss: 1.2337 - val_accuracy: 0.6581\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.2338 - accuracy: 0.6370 - val_loss: 1.6382 - val_accuracy: 0.6581\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.2151 - accuracy: 0.6111 - val_loss: 1.1391 - val_accuracy: 0.6581\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9115 - accuracy: 0.6148 - val_loss: 0.9650 - val_accuracy: 0.5726\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0254 - accuracy: 0.6222 - val_loss: 1.3313 - val_accuracy: 0.6325\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 1.1360 - accuracy: 0.6259 - val_loss: 1.2048 - val_accuracy: 0.6239\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9269 - accuracy: 0.6111 - val_loss: 0.9370 - val_accuracy: 0.6239\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9612 - accuracy: 0.6037 - val_loss: 1.0098 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9485 - accuracy: 0.6259 - val_loss: 1.0103 - val_accuracy: 0.6496\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9275 - accuracy: 0.6370 - val_loss: 0.9178 - val_accuracy: 0.5983\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8940 - accuracy: 0.6296 - val_loss: 0.9559 - val_accuracy: 0.6410\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8812 - accuracy: 0.6074 - val_loss: 0.9847 - val_accuracy: 0.6581\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9947 - accuracy: 0.6222 - val_loss: 1.0298 - val_accuracy: 0.5983\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.0506 - accuracy: 0.5852 - val_loss: 0.8858 - val_accuracy: 0.6581\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9346 - accuracy: 0.6148 - val_loss: 1.2684 - val_accuracy: 0.5983\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 1.0464 - accuracy: 0.6148 - val_loss: 1.0940 - val_accuracy: 0.5897\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9810 - accuracy: 0.6111 - val_loss: 1.0278 - val_accuracy: 0.5897\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.9143 - accuracy: 0.6407 - val_loss: 0.9631 - val_accuracy: 0.5983\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9197 - accuracy: 0.5963 - val_loss: 0.9991 - val_accuracy: 0.5897\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9946 - accuracy: 0.5963 - val_loss: 1.1463 - val_accuracy: 0.6154\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 1.2409 - accuracy: 0.6037 - val_loss: 1.8019 - val_accuracy: 0.6496\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 2.1939 - accuracy: 0.45 - 0s 48us/step - loss: 1.3593 - accuracy: 0.6074 - val_loss: 1.3885 - val_accuracy: 0.5812\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0335 - accuracy: 0.6148 - val_loss: 1.1749 - val_accuracy: 0.5214\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1450 - accuracy: 0.5667 - val_loss: 1.1249 - val_accuracy: 0.5897\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9730 - accuracy: 0.6333 - val_loss: 1.0133 - val_accuracy: 0.6581\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.1214 - accuracy: 0.5667 - val_loss: 1.0245 - val_accuracy: 0.6154\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0941 - accuracy: 0.5704 - val_loss: 1.3092 - val_accuracy: 0.6239\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.1250 - accuracy: 0.6259 - val_loss: 0.9677 - val_accuracy: 0.5897\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1397 - accuracy: 0.5963 - val_loss: 1.3572 - val_accuracy: 0.6325\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.1823 - accuracy: 0.5926 - val_loss: 1.5559 - val_accuracy: 0.6581\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.1622 - accuracy: 0.6148 - val_loss: 1.0494 - val_accuracy: 0.6923\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.2889 - accuracy: 0.6037 - val_loss: 0.8933 - val_accuracy: 0.6410\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 1.0728 - accuracy: 0.6370 - val_loss: 1.5002 - val_accuracy: 0.6581\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 1.1300 - accuracy: 0.6407 - val_loss: 1.1792 - val_accuracy: 0.6154\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.9001 - accuracy: 0.6037 - val_loss: 0.9591 - val_accuracy: 0.5897\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9439 - accuracy: 0.6259 - val_loss: 1.5305 - val_accuracy: 0.6325\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.2612 - accuracy: 0.6185 - val_loss: 1.4831 - val_accuracy: 0.6581\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0930 - accuracy: 0.5852 - val_loss: 0.9792 - val_accuracy: 0.6496\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.2180 - accuracy: 0.5667 - val_loss: 1.0154 - val_accuracy: 0.5641\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.0734 - accuracy: 0.5852 - val_loss: 1.2994 - val_accuracy: 0.6667\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0635 - accuracy: 0.5852 - val_loss: 0.8857 - val_accuracy: 0.6239\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9345 - accuracy: 0.6111 - val_loss: 1.0165 - val_accuracy: 0.6154\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9176 - accuracy: 0.6074 - val_loss: 0.9740 - val_accuracy: 0.5043\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9224 - accuracy: 0.5481 - val_loss: 1.1329 - val_accuracy: 0.5214\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.1267 - accuracy: 0.5333 - val_loss: 1.4797 - val_accuracy: 0.5043\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0953 - accuracy: 0.6037 - val_loss: 0.8989 - val_accuracy: 0.6325\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 518us/step - loss: 1.0438 - accuracy: 0.5926 - val_loss: 1.3349 - val_accuracy: 0.6325\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.2002 - accuracy: 0.6037 - val_loss: 1.6134 - val_accuracy: 0.6581\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1888 - accuracy: 0.6148 - val_loss: 1.1284 - val_accuracy: 0.6581\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9287 - accuracy: 0.6296 - val_loss: 0.9791 - val_accuracy: 0.5983\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.9689 - accuracy: 0.6074 - val_loss: 1.2483 - val_accuracy: 0.6667\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0539 - accuracy: 0.5741 - val_loss: 1.3006 - val_accuracy: 0.5641\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9913 - accuracy: 0.5815 - val_loss: 0.9234 - val_accuracy: 0.6325\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8495 - accuracy: 0.6556 - val_loss: 0.8969 - val_accuracy: 0.6325\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8879 - accuracy: 0.6370 - val_loss: 1.0177 - val_accuracy: 0.6410\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8790 - accuracy: 0.6556 - val_loss: 0.9342 - val_accuracy: 0.6410\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8874 - accuracy: 0.6444 - val_loss: 1.1696 - val_accuracy: 0.5641\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 1.1192 - accuracy: 0.5963 - val_loss: 1.0942 - val_accuracy: 0.5641\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9753 - accuracy: 0.6222 - val_loss: 0.9563 - val_accuracy: 0.6496\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9235 - accuracy: 0.5963 - val_loss: 0.9687 - val_accuracy: 0.6410\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9412 - accuracy: 0.6407 - val_loss: 0.9557 - val_accuracy: 0.5983\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.9063 - accuracy: 0.6370 - val_loss: 0.9608 - val_accuracy: 0.6496\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8724 - accuracy: 0.6148 - val_loss: 0.9750 - val_accuracy: 0.6154\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9146 - accuracy: 0.6148 - val_loss: 1.0753 - val_accuracy: 0.6068\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0132 - accuracy: 0.6148 - val_loss: 0.8817 - val_accuracy: 0.6325\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0426 - accuracy: 0.6148 - val_loss: 1.2814 - val_accuracy: 0.5983\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.2084 - accuracy: 0.5852 - val_loss: 1.6439 - val_accuracy: 0.6325\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1836 - accuracy: 0.6111 - val_loss: 0.9255 - val_accuracy: 0.6667\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9289 - accuracy: 0.6370 - val_loss: 0.8718 - val_accuracy: 0.6496\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9308 - accuracy: 0.6444 - val_loss: 1.1055 - val_accuracy: 0.6838\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9104 - accuracy: 0.6593 - val_loss: 0.8786 - val_accuracy: 0.6410\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8641 - accuracy: 0.6444 - val_loss: 0.9641 - val_accuracy: 0.6667\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9179 - accuracy: 0.6556 - val_loss: 1.1304 - val_accuracy: 0.6752\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9171 - accuracy: 0.6556 - val_loss: 0.9014 - val_accuracy: 0.5983\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9291 - accuracy: 0.6148 - val_loss: 0.9519 - val_accuracy: 0.5812\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8779 - accuracy: 0.6444 - val_loss: 0.8829 - val_accuracy: 0.6154\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8823 - accuracy: 0.6259 - val_loss: 1.0152 - val_accuracy: 0.5812\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9966 - accuracy: 0.6111 - val_loss: 0.9651 - val_accuracy: 0.5726\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8968 - accuracy: 0.6407 - val_loss: 0.9959 - val_accuracy: 0.5983\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8972 - accuracy: 0.6000 - val_loss: 0.9301 - val_accuracy: 0.5983\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9467 - accuracy: 0.6222 - val_loss: 0.9440 - val_accuracy: 0.5897\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8538 - accuracy: 0.6370 - val_loss: 0.9624 - val_accuracy: 0.5983\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.0513 - accuracy: 0.5778 - val_loss: 1.0445 - val_accuracy: 0.6239\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9743 - accuracy: 0.6333 - val_loss: 0.8764 - val_accuracy: 0.6496\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8724 - accuracy: 0.6148 - val_loss: 1.0463 - val_accuracy: 0.5983\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8958 - accuracy: 0.6074 - val_loss: 0.8598 - val_accuracy: 0.6410\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8523 - accuracy: 0.6704 - val_loss: 0.8366 - val_accuracy: 0.6581\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8917 - accuracy: 0.6074 - val_loss: 1.1379 - val_accuracy: 0.6581\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.9644 - accuracy: 0.6222 - val_loss: 0.9187 - val_accuracy: 0.6752\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8257 - accuracy: 0.6296 - val_loss: 0.9736 - val_accuracy: 0.6581\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 1.0902 - accuracy: 0.6444 - val_loss: 1.4770 - val_accuracy: 0.6581\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.0464 - accuracy: 0.6444 - val_loss: 0.9644 - val_accuracy: 0.5812\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9638 - accuracy: 0.5852 - val_loss: 1.1742 - val_accuracy: 0.5641\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.1087 - accuracy: 0.6000 - val_loss: 1.0756 - val_accuracy: 0.6496\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9443 - accuracy: 0.6407 - val_loss: 0.9331 - val_accuracy: 0.5983\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9300 - accuracy: 0.5963 - val_loss: 1.2244 - val_accuracy: 0.6410\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9710 - accuracy: 0.6333 - val_loss: 0.8806 - val_accuracy: 0.6581\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.2229 - accuracy: 0.6111 - val_loss: 0.8729 - val_accuracy: 0.6581\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9520 - accuracy: 0.6444 - val_loss: 1.2924 - val_accuracy: 0.6325\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0564 - accuracy: 0.6259 - val_loss: 0.8921 - val_accuracy: 0.6154\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8546 - accuracy: 0.6259 - val_loss: 1.0923 - val_accuracy: 0.6068\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.9400 - accuracy: 0.5963 - val_loss: 1.0154 - val_accuracy: 0.6667\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8920 - accuracy: 0.6407 - val_loss: 0.8767 - val_accuracy: 0.6325\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8459 - accuracy: 0.6407 - val_loss: 0.9594 - val_accuracy: 0.6581\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8719 - accuracy: 0.6000 - val_loss: 0.8690 - val_accuracy: 0.6752\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8681 - accuracy: 0.6630 - val_loss: 0.9436 - val_accuracy: 0.6068\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8570 - accuracy: 0.6519 - val_loss: 0.8659 - val_accuracy: 0.6667\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8404 - accuracy: 0.6148 - val_loss: 0.9441 - val_accuracy: 0.6667\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8423 - accuracy: 0.6519 - val_loss: 0.8590 - val_accuracy: 0.6667\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8230 - accuracy: 0.6630 - val_loss: 0.8529 - val_accuracy: 0.6581\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8310 - accuracy: 0.6593 - val_loss: 0.8742 - val_accuracy: 0.6752\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8556 - accuracy: 0.6259 - val_loss: 1.0497 - val_accuracy: 0.6752\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0193 - accuracy: 0.6296 - val_loss: 1.2633 - val_accuracy: 0.6752\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9741 - accuracy: 0.6444 - val_loss: 0.9748 - val_accuracy: 0.5983\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0942 - accuracy: 0.6185 - val_loss: 1.7418 - val_accuracy: 0.5726\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.5189 - accuracy: 0.6000 - val_loss: 1.6519 - val_accuracy: 0.5641\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.4038 - accuracy: 0.6000 - val_loss: 1.6526 - val_accuracy: 0.6068\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.1229 - accuracy: 0.5741 - val_loss: 1.4339 - val_accuracy: 0.5641\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.1968 - accuracy: 0.5481 - val_loss: 0.9521 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.1026 - accuracy: 0.6000 - val_loss: 1.5215 - val_accuracy: 0.5897\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.2535 - accuracy: 0.6148 - val_loss: 1.1992 - val_accuracy: 0.5897\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9111 - accuracy: 0.6519 - val_loss: 0.9652 - val_accuracy: 0.5983\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9964 - accuracy: 0.5741 - val_loss: 1.0162 - val_accuracy: 0.6581\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9997 - accuracy: 0.6519 - val_loss: 1.0397 - val_accuracy: 0.6667\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8516 - accuracy: 0.6481 - val_loss: 0.8942 - val_accuracy: 0.6154\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8627 - accuracy: 0.6074 - val_loss: 1.0442 - val_accuracy: 0.6239\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0135 - accuracy: 0.6259 - val_loss: 1.0110 - val_accuracy: 0.6068\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9868 - accuracy: 0.6259 - val_loss: 1.0191 - val_accuracy: 0.6581\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0063 - accuracy: 0.6333 - val_loss: 1.3892 - val_accuracy: 0.6581\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0903 - accuracy: 0.6259 - val_loss: 1.1055 - val_accuracy: 0.6752\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9847 - accuracy: 0.6407 - val_loss: 0.9894 - val_accuracy: 0.6410\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0536 - accuracy: 0.6481 - val_loss: 1.5376 - val_accuracy: 0.6752\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.1733 - accuracy: 0.6370 - val_loss: 1.2540 - val_accuracy: 0.5897\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9205 - accuracy: 0.6148 - val_loss: 0.9300 - val_accuracy: 0.5897\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0264 - accuracy: 0.5889 - val_loss: 1.0115 - val_accuracy: 0.6410\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8543 - accuracy: 0.6444 - val_loss: 0.9417 - val_accuracy: 0.5983\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8665 - accuracy: 0.6000 - val_loss: 0.9304 - val_accuracy: 0.6496\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8683 - accuracy: 0.6556 - val_loss: 0.9912 - val_accuracy: 0.6752\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8984 - accuracy: 0.6519 - val_loss: 1.0055 - val_accuracy: 0.6752\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8516 - accuracy: 0.6519 - val_loss: 0.8906 - val_accuracy: 0.6667\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8461 - accuracy: 0.6556 - val_loss: 0.9118 - val_accuracy: 0.6581\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8332 - accuracy: 0.6519 - val_loss: 0.8771 - val_accuracy: 0.6581\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8309 - accuracy: 0.6630 - val_loss: 0.8755 - val_accuracy: 0.6667\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8223 - accuracy: 0.5889 - val_loss: 0.8964 - val_accuracy: 0.5726\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8343 - accuracy: 0.5926 - val_loss: 0.8637 - val_accuracy: 0.6667\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9801 - accuracy: 0.6185 - val_loss: 1.3490 - val_accuracy: 0.6581\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.0701 - accuracy: 0.6481 - val_loss: 1.1751 - val_accuracy: 0.6752\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9235 - accuracy: 0.6111 - val_loss: 0.9030 - val_accuracy: 0.6239\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8839 - accuracy: 0.6185 - val_loss: 0.9754 - val_accuracy: 0.6496\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8547 - accuracy: 0.6407 - val_loss: 0.9042 - val_accuracy: 0.6239\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8309 - accuracy: 0.6074 - val_loss: 0.9769 - val_accuracy: 0.5726\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8874 - accuracy: 0.6000 - val_loss: 0.8892 - val_accuracy: 0.6581\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8295 - accuracy: 0.6630 - val_loss: 0.9361 - val_accuracy: 0.6496\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9214 - accuracy: 0.6407 - val_loss: 1.1168 - val_accuracy: 0.6923\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8787 - accuracy: 0.6444 - val_loss: 0.8677 - val_accuracy: 0.6239\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8653 - accuracy: 0.6259 - val_loss: 0.9773 - val_accuracy: 0.6154\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8699 - accuracy: 0.6556 - val_loss: 0.9069 - val_accuracy: 0.6496\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8715 - accuracy: 0.6407 - val_loss: 0.9155 - val_accuracy: 0.6325\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8602 - accuracy: 0.6481 - val_loss: 0.9251 - val_accuracy: 0.6325\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8415 - accuracy: 0.6519 - val_loss: 0.8781 - val_accuracy: 0.6496\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8315 - accuracy: 0.6185 - val_loss: 0.9085 - val_accuracy: 0.6667\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8199 - accuracy: 0.6556 - val_loss: 0.8572 - val_accuracy: 0.6410\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8483 - accuracy: 0.6519 - val_loss: 0.9541 - val_accuracy: 0.6838\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8405 - accuracy: 0.6778 - val_loss: 0.8900 - val_accuracy: 0.6752\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8094 - accuracy: 0.6519 - val_loss: 0.8510 - val_accuracy: 0.6496\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8159 - accuracy: 0.6741 - val_loss: 0.8841 - val_accuracy: 0.6581\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8067 - accuracy: 0.6741 - val_loss: 0.8721 - val_accuracy: 0.6752\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8253 - accuracy: 0.6630 - val_loss: 0.8454 - val_accuracy: 0.6410\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9853 - accuracy: 0.6481 - val_loss: 1.2635 - val_accuracy: 0.6667\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.3628 - accuracy: 0.6185 - val_loss: 2.5355 - val_accuracy: 0.6496\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.8443 - accuracy: 0.6370 - val_loss: 2.4093 - val_accuracy: 0.5726\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.5952 - accuracy: 0.5519 - val_loss: 1.6924 - val_accuracy: 0.5556\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.2064 - accuracy: 0.5333 - val_loss: 1.4354 - val_accuracy: 0.4444\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.2925 - accuracy: 0.5148 - val_loss: 1.2781 - val_accuracy: 0.6923\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 1.1812 - accuracy: 0.6185 - val_loss: 1.5437 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 1.0830 - accuracy: 0.6481 - val_loss: 0.8907 - val_accuracy: 0.5983\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8856 - accuracy: 0.6259 - val_loss: 1.0204 - val_accuracy: 0.6496\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9351 - accuracy: 0.5963 - val_loss: 1.0848 - val_accuracy: 0.5897\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8872 - accuracy: 0.6370 - val_loss: 0.8593 - val_accuracy: 0.6667\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8226 - accuracy: 0.6667 - val_loss: 0.9155 - val_accuracy: 0.6667\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8722 - accuracy: 0.6630 - val_loss: 1.0619 - val_accuracy: 0.6325\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8679 - accuracy: 0.6667 - val_loss: 0.8767 - val_accuracy: 0.6410\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8544 - accuracy: 0.6296 - val_loss: 0.9436 - val_accuracy: 0.6667\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8653 - accuracy: 0.6667 - val_loss: 0.9347 - val_accuracy: 0.6667\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8262 - accuracy: 0.6741 - val_loss: 0.8525 - val_accuracy: 0.6581\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8112 - accuracy: 0.6741 - val_loss: 0.8457 - val_accuracy: 0.6667\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9383 - accuracy: 0.6630 - val_loss: 1.3548 - val_accuracy: 0.6667\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.1981 - accuracy: 0.6444 - val_loss: 1.6069 - val_accuracy: 0.6667\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1557 - accuracy: 0.6630 - val_loss: 1.0583 - val_accuracy: 0.6410\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9284 - accuracy: 0.5926 - val_loss: 1.0546 - val_accuracy: 0.6325\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 1.3027 - accuracy: 0.6037 - val_loss: 2.1599 - val_accuracy: 0.6410\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 1.5219 - accuracy: 0.6370 - val_loss: 1.9183 - val_accuracy: 0.5983\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 1.2654 - accuracy: 0.6111 - val_loss: 1.2924 - val_accuracy: 0.5299\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 1.1340 - accuracy: 0.5963 - val_loss: 1.3027 - val_accuracy: 0.5470\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 1.1115 - accuracy: 0.5926 - val_loss: 1.0323 - val_accuracy: 0.6410\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.9347 - accuracy: 0.6074 - val_loss: 1.0683 - val_accuracy: 0.5385\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8511 - accuracy: 0.6111 - val_loss: 0.8851 - val_accuracy: 0.5556\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8631 - accuracy: 0.5926 - val_loss: 0.9694 - val_accuracy: 0.5726\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.8878 - accuracy: 0.6074 - val_loss: 1.0227 - val_accuracy: 0.6667\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8573 - accuracy: 0.6630 - val_loss: 0.8637 - val_accuracy: 0.6325\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8301 - accuracy: 0.6519 - val_loss: 0.9387 - val_accuracy: 0.6496\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8362 - accuracy: 0.6778 - val_loss: 0.9405 - val_accuracy: 0.6496\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8343 - accuracy: 0.6519 - val_loss: 0.8702 - val_accuracy: 0.6068\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.8629 - accuracy: 0.6556 - val_loss: 0.8960 - val_accuracy: 0.6325\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8230 - accuracy: 0.6704 - val_loss: 0.9084 - val_accuracy: 0.6325\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8363 - accuracy: 0.6519 - val_loss: 0.8814 - val_accuracy: 0.6667\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8307 - accuracy: 0.6630 - val_loss: 0.8525 - val_accuracy: 0.6325\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8087 - accuracy: 0.6815 - val_loss: 0.8899 - val_accuracy: 0.6838\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8109 - accuracy: 0.6778 - val_loss: 0.8574 - val_accuracy: 0.6667\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8227 - accuracy: 0.6778 - val_loss: 0.8331 - val_accuracy: 0.6496\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8079 - accuracy: 0.6778 - val_loss: 0.8813 - val_accuracy: 0.6838\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8112 - accuracy: 0.6667 - val_loss: 0.8424 - val_accuracy: 0.6667\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7962 - accuracy: 0.6889 - val_loss: 0.8469 - val_accuracy: 0.6667\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.8016 - accuracy: 0.6926 - val_loss: 0.8717 - val_accuracy: 0.6838\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8224 - accuracy: 0.6407 - val_loss: 0.8794 - val_accuracy: 0.6581\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8520 - accuracy: 0.6519 - val_loss: 0.8796 - val_accuracy: 0.6667\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.8169 - accuracy: 0.6704 - val_loss: 0.8514 - val_accuracy: 0.6581\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.8985 - accuracy: 0.6481 - val_loss: 1.0838 - val_accuracy: 0.6068\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 1.0070 - accuracy: 0.6333 - val_loss: 0.9609 - val_accuracy: 0.5983\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8956 - accuracy: 0.6370 - val_loss: 1.0053 - val_accuracy: 0.6752\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8999 - accuracy: 0.6185 - val_loss: 1.0230 - val_accuracy: 0.6667\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.9126 - accuracy: 0.6407 - val_loss: 0.8839 - val_accuracy: 0.6325\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8396 - accuracy: 0.6593 - val_loss: 0.8815 - val_accuracy: 0.6581\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8345 - accuracy: 0.6148 - val_loss: 0.8581 - val_accuracy: 0.6667\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8422 - accuracy: 0.6667 - val_loss: 0.8581 - val_accuracy: 0.6667\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8346 - accuracy: 0.6296 - val_loss: 0.8737 - val_accuracy: 0.6581\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8064 - accuracy: 0.6556 - val_loss: 0.8541 - val_accuracy: 0.6496\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8093 - accuracy: 0.6778 - val_loss: 0.8484 - val_accuracy: 0.6496\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8025 - accuracy: 0.6593 - val_loss: 0.8675 - val_accuracy: 0.6496\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8028 - accuracy: 0.6556 - val_loss: 0.8428 - val_accuracy: 0.6496\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8046 - accuracy: 0.6852 - val_loss: 0.8336 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8184 - accuracy: 0.6593 - val_loss: 0.8602 - val_accuracy: 0.6496\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7929 - accuracy: 0.6667 - val_loss: 0.8600 - val_accuracy: 0.6667\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8172 - accuracy: 0.6815 - val_loss: 0.8357 - val_accuracy: 0.6752\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8024 - accuracy: 0.6852 - val_loss: 0.8413 - val_accuracy: 0.6410\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8092 - accuracy: 0.6741 - val_loss: 1.0562 - val_accuracy: 0.6581\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9293 - accuracy: 0.6815 - val_loss: 1.0227 - val_accuracy: 0.6667\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8213 - accuracy: 0.6593 - val_loss: 0.8970 - val_accuracy: 0.6068\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8651 - accuracy: 0.6741 - val_loss: 1.2346 - val_accuracy: 0.6667\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0457 - accuracy: 0.6741 - val_loss: 1.1819 - val_accuracy: 0.6581\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9231 - accuracy: 0.6333 - val_loss: 0.9836 - val_accuracy: 0.5556\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9977 - accuracy: 0.6037 - val_loss: 1.1115 - val_accuracy: 0.6154\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9072 - accuracy: 0.6519 - val_loss: 0.9239 - val_accuracy: 0.6667\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8453 - accuracy: 0.6333 - val_loss: 0.9240 - val_accuracy: 0.6068\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8839 - accuracy: 0.6222 - val_loss: 0.8775 - val_accuracy: 0.6410\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8821 - accuracy: 0.6037 - val_loss: 1.0096 - val_accuracy: 0.6923\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8815 - accuracy: 0.6778 - val_loss: 0.9243 - val_accuracy: 0.6325\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8373 - accuracy: 0.6519 - val_loss: 1.1044 - val_accuracy: 0.6410\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9315 - accuracy: 0.6407 - val_loss: 1.1094 - val_accuracy: 0.6496\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8503 - accuracy: 0.6704 - val_loss: 0.8607 - val_accuracy: 0.6239\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8907 - accuracy: 0.6519 - val_loss: 1.0937 - val_accuracy: 0.6667\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9265 - accuracy: 0.6852 - val_loss: 1.0802 - val_accuracy: 0.6667\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8328 - accuracy: 0.6963 - val_loss: 0.8641 - val_accuracy: 0.6410\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8849 - accuracy: 0.6741 - val_loss: 1.0407 - val_accuracy: 0.6667\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8779 - accuracy: 0.6815 - val_loss: 0.9555 - val_accuracy: 0.6410\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8161 - accuracy: 0.6704 - val_loss: 0.8674 - val_accuracy: 0.6239\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8053 - accuracy: 0.6852 - val_loss: 1.0071 - val_accuracy: 0.6667\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8385 - accuracy: 0.6889 - val_loss: 0.9123 - val_accuracy: 0.6410\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8061 - accuracy: 0.6556 - val_loss: 0.8840 - val_accuracy: 0.6154\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8183 - accuracy: 0.6667 - val_loss: 0.9007 - val_accuracy: 0.6496\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7887 - accuracy: 0.6741 - val_loss: 0.9545 - val_accuracy: 0.6154\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8479 - accuracy: 0.6556 - val_loss: 0.9309 - val_accuracy: 0.6154\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8629 - accuracy: 0.6296 - val_loss: 0.8868 - val_accuracy: 0.6752\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8188 - accuracy: 0.6593 - val_loss: 0.9481 - val_accuracy: 0.6667\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8085 - accuracy: 0.6852 - val_loss: 0.8449 - val_accuracy: 0.6496\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8181 - accuracy: 0.6889 - val_loss: 0.9257 - val_accuracy: 0.6667\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8044 - accuracy: 0.6815 - val_loss: 0.8442 - val_accuracy: 0.6410\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8383 - accuracy: 0.6630 - val_loss: 0.9009 - val_accuracy: 0.6581\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7860 - accuracy: 0.6926 - val_loss: 0.9467 - val_accuracy: 0.6154\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9337 - accuracy: 0.6296 - val_loss: 1.1414 - val_accuracy: 0.5470\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0320 - accuracy: 0.5667 - val_loss: 1.1730 - val_accuracy: 0.6325\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8699 - accuracy: 0.6667 - val_loss: 0.9630 - val_accuracy: 0.6068\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9863 - accuracy: 0.6370 - val_loss: 0.9994 - val_accuracy: 0.6496\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9125 - accuracy: 0.6444 - val_loss: 1.2020 - val_accuracy: 0.6068\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.2737 - accuracy: 0.5815 - val_loss: 2.3561 - val_accuracy: 0.5470\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.7218 - accuracy: 0.6444 - val_loss: 2.1935 - val_accuracy: 0.5812\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.5136 - accuracy: 0.6037 - val_loss: 1.5734 - val_accuracy: 0.5983\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.2079 - accuracy: 0.5778 - val_loss: 1.1599 - val_accuracy: 0.4701\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.0058 - accuracy: 0.5667 - val_loss: 0.9400 - val_accuracy: 0.6239\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8705 - accuracy: 0.6296 - val_loss: 1.2828 - val_accuracy: 0.6410\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.1393 - accuracy: 0.5815 - val_loss: 1.2963 - val_accuracy: 0.4872\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.0445 - accuracy: 0.5815 - val_loss: 1.0077 - val_accuracy: 0.6410\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.1956 - accuracy: 0.6593 - val_loss: 1.9432 - val_accuracy: 0.6325\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.4489 - accuracy: 0.6259 - val_loss: 1.8006 - val_accuracy: 0.6581\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1926 - accuracy: 0.6593 - val_loss: 1.1288 - val_accuracy: 0.5470\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0503 - accuracy: 0.5593 - val_loss: 1.0274 - val_accuracy: 0.5299\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9635 - accuracy: 0.6593 - val_loss: 1.3231 - val_accuracy: 0.6752\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9863 - accuracy: 0.6519 - val_loss: 1.0847 - val_accuracy: 0.5812\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8164 - accuracy: 0.6444 - val_loss: 0.8743 - val_accuracy: 0.6667\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8312 - accuracy: 0.6815 - val_loss: 1.0301 - val_accuracy: 0.6752\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8294 - accuracy: 0.6963 - val_loss: 0.9264 - val_accuracy: 0.6325\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8589 - accuracy: 0.6481 - val_loss: 0.9525 - val_accuracy: 0.5983\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8558 - accuracy: 0.6593 - val_loss: 0.8876 - val_accuracy: 0.6154\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7896 - accuracy: 0.6815 - val_loss: 0.9827 - val_accuracy: 0.5897\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8108 - accuracy: 0.6593 - val_loss: 0.9368 - val_accuracy: 0.6410\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8604 - accuracy: 0.6556 - val_loss: 0.8811 - val_accuracy: 0.6325\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9974 - accuracy: 0.6593 - val_loss: 1.1720 - val_accuracy: 0.6923\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9978 - accuracy: 0.6630 - val_loss: 1.3424 - val_accuracy: 0.6496\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9608 - accuracy: 0.6185 - val_loss: 0.9178 - val_accuracy: 0.6239\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8329 - accuracy: 0.6556 - val_loss: 0.9335 - val_accuracy: 0.6325\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9340 - accuracy: 0.6667 - val_loss: 1.3176 - val_accuracy: 0.6667\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9764 - accuracy: 0.6667 - val_loss: 1.0651 - val_accuracy: 0.6325\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8372 - accuracy: 0.6630 - val_loss: 0.8958 - val_accuracy: 0.5726\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8648 - accuracy: 0.6556 - val_loss: 1.0895 - val_accuracy: 0.6496\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8350 - accuracy: 0.6741 - val_loss: 0.9551 - val_accuracy: 0.5897\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8413 - accuracy: 0.6556 - val_loss: 1.0692 - val_accuracy: 0.5983\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9182 - accuracy: 0.6407 - val_loss: 0.9104 - val_accuracy: 0.6154\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8296 - accuracy: 0.6593 - val_loss: 0.9649 - val_accuracy: 0.5812\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8366 - accuracy: 0.6481 - val_loss: 0.9406 - val_accuracy: 0.6410\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7995 - accuracy: 0.6889 - val_loss: 0.8584 - val_accuracy: 0.6068\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8162 - accuracy: 0.6667 - val_loss: 0.9368 - val_accuracy: 0.6496\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8039 - accuracy: 0.6778 - val_loss: 0.8744 - val_accuracy: 0.6068\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.70 - 0s 39us/step - loss: 0.9276 - accuracy: 0.6519 - val_loss: 1.0984 - val_accuracy: 0.6838\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 1.0651 - accuracy: 0.6630 - val_loss: 1.4208 - val_accuracy: 0.6752\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9840 - accuracy: 0.6667 - val_loss: 0.9782 - val_accuracy: 0.6068\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8407 - accuracy: 0.6556 - val_loss: 1.0205 - val_accuracy: 0.5812\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9435 - accuracy: 0.6481 - val_loss: 1.1108 - val_accuracy: 0.6581\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8435 - accuracy: 0.6852 - val_loss: 0.8862 - val_accuracy: 0.5983\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9053 - accuracy: 0.6444 - val_loss: 1.1379 - val_accuracy: 0.5470\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9204 - accuracy: 0.6407 - val_loss: 0.8709 - val_accuracy: 0.6325\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7795 - accuracy: 0.6667 - val_loss: 1.0455 - val_accuracy: 0.5214\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 0.9019 - val_accuracy: 0.5812\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8565 - accuracy: 0.6667 - val_loss: 1.1001 - val_accuracy: 0.6581\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 1.1170 - accuracy: 0.6407 - val_loss: 1.4445 - val_accuracy: 0.6581\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 1.0352 - accuracy: 0.6815 - val_loss: 1.0733 - val_accuracy: 0.5726\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8831 - accuracy: 0.6370 - val_loss: 1.0978 - val_accuracy: 0.5641\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 1.0761 - accuracy: 0.6037 - val_loss: 1.4252 - val_accuracy: 0.6325\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.9706 - accuracy: 0.6630 - val_loss: 0.9382 - val_accuracy: 0.6239\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8782 - accuracy: 0.6481 - val_loss: 0.9306 - val_accuracy: 0.5983\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8951 - accuracy: 0.6519 - val_loss: 0.9818 - val_accuracy: 0.6667\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8133 - accuracy: 0.6741 - val_loss: 0.9182 - val_accuracy: 0.6239\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8318 - accuracy: 0.6593 - val_loss: 0.8845 - val_accuracy: 0.6667\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7879 - accuracy: 0.6889 - val_loss: 0.8630 - val_accuracy: 0.6581\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7908 - accuracy: 0.6704 - val_loss: 0.9384 - val_accuracy: 0.6752\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8530 - accuracy: 0.6815 - val_loss: 0.9515 - val_accuracy: 0.6667\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7868 - accuracy: 0.6815 - val_loss: 0.8975 - val_accuracy: 0.6239\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8640 - accuracy: 0.6741 - val_loss: 1.1508 - val_accuracy: 0.6667\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8801 - accuracy: 0.7000 - val_loss: 0.9442 - val_accuracy: 0.6496\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7876 - accuracy: 0.6889 - val_loss: 0.8815 - val_accuracy: 0.6068\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8014 - accuracy: 0.6889 - val_loss: 0.9964 - val_accuracy: 0.6667\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8208 - accuracy: 0.6778 - val_loss: 0.8967 - val_accuracy: 0.6410\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 45us/step - loss: 0.7947 - accuracy: 0.6963 - val_loss: 0.8690 - val_accuracy: 0.6239\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7828 - accuracy: 0.6926 - val_loss: 0.9770 - val_accuracy: 0.6752\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8184 - accuracy: 0.6815 - val_loss: 0.9364 - val_accuracy: 0.6838\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7879 - accuracy: 0.6926 - val_loss: 0.8744 - val_accuracy: 0.6239\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8246 - accuracy: 0.6556 - val_loss: 0.9063 - val_accuracy: 0.6838\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7667 - accuracy: 0.6926 - val_loss: 0.8852 - val_accuracy: 0.6239\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.9130 - accuracy: 0.6593 - val_loss: 1.1872 - val_accuracy: 0.6667\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 1.0431 - accuracy: 0.6407 - val_loss: 1.3167 - val_accuracy: 0.6581\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8890 - accuracy: 0.6741 - val_loss: 0.8957 - val_accuracy: 0.6325\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9235 - accuracy: 0.6370 - val_loss: 1.0870 - val_accuracy: 0.6496\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9304 - accuracy: 0.6593 - val_loss: 1.2412 - val_accuracy: 0.6581\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9051 - accuracy: 0.6815 - val_loss: 1.1107 - val_accuracy: 0.5470\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.3956 - accuracy: 0.6259 - val_loss: 2.2462 - val_accuracy: 0.5214\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 2.0204 - accuracy: 0.5778 - val_loss: 2.3746 - val_accuracy: 0.5641\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 2.1128 - accuracy: 0.6074 - val_loss: 2.6347 - val_accuracy: 0.5470\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.6638 - accuracy: 0.5630 - val_loss: 1.1420 - val_accuracy: 0.6154\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.1864 - accuracy: 0.5704 - val_loss: 1.2193 - val_accuracy: 0.5385\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 1.0286 - accuracy: 0.5741 - val_loss: 1.3356 - val_accuracy: 0.6068\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.1324 - accuracy: 0.6185 - val_loss: 1.1530 - val_accuracy: 0.5812\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0223 - accuracy: 0.6185 - val_loss: 0.8922 - val_accuracy: 0.6581\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9349 - accuracy: 0.5630 - val_loss: 1.3761 - val_accuracy: 0.5299\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0307 - accuracy: 0.5481 - val_loss: 1.0881 - val_accuracy: 0.6923\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8674 - accuracy: 0.6741 - val_loss: 0.9143 - val_accuracy: 0.6154\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8464 - accuracy: 0.6444 - val_loss: 1.0387 - val_accuracy: 0.6667\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8356 - accuracy: 0.6667 - val_loss: 0.9949 - val_accuracy: 0.5812\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7973 - accuracy: 0.6667 - val_loss: 0.9480 - val_accuracy: 0.6239\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8454 - accuracy: 0.6037 - val_loss: 1.1759 - val_accuracy: 0.4957\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9744 - accuracy: 0.5704 - val_loss: 0.9451 - val_accuracy: 0.5897\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8637 - accuracy: 0.6630 - val_loss: 1.0682 - val_accuracy: 0.6838\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8928 - accuracy: 0.6556 - val_loss: 1.1340 - val_accuracy: 0.6068\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9235 - accuracy: 0.6148 - val_loss: 1.3126 - val_accuracy: 0.5556\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.2116 - accuracy: 0.6333 - val_loss: 1.5234 - val_accuracy: 0.5470\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.2613 - accuracy: 0.6222 - val_loss: 1.2058 - val_accuracy: 0.5556\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9485 - accuracy: 0.6444 - val_loss: 1.0609 - val_accuracy: 0.6239\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9443 - accuracy: 0.5815 - val_loss: 1.0140 - val_accuracy: 0.6496\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9077 - accuracy: 0.6519 - val_loss: 1.1378 - val_accuracy: 0.5641\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.1478 - accuracy: 0.6333 - val_loss: 1.1691 - val_accuracy: 0.5897\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9820 - accuracy: 0.6704 - val_loss: 0.8744 - val_accuracy: 0.5983\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8920 - accuracy: 0.6630 - val_loss: 1.4676 - val_accuracy: 0.5897\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1291 - accuracy: 0.6370 - val_loss: 1.0110 - val_accuracy: 0.6068\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8312 - accuracy: 0.6667 - val_loss: 0.9297 - val_accuracy: 0.6154\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8452 - accuracy: 0.6259 - val_loss: 0.9430 - val_accuracy: 0.6667\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8675 - accuracy: 0.6630 - val_loss: 1.1388 - val_accuracy: 0.6239\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.1876 - accuracy: 0.6333 - val_loss: 1.9522 - val_accuracy: 0.6325\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.2826 - accuracy: 0.6667 - val_loss: 1.4041 - val_accuracy: 0.5983\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0486 - accuracy: 0.5963 - val_loss: 1.0191 - val_accuracy: 0.5299\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.1424 - accuracy: 0.6000 - val_loss: 1.4218 - val_accuracy: 0.5556\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1614 - accuracy: 0.6222 - val_loss: 1.0152 - val_accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8471 - accuracy: 0.6333 - val_loss: 1.1590 - val_accuracy: 0.5214\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0041 - accuracy: 0.5407 - val_loss: 0.9586 - val_accuracy: 0.6581\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0238 - accuracy: 0.6444 - val_loss: 1.0795 - val_accuracy: 0.6239\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.1899 - accuracy: 0.6519 - val_loss: 1.5637 - val_accuracy: 0.6581\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0151 - accuracy: 0.6407 - val_loss: 0.9538 - val_accuracy: 0.5812\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9091 - accuracy: 0.5704 - val_loss: 1.2000 - val_accuracy: 0.4359\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0818 - accuracy: 0.5815 - val_loss: 1.0726 - val_accuracy: 0.5470\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8783 - accuracy: 0.6407 - val_loss: 1.3214 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1007 - accuracy: 0.5963 - val_loss: 1.5412 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.1044 - accuracy: 0.6259 - val_loss: 1.0503 - val_accuracy: 0.6496\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8258 - accuracy: 0.6778 - val_loss: 0.8835 - val_accuracy: 0.6325\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7993 - accuracy: 0.6741 - val_loss: 1.1149 - val_accuracy: 0.6325\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8631 - accuracy: 0.6222 - val_loss: 0.9558 - val_accuracy: 0.6496\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8035 - accuracy: 0.6815 - val_loss: 0.9038 - val_accuracy: 0.5983\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8302 - accuracy: 0.6630 - val_loss: 0.9288 - val_accuracy: 0.6496\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7893 - accuracy: 0.6889 - val_loss: 0.9351 - val_accuracy: 0.6410\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7802 - accuracy: 0.6704 - val_loss: 0.9094 - val_accuracy: 0.6581\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7699 - accuracy: 0.6852 - val_loss: 0.8771 - val_accuracy: 0.6496\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7766 - accuracy: 0.6963 - val_loss: 0.8803 - val_accuracy: 0.6581\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7696 - accuracy: 0.6963 - val_loss: 0.8799 - val_accuracy: 0.6496\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7797 - accuracy: 0.6852 - val_loss: 0.9076 - val_accuracy: 0.6410\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7869 - accuracy: 0.6889 - val_loss: 0.9498 - val_accuracy: 0.6496\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8897 - accuracy: 0.6778 - val_loss: 1.0795 - val_accuracy: 0.6667\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7922 - accuracy: 0.7000 - val_loss: 0.8788 - val_accuracy: 0.6154\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8002 - accuracy: 0.6778 - val_loss: 0.9446 - val_accuracy: 0.6581\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7912 - accuracy: 0.6778 - val_loss: 0.8778 - val_accuracy: 0.6496\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8439 - accuracy: 0.6593 - val_loss: 0.9966 - val_accuracy: 0.6581\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8754 - accuracy: 0.6815 - val_loss: 0.9955 - val_accuracy: 0.6410\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7866 - accuracy: 0.6963 - val_loss: 0.8675 - val_accuracy: 0.6325\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8073 - accuracy: 0.6778 - val_loss: 1.0732 - val_accuracy: 0.6752\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8381 - accuracy: 0.6926 - val_loss: 0.9002 - val_accuracy: 0.6496\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7737 - accuracy: 0.7000 - val_loss: 0.8611 - val_accuracy: 0.6410\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7885 - accuracy: 0.6926 - val_loss: 0.9727 - val_accuracy: 0.6752\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7866 - accuracy: 0.7000 - val_loss: 0.8662 - val_accuracy: 0.6410\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7826 - accuracy: 0.6926 - val_loss: 0.9860 - val_accuracy: 0.6667\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8010 - accuracy: 0.7000 - val_loss: 0.9288 - val_accuracy: 0.6667\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8095 - accuracy: 0.6704 - val_loss: 1.0633 - val_accuracy: 0.5897\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0387 - accuracy: 0.6333 - val_loss: 1.3748 - val_accuracy: 0.5556\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9748 - accuracy: 0.6259 - val_loss: 0.8880 - val_accuracy: 0.6410\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8373 - accuracy: 0.6407 - val_loss: 1.0809 - val_accuracy: 0.6752\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8301 - accuracy: 0.6963 - val_loss: 0.9073 - val_accuracy: 0.6496\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7631 - accuracy: 0.6926 - val_loss: 0.8595 - val_accuracy: 0.6410\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7700 - accuracy: 0.6926 - val_loss: 0.9180 - val_accuracy: 0.6752\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7713 - accuracy: 0.7037 - val_loss: 0.9101 - val_accuracy: 0.6667\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7751 - accuracy: 0.7074 - val_loss: 0.9027 - val_accuracy: 0.6496\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7802 - accuracy: 0.6704 - val_loss: 0.9084 - val_accuracy: 0.6496\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7837 - accuracy: 0.6778 - val_loss: 0.9433 - val_accuracy: 0.6496\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8855 - accuracy: 0.6815 - val_loss: 0.9994 - val_accuracy: 0.6667\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7750 - accuracy: 0.7037 - val_loss: 0.8845 - val_accuracy: 0.6239\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7823 - accuracy: 0.6963 - val_loss: 1.0032 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7960 - accuracy: 0.6889 - val_loss: 0.8596 - val_accuracy: 0.6496\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8016 - accuracy: 0.6741 - val_loss: 1.0124 - val_accuracy: 0.6752\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8211 - accuracy: 0.7074 - val_loss: 0.9121 - val_accuracy: 0.6410\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7810 - accuracy: 0.6852 - val_loss: 0.9183 - val_accuracy: 0.6410\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8760 - accuracy: 0.7037 - val_loss: 1.0959 - val_accuracy: 0.6752\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7931 - accuracy: 0.6926 - val_loss: 0.8795 - val_accuracy: 0.6068\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8033 - accuracy: 0.6778 - val_loss: 1.0031 - val_accuracy: 0.6581\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8108 - accuracy: 0.6926 - val_loss: 0.8792 - val_accuracy: 0.6496\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7692 - accuracy: 0.6852 - val_loss: 0.8982 - val_accuracy: 0.6496\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7615 - accuracy: 0.6963 - val_loss: 0.9020 - val_accuracy: 0.6496\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7934 - accuracy: 0.6778 - val_loss: 0.9180 - val_accuracy: 0.6496\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7710 - accuracy: 0.7000 - val_loss: 0.8789 - val_accuracy: 0.6667\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7669 - accuracy: 0.6630 - val_loss: 0.9210 - val_accuracy: 0.5897\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7747 - accuracy: 0.6370 - val_loss: 0.8644 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7702 - accuracy: 0.6370 - val_loss: 0.8879 - val_accuracy: 0.6667\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7588 - accuracy: 0.6815 - val_loss: 0.8976 - val_accuracy: 0.6581\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7583 - accuracy: 0.6815 - val_loss: 0.8839 - val_accuracy: 0.6325\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7584 - accuracy: 0.6889 - val_loss: 0.9240 - val_accuracy: 0.6923\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7690 - accuracy: 0.6926 - val_loss: 0.8630 - val_accuracy: 0.6667\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7610 - accuracy: 0.7000 - val_loss: 0.9541 - val_accuracy: 0.6838\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.8032 - accuracy: 0.6963 - val_loss: 1.0988 - val_accuracy: 0.6667\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8180 - accuracy: 0.6889 - val_loss: 0.8939 - val_accuracy: 0.6239\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8080 - accuracy: 0.6889 - val_loss: 1.1698 - val_accuracy: 0.6667\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9013 - accuracy: 0.6741 - val_loss: 1.0330 - val_accuracy: 0.6581\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8591 - accuracy: 0.6556 - val_loss: 0.9460 - val_accuracy: 0.6496\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7986 - accuracy: 0.7074 - val_loss: 1.0281 - val_accuracy: 0.6752\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7825 - accuracy: 0.7037 - val_loss: 0.8712 - val_accuracy: 0.6325\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7842 - accuracy: 0.6815 - val_loss: 0.9733 - val_accuracy: 0.6410\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7991 - accuracy: 0.6852 - val_loss: 0.8988 - val_accuracy: 0.6667\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7696 - accuracy: 0.6889 - val_loss: 0.8606 - val_accuracy: 0.6496\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7837 - accuracy: 0.6889 - val_loss: 0.9968 - val_accuracy: 0.6496\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8692 - accuracy: 0.6889 - val_loss: 0.9098 - val_accuracy: 0.6752\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8736 - accuracy: 0.6667 - val_loss: 0.9996 - val_accuracy: 0.6752\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7983 - accuracy: 0.6926 - val_loss: 1.0631 - val_accuracy: 0.6667\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7996 - accuracy: 0.7037 - val_loss: 0.8982 - val_accuracy: 0.6239\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7701 - accuracy: 0.6815 - val_loss: 0.9512 - val_accuracy: 0.6581\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8435 - accuracy: 0.6889 - val_loss: 1.0276 - val_accuracy: 0.6667\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7945 - accuracy: 0.7037 - val_loss: 0.8847 - val_accuracy: 0.6496\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8268 - accuracy: 0.6778 - val_loss: 1.0997 - val_accuracy: 0.6581\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9122 - accuracy: 0.6778 - val_loss: 1.0496 - val_accuracy: 0.6752\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9149 - accuracy: 0.6852 - val_loss: 0.9176 - val_accuracy: 0.5983\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8239 - accuracy: 0.7000 - val_loss: 1.1443 - val_accuracy: 0.6667\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8727 - accuracy: 0.6815 - val_loss: 0.8843 - val_accuracy: 0.6068\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7828 - accuracy: 0.6889 - val_loss: 0.9605 - val_accuracy: 0.6752\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7871 - accuracy: 0.6815 - val_loss: 0.9924 - val_accuracy: 0.5385\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8544 - accuracy: 0.6074 - val_loss: 0.9065 - val_accuracy: 0.6410\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7809 - accuracy: 0.6852 - val_loss: 0.9084 - val_accuracy: 0.7009\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7563 - accuracy: 0.7111 - val_loss: 0.8782 - val_accuracy: 0.6325\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8167 - accuracy: 0.6741 - val_loss: 0.9368 - val_accuracy: 0.6581\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7635 - accuracy: 0.7037 - val_loss: 0.8762 - val_accuracy: 0.6325\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7732 - accuracy: 0.6815 - val_loss: 0.9874 - val_accuracy: 0.6752\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8528 - accuracy: 0.6852 - val_loss: 0.9055 - val_accuracy: 0.6581\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8919 - accuracy: 0.6667 - val_loss: 1.2732 - val_accuracy: 0.6838\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0585 - accuracy: 0.6889 - val_loss: 1.4428 - val_accuracy: 0.6838\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9617 - accuracy: 0.7037 - val_loss: 0.9526 - val_accuracy: 0.6068\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8513 - accuracy: 0.6407 - val_loss: 0.9889 - val_accuracy: 0.5983\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8318 - accuracy: 0.6778 - val_loss: 1.0613 - val_accuracy: 0.6581\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8081 - accuracy: 0.6963 - val_loss: 0.9285 - val_accuracy: 0.6154\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8881 - accuracy: 0.6630 - val_loss: 0.9748 - val_accuracy: 0.6325\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8411 - accuracy: 0.6815 - val_loss: 1.1874 - val_accuracy: 0.6496\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8613 - accuracy: 0.7037 - val_loss: 0.9361 - val_accuracy: 0.5983\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7698 - accuracy: 0.6741 - val_loss: 0.9532 - val_accuracy: 0.6154\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8054 - accuracy: 0.6926 - val_loss: 0.9237 - val_accuracy: 0.6410\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7470 - accuracy: 0.7000 - val_loss: 0.9162 - val_accuracy: 0.6239\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7670 - accuracy: 0.6926 - val_loss: 0.9266 - val_accuracy: 0.6667\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7583 - accuracy: 0.7074 - val_loss: 0.9121 - val_accuracy: 0.6239\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7688 - accuracy: 0.6963 - val_loss: 0.9357 - val_accuracy: 0.6496\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7677 - accuracy: 0.6963 - val_loss: 0.8793 - val_accuracy: 0.6581\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7640 - accuracy: 0.6889 - val_loss: 0.9324 - val_accuracy: 0.6667\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7629 - accuracy: 0.6926 - val_loss: 0.8672 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7547 - accuracy: 0.6852 - val_loss: 0.9189 - val_accuracy: 0.6752\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7583 - accuracy: 0.7111 - val_loss: 0.9348 - val_accuracy: 0.6581\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7538 - accuracy: 0.7037 - val_loss: 0.9065 - val_accuracy: 0.6667\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7548 - accuracy: 0.7111 - val_loss: 0.9024 - val_accuracy: 0.6838\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7591 - accuracy: 0.7074 - val_loss: 0.9043 - val_accuracy: 0.6667\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7440 - accuracy: 0.7037 - val_loss: 0.9059 - val_accuracy: 0.6239\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7793 - accuracy: 0.6852 - val_loss: 0.9297 - val_accuracy: 0.6496\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7620 - accuracy: 0.6741 - val_loss: 0.8652 - val_accuracy: 0.6581\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7690 - accuracy: 0.6926 - val_loss: 0.9474 - val_accuracy: 0.6752\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7525 - accuracy: 0.7037 - val_loss: 0.8699 - val_accuracy: 0.6581\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7529 - accuracy: 0.6963 - val_loss: 0.9049 - val_accuracy: 0.6838\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7568 - accuracy: 0.7074 - val_loss: 0.9241 - val_accuracy: 0.6496\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7756 - accuracy: 0.6741 - val_loss: 0.8797 - val_accuracy: 0.6325\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7809 - accuracy: 0.6778 - val_loss: 0.8788 - val_accuracy: 0.6667\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7585 - accuracy: 0.6815 - val_loss: 1.0245 - val_accuracy: 0.6667\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8322 - accuracy: 0.6926 - val_loss: 0.9842 - val_accuracy: 0.6752\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8013 - accuracy: 0.7000 - val_loss: 0.9039 - val_accuracy: 0.6581\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8414 - accuracy: 0.6889 - val_loss: 1.2053 - val_accuracy: 0.6667\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8482 - accuracy: 0.6926 - val_loss: 0.9258 - val_accuracy: 0.5983\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8267 - accuracy: 0.6444 - val_loss: 1.3514 - val_accuracy: 0.5812\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0764 - accuracy: 0.6333 - val_loss: 1.1960 - val_accuracy: 0.6581\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8532 - accuracy: 0.6852 - val_loss: 0.9420 - val_accuracy: 0.5641\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0765 - accuracy: 0.6370 - val_loss: 1.8404 - val_accuracy: 0.5556\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.4505 - accuracy: 0.6333 - val_loss: 1.4960 - val_accuracy: 0.5556\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.2011 - accuracy: 0.5889 - val_loss: 1.0911 - val_accuracy: 0.6581\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9281 - accuracy: 0.5704 - val_loss: 1.0738 - val_accuracy: 0.5897\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8191 - accuracy: 0.6481 - val_loss: 1.0126 - val_accuracy: 0.6154\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8829 - accuracy: 0.6630 - val_loss: 0.8815 - val_accuracy: 0.6410\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7917 - accuracy: 0.6815 - val_loss: 0.8725 - val_accuracy: 0.6581\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7779 - accuracy: 0.6889 - val_loss: 0.9679 - val_accuracy: 0.6325\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8384 - accuracy: 0.6593 - val_loss: 0.8846 - val_accuracy: 0.6410\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7555 - accuracy: 0.6963 - val_loss: 0.9210 - val_accuracy: 0.6410\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7707 - accuracy: 0.6704 - val_loss: 0.8871 - val_accuracy: 0.6752\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7878 - accuracy: 0.6815 - val_loss: 0.9091 - val_accuracy: 0.6496\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7758 - accuracy: 0.6852 - val_loss: 0.8633 - val_accuracy: 0.6752\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7713 - accuracy: 0.6963 - val_loss: 0.8881 - val_accuracy: 0.6838\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7739 - accuracy: 0.6889 - val_loss: 1.0691 - val_accuracy: 0.6581\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8712 - accuracy: 0.6852 - val_loss: 1.0008 - val_accuracy: 0.6496\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7578 - accuracy: 0.6926 - val_loss: 0.9155 - val_accuracy: 0.5897\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7652 - accuracy: 0.6667 - val_loss: 0.9629 - val_accuracy: 0.6581\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7781 - accuracy: 0.7000 - val_loss: 0.9244 - val_accuracy: 0.6667\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7632 - accuracy: 0.7111 - val_loss: 0.9155 - val_accuracy: 0.6581\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7946 - accuracy: 0.6815 - val_loss: 0.9026 - val_accuracy: 0.6154\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7715 - accuracy: 0.6852 - val_loss: 0.8887 - val_accuracy: 0.6581\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7523 - accuracy: 0.7000 - val_loss: 0.9684 - val_accuracy: 0.6752\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7845 - accuracy: 0.6926 - val_loss: 0.8792 - val_accuracy: 0.6410\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7470 - accuracy: 0.7000 - val_loss: 0.9010 - val_accuracy: 0.6581\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7480 - accuracy: 0.7037 - val_loss: 0.9056 - val_accuracy: 0.6496\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7459 - accuracy: 0.6889 - val_loss: 0.9231 - val_accuracy: 0.6667\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7530 - accuracy: 0.7148 - val_loss: 0.8995 - val_accuracy: 0.6752\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7468 - accuracy: 0.7148 - val_loss: 0.8752 - val_accuracy: 0.6325\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7524 - accuracy: 0.6778 - val_loss: 1.0809 - val_accuracy: 0.6581\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8429 - accuracy: 0.6963 - val_loss: 0.9857 - val_accuracy: 0.6667\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7937 - accuracy: 0.7000 - val_loss: 0.9225 - val_accuracy: 0.6752\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7761 - accuracy: 0.6963 - val_loss: 0.9467 - val_accuracy: 0.6410\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7914 - accuracy: 0.6667 - val_loss: 0.9161 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7931 - accuracy: 0.6815 - val_loss: 0.9618 - val_accuracy: 0.6752\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8499 - accuracy: 0.6741 - val_loss: 1.0293 - val_accuracy: 0.6496\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7913 - accuracy: 0.6815 - val_loss: 0.9419 - val_accuracy: 0.6239\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9028 - accuracy: 0.6667 - val_loss: 1.1022 - val_accuracy: 0.6325\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8060 - accuracy: 0.6963 - val_loss: 0.9076 - val_accuracy: 0.5983\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7850 - accuracy: 0.6852 - val_loss: 1.0285 - val_accuracy: 0.6752\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8243 - accuracy: 0.6963 - val_loss: 0.8990 - val_accuracy: 0.6838\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7553 - accuracy: 0.6926 - val_loss: 0.9098 - val_accuracy: 0.6752\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7428 - accuracy: 0.7111 - val_loss: 0.8743 - val_accuracy: 0.6496\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7396 - accuracy: 0.6963 - val_loss: 0.9277 - val_accuracy: 0.6581\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7944 - accuracy: 0.6963 - val_loss: 0.8734 - val_accuracy: 0.6752\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7463 - accuracy: 0.7111 - val_loss: 0.8837 - val_accuracy: 0.6752\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7467 - accuracy: 0.7074 - val_loss: 0.9244 - val_accuracy: 0.6752\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7427 - accuracy: 0.7111 - val_loss: 0.8964 - val_accuracy: 0.6752\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7456 - accuracy: 0.6963 - val_loss: 0.8955 - val_accuracy: 0.6667\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7486 - accuracy: 0.7037 - val_loss: 0.8865 - val_accuracy: 0.6752\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7436 - accuracy: 0.7074 - val_loss: 0.9229 - val_accuracy: 0.6752\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7557 - accuracy: 0.6963 - val_loss: 0.9125 - val_accuracy: 0.6667\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7716 - accuracy: 0.6889 - val_loss: 0.9156 - val_accuracy: 0.6923\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7447 - accuracy: 0.6926 - val_loss: 0.8872 - val_accuracy: 0.6581\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7463 - accuracy: 0.7148 - val_loss: 0.8932 - val_accuracy: 0.6325\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7723 - accuracy: 0.6963 - val_loss: 0.9844 - val_accuracy: 0.6581\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7499 - accuracy: 0.7000 - val_loss: 0.9003 - val_accuracy: 0.6068\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7702 - accuracy: 0.7000 - val_loss: 0.9626 - val_accuracy: 0.6752\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7521 - accuracy: 0.7259 - val_loss: 0.8873 - val_accuracy: 0.6496\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7530 - accuracy: 0.6926 - val_loss: 0.8828 - val_accuracy: 0.6667\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7601 - accuracy: 0.6852 - val_loss: 1.1334 - val_accuracy: 0.6581\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8575 - accuracy: 0.6852 - val_loss: 1.0338 - val_accuracy: 0.6496\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8396 - accuracy: 0.6593 - val_loss: 1.1604 - val_accuracy: 0.5812\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0542 - accuracy: 0.6222 - val_loss: 1.2819 - val_accuracy: 0.6239\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8351 - accuracy: 0.6704 - val_loss: 1.0624 - val_accuracy: 0.5897\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8797 - accuracy: 0.6704 - val_loss: 1.0741 - val_accuracy: 0.5641\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9018 - accuracy: 0.6296 - val_loss: 0.9065 - val_accuracy: 0.5897\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7701 - accuracy: 0.6926 - val_loss: 1.1845 - val_accuracy: 0.6068\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9384 - accuracy: 0.6333 - val_loss: 1.0360 - val_accuracy: 0.6581\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8713 - accuracy: 0.6556 - val_loss: 0.9748 - val_accuracy: 0.5641\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8245 - accuracy: 0.6593 - val_loss: 0.9962 - val_accuracy: 0.6752\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7755 - accuracy: 0.7000 - val_loss: 0.8795 - val_accuracy: 0.6068\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7843 - accuracy: 0.6704 - val_loss: 0.9554 - val_accuracy: 0.6154\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7946 - accuracy: 0.6667 - val_loss: 0.8842 - val_accuracy: 0.6838\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7621 - accuracy: 0.6815 - val_loss: 0.8906 - val_accuracy: 0.6667\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7519 - accuracy: 0.6815 - val_loss: 0.9833 - val_accuracy: 0.6667\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8084 - accuracy: 0.7000 - val_loss: 0.9380 - val_accuracy: 0.6667\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7574 - accuracy: 0.6963 - val_loss: 0.8759 - val_accuracy: 0.6496\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.73 - 0s 62us/step - loss: 0.7453 - accuracy: 0.7111 - val_loss: 0.9207 - val_accuracy: 0.6838\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7481 - accuracy: 0.7000 - val_loss: 0.9099 - val_accuracy: 0.6838\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7365 - accuracy: 0.7074 - val_loss: 0.8621 - val_accuracy: 0.6496\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7529 - accuracy: 0.6778 - val_loss: 0.9681 - val_accuracy: 0.6667\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7697 - accuracy: 0.6889 - val_loss: 0.9023 - val_accuracy: 0.6667\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7364 - accuracy: 0.7074 - val_loss: 0.8786 - val_accuracy: 0.6667\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7396 - accuracy: 0.6926 - val_loss: 0.8921 - val_accuracy: 0.6667\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7425 - accuracy: 0.6778 - val_loss: 0.9598 - val_accuracy: 0.6752\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7733 - accuracy: 0.6963 - val_loss: 0.9678 - val_accuracy: 0.6410\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7360 - accuracy: 0.6926 - val_loss: 0.8791 - val_accuracy: 0.6239\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8768 - accuracy: 0.6778 - val_loss: 1.1592 - val_accuracy: 0.6667\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8272 - accuracy: 0.7037 - val_loss: 0.9195 - val_accuracy: 0.6325\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7758 - accuracy: 0.6963 - val_loss: 1.0073 - val_accuracy: 0.6667\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7895 - accuracy: 0.6852 - val_loss: 0.8875 - val_accuracy: 0.6325\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7367 - accuracy: 0.6926 - val_loss: 1.0119 - val_accuracy: 0.6325\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8143 - accuracy: 0.6815 - val_loss: 1.0638 - val_accuracy: 0.6068\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8548 - accuracy: 0.6778 - val_loss: 0.9019 - val_accuracy: 0.5983\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8576 - accuracy: 0.6778 - val_loss: 1.1080 - val_accuracy: 0.6581\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7745 - accuracy: 0.7185 - val_loss: 0.8728 - val_accuracy: 0.6154\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7553 - accuracy: 0.7000 - val_loss: 0.9489 - val_accuracy: 0.6410\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7649 - accuracy: 0.6963 - val_loss: 0.9159 - val_accuracy: 0.6239\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7631 - accuracy: 0.7000 - val_loss: 1.1676 - val_accuracy: 0.6752\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9207 - accuracy: 0.6667 - val_loss: 1.0765 - val_accuracy: 0.6667\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7429 - accuracy: 0.7148 - val_loss: 0.9286 - val_accuracy: 0.6239\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8367 - accuracy: 0.6778 - val_loss: 0.9920 - val_accuracy: 0.6667\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7755 - accuracy: 0.7037 - val_loss: 0.8846 - val_accuracy: 0.6325\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8240 - accuracy: 0.6667 - val_loss: 1.3199 - val_accuracy: 0.6667\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9892 - accuracy: 0.6815 - val_loss: 1.1744 - val_accuracy: 0.6752\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8158 - accuracy: 0.7037 - val_loss: 1.0150 - val_accuracy: 0.5556\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0701 - accuracy: 0.6296 - val_loss: 1.4895 - val_accuracy: 0.6239\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.1383 - accuracy: 0.6370 - val_loss: 1.2747 - val_accuracy: 0.6752\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9597 - accuracy: 0.6852 - val_loss: 0.9062 - val_accuracy: 0.5641\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9061 - accuracy: 0.6259 - val_loss: 1.0996 - val_accuracy: 0.5556\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9120 - accuracy: 0.6370 - val_loss: 1.0197 - val_accuracy: 0.6838\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0076 - accuracy: 0.6815 - val_loss: 1.3954 - val_accuracy: 0.6838\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9641 - accuracy: 0.6667 - val_loss: 0.9555 - val_accuracy: 0.5983\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7932 - accuracy: 0.6593 - val_loss: 0.8906 - val_accuracy: 0.5983\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8036 - accuracy: 0.6630 - val_loss: 1.1083 - val_accuracy: 0.6752\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.64 - 0s 60us/step - loss: 0.8167 - accuracy: 0.6926 - val_loss: 0.9288 - val_accuracy: 0.6581\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7664 - accuracy: 0.6630 - val_loss: 0.9150 - val_accuracy: 0.6496\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8092 - accuracy: 0.7111 - val_loss: 1.0535 - val_accuracy: 0.6838\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7911 - accuracy: 0.6926 - val_loss: 0.9325 - val_accuracy: 0.6667\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8022 - accuracy: 0.6815 - val_loss: 1.0377 - val_accuracy: 0.6752\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8831 - accuracy: 0.6741 - val_loss: 1.1508 - val_accuracy: 0.6581\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1106 - accuracy: 0.6593 - val_loss: 2.6743 - val_accuracy: 0.6410\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.9140 - accuracy: 0.6556 - val_loss: 2.5063 - val_accuracy: 0.6667\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.6338 - accuracy: 0.6296 - val_loss: 1.4819 - val_accuracy: 0.6154\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0989 - accuracy: 0.5630 - val_loss: 1.0927 - val_accuracy: 0.4701\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9842 - accuracy: 0.5852 - val_loss: 1.0273 - val_accuracy: 0.6154\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7922 - accuracy: 0.6593 - val_loss: 0.9674 - val_accuracy: 0.5385\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7733 - accuracy: 0.6333 - val_loss: 0.9463 - val_accuracy: 0.5556\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7800 - accuracy: 0.6444 - val_loss: 0.8928 - val_accuracy: 0.6410\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7539 - accuracy: 0.6667 - val_loss: 0.9746 - val_accuracy: 0.6667\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7634 - accuracy: 0.6889 - val_loss: 0.9102 - val_accuracy: 0.6239\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7878 - accuracy: 0.6852 - val_loss: 0.9836 - val_accuracy: 0.6667\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7456 - accuracy: 0.7037 - val_loss: 0.8817 - val_accuracy: 0.6068\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8146 - accuracy: 0.6704 - val_loss: 0.9904 - val_accuracy: 0.6239\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7682 - accuracy: 0.6926 - val_loss: 1.0049 - val_accuracy: 0.6068\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8193 - accuracy: 0.6630 - val_loss: 0.9331 - val_accuracy: 0.6239\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9184 - accuracy: 0.6259 - val_loss: 1.1664 - val_accuracy: 0.6410\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8477 - accuracy: 0.7000 - val_loss: 0.9126 - val_accuracy: 0.6410\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7748 - accuracy: 0.6889 - val_loss: 0.9370 - val_accuracy: 0.6581\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7430 - accuracy: 0.7222 - val_loss: 0.8656 - val_accuracy: 0.6496\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7473 - accuracy: 0.7037 - val_loss: 0.9106 - val_accuracy: 0.5983\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7595 - accuracy: 0.6444 - val_loss: 0.8830 - val_accuracy: 0.5812\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7752 - accuracy: 0.6667 - val_loss: 1.1177 - val_accuracy: 0.5897\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 58us/step - loss: 0.8484 - accuracy: 0.6630 - val_loss: 1.1132 - val_accuracy: 0.6838\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7950 - accuracy: 0.7037 - val_loss: 0.9372 - val_accuracy: 0.5812\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8172 - accuracy: 0.6630 - val_loss: 1.1329 - val_accuracy: 0.6410\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8622 - accuracy: 0.6741 - val_loss: 0.8725 - val_accuracy: 0.6410\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0373 - accuracy: 0.6741 - val_loss: 0.9533 - val_accuracy: 0.6752\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7895 - accuracy: 0.6815 - val_loss: 1.1521 - val_accuracy: 0.6410\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8439 - accuracy: 0.6815 - val_loss: 0.8741 - val_accuracy: 0.6410\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7456 - accuracy: 0.6963 - val_loss: 1.0482 - val_accuracy: 0.6752\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8297 - accuracy: 0.7000 - val_loss: 1.0181 - val_accuracy: 0.6752\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7392 - accuracy: 0.6963 - val_loss: 0.8704 - val_accuracy: 0.6325\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7485 - accuracy: 0.7000 - val_loss: 0.9317 - val_accuracy: 0.6667\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7917 - accuracy: 0.6778 - val_loss: 0.9188 - val_accuracy: 0.6325\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7989 - accuracy: 0.7037 - val_loss: 1.1701 - val_accuracy: 0.6581\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8254 - accuracy: 0.6889 - val_loss: 0.8840 - val_accuracy: 0.6154\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7577 - accuracy: 0.6778 - val_loss: 1.0285 - val_accuracy: 0.6667\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7927 - accuracy: 0.7000 - val_loss: 0.9268 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7899 - accuracy: 0.6556 - val_loss: 1.0042 - val_accuracy: 0.6667\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7887 - accuracy: 0.7000 - val_loss: 1.0357 - val_accuracy: 0.6667\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7624 - accuracy: 0.6815 - val_loss: 0.8943 - val_accuracy: 0.6068\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7623 - accuracy: 0.6741 - val_loss: 0.9991 - val_accuracy: 0.6581\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7714 - accuracy: 0.6778 - val_loss: 0.8927 - val_accuracy: 0.6410\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7407 - accuracy: 0.6815 - val_loss: 0.9900 - val_accuracy: 0.6667\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7555 - accuracy: 0.6852 - val_loss: 0.8915 - val_accuracy: 0.6068\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7329 - accuracy: 0.6963 - val_loss: 0.9059 - val_accuracy: 0.6752\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7362 - accuracy: 0.6926 - val_loss: 0.9352 - val_accuracy: 0.6667\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7443 - accuracy: 0.7000 - val_loss: 0.8902 - val_accuracy: 0.6581\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7320 - accuracy: 0.6815 - val_loss: 0.8879 - val_accuracy: 0.6581\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7262 - accuracy: 0.6889 - val_loss: 0.9128 - val_accuracy: 0.6752\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7401 - accuracy: 0.6852 - val_loss: 0.9131 - val_accuracy: 0.6581\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7677 - accuracy: 0.6926 - val_loss: 0.9291 - val_accuracy: 0.6410\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7701 - accuracy: 0.6926 - val_loss: 1.3328 - val_accuracy: 0.5812\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.6499 - accuracy: 0.6000 - val_loss: 3.8405 - val_accuracy: 0.5470\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 2.8580 - accuracy: 0.5852 - val_loss: 3.2605 - val_accuracy: 0.5470\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.9612 - accuracy: 0.5593 - val_loss: 1.6304 - val_accuracy: 0.4872\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.6264 - accuracy: 0.5370 - val_loss: 1.2680 - val_accuracy: 0.5897\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0698 - accuracy: 0.5556 - val_loss: 1.3711 - val_accuracy: 0.5556\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9071 - accuracy: 0.6259 - val_loss: 0.8795 - val_accuracy: 0.6154\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8585 - accuracy: 0.6593 - val_loss: 1.0036 - val_accuracy: 0.5726\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8447 - accuracy: 0.6222 - val_loss: 1.0538 - val_accuracy: 0.6838\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7978 - accuracy: 0.6778 - val_loss: 0.9511 - val_accuracy: 0.6496\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9728 - accuracy: 0.6519 - val_loss: 1.3198 - val_accuracy: 0.5726\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0988 - accuracy: 0.6333 - val_loss: 1.1434 - val_accuracy: 0.5726\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8908 - accuracy: 0.6778 - val_loss: 0.9725 - val_accuracy: 0.6410\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8958 - accuracy: 0.6222 - val_loss: 1.0240 - val_accuracy: 0.6752\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9003 - accuracy: 0.6556 - val_loss: 0.9273 - val_accuracy: 0.5897\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8689 - accuracy: 0.6481 - val_loss: 0.9349 - val_accuracy: 0.6752\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7670 - accuracy: 0.6926 - val_loss: 0.8801 - val_accuracy: 0.6923\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7818 - accuracy: 0.6926 - val_loss: 0.9269 - val_accuracy: 0.5897\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8501 - accuracy: 0.6481 - val_loss: 1.0539 - val_accuracy: 0.6581\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8611 - accuracy: 0.6926 - val_loss: 0.9897 - val_accuracy: 0.6581\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8471 - accuracy: 0.6778 - val_loss: 0.9655 - val_accuracy: 0.6581\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9531 - accuracy: 0.6444 - val_loss: 1.2306 - val_accuracy: 0.5726\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9402 - accuracy: 0.6481 - val_loss: 0.9094 - val_accuracy: 0.6068\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8036 - accuracy: 0.6741 - val_loss: 1.2474 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c03e240>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 93us/step\n",
      "over-sampling test accuracy: 68.38%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 2, 2, 1,\n",
       "       0, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 0, 0, 0, 1,\n",
       "       2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 2, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1,\n",
       "       1, 0, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 0, 0, 1, 1, 0, 2, 1, 2,\n",
       "       0, 1, 2, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0    BCH-SA-11     2     2\n",
       "1       NRS161     1     2\n",
       "2    BCH-SA-14     2     2\n",
       "3    BCH-SA-11     2     2\n",
       "4     CFBRSa49     1     0\n",
       "..         ...   ...   ...\n",
       "112     NRS064     2     2\n",
       "113     NRS266     2     2\n",
       "114     NRS222     0     0\n",
       "115       GA27     2     0\n",
       "116      GA984     1     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.974256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>0.974217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244668</td>\n",
       "      <td>0.097915</td>\n",
       "      <td>0.657416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.974256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.393953</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>0.379088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.990461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.127922</td>\n",
       "      <td>0.046466</td>\n",
       "      <td>0.825612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.696836</td>\n",
       "      <td>0.255523</td>\n",
       "      <td>0.047641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.393953</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>0.379088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.380424</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.618946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.023214  0.002530  0.974256\n",
       "1    0.020274  0.005509  0.974217\n",
       "2    0.244668  0.097915  0.657416\n",
       "3    0.023214  0.002530  0.974256\n",
       "4    0.393953  0.226959  0.379088\n",
       "..        ...       ...       ...\n",
       "112  0.004061  0.005477  0.990461\n",
       "113  0.127922  0.046466  0.825612\n",
       "114  0.696836  0.255523  0.047641\n",
       "115  0.393953  0.226959  0.379088\n",
       "116  0.380424  0.000630  0.618946\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 389us/step - loss: 22.6280 - accuracy: 0.3593 - val_loss: 14.0377 - val_accuracy: 0.3846\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 18.6573 - accuracy: 0.3556 - val_loss: 11.4446 - val_accuracy: 0.3846\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 14.8883 - accuracy: 0.3556 - val_loss: 8.9187 - val_accuracy: 0.3846\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 10.6455 - accuracy: 0.3556 - val_loss: 6.4705 - val_accuracy: 0.3846\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 6.8513 - accuracy: 0.3741 - val_loss: 3.9568 - val_accuracy: 0.4444\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 2.8718 - accuracy: 0.3370 - val_loss: 3.0208 - val_accuracy: 0.4103\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 2.3636 - accuracy: 0.3667 - val_loss: 3.1598 - val_accuracy: 0.3846\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 2.3671 - accuracy: 0.3556 - val_loss: 2.7347 - val_accuracy: 0.3590\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 2.1183 - accuracy: 0.3667 - val_loss: 2.2706 - val_accuracy: 0.3504\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.9590 - accuracy: 0.3556 - val_loss: 1.9023 - val_accuracy: 0.3333\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.6091 - accuracy: 0.3741 - val_loss: 1.6200 - val_accuracy: 0.2650\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.3117 - accuracy: 0.3370 - val_loss: 1.3844 - val_accuracy: 0.2821\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.4851 - accuracy: 0.3407 - val_loss: 1.2917 - val_accuracy: 0.2906\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.1694 - accuracy: 0.3667 - val_loss: 1.2466 - val_accuracy: 0.3761\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.2120 - accuracy: 0.3704 - val_loss: 1.1323 - val_accuracy: 0.3761\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.1286 - accuracy: 0.4074 - val_loss: 1.3533 - val_accuracy: 0.4017\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.3261 - accuracy: 0.4185 - val_loss: 1.8142 - val_accuracy: 0.3248\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.4990 - accuracy: 0.4481 - val_loss: 1.5658 - val_accuracy: 0.4701\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.5005 - accuracy: 0.4481 - val_loss: 1.3824 - val_accuracy: 0.4615\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.3845 - accuracy: 0.4370 - val_loss: 1.7252 - val_accuracy: 0.4188\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.3961 - accuracy: 0.4259 - val_loss: 1.6088 - val_accuracy: 0.5214\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.3722 - accuracy: 0.4630 - val_loss: 1.3557 - val_accuracy: 0.5812\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.1584 - accuracy: 0.5111 - val_loss: 1.1816 - val_accuracy: 0.5128\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0853 - accuracy: 0.4741 - val_loss: 1.0661 - val_accuracy: 0.5385\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0764 - accuracy: 0.4926 - val_loss: 1.0820 - val_accuracy: 0.5470\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0632 - accuracy: 0.5296 - val_loss: 1.1768 - val_accuracy: 0.5726\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0612 - accuracy: 0.5815 - val_loss: 1.0821 - val_accuracy: 0.5470\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0308 - accuracy: 0.5185 - val_loss: 1.0280 - val_accuracy: 0.5556\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0259 - accuracy: 0.5111 - val_loss: 1.0545 - val_accuracy: 0.5897\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0411 - accuracy: 0.5407 - val_loss: 1.1119 - val_accuracy: 0.5726\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0302 - accuracy: 0.5370 - val_loss: 1.0325 - val_accuracy: 0.5641\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0154 - accuracy: 0.5111 - val_loss: 1.0186 - val_accuracy: 0.5556\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0240 - accuracy: 0.5185 - val_loss: 1.0053 - val_accuracy: 0.5726\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0128 - accuracy: 0.5074 - val_loss: 1.0420 - val_accuracy: 0.5812\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 1.0239 - accuracy: 0.5037 - val_loss: 1.0065 - val_accuracy: 0.5726\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 1.0403 - accuracy: 0.4926 - val_loss: 0.9980 - val_accuracy: 0.5812\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 1.0061 - accuracy: 0.5222 - val_loss: 1.0350 - val_accuracy: 0.5556\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0046 - accuracy: 0.5222 - val_loss: 0.9929 - val_accuracy: 0.5983\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0248 - accuracy: 0.5222 - val_loss: 1.1075 - val_accuracy: 0.5556\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0664 - accuracy: 0.5481 - val_loss: 1.0408 - val_accuracy: 0.5556\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9954 - accuracy: 0.5222 - val_loss: 0.9801 - val_accuracy: 0.5641\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0061 - accuracy: 0.5037 - val_loss: 1.0367 - val_accuracy: 0.5812\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9818 - accuracy: 0.5444 - val_loss: 0.9687 - val_accuracy: 0.5812\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0008 - accuracy: 0.5259 - val_loss: 1.0220 - val_accuracy: 0.5812\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9971 - accuracy: 0.5111 - val_loss: 1.0368 - val_accuracy: 0.5812\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9987 - accuracy: 0.5074 - val_loss: 0.9609 - val_accuracy: 0.5812\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9826 - accuracy: 0.5111 - val_loss: 0.9826 - val_accuracy: 0.5812\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9869 - accuracy: 0.5111 - val_loss: 0.9674 - val_accuracy: 0.5641\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9714 - accuracy: 0.5296 - val_loss: 0.9820 - val_accuracy: 0.5641\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9789 - accuracy: 0.5407 - val_loss: 0.9640 - val_accuracy: 0.6239\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9670 - accuracy: 0.5741 - val_loss: 0.9535 - val_accuracy: 0.5641\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9813 - accuracy: 0.5296 - val_loss: 0.9672 - val_accuracy: 0.5641\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9701 - accuracy: 0.5148 - val_loss: 0.9616 - val_accuracy: 0.5726\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0261 - accuracy: 0.5000 - val_loss: 0.9847 - val_accuracy: 0.5812\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9853 - accuracy: 0.5259 - val_loss: 1.0785 - val_accuracy: 0.5556\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0013 - accuracy: 0.5407 - val_loss: 0.9450 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9746 - accuracy: 0.5370 - val_loss: 0.9874 - val_accuracy: 0.5726\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9688 - accuracy: 0.5259 - val_loss: 1.0037 - val_accuracy: 0.5897\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9676 - accuracy: 0.5407 - val_loss: 0.9346 - val_accuracy: 0.5726\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9476 - accuracy: 0.5444 - val_loss: 0.9381 - val_accuracy: 0.5726\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9512 - accuracy: 0.5407 - val_loss: 0.9486 - val_accuracy: 0.5983\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9638 - accuracy: 0.5630 - val_loss: 0.9628 - val_accuracy: 0.5983\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9503 - accuracy: 0.5889 - val_loss: 0.9274 - val_accuracy: 0.6068\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9536 - accuracy: 0.5259 - val_loss: 0.9534 - val_accuracy: 0.5812\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9479 - accuracy: 0.5370 - val_loss: 0.9286 - val_accuracy: 0.5812\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9421 - accuracy: 0.5407 - val_loss: 0.9223 - val_accuracy: 0.5556\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9468 - accuracy: 0.5333 - val_loss: 0.9330 - val_accuracy: 0.5812\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9425 - accuracy: 0.5407 - val_loss: 0.9217 - val_accuracy: 0.5897\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9386 - accuracy: 0.5556 - val_loss: 0.9203 - val_accuracy: 0.5726\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9346 - accuracy: 0.5370 - val_loss: 0.9427 - val_accuracy: 0.5812\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9392 - accuracy: 0.5407 - val_loss: 0.9285 - val_accuracy: 0.5812\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9368 - accuracy: 0.5630 - val_loss: 0.9365 - val_accuracy: 0.5983\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9511 - accuracy: 0.5630 - val_loss: 0.9045 - val_accuracy: 0.6325\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9888 - accuracy: 0.53 - 0s 77us/step - loss: 0.9771 - accuracy: 0.5667 - val_loss: 1.0352 - val_accuracy: 0.6496\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0310 - accuracy: 0.5778 - val_loss: 1.1009 - val_accuracy: 0.6239\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9911 - accuracy: 0.5444 - val_loss: 0.9060 - val_accuracy: 0.5983\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9504 - accuracy: 0.5741 - val_loss: 0.9625 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9741 - accuracy: 0.5519 - val_loss: 0.9208 - val_accuracy: 0.5726\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9305 - accuracy: 0.5222 - val_loss: 0.9124 - val_accuracy: 0.5897\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9352 - accuracy: 0.5407 - val_loss: 0.9436 - val_accuracy: 0.5726\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9459 - accuracy: 0.5852 - val_loss: 0.9455 - val_accuracy: 0.6154\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9267 - accuracy: 0.5815 - val_loss: 0.8980 - val_accuracy: 0.6068\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9199 - accuracy: 0.5704 - val_loss: 0.9026 - val_accuracy: 0.5812\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9215 - accuracy: 0.5407 - val_loss: 0.9044 - val_accuracy: 0.5556\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9168 - accuracy: 0.5148 - val_loss: 0.9139 - val_accuracy: 0.5897\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9483 - accuracy: 0.5852 - val_loss: 0.9178 - val_accuracy: 0.6154\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9289 - accuracy: 0.5667 - val_loss: 0.9169 - val_accuracy: 0.6154\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9365 - accuracy: 0.5963 - val_loss: 0.9924 - val_accuracy: 0.6410\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9382 - accuracy: 0.5630 - val_loss: 0.8898 - val_accuracy: 0.5470\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9277 - accuracy: 0.5556 - val_loss: 0.9505 - val_accuracy: 0.6154\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9429 - accuracy: 0.6000 - val_loss: 0.8826 - val_accuracy: 0.6068\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9136 - accuracy: 0.5778 - val_loss: 0.8939 - val_accuracy: 0.6068\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9059 - accuracy: 0.5778 - val_loss: 0.8916 - val_accuracy: 0.5897\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9031 - accuracy: 0.5741 - val_loss: 0.8774 - val_accuracy: 0.5812\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9053 - accuracy: 0.5333 - val_loss: 0.9041 - val_accuracy: 0.6068\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9354 - accuracy: 0.5519 - val_loss: 0.8874 - val_accuracy: 0.5897\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9157 - accuracy: 0.5296 - val_loss: 0.8771 - val_accuracy: 0.5983\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9161 - accuracy: 0.5259 - val_loss: 0.8976 - val_accuracy: 0.6239\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9039 - accuracy: 0.5481 - val_loss: 0.8784 - val_accuracy: 0.5983\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9027 - accuracy: 0.5259 - val_loss: 0.9225 - val_accuracy: 0.6239\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9667 - accuracy: 0.5963 - val_loss: 0.9523 - val_accuracy: 0.6068\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9450 - accuracy: 0.5815 - val_loss: 0.9623 - val_accuracy: 0.6068\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9637 - accuracy: 0.6111 - val_loss: 0.9297 - val_accuracy: 0.5983\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9205 - accuracy: 0.5630 - val_loss: 0.9032 - val_accuracy: 0.5897\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9874 - accuracy: 0.5741 - val_loss: 0.9015 - val_accuracy: 0.6410\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.2603 - accuracy: 0.5778 - val_loss: 0.9339 - val_accuracy: 0.6154\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9993 - accuracy: 0.6000 - val_loss: 1.2328 - val_accuracy: 0.6581\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0611 - accuracy: 0.6222 - val_loss: 0.9566 - val_accuracy: 0.6239\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8996 - accuracy: 0.5667 - val_loss: 0.9390 - val_accuracy: 0.6154\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9688 - accuracy: 0.5778 - val_loss: 1.2725 - val_accuracy: 0.6154\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0825 - accuracy: 0.6074 - val_loss: 1.0398 - val_accuracy: 0.5641\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0593 - accuracy: 0.5074 - val_loss: 0.9655 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0637 - accuracy: 0.5963 - val_loss: 1.0996 - val_accuracy: 0.5726\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9701 - accuracy: 0.5556 - val_loss: 0.9102 - val_accuracy: 0.5983\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9457 - accuracy: 0.5259 - val_loss: 1.2000 - val_accuracy: 0.6325\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0702 - accuracy: 0.6111 - val_loss: 1.1222 - val_accuracy: 0.6239\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9496 - accuracy: 0.5444 - val_loss: 0.8690 - val_accuracy: 0.5897\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9523 - accuracy: 0.5481 - val_loss: 1.0635 - val_accuracy: 0.5897\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9812 - accuracy: 0.5815 - val_loss: 0.9889 - val_accuracy: 0.5983\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9362 - accuracy: 0.5222 - val_loss: 0.8979 - val_accuracy: 0.5726\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9525 - accuracy: 0.5593 - val_loss: 0.9766 - val_accuracy: 0.5726\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9370 - accuracy: 0.6111 - val_loss: 0.8827 - val_accuracy: 0.5983\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9012 - accuracy: 0.5852 - val_loss: 0.8994 - val_accuracy: 0.6239\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9038 - accuracy: 0.5926 - val_loss: 0.8884 - val_accuracy: 0.5983\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9091 - accuracy: 0.6000 - val_loss: 0.9085 - val_accuracy: 0.6410\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9087 - accuracy: 0.6000 - val_loss: 0.9228 - val_accuracy: 0.6154\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8908 - accuracy: 0.5963 - val_loss: 0.8498 - val_accuracy: 0.6239\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8788 - accuracy: 0.5963 - val_loss: 0.9203 - val_accuracy: 0.6496\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9463 - accuracy: 0.6259 - val_loss: 0.9883 - val_accuracy: 0.6410\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9231 - accuracy: 0.5889 - val_loss: 0.8551 - val_accuracy: 0.6325\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8899 - accuracy: 0.6111 - val_loss: 0.9067 - val_accuracy: 0.6154\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9078 - accuracy: 0.6074 - val_loss: 0.9038 - val_accuracy: 0.6239\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8741 - accuracy: 0.6074 - val_loss: 0.8479 - val_accuracy: 0.6239\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8748 - accuracy: 0.6074 - val_loss: 0.8889 - val_accuracy: 0.6496\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8895 - accuracy: 0.6222 - val_loss: 0.8504 - val_accuracy: 0.6239\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8791 - accuracy: 0.6000 - val_loss: 0.8782 - val_accuracy: 0.6496\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8948 - accuracy: 0.5926 - val_loss: 0.8512 - val_accuracy: 0.6239\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9210 - accuracy: 0.5852 - val_loss: 0.9664 - val_accuracy: 0.5897\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9558 - accuracy: 0.5741 - val_loss: 0.9416 - val_accuracy: 0.6239\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9171 - accuracy: 0.5370 - val_loss: 0.8735 - val_accuracy: 0.5556\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9258 - accuracy: 0.5407 - val_loss: 0.9780 - val_accuracy: 0.6154\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8794 - accuracy: 0.6037 - val_loss: 0.8797 - val_accuracy: 0.6154\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9639 - accuracy: 0.5741 - val_loss: 0.9562 - val_accuracy: 0.6325\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8958 - accuracy: 0.6037 - val_loss: 0.8530 - val_accuracy: 0.6068\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8645 - accuracy: 0.5889 - val_loss: 0.8598 - val_accuracy: 0.6239\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8686 - accuracy: 0.6037 - val_loss: 0.8589 - val_accuracy: 0.6154\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8699 - accuracy: 0.6148 - val_loss: 0.8589 - val_accuracy: 0.6154\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8786 - accuracy: 0.6407 - val_loss: 0.8625 - val_accuracy: 0.6410\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8608 - accuracy: 0.6074 - val_loss: 0.8487 - val_accuracy: 0.6239\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8654 - accuracy: 0.6037 - val_loss: 0.8484 - val_accuracy: 0.6410\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9607 - accuracy: 0.5741 - val_loss: 0.9339 - val_accuracy: 0.6068\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9559 - accuracy: 0.6148 - val_loss: 0.9999 - val_accuracy: 0.5983\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9291 - accuracy: 0.6037 - val_loss: 0.8476 - val_accuracy: 0.6410\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8792 - accuracy: 0.6000 - val_loss: 1.0333 - val_accuracy: 0.6239\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9394 - accuracy: 0.6074 - val_loss: 0.9495 - val_accuracy: 0.6581\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8933 - accuracy: 0.6222 - val_loss: 0.8443 - val_accuracy: 0.6325\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8601 - accuracy: 0.6185 - val_loss: 0.9006 - val_accuracy: 0.6581\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8764 - accuracy: 0.6000 - val_loss: 0.8546 - val_accuracy: 0.6239\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1402 - accuracy: 0.5889 - val_loss: 1.1417 - val_accuracy: 0.6068\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1149 - accuracy: 0.6111 - val_loss: 1.2878 - val_accuracy: 0.6325\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0137 - accuracy: 0.6000 - val_loss: 0.9415 - val_accuracy: 0.5812\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9450 - accuracy: 0.5370 - val_loss: 1.0964 - val_accuracy: 0.5641\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1192 - accuracy: 0.5815 - val_loss: 1.2222 - val_accuracy: 0.6068\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9870 - accuracy: 0.5963 - val_loss: 0.9725 - val_accuracy: 0.5897\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9474 - accuracy: 0.5852 - val_loss: 0.9911 - val_accuracy: 0.5726\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9563 - accuracy: 0.6111 - val_loss: 0.9242 - val_accuracy: 0.5897\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8721 - accuracy: 0.6148 - val_loss: 0.9075 - val_accuracy: 0.6068\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9032 - accuracy: 0.5889 - val_loss: 0.9608 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9130 - accuracy: 0.5963 - val_loss: 0.8504 - val_accuracy: 0.6154\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8597 - accuracy: 0.6148 - val_loss: 0.9139 - val_accuracy: 0.6154\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8704 - accuracy: 0.6185 - val_loss: 0.8491 - val_accuracy: 0.6325\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8617 - accuracy: 0.6111 - val_loss: 0.8346 - val_accuracy: 0.6325\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8538 - accuracy: 0.6296 - val_loss: 0.8512 - val_accuracy: 0.6496\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8493 - accuracy: 0.6259 - val_loss: 0.8435 - val_accuracy: 0.6325\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8503 - accuracy: 0.6148 - val_loss: 0.8878 - val_accuracy: 0.6667\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8623 - accuracy: 0.6407 - val_loss: 0.8573 - val_accuracy: 0.6496\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8459 - accuracy: 0.6222 - val_loss: 0.8368 - val_accuracy: 0.6325\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8515 - accuracy: 0.6296 - val_loss: 0.8320 - val_accuracy: 0.6496\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9433 - accuracy: 0.5778 - val_loss: 0.9480 - val_accuracy: 0.6581\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8731 - accuracy: 0.6111 - val_loss: 0.8589 - val_accuracy: 0.6581\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8888 - accuracy: 0.6259 - val_loss: 1.1534 - val_accuracy: 0.6410\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0239 - accuracy: 0.6407 - val_loss: 1.1005 - val_accuracy: 0.6410\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9282 - accuracy: 0.5926 - val_loss: 0.8591 - val_accuracy: 0.6325\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9134 - accuracy: 0.6037 - val_loss: 0.9405 - val_accuracy: 0.5726\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9027 - accuracy: 0.6148 - val_loss: 0.8531 - val_accuracy: 0.6325\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8481 - accuracy: 0.6185 - val_loss: 0.8994 - val_accuracy: 0.6496\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8815 - accuracy: 0.6222 - val_loss: 0.8633 - val_accuracy: 0.6239\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8477 - accuracy: 0.6259 - val_loss: 0.8589 - val_accuracy: 0.6410\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8511 - accuracy: 0.6111 - val_loss: 0.8751 - val_accuracy: 0.6581\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8470 - accuracy: 0.6296 - val_loss: 0.8295 - val_accuracy: 0.6410\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8466 - accuracy: 0.6148 - val_loss: 0.8674 - val_accuracy: 0.6581\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8478 - accuracy: 0.6111 - val_loss: 0.8399 - val_accuracy: 0.6496\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8429 - accuracy: 0.6296 - val_loss: 0.8466 - val_accuracy: 0.6496\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8399 - accuracy: 0.6259 - val_loss: 0.8453 - val_accuracy: 0.6581\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8357 - accuracy: 0.6333 - val_loss: 0.8350 - val_accuracy: 0.6410\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8397 - accuracy: 0.6185 - val_loss: 0.9043 - val_accuracy: 0.6667\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9050 - accuracy: 0.6481 - val_loss: 0.9270 - val_accuracy: 0.6581\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8384 - accuracy: 0.6296 - val_loss: 0.8358 - val_accuracy: 0.6410\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8654 - accuracy: 0.6370 - val_loss: 1.0382 - val_accuracy: 0.6752\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9519 - accuracy: 0.6556 - val_loss: 0.9339 - val_accuracy: 0.6154\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9068 - accuracy: 0.5852 - val_loss: 0.9463 - val_accuracy: 0.6068\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9180 - accuracy: 0.6111 - val_loss: 0.9710 - val_accuracy: 0.6325\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8688 - accuracy: 0.6296 - val_loss: 0.8746 - val_accuracy: 0.6154\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9598 - accuracy: 0.5889 - val_loss: 1.0324 - val_accuracy: 0.6068\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9854 - accuracy: 0.6222 - val_loss: 1.0217 - val_accuracy: 0.6239\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9071 - accuracy: 0.6111 - val_loss: 0.8657 - val_accuracy: 0.6154\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8825 - accuracy: 0.5926 - val_loss: 0.9092 - val_accuracy: 0.6239\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9170 - accuracy: 0.6185 - val_loss: 0.8803 - val_accuracy: 0.6154\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9262 - accuracy: 0.6222 - val_loss: 1.0400 - val_accuracy: 0.6667\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9648 - accuracy: 0.6407 - val_loss: 1.1303 - val_accuracy: 0.6410\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9329 - accuracy: 0.6111 - val_loss: 0.8382 - val_accuracy: 0.6325\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9006 - accuracy: 0.6111 - val_loss: 1.0027 - val_accuracy: 0.6239\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9571 - accuracy: 0.6333 - val_loss: 1.1166 - val_accuracy: 0.6239\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9395 - accuracy: 0.6148 - val_loss: 0.9270 - val_accuracy: 0.6496\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8620 - accuracy: 0.6333 - val_loss: 0.8448 - val_accuracy: 0.6496\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8341 - accuracy: 0.6370 - val_loss: 0.9362 - val_accuracy: 0.6581\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8724 - accuracy: 0.6222 - val_loss: 0.8914 - val_accuracy: 0.6154\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8508 - accuracy: 0.6148 - val_loss: 0.8490 - val_accuracy: 0.6325\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9006 - accuracy: 0.6370 - val_loss: 0.9469 - val_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8625 - accuracy: 0.6074 - val_loss: 0.8704 - val_accuracy: 0.6068\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9080 - accuracy: 0.6000 - val_loss: 0.9538 - val_accuracy: 0.6154\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9102 - accuracy: 0.6148 - val_loss: 0.8840 - val_accuracy: 0.6325\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8853 - accuracy: 0.6222 - val_loss: 0.9755 - val_accuracy: 0.6325\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8308 - accuracy: 0.6222 - val_loss: 0.8390 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8586 - accuracy: 0.6370 - val_loss: 0.9043 - val_accuracy: 0.6496\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8558 - accuracy: 0.6519 - val_loss: 0.8692 - val_accuracy: 0.6667\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8334 - accuracy: 0.6407 - val_loss: 0.8489 - val_accuracy: 0.6667\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8343 - accuracy: 0.6370 - val_loss: 0.8318 - val_accuracy: 0.6410\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8238 - accuracy: 0.6148 - val_loss: 0.8868 - val_accuracy: 0.6667\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8598 - accuracy: 0.6259 - val_loss: 0.8614 - val_accuracy: 0.6496\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8379 - accuracy: 0.6185 - val_loss: 0.9394 - val_accuracy: 0.6752\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9057 - accuracy: 0.6481 - val_loss: 1.0177 - val_accuracy: 0.6752\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8653 - accuracy: 0.6407 - val_loss: 0.8430 - val_accuracy: 0.6068\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8445 - accuracy: 0.6037 - val_loss: 0.8618 - val_accuracy: 0.6496\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8306 - accuracy: 0.6296 - val_loss: 0.8245 - val_accuracy: 0.6325\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8215 - accuracy: 0.6222 - val_loss: 0.8587 - val_accuracy: 0.6496\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8226 - accuracy: 0.6259 - val_loss: 0.8423 - val_accuracy: 0.6581\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8233 - accuracy: 0.6222 - val_loss: 0.8348 - val_accuracy: 0.6496\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8271 - accuracy: 0.6333 - val_loss: 0.8257 - val_accuracy: 0.6410\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9100 - accuracy: 0.6074 - val_loss: 1.0132 - val_accuracy: 0.6752\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0172 - accuracy: 0.6481 - val_loss: 1.3214 - val_accuracy: 0.6581\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0256 - accuracy: 0.6630 - val_loss: 0.9954 - val_accuracy: 0.6325\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9289 - accuracy: 0.5926 - val_loss: 0.8554 - val_accuracy: 0.6239\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8754 - accuracy: 0.6296 - val_loss: 0.8942 - val_accuracy: 0.6581\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8261 - accuracy: 0.6407 - val_loss: 0.8734 - val_accuracy: 0.6068\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8912 - accuracy: 0.6185 - val_loss: 1.0480 - val_accuracy: 0.6068\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9566 - accuracy: 0.6222 - val_loss: 0.8725 - val_accuracy: 0.6068\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8498 - accuracy: 0.6148 - val_loss: 1.0396 - val_accuracy: 0.6068\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9753 - accuracy: 0.6259 - val_loss: 1.1506 - val_accuracy: 0.6410\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9268 - accuracy: 0.6370 - val_loss: 0.8262 - val_accuracy: 0.6325\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8904 - accuracy: 0.5852 - val_loss: 0.9234 - val_accuracy: 0.6581\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9138 - accuracy: 0.6444 - val_loss: 0.9630 - val_accuracy: 0.6667\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9241 - accuracy: 0.5889 - val_loss: 1.0353 - val_accuracy: 0.6667\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1616 - accuracy: 0.6148 - val_loss: 2.4224 - val_accuracy: 0.6154\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 1.8200 - accuracy: 0.6111 - val_loss: 2.3954 - val_accuracy: 0.6667\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.8101 - accuracy: 0.6000 - val_loss: 2.1626 - val_accuracy: 0.6752\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.5115 - accuracy: 0.6185 - val_loss: 1.6151 - val_accuracy: 0.6410\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0880 - accuracy: 0.5815 - val_loss: 0.9402 - val_accuracy: 0.5556\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9569 - accuracy: 0.5593 - val_loss: 0.9242 - val_accuracy: 0.5897\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9668 - accuracy: 0.6037 - val_loss: 1.1356 - val_accuracy: 0.6325\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9622 - accuracy: 0.6370 - val_loss: 1.1315 - val_accuracy: 0.6154\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9074 - accuracy: 0.6148 - val_loss: 0.8666 - val_accuracy: 0.6325\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9992 - accuracy: 0.6074 - val_loss: 0.8616 - val_accuracy: 0.6325\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8736 - accuracy: 0.6333 - val_loss: 1.0145 - val_accuracy: 0.6581\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8884 - accuracy: 0.6185 - val_loss: 0.9628 - val_accuracy: 0.6581\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8637 - accuracy: 0.6444 - val_loss: 0.8455 - val_accuracy: 0.6496\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8397 - accuracy: 0.6222 - val_loss: 0.8823 - val_accuracy: 0.6410\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8357 - accuracy: 0.6333 - val_loss: 0.9136 - val_accuracy: 0.6496\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8257 - accuracy: 0.6259 - val_loss: 0.8450 - val_accuracy: 0.6496\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8220 - accuracy: 0.6481 - val_loss: 0.8409 - val_accuracy: 0.6325\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8116 - accuracy: 0.6519 - val_loss: 0.8478 - val_accuracy: 0.6496\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8190 - accuracy: 0.6222 - val_loss: 0.8428 - val_accuracy: 0.6496\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8100 - accuracy: 0.6296 - val_loss: 0.8325 - val_accuracy: 0.6496\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8095 - accuracy: 0.6296 - val_loss: 0.8360 - val_accuracy: 0.6581\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8096 - accuracy: 0.6296 - val_loss: 0.8401 - val_accuracy: 0.6581\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8207 - accuracy: 0.6444 - val_loss: 0.8261 - val_accuracy: 0.6838\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8877 - accuracy: 0.6222 - val_loss: 0.9202 - val_accuracy: 0.6752\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8564 - accuracy: 0.6481 - val_loss: 1.0094 - val_accuracy: 0.6667\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8680 - accuracy: 0.6333 - val_loss: 0.8574 - val_accuracy: 0.6581\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8325 - accuracy: 0.6444 - val_loss: 0.8178 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8199 - accuracy: 0.6667 - val_loss: 0.9458 - val_accuracy: 0.6752\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8626 - accuracy: 0.6593 - val_loss: 0.8854 - val_accuracy: 0.6581\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8264 - accuracy: 0.6259 - val_loss: 0.8405 - val_accuracy: 0.6581\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8342 - accuracy: 0.6481 - val_loss: 0.8589 - val_accuracy: 0.6496\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8040 - accuracy: 0.6407 - val_loss: 0.8487 - val_accuracy: 0.6325\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8375 - accuracy: 0.6333 - val_loss: 0.8895 - val_accuracy: 0.6496\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8203 - accuracy: 0.6556 - val_loss: 0.8193 - val_accuracy: 0.6581\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8057 - accuracy: 0.6370 - val_loss: 0.8285 - val_accuracy: 0.6581\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7991 - accuracy: 0.6370 - val_loss: 0.8394 - val_accuracy: 0.6667\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8116 - accuracy: 0.6481 - val_loss: 0.8143 - val_accuracy: 0.6496\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8109 - accuracy: 0.6444 - val_loss: 0.8171 - val_accuracy: 0.6667\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8104 - accuracy: 0.6259 - val_loss: 0.9312 - val_accuracy: 0.6752\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8578 - accuracy: 0.6519 - val_loss: 0.9129 - val_accuracy: 0.6581\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8113 - accuracy: 0.6222 - val_loss: 0.8349 - val_accuracy: 0.6496\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8497 - accuracy: 0.6519 - val_loss: 0.9057 - val_accuracy: 0.6325\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8367 - accuracy: 0.6630 - val_loss: 0.8837 - val_accuracy: 0.6667\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8358 - accuracy: 0.6148 - val_loss: 0.8545 - val_accuracy: 0.6581\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8251 - accuracy: 0.6481 - val_loss: 0.8326 - val_accuracy: 0.6581\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8046 - accuracy: 0.6481 - val_loss: 0.8154 - val_accuracy: 0.6496\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8041 - accuracy: 0.6407 - val_loss: 0.8191 - val_accuracy: 0.6752\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7950 - accuracy: 0.6667 - val_loss: 0.8303 - val_accuracy: 0.6667\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7947 - accuracy: 0.6630 - val_loss: 0.8276 - val_accuracy: 0.6667\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7962 - accuracy: 0.6407 - val_loss: 0.8079 - val_accuracy: 0.6752\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8182 - accuracy: 0.6407 - val_loss: 0.9094 - val_accuracy: 0.6752\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8343 - accuracy: 0.6556 - val_loss: 0.8302 - val_accuracy: 0.6752\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8426 - accuracy: 0.6333 - val_loss: 0.9317 - val_accuracy: 0.6752\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8519 - accuracy: 0.6667 - val_loss: 0.9184 - val_accuracy: 0.6752\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8119 - accuracy: 0.6481 - val_loss: 0.8332 - val_accuracy: 0.6667\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8455 - accuracy: 0.6481 - val_loss: 0.9644 - val_accuracy: 0.6838\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8620 - accuracy: 0.6667 - val_loss: 0.8595 - val_accuracy: 0.6838\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9017 - accuracy: 0.6296 - val_loss: 0.8792 - val_accuracy: 0.6838\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9170 - accuracy: 0.6704 - val_loss: 1.1488 - val_accuracy: 0.6752\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9326 - accuracy: 0.6407 - val_loss: 0.9363 - val_accuracy: 0.6239\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8089 - accuracy: 0.6370 - val_loss: 0.8372 - val_accuracy: 0.6239\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8267 - accuracy: 0.6667 - val_loss: 0.8726 - val_accuracy: 0.6410\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8515 - accuracy: 0.6222 - val_loss: 0.8924 - val_accuracy: 0.6667\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8551 - accuracy: 0.6519 - val_loss: 0.8691 - val_accuracy: 0.6068\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8352 - accuracy: 0.6333 - val_loss: 0.9032 - val_accuracy: 0.6154\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8236 - accuracy: 0.6000 - val_loss: 0.8428 - val_accuracy: 0.6496\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7990 - accuracy: 0.6704 - val_loss: 0.8204 - val_accuracy: 0.6667\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7978 - accuracy: 0.6667 - val_loss: 0.8651 - val_accuracy: 0.6581\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8063 - accuracy: 0.6519 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8202 - accuracy: 0.6222 - val_loss: 0.8447 - val_accuracy: 0.6752\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8252 - accuracy: 0.6519 - val_loss: 0.8519 - val_accuracy: 0.6667\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8386 - accuracy: 0.6222 - val_loss: 0.8206 - val_accuracy: 0.6496\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7993 - accuracy: 0.6556 - val_loss: 0.9607 - val_accuracy: 0.6752\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8391 - accuracy: 0.6630 - val_loss: 0.8609 - val_accuracy: 0.6667\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7891 - accuracy: 0.6667 - val_loss: 0.8324 - val_accuracy: 0.6496\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8267 - accuracy: 0.6519 - val_loss: 0.8587 - val_accuracy: 0.6410\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8067 - accuracy: 0.6519 - val_loss: 0.8773 - val_accuracy: 0.6581\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8695 - accuracy: 0.6444 - val_loss: 0.9570 - val_accuracy: 0.6667\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8094 - accuracy: 0.6519 - val_loss: 0.8763 - val_accuracy: 0.6496\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9222 - accuracy: 0.6259 - val_loss: 0.9658 - val_accuracy: 0.6838\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8326 - accuracy: 0.6593 - val_loss: 0.8094 - val_accuracy: 0.6838\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8439 - accuracy: 0.6333 - val_loss: 0.9763 - val_accuracy: 0.6325\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9076 - accuracy: 0.6259 - val_loss: 0.9915 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8853 - accuracy: 0.6148 - val_loss: 0.8669 - val_accuracy: 0.6581\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8589 - accuracy: 0.6444 - val_loss: 0.9313 - val_accuracy: 0.6068\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8795 - accuracy: 0.6370 - val_loss: 0.8428 - val_accuracy: 0.6581\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8180 - accuracy: 0.6259 - val_loss: 0.9123 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8457 - accuracy: 0.6519 - val_loss: 0.9178 - val_accuracy: 0.6239\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8468 - accuracy: 0.6296 - val_loss: 0.8122 - val_accuracy: 0.6410\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7885 - accuracy: 0.6370 - val_loss: 0.8636 - val_accuracy: 0.6667\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8049 - accuracy: 0.6333 - val_loss: 0.8059 - val_accuracy: 0.6667\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8240 - accuracy: 0.6481 - val_loss: 0.8887 - val_accuracy: 0.6239\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8350 - accuracy: 0.6481 - val_loss: 0.8350 - val_accuracy: 0.6667\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7966 - accuracy: 0.6370 - val_loss: 0.8393 - val_accuracy: 0.6496\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7945 - accuracy: 0.6481 - val_loss: 0.8120 - val_accuracy: 0.6752\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8209 - accuracy: 0.6185 - val_loss: 0.8297 - val_accuracy: 0.6667\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7804 - accuracy: 0.6556 - val_loss: 0.8122 - val_accuracy: 0.6581\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7916 - accuracy: 0.6481 - val_loss: 0.8428 - val_accuracy: 0.6581\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7826 - accuracy: 0.6481 - val_loss: 0.8064 - val_accuracy: 0.6667\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7844 - accuracy: 0.6630 - val_loss: 0.8535 - val_accuracy: 0.6752\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7970 - accuracy: 0.6704 - val_loss: 0.8322 - val_accuracy: 0.6838\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7852 - accuracy: 0.6444 - val_loss: 0.8034 - val_accuracy: 0.6838\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7822 - accuracy: 0.6704 - val_loss: 0.8236 - val_accuracy: 0.6752\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7932 - accuracy: 0.6556 - val_loss: 0.8108 - val_accuracy: 0.6667\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8452 - accuracy: 0.5926 - val_loss: 0.8663 - val_accuracy: 0.6667\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8485 - accuracy: 0.6333 - val_loss: 0.8924 - val_accuracy: 0.6154\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8585 - accuracy: 0.6407 - val_loss: 0.8397 - val_accuracy: 0.6667\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8210 - accuracy: 0.6481 - val_loss: 0.9513 - val_accuracy: 0.6325\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8240 - accuracy: 0.6556 - val_loss: 0.8272 - val_accuracy: 0.6410\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8451 - accuracy: 0.6481 - val_loss: 0.9232 - val_accuracy: 0.6496\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8485 - accuracy: 0.6593 - val_loss: 1.0007 - val_accuracy: 0.6496\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8350 - accuracy: 0.6481 - val_loss: 0.8124 - val_accuracy: 0.6410\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8143 - accuracy: 0.6296 - val_loss: 0.9946 - val_accuracy: 0.6752\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8613 - accuracy: 0.6704 - val_loss: 0.8814 - val_accuracy: 0.6838\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7930 - accuracy: 0.6444 - val_loss: 0.8101 - val_accuracy: 0.6667\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7935 - accuracy: 0.6556 - val_loss: 0.9068 - val_accuracy: 0.6581\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8434 - accuracy: 0.6593 - val_loss: 0.8794 - val_accuracy: 0.6496\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8011 - accuracy: 0.6296 - val_loss: 0.8226 - val_accuracy: 0.6410\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8262 - accuracy: 0.6593 - val_loss: 0.8656 - val_accuracy: 0.6752\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8543 - accuracy: 0.6481 - val_loss: 0.8688 - val_accuracy: 0.6581\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8416 - accuracy: 0.6556 - val_loss: 1.0015 - val_accuracy: 0.6923\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8276 - accuracy: 0.6667 - val_loss: 0.8224 - val_accuracy: 0.6581\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8063 - accuracy: 0.6481 - val_loss: 0.8568 - val_accuracy: 0.6752\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7885 - accuracy: 0.6630 - val_loss: 0.8652 - val_accuracy: 0.6752\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7807 - accuracy: 0.6778 - val_loss: 0.8160 - val_accuracy: 0.6667\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7750 - accuracy: 0.6815 - val_loss: 0.8458 - val_accuracy: 0.6581\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8125 - accuracy: 0.6741 - val_loss: 0.8739 - val_accuracy: 0.6581\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7889 - accuracy: 0.6704 - val_loss: 0.8894 - val_accuracy: 0.6667\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9696 - accuracy: 0.6519 - val_loss: 1.3052 - val_accuracy: 0.6410\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9841 - accuracy: 0.6593 - val_loss: 1.0553 - val_accuracy: 0.6410\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8772 - accuracy: 0.6259 - val_loss: 0.8753 - val_accuracy: 0.6239\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8615 - accuracy: 0.6481 - val_loss: 0.9555 - val_accuracy: 0.6325\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8242 - accuracy: 0.6667 - val_loss: 0.8588 - val_accuracy: 0.6325\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8005 - accuracy: 0.6370 - val_loss: 0.8406 - val_accuracy: 0.6667\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.78 - 0s 55us/step - loss: 0.7946 - accuracy: 0.6704 - val_loss: 0.8200 - val_accuracy: 0.6325\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7767 - accuracy: 0.6519 - val_loss: 0.8687 - val_accuracy: 0.6752\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8120 - accuracy: 0.6593 - val_loss: 0.9672 - val_accuracy: 0.6068\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8525 - accuracy: 0.6556 - val_loss: 0.8141 - val_accuracy: 0.6410\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8151 - accuracy: 0.6593 - val_loss: 0.9438 - val_accuracy: 0.6667\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8184 - accuracy: 0.6333 - val_loss: 0.8282 - val_accuracy: 0.6667\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7782 - accuracy: 0.6481 - val_loss: 0.8527 - val_accuracy: 0.6667\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8065 - accuracy: 0.6593 - val_loss: 0.9436 - val_accuracy: 0.6581\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7946 - accuracy: 0.6667 - val_loss: 0.9007 - val_accuracy: 0.6325\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0593 - accuracy: 0.6074 - val_loss: 1.2503 - val_accuracy: 0.6667\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1407 - accuracy: 0.6407 - val_loss: 1.6159 - val_accuracy: 0.6496\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.1702 - accuracy: 0.6444 - val_loss: 1.2536 - val_accuracy: 0.6923\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8898 - accuracy: 0.6481 - val_loss: 0.8943 - val_accuracy: 0.5983\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8774 - accuracy: 0.6111 - val_loss: 1.0713 - val_accuracy: 0.5983\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9113 - accuracy: 0.6148 - val_loss: 0.9469 - val_accuracy: 0.6581\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7939 - accuracy: 0.6407 - val_loss: 0.8831 - val_accuracy: 0.5983\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8090 - accuracy: 0.6556 - val_loss: 0.8905 - val_accuracy: 0.6239\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8228 - accuracy: 0.6667 - val_loss: 0.8789 - val_accuracy: 0.6667\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7914 - accuracy: 0.7037 - val_loss: 0.8346 - val_accuracy: 0.6581\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7730 - accuracy: 0.6741 - val_loss: 0.8420 - val_accuracy: 0.6667\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8401 - accuracy: 0.6630 - val_loss: 1.0993 - val_accuracy: 0.6581\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8932 - accuracy: 0.6667 - val_loss: 0.9378 - val_accuracy: 0.6838\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8379 - accuracy: 0.6519 - val_loss: 0.8325 - val_accuracy: 0.6325\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7949 - accuracy: 0.6630 - val_loss: 0.9858 - val_accuracy: 0.6496\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8498 - accuracy: 0.6704 - val_loss: 0.9512 - val_accuracy: 0.6752\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7888 - accuracy: 0.6630 - val_loss: 0.8314 - val_accuracy: 0.6496\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8751 - accuracy: 0.6370 - val_loss: 0.9957 - val_accuracy: 0.6239\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8589 - accuracy: 0.6444 - val_loss: 0.8743 - val_accuracy: 0.6838\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7903 - accuracy: 0.6370 - val_loss: 0.8781 - val_accuracy: 0.6154\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8915 - accuracy: 0.6593 - val_loss: 1.0275 - val_accuracy: 0.6154\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8922 - accuracy: 0.6407 - val_loss: 0.8989 - val_accuracy: 0.6667\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7874 - accuracy: 0.6630 - val_loss: 0.8251 - val_accuracy: 0.6496\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8802 - accuracy: 0.6593 - val_loss: 1.1229 - val_accuracy: 0.5812\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0920 - accuracy: 0.6370 - val_loss: 1.1564 - val_accuracy: 0.6068\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9641 - accuracy: 0.6333 - val_loss: 1.0516 - val_accuracy: 0.6667\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8980 - accuracy: 0.6222 - val_loss: 0.8803 - val_accuracy: 0.6496\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7894 - accuracy: 0.6444 - val_loss: 0.8497 - val_accuracy: 0.6667\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8544 - accuracy: 0.6667 - val_loss: 1.0422 - val_accuracy: 0.6667\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8527 - accuracy: 0.6593 - val_loss: 0.8412 - val_accuracy: 0.6752\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8436 - accuracy: 0.6630 - val_loss: 1.0819 - val_accuracy: 0.6752\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8676 - accuracy: 0.6741 - val_loss: 0.8828 - val_accuracy: 0.6752\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7805 - accuracy: 0.6519 - val_loss: 0.8240 - val_accuracy: 0.6667\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7953 - accuracy: 0.6444 - val_loss: 0.9388 - val_accuracy: 0.6838\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7989 - accuracy: 0.6889 - val_loss: 0.8332 - val_accuracy: 0.6581\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7844 - accuracy: 0.6556 - val_loss: 0.8333 - val_accuracy: 0.6752\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7851 - accuracy: 0.6926 - val_loss: 0.9179 - val_accuracy: 0.6752\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7754 - accuracy: 0.6852 - val_loss: 0.8154 - val_accuracy: 0.6581\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8162 - accuracy: 0.6630 - val_loss: 0.9283 - val_accuracy: 0.6752\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8233 - accuracy: 0.6741 - val_loss: 0.9555 - val_accuracy: 0.6838\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8025 - accuracy: 0.6593 - val_loss: 0.8259 - val_accuracy: 0.6581\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7824 - accuracy: 0.6630 - val_loss: 0.8463 - val_accuracy: 0.6667\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7800 - accuracy: 0.6778 - val_loss: 0.8615 - val_accuracy: 0.6752\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7814 - accuracy: 0.6556 - val_loss: 0.8091 - val_accuracy: 0.6581\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7999 - accuracy: 0.6667 - val_loss: 0.8537 - val_accuracy: 0.6496\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7956 - accuracy: 0.6630 - val_loss: 0.8431 - val_accuracy: 0.6667\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7710 - accuracy: 0.6852 - val_loss: 0.8208 - val_accuracy: 0.6667\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7564 - accuracy: 0.6852 - val_loss: 0.8610 - val_accuracy: 0.6752\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7903 - accuracy: 0.6593 - val_loss: 0.8840 - val_accuracy: 0.6581\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7770 - accuracy: 0.6593 - val_loss: 0.8046 - val_accuracy: 0.6752\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7906 - accuracy: 0.6963 - val_loss: 0.8380 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8117 - accuracy: 0.6630 - val_loss: 0.8829 - val_accuracy: 0.6838\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7846 - accuracy: 0.6963 - val_loss: 0.8132 - val_accuracy: 0.6581\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7715 - accuracy: 0.6815 - val_loss: 0.8429 - val_accuracy: 0.6752\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7675 - accuracy: 0.6852 - val_loss: 0.8333 - val_accuracy: 0.6752\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7814 - accuracy: 0.6778 - val_loss: 0.9197 - val_accuracy: 0.6752\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7839 - accuracy: 0.6852 - val_loss: 0.8081 - val_accuracy: 0.6752\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7676 - accuracy: 0.6704 - val_loss: 0.8496 - val_accuracy: 0.6667\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7862 - accuracy: 0.6667 - val_loss: 0.8895 - val_accuracy: 0.6752\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7967 - accuracy: 0.6704 - val_loss: 0.8167 - val_accuracy: 0.6752\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7704 - accuracy: 0.6778 - val_loss: 0.8909 - val_accuracy: 0.6581\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7663 - accuracy: 0.6889 - val_loss: 0.8167 - val_accuracy: 0.6752\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7672 - accuracy: 0.6852 - val_loss: 0.8814 - val_accuracy: 0.6667\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7988 - accuracy: 0.6852 - val_loss: 0.8762 - val_accuracy: 0.6667\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7643 - accuracy: 0.6852 - val_loss: 0.8247 - val_accuracy: 0.6667\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7691 - accuracy: 0.6963 - val_loss: 0.8669 - val_accuracy: 0.6752\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7609 - accuracy: 0.6889 - val_loss: 0.8065 - val_accuracy: 0.6667\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7743 - accuracy: 0.6815 - val_loss: 0.9000 - val_accuracy: 0.6667\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7909 - accuracy: 0.6852 - val_loss: 0.8551 - val_accuracy: 0.6667\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7822 - accuracy: 0.6741 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7791 - accuracy: 0.6852 - val_loss: 0.8301 - val_accuracy: 0.6581\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7782 - accuracy: 0.6852 - val_loss: 0.8318 - val_accuracy: 0.6838\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7649 - accuracy: 0.6926 - val_loss: 0.8501 - val_accuracy: 0.6667\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8209 - accuracy: 0.6519 - val_loss: 0.8920 - val_accuracy: 0.5983\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7900 - accuracy: 0.6741 - val_loss: 0.8148 - val_accuracy: 0.6581\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7699 - accuracy: 0.6741 - val_loss: 0.9371 - val_accuracy: 0.6496\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8310 - accuracy: 0.6630 - val_loss: 0.8475 - val_accuracy: 0.6496\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7538 - accuracy: 0.7037 - val_loss: 0.8176 - val_accuracy: 0.6581\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7993 - accuracy: 0.6556 - val_loss: 0.8810 - val_accuracy: 0.6752\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7589 - accuracy: 0.6963 - val_loss: 0.8061 - val_accuracy: 0.6410\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7877 - accuracy: 0.6556 - val_loss: 0.9751 - val_accuracy: 0.6667\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8304 - accuracy: 0.6741 - val_loss: 0.9565 - val_accuracy: 0.6923\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7890 - accuracy: 0.6778 - val_loss: 0.8172 - val_accuracy: 0.6581\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7690 - accuracy: 0.6815 - val_loss: 0.8168 - val_accuracy: 0.6752\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7762 - accuracy: 0.6778 - val_loss: 0.8373 - val_accuracy: 0.6667\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7788 - accuracy: 0.6778 - val_loss: 0.8631 - val_accuracy: 0.6581\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8017 - accuracy: 0.6889 - val_loss: 0.9177 - val_accuracy: 0.6667\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7716 - accuracy: 0.6889 - val_loss: 0.8083 - val_accuracy: 0.6923\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7636 - accuracy: 0.6741 - val_loss: 0.8463 - val_accuracy: 0.6752\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7666 - accuracy: 0.6741 - val_loss: 0.8104 - val_accuracy: 0.6838\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7961 - accuracy: 0.6667 - val_loss: 0.8771 - val_accuracy: 0.6752\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8694 - accuracy: 0.6741 - val_loss: 1.2065 - val_accuracy: 0.6667\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9249 - accuracy: 0.6778 - val_loss: 0.9691 - val_accuracy: 0.6838\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7935 - accuracy: 0.6778 - val_loss: 0.8118 - val_accuracy: 0.6581\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7686 - accuracy: 0.6852 - val_loss: 0.9295 - val_accuracy: 0.6667\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7908 - accuracy: 0.6889 - val_loss: 0.8711 - val_accuracy: 0.6581\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7922 - accuracy: 0.6741 - val_loss: 0.8285 - val_accuracy: 0.6410\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7630 - accuracy: 0.6778 - val_loss: 0.8523 - val_accuracy: 0.6667\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7671 - accuracy: 0.6815 - val_loss: 0.8196 - val_accuracy: 0.6667\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7645 - accuracy: 0.6778 - val_loss: 0.8215 - val_accuracy: 0.6667\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7645 - accuracy: 0.6778 - val_loss: 0.8240 - val_accuracy: 0.6752\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7476 - accuracy: 0.6963 - val_loss: 0.8653 - val_accuracy: 0.6752\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7597 - accuracy: 0.6889 - val_loss: 0.8126 - val_accuracy: 0.6667\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7663 - accuracy: 0.6815 - val_loss: 0.8816 - val_accuracy: 0.6581\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7968 - accuracy: 0.6815 - val_loss: 0.9540 - val_accuracy: 0.6667\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7990 - accuracy: 0.6741 - val_loss: 0.8097 - val_accuracy: 0.6667\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7588 - accuracy: 0.6926 - val_loss: 0.8107 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7600 - accuracy: 0.6889 - val_loss: 0.8433 - val_accuracy: 0.6838\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7620 - accuracy: 0.6926 - val_loss: 0.8992 - val_accuracy: 0.6838\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7634 - accuracy: 0.6889 - val_loss: 0.8078 - val_accuracy: 0.6667\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7942 - accuracy: 0.6593 - val_loss: 0.8904 - val_accuracy: 0.6581\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7865 - accuracy: 0.6852 - val_loss: 0.9581 - val_accuracy: 0.6838\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8050 - accuracy: 0.6778 - val_loss: 0.8499 - val_accuracy: 0.6667\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7741 - accuracy: 0.6778 - val_loss: 0.8027 - val_accuracy: 0.6410\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7791 - accuracy: 0.6667 - val_loss: 0.9056 - val_accuracy: 0.6667\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8574 - accuracy: 0.6630 - val_loss: 0.9041 - val_accuracy: 0.6154\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8198 - accuracy: 0.6556 - val_loss: 1.0199 - val_accuracy: 0.6752\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0049 - accuracy: 0.6667 - val_loss: 2.0358 - val_accuracy: 0.6496\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.5552 - accuracy: 0.6519 - val_loss: 2.0590 - val_accuracy: 0.6667\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.4282 - accuracy: 0.6704 - val_loss: 1.6590 - val_accuracy: 0.6581\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9879 - accuracy: 0.6630 - val_loss: 0.8652 - val_accuracy: 0.6325\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8757 - accuracy: 0.6296 - val_loss: 0.9436 - val_accuracy: 0.6154\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.1051 - accuracy: 0.6111 - val_loss: 1.7012 - val_accuracy: 0.6410\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.2222 - accuracy: 0.6259 - val_loss: 1.4960 - val_accuracy: 0.6239\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.0264 - accuracy: 0.6333 - val_loss: 1.1007 - val_accuracy: 0.6838\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8372 - accuracy: 0.6593 - val_loss: 0.8937 - val_accuracy: 0.6068\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8653 - accuracy: 0.6074 - val_loss: 0.9124 - val_accuracy: 0.6410\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8244 - accuracy: 0.6741 - val_loss: 1.0246 - val_accuracy: 0.6496\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8063 - accuracy: 0.6815 - val_loss: 0.8703 - val_accuracy: 0.6410\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7874 - accuracy: 0.6556 - val_loss: 0.8463 - val_accuracy: 0.6410\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7560 - accuracy: 0.6778 - val_loss: 0.8988 - val_accuracy: 0.6410\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7671 - accuracy: 0.6889 - val_loss: 0.8596 - val_accuracy: 0.6325\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7666 - accuracy: 0.6815 - val_loss: 0.8253 - val_accuracy: 0.6325\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7656 - accuracy: 0.6667 - val_loss: 0.8252 - val_accuracy: 0.6667\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7870 - accuracy: 0.6704 - val_loss: 0.8653 - val_accuracy: 0.6838\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7978 - accuracy: 0.6778 - val_loss: 0.8290 - val_accuracy: 0.6581\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7735 - accuracy: 0.6852 - val_loss: 0.8328 - val_accuracy: 0.6838\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7498 - accuracy: 0.6852 - val_loss: 0.8037 - val_accuracy: 0.6838\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7765 - accuracy: 0.6852 - val_loss: 0.8584 - val_accuracy: 0.6667\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7697 - accuracy: 0.6852 - val_loss: 0.8204 - val_accuracy: 0.6838\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7534 - accuracy: 0.7074 - val_loss: 0.8082 - val_accuracy: 0.6838\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7624 - accuracy: 0.6963 - val_loss: 0.8005 - val_accuracy: 0.6838\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7989 - accuracy: 0.6778 - val_loss: 0.9575 - val_accuracy: 0.6752\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8781 - accuracy: 0.6889 - val_loss: 1.0510 - val_accuracy: 0.6581\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8239 - accuracy: 0.6667 - val_loss: 0.8370 - val_accuracy: 0.6581\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7605 - accuracy: 0.6815 - val_loss: 0.8269 - val_accuracy: 0.6667\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7662 - accuracy: 0.6815 - val_loss: 0.8166 - val_accuracy: 0.6752\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7440 - accuracy: 0.6889 - val_loss: 0.8194 - val_accuracy: 0.6581\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7479 - accuracy: 0.6778 - val_loss: 0.8612 - val_accuracy: 0.6496\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7489 - accuracy: 0.6778 - val_loss: 0.8047 - val_accuracy: 0.6838\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7585 - accuracy: 0.6889 - val_loss: 0.8211 - val_accuracy: 0.6838\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7480 - accuracy: 0.6963 - val_loss: 0.8006 - val_accuracy: 0.6581\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7611 - accuracy: 0.6926 - val_loss: 0.8311 - val_accuracy: 0.6667\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7459 - accuracy: 0.6852 - val_loss: 0.8303 - val_accuracy: 0.6923\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7474 - accuracy: 0.6963 - val_loss: 0.8239 - val_accuracy: 0.6667\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7591 - accuracy: 0.6815 - val_loss: 0.8067 - val_accuracy: 0.6667\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7539 - accuracy: 0.6926 - val_loss: 0.8168 - val_accuracy: 0.6838\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7495 - accuracy: 0.6963 - val_loss: 0.8324 - val_accuracy: 0.6838\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7412 - accuracy: 0.6889 - val_loss: 0.8084 - val_accuracy: 0.6667\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7494 - accuracy: 0.6667 - val_loss: 0.8379 - val_accuracy: 0.6752\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7548 - accuracy: 0.6815 - val_loss: 0.8094 - val_accuracy: 0.6838\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7831 - accuracy: 0.6704 - val_loss: 0.8553 - val_accuracy: 0.6581\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8517 - accuracy: 0.6815 - val_loss: 1.0597 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9249 - accuracy: 0.6444 - val_loss: 0.9317 - val_accuracy: 0.5897\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9178 - accuracy: 0.6407 - val_loss: 1.2096 - val_accuracy: 0.6667\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9900 - accuracy: 0.6704 - val_loss: 1.2230 - val_accuracy: 0.6239\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9061 - accuracy: 0.6556 - val_loss: 0.8686 - val_accuracy: 0.6325\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8381 - accuracy: 0.6333 - val_loss: 0.8726 - val_accuracy: 0.6068\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7823 - accuracy: 0.6593 - val_loss: 0.8560 - val_accuracy: 0.6752\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7675 - accuracy: 0.6630 - val_loss: 0.8448 - val_accuracy: 0.6667\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7454 - accuracy: 0.6889 - val_loss: 0.8061 - val_accuracy: 0.6410\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8154 - accuracy: 0.6630 - val_loss: 0.8766 - val_accuracy: 0.6667\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7949 - accuracy: 0.6926 - val_loss: 0.9734 - val_accuracy: 0.6752\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7829 - accuracy: 0.6852 - val_loss: 0.8286 - val_accuracy: 0.6667\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7693 - accuracy: 0.6704 - val_loss: 0.8158 - val_accuracy: 0.6581\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7511 - accuracy: 0.6926 - val_loss: 0.8184 - val_accuracy: 0.6667\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7406 - accuracy: 0.7074 - val_loss: 0.8518 - val_accuracy: 0.6752\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7515 - accuracy: 0.6815 - val_loss: 0.8224 - val_accuracy: 0.6667\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7497 - accuracy: 0.6889 - val_loss: 0.8036 - val_accuracy: 0.6581\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7369 - accuracy: 0.6815 - val_loss: 0.8486 - val_accuracy: 0.6667\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7442 - accuracy: 0.6852 - val_loss: 0.8035 - val_accuracy: 0.6667\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7630 - accuracy: 0.6778 - val_loss: 0.8592 - val_accuracy: 0.6581\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7893 - accuracy: 0.6852 - val_loss: 0.8481 - val_accuracy: 0.6410\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7823 - accuracy: 0.6704 - val_loss: 0.8071 - val_accuracy: 0.6838\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7647 - accuracy: 0.6889 - val_loss: 1.0059 - val_accuracy: 0.6667\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8218 - accuracy: 0.6593 - val_loss: 0.8612 - val_accuracy: 0.6752\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8436 - accuracy: 0.6519 - val_loss: 1.0139 - val_accuracy: 0.6752\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 1.0063 - accuracy: 0.6852 - val_loss: 1.4060 - val_accuracy: 0.6752\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 1.0258 - accuracy: 0.6741 - val_loss: 1.1510 - val_accuracy: 0.6752\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8219 - accuracy: 0.6704 - val_loss: 0.8427 - val_accuracy: 0.6325\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8148 - accuracy: 0.6296 - val_loss: 0.9307 - val_accuracy: 0.6752\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8092 - accuracy: 0.6926 - val_loss: 1.0113 - val_accuracy: 0.6667\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8079 - accuracy: 0.6926 - val_loss: 0.8507 - val_accuracy: 0.6410\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7949 - accuracy: 0.6630 - val_loss: 0.8835 - val_accuracy: 0.6154\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8138 - accuracy: 0.6815 - val_loss: 0.9367 - val_accuracy: 0.6581\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7842 - accuracy: 0.6704 - val_loss: 0.8548 - val_accuracy: 0.6154\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7688 - accuracy: 0.6593 - val_loss: 0.8442 - val_accuracy: 0.6154\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7501 - accuracy: 0.7037 - val_loss: 0.8399 - val_accuracy: 0.6667\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7486 - accuracy: 0.6963 - val_loss: 0.8320 - val_accuracy: 0.6581\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7556 - accuracy: 0.6815 - val_loss: 0.8016 - val_accuracy: 0.6581\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7617 - accuracy: 0.6852 - val_loss: 0.8030 - val_accuracy: 0.6752\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7449 - accuracy: 0.6889 - val_loss: 0.8460 - val_accuracy: 0.6752\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7494 - accuracy: 0.6852 - val_loss: 0.8093 - val_accuracy: 0.6752\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7430 - accuracy: 0.6926 - val_loss: 0.8130 - val_accuracy: 0.6752\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7464 - accuracy: 0.6815 - val_loss: 0.9032 - val_accuracy: 0.6667\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7548 - accuracy: 0.6815 - val_loss: 0.8035 - val_accuracy: 0.6752\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7366 - accuracy: 0.6889 - val_loss: 0.8091 - val_accuracy: 0.6752\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7398 - accuracy: 0.6852 - val_loss: 0.8454 - val_accuracy: 0.6667\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7383 - accuracy: 0.6778 - val_loss: 0.8277 - val_accuracy: 0.6923\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7418 - accuracy: 0.6852 - val_loss: 0.8773 - val_accuracy: 0.6496\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7885 - accuracy: 0.6741 - val_loss: 0.8249 - val_accuracy: 0.6581\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7555 - accuracy: 0.6889 - val_loss: 0.8332 - val_accuracy: 0.6752\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7460 - accuracy: 0.6889 - val_loss: 0.8595 - val_accuracy: 0.6496\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7468 - accuracy: 0.6852 - val_loss: 0.8045 - val_accuracy: 0.6581\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7413 - accuracy: 0.6889 - val_loss: 0.8345 - val_accuracy: 0.6410\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7492 - accuracy: 0.6741 - val_loss: 0.8277 - val_accuracy: 0.6496\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7427 - accuracy: 0.6889 - val_loss: 0.8179 - val_accuracy: 0.6581\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.73 - 0s 47us/step - loss: 0.7442 - accuracy: 0.6852 - val_loss: 0.8149 - val_accuracy: 0.6581\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7349 - accuracy: 0.6926 - val_loss: 0.8526 - val_accuracy: 0.6581\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7427 - accuracy: 0.6889 - val_loss: 0.7985 - val_accuracy: 0.6667\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7360 - accuracy: 0.6926 - val_loss: 0.8329 - val_accuracy: 0.6581\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7398 - accuracy: 0.6926 - val_loss: 0.8191 - val_accuracy: 0.6581\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7323 - accuracy: 0.6926 - val_loss: 0.8106 - val_accuracy: 0.6581\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7436 - accuracy: 0.6926 - val_loss: 0.8024 - val_accuracy: 0.6581\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7417 - accuracy: 0.6815 - val_loss: 0.8609 - val_accuracy: 0.6667\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7908 - accuracy: 0.6704 - val_loss: 0.8584 - val_accuracy: 0.6667\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7926 - accuracy: 0.6815 - val_loss: 0.8683 - val_accuracy: 0.6581\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7736 - accuracy: 0.6852 - val_loss: 0.8635 - val_accuracy: 0.6496\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7636 - accuracy: 0.6815 - val_loss: 0.9275 - val_accuracy: 0.6581\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8058 - accuracy: 0.6778 - val_loss: 1.1942 - val_accuracy: 0.6496\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9001 - accuracy: 0.6741 - val_loss: 0.9778 - val_accuracy: 0.6667\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8565 - accuracy: 0.6778 - val_loss: 1.0432 - val_accuracy: 0.5983\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1593 - accuracy: 0.6148 - val_loss: 2.5426 - val_accuracy: 0.5726\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.8450 - accuracy: 0.6185 - val_loss: 2.2208 - val_accuracy: 0.6496\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.5297 - accuracy: 0.6407 - val_loss: 1.7469 - val_accuracy: 0.6752\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.1348 - accuracy: 0.6741 - val_loss: 1.1722 - val_accuracy: 0.6496\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9571 - accuracy: 0.6444 - val_loss: 0.9941 - val_accuracy: 0.5726\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9485 - accuracy: 0.6111 - val_loss: 0.9837 - val_accuracy: 0.6581\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8094 - accuracy: 0.6926 - val_loss: 0.9799 - val_accuracy: 0.6496\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7583 - accuracy: 0.6741 - val_loss: 0.8758 - val_accuracy: 0.5983\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8289 - accuracy: 0.6519 - val_loss: 0.9872 - val_accuracy: 0.6581\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8372 - accuracy: 0.7037 - val_loss: 1.0352 - val_accuracy: 0.6752\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7928 - accuracy: 0.6926 - val_loss: 0.8624 - val_accuracy: 0.6410\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7498 - accuracy: 0.6778 - val_loss: 0.8330 - val_accuracy: 0.6496\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7630 - accuracy: 0.6667 - val_loss: 0.9128 - val_accuracy: 0.6581\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7630 - accuracy: 0.6741 - val_loss: 0.8314 - val_accuracy: 0.6496\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7390 - accuracy: 0.6963 - val_loss: 0.8279 - val_accuracy: 0.6667\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7396 - accuracy: 0.6926 - val_loss: 0.8195 - val_accuracy: 0.6667\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7329 - accuracy: 0.6963 - val_loss: 0.8314 - val_accuracy: 0.6752\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7322 - accuracy: 0.7148 - val_loss: 0.8154 - val_accuracy: 0.6752\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7333 - accuracy: 0.6815 - val_loss: 0.8685 - val_accuracy: 0.6667\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7485 - accuracy: 0.6889 - val_loss: 0.8309 - val_accuracy: 0.6667\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7450 - accuracy: 0.6778 - val_loss: 0.8880 - val_accuracy: 0.6581\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8869 - accuracy: 0.6741 - val_loss: 1.2322 - val_accuracy: 0.6667\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8787 - accuracy: 0.6741 - val_loss: 0.9209 - val_accuracy: 0.6581\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8438 - accuracy: 0.6444 - val_loss: 1.0408 - val_accuracy: 0.5983\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9781 - accuracy: 0.6444 - val_loss: 1.2710 - val_accuracy: 0.5983\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9082 - accuracy: 0.6519 - val_loss: 0.9361 - val_accuracy: 0.6496\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7652 - accuracy: 0.6778 - val_loss: 0.8222 - val_accuracy: 0.6496\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7692 - accuracy: 0.6741 - val_loss: 0.8372 - val_accuracy: 0.6752\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7461 - accuracy: 0.7000 - val_loss: 0.8879 - val_accuracy: 0.6838\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7410 - accuracy: 0.7000 - val_loss: 0.8229 - val_accuracy: 0.6752\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7388 - accuracy: 0.7111 - val_loss: 0.8250 - val_accuracy: 0.6752\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7339 - accuracy: 0.6889 - val_loss: 0.8244 - val_accuracy: 0.6752\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7290 - accuracy: 0.6963 - val_loss: 0.8309 - val_accuracy: 0.6752\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7270 - accuracy: 0.6852 - val_loss: 0.8309 - val_accuracy: 0.6496\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7318 - accuracy: 0.6741 - val_loss: 0.8100 - val_accuracy: 0.6667\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7398 - accuracy: 0.6963 - val_loss: 0.8138 - val_accuracy: 0.6667\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7881 - accuracy: 0.6704 - val_loss: 0.8820 - val_accuracy: 0.6581\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7664 - accuracy: 0.6926 - val_loss: 0.9485 - val_accuracy: 0.6667\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7808 - accuracy: 0.6815 - val_loss: 0.8043 - val_accuracy: 0.6752\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7307 - accuracy: 0.6889 - val_loss: 0.8320 - val_accuracy: 0.6581\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7387 - accuracy: 0.6889 - val_loss: 0.8107 - val_accuracy: 0.6667\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7397 - accuracy: 0.6741 - val_loss: 0.8438 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7428 - accuracy: 0.6852 - val_loss: 0.8054 - val_accuracy: 0.6581\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7606 - accuracy: 0.6778 - val_loss: 0.8676 - val_accuracy: 0.6581\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7617 - accuracy: 0.6667 - val_loss: 0.8952 - val_accuracy: 0.6667\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7413 - accuracy: 0.6704 - val_loss: 0.8062 - val_accuracy: 0.6581\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7416 - accuracy: 0.6889 - val_loss: 0.8133 - val_accuracy: 0.6667\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7283 - accuracy: 0.6889 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7361 - accuracy: 0.6963 - val_loss: 0.8309 - val_accuracy: 0.6410\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7287 - accuracy: 0.6815 - val_loss: 0.8401 - val_accuracy: 0.6667\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7244 - accuracy: 0.6963 - val_loss: 0.8109 - val_accuracy: 0.6581\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7279 - accuracy: 0.6852 - val_loss: 0.8351 - val_accuracy: 0.6581\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7261 - accuracy: 0.6852 - val_loss: 0.8207 - val_accuracy: 0.6581\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7260 - accuracy: 0.6852 - val_loss: 0.8389 - val_accuracy: 0.6581\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7421 - accuracy: 0.6815 - val_loss: 0.9114 - val_accuracy: 0.6581\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7359 - accuracy: 0.6815 - val_loss: 0.8141 - val_accuracy: 0.6496\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7579 - accuracy: 0.6778 - val_loss: 0.8824 - val_accuracy: 0.6496\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7644 - accuracy: 0.6852 - val_loss: 0.9986 - val_accuracy: 0.6496\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7780 - accuracy: 0.6889 - val_loss: 0.8299 - val_accuracy: 0.6581\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7645 - accuracy: 0.6815 - val_loss: 0.8497 - val_accuracy: 0.6496\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7327 - accuracy: 0.6926 - val_loss: 0.9231 - val_accuracy: 0.6410\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8581 - accuracy: 0.6593 - val_loss: 1.0899 - val_accuracy: 0.5812\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8679 - accuracy: 0.6519 - val_loss: 0.8332 - val_accuracy: 0.6239\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7655 - accuracy: 0.6926 - val_loss: 0.8584 - val_accuracy: 0.6581\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7402 - accuracy: 0.6852 - val_loss: 0.8519 - val_accuracy: 0.6410\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7825 - accuracy: 0.6778 - val_loss: 0.8137 - val_accuracy: 0.6667\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7665 - accuracy: 0.6741 - val_loss: 0.9190 - val_accuracy: 0.6581\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8693 - accuracy: 0.6519 - val_loss: 0.8789 - val_accuracy: 0.6325\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7587 - accuracy: 0.6852 - val_loss: 0.9378 - val_accuracy: 0.6154\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8529 - accuracy: 0.6222 - val_loss: 0.9215 - val_accuracy: 0.6752\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8355 - accuracy: 0.6593 - val_loss: 0.9206 - val_accuracy: 0.6154\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8461 - accuracy: 0.6667 - val_loss: 0.8321 - val_accuracy: 0.6581\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7601 - accuracy: 0.6704 - val_loss: 0.9793 - val_accuracy: 0.6154\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7805 - accuracy: 0.6407 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7583 - accuracy: 0.6815 - val_loss: 0.8652 - val_accuracy: 0.6581\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8166 - accuracy: 0.6778 - val_loss: 0.9935 - val_accuracy: 0.6752\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7882 - accuracy: 0.6852 - val_loss: 0.8094 - val_accuracy: 0.6923\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7302 - accuracy: 0.6963 - val_loss: 0.8499 - val_accuracy: 0.6667\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7734 - accuracy: 0.6889 - val_loss: 0.8536 - val_accuracy: 0.6667\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7237 - accuracy: 0.6963 - val_loss: 0.8293 - val_accuracy: 0.6325\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7596 - accuracy: 0.6889 - val_loss: 0.9109 - val_accuracy: 0.6410\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7920 - accuracy: 0.6852 - val_loss: 0.8536 - val_accuracy: 0.6496\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7433 - accuracy: 0.6778 - val_loss: 0.8609 - val_accuracy: 0.6581\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7705 - accuracy: 0.6741 - val_loss: 0.9277 - val_accuracy: 0.6581\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7416 - accuracy: 0.6926 - val_loss: 0.8160 - val_accuracy: 0.6410\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7661 - accuracy: 0.6815 - val_loss: 1.0695 - val_accuracy: 0.6581\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8399 - accuracy: 0.6741 - val_loss: 1.0021 - val_accuracy: 0.6838\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7568 - accuracy: 0.6815 - val_loss: 0.8077 - val_accuracy: 0.6581\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7597 - accuracy: 0.6667 - val_loss: 0.8571 - val_accuracy: 0.6581\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7388 - accuracy: 0.6852 - val_loss: 0.8339 - val_accuracy: 0.6667\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7449 - accuracy: 0.6778 - val_loss: 0.8236 - val_accuracy: 0.6667\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7428 - accuracy: 0.6852 - val_loss: 0.8784 - val_accuracy: 0.6667\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7403 - accuracy: 0.6926 - val_loss: 0.8204 - val_accuracy: 0.6923\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7329 - accuracy: 0.7074 - val_loss: 0.7948 - val_accuracy: 0.6752\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7252 - accuracy: 0.6926 - val_loss: 0.8399 - val_accuracy: 0.6667\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7291 - accuracy: 0.7111 - val_loss: 0.7940 - val_accuracy: 0.6838\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7345 - accuracy: 0.7000 - val_loss: 0.8425 - val_accuracy: 0.6667\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7787 - accuracy: 0.6963 - val_loss: 0.8786 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7456 - accuracy: 0.6963 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7666 - accuracy: 0.6741 - val_loss: 0.9616 - val_accuracy: 0.6667\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7763 - accuracy: 0.6926 - val_loss: 0.8486 - val_accuracy: 0.6496\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7221 - accuracy: 0.6963 - val_loss: 0.8087 - val_accuracy: 0.6667\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7277 - accuracy: 0.6963 - val_loss: 0.8105 - val_accuracy: 0.6752\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7562 - accuracy: 0.7000 - val_loss: 1.0337 - val_accuracy: 0.6667\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8769 - accuracy: 0.6889 - val_loss: 1.1171 - val_accuracy: 0.6667\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8128 - accuracy: 0.6815 - val_loss: 0.8323 - val_accuracy: 0.6838\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7580 - accuracy: 0.6852 - val_loss: 0.8683 - val_accuracy: 0.6496\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7697 - accuracy: 0.6963 - val_loss: 0.9439 - val_accuracy: 0.6667\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7408 - accuracy: 0.6963 - val_loss: 0.8203 - val_accuracy: 0.6496\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7357 - accuracy: 0.6778 - val_loss: 0.8800 - val_accuracy: 0.6581\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7909 - accuracy: 0.6852 - val_loss: 1.0589 - val_accuracy: 0.6667\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7899 - accuracy: 0.6741 - val_loss: 0.8226 - val_accuracy: 0.6325\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8803 - accuracy: 0.6593 - val_loss: 0.9124 - val_accuracy: 0.6496\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9744 - accuracy: 0.6704 - val_loss: 1.8377 - val_accuracy: 0.6667\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.3112 - accuracy: 0.6556 - val_loss: 1.7525 - val_accuracy: 0.6667\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.2186 - accuracy: 0.6741 - val_loss: 1.2960 - val_accuracy: 0.6667\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8312 - accuracy: 0.6778 - val_loss: 0.8519 - val_accuracy: 0.6410\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9723 - accuracy: 0.6259 - val_loss: 0.9104 - val_accuracy: 0.6239\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9062 - accuracy: 0.6444 - val_loss: 1.4871 - val_accuracy: 0.6667\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.1448 - accuracy: 0.6778 - val_loss: 1.6007 - val_accuracy: 0.6496\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0781 - accuracy: 0.6630 - val_loss: 1.0132 - val_accuracy: 0.6496\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7893 - accuracy: 0.6778 - val_loss: 0.9275 - val_accuracy: 0.5726\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8534 - accuracy: 0.6370 - val_loss: 1.0441 - val_accuracy: 0.6496\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8980 - accuracy: 0.6778 - val_loss: 1.3265 - val_accuracy: 0.6752\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9563 - accuracy: 0.6741 - val_loss: 1.1595 - val_accuracy: 0.6752\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8423 - accuracy: 0.6963 - val_loss: 0.8321 - val_accuracy: 0.6581\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7842 - accuracy: 0.6481 - val_loss: 0.9001 - val_accuracy: 0.6410\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7890 - accuracy: 0.6889 - val_loss: 1.1058 - val_accuracy: 0.6752\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8231 - accuracy: 0.6852 - val_loss: 0.9407 - val_accuracy: 0.6410\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7342 - accuracy: 0.6926 - val_loss: 0.8210 - val_accuracy: 0.6410\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7440 - accuracy: 0.6741 - val_loss: 0.8572 - val_accuracy: 0.6410\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7420 - accuracy: 0.6889 - val_loss: 0.8638 - val_accuracy: 0.6581\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.70 - 0s 50us/step - loss: 0.7212 - accuracy: 0.6963 - val_loss: 0.8089 - val_accuracy: 0.6496\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7319 - accuracy: 0.6778 - val_loss: 0.8395 - val_accuracy: 0.6581\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7272 - accuracy: 0.7000 - val_loss: 0.8439 - val_accuracy: 0.6581\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7350 - accuracy: 0.6926 - val_loss: 0.8121 - val_accuracy: 0.6581\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7215 - accuracy: 0.7000 - val_loss: 0.8399 - val_accuracy: 0.6667\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7220 - accuracy: 0.6963 - val_loss: 0.8313 - val_accuracy: 0.6752\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7211 - accuracy: 0.6963 - val_loss: 0.8155 - val_accuracy: 0.6752\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7162 - accuracy: 0.7000 - val_loss: 0.8142 - val_accuracy: 0.6752\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7244 - accuracy: 0.7000 - val_loss: 0.8074 - val_accuracy: 0.6752\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7166 - accuracy: 0.6963 - val_loss: 0.7983 - val_accuracy: 0.6752\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7277 - accuracy: 0.6815 - val_loss: 0.8156 - val_accuracy: 0.6752\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7270 - accuracy: 0.7000 - val_loss: 0.8124 - val_accuracy: 0.6752\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7159 - accuracy: 0.6926 - val_loss: 0.8346 - val_accuracy: 0.6752\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7165 - accuracy: 0.6926 - val_loss: 0.8154 - val_accuracy: 0.6752\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7119 - accuracy: 0.6963 - val_loss: 0.8289 - val_accuracy: 0.6752\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7139 - accuracy: 0.7000 - val_loss: 0.8199 - val_accuracy: 0.6752\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7476 - accuracy: 0.6926 - val_loss: 0.8047 - val_accuracy: 0.6752\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7318 - accuracy: 0.6926 - val_loss: 0.8341 - val_accuracy: 0.6838\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7289 - accuracy: 0.6963 - val_loss: 0.8327 - val_accuracy: 0.6581\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7301 - accuracy: 0.6889 - val_loss: 0.8009 - val_accuracy: 0.6752\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7227 - accuracy: 0.6889 - val_loss: 0.8310 - val_accuracy: 0.6752\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7239 - accuracy: 0.7000 - val_loss: 0.8873 - val_accuracy: 0.6581\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7253 - accuracy: 0.6926 - val_loss: 0.8058 - val_accuracy: 0.6752\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7267 - accuracy: 0.6889 - val_loss: 0.8671 - val_accuracy: 0.6752\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7284 - accuracy: 0.7000 - val_loss: 0.8194 - val_accuracy: 0.6752\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7507 - accuracy: 0.6704 - val_loss: 0.8769 - val_accuracy: 0.6496\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8200 - accuracy: 0.6963 - val_loss: 0.9365 - val_accuracy: 0.6581\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7600 - accuracy: 0.6852 - val_loss: 0.8050 - val_accuracy: 0.6581\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7266 - accuracy: 0.7037 - val_loss: 0.8503 - val_accuracy: 0.6581\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7246 - accuracy: 0.6926 - val_loss: 0.8074 - val_accuracy: 0.6581\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7133 - accuracy: 0.6815 - val_loss: 0.8385 - val_accuracy: 0.6667\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7207 - accuracy: 0.6889 - val_loss: 0.8082 - val_accuracy: 0.6496\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7208 - accuracy: 0.6852 - val_loss: 0.8279 - val_accuracy: 0.6496\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7144 - accuracy: 0.6889 - val_loss: 0.8286 - val_accuracy: 0.6581\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7134 - accuracy: 0.7037 - val_loss: 0.8119 - val_accuracy: 0.6667\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7124 - accuracy: 0.6889 - val_loss: 0.8111 - val_accuracy: 0.6752\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7240 - accuracy: 0.6852 - val_loss: 0.8535 - val_accuracy: 0.6752\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7398 - accuracy: 0.6778 - val_loss: 0.8034 - val_accuracy: 0.6667\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7310 - accuracy: 0.6963 - val_loss: 0.8286 - val_accuracy: 0.6581\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7207 - accuracy: 0.6889 - val_loss: 0.8109 - val_accuracy: 0.6667\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7265 - accuracy: 0.6852 - val_loss: 0.7965 - val_accuracy: 0.6838\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7336 - accuracy: 0.6778 - val_loss: 0.8195 - val_accuracy: 0.6752\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7235 - accuracy: 0.6926 - val_loss: 0.8402 - val_accuracy: 0.6752\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7253 - accuracy: 0.6926 - val_loss: 0.7990 - val_accuracy: 0.6752\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7169 - accuracy: 0.6852 - val_loss: 0.9027 - val_accuracy: 0.6752\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7545 - accuracy: 0.6926 - val_loss: 0.8690 - val_accuracy: 0.6752\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7183 - accuracy: 0.7037 - val_loss: 0.8031 - val_accuracy: 0.6752\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7087 - accuracy: 0.6963 - val_loss: 0.8531 - val_accuracy: 0.6581\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7246 - accuracy: 0.6852 - val_loss: 0.8045 - val_accuracy: 0.6838\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7152 - accuracy: 0.6926 - val_loss: 0.8519 - val_accuracy: 0.6667\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7381 - accuracy: 0.6926 - val_loss: 0.8200 - val_accuracy: 0.6581\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7440 - accuracy: 0.6815 - val_loss: 0.8416 - val_accuracy: 0.6581\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7174 - accuracy: 0.7037 - val_loss: 0.8715 - val_accuracy: 0.6496\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7250 - accuracy: 0.6963 - val_loss: 0.8015 - val_accuracy: 0.6752\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7404 - accuracy: 0.6889 - val_loss: 1.0637 - val_accuracy: 0.6667\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8560 - accuracy: 0.6815 - val_loss: 1.1620 - val_accuracy: 0.6667\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8253 - accuracy: 0.6852 - val_loss: 0.8461 - val_accuracy: 0.6838\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0493 - accuracy: 0.6667 - val_loss: 0.8987 - val_accuracy: 0.6667\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9080 - accuracy: 0.6704 - val_loss: 1.5171 - val_accuracy: 0.6667\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0866 - accuracy: 0.6630 - val_loss: 1.3632 - val_accuracy: 0.6838\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9425 - accuracy: 0.6778 - val_loss: 0.9192 - val_accuracy: 0.6581\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7520 - accuracy: 0.6852 - val_loss: 0.8797 - val_accuracy: 0.5812\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7788 - accuracy: 0.6667 - val_loss: 0.9740 - val_accuracy: 0.6838\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7639 - accuracy: 0.7074 - val_loss: 0.9031 - val_accuracy: 0.6581\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7313 - accuracy: 0.7000 - val_loss: 0.8249 - val_accuracy: 0.6496\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7598 - accuracy: 0.6815 - val_loss: 0.9331 - val_accuracy: 0.6581\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8002 - accuracy: 0.6815 - val_loss: 0.9807 - val_accuracy: 0.6581\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7751 - accuracy: 0.6852 - val_loss: 0.8460 - val_accuracy: 0.6581\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7810 - accuracy: 0.6630 - val_loss: 1.0900 - val_accuracy: 0.6068\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8655 - accuracy: 0.6556 - val_loss: 0.9023 - val_accuracy: 0.6838\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7418 - accuracy: 0.7000 - val_loss: 0.9097 - val_accuracy: 0.6239\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8516 - accuracy: 0.6704 - val_loss: 1.0263 - val_accuracy: 0.6239\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9625 - accuracy: 0.6407 - val_loss: 1.0766 - val_accuracy: 0.6068\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7744 - accuracy: 0.6778 - val_loss: 0.8902 - val_accuracy: 0.6154\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8312 - accuracy: 0.6444 - val_loss: 0.9513 - val_accuracy: 0.6667\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8409 - accuracy: 0.6704 - val_loss: 1.0292 - val_accuracy: 0.6325\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7978 - accuracy: 0.6815 - val_loss: 0.8146 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7410 - accuracy: 0.6556 - val_loss: 0.8515 - val_accuracy: 0.6838\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7356 - accuracy: 0.7037 - val_loss: 0.8302 - val_accuracy: 0.6752\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7299 - accuracy: 0.7074 - val_loss: 0.8176 - val_accuracy: 0.6752\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7142 - accuracy: 0.6963 - val_loss: 0.8448 - val_accuracy: 0.6923\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7267 - accuracy: 0.6852 - val_loss: 0.8216 - val_accuracy: 0.6838\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7288 - accuracy: 0.6963 - val_loss: 0.8402 - val_accuracy: 0.6838\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7161 - accuracy: 0.6963 - val_loss: 0.8435 - val_accuracy: 0.6923\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7312 - accuracy: 0.7074 - val_loss: 0.8621 - val_accuracy: 0.6667\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7058 - accuracy: 0.6963 - val_loss: 0.8071 - val_accuracy: 0.6581\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7316 - accuracy: 0.6926 - val_loss: 0.8377 - val_accuracy: 0.6581\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7051 - accuracy: 0.7074 - val_loss: 0.8162 - val_accuracy: 0.6838\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7144 - accuracy: 0.6926 - val_loss: 0.8492 - val_accuracy: 0.6752\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7165 - accuracy: 0.6963 - val_loss: 0.8183 - val_accuracy: 0.6752\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7047 - accuracy: 0.6926 - val_loss: 0.8225 - val_accuracy: 0.6752\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7117 - accuracy: 0.6926 - val_loss: 0.8237 - val_accuracy: 0.6752\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7069 - accuracy: 0.7000 - val_loss: 0.8070 - val_accuracy: 0.6667\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7117 - accuracy: 0.6926 - val_loss: 0.8268 - val_accuracy: 0.6581\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7131 - accuracy: 0.6889 - val_loss: 0.8205 - val_accuracy: 0.6496\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7085 - accuracy: 0.6889 - val_loss: 0.8452 - val_accuracy: 0.6496\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7388 - accuracy: 0.6667 - val_loss: 0.8801 - val_accuracy: 0.6410\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8228 - accuracy: 0.6481 - val_loss: 0.9116 - val_accuracy: 0.6068\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7895 - accuracy: 0.6704 - val_loss: 0.8453 - val_accuracy: 0.6752\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7635 - accuracy: 0.6815 - val_loss: 0.8907 - val_accuracy: 0.6667\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7737 - accuracy: 0.6630 - val_loss: 0.8914 - val_accuracy: 0.6410\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8541 - accuracy: 0.6519 - val_loss: 1.0026 - val_accuracy: 0.6667\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8203 - accuracy: 0.6741 - val_loss: 0.9161 - val_accuracy: 0.6838\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7663 - accuracy: 0.6593 - val_loss: 0.8274 - val_accuracy: 0.6581\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8025 - accuracy: 0.6556 - val_loss: 0.8935 - val_accuracy: 0.6410\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7548 - accuracy: 0.6741 - val_loss: 0.8131 - val_accuracy: 0.6838\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7506 - accuracy: 0.6778 - val_loss: 0.9934 - val_accuracy: 0.6752\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7804 - accuracy: 0.6889 - val_loss: 0.8676 - val_accuracy: 0.6752\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7418 - accuracy: 0.7037 - val_loss: 0.9154 - val_accuracy: 0.6838\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8349 - accuracy: 0.6815 - val_loss: 1.4770 - val_accuracy: 0.6667\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0584 - accuracy: 0.6704 - val_loss: 1.2247 - val_accuracy: 0.6752\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7819 - accuracy: 0.6926 - val_loss: 0.8462 - val_accuracy: 0.6410\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9278 - accuracy: 0.6630 - val_loss: 1.1146 - val_accuracy: 0.6581\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9161 - accuracy: 0.6778 - val_loss: 1.2326 - val_accuracy: 0.6496\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8737 - accuracy: 0.6889 - val_loss: 0.9971 - val_accuracy: 0.6154\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7619 - accuracy: 0.6778 - val_loss: 1.0108 - val_accuracy: 0.5470\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0571 - accuracy: 0.6444 - val_loss: 1.2254 - val_accuracy: 0.5214\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9105 - accuracy: 0.6519 - val_loss: 0.8444 - val_accuracy: 0.6496\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9171 - accuracy: 0.6667 - val_loss: 0.8445 - val_accuracy: 0.6410\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8091 - accuracy: 0.6704 - val_loss: 1.0782 - val_accuracy: 0.6068\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8196 - accuracy: 0.6815 - val_loss: 0.8239 - val_accuracy: 0.6410\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7371 - accuracy: 0.6704 - val_loss: 0.8687 - val_accuracy: 0.6154\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7783 - accuracy: 0.6926 - val_loss: 0.9991 - val_accuracy: 0.6496\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8253 - accuracy: 0.6630 - val_loss: 0.8297 - val_accuracy: 0.6239\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7428 - accuracy: 0.6926 - val_loss: 0.8232 - val_accuracy: 0.6410\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7150 - accuracy: 0.7000 - val_loss: 0.9010 - val_accuracy: 0.6838\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7355 - accuracy: 0.7037 - val_loss: 0.8092 - val_accuracy: 0.6838\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7282 - accuracy: 0.6963 - val_loss: 0.8257 - val_accuracy: 0.6838\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7240 - accuracy: 0.6889 - val_loss: 0.8443 - val_accuracy: 0.6667\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7167 - accuracy: 0.6926 - val_loss: 0.8123 - val_accuracy: 0.6838\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7058 - accuracy: 0.7037 - val_loss: 0.8339 - val_accuracy: 0.6838\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7080 - accuracy: 0.7000 - val_loss: 0.8148 - val_accuracy: 0.6752\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7075 - accuracy: 0.6926 - val_loss: 0.8406 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7431 - accuracy: 0.6889 - val_loss: 0.8135 - val_accuracy: 0.6667\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7301 - accuracy: 0.6852 - val_loss: 0.8911 - val_accuracy: 0.6752\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7676 - accuracy: 0.6815 - val_loss: 0.9697 - val_accuracy: 0.6752\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7188 - accuracy: 0.7037 - val_loss: 0.8373 - val_accuracy: 0.6581\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8146 - accuracy: 0.6778 - val_loss: 1.0455 - val_accuracy: 0.6667\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8198 - accuracy: 0.6852 - val_loss: 0.9788 - val_accuracy: 0.6752\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7609 - accuracy: 0.6889 - val_loss: 0.8093 - val_accuracy: 0.6581\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7276 - accuracy: 0.6815 - val_loss: 0.8353 - val_accuracy: 0.6581\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7051 - accuracy: 0.7000 - val_loss: 0.8161 - val_accuracy: 0.6496\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7121 - accuracy: 0.6815 - val_loss: 0.8158 - val_accuracy: 0.6581\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7174 - accuracy: 0.6852 - val_loss: 0.8500 - val_accuracy: 0.6667\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7364 - accuracy: 0.6889 - val_loss: 0.8801 - val_accuracy: 0.6667\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7106 - accuracy: 0.6852 - val_loss: 0.8164 - val_accuracy: 0.6752\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7109 - accuracy: 0.6963 - val_loss: 0.8592 - val_accuracy: 0.6667\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7073 - accuracy: 0.6926 - val_loss: 0.8231 - val_accuracy: 0.6752\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7080 - accuracy: 0.6963 - val_loss: 0.8248 - val_accuracy: 0.6752\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7032 - accuracy: 0.6889 - val_loss: 0.8591 - val_accuracy: 0.6752\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7133 - accuracy: 0.7000 - val_loss: 0.8364 - val_accuracy: 0.6752\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7026 - accuracy: 0.7000 - val_loss: 0.8146 - val_accuracy: 0.6752\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7130 - accuracy: 0.6852 - val_loss: 0.8048 - val_accuracy: 0.6752\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7049 - accuracy: 0.6963 - val_loss: 0.8407 - val_accuracy: 0.6667\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7374 - accuracy: 0.6926 - val_loss: 0.8222 - val_accuracy: 0.6752\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8145 - accuracy: 0.6741 - val_loss: 0.9183 - val_accuracy: 0.6410\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7869 - accuracy: 0.7000 - val_loss: 0.9799 - val_accuracy: 0.6496\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7565 - accuracy: 0.7074 - val_loss: 0.8071 - val_accuracy: 0.6410\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7204 - accuracy: 0.7037 - val_loss: 0.8336 - val_accuracy: 0.6581\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7227 - accuracy: 0.6852 - val_loss: 0.8166 - val_accuracy: 0.6667\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7071 - accuracy: 0.6963 - val_loss: 0.8084 - val_accuracy: 0.6667\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7030 - accuracy: 0.6889 - val_loss: 0.8262 - val_accuracy: 0.6752\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7104 - accuracy: 0.6963 - val_loss: 0.8106 - val_accuracy: 0.6752\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8325 - accuracy: 0.7000 - val_loss: 0.8553 - val_accuracy: 0.6667\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8851 - accuracy: 0.6667 - val_loss: 1.2107 - val_accuracy: 0.6325\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8584 - accuracy: 0.6741 - val_loss: 0.8413 - val_accuracy: 0.6752\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7949 - accuracy: 0.6852 - val_loss: 0.9331 - val_accuracy: 0.6752\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9592 - accuracy: 0.6630 - val_loss: 1.6801 - val_accuracy: 0.6239\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1576 - accuracy: 0.6333 - val_loss: 1.2203 - val_accuracy: 0.6752\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8283 - accuracy: 0.6741 - val_loss: 0.9076 - val_accuracy: 0.6239\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8400 - accuracy: 0.6630 - val_loss: 0.9916 - val_accuracy: 0.6752\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7913 - accuracy: 0.7222 - val_loss: 1.0398 - val_accuracy: 0.6838\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7867 - accuracy: 0.7037 - val_loss: 0.8449 - val_accuracy: 0.6496\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7180 - accuracy: 0.6852 - val_loss: 0.8590 - val_accuracy: 0.6410\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7255 - accuracy: 0.7037 - val_loss: 0.8618 - val_accuracy: 0.6496\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7139 - accuracy: 0.7037 - val_loss: 0.8277 - val_accuracy: 0.6496\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7738 - accuracy: 0.6704 - val_loss: 0.9064 - val_accuracy: 0.6581\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7397 - accuracy: 0.7074 - val_loss: 0.9284 - val_accuracy: 0.6752\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7462 - accuracy: 0.6889 - val_loss: 0.8223 - val_accuracy: 0.6581\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7299 - accuracy: 0.6926 - val_loss: 0.9377 - val_accuracy: 0.6752\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7654 - accuracy: 0.6926 - val_loss: 0.9295 - val_accuracy: 0.6752\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7240 - accuracy: 0.7111 - val_loss: 0.8297 - val_accuracy: 0.6496\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7397 - accuracy: 0.6852 - val_loss: 0.8780 - val_accuracy: 0.6410\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7009 - accuracy: 0.6889 - val_loss: 0.8232 - val_accuracy: 0.6496\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7562 - accuracy: 0.6667 - val_loss: 0.8461 - val_accuracy: 0.6667\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7423 - accuracy: 0.6778 - val_loss: 0.8301 - val_accuracy: 0.6581\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7384 - accuracy: 0.6852 - val_loss: 0.8752 - val_accuracy: 0.6667\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7329 - accuracy: 0.6963 - val_loss: 0.9525 - val_accuracy: 0.6838\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7246 - accuracy: 0.6963 - val_loss: 0.8048 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7545 - accuracy: 0.6741 - val_loss: 0.9480 - val_accuracy: 0.6667\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7741 - accuracy: 0.7037 - val_loss: 0.9562 - val_accuracy: 0.6752\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7344 - accuracy: 0.7074 - val_loss: 0.8076 - val_accuracy: 0.6752\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7321 - accuracy: 0.6667 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7115 - accuracy: 0.7148 - val_loss: 0.8434 - val_accuracy: 0.6923\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7128 - accuracy: 0.7074 - val_loss: 0.8432 - val_accuracy: 0.6667\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7115 - accuracy: 0.6889 - val_loss: 0.8011 - val_accuracy: 0.6752\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7159 - accuracy: 0.6889 - val_loss: 0.8585 - val_accuracy: 0.6667\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7191 - accuracy: 0.6963 - val_loss: 0.8464 - val_accuracy: 0.6667\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7005 - accuracy: 0.6963 - val_loss: 0.7969 - val_accuracy: 0.6752\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7201 - accuracy: 0.6852 - val_loss: 0.8412 - val_accuracy: 0.6667\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7335 - accuracy: 0.6963 - val_loss: 0.8104 - val_accuracy: 0.6667\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8940 - accuracy: 0.6852 - val_loss: 0.8538 - val_accuracy: 0.6752\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7940 - accuracy: 0.6704 - val_loss: 1.2135 - val_accuracy: 0.6496\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8598 - accuracy: 0.6778 - val_loss: 0.8128 - val_accuracy: 0.6838\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7264 - accuracy: 0.7000 - val_loss: 0.8847 - val_accuracy: 0.6923\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7399 - accuracy: 0.7037 - val_loss: 0.9041 - val_accuracy: 0.6667\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7094 - accuracy: 0.6852 - val_loss: 0.8160 - val_accuracy: 0.6667\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7022 - accuracy: 0.6963 - val_loss: 0.8499 - val_accuracy: 0.6752\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7108 - accuracy: 0.7000 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6998 - accuracy: 0.6963 - val_loss: 0.8179 - val_accuracy: 0.6838\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7172 - accuracy: 0.6852 - val_loss: 0.8071 - val_accuracy: 0.6752\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7213 - accuracy: 0.7037 - val_loss: 0.8004 - val_accuracy: 0.6752\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7089 - accuracy: 0.7000 - val_loss: 0.8390 - val_accuracy: 0.6581\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7106 - accuracy: 0.6815 - val_loss: 0.8595 - val_accuracy: 0.6667\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7059 - accuracy: 0.6926 - val_loss: 0.8035 - val_accuracy: 0.6752\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7043 - accuracy: 0.6889 - val_loss: 0.8311 - val_accuracy: 0.6838\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7010 - accuracy: 0.6889 - val_loss: 0.8098 - val_accuracy: 0.6752\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6981 - accuracy: 0.6889 - val_loss: 0.8284 - val_accuracy: 0.6838\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6985 - accuracy: 0.7000 - val_loss: 0.8151 - val_accuracy: 0.6838\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7004 - accuracy: 0.6926 - val_loss: 0.8141 - val_accuracy: 0.6752\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7080 - accuracy: 0.6889 - val_loss: 0.8120 - val_accuracy: 0.6752\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7006 - accuracy: 0.6963 - val_loss: 0.8160 - val_accuracy: 0.6838\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6999 - accuracy: 0.6963 - val_loss: 0.8173 - val_accuracy: 0.6667\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6955 - accuracy: 0.7000 - val_loss: 0.8341 - val_accuracy: 0.6752\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7071 - accuracy: 0.6963 - val_loss: 0.8225 - val_accuracy: 0.6667\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7005 - accuracy: 0.6889 - val_loss: 0.8030 - val_accuracy: 0.6838\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6966 - accuracy: 0.6963 - val_loss: 0.8319 - val_accuracy: 0.6838\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6987 - accuracy: 0.7037 - val_loss: 0.8050 - val_accuracy: 0.6752\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7006 - accuracy: 0.6926 - val_loss: 0.8088 - val_accuracy: 0.6667\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6970 - accuracy: 0.6926 - val_loss: 0.8085 - val_accuracy: 0.6838\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7316 - accuracy: 0.6852 - val_loss: 0.8161 - val_accuracy: 0.6752\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7248 - accuracy: 0.6815 - val_loss: 0.8621 - val_accuracy: 0.6667\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7244 - accuracy: 0.6963 - val_loss: 0.9218 - val_accuracy: 0.6667\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7162 - accuracy: 0.6963 - val_loss: 0.8052 - val_accuracy: 0.6752\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7047 - accuracy: 0.6889 - val_loss: 0.8112 - val_accuracy: 0.6667\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7063 - accuracy: 0.6852 - val_loss: 0.8435 - val_accuracy: 0.6496\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7080 - accuracy: 0.6889 - val_loss: 0.8171 - val_accuracy: 0.6581\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7150 - accuracy: 0.6963 - val_loss: 0.8410 - val_accuracy: 0.6667\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7159 - accuracy: 0.6926 - val_loss: 0.9016 - val_accuracy: 0.6752\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7162 - accuracy: 0.6889 - val_loss: 0.8071 - val_accuracy: 0.6752\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 64.63%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.32143250e-02, 2.53005160e-03, 9.74255600e-01],\n",
       "       [2.02739520e-02, 5.50900260e-03, 9.74217060e-01],\n",
       "       [2.44668160e-01, 9.79154300e-02, 6.57416400e-01],\n",
       "       [2.32143250e-02, 2.53005160e-03, 9.74255600e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [5.28821050e-02, 2.40460450e-02, 9.23071800e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [3.10971440e-01, 4.59986750e-01, 2.29041800e-01],\n",
       "       [1.64014620e-01, 8.20671600e-01, 1.53138050e-02],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [6.77101300e-04, 1.93885830e-08, 9.99322900e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [1.87493620e-01, 3.79260060e-01, 4.33246300e-01],\n",
       "       [6.19027100e-01, 3.51751950e-01, 2.92209890e-02],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [1.22721900e-03, 5.06774380e-05, 9.98722140e-01],\n",
       "       [1.40099730e-01, 1.68918730e-02, 8.43008400e-01],\n",
       "       [3.80423700e-01, 6.30313060e-04, 6.18946100e-01],\n",
       "       [2.13536400e-02, 8.46871550e-03, 9.70177650e-01],\n",
       "       [4.89952860e-02, 7.78445100e-02, 8.73160200e-01],\n",
       "       [1.35841920e-01, 1.99589680e-01, 6.64568400e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [4.35563500e-01, 2.03826250e-01, 3.60610300e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.80423700e-01, 6.30313060e-04, 6.18946100e-01],\n",
       "       [3.97262220e-01, 5.15873400e-01, 8.68643800e-02],\n",
       "       [1.42793240e-03, 3.63107250e-04, 9.98209000e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [6.77101300e-04, 1.93885830e-08, 9.99322900e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [2.24675670e-01, 6.81548950e-01, 9.37753840e-02],\n",
       "       [2.90586110e-02, 7.57292700e-02, 8.95212050e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [6.19027100e-01, 3.51751950e-01, 2.92209890e-02],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [7.25699400e-02, 1.02844620e-02, 9.17145600e-01],\n",
       "       [2.02739520e-02, 5.50900260e-03, 9.74217060e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [4.35563500e-01, 2.03826250e-01, 3.60610300e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.78016600e-01, 2.37842150e-04, 6.21745600e-01],\n",
       "       [6.96836050e-01, 2.55522520e-01, 4.76414500e-02],\n",
       "       [2.32143250e-02, 2.53005160e-03, 9.74255600e-01],\n",
       "       [1.35841920e-01, 1.99589680e-01, 6.64568400e-01],\n",
       "       [2.02739520e-02, 5.50900260e-03, 9.74217060e-01],\n",
       "       [3.97262220e-01, 5.15873400e-01, 8.68643800e-02],\n",
       "       [6.96836050e-01, 2.55522520e-01, 4.76414500e-02],\n",
       "       [6.92530700e-02, 4.16299800e-01, 5.14447150e-01],\n",
       "       [2.32143250e-02, 2.53005160e-03, 9.74255600e-01],\n",
       "       [2.02739520e-02, 5.50900260e-03, 9.74217060e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [1.26384690e-01, 2.01696500e-02, 8.53445650e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [6.20959200e-04, 6.65018250e-06, 9.99372400e-01],\n",
       "       [1.38981440e-03, 2.76467540e-08, 9.98610140e-01],\n",
       "       [2.90586110e-02, 7.57292700e-02, 8.95212050e-01],\n",
       "       [9.74210000e-01, 4.75479830e-05, 2.57424940e-02],\n",
       "       [2.24675670e-01, 6.81548950e-01, 9.37753840e-02],\n",
       "       [5.14669950e-01, 6.51584500e-02, 4.20171560e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [2.24675670e-01, 6.81548950e-01, 9.37753840e-02],\n",
       "       [5.14669950e-01, 6.51584500e-02, 4.20171560e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [6.96836050e-01, 2.55522520e-01, 4.76414500e-02],\n",
       "       [2.02739520e-02, 5.50900260e-03, 9.74217060e-01],\n",
       "       [3.47214540e-03, 5.69300100e-03, 9.90834830e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [3.88353240e-02, 1.37223850e-01, 8.23940900e-01],\n",
       "       [3.10971440e-01, 4.59986750e-01, 2.29041800e-01],\n",
       "       [3.62189140e-01, 4.94363830e-02, 5.88374500e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [1.21325046e-01, 1.61677270e-01, 7.16997740e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [1.21325046e-01, 1.61677270e-01, 7.16997740e-01],\n",
       "       [3.80423700e-01, 6.30313060e-04, 6.18946100e-01],\n",
       "       [3.80423700e-01, 6.30313060e-04, 6.18946100e-01],\n",
       "       [2.24675670e-01, 6.81548950e-01, 9.37753840e-02],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [6.74078940e-01, 2.91855160e-01, 3.40658240e-02],\n",
       "       [2.94516570e-02, 2.18003700e-02, 9.48748000e-01],\n",
       "       [1.64014620e-01, 8.20671600e-01, 1.53138050e-02],\n",
       "       [1.35841920e-01, 1.99589680e-01, 6.64568400e-01],\n",
       "       [3.10971440e-01, 4.59986750e-01, 2.29041800e-01],\n",
       "       [4.35408400e-01, 5.03578820e-02, 5.14233650e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [4.06135300e-03, 5.47746150e-03, 9.90461200e-01],\n",
       "       [2.90586110e-02, 7.57292700e-02, 8.95212050e-01],\n",
       "       [1.34622450e-01, 2.48310900e-01, 6.17066700e-01],\n",
       "       [2.90586110e-02, 7.57292700e-02, 8.95212050e-01],\n",
       "       [1.26384690e-01, 2.01696500e-02, 8.53445650e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [6.41407000e-01, 2.09890250e-06, 3.58590960e-01],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [3.50327800e-01, 4.53829140e-01, 1.95843040e-01],\n",
       "       [4.07823200e-01, 4.79629460e-01, 1.12547280e-01],\n",
       "       [8.31619200e-01, 8.70932300e-06, 1.68372060e-01],\n",
       "       [1.42793240e-03, 3.63107250e-04, 9.98209000e-01],\n",
       "       [2.24675670e-01, 6.81548950e-01, 9.37753840e-02],\n",
       "       [7.25699400e-02, 1.02844620e-02, 9.17145600e-01],\n",
       "       [5.47578000e-01, 3.68461220e-01, 8.39607500e-02],\n",
       "       [3.97262220e-01, 5.15873400e-01, 8.68643800e-02],\n",
       "       [4.06135300e-03, 5.47746150e-03, 9.90461200e-01],\n",
       "       [1.27922180e-01, 4.64662350e-02, 8.25611530e-01],\n",
       "       [6.96836050e-01, 2.55522520e-01, 4.76414500e-02],\n",
       "       [3.93953000e-01, 2.26959060e-01, 3.79087950e-01],\n",
       "       [3.80423700e-01, 6.30313060e-04, 6.18946100e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876397107166339"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876397107166339"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR4187     0\n",
       "1         NRS177     0\n",
       "2         NRS109     2\n",
       "3    CFBREBSa131     2\n",
       "4         SR4152     1\n",
       "..           ...   ...\n",
       "112       NRS110     2\n",
       "113     CFBRSa25     1\n",
       "114         834N     0\n",
       "115  CFBREBSa114     1\n",
       "116       NRS387     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 582us/step - loss: 5.9427 - accuracy: 0.3259 - val_loss: 7.4440 - val_accuracy: 0.2991\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 4.4709 - accuracy: 0.3889 - val_loss: 5.3584 - val_accuracy: 0.3590\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 3.5127 - accuracy: 0.3815 - val_loss: 4.1276 - val_accuracy: 0.3590\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 2.7177 - accuracy: 0.3963 - val_loss: 2.2060 - val_accuracy: 0.3590\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.7836 - accuracy: 0.3926 - val_loss: 1.4081 - val_accuracy: 0.3162\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.4302 - accuracy: 0.4556 - val_loss: 1.7357 - val_accuracy: 0.4530\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.7184 - accuracy: 0.4593 - val_loss: 1.4612 - val_accuracy: 0.4615\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.3967 - accuracy: 0.4667 - val_loss: 1.2156 - val_accuracy: 0.4103\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.2018 - accuracy: 0.4778 - val_loss: 1.6251 - val_accuracy: 0.4444\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.3281 - accuracy: 0.5148 - val_loss: 1.4794 - val_accuracy: 0.4103\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.3346 - accuracy: 0.4741 - val_loss: 1.1713 - val_accuracy: 0.4786\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.3096 - accuracy: 0.4741 - val_loss: 1.2042 - val_accuracy: 0.4786\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.1763 - accuracy: 0.5000 - val_loss: 1.1033 - val_accuracy: 0.4359\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 1.1838 - accuracy: 0.4741 - val_loss: 1.1540 - val_accuracy: 0.4701\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.5093 - accuracy: 0.4889 - val_loss: 1.6299 - val_accuracy: 0.4017\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.6466 - accuracy: 0.4815 - val_loss: 1.2092 - val_accuracy: 0.4872\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1716 - accuracy: 0.4815 - val_loss: 2.1305 - val_accuracy: 0.4188\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.6758 - accuracy: 0.5037 - val_loss: 1.4934 - val_accuracy: 0.5043\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.4117 - accuracy: 0.4889 - val_loss: 1.4598 - val_accuracy: 0.4188\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.3929 - accuracy: 0.4741 - val_loss: 1.6920 - val_accuracy: 0.4444\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.4523 - accuracy: 0.5333 - val_loss: 1.9307 - val_accuracy: 0.4701\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.4301 - accuracy: 0.5333 - val_loss: 1.4020 - val_accuracy: 0.4872\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.1696 - accuracy: 0.5074 - val_loss: 1.2031 - val_accuracy: 0.4701\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1375 - accuracy: 0.5185 - val_loss: 1.2977 - val_accuracy: 0.4957\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1768 - accuracy: 0.5407 - val_loss: 1.3569 - val_accuracy: 0.4957\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.2542 - accuracy: 0.5259 - val_loss: 1.2605 - val_accuracy: 0.4701\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.2027 - accuracy: 0.4889 - val_loss: 1.2929 - val_accuracy: 0.4957\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1653 - accuracy: 0.5185 - val_loss: 1.5111 - val_accuracy: 0.4872\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.3253 - accuracy: 0.5407 - val_loss: 1.0493 - val_accuracy: 0.4701\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.3530 - accuracy: 0.5407 - val_loss: 1.1044 - val_accuracy: 0.4872\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.4294 - accuracy: 0.5148 - val_loss: 1.8653 - val_accuracy: 0.4359\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.8509 - accuracy: 0.5222 - val_loss: 1.5974 - val_accuracy: 0.4701\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.5442 - accuracy: 0.5185 - val_loss: 1.1782 - val_accuracy: 0.4957\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.1466 - accuracy: 0.5444 - val_loss: 1.2284 - val_accuracy: 0.5128\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 1.1088 - accuracy: 0.5259 - val_loss: 1.0538 - val_accuracy: 0.4615\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1011 - accuracy: 0.5259 - val_loss: 1.0266 - val_accuracy: 0.4786\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.1785 - accuracy: 0.5259 - val_loss: 1.2393 - val_accuracy: 0.4701\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.1669 - accuracy: 0.5519 - val_loss: 1.6230 - val_accuracy: 0.5385\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.2503 - accuracy: 0.5481 - val_loss: 1.3708 - val_accuracy: 0.5214\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0000 - accuracy: 0.5519 - val_loss: 1.2431 - val_accuracy: 0.4701\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1735 - accuracy: 0.5148 - val_loss: 1.3736 - val_accuracy: 0.5214\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.2752 - accuracy: 0.5333 - val_loss: 1.7308 - val_accuracy: 0.4872\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.3942 - accuracy: 0.5630 - val_loss: 1.2911 - val_accuracy: 0.5128\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.1213 - accuracy: 0.5259 - val_loss: 1.4732 - val_accuracy: 0.4786\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.2559 - accuracy: 0.5185 - val_loss: 1.5164 - val_accuracy: 0.4957\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.9248 - accuracy: 0.5407 - val_loss: 2.5068 - val_accuracy: 0.4530\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.8591 - accuracy: 0.5407 - val_loss: 1.2050 - val_accuracy: 0.5214\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.2994 - accuracy: 0.5333 - val_loss: 1.5024 - val_accuracy: 0.4530\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 1.2525 - accuracy: 0.5000 - val_loss: 1.3174 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.1676 - accuracy: 0.5519 - val_loss: 1.5707 - val_accuracy: 0.5385\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.1652 - accuracy: 0.5370 - val_loss: 1.1027 - val_accuracy: 0.5470\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.0618 - accuracy: 0.5556 - val_loss: 1.0431 - val_accuracy: 0.4786\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0196 - accuracy: 0.5556 - val_loss: 1.1668 - val_accuracy: 0.5470\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0027 - accuracy: 0.5519 - val_loss: 1.1589 - val_accuracy: 0.5128\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.3701 - accuracy: 0.5778 - val_loss: 1.9113 - val_accuracy: 0.4957\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.3878 - accuracy: 0.5519 - val_loss: 1.6269 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1445 - accuracy: 0.5630 - val_loss: 1.3148 - val_accuracy: 0.4701\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.1840 - accuracy: 0.5074 - val_loss: 1.2057 - val_accuracy: 0.5299\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.0909 - accuracy: 0.5704 - val_loss: 1.4146 - val_accuracy: 0.5214\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.1455 - accuracy: 0.5333 - val_loss: 1.0767 - val_accuracy: 0.5641\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 1.0899 - accuracy: 0.5519 - val_loss: 1.0178 - val_accuracy: 0.5470\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9568 - accuracy: 0.5630 - val_loss: 1.1766 - val_accuracy: 0.5385\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9665 - accuracy: 0.5519 - val_loss: 1.1064 - val_accuracy: 0.4786\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9567 - accuracy: 0.5630 - val_loss: 1.0148 - val_accuracy: 0.5043\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.9415 - accuracy: 0.5556 - val_loss: 1.0968 - val_accuracy: 0.4786\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9403 - accuracy: 0.5630 - val_loss: 0.9868 - val_accuracy: 0.5043\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 1.0079 - accuracy: 0.5481 - val_loss: 1.1812 - val_accuracy: 0.5299\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0395 - accuracy: 0.5481 - val_loss: 1.3248 - val_accuracy: 0.5043\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9975 - accuracy: 0.5704 - val_loss: 0.9787 - val_accuracy: 0.5128\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1273 - accuracy: 0.5481 - val_loss: 1.1346 - val_accuracy: 0.5470\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.1127 - accuracy: 0.5407 - val_loss: 1.3800 - val_accuracy: 0.5299\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0309 - accuracy: 0.5704 - val_loss: 1.0237 - val_accuracy: 0.5470\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9917 - accuracy: 0.5333 - val_loss: 1.0626 - val_accuracy: 0.5470\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.0329 - accuracy: 0.5704 - val_loss: 1.4782 - val_accuracy: 0.5470\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 2.0529 - accuracy: 0.5630 - val_loss: 2.8079 - val_accuracy: 0.4444\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 2.9400 - accuracy: 0.5037 - val_loss: 1.8840 - val_accuracy: 0.4444\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 2.3924 - accuracy: 0.5185 - val_loss: 1.0630 - val_accuracy: 0.4786\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.2834 - accuracy: 0.5370 - val_loss: 2.0718 - val_accuracy: 0.4786\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.6765 - accuracy: 0.5667 - val_loss: 2.1545 - val_accuracy: 0.5470\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.4470 - accuracy: 0.5852 - val_loss: 1.5833 - val_accuracy: 0.5043\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.0019 - accuracy: 0.5778 - val_loss: 1.2749 - val_accuracy: 0.4615\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.2293 - accuracy: 0.5370 - val_loss: 1.1458 - val_accuracy: 0.5214\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.2656 - accuracy: 0.5630 - val_loss: 1.2584 - val_accuracy: 0.5385\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.1128 - accuracy: 0.5667 - val_loss: 1.1234 - val_accuracy: 0.5043\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9667 - accuracy: 0.5481 - val_loss: 1.0507 - val_accuracy: 0.5214\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9649 - accuracy: 0.5370 - val_loss: 1.0185 - val_accuracy: 0.5214\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8901 - accuracy: 0.5630 - val_loss: 1.0540 - val_accuracy: 0.5128\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9198 - accuracy: 0.6037 - val_loss: 1.0972 - val_accuracy: 0.5726\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9308 - accuracy: 0.5926 - val_loss: 1.0246 - val_accuracy: 0.5128\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.0910 - accuracy: 0.51 - 0s 66us/step - loss: 0.9840 - accuracy: 0.5815 - val_loss: 1.1034 - val_accuracy: 0.5470\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0008 - accuracy: 0.6222 - val_loss: 1.2474 - val_accuracy: 0.5214\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9338 - accuracy: 0.5852 - val_loss: 1.1812 - val_accuracy: 0.4957\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 1.0083 - accuracy: 0.5593 - val_loss: 1.1027 - val_accuracy: 0.5385\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9837 - accuracy: 0.6000 - val_loss: 1.1183 - val_accuracy: 0.5556\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 1.0596 - accuracy: 0.5630 - val_loss: 0.9984 - val_accuracy: 0.4957\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9315 - accuracy: 0.5778 - val_loss: 1.2073 - val_accuracy: 0.5812\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9898 - accuracy: 0.5926 - val_loss: 0.9894 - val_accuracy: 0.5043\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8953 - accuracy: 0.5667 - val_loss: 0.9442 - val_accuracy: 0.5128\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8750 - accuracy: 0.5889 - val_loss: 0.9959 - val_accuracy: 0.5214\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8738 - accuracy: 0.6000 - val_loss: 0.9451 - val_accuracy: 0.5128\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8925 - accuracy: 0.5926 - val_loss: 1.0206 - val_accuracy: 0.5726\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9290 - accuracy: 0.6148 - val_loss: 1.0502 - val_accuracy: 0.5726\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8909 - accuracy: 0.6074 - val_loss: 1.0321 - val_accuracy: 0.5043\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9113 - accuracy: 0.6000 - val_loss: 1.1423 - val_accuracy: 0.5641\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9910 - accuracy: 0.6000 - val_loss: 1.0976 - val_accuracy: 0.5299\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9175 - accuracy: 0.5926 - val_loss: 0.9899 - val_accuracy: 0.5299\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9392 - accuracy: 0.5963 - val_loss: 0.9848 - val_accuracy: 0.5128\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9270 - accuracy: 0.5815 - val_loss: 1.0049 - val_accuracy: 0.5726\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8792 - accuracy: 0.5963 - val_loss: 0.9502 - val_accuracy: 0.5214\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8577 - accuracy: 0.6148 - val_loss: 0.9920 - val_accuracy: 0.5726\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8715 - accuracy: 0.6074 - val_loss: 1.0181 - val_accuracy: 0.5214\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9503 - accuracy: 0.5778 - val_loss: 0.9784 - val_accuracy: 0.5214\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9286 - accuracy: 0.5889 - val_loss: 1.2582 - val_accuracy: 0.5128\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9271 - accuracy: 0.6222 - val_loss: 1.0571 - val_accuracy: 0.5556\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.9372 - accuracy: 0.6037 - val_loss: 1.1213 - val_accuracy: 0.5214\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9199 - accuracy: 0.6222 - val_loss: 1.0615 - val_accuracy: 0.5470\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9419 - accuracy: 0.6111 - val_loss: 1.0731 - val_accuracy: 0.5726\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1188 - accuracy: 0.6037 - val_loss: 1.6586 - val_accuracy: 0.5385\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.1729 - accuracy: 0.6148 - val_loss: 1.1789 - val_accuracy: 0.5641\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9122 - accuracy: 0.5815 - val_loss: 1.4037 - val_accuracy: 0.4957\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.1986 - accuracy: 0.5667 - val_loss: 1.4779 - val_accuracy: 0.5470\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.2065 - accuracy: 0.6370 - val_loss: 1.6645 - val_accuracy: 0.5299\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.1499 - accuracy: 0.6222 - val_loss: 1.2097 - val_accuracy: 0.5385\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 1.0320 - accuracy: 0.5926 - val_loss: 0.9666 - val_accuracy: 0.5043\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9814 - accuracy: 0.5741 - val_loss: 1.1398 - val_accuracy: 0.5043\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 1.0012 - accuracy: 0.5815 - val_loss: 0.9870 - val_accuracy: 0.5299\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 1.0064 - accuracy: 0.5926 - val_loss: 0.9923 - val_accuracy: 0.5299\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9556 - accuracy: 0.5667 - val_loss: 0.9811 - val_accuracy: 0.5214\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9200 - accuracy: 0.6185 - val_loss: 1.0093 - val_accuracy: 0.5726\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9024 - accuracy: 0.5815 - val_loss: 1.1172 - val_accuracy: 0.4957\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9207 - accuracy: 0.5889 - val_loss: 1.1552 - val_accuracy: 0.5556\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9231 - accuracy: 0.6074 - val_loss: 0.9811 - val_accuracy: 0.5641\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9588 - accuracy: 0.6185 - val_loss: 1.0517 - val_accuracy: 0.5641\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9019 - accuracy: 0.6074 - val_loss: 1.2182 - val_accuracy: 0.5214\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9040 - accuracy: 0.6222 - val_loss: 0.9226 - val_accuracy: 0.5214\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9764 - accuracy: 0.5704 - val_loss: 1.2484 - val_accuracy: 0.5299\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0102 - accuracy: 0.5963 - val_loss: 1.1959 - val_accuracy: 0.5214\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.0441 - accuracy: 0.5704 - val_loss: 0.9661 - val_accuracy: 0.5128\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8663 - accuracy: 0.5889 - val_loss: 1.0870 - val_accuracy: 0.4957\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8772 - accuracy: 0.5963 - val_loss: 0.9821 - val_accuracy: 0.5556\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8726 - accuracy: 0.6148 - val_loss: 0.9216 - val_accuracy: 0.5385\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8255 - accuracy: 0.6296 - val_loss: 0.9799 - val_accuracy: 0.5385\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8429 - accuracy: 0.6185 - val_loss: 0.9198 - val_accuracy: 0.5556\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8543 - accuracy: 0.6333 - val_loss: 0.9268 - val_accuracy: 0.5556\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8452 - accuracy: 0.6296 - val_loss: 1.1748 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9732 - accuracy: 0.6370 - val_loss: 1.1153 - val_accuracy: 0.5214\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8361 - accuracy: 0.6370 - val_loss: 1.1354 - val_accuracy: 0.5299\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9785 - accuracy: 0.6037 - val_loss: 1.0954 - val_accuracy: 0.5641\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8859 - accuracy: 0.6111 - val_loss: 0.9233 - val_accuracy: 0.5470\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0105 - accuracy: 0.6259 - val_loss: 0.9734 - val_accuracy: 0.5385\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8645 - accuracy: 0.6259 - val_loss: 1.2602 - val_accuracy: 0.5214\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9223 - accuracy: 0.6185 - val_loss: 1.0505 - val_accuracy: 0.5470\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8772 - accuracy: 0.6407 - val_loss: 1.1753 - val_accuracy: 0.5726\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9957 - accuracy: 0.6370 - val_loss: 1.0988 - val_accuracy: 0.5556\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0184 - accuracy: 0.6333 - val_loss: 1.1231 - val_accuracy: 0.5556\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9618 - accuracy: 0.6333 - val_loss: 0.9710 - val_accuracy: 0.5128\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.5005 - accuracy: 0.6074 - val_loss: 1.6110 - val_accuracy: 0.5128\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 2.1554 - accuracy: 0.5741 - val_loss: 1.3144 - val_accuracy: 0.5214\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.2652 - accuracy: 0.6111 - val_loss: 1.9038 - val_accuracy: 0.4957\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 1.5626 - accuracy: 0.6037 - val_loss: 1.3379 - val_accuracy: 0.5470\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.2198 - accuracy: 0.6000 - val_loss: 1.2108 - val_accuracy: 0.5128\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 1.3138 - accuracy: 0.5519 - val_loss: 1.3288 - val_accuracy: 0.5470\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.1063 - accuracy: 0.6296 - val_loss: 1.6999 - val_accuracy: 0.4957\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1324 - accuracy: 0.5852 - val_loss: 1.0019 - val_accuracy: 0.5128\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 1.1014 - accuracy: 0.5778 - val_loss: 1.0112 - val_accuracy: 0.4872\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9779 - accuracy: 0.6037 - val_loss: 1.1041 - val_accuracy: 0.5299\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8957 - accuracy: 0.6296 - val_loss: 1.0148 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9433 - accuracy: 0.6148 - val_loss: 0.9560 - val_accuracy: 0.5470\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8983 - accuracy: 0.6111 - val_loss: 1.1838 - val_accuracy: 0.5385\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9052 - accuracy: 0.6333 - val_loss: 0.9414 - val_accuracy: 0.5556\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8613 - accuracy: 0.6519 - val_loss: 1.3537 - val_accuracy: 0.5385\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 1.7346 - accuracy: 0.6222 - val_loss: 3.2927 - val_accuracy: 0.5470\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 2.3068 - accuracy: 0.6000 - val_loss: 3.4223 - val_accuracy: 0.5385\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 2.2466 - accuracy: 0.6222 - val_loss: 3.1315 - val_accuracy: 0.5128\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.9258 - accuracy: 0.5852 - val_loss: 2.3539 - val_accuracy: 0.5128\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.3786 - accuracy: 0.5741 - val_loss: 1.1472 - val_accuracy: 0.4530\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.1188 - accuracy: 0.5444 - val_loss: 1.0798 - val_accuracy: 0.5214\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9928 - accuracy: 0.5815 - val_loss: 1.8056 - val_accuracy: 0.5470\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.3575 - accuracy: 0.6111 - val_loss: 1.8997 - val_accuracy: 0.5385\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.2796 - accuracy: 0.6148 - val_loss: 1.3743 - val_accuracy: 0.5128\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9554 - accuracy: 0.5852 - val_loss: 1.0076 - val_accuracy: 0.5043\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9100 - accuracy: 0.5556 - val_loss: 0.9840 - val_accuracy: 0.5556\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8399 - accuracy: 0.6148 - val_loss: 0.9918 - val_accuracy: 0.5128\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8229 - accuracy: 0.6222 - val_loss: 0.9239 - val_accuracy: 0.5214\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8241 - accuracy: 0.6370 - val_loss: 0.9543 - val_accuracy: 0.5556\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8201 - accuracy: 0.6444 - val_loss: 0.9179 - val_accuracy: 0.5385\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8021 - accuracy: 0.6519 - val_loss: 0.9105 - val_accuracy: 0.5641\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8032 - accuracy: 0.6667 - val_loss: 0.9390 - val_accuracy: 0.5812\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8213 - accuracy: 0.6481 - val_loss: 0.9555 - val_accuracy: 0.5726\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8281 - accuracy: 0.6667 - val_loss: 0.9362 - val_accuracy: 0.5299\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8083 - accuracy: 0.6593 - val_loss: 0.9035 - val_accuracy: 0.5556\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7940 - accuracy: 0.6667 - val_loss: 0.9309 - val_accuracy: 0.5726\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8178 - accuracy: 0.6630 - val_loss: 0.9336 - val_accuracy: 0.5726\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7976 - accuracy: 0.6593 - val_loss: 0.9058 - val_accuracy: 0.5641\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7986 - accuracy: 0.6704 - val_loss: 0.9065 - val_accuracy: 0.5470\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7942 - accuracy: 0.6519 - val_loss: 0.9032 - val_accuracy: 0.5726\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7927 - accuracy: 0.6630 - val_loss: 0.9109 - val_accuracy: 0.5556\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7951 - accuracy: 0.6630 - val_loss: 0.9109 - val_accuracy: 0.5641\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7949 - accuracy: 0.6778 - val_loss: 0.9000 - val_accuracy: 0.5641\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7977 - accuracy: 0.6593 - val_loss: 0.8968 - val_accuracy: 0.5641\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7977 - accuracy: 0.6630 - val_loss: 0.9241 - val_accuracy: 0.5641\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7957 - accuracy: 0.6704 - val_loss: 0.8935 - val_accuracy: 0.5726\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8063 - accuracy: 0.6630 - val_loss: 0.9095 - val_accuracy: 0.5299\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8163 - accuracy: 0.6481 - val_loss: 0.9857 - val_accuracy: 0.5812\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8672 - accuracy: 0.6556 - val_loss: 0.9721 - val_accuracy: 0.5043\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7990 - accuracy: 0.6519 - val_loss: 0.8854 - val_accuracy: 0.5641\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7873 - accuracy: 0.6667 - val_loss: 0.9075 - val_accuracy: 0.5385\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8068 - accuracy: 0.6481 - val_loss: 0.8950 - val_accuracy: 0.5641\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7891 - accuracy: 0.6778 - val_loss: 0.9144 - val_accuracy: 0.5897\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8500 - accuracy: 0.6333 - val_loss: 0.8854 - val_accuracy: 0.5641\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9573 - accuracy: 0.6296 - val_loss: 1.2913 - val_accuracy: 0.5556\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.2157 - accuracy: 0.6296 - val_loss: 1.0563 - val_accuracy: 0.5128\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8744 - accuracy: 0.6222 - val_loss: 0.9720 - val_accuracy: 0.5214\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9741 - accuracy: 0.6259 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8322 - accuracy: 0.6370 - val_loss: 1.0146 - val_accuracy: 0.5470\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8769 - accuracy: 0.6148 - val_loss: 1.0587 - val_accuracy: 0.5470\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8306 - accuracy: 0.6370 - val_loss: 1.3639 - val_accuracy: 0.5214\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9853 - accuracy: 0.6407 - val_loss: 1.0230 - val_accuracy: 0.5726\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0189 - accuracy: 0.6296 - val_loss: 0.9430 - val_accuracy: 0.5812\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8332 - accuracy: 0.6296 - val_loss: 0.9534 - val_accuracy: 0.5897\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.1139 - accuracy: 0.6370 - val_loss: 1.5358 - val_accuracy: 0.5470\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.2613 - accuracy: 0.6185 - val_loss: 1.1624 - val_accuracy: 0.5299\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0271 - accuracy: 0.6148 - val_loss: 1.2067 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9820 - accuracy: 0.6556 - val_loss: 1.2667 - val_accuracy: 0.5556\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9625 - accuracy: 0.6444 - val_loss: 0.9459 - val_accuracy: 0.5726\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7781 - accuracy: 0.6556 - val_loss: 1.0378 - val_accuracy: 0.5726\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8524 - accuracy: 0.6704 - val_loss: 0.9478 - val_accuracy: 0.5726\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7952 - accuracy: 0.6630 - val_loss: 0.9248 - val_accuracy: 0.5812\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7827 - accuracy: 0.6741 - val_loss: 0.8988 - val_accuracy: 0.5726\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7949 - accuracy: 0.6519 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7830 - accuracy: 0.6741 - val_loss: 0.9256 - val_accuracy: 0.5897\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7956 - accuracy: 0.6630 - val_loss: 0.9181 - val_accuracy: 0.5385\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7884 - accuracy: 0.6667 - val_loss: 0.9060 - val_accuracy: 0.5641\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8343 - accuracy: 0.6296 - val_loss: 1.0115 - val_accuracy: 0.5812\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8716 - accuracy: 0.6630 - val_loss: 1.0796 - val_accuracy: 0.5299\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9054 - accuracy: 0.6259 - val_loss: 1.0055 - val_accuracy: 0.5641\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9423 - accuracy: 0.6407 - val_loss: 0.9650 - val_accuracy: 0.5812\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8481 - accuracy: 0.6370 - val_loss: 1.3215 - val_accuracy: 0.5897\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.1201 - accuracy: 0.6259 - val_loss: 1.1107 - val_accuracy: 0.5556\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9848 - accuracy: 0.6556 - val_loss: 1.5580 - val_accuracy: 0.5299\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.1278 - accuracy: 0.6370 - val_loss: 1.1838 - val_accuracy: 0.5983\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8859 - accuracy: 0.6444 - val_loss: 1.1363 - val_accuracy: 0.5385\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9262 - accuracy: 0.6333 - val_loss: 1.1375 - val_accuracy: 0.5556\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9023 - accuracy: 0.6556 - val_loss: 1.1973 - val_accuracy: 0.5385\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8598 - accuracy: 0.6593 - val_loss: 0.8945 - val_accuracy: 0.5556\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8282 - accuracy: 0.6519 - val_loss: 0.8995 - val_accuracy: 0.5812\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8151 - accuracy: 0.6519 - val_loss: 1.0325 - val_accuracy: 0.5641\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8105 - accuracy: 0.6667 - val_loss: 0.8831 - val_accuracy: 0.5812\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7748 - accuracy: 0.6667 - val_loss: 0.8911 - val_accuracy: 0.5299\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7757 - accuracy: 0.6593 - val_loss: 0.9086 - val_accuracy: 0.5556\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7698 - accuracy: 0.6519 - val_loss: 0.8869 - val_accuracy: 0.5726\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7656 - accuracy: 0.6667 - val_loss: 0.8945 - val_accuracy: 0.5556\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7635 - accuracy: 0.6593 - val_loss: 0.8981 - val_accuracy: 0.5470\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7676 - accuracy: 0.6519 - val_loss: 0.8819 - val_accuracy: 0.5556\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7756 - accuracy: 0.6593 - val_loss: 0.8786 - val_accuracy: 0.5641\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7588 - accuracy: 0.6667 - val_loss: 0.9037 - val_accuracy: 0.5385\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7694 - accuracy: 0.6630 - val_loss: 0.8790 - val_accuracy: 0.5812\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7554 - accuracy: 0.6667 - val_loss: 0.8795 - val_accuracy: 0.5556\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7589 - accuracy: 0.6630 - val_loss: 0.8897 - val_accuracy: 0.5641\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7605 - accuracy: 0.6778 - val_loss: 0.8819 - val_accuracy: 0.5470\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7593 - accuracy: 0.6889 - val_loss: 0.8876 - val_accuracy: 0.5726\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7617 - accuracy: 0.6630 - val_loss: 0.9394 - val_accuracy: 0.5556\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7868 - accuracy: 0.6593 - val_loss: 0.9173 - val_accuracy: 0.5299\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7593 - accuracy: 0.6593 - val_loss: 0.8830 - val_accuracy: 0.5641\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7576 - accuracy: 0.6815 - val_loss: 0.8774 - val_accuracy: 0.5726\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7549 - accuracy: 0.6778 - val_loss: 0.8961 - val_accuracy: 0.5556\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7663 - accuracy: 0.6741 - val_loss: 0.8981 - val_accuracy: 0.5556\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7551 - accuracy: 0.6778 - val_loss: 0.8762 - val_accuracy: 0.5812\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7528 - accuracy: 0.6778 - val_loss: 0.8843 - val_accuracy: 0.5812\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7585 - accuracy: 0.6593 - val_loss: 0.8938 - val_accuracy: 0.5385\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7622 - accuracy: 0.6630 - val_loss: 0.8920 - val_accuracy: 0.5726\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7454 - accuracy: 0.6778 - val_loss: 0.9216 - val_accuracy: 0.5641\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8016 - accuracy: 0.6593 - val_loss: 1.0034 - val_accuracy: 0.5983\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7945 - accuracy: 0.6704 - val_loss: 0.8888 - val_accuracy: 0.5812\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7537 - accuracy: 0.6704 - val_loss: 0.8776 - val_accuracy: 0.5812\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7494 - accuracy: 0.6778 - val_loss: 0.9142 - val_accuracy: 0.5641\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7590 - accuracy: 0.6815 - val_loss: 0.8922 - val_accuracy: 0.5812\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7474 - accuracy: 0.6741 - val_loss: 0.8835 - val_accuracy: 0.5812\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7479 - accuracy: 0.6778 - val_loss: 0.8863 - val_accuracy: 0.5812\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7606 - accuracy: 0.6667 - val_loss: 0.9060 - val_accuracy: 0.5470\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7599 - accuracy: 0.6667 - val_loss: 0.9196 - val_accuracy: 0.5897\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7609 - accuracy: 0.6704 - val_loss: 0.9490 - val_accuracy: 0.5641\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8245 - accuracy: 0.6741 - val_loss: 1.2120 - val_accuracy: 0.5812\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.9741 - accuracy: 0.6593 - val_loss: 1.3690 - val_accuracy: 0.5214\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9251 - accuracy: 0.6630 - val_loss: 0.8773 - val_accuracy: 0.5812\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7897 - accuracy: 0.6630 - val_loss: 0.8920 - val_accuracy: 0.5812\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7894 - accuracy: 0.6704 - val_loss: 0.9909 - val_accuracy: 0.5043\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7641 - accuracy: 0.6889 - val_loss: 0.9102 - val_accuracy: 0.5470\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7744 - accuracy: 0.6667 - val_loss: 0.9213 - val_accuracy: 0.5983\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7629 - accuracy: 0.6630 - val_loss: 0.9357 - val_accuracy: 0.5299\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7497 - accuracy: 0.6852 - val_loss: 0.8879 - val_accuracy: 0.5812\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7602 - accuracy: 0.7000 - val_loss: 0.8922 - val_accuracy: 0.5556\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7491 - accuracy: 0.6852 - val_loss: 0.8977 - val_accuracy: 0.5726\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7471 - accuracy: 0.6667 - val_loss: 0.8811 - val_accuracy: 0.5641\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7753 - accuracy: 0.6889 - val_loss: 0.8972 - val_accuracy: 0.5726\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7450 - accuracy: 0.6926 - val_loss: 0.9386 - val_accuracy: 0.5641\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7798 - accuracy: 0.6630 - val_loss: 0.9740 - val_accuracy: 0.5983\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8009 - accuracy: 0.6704 - val_loss: 0.9452 - val_accuracy: 0.5726\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.2591 - accuracy: 0.6481 - val_loss: 1.0668 - val_accuracy: 0.5726\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7952 - accuracy: 0.6630 - val_loss: 1.2659 - val_accuracy: 0.5812\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9088 - accuracy: 0.6556 - val_loss: 1.0634 - val_accuracy: 0.5470\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8185 - accuracy: 0.6852 - val_loss: 0.9494 - val_accuracy: 0.5983\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8217 - accuracy: 0.6630 - val_loss: 0.9026 - val_accuracy: 0.5556\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7714 - accuracy: 0.6778 - val_loss: 0.8835 - val_accuracy: 0.5812\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7491 - accuracy: 0.6741 - val_loss: 0.8792 - val_accuracy: 0.5641\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7531 - accuracy: 0.6704 - val_loss: 0.9450 - val_accuracy: 0.5470\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7901 - accuracy: 0.6593 - val_loss: 0.9560 - val_accuracy: 0.5641\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7606 - accuracy: 0.6704 - val_loss: 0.9079 - val_accuracy: 0.5641\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7371 - accuracy: 0.6778 - val_loss: 0.9201 - val_accuracy: 0.5726\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7447 - accuracy: 0.6704 - val_loss: 0.8933 - val_accuracy: 0.5726\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7353 - accuracy: 0.6815 - val_loss: 0.8941 - val_accuracy: 0.5556\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7428 - accuracy: 0.6778 - val_loss: 0.9670 - val_accuracy: 0.5556\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8066 - accuracy: 0.6593 - val_loss: 1.0972 - val_accuracy: 0.5897\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8129 - accuracy: 0.6778 - val_loss: 0.9310 - val_accuracy: 0.5812\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7559 - accuracy: 0.6778 - val_loss: 0.9109 - val_accuracy: 0.5641\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7595 - accuracy: 0.6778 - val_loss: 0.8827 - val_accuracy: 0.5812\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7862 - accuracy: 0.6704 - val_loss: 0.8993 - val_accuracy: 0.5556\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8149 - accuracy: 0.6667 - val_loss: 0.8879 - val_accuracy: 0.5556\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8176 - accuracy: 0.6630 - val_loss: 0.9456 - val_accuracy: 0.5897\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7661 - accuracy: 0.6630 - val_loss: 1.1506 - val_accuracy: 0.5726\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8386 - accuracy: 0.6704 - val_loss: 1.1498 - val_accuracy: 0.5897\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8520 - accuracy: 0.6815 - val_loss: 1.1503 - val_accuracy: 0.5385\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8449 - accuracy: 0.6444 - val_loss: 1.0393 - val_accuracy: 0.5385\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8091 - accuracy: 0.6630 - val_loss: 0.9817 - val_accuracy: 0.5897\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7667 - accuracy: 0.6741 - val_loss: 0.8906 - val_accuracy: 0.5726\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7314 - accuracy: 0.6852 - val_loss: 0.8761 - val_accuracy: 0.5812\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7464 - accuracy: 0.6741 - val_loss: 0.8916 - val_accuracy: 0.5726\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8912 - accuracy: 0.6630 - val_loss: 1.1494 - val_accuracy: 0.5897\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0890 - accuracy: 0.6704 - val_loss: 1.5218 - val_accuracy: 0.5726\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0001 - accuracy: 0.6519 - val_loss: 0.9617 - val_accuracy: 0.5556\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9798 - accuracy: 0.6370 - val_loss: 0.9964 - val_accuracy: 0.5556\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8213 - accuracy: 0.6556 - val_loss: 1.2887 - val_accuracy: 0.5299\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0342 - accuracy: 0.6259 - val_loss: 1.1401 - val_accuracy: 0.5641\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8967 - accuracy: 0.6333 - val_loss: 1.0584 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8363 - accuracy: 0.6593 - val_loss: 1.0332 - val_accuracy: 0.5726\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8010 - accuracy: 0.6889 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7607 - accuracy: 0.6741 - val_loss: 0.8937 - val_accuracy: 0.5812\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7440 - accuracy: 0.6852 - val_loss: 0.9176 - val_accuracy: 0.5641\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7234 - accuracy: 0.6741 - val_loss: 0.9434 - val_accuracy: 0.5726\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7691 - accuracy: 0.6593 - val_loss: 0.9128 - val_accuracy: 0.6068\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7249 - accuracy: 0.6889 - val_loss: 0.9443 - val_accuracy: 0.5726\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7398 - accuracy: 0.6852 - val_loss: 0.9086 - val_accuracy: 0.5812\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7425 - accuracy: 0.6778 - val_loss: 0.8986 - val_accuracy: 0.5812\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7412 - accuracy: 0.7074 - val_loss: 0.8840 - val_accuracy: 0.5812\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7632 - accuracy: 0.6815 - val_loss: 0.8935 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7405 - accuracy: 0.6815 - val_loss: 0.9945 - val_accuracy: 0.5556\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7802 - accuracy: 0.6741 - val_loss: 0.9746 - val_accuracy: 0.5983\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7470 - accuracy: 0.6852 - val_loss: 0.9385 - val_accuracy: 0.5641\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7791 - accuracy: 0.7037 - val_loss: 1.1655 - val_accuracy: 0.5897\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8993 - accuracy: 0.6741 - val_loss: 1.0597 - val_accuracy: 0.5726\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7614 - accuracy: 0.6963 - val_loss: 0.9940 - val_accuracy: 0.5983\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9510 - accuracy: 0.6444 - val_loss: 1.5470 - val_accuracy: 0.6068\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.0647 - accuracy: 0.6852 - val_loss: 1.4674 - val_accuracy: 0.5470\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8621 - accuracy: 0.6815 - val_loss: 0.9248 - val_accuracy: 0.5385\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8337 - accuracy: 0.6407 - val_loss: 0.9013 - val_accuracy: 0.5897\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7413 - accuracy: 0.6889 - val_loss: 0.9668 - val_accuracy: 0.5385\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7311 - accuracy: 0.6815 - val_loss: 0.9075 - val_accuracy: 0.5556\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.7629 - accuracy: 0.6741 - val_loss: 0.8810 - val_accuracy: 0.5726\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7503 - accuracy: 0.6593 - val_loss: 0.9376 - val_accuracy: 0.5556\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7308 - accuracy: 0.7037 - val_loss: 0.9369 - val_accuracy: 0.5983\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7312 - accuracy: 0.6889 - val_loss: 0.9135 - val_accuracy: 0.5983\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7259 - accuracy: 0.6778 - val_loss: 0.9192 - val_accuracy: 0.5897\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8042 - accuracy: 0.6630 - val_loss: 0.8911 - val_accuracy: 0.5726\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7671 - accuracy: 0.6889 - val_loss: 1.0098 - val_accuracy: 0.5897\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8651 - accuracy: 0.6333 - val_loss: 0.9222 - val_accuracy: 0.5812\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8010 - accuracy: 0.6778 - val_loss: 1.1028 - val_accuracy: 0.5726\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7611 - accuracy: 0.6852 - val_loss: 0.8867 - val_accuracy: 0.5983\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7782 - accuracy: 0.6741 - val_loss: 0.9292 - val_accuracy: 0.5983\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7725 - accuracy: 0.6815 - val_loss: 1.2020 - val_accuracy: 0.5641\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0401 - accuracy: 0.6407 - val_loss: 1.2295 - val_accuracy: 0.5641\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.3157 - accuracy: 0.6037 - val_loss: 0.9434 - val_accuracy: 0.5641\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8101 - accuracy: 0.6704 - val_loss: 1.4147 - val_accuracy: 0.6068\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0043 - accuracy: 0.6815 - val_loss: 1.2055 - val_accuracy: 0.6068\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8379 - accuracy: 0.6889 - val_loss: 1.1379 - val_accuracy: 0.5812\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8454 - accuracy: 0.6778 - val_loss: 1.0340 - val_accuracy: 0.6068\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7988 - accuracy: 0.6852 - val_loss: 0.9420 - val_accuracy: 0.5726\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7481 - accuracy: 0.6889 - val_loss: 0.8930 - val_accuracy: 0.5812\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7303 - accuracy: 0.6815 - val_loss: 0.9703 - val_accuracy: 0.5470\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7293 - accuracy: 0.6963 - val_loss: 0.8874 - val_accuracy: 0.5897\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7121 - accuracy: 0.6889 - val_loss: 0.9010 - val_accuracy: 0.5983\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7323 - accuracy: 0.7000 - val_loss: 0.9026 - val_accuracy: 0.5726\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7687 - accuracy: 0.6741 - val_loss: 0.8878 - val_accuracy: 0.5983\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8500 - accuracy: 0.6815 - val_loss: 0.9710 - val_accuracy: 0.5812\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7704 - accuracy: 0.6889 - val_loss: 1.0869 - val_accuracy: 0.5983\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7756 - accuracy: 0.6926 - val_loss: 1.1443 - val_accuracy: 0.6068\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8179 - accuracy: 0.6630 - val_loss: 1.0613 - val_accuracy: 0.6068\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7885 - accuracy: 0.6852 - val_loss: 0.9631 - val_accuracy: 0.5641\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7447 - accuracy: 0.6815 - val_loss: 0.8887 - val_accuracy: 0.5726\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7665 - accuracy: 0.6889 - val_loss: 0.9480 - val_accuracy: 0.5470\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8619 - accuracy: 0.6852 - val_loss: 0.8969 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7949 - accuracy: 0.6704 - val_loss: 0.9960 - val_accuracy: 0.5983\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7344 - accuracy: 0.6815 - val_loss: 1.0169 - val_accuracy: 0.5812\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8444 - accuracy: 0.6778 - val_loss: 1.2045 - val_accuracy: 0.5983\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8558 - accuracy: 0.6889 - val_loss: 0.9570 - val_accuracy: 0.5726\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7509 - accuracy: 0.6778 - val_loss: 0.8908 - val_accuracy: 0.5897\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7094 - accuracy: 0.7111 - val_loss: 0.9467 - val_accuracy: 0.5556\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7448 - accuracy: 0.6926 - val_loss: 0.9098 - val_accuracy: 0.5556\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7966 - accuracy: 0.6778 - val_loss: 0.9982 - val_accuracy: 0.5983\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7027 - accuracy: 0.7037 - val_loss: 1.3139 - val_accuracy: 0.5726\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9020 - accuracy: 0.6778 - val_loss: 1.2129 - val_accuracy: 0.5983\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9151 - accuracy: 0.6852 - val_loss: 1.2169 - val_accuracy: 0.5726\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8652 - accuracy: 0.6778 - val_loss: 1.0018 - val_accuracy: 0.5897\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7531 - accuracy: 0.6741 - val_loss: 1.0312 - val_accuracy: 0.5812\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8031 - accuracy: 0.6778 - val_loss: 0.9716 - val_accuracy: 0.5470\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7233 - accuracy: 0.7148 - val_loss: 0.9121 - val_accuracy: 0.5812\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7230 - accuracy: 0.6852 - val_loss: 0.9079 - val_accuracy: 0.5726\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7081 - accuracy: 0.6963 - val_loss: 0.9238 - val_accuracy: 0.5812\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7171 - accuracy: 0.6667 - val_loss: 0.9086 - val_accuracy: 0.5726\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7314 - accuracy: 0.6852 - val_loss: 0.9019 - val_accuracy: 0.5641\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7242 - accuracy: 0.6815 - val_loss: 0.9096 - val_accuracy: 0.5897\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7021 - accuracy: 0.7074 - val_loss: 0.9473 - val_accuracy: 0.6068\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7238 - accuracy: 0.6815 - val_loss: 0.9066 - val_accuracy: 0.5983\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7054 - accuracy: 0.7037 - val_loss: 0.9078 - val_accuracy: 0.5897\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7072 - accuracy: 0.6926 - val_loss: 0.8940 - val_accuracy: 0.5641\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6996 - accuracy: 0.6889 - val_loss: 0.9069 - val_accuracy: 0.5897\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7050 - accuracy: 0.7037 - val_loss: 0.8925 - val_accuracy: 0.5726\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7151 - accuracy: 0.7037 - val_loss: 0.9048 - val_accuracy: 0.5641\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7139 - accuracy: 0.6963 - val_loss: 0.9608 - val_accuracy: 0.5556\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7344 - accuracy: 0.7074 - val_loss: 0.9040 - val_accuracy: 0.5726\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7111 - accuracy: 0.7000 - val_loss: 0.8877 - val_accuracy: 0.5641\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6962 - accuracy: 0.6926 - val_loss: 0.9136 - val_accuracy: 0.5726\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7096 - accuracy: 0.7000 - val_loss: 0.8864 - val_accuracy: 0.5897\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6989 - accuracy: 0.6926 - val_loss: 0.8966 - val_accuracy: 0.6154\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6951 - accuracy: 0.7037 - val_loss: 0.8976 - val_accuracy: 0.6068\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7041 - accuracy: 0.7148 - val_loss: 0.8892 - val_accuracy: 0.5812\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7102 - accuracy: 0.6926 - val_loss: 0.8886 - val_accuracy: 0.5897\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7052 - accuracy: 0.6963 - val_loss: 0.9110 - val_accuracy: 0.5897\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6985 - accuracy: 0.6963 - val_loss: 0.8786 - val_accuracy: 0.5726\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7005 - accuracy: 0.6926 - val_loss: 0.8911 - val_accuracy: 0.5897\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7000 - accuracy: 0.6926 - val_loss: 0.9183 - val_accuracy: 0.5726\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7090 - accuracy: 0.7037 - val_loss: 0.8748 - val_accuracy: 0.5897\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7190 - accuracy: 0.6963 - val_loss: 0.8910 - val_accuracy: 0.5897\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7164 - accuracy: 0.6852 - val_loss: 1.0184 - val_accuracy: 0.5470\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7255 - accuracy: 0.6926 - val_loss: 0.8966 - val_accuracy: 0.5812\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7179 - accuracy: 0.7074 - val_loss: 0.9129 - val_accuracy: 0.6068\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6977 - accuracy: 0.6963 - val_loss: 0.9469 - val_accuracy: 0.5812\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7018 - accuracy: 0.7148 - val_loss: 0.8974 - val_accuracy: 0.5812\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7104 - accuracy: 0.6963 - val_loss: 0.8797 - val_accuracy: 0.5812\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7095 - accuracy: 0.6852 - val_loss: 0.8933 - val_accuracy: 0.5641\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7130 - accuracy: 0.6741 - val_loss: 0.8805 - val_accuracy: 0.5897\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7188 - accuracy: 0.6889 - val_loss: 0.9674 - val_accuracy: 0.5983\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7612 - accuracy: 0.6926 - val_loss: 0.8878 - val_accuracy: 0.5641\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7016 - accuracy: 0.6926 - val_loss: 0.9027 - val_accuracy: 0.5812\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7056 - accuracy: 0.6889 - val_loss: 0.9426 - val_accuracy: 0.5897\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7264 - accuracy: 0.6926 - val_loss: 0.9298 - val_accuracy: 0.5812\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6979 - accuracy: 0.7074 - val_loss: 0.8932 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6894 - accuracy: 0.7037 - val_loss: 0.9122 - val_accuracy: 0.5812\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7166 - accuracy: 0.6926 - val_loss: 0.9233 - val_accuracy: 0.5556\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6940 - accuracy: 0.7037 - val_loss: 0.9083 - val_accuracy: 0.5812\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6896 - accuracy: 0.6889 - val_loss: 0.9064 - val_accuracy: 0.5641\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7055 - accuracy: 0.6815 - val_loss: 0.9012 - val_accuracy: 0.5726\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6892 - accuracy: 0.7000 - val_loss: 0.9107 - val_accuracy: 0.5470\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6895 - accuracy: 0.6815 - val_loss: 0.8925 - val_accuracy: 0.5983\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6982 - accuracy: 0.7000 - val_loss: 0.8967 - val_accuracy: 0.5641\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7005 - accuracy: 0.6963 - val_loss: 0.8994 - val_accuracy: 0.5897\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6864 - accuracy: 0.6963 - val_loss: 0.8866 - val_accuracy: 0.5726\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6894 - accuracy: 0.6963 - val_loss: 0.9072 - val_accuracy: 0.5726\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6907 - accuracy: 0.6963 - val_loss: 0.9140 - val_accuracy: 0.5641\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7029 - accuracy: 0.6815 - val_loss: 0.8888 - val_accuracy: 0.5556\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6820 - accuracy: 0.6963 - val_loss: 0.9147 - val_accuracy: 0.5983\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6934 - accuracy: 0.7037 - val_loss: 0.8864 - val_accuracy: 0.6068\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.6961 - accuracy: 0.6963 - val_loss: 0.8879 - val_accuracy: 0.5983\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.6883 - accuracy: 0.7000 - val_loss: 0.9109 - val_accuracy: 0.5556\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7090 - accuracy: 0.6852 - val_loss: 0.9292 - val_accuracy: 0.5556\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7397 - accuracy: 0.6852 - val_loss: 1.0869 - val_accuracy: 0.5983\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8697 - accuracy: 0.6815 - val_loss: 1.2910 - val_accuracy: 0.5641\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8602 - accuracy: 0.6852 - val_loss: 0.8930 - val_accuracy: 0.5812\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7437 - accuracy: 0.6815 - val_loss: 0.8843 - val_accuracy: 0.5726\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7459 - accuracy: 0.6926 - val_loss: 1.0671 - val_accuracy: 0.5641\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7316 - accuracy: 0.6889 - val_loss: 0.9063 - val_accuracy: 0.5983\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7012 - accuracy: 0.7037 - val_loss: 0.9494 - val_accuracy: 0.5812\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7188 - accuracy: 0.6963 - val_loss: 0.9254 - val_accuracy: 0.5983\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7176 - accuracy: 0.6852 - val_loss: 0.9166 - val_accuracy: 0.5726\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6901 - accuracy: 0.6963 - val_loss: 0.9002 - val_accuracy: 0.5812\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6826 - accuracy: 0.7000 - val_loss: 0.8894 - val_accuracy: 0.5983\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7067 - accuracy: 0.6889 - val_loss: 0.9098 - val_accuracy: 0.6068\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6918 - accuracy: 0.7000 - val_loss: 0.9104 - val_accuracy: 0.5726\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6825 - accuracy: 0.7000 - val_loss: 0.9354 - val_accuracy: 0.5641\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6884 - accuracy: 0.6926 - val_loss: 0.8918 - val_accuracy: 0.5812\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6756 - accuracy: 0.7000 - val_loss: 0.8930 - val_accuracy: 0.5812\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6907 - accuracy: 0.7037 - val_loss: 0.8781 - val_accuracy: 0.5983\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7388 - accuracy: 0.6963 - val_loss: 0.9345 - val_accuracy: 0.5983\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7070 - accuracy: 0.6963 - val_loss: 0.9495 - val_accuracy: 0.5812\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7095 - accuracy: 0.7037 - val_loss: 0.8929 - val_accuracy: 0.5812\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7030 - accuracy: 0.7037 - val_loss: 0.8967 - val_accuracy: 0.5726\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6913 - accuracy: 0.6889 - val_loss: 0.8967 - val_accuracy: 0.5556\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6808 - accuracy: 0.6889 - val_loss: 0.8851 - val_accuracy: 0.5897\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6765 - accuracy: 0.7000 - val_loss: 0.8968 - val_accuracy: 0.5641\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6838 - accuracy: 0.6926 - val_loss: 0.8888 - val_accuracy: 0.5983\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6865 - accuracy: 0.6926 - val_loss: 0.8861 - val_accuracy: 0.5983\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7046 - accuracy: 0.6852 - val_loss: 0.9574 - val_accuracy: 0.5812\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8311 - accuracy: 0.6815 - val_loss: 1.1556 - val_accuracy: 0.5726\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7450 - accuracy: 0.6778 - val_loss: 1.0424 - val_accuracy: 0.5385\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7140 - accuracy: 0.7000 - val_loss: 1.0217 - val_accuracy: 0.5812\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7488 - accuracy: 0.6852 - val_loss: 1.0199 - val_accuracy: 0.5726\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7446 - accuracy: 0.6741 - val_loss: 0.9018 - val_accuracy: 0.5897\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6984 - accuracy: 0.6926 - val_loss: 0.9568 - val_accuracy: 0.5641\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6983 - accuracy: 0.6963 - val_loss: 0.9265 - val_accuracy: 0.5726\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7037 - accuracy: 0.6926 - val_loss: 0.9049 - val_accuracy: 0.5641\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6784 - accuracy: 0.7111 - val_loss: 0.9195 - val_accuracy: 0.5812\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7770 - accuracy: 0.6704 - val_loss: 1.1923 - val_accuracy: 0.5812\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8369 - accuracy: 0.6704 - val_loss: 1.3200 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7684 - accuracy: 0.6963 - val_loss: 0.9457 - val_accuracy: 0.5470\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7473 - accuracy: 0.6815 - val_loss: 0.9323 - val_accuracy: 0.5641\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7133 - accuracy: 0.6963 - val_loss: 0.9476 - val_accuracy: 0.5812\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6849 - accuracy: 0.7185 - val_loss: 0.9120 - val_accuracy: 0.5726\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7354 - accuracy: 0.6815 - val_loss: 0.8919 - val_accuracy: 0.5812\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6969 - accuracy: 0.6926 - val_loss: 0.9265 - val_accuracy: 0.5983\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8298 - accuracy: 0.6519 - val_loss: 0.9784 - val_accuracy: 0.6154\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7205 - accuracy: 0.6926 - val_loss: 1.0234 - val_accuracy: 0.5726\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6986 - accuracy: 0.6926 - val_loss: 0.9843 - val_accuracy: 0.5812\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7084 - accuracy: 0.6889 - val_loss: 1.1597 - val_accuracy: 0.5641\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.3111 - accuracy: 0.6963 - val_loss: 1.0711 - val_accuracy: 0.5299\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7555 - accuracy: 0.6889 - val_loss: 1.2060 - val_accuracy: 0.5812\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7701 - accuracy: 0.6630 - val_loss: 1.1603 - val_accuracy: 0.5641\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7819 - accuracy: 0.6963 - val_loss: 1.3549 - val_accuracy: 0.5726\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0472 - accuracy: 0.6519 - val_loss: 1.2924 - val_accuracy: 0.5641\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8295 - accuracy: 0.6815 - val_loss: 0.9862 - val_accuracy: 0.5812\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8040 - accuracy: 0.6630 - val_loss: 0.9995 - val_accuracy: 0.6068\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7708 - accuracy: 0.6778 - val_loss: 1.1265 - val_accuracy: 0.5470\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7871 - accuracy: 0.6778 - val_loss: 0.9558 - val_accuracy: 0.5556\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7266 - accuracy: 0.6889 - val_loss: 0.9604 - val_accuracy: 0.5897\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7100 - accuracy: 0.7037 - val_loss: 0.9718 - val_accuracy: 0.6068\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7333 - accuracy: 0.6778 - val_loss: 0.9229 - val_accuracy: 0.5641\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7037 - accuracy: 0.7000 - val_loss: 0.9369 - val_accuracy: 0.5983\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6997 - accuracy: 0.7000 - val_loss: 0.8928 - val_accuracy: 0.5641\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7909 - accuracy: 0.6778 - val_loss: 0.9775 - val_accuracy: 0.5812\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7516 - accuracy: 0.6815 - val_loss: 0.9500 - val_accuracy: 0.5556\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7923 - accuracy: 0.6926 - val_loss: 1.1295 - val_accuracy: 0.6154\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7919 - accuracy: 0.7037 - val_loss: 1.0108 - val_accuracy: 0.5385\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7037 - accuracy: 0.6963 - val_loss: 0.9313 - val_accuracy: 0.5726\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6831 - accuracy: 0.7037 - val_loss: 1.0433 - val_accuracy: 0.5812\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7089 - accuracy: 0.7037 - val_loss: 0.9055 - val_accuracy: 0.5726\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6806 - accuracy: 0.7000 - val_loss: 0.9012 - val_accuracy: 0.5641\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6726 - accuracy: 0.7037 - val_loss: 0.9059 - val_accuracy: 0.5897\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6723 - accuracy: 0.7111 - val_loss: 0.8920 - val_accuracy: 0.5897\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7035 - accuracy: 0.7000 - val_loss: 0.8905 - val_accuracy: 0.5812\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6883 - accuracy: 0.7000 - val_loss: 0.9787 - val_accuracy: 0.5726\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6907 - accuracy: 0.7148 - val_loss: 0.9047 - val_accuracy: 0.5726\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7167 - accuracy: 0.6741 - val_loss: 0.9045 - val_accuracy: 0.5641\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6673 - accuracy: 0.6889 - val_loss: 0.9342 - val_accuracy: 0.5897\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6829 - accuracy: 0.7259 - val_loss: 0.9207 - val_accuracy: 0.5897\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7561 - accuracy: 0.6963 - val_loss: 0.8964 - val_accuracy: 0.5897\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7069 - accuracy: 0.6963 - val_loss: 0.9159 - val_accuracy: 0.5641\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6705 - accuracy: 0.6926 - val_loss: 0.9624 - val_accuracy: 0.5983\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7126 - accuracy: 0.6926 - val_loss: 0.9470 - val_accuracy: 0.5556\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6702 - accuracy: 0.7000 - val_loss: 0.9225 - val_accuracy: 0.6068\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6824 - accuracy: 0.6926 - val_loss: 0.9011 - val_accuracy: 0.5897\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6925 - accuracy: 0.6926 - val_loss: 0.9267 - val_accuracy: 0.5983\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6825 - accuracy: 0.7000 - val_loss: 1.0156 - val_accuracy: 0.5726\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.6918 - accuracy: 0.7000 - val_loss: 0.9388 - val_accuracy: 0.5556\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6985 - accuracy: 0.6926 - val_loss: 0.9741 - val_accuracy: 0.5385\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7264 - accuracy: 0.6889 - val_loss: 0.9172 - val_accuracy: 0.5726\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8130 - accuracy: 0.6704 - val_loss: 1.0688 - val_accuracy: 0.5385\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7894 - accuracy: 0.6593 - val_loss: 1.1832 - val_accuracy: 0.5726\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7665 - accuracy: 0.6778 - val_loss: 0.9123 - val_accuracy: 0.5897\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6818 - accuracy: 0.6926 - val_loss: 0.9616 - val_accuracy: 0.5812\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7100 - accuracy: 0.6889 - val_loss: 0.9086 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.6794 - accuracy: 0.6926 - val_loss: 0.9099 - val_accuracy: 0.5812\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6652 - accuracy: 0.6963 - val_loss: 0.9052 - val_accuracy: 0.5726\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6800 - accuracy: 0.7000 - val_loss: 1.0014 - val_accuracy: 0.5641\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7294 - accuracy: 0.6889 - val_loss: 1.0121 - val_accuracy: 0.5812\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7042 - accuracy: 0.6963 - val_loss: 0.9159 - val_accuracy: 0.5641\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6800 - accuracy: 0.7074 - val_loss: 0.9069 - val_accuracy: 0.5897\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6748 - accuracy: 0.7000 - val_loss: 0.9098 - val_accuracy: 0.5726\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6700 - accuracy: 0.7000 - val_loss: 0.9750 - val_accuracy: 0.5897\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8486 - accuracy: 0.6815 - val_loss: 1.1695 - val_accuracy: 0.5641\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7667 - accuracy: 0.6963 - val_loss: 0.9515 - val_accuracy: 0.5812\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7281 - accuracy: 0.6852 - val_loss: 0.9344 - val_accuracy: 0.6068\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6728 - accuracy: 0.7037 - val_loss: 1.0608 - val_accuracy: 0.5812\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6940 - accuracy: 0.7074 - val_loss: 0.9363 - val_accuracy: 0.5812\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7468 - accuracy: 0.6889 - val_loss: 0.9255 - val_accuracy: 0.5556\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7099 - accuracy: 0.7111 - val_loss: 0.9263 - val_accuracy: 0.5812\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7390 - accuracy: 0.6926 - val_loss: 0.9460 - val_accuracy: 0.5983\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.6732 - accuracy: 0.6926 - val_loss: 0.9783 - val_accuracy: 0.5726\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6790 - accuracy: 0.7074 - val_loss: 0.9211 - val_accuracy: 0.5983\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6907 - accuracy: 0.6889 - val_loss: 0.9256 - val_accuracy: 0.5897\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6812 - accuracy: 0.7037 - val_loss: 0.9290 - val_accuracy: 0.5556\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6725 - accuracy: 0.7111 - val_loss: 0.9242 - val_accuracy: 0.5897\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9339 - accuracy: 0.6926 - val_loss: 0.9924 - val_accuracy: 0.5983\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8037 - accuracy: 0.6630 - val_loss: 0.9479 - val_accuracy: 0.6068\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7043 - accuracy: 0.6889 - val_loss: 1.0234 - val_accuracy: 0.5470\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.6921 - accuracy: 0.7037 - val_loss: 0.9859 - val_accuracy: 0.5983\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7031 - accuracy: 0.6963 - val_loss: 0.9654 - val_accuracy: 0.5812\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6680 - accuracy: 0.6963 - val_loss: 1.0040 - val_accuracy: 0.5641\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7184 - accuracy: 0.7000 - val_loss: 0.9285 - val_accuracy: 0.5812\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.6678 - accuracy: 0.6963 - val_loss: 0.9456 - val_accuracy: 0.5812\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6861 - accuracy: 0.7037 - val_loss: 0.9122 - val_accuracy: 0.5726\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6819 - accuracy: 0.7037 - val_loss: 0.9390 - val_accuracy: 0.5812\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.6972 - accuracy: 0.6926 - val_loss: 0.9322 - val_accuracy: 0.5470\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6570 - accuracy: 0.7074 - val_loss: 0.9277 - val_accuracy: 0.5812\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6594 - accuracy: 0.7000 - val_loss: 0.9262 - val_accuracy: 0.5470\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6831 - accuracy: 0.6963 - val_loss: 0.9019 - val_accuracy: 0.5983\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6760 - accuracy: 0.6963 - val_loss: 0.9668 - val_accuracy: 0.5726\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.6921 - accuracy: 0.6889 - val_loss: 0.8908 - val_accuracy: 0.5897\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6599 - accuracy: 0.7148 - val_loss: 0.9118 - val_accuracy: 0.5812\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6677 - accuracy: 0.7111 - val_loss: 0.9052 - val_accuracy: 0.5812\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.6504 - accuracy: 0.7074 - val_loss: 0.9052 - val_accuracy: 0.5983\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6707 - accuracy: 0.7148 - val_loss: 0.9026 - val_accuracy: 0.5983\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.6825 - accuracy: 0.7000 - val_loss: 0.9079 - val_accuracy: 0.6068\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.6559 - accuracy: 0.7111 - val_loss: 0.9129 - val_accuracy: 0.5983\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6576 - accuracy: 0.7074 - val_loss: 0.9510 - val_accuracy: 0.5726\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.6849 - accuracy: 0.7000 - val_loss: 0.9023 - val_accuracy: 0.5897\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6716 - accuracy: 0.6963 - val_loss: 0.9194 - val_accuracy: 0.5812\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6850 - accuracy: 0.7037 - val_loss: 0.8889 - val_accuracy: 0.6068\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.6694 - accuracy: 0.7037 - val_loss: 0.9078 - val_accuracy: 0.5983\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.6702 - accuracy: 0.6889 - val_loss: 0.9143 - val_accuracy: 0.5983\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.6622 - accuracy: 0.6963 - val_loss: 0.9257 - val_accuracy: 0.5897\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.6674 - accuracy: 0.7074 - val_loss: 0.9463 - val_accuracy: 0.5812\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7757 - accuracy: 0.6926 - val_loss: 0.9248 - val_accuracy: 0.5897\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.6654 - accuracy: 0.6926 - val_loss: 0.9767 - val_accuracy: 0.5983\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.6816 - accuracy: 0.6963 - val_loss: 0.9674 - val_accuracy: 0.5812\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.6879 - accuracy: 0.6963 - val_loss: 0.9297 - val_accuracy: 0.5812\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.6782 - accuracy: 0.7111 - val_loss: 0.9815 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7175 - accuracy: 0.6926 - val_loss: 0.9299 - val_accuracy: 0.5983\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6857 - accuracy: 0.7222 - val_loss: 0.9557 - val_accuracy: 0.5897\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7113 - accuracy: 0.7000 - val_loss: 0.9075 - val_accuracy: 0.5556\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6796 - accuracy: 0.7037 - val_loss: 0.9034 - val_accuracy: 0.5897\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6516 - accuracy: 0.7037 - val_loss: 0.9029 - val_accuracy: 0.5983\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6582 - accuracy: 0.7074 - val_loss: 0.8914 - val_accuracy: 0.5897\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6547 - accuracy: 0.7111 - val_loss: 0.9049 - val_accuracy: 0.5812\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6466 - accuracy: 0.7037 - val_loss: 0.9132 - val_accuracy: 0.6068\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6543 - accuracy: 0.7148 - val_loss: 0.9079 - val_accuracy: 0.5983\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6617 - accuracy: 0.7111 - val_loss: 0.9103 - val_accuracy: 0.5983\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6516 - accuracy: 0.7370 - val_loss: 0.9029 - val_accuracy: 0.5983\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6476 - accuracy: 0.7111 - val_loss: 0.9014 - val_accuracy: 0.6068\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6855 - accuracy: 0.7148 - val_loss: 0.8954 - val_accuracy: 0.5897\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6659 - accuracy: 0.7259 - val_loss: 0.9386 - val_accuracy: 0.5897\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7040 - accuracy: 0.6963 - val_loss: 0.9039 - val_accuracy: 0.5897\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6809 - accuracy: 0.7111 - val_loss: 0.9847 - val_accuracy: 0.5726\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7257 - accuracy: 0.7037 - val_loss: 0.9612 - val_accuracy: 0.6068\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7102 - accuracy: 0.6889 - val_loss: 0.9483 - val_accuracy: 0.5812\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6870 - accuracy: 0.7074 - val_loss: 0.9930 - val_accuracy: 0.5812\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7005 - accuracy: 0.7000 - val_loss: 0.9385 - val_accuracy: 0.5812\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6629 - accuracy: 0.7185 - val_loss: 0.8923 - val_accuracy: 0.5983\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6629 - accuracy: 0.7074 - val_loss: 0.9357 - val_accuracy: 0.5812\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6990 - accuracy: 0.7185 - val_loss: 0.9799 - val_accuracy: 0.5897\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6631 - accuracy: 0.7148 - val_loss: 0.9326 - val_accuracy: 0.5983\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6734 - accuracy: 0.6926 - val_loss: 0.9377 - val_accuracy: 0.6068\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6577 - accuracy: 0.7111 - val_loss: 0.9091 - val_accuracy: 0.5897\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6536 - accuracy: 0.7148 - val_loss: 0.9222 - val_accuracy: 0.5983\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6413 - accuracy: 0.7370 - val_loss: 0.8951 - val_accuracy: 0.5812\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6619 - accuracy: 0.7074 - val_loss: 0.9050 - val_accuracy: 0.5897\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6724 - accuracy: 0.7148 - val_loss: 0.9462 - val_accuracy: 0.5726\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6668 - accuracy: 0.7074 - val_loss: 0.9358 - val_accuracy: 0.5983\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6509 - accuracy: 0.7148 - val_loss: 0.9533 - val_accuracy: 0.5641\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6993 - accuracy: 0.7037 - val_loss: 0.9513 - val_accuracy: 0.5641\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6754 - accuracy: 0.7074 - val_loss: 0.9686 - val_accuracy: 0.5897\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7183 - accuracy: 0.6963 - val_loss: 0.9068 - val_accuracy: 0.5983\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6573 - accuracy: 0.7222 - val_loss: 0.9327 - val_accuracy: 0.5812\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6517 - accuracy: 0.7148 - val_loss: 0.9508 - val_accuracy: 0.6068\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6701 - accuracy: 0.7111 - val_loss: 0.9713 - val_accuracy: 0.5983\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6677 - accuracy: 0.7296 - val_loss: 0.9663 - val_accuracy: 0.6068\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6842 - accuracy: 0.7000 - val_loss: 0.9262 - val_accuracy: 0.6154\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6590 - accuracy: 0.7037 - val_loss: 0.9541 - val_accuracy: 0.5897\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6665 - accuracy: 0.7222 - val_loss: 0.9485 - val_accuracy: 0.6068\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6473 - accuracy: 0.7185 - val_loss: 0.9535 - val_accuracy: 0.5983\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6665 - accuracy: 0.7259 - val_loss: 1.0482 - val_accuracy: 0.6154\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7411 - accuracy: 0.7000 - val_loss: 0.9636 - val_accuracy: 0.5983\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6642 - accuracy: 0.7111 - val_loss: 1.0100 - val_accuracy: 0.6068\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0214 - accuracy: 0.6630 - val_loss: 1.5498 - val_accuracy: 0.5897\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9786 - accuracy: 0.6852 - val_loss: 0.9127 - val_accuracy: 0.5983\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8603 - accuracy: 0.6778 - val_loss: 1.0386 - val_accuracy: 0.5556\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7152 - accuracy: 0.7185 - val_loss: 0.9998 - val_accuracy: 0.5726\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7851 - accuracy: 0.6852 - val_loss: 1.0453 - val_accuracy: 0.5897\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7070 - accuracy: 0.7000 - val_loss: 1.0083 - val_accuracy: 0.6068\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7318 - accuracy: 0.7000 - val_loss: 1.0933 - val_accuracy: 0.6068\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7329 - accuracy: 0.7037 - val_loss: 1.1419 - val_accuracy: 0.5641\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7252 - accuracy: 0.7222 - val_loss: 1.0652 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7385 - accuracy: 0.7111 - val_loss: 0.9019 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6507 - accuracy: 0.7111 - val_loss: 0.9020 - val_accuracy: 0.6068\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6506 - accuracy: 0.7259 - val_loss: 0.9733 - val_accuracy: 0.6068\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6614 - accuracy: 0.7222 - val_loss: 0.9362 - val_accuracy: 0.5897\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6410 - accuracy: 0.7185 - val_loss: 0.9638 - val_accuracy: 0.6068\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7060 - accuracy: 0.6852 - val_loss: 0.9070 - val_accuracy: 0.5983\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6674 - accuracy: 0.7259 - val_loss: 1.0248 - val_accuracy: 0.6154\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7023 - accuracy: 0.7296 - val_loss: 0.9764 - val_accuracy: 0.5726\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6652 - accuracy: 0.7296 - val_loss: 0.8984 - val_accuracy: 0.6068\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6597 - accuracy: 0.7074 - val_loss: 0.9069 - val_accuracy: 0.5812\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6568 - accuracy: 0.7296 - val_loss: 0.9746 - val_accuracy: 0.5641\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6574 - accuracy: 0.7296 - val_loss: 0.9099 - val_accuracy: 0.5897\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6597 - accuracy: 0.7074 - val_loss: 0.8951 - val_accuracy: 0.6239\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6404 - accuracy: 0.7444 - val_loss: 0.9176 - val_accuracy: 0.5983\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6473 - accuracy: 0.7259 - val_loss: 0.8994 - val_accuracy: 0.6068\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6388 - accuracy: 0.7259 - val_loss: 0.9377 - val_accuracy: 0.5983\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6463 - accuracy: 0.7407 - val_loss: 0.8988 - val_accuracy: 0.6068\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6510 - accuracy: 0.7222 - val_loss: 0.9053 - val_accuracy: 0.6068\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6386 - accuracy: 0.7407 - val_loss: 0.9178 - val_accuracy: 0.5983\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6447 - accuracy: 0.7370 - val_loss: 0.9079 - val_accuracy: 0.6068\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6732 - accuracy: 0.6926 - val_loss: 0.8919 - val_accuracy: 0.6239\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6339 - accuracy: 0.7185 - val_loss: 0.9415 - val_accuracy: 0.5983\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6400 - accuracy: 0.7370 - val_loss: 0.8977 - val_accuracy: 0.6068\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6434 - accuracy: 0.7222 - val_loss: 0.9025 - val_accuracy: 0.6068\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6737 - accuracy: 0.7296 - val_loss: 0.9214 - val_accuracy: 0.6068\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7935 - accuracy: 0.6704 - val_loss: 0.9401 - val_accuracy: 0.6068\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6717 - accuracy: 0.7148 - val_loss: 1.0473 - val_accuracy: 0.5897\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6673 - accuracy: 0.7111 - val_loss: 0.9406 - val_accuracy: 0.6154\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7064 - accuracy: 0.6889 - val_loss: 0.9192 - val_accuracy: 0.5812\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7017 - accuracy: 0.7222 - val_loss: 0.9530 - val_accuracy: 0.6239\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6927 - accuracy: 0.7222 - val_loss: 0.9522 - val_accuracy: 0.6068\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7622 - accuracy: 0.6926 - val_loss: 0.9587 - val_accuracy: 0.5812\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6481 - accuracy: 0.7407 - val_loss: 0.9440 - val_accuracy: 0.5897\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6634 - accuracy: 0.7148 - val_loss: 0.8986 - val_accuracy: 0.5897\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6529 - accuracy: 0.7370 - val_loss: 0.9400 - val_accuracy: 0.5983\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6596 - accuracy: 0.7296 - val_loss: 0.9144 - val_accuracy: 0.6068\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6858 - accuracy: 0.7148 - val_loss: 0.8949 - val_accuracy: 0.6239\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6462 - accuracy: 0.7259 - val_loss: 0.9462 - val_accuracy: 0.5897\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6978 - accuracy: 0.7111 - val_loss: 0.8935 - val_accuracy: 0.6068\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6802 - accuracy: 0.7074 - val_loss: 0.9337 - val_accuracy: 0.5897\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6850 - accuracy: 0.7148 - val_loss: 1.0362 - val_accuracy: 0.5983\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8266 - accuracy: 0.7259 - val_loss: 1.1352 - val_accuracy: 0.5983\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8360 - accuracy: 0.6741 - val_loss: 0.9480 - val_accuracy: 0.5812\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8880 - accuracy: 0.6926 - val_loss: 1.4103 - val_accuracy: 0.6154\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8252 - accuracy: 0.7185 - val_loss: 1.4110 - val_accuracy: 0.6068\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9187 - accuracy: 0.7000 - val_loss: 1.3593 - val_accuracy: 0.5983\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7868 - accuracy: 0.7111 - val_loss: 0.9979 - val_accuracy: 0.5812\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6960 - accuracy: 0.7037 - val_loss: 0.9844 - val_accuracy: 0.5726\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6981 - accuracy: 0.7370 - val_loss: 0.9466 - val_accuracy: 0.6068\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7050 - accuracy: 0.6926 - val_loss: 1.0547 - val_accuracy: 0.5641\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7627 - accuracy: 0.6926 - val_loss: 1.0895 - val_accuracy: 0.6068\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7934 - accuracy: 0.7037 - val_loss: 0.9625 - val_accuracy: 0.5983\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8148 - accuracy: 0.6778 - val_loss: 0.9331 - val_accuracy: 0.6154\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7227 - accuracy: 0.7185 - val_loss: 1.1226 - val_accuracy: 0.5812\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6468 - accuracy: 0.7333 - val_loss: 0.9373 - val_accuracy: 0.5641\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7190 - accuracy: 0.7000 - val_loss: 0.9246 - val_accuracy: 0.5983\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7191 - accuracy: 0.6963 - val_loss: 0.9099 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7514 - accuracy: 0.6889 - val_loss: 1.0095 - val_accuracy: 0.5641\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7405 - accuracy: 0.6889 - val_loss: 1.2199 - val_accuracy: 0.5983\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.2580 - accuracy: 0.6963 - val_loss: 0.9412 - val_accuracy: 0.6154\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7087 - accuracy: 0.7000 - val_loss: 1.0272 - val_accuracy: 0.6068\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6722 - accuracy: 0.7148 - val_loss: 1.0102 - val_accuracy: 0.5726\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6672 - accuracy: 0.7370 - val_loss: 0.9006 - val_accuracy: 0.5897\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6470 - accuracy: 0.7333 - val_loss: 0.9110 - val_accuracy: 0.6068\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6395 - accuracy: 0.7259 - val_loss: 0.9379 - val_accuracy: 0.5812\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6703 - accuracy: 0.7185 - val_loss: 1.0217 - val_accuracy: 0.5983\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6917 - accuracy: 0.7259 - val_loss: 0.9505 - val_accuracy: 0.5812\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6316 - accuracy: 0.7444 - val_loss: 0.9758 - val_accuracy: 0.5812\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6593 - accuracy: 0.7259 - val_loss: 0.9521 - val_accuracy: 0.5983\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6715 - accuracy: 0.7370 - val_loss: 1.0585 - val_accuracy: 0.6154\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0310 - accuracy: 0.6630 - val_loss: 1.9256 - val_accuracy: 0.5897\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1304 - accuracy: 0.6815 - val_loss: 1.7749 - val_accuracy: 0.5812\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8422 - accuracy: 0.7037 - val_loss: 0.9796 - val_accuracy: 0.5812\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0025 - accuracy: 0.6593 - val_loss: 0.9841 - val_accuracy: 0.5641\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6411 - accuracy: 0.7185 - val_loss: 1.4145 - val_accuracy: 0.5726\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7960 - accuracy: 0.7148 - val_loss: 0.9262 - val_accuracy: 0.6068\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6847 - accuracy: 0.7037 - val_loss: 0.9366 - val_accuracy: 0.5983\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6598 - accuracy: 0.7259 - val_loss: 1.0611 - val_accuracy: 0.5897\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6952 - accuracy: 0.7370 - val_loss: 0.9115 - val_accuracy: 0.5812\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7191 - accuracy: 0.6963 - val_loss: 0.9329 - val_accuracy: 0.5983\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6550 - accuracy: 0.7370 - val_loss: 1.1070 - val_accuracy: 0.5897\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6801 - accuracy: 0.7185 - val_loss: 0.9699 - val_accuracy: 0.6068\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6534 - accuracy: 0.7222 - val_loss: 0.9746 - val_accuracy: 0.6154\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6614 - accuracy: 0.7407 - val_loss: 0.9543 - val_accuracy: 0.6068\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6661 - accuracy: 0.7370 - val_loss: 0.9118 - val_accuracy: 0.5897\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6523 - accuracy: 0.7222 - val_loss: 0.9150 - val_accuracy: 0.6068\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6312 - accuracy: 0.7444 - val_loss: 0.9601 - val_accuracy: 0.5983\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6891 - accuracy: 0.7259 - val_loss: 1.0264 - val_accuracy: 0.5897\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6656 - accuracy: 0.7296 - val_loss: 0.9780 - val_accuracy: 0.5897\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6583 - accuracy: 0.7296 - val_loss: 0.9658 - val_accuracy: 0.6068\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6810 - accuracy: 0.7111 - val_loss: 0.9745 - val_accuracy: 0.5812\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6647 - accuracy: 0.7259 - val_loss: 0.9139 - val_accuracy: 0.5983\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7487 - accuracy: 0.6778 - val_loss: 1.0478 - val_accuracy: 0.6068\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6802 - accuracy: 0.7296 - val_loss: 1.0248 - val_accuracy: 0.6068\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6566 - accuracy: 0.7222 - val_loss: 0.9375 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6676 - accuracy: 0.7185 - val_loss: 0.9137 - val_accuracy: 0.6239\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6357 - accuracy: 0.7222 - val_loss: 1.0345 - val_accuracy: 0.6068\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6743 - accuracy: 0.7407 - val_loss: 0.9085 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6907 - accuracy: 0.7148 - val_loss: 0.9273 - val_accuracy: 0.6154\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6972 - accuracy: 0.7074 - val_loss: 0.9981 - val_accuracy: 0.5812\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6845 - accuracy: 0.7333 - val_loss: 0.8971 - val_accuracy: 0.6068\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6993 - accuracy: 0.7074 - val_loss: 0.9251 - val_accuracy: 0.5897\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6420 - accuracy: 0.7370 - val_loss: 1.0409 - val_accuracy: 0.5983\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6597 - accuracy: 0.7259 - val_loss: 0.9553 - val_accuracy: 0.6068\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6499 - accuracy: 0.7222 - val_loss: 0.9183 - val_accuracy: 0.6154\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6392 - accuracy: 0.7296 - val_loss: 0.9333 - val_accuracy: 0.6068\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6412 - accuracy: 0.7222 - val_loss: 0.9225 - val_accuracy: 0.5897\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6531 - accuracy: 0.7333 - val_loss: 0.9277 - val_accuracy: 0.6068\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7198 - accuracy: 0.6963 - val_loss: 1.0222 - val_accuracy: 0.6154\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6614 - accuracy: 0.7370 - val_loss: 1.1908 - val_accuracy: 0.5556\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7561 - accuracy: 0.6926 - val_loss: 1.2559 - val_accuracy: 0.5897\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8071 - accuracy: 0.6889 - val_loss: 1.1846 - val_accuracy: 0.5556\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7110 - accuracy: 0.7111 - val_loss: 0.9476 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6718 - accuracy: 0.7000 - val_loss: 0.9579 - val_accuracy: 0.6410\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6394 - accuracy: 0.7444 - val_loss: 0.9811 - val_accuracy: 0.6154\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6287 - accuracy: 0.7407 - val_loss: 0.9143 - val_accuracy: 0.5983\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6829 - accuracy: 0.7111 - val_loss: 0.9298 - val_accuracy: 0.5983\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6353 - accuracy: 0.7296 - val_loss: 1.0585 - val_accuracy: 0.5897\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6940 - accuracy: 0.7259 - val_loss: 0.9575 - val_accuracy: 0.5812\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7249 - accuracy: 0.7000 - val_loss: 0.9641 - val_accuracy: 0.5897\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6572 - accuracy: 0.7407 - val_loss: 1.0365 - val_accuracy: 0.6154\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6584 - accuracy: 0.7296 - val_loss: 0.9245 - val_accuracy: 0.5983\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6631 - accuracy: 0.7148 - val_loss: 0.9325 - val_accuracy: 0.5983\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6381 - accuracy: 0.7185 - val_loss: 0.9770 - val_accuracy: 0.5983\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6517 - accuracy: 0.7333 - val_loss: 0.9178 - val_accuracy: 0.5983\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6618 - accuracy: 0.7111 - val_loss: 0.9153 - val_accuracy: 0.5983\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6390 - accuracy: 0.7222 - val_loss: 0.9702 - val_accuracy: 0.5897\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6410 - accuracy: 0.7296 - val_loss: 0.9589 - val_accuracy: 0.6068\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6413 - accuracy: 0.7222 - val_loss: 0.8973 - val_accuracy: 0.6325\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6398 - accuracy: 0.7185 - val_loss: 0.9283 - val_accuracy: 0.5897\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6356 - accuracy: 0.7444 - val_loss: 0.8903 - val_accuracy: 0.6239\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6807 - accuracy: 0.6963 - val_loss: 0.9546 - val_accuracy: 0.6154\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8427 - accuracy: 0.7148 - val_loss: 1.0343 - val_accuracy: 0.5897\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6804 - accuracy: 0.7259 - val_loss: 1.1354 - val_accuracy: 0.6154\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6774 - accuracy: 0.7259 - val_loss: 1.0334 - val_accuracy: 0.6154\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7214 - accuracy: 0.7222 - val_loss: 1.0030 - val_accuracy: 0.5897\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7287 - accuracy: 0.7185 - val_loss: 0.9094 - val_accuracy: 0.5812\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7120 - accuracy: 0.7111 - val_loss: 1.0138 - val_accuracy: 0.6239\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7088 - accuracy: 0.7074 - val_loss: 0.9295 - val_accuracy: 0.6068\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6189 - accuracy: 0.7519 - val_loss: 0.9808 - val_accuracy: 0.6068\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6315 - accuracy: 0.7519 - val_loss: 0.9199 - val_accuracy: 0.5897\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6365 - accuracy: 0.7111 - val_loss: 0.9408 - val_accuracy: 0.5983\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6294 - accuracy: 0.7407 - val_loss: 1.0127 - val_accuracy: 0.6068\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6776 - accuracy: 0.7148 - val_loss: 0.9736 - val_accuracy: 0.5983\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6449 - accuracy: 0.7185 - val_loss: 0.9218 - val_accuracy: 0.6068\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6141 - accuracy: 0.7444 - val_loss: 0.9442 - val_accuracy: 0.6068\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6466 - accuracy: 0.7333 - val_loss: 0.9639 - val_accuracy: 0.5726\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9014 - accuracy: 0.6852 - val_loss: 1.0855 - val_accuracy: 0.6154\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0889 - accuracy: 0.6667 - val_loss: 1.8868 - val_accuracy: 0.6154\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.1713 - accuracy: 0.6963 - val_loss: 1.4977 - val_accuracy: 0.5983\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7219 - accuracy: 0.7185 - val_loss: 1.3874 - val_accuracy: 0.5043\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.1481 - accuracy: 0.6444 - val_loss: 1.0873 - val_accuracy: 0.5897\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0541 - accuracy: 0.7000 - val_loss: 2.0734 - val_accuracy: 0.5983\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.2399 - accuracy: 0.7074 - val_loss: 1.8817 - val_accuracy: 0.5812\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9650 - accuracy: 0.7222 - val_loss: 1.0440 - val_accuracy: 0.5726\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7501 - accuracy: 0.6926 - val_loss: 1.0927 - val_accuracy: 0.5470\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6737 - accuracy: 0.7222 - val_loss: 1.1540 - val_accuracy: 0.5812\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8082 - accuracy: 0.7148 - val_loss: 1.1431 - val_accuracy: 0.5897\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6737 - accuracy: 0.7222 - val_loss: 1.2635 - val_accuracy: 0.5214\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8548 - accuracy: 0.6667 - val_loss: 1.2437 - val_accuracy: 0.5812\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7852 - accuracy: 0.7222 - val_loss: 1.7859 - val_accuracy: 0.5214\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8094 - accuracy: 0.7185 - val_loss: 1.1056 - val_accuracy: 0.5299\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8290 - accuracy: 0.6370 - val_loss: 1.0113 - val_accuracy: 0.5812\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.0736 - accuracy: 0.6630 - val_loss: 2.0171 - val_accuracy: 0.6154\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.2395 - accuracy: 0.6852 - val_loss: 1.9251 - val_accuracy: 0.5385\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9370 - accuracy: 0.6926 - val_loss: 1.0023 - val_accuracy: 0.5470\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0649 - accuracy: 0.6556 - val_loss: 0.9969 - val_accuracy: 0.5470\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6880 - accuracy: 0.7111 - val_loss: 1.4198 - val_accuracy: 0.6239\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8813 - accuracy: 0.7148 - val_loss: 1.4228 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7192 - accuracy: 0.7222 - val_loss: 0.9598 - val_accuracy: 0.5641\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7724 - accuracy: 0.6741 - val_loss: 0.9180 - val_accuracy: 0.5641\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6344 - accuracy: 0.7222 - val_loss: 1.1442 - val_accuracy: 0.6154\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6899 - accuracy: 0.7333 - val_loss: 0.9776 - val_accuracy: 0.6154\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6558 - accuracy: 0.7222 - val_loss: 0.9584 - val_accuracy: 0.5897\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6485 - accuracy: 0.7185 - val_loss: 0.9800 - val_accuracy: 0.5983\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6425 - accuracy: 0.7481 - val_loss: 1.0070 - val_accuracy: 0.5897\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6643 - accuracy: 0.7222 - val_loss: 0.9210 - val_accuracy: 0.6068\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6257 - accuracy: 0.7370 - val_loss: 0.9641 - val_accuracy: 0.6154\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6443 - accuracy: 0.7407 - val_loss: 0.9609 - val_accuracy: 0.6239\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6671 - accuracy: 0.7148 - val_loss: 0.9630 - val_accuracy: 0.6154\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6335 - accuracy: 0.7407 - val_loss: 1.1759 - val_accuracy: 0.5983\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7218 - accuracy: 0.7259 - val_loss: 1.1069 - val_accuracy: 0.6239\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6902 - accuracy: 0.7296 - val_loss: 0.9670 - val_accuracy: 0.6154\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7186 - accuracy: 0.7074 - val_loss: 0.9792 - val_accuracy: 0.6154\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7238 - accuracy: 0.7037 - val_loss: 1.1786 - val_accuracy: 0.6239\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6845 - accuracy: 0.7296 - val_loss: 1.0036 - val_accuracy: 0.6239\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6734 - accuracy: 0.7296 - val_loss: 0.9772 - val_accuracy: 0.6154\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7042 - accuracy: 0.7037 - val_loss: 0.9810 - val_accuracy: 0.5897\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6519 - accuracy: 0.7444 - val_loss: 0.9897 - val_accuracy: 0.6410\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6975 - accuracy: 0.7148 - val_loss: 0.9699 - val_accuracy: 0.5726\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6827 - accuracy: 0.7185 - val_loss: 1.0111 - val_accuracy: 0.6068\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7612 - accuracy: 0.7259 - val_loss: 0.9082 - val_accuracy: 0.5983\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6519 - accuracy: 0.7037 - val_loss: 0.9688 - val_accuracy: 0.5983\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6444 - accuracy: 0.7370 - val_loss: 0.9761 - val_accuracy: 0.6068\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6365 - accuracy: 0.7296 - val_loss: 0.9163 - val_accuracy: 0.6068\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6932 - accuracy: 0.7222 - val_loss: 1.1515 - val_accuracy: 0.5983\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6443 - accuracy: 0.7296 - val_loss: 0.9826 - val_accuracy: 0.6068\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6669 - accuracy: 0.7185 - val_loss: 0.9326 - val_accuracy: 0.5897\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6551 - accuracy: 0.7407 - val_loss: 0.9489 - val_accuracy: 0.5983\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6855 - accuracy: 0.7111 - val_loss: 0.9757 - val_accuracy: 0.5983\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6920 - accuracy: 0.7111 - val_loss: 1.0650 - val_accuracy: 0.6068\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6786 - accuracy: 0.7444 - val_loss: 0.9665 - val_accuracy: 0.5897\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6419 - accuracy: 0.7333 - val_loss: 0.9835 - val_accuracy: 0.6325\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6494 - accuracy: 0.7444 - val_loss: 0.9587 - val_accuracy: 0.6154\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6382 - accuracy: 0.7222 - val_loss: 0.9112 - val_accuracy: 0.6068\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6432 - accuracy: 0.7444 - val_loss: 0.9916 - val_accuracy: 0.6154\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6255 - accuracy: 0.7481 - val_loss: 0.9828 - val_accuracy: 0.6154\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6624 - accuracy: 0.7074 - val_loss: 0.9140 - val_accuracy: 0.6154\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6402 - accuracy: 0.7370 - val_loss: 0.9958 - val_accuracy: 0.6239\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6456 - accuracy: 0.7111 - val_loss: 0.9944 - val_accuracy: 0.6154\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6452 - accuracy: 0.7222 - val_loss: 0.9405 - val_accuracy: 0.6325\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6210 - accuracy: 0.7444 - val_loss: 0.9157 - val_accuracy: 0.6325\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6128 - accuracy: 0.7444 - val_loss: 0.9356 - val_accuracy: 0.5983\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6071 - accuracy: 0.7593 - val_loss: 0.9129 - val_accuracy: 0.6154\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6122 - accuracy: 0.7444 - val_loss: 0.9031 - val_accuracy: 0.6239\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6164 - accuracy: 0.7407 - val_loss: 0.9096 - val_accuracy: 0.6239\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6639 - accuracy: 0.7481 - val_loss: 0.9247 - val_accuracy: 0.5897\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6403 - accuracy: 0.7296 - val_loss: 0.9746 - val_accuracy: 0.5897\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6619 - accuracy: 0.7111 - val_loss: 0.9498 - val_accuracy: 0.6154\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7308 - accuracy: 0.7370 - val_loss: 1.0393 - val_accuracy: 0.5983\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7725 - accuracy: 0.6815 - val_loss: 1.1005 - val_accuracy: 0.5641\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6860 - accuracy: 0.7148 - val_loss: 1.2362 - val_accuracy: 0.5983\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6942 - accuracy: 0.7333 - val_loss: 1.1218 - val_accuracy: 0.6154\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7108 - accuracy: 0.7074 - val_loss: 0.9824 - val_accuracy: 0.5983\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6452 - accuracy: 0.7185 - val_loss: 0.9935 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6361 - accuracy: 0.7444 - val_loss: 1.0030 - val_accuracy: 0.5983\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6364 - accuracy: 0.7333 - val_loss: 0.9155 - val_accuracy: 0.6496\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6107 - accuracy: 0.7704 - val_loss: 0.9289 - val_accuracy: 0.5983\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6137 - accuracy: 0.7593 - val_loss: 0.9383 - val_accuracy: 0.5897\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6353 - accuracy: 0.7111 - val_loss: 0.9142 - val_accuracy: 0.5983\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6205 - accuracy: 0.7370 - val_loss: 0.9820 - val_accuracy: 0.6154\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6317 - accuracy: 0.7556 - val_loss: 0.9290 - val_accuracy: 0.5983\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6206 - accuracy: 0.7370 - val_loss: 0.9208 - val_accuracy: 0.5983\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6199 - accuracy: 0.7370 - val_loss: 0.9340 - val_accuracy: 0.6239\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6075 - accuracy: 0.7630 - val_loss: 0.9406 - val_accuracy: 0.6068\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6188 - accuracy: 0.7481 - val_loss: 0.9338 - val_accuracy: 0.5897\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6093 - accuracy: 0.7444 - val_loss: 0.9236 - val_accuracy: 0.6068\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6084 - accuracy: 0.7481 - val_loss: 0.9363 - val_accuracy: 0.5897\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6091 - accuracy: 0.7407 - val_loss: 0.9286 - val_accuracy: 0.6154\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6101 - accuracy: 0.7519 - val_loss: 0.9309 - val_accuracy: 0.6068\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6110 - accuracy: 0.7444 - val_loss: 0.9227 - val_accuracy: 0.5983\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6127 - accuracy: 0.7407 - val_loss: 0.9403 - val_accuracy: 0.6239\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6070 - accuracy: 0.7593 - val_loss: 0.9110 - val_accuracy: 0.6068\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6123 - accuracy: 0.7444 - val_loss: 0.9081 - val_accuracy: 0.6154\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6036 - accuracy: 0.7481 - val_loss: 0.9259 - val_accuracy: 0.6154\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6107 - accuracy: 0.7481 - val_loss: 0.9171 - val_accuracy: 0.6068\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6043 - accuracy: 0.7556 - val_loss: 0.9544 - val_accuracy: 0.6410\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6044 - accuracy: 0.7556 - val_loss: 0.9088 - val_accuracy: 0.6325\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6019 - accuracy: 0.7444 - val_loss: 0.9335 - val_accuracy: 0.6410\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6131 - accuracy: 0.7556 - val_loss: 0.9062 - val_accuracy: 0.6325\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6012 - accuracy: 0.7519 - val_loss: 0.9209 - val_accuracy: 0.6496\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6028 - accuracy: 0.7519 - val_loss: 0.9267 - val_accuracy: 0.6581\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.5993 - accuracy: 0.7704 - val_loss: 0.9255 - val_accuracy: 0.6154\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6110 - accuracy: 0.7333 - val_loss: 0.9493 - val_accuracy: 0.6496\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6149 - accuracy: 0.7667 - val_loss: 0.9096 - val_accuracy: 0.5983\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6030 - accuracy: 0.7333 - val_loss: 0.9400 - val_accuracy: 0.5812\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6155 - accuracy: 0.7370 - val_loss: 0.9681 - val_accuracy: 0.6325\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6064 - accuracy: 0.7593 - val_loss: 0.9253 - val_accuracy: 0.6154\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6119 - accuracy: 0.7333 - val_loss: 0.9264 - val_accuracy: 0.6068\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6091 - accuracy: 0.7519 - val_loss: 0.9811 - val_accuracy: 0.6239\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6174 - accuracy: 0.7444 - val_loss: 0.9328 - val_accuracy: 0.5983\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6450 - accuracy: 0.7148 - val_loss: 0.9381 - val_accuracy: 0.6068\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6417 - accuracy: 0.7333 - val_loss: 0.9909 - val_accuracy: 0.6154\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6063 - accuracy: 0.7519 - val_loss: 0.9531 - val_accuracy: 0.6068\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6397 - accuracy: 0.7296 - val_loss: 0.9965 - val_accuracy: 0.6239\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6228 - accuracy: 0.7333 - val_loss: 0.9294 - val_accuracy: 0.6068\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6125 - accuracy: 0.7444 - val_loss: 0.9768 - val_accuracy: 0.6239\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6260 - accuracy: 0.7593 - val_loss: 0.9322 - val_accuracy: 0.6239\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6008 - accuracy: 0.7630 - val_loss: 0.9359 - val_accuracy: 0.6154\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6062 - accuracy: 0.7481 - val_loss: 0.9411 - val_accuracy: 0.6239\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6058 - accuracy: 0.7630 - val_loss: 0.9074 - val_accuracy: 0.6325\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6042 - accuracy: 0.7407 - val_loss: 0.9145 - val_accuracy: 0.6239\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6000 - accuracy: 0.7519 - val_loss: 0.9233 - val_accuracy: 0.6068\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6033 - accuracy: 0.7444 - val_loss: 0.9071 - val_accuracy: 0.6068\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5944 - accuracy: 0.7593 - val_loss: 0.9635 - val_accuracy: 0.6068\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6103 - accuracy: 0.7481 - val_loss: 0.9298 - val_accuracy: 0.6239\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6125 - accuracy: 0.7111 - val_loss: 0.9159 - val_accuracy: 0.6325\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6030 - accuracy: 0.7481 - val_loss: 0.9494 - val_accuracy: 0.6239\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6143 - accuracy: 0.7481 - val_loss: 0.9483 - val_accuracy: 0.6496\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6509 - accuracy: 0.7407 - val_loss: 1.1101 - val_accuracy: 0.6239\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7524 - accuracy: 0.6926 - val_loss: 1.0621 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6217 - accuracy: 0.7593 - val_loss: 0.9865 - val_accuracy: 0.6410\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6561 - accuracy: 0.7481 - val_loss: 1.1739 - val_accuracy: 0.6239\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8718 - accuracy: 0.6889 - val_loss: 1.2659 - val_accuracy: 0.6325\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8162 - accuracy: 0.7148 - val_loss: 0.9951 - val_accuracy: 0.6325\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6749 - accuracy: 0.7296 - val_loss: 0.9384 - val_accuracy: 0.6154\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6491 - accuracy: 0.7296 - val_loss: 0.9554 - val_accuracy: 0.6410\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6350 - accuracy: 0.7556 - val_loss: 0.9263 - val_accuracy: 0.6154\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6135 - accuracy: 0.7296 - val_loss: 0.9143 - val_accuracy: 0.6154\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6148 - accuracy: 0.7481 - val_loss: 0.9431 - val_accuracy: 0.6325\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6130 - accuracy: 0.7556 - val_loss: 0.9406 - val_accuracy: 0.6239\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6010 - accuracy: 0.7519 - val_loss: 0.9394 - val_accuracy: 0.6410\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6241 - accuracy: 0.7296 - val_loss: 0.9264 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6051 - accuracy: 0.7407 - val_loss: 0.9134 - val_accuracy: 0.6410\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6132 - accuracy: 0.7593 - val_loss: 0.9286 - val_accuracy: 0.6325\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6098 - accuracy: 0.7444 - val_loss: 0.9252 - val_accuracy: 0.6410\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6055 - accuracy: 0.7556 - val_loss: 0.9075 - val_accuracy: 0.6496\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6144 - accuracy: 0.7370 - val_loss: 0.8995 - val_accuracy: 0.6325\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6185 - accuracy: 0.7519 - val_loss: 0.9653 - val_accuracy: 0.6410\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6153 - accuracy: 0.7296 - val_loss: 0.9082 - val_accuracy: 0.6154\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6001 - accuracy: 0.7556 - val_loss: 0.9134 - val_accuracy: 0.6410\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.5967 - accuracy: 0.7481 - val_loss: 0.9021 - val_accuracy: 0.6325\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6121 - accuracy: 0.7296 - val_loss: 0.8957 - val_accuracy: 0.6496\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.5971 - accuracy: 0.7519 - val_loss: 0.9339 - val_accuracy: 0.6239\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6463 - accuracy: 0.7259 - val_loss: 0.9097 - val_accuracy: 0.6239\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6120 - accuracy: 0.7296 - val_loss: 0.9745 - val_accuracy: 0.5983\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6265 - accuracy: 0.7407 - val_loss: 0.9027 - val_accuracy: 0.6410\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.5985 - accuracy: 0.7519 - val_loss: 0.9478 - val_accuracy: 0.5983\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6385 - accuracy: 0.7333 - val_loss: 0.9371 - val_accuracy: 0.6325\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6469 - accuracy: 0.7370 - val_loss: 0.9593 - val_accuracy: 0.6068\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6039 - accuracy: 0.7481 - val_loss: 0.9875 - val_accuracy: 0.6154\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6157 - accuracy: 0.7333 - val_loss: 0.9569 - val_accuracy: 0.6068\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6177 - accuracy: 0.7444 - val_loss: 0.9416 - val_accuracy: 0.6068\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6013 - accuracy: 0.7667 - val_loss: 0.9086 - val_accuracy: 0.6496\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6144 - accuracy: 0.7556 - val_loss: 0.9177 - val_accuracy: 0.6410\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.5921 - accuracy: 0.7630 - val_loss: 0.8957 - val_accuracy: 0.6410\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.5984 - accuracy: 0.7667 - val_loss: 0.9063 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6151 - accuracy: 0.7370 - val_loss: 0.9202 - val_accuracy: 0.6154\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6273 - accuracy: 0.7407 - val_loss: 0.9232 - val_accuracy: 0.5983\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6605 - accuracy: 0.7296 - val_loss: 0.9880 - val_accuracy: 0.6325\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6188 - accuracy: 0.7481 - val_loss: 0.9729 - val_accuracy: 0.6410\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6075 - accuracy: 0.7444 - val_loss: 0.9402 - val_accuracy: 0.6325\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6136 - accuracy: 0.7407 - val_loss: 0.9480 - val_accuracy: 0.6410\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6074 - accuracy: 0.7370 - val_loss: 0.9032 - val_accuracy: 0.6410\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6203 - accuracy: 0.7407 - val_loss: 0.9218 - val_accuracy: 0.6496\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6023 - accuracy: 0.7593 - val_loss: 0.9493 - val_accuracy: 0.5983\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6251 - accuracy: 0.7370 - val_loss: 0.9340 - val_accuracy: 0.6496\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6714 - accuracy: 0.7407 - val_loss: 0.9515 - val_accuracy: 0.6325\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6222 - accuracy: 0.7519 - val_loss: 1.0204 - val_accuracy: 0.6154\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6244 - accuracy: 0.7370 - val_loss: 0.9544 - val_accuracy: 0.6410\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6084 - accuracy: 0.7481 - val_loss: 0.9235 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c6063c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 35us/step\n",
      "over-sampling test accuracy: 61.54%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 1,\n",
       "       2, 2, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 1, 2,\n",
       "       2, 2, 0, 2, 1, 0, 2, 0, 2, 2, 1, 1, 2, 0, 0, 1, 2, 0, 1, 0, 1, 2,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 2, 0, 2, 0, 1, 2, 0,\n",
       "       1, 1, 2, 0, 2, 1, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR4187     0     0\n",
       "1         NRS177     0     0\n",
       "2         NRS109     2     2\n",
       "3    CFBREBSa131     2     2\n",
       "4         SR4152     1     1\n",
       "..           ...   ...   ...\n",
       "112       NRS110     2     1\n",
       "113     CFBRSa25     1     1\n",
       "114         834N     0     0\n",
       "115  CFBREBSa114     1     1\n",
       "116       NRS387     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.582708e-12</td>\n",
       "      <td>3.055194e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.579007</td>\n",
       "      <td>4.162575e-01</td>\n",
       "      <td>4.735081e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007004</td>\n",
       "      <td>4.206216e-01</td>\n",
       "      <td>5.723745e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022045</td>\n",
       "      <td>9.653085e-02</td>\n",
       "      <td>8.814240e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218927</td>\n",
       "      <td>6.354200e-01</td>\n",
       "      <td>1.456533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.218927</td>\n",
       "      <td>6.354200e-01</td>\n",
       "      <td>1.456533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.218927</td>\n",
       "      <td>6.354200e-01</td>\n",
       "      <td>1.456533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.891823</td>\n",
       "      <td>9.339423e-02</td>\n",
       "      <td>1.478260e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.403542</td>\n",
       "      <td>4.730577e-01</td>\n",
       "      <td>1.234005e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.218927</td>\n",
       "      <td>6.354200e-01</td>\n",
       "      <td>1.456533e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    1.000000  3.582708e-12  3.055194e-32\n",
       "1    0.579007  4.162575e-01  4.735081e-03\n",
       "2    0.007004  4.206216e-01  5.723745e-01\n",
       "3    0.022045  9.653085e-02  8.814240e-01\n",
       "4    0.218927  6.354200e-01  1.456533e-01\n",
       "..        ...           ...           ...\n",
       "112  0.218927  6.354200e-01  1.456533e-01\n",
       "113  0.218927  6.354200e-01  1.456533e-01\n",
       "114  0.891823  9.339423e-02  1.478260e-02\n",
       "115  0.403542  4.730577e-01  1.234005e-01\n",
       "116  0.218927  6.354200e-01  1.456533e-01\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7394 - accuracy: 0.7148 - val_loss: 0.9625 - val_accuracy: 0.6068\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7180 - accuracy: 0.7185 - val_loss: 0.9138 - val_accuracy: 0.5897\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7410 - accuracy: 0.7037 - val_loss: 0.9342 - val_accuracy: 0.6239\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7706 - accuracy: 0.6963 - val_loss: 0.9613 - val_accuracy: 0.6154\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7077 - accuracy: 0.7259 - val_loss: 0.9559 - val_accuracy: 0.5897\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7564 - accuracy: 0.7000 - val_loss: 1.0571 - val_accuracy: 0.6154\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8158 - accuracy: 0.7148 - val_loss: 0.9926 - val_accuracy: 0.5897\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7257 - accuracy: 0.7000 - val_loss: 0.8817 - val_accuracy: 0.5641\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7685 - accuracy: 0.7000 - val_loss: 0.8636 - val_accuracy: 0.5983\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7139 - accuracy: 0.7185 - val_loss: 1.0461 - val_accuracy: 0.5385\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7286 - accuracy: 0.7074 - val_loss: 0.8628 - val_accuracy: 0.5897\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7089 - accuracy: 0.6963 - val_loss: 0.8519 - val_accuracy: 0.5983\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6935 - accuracy: 0.7148 - val_loss: 0.8481 - val_accuracy: 0.5812\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6982 - accuracy: 0.7148 - val_loss: 0.8759 - val_accuracy: 0.5812\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7307 - accuracy: 0.7000 - val_loss: 0.8504 - val_accuracy: 0.6154\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7197 - accuracy: 0.7222 - val_loss: 0.9890 - val_accuracy: 0.5726\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7274 - accuracy: 0.7185 - val_loss: 0.8825 - val_accuracy: 0.5812\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7294 - accuracy: 0.7111 - val_loss: 0.8527 - val_accuracy: 0.6325\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6958 - accuracy: 0.7296 - val_loss: 0.9391 - val_accuracy: 0.5812\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7191 - accuracy: 0.7000 - val_loss: 0.8589 - val_accuracy: 0.5983\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7202 - accuracy: 0.7000 - val_loss: 0.8794 - val_accuracy: 0.5812\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7051 - accuracy: 0.7148 - val_loss: 0.8579 - val_accuracy: 0.5983\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7088 - accuracy: 0.7111 - val_loss: 0.8614 - val_accuracy: 0.6068\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6940 - accuracy: 0.7148 - val_loss: 0.8590 - val_accuracy: 0.5897\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6913 - accuracy: 0.7259 - val_loss: 0.8536 - val_accuracy: 0.6239\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7000 - accuracy: 0.7111 - val_loss: 0.8558 - val_accuracy: 0.6154\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6965 - accuracy: 0.7296 - val_loss: 0.8352 - val_accuracy: 0.6410\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7125 - accuracy: 0.6852 - val_loss: 0.8332 - val_accuracy: 0.6154\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6920 - accuracy: 0.7148 - val_loss: 0.8837 - val_accuracy: 0.6068\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6988 - accuracy: 0.7185 - val_loss: 0.8560 - val_accuracy: 0.6154\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7390 - accuracy: 0.7037 - val_loss: 0.8519 - val_accuracy: 0.5983\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7080 - accuracy: 0.7185 - val_loss: 0.9535 - val_accuracy: 0.5641\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7144 - accuracy: 0.7148 - val_loss: 0.8450 - val_accuracy: 0.6410\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7125 - accuracy: 0.7037 - val_loss: 0.8721 - val_accuracy: 0.6154\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6991 - accuracy: 0.7333 - val_loss: 0.8530 - val_accuracy: 0.6154\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6995 - accuracy: 0.7222 - val_loss: 0.8600 - val_accuracy: 0.6068\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6914 - accuracy: 0.7296 - val_loss: 0.8385 - val_accuracy: 0.6154\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7096 - accuracy: 0.6926 - val_loss: 0.8423 - val_accuracy: 0.6154\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6930 - accuracy: 0.7148 - val_loss: 0.8781 - val_accuracy: 0.5983\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7038 - accuracy: 0.7259 - val_loss: 0.8500 - val_accuracy: 0.5812\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7292 - accuracy: 0.7037 - val_loss: 0.8442 - val_accuracy: 0.6154\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7197 - accuracy: 0.7259 - val_loss: 0.8379 - val_accuracy: 0.6239\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8036 - accuracy: 0.7000 - val_loss: 0.9450 - val_accuracy: 0.5983\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7679 - accuracy: 0.7037 - val_loss: 0.9405 - val_accuracy: 0.5897\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7632 - accuracy: 0.6963 - val_loss: 0.8669 - val_accuracy: 0.6325\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7552 - accuracy: 0.7037 - val_loss: 0.8976 - val_accuracy: 0.6325\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7016 - accuracy: 0.7148 - val_loss: 1.1881 - val_accuracy: 0.5983\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8053 - accuracy: 0.7185 - val_loss: 0.9770 - val_accuracy: 0.6325\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7843 - accuracy: 0.7037 - val_loss: 0.8953 - val_accuracy: 0.6154\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7270 - accuracy: 0.7333 - val_loss: 0.8868 - val_accuracy: 0.5641\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7438 - accuracy: 0.7111 - val_loss: 1.0103 - val_accuracy: 0.5726\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7503 - accuracy: 0.7074 - val_loss: 0.8843 - val_accuracy: 0.6154\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7157 - accuracy: 0.7296 - val_loss: 0.8428 - val_accuracy: 0.6154\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6815 - accuracy: 0.7185 - val_loss: 0.9040 - val_accuracy: 0.5897\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6919 - accuracy: 0.7111 - val_loss: 0.8505 - val_accuracy: 0.5983\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6895 - accuracy: 0.7185 - val_loss: 0.9439 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7713 - accuracy: 0.7259 - val_loss: 0.9810 - val_accuracy: 0.6154\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7797 - accuracy: 0.7111 - val_loss: 0.8654 - val_accuracy: 0.6325\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8054 - accuracy: 0.7074 - val_loss: 1.1141 - val_accuracy: 0.6410\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7947 - accuracy: 0.7037 - val_loss: 1.0632 - val_accuracy: 0.5983\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7777 - accuracy: 0.6704 - val_loss: 1.1258 - val_accuracy: 0.6325\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8971 - accuracy: 0.7148 - val_loss: 1.1812 - val_accuracy: 0.5726\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.68 - 0s 73us/step - loss: 0.8259 - accuracy: 0.6852 - val_loss: 0.9496 - val_accuracy: 0.5726\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7610 - accuracy: 0.6704 - val_loss: 1.0662 - val_accuracy: 0.6068\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8419 - accuracy: 0.7111 - val_loss: 1.1812 - val_accuracy: 0.6325\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8264 - accuracy: 0.7037 - val_loss: 0.9032 - val_accuracy: 0.5897\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7542 - accuracy: 0.6963 - val_loss: 1.2032 - val_accuracy: 0.6325\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9353 - accuracy: 0.6963 - val_loss: 1.2985 - val_accuracy: 0.6239\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8292 - accuracy: 0.7185 - val_loss: 0.8420 - val_accuracy: 0.5897\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7353 - accuracy: 0.6926 - val_loss: 0.8584 - val_accuracy: 0.6068\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7128 - accuracy: 0.7111 - val_loss: 0.8401 - val_accuracy: 0.5983\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7378 - accuracy: 0.6963 - val_loss: 0.8668 - val_accuracy: 0.6154\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7813 - accuracy: 0.6926 - val_loss: 0.9118 - val_accuracy: 0.6410\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7396 - accuracy: 0.7037 - val_loss: 0.8825 - val_accuracy: 0.5897\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7160 - accuracy: 0.7111 - val_loss: 0.8877 - val_accuracy: 0.6410\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7129 - accuracy: 0.7259 - val_loss: 0.8534 - val_accuracy: 0.6496\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6756 - accuracy: 0.7111 - val_loss: 0.8873 - val_accuracy: 0.6239\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6827 - accuracy: 0.7296 - val_loss: 0.8880 - val_accuracy: 0.6410\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7153 - accuracy: 0.7222 - val_loss: 0.8495 - val_accuracy: 0.6325\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6922 - accuracy: 0.7222 - val_loss: 0.8736 - val_accuracy: 0.6154\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6889 - accuracy: 0.7407 - val_loss: 0.8468 - val_accuracy: 0.6325\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6882 - accuracy: 0.7185 - val_loss: 0.8490 - val_accuracy: 0.6068\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6858 - accuracy: 0.7222 - val_loss: 0.9186 - val_accuracy: 0.5812\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7007 - accuracy: 0.7333 - val_loss: 0.8362 - val_accuracy: 0.6239\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7007 - accuracy: 0.7148 - val_loss: 0.8496 - val_accuracy: 0.6239\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7033 - accuracy: 0.7333 - val_loss: 0.8483 - val_accuracy: 0.6239\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7525 - accuracy: 0.6852 - val_loss: 0.8429 - val_accuracy: 0.6068\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6778 - accuracy: 0.7407 - val_loss: 0.9267 - val_accuracy: 0.5556\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6940 - accuracy: 0.7222 - val_loss: 0.8507 - val_accuracy: 0.6068\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6966 - accuracy: 0.7222 - val_loss: 0.8722 - val_accuracy: 0.6325\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.78 - 0s 70us/step - loss: 0.7103 - accuracy: 0.7000 - val_loss: 0.8888 - val_accuracy: 0.6239\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7151 - accuracy: 0.7111 - val_loss: 0.8548 - val_accuracy: 0.6239\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7307 - accuracy: 0.7037 - val_loss: 0.8560 - val_accuracy: 0.6239\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6870 - accuracy: 0.7222 - val_loss: 0.9390 - val_accuracy: 0.5726\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6965 - accuracy: 0.7296 - val_loss: 0.8492 - val_accuracy: 0.6239\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6851 - accuracy: 0.7074 - val_loss: 0.8727 - val_accuracy: 0.6410\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6968 - accuracy: 0.7259 - val_loss: 0.8525 - val_accuracy: 0.6239\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7050 - accuracy: 0.7185 - val_loss: 0.8919 - val_accuracy: 0.6325\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8565 - accuracy: 0.7111 - val_loss: 1.0556 - val_accuracy: 0.6068\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7995 - accuracy: 0.7037 - val_loss: 0.9769 - val_accuracy: 0.5897\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7224 - accuracy: 0.7074 - val_loss: 0.9795 - val_accuracy: 0.6325\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7129 - accuracy: 0.7296 - val_loss: 0.8916 - val_accuracy: 0.6068\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6935 - accuracy: 0.7333 - val_loss: 0.9128 - val_accuracy: 0.6154\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8025 - accuracy: 0.7037 - val_loss: 1.0892 - val_accuracy: 0.6410\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8638 - accuracy: 0.7111 - val_loss: 1.1909 - val_accuracy: 0.6410\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8034 - accuracy: 0.7185 - val_loss: 0.8723 - val_accuracy: 0.5983\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7150 - accuracy: 0.7222 - val_loss: 0.8770 - val_accuracy: 0.6154\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7187 - accuracy: 0.7259 - val_loss: 0.8819 - val_accuracy: 0.6239\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6923 - accuracy: 0.7111 - val_loss: 0.8752 - val_accuracy: 0.5983\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7334 - accuracy: 0.7148 - val_loss: 0.9056 - val_accuracy: 0.5812\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7461 - accuracy: 0.6926 - val_loss: 0.8791 - val_accuracy: 0.5897\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7114 - accuracy: 0.7185 - val_loss: 0.8489 - val_accuracy: 0.6325\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7000 - accuracy: 0.7222 - val_loss: 0.8404 - val_accuracy: 0.6239\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6812 - accuracy: 0.7259 - val_loss: 0.8792 - val_accuracy: 0.6239\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6891 - accuracy: 0.7222 - val_loss: 0.9030 - val_accuracy: 0.6239\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7076 - accuracy: 0.7259 - val_loss: 0.8582 - val_accuracy: 0.6154\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7051 - accuracy: 0.7074 - val_loss: 0.8575 - val_accuracy: 0.6068\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6919 - accuracy: 0.7370 - val_loss: 0.8435 - val_accuracy: 0.6410\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7001 - accuracy: 0.7185 - val_loss: 0.8481 - val_accuracy: 0.6068\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7010 - accuracy: 0.7259 - val_loss: 0.8442 - val_accuracy: 0.6068\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7664 - accuracy: 0.6852 - val_loss: 0.8706 - val_accuracy: 0.6068\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8976 - accuracy: 0.6852 - val_loss: 0.8831 - val_accuracy: 0.5897\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7907 - accuracy: 0.6852 - val_loss: 1.2689 - val_accuracy: 0.5812\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9073 - accuracy: 0.6926 - val_loss: 1.2914 - val_accuracy: 0.5299\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7578 - accuracy: 0.7074 - val_loss: 0.9172 - val_accuracy: 0.5726\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7838 - accuracy: 0.6926 - val_loss: 0.9470 - val_accuracy: 0.6068\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7567 - accuracy: 0.6963 - val_loss: 0.8850 - val_accuracy: 0.5897\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7085 - accuracy: 0.7148 - val_loss: 0.9606 - val_accuracy: 0.6410\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7478 - accuracy: 0.7111 - val_loss: 0.8620 - val_accuracy: 0.6496\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7888 - accuracy: 0.6963 - val_loss: 0.9518 - val_accuracy: 0.6154\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8256 - accuracy: 0.7037 - val_loss: 1.3062 - val_accuracy: 0.5897\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8566 - accuracy: 0.6963 - val_loss: 0.8541 - val_accuracy: 0.6410\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9596 - accuracy: 0.6815 - val_loss: 0.8803 - val_accuracy: 0.6410\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8415 - accuracy: 0.7333 - val_loss: 1.2741 - val_accuracy: 0.6325\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8582 - accuracy: 0.7111 - val_loss: 0.9098 - val_accuracy: 0.6239\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7933 - accuracy: 0.7000 - val_loss: 0.9272 - val_accuracy: 0.5812\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.7035 - accuracy: 0.7148 - val_loss: 1.1858 - val_accuracy: 0.6068\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8356 - accuracy: 0.7148 - val_loss: 1.0323 - val_accuracy: 0.6239\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7338 - accuracy: 0.7074 - val_loss: 1.1338 - val_accuracy: 0.5983\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8285 - accuracy: 0.7148 - val_loss: 1.0781 - val_accuracy: 0.6239\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7982 - accuracy: 0.7259 - val_loss: 0.9980 - val_accuracy: 0.6410\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6660 - accuracy: 0.7370 - val_loss: 1.0720 - val_accuracy: 0.5897\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7529 - accuracy: 0.6889 - val_loss: 0.9575 - val_accuracy: 0.6239\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7539 - accuracy: 0.7259 - val_loss: 0.9858 - val_accuracy: 0.6325\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6947 - accuracy: 0.7222 - val_loss: 0.8903 - val_accuracy: 0.6068\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6900 - accuracy: 0.7074 - val_loss: 0.9934 - val_accuracy: 0.6496\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7365 - accuracy: 0.7185 - val_loss: 0.9047 - val_accuracy: 0.6325\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6775 - accuracy: 0.7185 - val_loss: 0.9939 - val_accuracy: 0.5726\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7313 - accuracy: 0.7111 - val_loss: 1.1513 - val_accuracy: 0.6154\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8468 - accuracy: 0.7074 - val_loss: 1.1854 - val_accuracy: 0.6239\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7698 - accuracy: 0.7259 - val_loss: 0.8586 - val_accuracy: 0.5983\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8064 - accuracy: 0.6963 - val_loss: 1.1802 - val_accuracy: 0.6154\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.4071 - accuracy: 0.6852 - val_loss: 2.9833 - val_accuracy: 0.5812\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 1.9698 - accuracy: 0.7037 - val_loss: 3.1473 - val_accuracy: 0.5556\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.8547 - accuracy: 0.6778 - val_loss: 2.3571 - val_accuracy: 0.6154\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.3451 - accuracy: 0.6889 - val_loss: 1.2026 - val_accuracy: 0.5812\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8062 - accuracy: 0.6593 - val_loss: 0.9422 - val_accuracy: 0.5214\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7950 - accuracy: 0.6296 - val_loss: 0.9923 - val_accuracy: 0.5641\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7875 - accuracy: 0.6815 - val_loss: 1.0061 - val_accuracy: 0.6154\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7546 - accuracy: 0.6889 - val_loss: 0.9017 - val_accuracy: 0.5983\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7668 - accuracy: 0.6593 - val_loss: 0.9329 - val_accuracy: 0.6068\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8076 - accuracy: 0.6815 - val_loss: 1.0115 - val_accuracy: 0.6068\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7302 - accuracy: 0.6926 - val_loss: 0.9105 - val_accuracy: 0.5641\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7036 - accuracy: 0.6926 - val_loss: 0.9136 - val_accuracy: 0.6325\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7305 - accuracy: 0.7111 - val_loss: 0.9224 - val_accuracy: 0.6239\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.6860 - accuracy: 0.7037 - val_loss: 0.9113 - val_accuracy: 0.6068\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 432us/step - loss: 0.6961 - accuracy: 0.7148 - val_loss: 0.8810 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7001 - accuracy: 0.7111 - val_loss: 0.8540 - val_accuracy: 0.5983\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6835 - accuracy: 0.7222 - val_loss: 0.8905 - val_accuracy: 0.5983\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6846 - accuracy: 0.7259 - val_loss: 0.8480 - val_accuracy: 0.6410\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6704 - accuracy: 0.7148 - val_loss: 0.8427 - val_accuracy: 0.6410\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7168 - accuracy: 0.7037 - val_loss: 0.8776 - val_accuracy: 0.6325\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6802 - accuracy: 0.7111 - val_loss: 0.9074 - val_accuracy: 0.5983\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6820 - accuracy: 0.7370 - val_loss: 0.9039 - val_accuracy: 0.6325\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7513 - accuracy: 0.6889 - val_loss: 0.8637 - val_accuracy: 0.6239\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7592 - accuracy: 0.7148 - val_loss: 1.0139 - val_accuracy: 0.6068\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9904 - accuracy: 0.6593 - val_loss: 2.0467 - val_accuracy: 0.6068\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.3679 - accuracy: 0.6852 - val_loss: 2.0716 - val_accuracy: 0.6068\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 1.2158 - accuracy: 0.7037 - val_loss: 1.3978 - val_accuracy: 0.6325\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9038 - accuracy: 0.6889 - val_loss: 0.9241 - val_accuracy: 0.5385\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7698 - accuracy: 0.6852 - val_loss: 1.1722 - val_accuracy: 0.6410\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8019 - accuracy: 0.7185 - val_loss: 0.9419 - val_accuracy: 0.6325\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7207 - accuracy: 0.7111 - val_loss: 0.9930 - val_accuracy: 0.6154\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7305 - accuracy: 0.6889 - val_loss: 0.9972 - val_accuracy: 0.6496\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7595 - accuracy: 0.7185 - val_loss: 0.9975 - val_accuracy: 0.6410\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7035 - accuracy: 0.7185 - val_loss: 0.8833 - val_accuracy: 0.5897\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7227 - accuracy: 0.6852 - val_loss: 0.9888 - val_accuracy: 0.6239\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7728 - accuracy: 0.7222 - val_loss: 1.0614 - val_accuracy: 0.6581\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7387 - accuracy: 0.7222 - val_loss: 0.8854 - val_accuracy: 0.5983\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7104 - accuracy: 0.6889 - val_loss: 0.9805 - val_accuracy: 0.6239\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7486 - accuracy: 0.7222 - val_loss: 1.0014 - val_accuracy: 0.6325\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7050 - accuracy: 0.7074 - val_loss: 0.8772 - val_accuracy: 0.6068\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6898 - accuracy: 0.7185 - val_loss: 0.8568 - val_accuracy: 0.6325\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6764 - accuracy: 0.7222 - val_loss: 0.8594 - val_accuracy: 0.6154\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6743 - accuracy: 0.7333 - val_loss: 0.8934 - val_accuracy: 0.6154\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6806 - accuracy: 0.7333 - val_loss: 0.8496 - val_accuracy: 0.6239\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6830 - accuracy: 0.7259 - val_loss: 0.8568 - val_accuracy: 0.6154\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7076 - accuracy: 0.6926 - val_loss: 0.8570 - val_accuracy: 0.6325\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7023 - accuracy: 0.7074 - val_loss: 0.8629 - val_accuracy: 0.6068\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6877 - accuracy: 0.7148 - val_loss: 0.8895 - val_accuracy: 0.6154\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6955 - accuracy: 0.7148 - val_loss: 0.8839 - val_accuracy: 0.6325\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6884 - accuracy: 0.7148 - val_loss: 0.9523 - val_accuracy: 0.6410\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7753 - accuracy: 0.7259 - val_loss: 0.9869 - val_accuracy: 0.6496\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6810 - accuracy: 0.7222 - val_loss: 0.8847 - val_accuracy: 0.6068\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6829 - accuracy: 0.7222 - val_loss: 0.9241 - val_accuracy: 0.6410\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7162 - accuracy: 0.7370 - val_loss: 0.8617 - val_accuracy: 0.6154\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 664us/step - loss: 0.6783 - accuracy: 0.7222 - val_loss: 0.8697 - val_accuracy: 0.6154\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6880 - accuracy: 0.7148 - val_loss: 0.8939 - val_accuracy: 0.6325\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7147 - accuracy: 0.7259 - val_loss: 0.9786 - val_accuracy: 0.6325\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6985 - accuracy: 0.7296 - val_loss: 0.9068 - val_accuracy: 0.5983\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6955 - accuracy: 0.7185 - val_loss: 0.8865 - val_accuracy: 0.6325\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7063 - accuracy: 0.7407 - val_loss: 0.8460 - val_accuracy: 0.6154\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7810 - accuracy: 0.6926 - val_loss: 0.8479 - val_accuracy: 0.6154\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6993 - accuracy: 0.7000 - val_loss: 0.8637 - val_accuracy: 0.6325\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6810 - accuracy: 0.7222 - val_loss: 0.8708 - val_accuracy: 0.6410\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7376 - accuracy: 0.7185 - val_loss: 1.2652 - val_accuracy: 0.6239\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8497 - accuracy: 0.7111 - val_loss: 0.9582 - val_accuracy: 0.6496\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8035 - accuracy: 0.6815 - val_loss: 0.8624 - val_accuracy: 0.6239\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7040 - accuracy: 0.7259 - val_loss: 1.0307 - val_accuracy: 0.6410\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7312 - accuracy: 0.7185 - val_loss: 0.8417 - val_accuracy: 0.6581\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6884 - accuracy: 0.7259 - val_loss: 0.8617 - val_accuracy: 0.6239\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6877 - accuracy: 0.7407 - val_loss: 0.8905 - val_accuracy: 0.6239\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7093 - accuracy: 0.7074 - val_loss: 0.8562 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6710 - accuracy: 0.7407 - val_loss: 0.8901 - val_accuracy: 0.6410\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6781 - accuracy: 0.7148 - val_loss: 0.8490 - val_accuracy: 0.6154\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6588 - accuracy: 0.7556 - val_loss: 0.8628 - val_accuracy: 0.6410\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6620 - accuracy: 0.7370 - val_loss: 0.8562 - val_accuracy: 0.6496\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6677 - accuracy: 0.7296 - val_loss: 0.8846 - val_accuracy: 0.6239\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6712 - accuracy: 0.7259 - val_loss: 0.8836 - val_accuracy: 0.6325\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8028 - accuracy: 0.7185 - val_loss: 1.1122 - val_accuracy: 0.6410\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7645 - accuracy: 0.7296 - val_loss: 1.0499 - val_accuracy: 0.5897\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7654 - accuracy: 0.6963 - val_loss: 1.0326 - val_accuracy: 0.6239\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8488 - accuracy: 0.7222 - val_loss: 1.2573 - val_accuracy: 0.6410\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7475 - accuracy: 0.7111 - val_loss: 0.9141 - val_accuracy: 0.6068\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8682 - accuracy: 0.6741 - val_loss: 0.8859 - val_accuracy: 0.6325\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7438 - accuracy: 0.7222 - val_loss: 1.0100 - val_accuracy: 0.6325\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7015 - accuracy: 0.7222 - val_loss: 0.9759 - val_accuracy: 0.6068\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6975 - accuracy: 0.7370 - val_loss: 1.0540 - val_accuracy: 0.6239\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7725 - accuracy: 0.7000 - val_loss: 0.9266 - val_accuracy: 0.6410\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6740 - accuracy: 0.7111 - val_loss: 1.1288 - val_accuracy: 0.5726\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8489 - accuracy: 0.6926 - val_loss: 1.1806 - val_accuracy: 0.5726\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9273 - accuracy: 0.6556 - val_loss: 1.0176 - val_accuracy: 0.6239\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7563 - accuracy: 0.7037 - val_loss: 0.9480 - val_accuracy: 0.6068\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7651 - accuracy: 0.6889 - val_loss: 1.1270 - val_accuracy: 0.6154\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8242 - accuracy: 0.7259 - val_loss: 1.1008 - val_accuracy: 0.6239\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7414 - accuracy: 0.7333 - val_loss: 0.8816 - val_accuracy: 0.5897\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7475 - accuracy: 0.6852 - val_loss: 0.8785 - val_accuracy: 0.5983\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7012 - accuracy: 0.7370 - val_loss: 0.9196 - val_accuracy: 0.6154\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7213 - accuracy: 0.7000 - val_loss: 0.8510 - val_accuracy: 0.6410\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6770 - accuracy: 0.7370 - val_loss: 0.8599 - val_accuracy: 0.6068\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6722 - accuracy: 0.7407 - val_loss: 0.8431 - val_accuracy: 0.6154\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6982 - accuracy: 0.7296 - val_loss: 0.8338 - val_accuracy: 0.6154\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8020 - accuracy: 0.7000 - val_loss: 0.8578 - val_accuracy: 0.6239\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7225 - accuracy: 0.7111 - val_loss: 1.1231 - val_accuracy: 0.6068\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7497 - accuracy: 0.7111 - val_loss: 0.8548 - val_accuracy: 0.6239\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7203 - accuracy: 0.7037 - val_loss: 0.8613 - val_accuracy: 0.6154\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7066 - accuracy: 0.7185 - val_loss: 0.9942 - val_accuracy: 0.6068\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7893 - accuracy: 0.6889 - val_loss: 0.9089 - val_accuracy: 0.5812\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7831 - accuracy: 0.6889 - val_loss: 0.9363 - val_accuracy: 0.5812\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7007 - accuracy: 0.7148 - val_loss: 0.8606 - val_accuracy: 0.6410\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6788 - accuracy: 0.7296 - val_loss: 0.8603 - val_accuracy: 0.6410\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6863 - accuracy: 0.7444 - val_loss: 0.8421 - val_accuracy: 0.6667\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6968 - accuracy: 0.7074 - val_loss: 0.8651 - val_accuracy: 0.6581\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6605 - accuracy: 0.7444 - val_loss: 0.9218 - val_accuracy: 0.6154\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7887 - accuracy: 0.6815 - val_loss: 0.8772 - val_accuracy: 0.6068\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7321 - accuracy: 0.7185 - val_loss: 0.8531 - val_accuracy: 0.6325\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8351 - accuracy: 0.6630 - val_loss: 1.0305 - val_accuracy: 0.5812\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8435 - accuracy: 0.6667 - val_loss: 1.6449 - val_accuracy: 0.5556\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8573 - accuracy: 0.7037 - val_loss: 1.0560 - val_accuracy: 0.5897\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8689 - accuracy: 0.6630 - val_loss: 1.1294 - val_accuracy: 0.5983\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8527 - accuracy: 0.6926 - val_loss: 0.9744 - val_accuracy: 0.6239\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8242 - accuracy: 0.6815 - val_loss: 0.8468 - val_accuracy: 0.6325\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7491 - accuracy: 0.6889 - val_loss: 0.8525 - val_accuracy: 0.6325\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7384 - accuracy: 0.7000 - val_loss: 0.8716 - val_accuracy: 0.6496\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6791 - accuracy: 0.7407 - val_loss: 0.8899 - val_accuracy: 0.6239\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6810 - accuracy: 0.7259 - val_loss: 0.8860 - val_accuracy: 0.6154\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7591 - accuracy: 0.7148 - val_loss: 0.9128 - val_accuracy: 0.6496\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6834 - accuracy: 0.7556 - val_loss: 0.9639 - val_accuracy: 0.6154\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7469 - accuracy: 0.7259 - val_loss: 1.0633 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7235 - accuracy: 0.7370 - val_loss: 0.9291 - val_accuracy: 0.6068\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.75 - 0s 68us/step - loss: 0.6777 - accuracy: 0.7407 - val_loss: 0.8761 - val_accuracy: 0.6239\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7484 - accuracy: 0.6926 - val_loss: 0.8454 - val_accuracy: 0.6581\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6967 - accuracy: 0.7259 - val_loss: 0.9924 - val_accuracy: 0.5641\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6831 - accuracy: 0.7370 - val_loss: 0.8694 - val_accuracy: 0.6154\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6982 - accuracy: 0.6963 - val_loss: 0.8930 - val_accuracy: 0.6154\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7362 - accuracy: 0.7074 - val_loss: 1.0554 - val_accuracy: 0.5897\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7859 - accuracy: 0.6889 - val_loss: 0.9841 - val_accuracy: 0.5983\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7075 - accuracy: 0.7148 - val_loss: 0.8600 - val_accuracy: 0.6239\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7093 - accuracy: 0.7037 - val_loss: 0.8389 - val_accuracy: 0.6496\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6632 - accuracy: 0.7407 - val_loss: 0.8646 - val_accuracy: 0.6239\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8378 - accuracy: 0.6778 - val_loss: 0.8840 - val_accuracy: 0.5726\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8030 - accuracy: 0.7074 - val_loss: 0.9729 - val_accuracy: 0.6154\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7164 - accuracy: 0.7222 - val_loss: 1.0380 - val_accuracy: 0.6581\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7543 - accuracy: 0.7148 - val_loss: 0.8660 - val_accuracy: 0.6154\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7252 - accuracy: 0.7259 - val_loss: 0.8880 - val_accuracy: 0.5983\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8251 - accuracy: 0.6704 - val_loss: 0.9546 - val_accuracy: 0.6496\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.0533 - accuracy: 0.6704 - val_loss: 0.8696 - val_accuracy: 0.6496\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0683 - accuracy: 0.6593 - val_loss: 1.1751 - val_accuracy: 0.5470\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9638 - accuracy: 0.6667 - val_loss: 1.4063 - val_accuracy: 0.5556\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9392 - accuracy: 0.7074 - val_loss: 1.1333 - val_accuracy: 0.5812\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.2550 - accuracy: 0.6259 - val_loss: 0.9514 - val_accuracy: 0.5556\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8241 - accuracy: 0.6926 - val_loss: 0.9073 - val_accuracy: 0.6068\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.4029 - accuracy: 0.6519 - val_loss: 1.9461 - val_accuracy: 0.5726\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.8876 - accuracy: 0.6296 - val_loss: 0.9963 - val_accuracy: 0.5812\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9341 - accuracy: 0.6630 - val_loss: 1.0211 - val_accuracy: 0.5812\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8665 - accuracy: 0.6889 - val_loss: 1.2621 - val_accuracy: 0.6068\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0354 - accuracy: 0.6630 - val_loss: 1.0532 - val_accuracy: 0.6068\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8562 - accuracy: 0.6667 - val_loss: 0.8513 - val_accuracy: 0.6581\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8195 - accuracy: 0.6926 - val_loss: 0.8633 - val_accuracy: 0.6410\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7866 - accuracy: 0.6667 - val_loss: 1.0342 - val_accuracy: 0.6410\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8810 - accuracy: 0.6926 - val_loss: 1.0447 - val_accuracy: 0.5983\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7595 - accuracy: 0.6963 - val_loss: 1.1125 - val_accuracy: 0.5726\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8190 - accuracy: 0.6519 - val_loss: 1.0173 - val_accuracy: 0.6581\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8751 - accuracy: 0.6630 - val_loss: 0.8630 - val_accuracy: 0.6667\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8854 - accuracy: 0.6852 - val_loss: 0.9973 - val_accuracy: 0.5897\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7226 - accuracy: 0.7148 - val_loss: 1.1299 - val_accuracy: 0.5897\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8678 - accuracy: 0.6926 - val_loss: 1.0050 - val_accuracy: 0.6496\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7050 - accuracy: 0.6926 - val_loss: 0.9946 - val_accuracy: 0.5983\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7323 - accuracy: 0.7148 - val_loss: 0.9406 - val_accuracy: 0.6239\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7283 - accuracy: 0.7370 - val_loss: 0.9382 - val_accuracy: 0.6325\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6784 - accuracy: 0.7296 - val_loss: 0.9506 - val_accuracy: 0.5897\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6996 - accuracy: 0.7296 - val_loss: 0.9312 - val_accuracy: 0.5983\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7205 - accuracy: 0.7037 - val_loss: 0.8687 - val_accuracy: 0.6154\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8499 - accuracy: 0.7074 - val_loss: 0.9307 - val_accuracy: 0.5897\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7481 - accuracy: 0.7148 - val_loss: 1.1317 - val_accuracy: 0.6410\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7877 - accuracy: 0.7222 - val_loss: 0.8865 - val_accuracy: 0.6410\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7412 - accuracy: 0.7185 - val_loss: 0.9050 - val_accuracy: 0.5897\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7342 - accuracy: 0.7148 - val_loss: 1.0466 - val_accuracy: 0.6410\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7375 - accuracy: 0.7259 - val_loss: 0.8674 - val_accuracy: 0.6068\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8518 - accuracy: 0.7185 - val_loss: 0.8575 - val_accuracy: 0.6239\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6984 - accuracy: 0.7148 - val_loss: 1.1473 - val_accuracy: 0.6068\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8091 - accuracy: 0.7111 - val_loss: 0.9904 - val_accuracy: 0.6410\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6684 - accuracy: 0.7370 - val_loss: 1.0453 - val_accuracy: 0.6239\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7414 - accuracy: 0.6852 - val_loss: 1.1140 - val_accuracy: 0.6496\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8240 - accuracy: 0.7148 - val_loss: 1.1974 - val_accuracy: 0.6325\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7820 - accuracy: 0.7296 - val_loss: 0.8580 - val_accuracy: 0.6239\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6880 - accuracy: 0.6963 - val_loss: 0.8558 - val_accuracy: 0.6325\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6983 - accuracy: 0.7333 - val_loss: 1.0216 - val_accuracy: 0.6410\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7231 - accuracy: 0.7296 - val_loss: 0.8539 - val_accuracy: 0.6154\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6615 - accuracy: 0.7370 - val_loss: 0.8906 - val_accuracy: 0.6154\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6688 - accuracy: 0.7444 - val_loss: 0.8443 - val_accuracy: 0.6581\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6707 - accuracy: 0.7259 - val_loss: 0.8569 - val_accuracy: 0.6410\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6597 - accuracy: 0.7444 - val_loss: 0.8865 - val_accuracy: 0.6325\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6600 - accuracy: 0.7370 - val_loss: 0.8472 - val_accuracy: 0.5983\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6655 - accuracy: 0.7333 - val_loss: 0.8757 - val_accuracy: 0.6154\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7382 - accuracy: 0.7037 - val_loss: 0.9395 - val_accuracy: 0.6239\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6889 - accuracy: 0.7222 - val_loss: 0.9430 - val_accuracy: 0.6068\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6687 - accuracy: 0.7333 - val_loss: 0.9306 - val_accuracy: 0.6239\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7643 - accuracy: 0.7370 - val_loss: 1.2277 - val_accuracy: 0.6325\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7877 - accuracy: 0.7259 - val_loss: 0.9114 - val_accuracy: 0.6410\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6842 - accuracy: 0.7185 - val_loss: 0.8747 - val_accuracy: 0.6154\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6528 - accuracy: 0.7407 - val_loss: 0.8599 - val_accuracy: 0.6239\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6500 - accuracy: 0.7556 - val_loss: 0.8865 - val_accuracy: 0.5897\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6556 - accuracy: 0.7481 - val_loss: 0.8559 - val_accuracy: 0.6325\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6782 - accuracy: 0.7037 - val_loss: 0.8682 - val_accuracy: 0.5983\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6608 - accuracy: 0.7444 - val_loss: 0.9291 - val_accuracy: 0.5812\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6670 - accuracy: 0.7296 - val_loss: 0.8695 - val_accuracy: 0.6239\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6927 - accuracy: 0.6963 - val_loss: 0.8417 - val_accuracy: 0.6496\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6607 - accuracy: 0.7333 - val_loss: 0.8481 - val_accuracy: 0.6752\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6478 - accuracy: 0.7519 - val_loss: 0.8379 - val_accuracy: 0.6325\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6514 - accuracy: 0.7407 - val_loss: 0.8389 - val_accuracy: 0.6239\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6522 - accuracy: 0.7481 - val_loss: 0.8504 - val_accuracy: 0.5983\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6462 - accuracy: 0.7481 - val_loss: 0.8419 - val_accuracy: 0.6239\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6619 - accuracy: 0.7259 - val_loss: 0.8517 - val_accuracy: 0.6154\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6449 - accuracy: 0.7593 - val_loss: 0.8512 - val_accuracy: 0.6325\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.6456 - accuracy: 0.7481 - val_loss: 0.8505 - val_accuracy: 0.6581\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6531 - accuracy: 0.7407 - val_loss: 0.8525 - val_accuracy: 0.6154\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6555 - accuracy: 0.7519 - val_loss: 0.8602 - val_accuracy: 0.6068\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6679 - accuracy: 0.7444 - val_loss: 0.8796 - val_accuracy: 0.6154\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6609 - accuracy: 0.7333 - val_loss: 0.9876 - val_accuracy: 0.5983\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6883 - accuracy: 0.7407 - val_loss: 0.9492 - val_accuracy: 0.6068\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6829 - accuracy: 0.7370 - val_loss: 0.8546 - val_accuracy: 0.6154\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6898 - accuracy: 0.7296 - val_loss: 0.9376 - val_accuracy: 0.5897\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7147 - accuracy: 0.7148 - val_loss: 1.0111 - val_accuracy: 0.5726\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7014 - accuracy: 0.7333 - val_loss: 0.8643 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6550 - accuracy: 0.7407 - val_loss: 0.8826 - val_accuracy: 0.5983\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6594 - accuracy: 0.7444 - val_loss: 0.8676 - val_accuracy: 0.6154\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6468 - accuracy: 0.7407 - val_loss: 0.8741 - val_accuracy: 0.5983\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6477 - accuracy: 0.7593 - val_loss: 0.8888 - val_accuracy: 0.6154\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6460 - accuracy: 0.7444 - val_loss: 0.8723 - val_accuracy: 0.6154\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6515 - accuracy: 0.7407 - val_loss: 0.8681 - val_accuracy: 0.6154\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6412 - accuracy: 0.7556 - val_loss: 0.8833 - val_accuracy: 0.6325\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6424 - accuracy: 0.7481 - val_loss: 0.8487 - val_accuracy: 0.6239\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 348us/step - loss: 0.6593 - accuracy: 0.7222 - val_loss: 0.8748 - val_accuracy: 0.6154\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7095 - accuracy: 0.7222 - val_loss: 1.0889 - val_accuracy: 0.6239\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7349 - accuracy: 0.7296 - val_loss: 0.8848 - val_accuracy: 0.6068\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6815 - accuracy: 0.7407 - val_loss: 0.8900 - val_accuracy: 0.6154\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6704 - accuracy: 0.7333 - val_loss: 0.9283 - val_accuracy: 0.5812\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6693 - accuracy: 0.7259 - val_loss: 0.8608 - val_accuracy: 0.6325\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6662 - accuracy: 0.7259 - val_loss: 0.9920 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 526us/step - loss: 0.7100 - accuracy: 0.7222 - val_loss: 0.9126 - val_accuracy: 0.5812\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6734 - accuracy: 0.7333 - val_loss: 0.8598 - val_accuracy: 0.6325\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6442 - accuracy: 0.7444 - val_loss: 0.8913 - val_accuracy: 0.5897\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6481 - accuracy: 0.7407 - val_loss: 0.8424 - val_accuracy: 0.6325\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6523 - accuracy: 0.7185 - val_loss: 0.8602 - val_accuracy: 0.6154\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6471 - accuracy: 0.7519 - val_loss: 0.8566 - val_accuracy: 0.5983\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6453 - accuracy: 0.7407 - val_loss: 0.8662 - val_accuracy: 0.5983\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6451 - accuracy: 0.7593 - val_loss: 0.8819 - val_accuracy: 0.6154\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6492 - accuracy: 0.7444 - val_loss: 0.8547 - val_accuracy: 0.6325\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6695 - accuracy: 0.7037 - val_loss: 0.8638 - val_accuracy: 0.6068\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6560 - accuracy: 0.7333 - val_loss: 0.8860 - val_accuracy: 0.6154\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6687 - accuracy: 0.7296 - val_loss: 0.9310 - val_accuracy: 0.6325\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6668 - accuracy: 0.7333 - val_loss: 0.9795 - val_accuracy: 0.5983\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7079 - accuracy: 0.7444 - val_loss: 1.0301 - val_accuracy: 0.6154\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7099 - accuracy: 0.7185 - val_loss: 0.8969 - val_accuracy: 0.6068\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6571 - accuracy: 0.7481 - val_loss: 0.8713 - val_accuracy: 0.6068\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6534 - accuracy: 0.7519 - val_loss: 0.8946 - val_accuracy: 0.6239\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6520 - accuracy: 0.7370 - val_loss: 0.8927 - val_accuracy: 0.5983\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6461 - accuracy: 0.7407 - val_loss: 0.9056 - val_accuracy: 0.6239\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6730 - accuracy: 0.7444 - val_loss: 0.8623 - val_accuracy: 0.6325\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6467 - accuracy: 0.7370 - val_loss: 0.8871 - val_accuracy: 0.6239\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6546 - accuracy: 0.7407 - val_loss: 0.8892 - val_accuracy: 0.6239\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6687 - accuracy: 0.7259 - val_loss: 0.8595 - val_accuracy: 0.5983\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6675 - accuracy: 0.7444 - val_loss: 0.8506 - val_accuracy: 0.6154\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6822 - accuracy: 0.7185 - val_loss: 0.8890 - val_accuracy: 0.5983\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6800 - accuracy: 0.7074 - val_loss: 0.9057 - val_accuracy: 0.5983\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6728 - accuracy: 0.7259 - val_loss: 0.8910 - val_accuracy: 0.6068\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6783 - accuracy: 0.7000 - val_loss: 0.8790 - val_accuracy: 0.6068\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6697 - accuracy: 0.7370 - val_loss: 0.8961 - val_accuracy: 0.6325\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7488 - accuracy: 0.7074 - val_loss: 0.8541 - val_accuracy: 0.6154\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6591 - accuracy: 0.7333 - val_loss: 0.9607 - val_accuracy: 0.6154\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6547 - accuracy: 0.7444 - val_loss: 0.9597 - val_accuracy: 0.5897\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6715 - accuracy: 0.7296 - val_loss: 0.9862 - val_accuracy: 0.6239\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7230 - accuracy: 0.7259 - val_loss: 0.9517 - val_accuracy: 0.6410\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6751 - accuracy: 0.7296 - val_loss: 0.9141 - val_accuracy: 0.6239\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6585 - accuracy: 0.7370 - val_loss: 0.9194 - val_accuracy: 0.6239\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6815 - accuracy: 0.7333 - val_loss: 0.8590 - val_accuracy: 0.6068\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6621 - accuracy: 0.7444 - val_loss: 0.8605 - val_accuracy: 0.6154\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6384 - accuracy: 0.7519 - val_loss: 0.8545 - val_accuracy: 0.6410\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6431 - accuracy: 0.7407 - val_loss: 0.9029 - val_accuracy: 0.6325\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6584 - accuracy: 0.7519 - val_loss: 0.8870 - val_accuracy: 0.6154\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6766 - accuracy: 0.7185 - val_loss: 0.8549 - val_accuracy: 0.6410\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6570 - accuracy: 0.7556 - val_loss: 0.8911 - val_accuracy: 0.6325\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6988 - accuracy: 0.7333 - val_loss: 0.8869 - val_accuracy: 0.6410\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6928 - accuracy: 0.7259 - val_loss: 0.8866 - val_accuracy: 0.5983\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6808 - accuracy: 0.7370 - val_loss: 0.9014 - val_accuracy: 0.6154\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7219 - accuracy: 0.7074 - val_loss: 1.0714 - val_accuracy: 0.6154\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0834 - accuracy: 0.7074 - val_loss: 2.4982 - val_accuracy: 0.6239\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.6930 - accuracy: 0.7074 - val_loss: 2.7502 - val_accuracy: 0.6154\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.6231 - accuracy: 0.7037 - val_loss: 2.2064 - val_accuracy: 0.6154\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.1862 - accuracy: 0.7000 - val_loss: 1.3060 - val_accuracy: 0.5983\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7523 - accuracy: 0.6556 - val_loss: 1.4023 - val_accuracy: 0.4530\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.9847 - accuracy: 0.5963 - val_loss: 1.0181 - val_accuracy: 0.5983\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7731 - accuracy: 0.7074 - val_loss: 1.0416 - val_accuracy: 0.6154\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6683 - accuracy: 0.7333 - val_loss: 0.9864 - val_accuracy: 0.5897\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7194 - accuracy: 0.6926 - val_loss: 0.9894 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7472 - accuracy: 0.7370 - val_loss: 0.9950 - val_accuracy: 0.6154\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7055 - accuracy: 0.6963 - val_loss: 0.9543 - val_accuracy: 0.5983\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6760 - accuracy: 0.7259 - val_loss: 0.8924 - val_accuracy: 0.5812\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7677 - accuracy: 0.6815 - val_loss: 0.9077 - val_accuracy: 0.6410\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6659 - accuracy: 0.7370 - val_loss: 0.9374 - val_accuracy: 0.5983\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7302 - accuracy: 0.7037 - val_loss: 1.0683 - val_accuracy: 0.5726\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8619 - accuracy: 0.7074 - val_loss: 1.2217 - val_accuracy: 0.6154\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8130 - accuracy: 0.6852 - val_loss: 0.9063 - val_accuracy: 0.5983\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7379 - accuracy: 0.6778 - val_loss: 0.9017 - val_accuracy: 0.5983\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6617 - accuracy: 0.7407 - val_loss: 1.2205 - val_accuracy: 0.5726\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7860 - accuracy: 0.6963 - val_loss: 0.8940 - val_accuracy: 0.6068\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6978 - accuracy: 0.7259 - val_loss: 0.9231 - val_accuracy: 0.5897\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6578 - accuracy: 0.7444 - val_loss: 0.8738 - val_accuracy: 0.6496\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.6650 - accuracy: 0.7148 - val_loss: 0.8562 - val_accuracy: 0.6068\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6488 - accuracy: 0.7481 - val_loss: 0.8588 - val_accuracy: 0.6325\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6525 - accuracy: 0.7407 - val_loss: 0.8469 - val_accuracy: 0.6239\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6702 - accuracy: 0.7222 - val_loss: 0.8750 - val_accuracy: 0.6068\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6647 - accuracy: 0.7259 - val_loss: 0.9032 - val_accuracy: 0.6410\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6893 - accuracy: 0.7407 - val_loss: 0.9187 - val_accuracy: 0.6410\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8035 - accuracy: 0.7296 - val_loss: 1.6702 - val_accuracy: 0.5983\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0931 - accuracy: 0.7000 - val_loss: 1.5604 - val_accuracy: 0.6325\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8628 - accuracy: 0.7222 - val_loss: 0.9310 - val_accuracy: 0.5726\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7890 - accuracy: 0.6926 - val_loss: 0.8818 - val_accuracy: 0.5983\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6543 - accuracy: 0.7481 - val_loss: 1.0365 - val_accuracy: 0.6325\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6999 - accuracy: 0.7370 - val_loss: 0.8672 - val_accuracy: 0.6325\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6781 - accuracy: 0.7148 - val_loss: 0.8668 - val_accuracy: 0.6154\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6714 - accuracy: 0.7444 - val_loss: 0.9003 - val_accuracy: 0.6239\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6722 - accuracy: 0.7222 - val_loss: 0.8723 - val_accuracy: 0.6325\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7966 - accuracy: 0.7259 - val_loss: 1.2967 - val_accuracy: 0.6410\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8404 - accuracy: 0.7370 - val_loss: 1.0367 - val_accuracy: 0.6410\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6532 - accuracy: 0.7519 - val_loss: 0.9179 - val_accuracy: 0.6068\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6766 - accuracy: 0.7111 - val_loss: 0.8937 - val_accuracy: 0.6154\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6803 - accuracy: 0.7370 - val_loss: 0.8938 - val_accuracy: 0.6239\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6351 - accuracy: 0.7370 - val_loss: 0.9154 - val_accuracy: 0.6068\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6529 - accuracy: 0.7370 - val_loss: 0.8771 - val_accuracy: 0.6068\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6447 - accuracy: 0.7407 - val_loss: 0.8544 - val_accuracy: 0.6410\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6476 - accuracy: 0.7259 - val_loss: 0.8963 - val_accuracy: 0.5983\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6426 - accuracy: 0.7556 - val_loss: 0.8631 - val_accuracy: 0.6239\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6381 - accuracy: 0.7444 - val_loss: 0.8668 - val_accuracy: 0.6154\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6385 - accuracy: 0.7444 - val_loss: 0.8618 - val_accuracy: 0.6239\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6403 - accuracy: 0.7593 - val_loss: 0.8631 - val_accuracy: 0.6325\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6687 - accuracy: 0.7296 - val_loss: 1.0384 - val_accuracy: 0.6325\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7048 - accuracy: 0.7296 - val_loss: 0.8868 - val_accuracy: 0.6410\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6455 - accuracy: 0.7444 - val_loss: 0.8814 - val_accuracy: 0.6068\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6395 - accuracy: 0.7556 - val_loss: 0.8918 - val_accuracy: 0.5897\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6476 - accuracy: 0.7407 - val_loss: 0.8535 - val_accuracy: 0.6325\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6511 - accuracy: 0.7074 - val_loss: 0.8583 - val_accuracy: 0.6154\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 427us/step - loss: 0.6521 - accuracy: 0.7481 - val_loss: 0.9288 - val_accuracy: 0.5726\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8069 - accuracy: 0.6593 - val_loss: 0.8875 - val_accuracy: 0.5983\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6999 - accuracy: 0.7407 - val_loss: 0.8736 - val_accuracy: 0.6068\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6887 - accuracy: 0.7148 - val_loss: 0.8861 - val_accuracy: 0.6239\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.6700 - accuracy: 0.7259 - val_loss: 0.8614 - val_accuracy: 0.6154\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6783 - accuracy: 0.7333 - val_loss: 0.8718 - val_accuracy: 0.6154\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6568 - accuracy: 0.7481 - val_loss: 1.1541 - val_accuracy: 0.5470\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7839 - accuracy: 0.6889 - val_loss: 0.9116 - val_accuracy: 0.5897\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7666 - accuracy: 0.6963 - val_loss: 1.4355 - val_accuracy: 0.5470\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8135 - accuracy: 0.6926 - val_loss: 1.3386 - val_accuracy: 0.5641\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.5706 - accuracy: 0.6296 - val_loss: 1.0634 - val_accuracy: 0.5556\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.1589 - accuracy: 0.6667 - val_loss: 0.9222 - val_accuracy: 0.6068\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.7758 - accuracy: 0.6667 - val_loss: 2.3865 - val_accuracy: 0.5556\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 2.7442 - accuracy: 0.6333 - val_loss: 1.6527 - val_accuracy: 0.5556\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.3788 - accuracy: 0.6407 - val_loss: 2.8664 - val_accuracy: 0.5385\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.9390 - accuracy: 0.6259 - val_loss: 1.0150 - val_accuracy: 0.5556\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.8214 - accuracy: 0.6333 - val_loss: 1.7664 - val_accuracy: 0.5556\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.6097 - accuracy: 0.6481 - val_loss: 0.9157 - val_accuracy: 0.5641\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 1.1755 - accuracy: 0.6481 - val_loss: 0.9162 - val_accuracy: 0.5897\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7352 - accuracy: 0.6852 - val_loss: 0.9328 - val_accuracy: 0.5897\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7885 - accuracy: 0.7074 - val_loss: 0.8947 - val_accuracy: 0.5897\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7754 - accuracy: 0.6556 - val_loss: 0.9377 - val_accuracy: 0.5726\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6875 - accuracy: 0.7074 - val_loss: 0.8724 - val_accuracy: 0.6325\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6741 - accuracy: 0.7185 - val_loss: 0.8730 - val_accuracy: 0.6239\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6927 - accuracy: 0.7074 - val_loss: 0.8749 - val_accuracy: 0.6239\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6556 - accuracy: 0.7333 - val_loss: 0.8635 - val_accuracy: 0.6410\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6551 - accuracy: 0.7333 - val_loss: 0.8874 - val_accuracy: 0.6325\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6498 - accuracy: 0.7407 - val_loss: 0.8784 - val_accuracy: 0.6154\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6541 - accuracy: 0.7370 - val_loss: 0.8782 - val_accuracy: 0.5983\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6502 - accuracy: 0.7333 - val_loss: 0.8764 - val_accuracy: 0.6154\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6404 - accuracy: 0.7444 - val_loss: 0.8442 - val_accuracy: 0.6410\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6375 - accuracy: 0.7333 - val_loss: 0.8695 - val_accuracy: 0.6154\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6460 - accuracy: 0.7444 - val_loss: 0.8691 - val_accuracy: 0.6154\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6402 - accuracy: 0.7444 - val_loss: 0.8520 - val_accuracy: 0.6325\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6538 - accuracy: 0.7370 - val_loss: 0.8545 - val_accuracy: 0.6239\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6580 - accuracy: 0.7407 - val_loss: 0.9707 - val_accuracy: 0.6239\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6712 - accuracy: 0.7519 - val_loss: 0.8716 - val_accuracy: 0.6068\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6520 - accuracy: 0.7370 - val_loss: 0.8685 - val_accuracy: 0.6239\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7527 - accuracy: 0.7259 - val_loss: 1.1033 - val_accuracy: 0.6325\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6893 - accuracy: 0.7296 - val_loss: 0.9737 - val_accuracy: 0.5897\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6834 - accuracy: 0.7296 - val_loss: 0.9584 - val_accuracy: 0.6325\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7092 - accuracy: 0.7333 - val_loss: 0.9414 - val_accuracy: 0.5897\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6517 - accuracy: 0.7519 - val_loss: 0.9504 - val_accuracy: 0.5983\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 319us/step - loss: 0.6739 - accuracy: 0.7259 - val_loss: 0.8552 - val_accuracy: 0.6325\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6427 - accuracy: 0.7370 - val_loss: 0.8708 - val_accuracy: 0.6154\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6369 - accuracy: 0.7481 - val_loss: 0.8643 - val_accuracy: 0.6154\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6453 - accuracy: 0.7370 - val_loss: 0.8733 - val_accuracy: 0.6239\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6586 - accuracy: 0.7444 - val_loss: 0.9306 - val_accuracy: 0.6325\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7129 - accuracy: 0.7259 - val_loss: 1.0059 - val_accuracy: 0.6239\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6599 - accuracy: 0.7333 - val_loss: 1.0313 - val_accuracy: 0.5983\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6921 - accuracy: 0.7222 - val_loss: 1.1470 - val_accuracy: 0.6325\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8325 - accuracy: 0.7259 - val_loss: 1.1717 - val_accuracy: 0.6239\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7436 - accuracy: 0.7185 - val_loss: 0.9995 - val_accuracy: 0.5897\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6982 - accuracy: 0.7037 - val_loss: 0.9180 - val_accuracy: 0.6239\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7062 - accuracy: 0.7333 - val_loss: 1.0179 - val_accuracy: 0.6239\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6646 - accuracy: 0.7481 - val_loss: 0.8979 - val_accuracy: 0.6068\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7031 - accuracy: 0.7222 - val_loss: 0.9395 - val_accuracy: 0.6239\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9748 - accuracy: 0.7222 - val_loss: 1.6963 - val_accuracy: 0.6325\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9749 - accuracy: 0.7148 - val_loss: 1.1065 - val_accuracy: 0.6068\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6697 - accuracy: 0.7481 - val_loss: 0.9000 - val_accuracy: 0.5726\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6466 - accuracy: 0.7333 - val_loss: 0.9309 - val_accuracy: 0.6239\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6671 - accuracy: 0.7444 - val_loss: 0.9192 - val_accuracy: 0.6239\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6714 - accuracy: 0.7185 - val_loss: 0.8594 - val_accuracy: 0.6239\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6662 - accuracy: 0.7370 - val_loss: 0.8505 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6815 - accuracy: 0.7148 - val_loss: 0.8651 - val_accuracy: 0.6239\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6532 - accuracy: 0.7407 - val_loss: 0.9265 - val_accuracy: 0.6068\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6743 - accuracy: 0.7407 - val_loss: 0.8663 - val_accuracy: 0.6154\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6452 - accuracy: 0.7259 - val_loss: 0.8971 - val_accuracy: 0.6239\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6427 - accuracy: 0.7333 - val_loss: 0.8809 - val_accuracy: 0.6239\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6384 - accuracy: 0.7519 - val_loss: 0.8631 - val_accuracy: 0.6325\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.6327 - accuracy: 0.7333 - val_loss: 0.8850 - val_accuracy: 0.6154\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6437 - accuracy: 0.7519 - val_loss: 0.8598 - val_accuracy: 0.6239\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6266 - accuracy: 0.7370 - val_loss: 0.8924 - val_accuracy: 0.6239\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.6433 - accuracy: 0.7370 - val_loss: 0.8694 - val_accuracy: 0.6239\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6270 - accuracy: 0.7444 - val_loss: 0.8562 - val_accuracy: 0.6410\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6307 - accuracy: 0.7444 - val_loss: 0.8693 - val_accuracy: 0.6325\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6350 - accuracy: 0.7556 - val_loss: 0.8688 - val_accuracy: 0.6239\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6333 - accuracy: 0.7519 - val_loss: 0.8882 - val_accuracy: 0.6154\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6317 - accuracy: 0.7444 - val_loss: 0.8722 - val_accuracy: 0.6239\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6300 - accuracy: 0.7519 - val_loss: 0.8673 - val_accuracy: 0.6239\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6311 - accuracy: 0.7556 - val_loss: 0.8810 - val_accuracy: 0.6154\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.6273 - accuracy: 0.7519 - val_loss: 0.8663 - val_accuracy: 0.6325\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6310 - accuracy: 0.7370 - val_loss: 0.8756 - val_accuracy: 0.6239\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6389 - accuracy: 0.7519 - val_loss: 0.8666 - val_accuracy: 0.6239\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6206 - accuracy: 0.7630 - val_loss: 0.8507 - val_accuracy: 0.6325\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6296 - accuracy: 0.7333 - val_loss: 0.8655 - val_accuracy: 0.6325\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6525 - accuracy: 0.7370 - val_loss: 0.8558 - val_accuracy: 0.6325\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6798 - accuracy: 0.7370 - val_loss: 0.8562 - val_accuracy: 0.6325\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6442 - accuracy: 0.7407 - val_loss: 0.9007 - val_accuracy: 0.6068\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6593 - accuracy: 0.7370 - val_loss: 0.8574 - val_accuracy: 0.6325\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6770 - accuracy: 0.7296 - val_loss: 0.9150 - val_accuracy: 0.6154\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6443 - accuracy: 0.7481 - val_loss: 0.9615 - val_accuracy: 0.5897\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6635 - accuracy: 0.7407 - val_loss: 0.8555 - val_accuracy: 0.6410\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6255 - accuracy: 0.7519 - val_loss: 0.9054 - val_accuracy: 0.6154\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6327 - accuracy: 0.7444 - val_loss: 0.8609 - val_accuracy: 0.6325\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6399 - accuracy: 0.7444 - val_loss: 0.8676 - val_accuracy: 0.6154\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6403 - accuracy: 0.7481 - val_loss: 0.8696 - val_accuracy: 0.6239\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7476 - accuracy: 0.7259 - val_loss: 1.0221 - val_accuracy: 0.6325\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6490 - accuracy: 0.7481 - val_loss: 1.3082 - val_accuracy: 0.6068\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 327us/step - loss: 0.8744 - accuracy: 0.7222 - val_loss: 1.0338 - val_accuracy: 0.6325\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.7095 - accuracy: 0.7296 - val_loss: 1.0717 - val_accuracy: 0.6325\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6797 - accuracy: 0.7370 - val_loss: 0.9039 - val_accuracy: 0.6068\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8855 - accuracy: 0.7185 - val_loss: 0.9266 - val_accuracy: 0.5897\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6487 - accuracy: 0.7296 - val_loss: 1.1670 - val_accuracy: 0.5897\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8066 - accuracy: 0.7074 - val_loss: 1.0427 - val_accuracy: 0.6154\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6800 - accuracy: 0.7370 - val_loss: 1.0247 - val_accuracy: 0.5983\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6741 - accuracy: 0.7222 - val_loss: 1.0659 - val_accuracy: 0.6239\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7560 - accuracy: 0.7222 - val_loss: 1.0477 - val_accuracy: 0.6239\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6705 - accuracy: 0.7296 - val_loss: 0.9283 - val_accuracy: 0.6154\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.7892 - accuracy: 0.7037 - val_loss: 0.9293 - val_accuracy: 0.6325\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7252 - accuracy: 0.7296 - val_loss: 1.1727 - val_accuracy: 0.6325\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7628 - accuracy: 0.7370 - val_loss: 0.9052 - val_accuracy: 0.6325\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.6312 - accuracy: 0.7481 - val_loss: 0.8614 - val_accuracy: 0.6325\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6651 - accuracy: 0.7333 - val_loss: 0.9684 - val_accuracy: 0.6239\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6498 - accuracy: 0.7407 - val_loss: 0.8782 - val_accuracy: 0.6068\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6703 - accuracy: 0.7148 - val_loss: 0.8668 - val_accuracy: 0.6410\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6434 - accuracy: 0.7370 - val_loss: 0.9479 - val_accuracy: 0.5983\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6421 - accuracy: 0.7556 - val_loss: 0.9464 - val_accuracy: 0.6154\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6530 - accuracy: 0.7407 - val_loss: 0.8930 - val_accuracy: 0.6154\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6505 - accuracy: 0.7444 - val_loss: 0.8975 - val_accuracy: 0.6239\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6555 - accuracy: 0.7407 - val_loss: 0.8872 - val_accuracy: 0.6068\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6563 - accuracy: 0.7111 - val_loss: 0.9237 - val_accuracy: 0.6239\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6529 - accuracy: 0.7259 - val_loss: 0.9312 - val_accuracy: 0.5897\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6699 - accuracy: 0.7296 - val_loss: 0.8954 - val_accuracy: 0.6068\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6679 - accuracy: 0.7296 - val_loss: 0.8989 - val_accuracy: 0.6154\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6294 - accuracy: 0.7444 - val_loss: 0.9120 - val_accuracy: 0.5983\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6403 - accuracy: 0.7222 - val_loss: 0.8587 - val_accuracy: 0.6496\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6409 - accuracy: 0.7333 - val_loss: 0.8763 - val_accuracy: 0.6496\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6215 - accuracy: 0.7370 - val_loss: 0.8832 - val_accuracy: 0.6154\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6257 - accuracy: 0.7519 - val_loss: 0.8851 - val_accuracy: 0.6068\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6330 - accuracy: 0.7593 - val_loss: 0.8934 - val_accuracy: 0.5897\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.6301 - accuracy: 0.7481 - val_loss: 0.8840 - val_accuracy: 0.6068\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.6219 - accuracy: 0.7593 - val_loss: 0.8730 - val_accuracy: 0.6154\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 346us/step - loss: 0.6186 - accuracy: 0.7593 - val_loss: 0.8626 - val_accuracy: 0.6410\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6241 - accuracy: 0.7444 - val_loss: 0.8570 - val_accuracy: 0.6410\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6209 - accuracy: 0.7556 - val_loss: 0.8565 - val_accuracy: 0.6581\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6330 - accuracy: 0.7444 - val_loss: 0.8759 - val_accuracy: 0.6410\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6278 - accuracy: 0.7556 - val_loss: 0.8823 - val_accuracy: 0.6239\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6391 - accuracy: 0.7370 - val_loss: 0.8743 - val_accuracy: 0.6239\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6412 - accuracy: 0.7407 - val_loss: 0.9033 - val_accuracy: 0.6239\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6269 - accuracy: 0.7444 - val_loss: 0.8683 - val_accuracy: 0.6239\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6407 - accuracy: 0.7407 - val_loss: 0.8592 - val_accuracy: 0.6410\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6179 - accuracy: 0.7556 - val_loss: 0.8625 - val_accuracy: 0.6325\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6396 - accuracy: 0.7333 - val_loss: 0.8677 - val_accuracy: 0.6239\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6288 - accuracy: 0.7481 - val_loss: 0.8976 - val_accuracy: 0.6239\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6290 - accuracy: 0.7556 - val_loss: 0.8687 - val_accuracy: 0.6325\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.6227 - accuracy: 0.7556 - val_loss: 0.8681 - val_accuracy: 0.6068\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.6166 - accuracy: 0.7519 - val_loss: 0.8655 - val_accuracy: 0.6154\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6186 - accuracy: 0.7481 - val_loss: 0.8641 - val_accuracy: 0.6239\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6180 - accuracy: 0.7556 - val_loss: 0.8833 - val_accuracy: 0.6239\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6190 - accuracy: 0.7519 - val_loss: 0.8683 - val_accuracy: 0.6239\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6236 - accuracy: 0.7519 - val_loss: 0.8811 - val_accuracy: 0.6154\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6314 - accuracy: 0.7407 - val_loss: 0.8815 - val_accuracy: 0.6239\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6218 - accuracy: 0.7519 - val_loss: 0.8724 - val_accuracy: 0.6154\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6376 - accuracy: 0.7333 - val_loss: 0.8730 - val_accuracy: 0.6410\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6220 - accuracy: 0.7481 - val_loss: 0.8794 - val_accuracy: 0.6239\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6556 - accuracy: 0.7333 - val_loss: 0.8878 - val_accuracy: 0.6410\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6612 - accuracy: 0.7333 - val_loss: 0.8939 - val_accuracy: 0.5983\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6428 - accuracy: 0.7370 - val_loss: 0.9214 - val_accuracy: 0.6325\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6718 - accuracy: 0.7111 - val_loss: 0.9723 - val_accuracy: 0.5897\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6647 - accuracy: 0.7407 - val_loss: 0.9368 - val_accuracy: 0.6068\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6514 - accuracy: 0.7407 - val_loss: 0.8993 - val_accuracy: 0.6154\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 289us/step - loss: 0.6523 - accuracy: 0.7222 - val_loss: 0.9052 - val_accuracy: 0.5983\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7687 - accuracy: 0.7074 - val_loss: 1.2390 - val_accuracy: 0.5641\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 1.2554 - accuracy: 0.6444 - val_loss: 1.0005 - val_accuracy: 0.5385\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8018 - accuracy: 0.6815 - val_loss: 0.9517 - val_accuracy: 0.5897\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6939 - accuracy: 0.7222 - val_loss: 0.9307 - val_accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6783 - accuracy: 0.7407 - val_loss: 1.0758 - val_accuracy: 0.5556\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6810 - accuracy: 0.7111 - val_loss: 0.9225 - val_accuracy: 0.6068\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7224 - accuracy: 0.7037 - val_loss: 0.8829 - val_accuracy: 0.6154\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6279 - accuracy: 0.7481 - val_loss: 0.9226 - val_accuracy: 0.5983\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6410 - accuracy: 0.7593 - val_loss: 0.8850 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6419 - accuracy: 0.7222 - val_loss: 0.8682 - val_accuracy: 0.6410\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6166 - accuracy: 0.7556 - val_loss: 0.8791 - val_accuracy: 0.6239\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 168us/step - loss: 0.6266 - accuracy: 0.7407 - val_loss: 0.8521 - val_accuracy: 0.6581\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6284 - accuracy: 0.7481 - val_loss: 0.8981 - val_accuracy: 0.6325\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6818 - accuracy: 0.7370 - val_loss: 1.1930 - val_accuracy: 0.6239\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.7612 - accuracy: 0.7259 - val_loss: 0.9525 - val_accuracy: 0.6154\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7059 - accuracy: 0.7259 - val_loss: 0.8797 - val_accuracy: 0.6068\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6748 - accuracy: 0.7333 - val_loss: 0.9415 - val_accuracy: 0.6325\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6265 - accuracy: 0.7407 - val_loss: 0.9360 - val_accuracy: 0.6068\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6607 - accuracy: 0.7407 - val_loss: 0.9116 - val_accuracy: 0.6239\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6590 - accuracy: 0.7333 - val_loss: 0.9388 - val_accuracy: 0.6068\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6281 - accuracy: 0.7481 - val_loss: 0.9179 - val_accuracy: 0.5897\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6438 - accuracy: 0.7407 - val_loss: 0.8727 - val_accuracy: 0.6154\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6114 - accuracy: 0.7593 - val_loss: 0.8632 - val_accuracy: 0.6325\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6198 - accuracy: 0.7481 - val_loss: 0.8776 - val_accuracy: 0.6154\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6161 - accuracy: 0.7519 - val_loss: 0.8642 - val_accuracy: 0.6154\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.71 - 0s 99us/step - loss: 0.6109 - accuracy: 0.7556 - val_loss: 0.8740 - val_accuracy: 0.6154\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6112 - accuracy: 0.7556 - val_loss: 0.8721 - val_accuracy: 0.6239\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6200 - accuracy: 0.7556 - val_loss: 0.8791 - val_accuracy: 0.6239\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.6157 - accuracy: 0.7444 - val_loss: 0.8692 - val_accuracy: 0.6239\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 330us/step - loss: 0.6169 - accuracy: 0.7481 - val_loss: 0.8985 - val_accuracy: 0.6068\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 361us/step - loss: 0.6471 - accuracy: 0.7407 - val_loss: 0.8732 - val_accuracy: 0.6325\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6629 - accuracy: 0.7037 - val_loss: 0.8997 - val_accuracy: 0.6239\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6432 - accuracy: 0.7481 - val_loss: 0.9457 - val_accuracy: 0.5983\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.6230 - accuracy: 0.7481 - val_loss: 0.8972 - val_accuracy: 0.6325\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6378 - accuracy: 0.7370 - val_loss: 0.8948 - val_accuracy: 0.6154\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 299us/step - loss: 0.6292 - accuracy: 0.7519 - val_loss: 0.8742 - val_accuracy: 0.6239\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6223 - accuracy: 0.7519 - val_loss: 0.9055 - val_accuracy: 0.5983\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6171 - accuracy: 0.7481 - val_loss: 0.8900 - val_accuracy: 0.6068\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6402 - accuracy: 0.7333 - val_loss: 0.8888 - val_accuracy: 0.6068\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.6952 - accuracy: 0.7333 - val_loss: 1.0675 - val_accuracy: 0.6239\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6908 - accuracy: 0.7407 - val_loss: 0.9125 - val_accuracy: 0.6068\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.73 - 0s 114us/step - loss: 0.7030 - accuracy: 0.7111 - val_loss: 1.1344 - val_accuracy: 0.6239\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.0032 - accuracy: 0.7037 - val_loss: 2.5236 - val_accuracy: 0.6239\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.6823 - accuracy: 0.7111 - val_loss: 2.8062 - val_accuracy: 0.5812\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.6366 - accuracy: 0.6926 - val_loss: 2.1211 - val_accuracy: 0.6068\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.1489 - accuracy: 0.7185 - val_loss: 1.3189 - val_accuracy: 0.6068\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7843 - accuracy: 0.6519 - val_loss: 1.0580 - val_accuracy: 0.5812\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7316 - accuracy: 0.7074 - val_loss: 1.1587 - val_accuracy: 0.5897\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7076 - accuracy: 0.7333 - val_loss: 0.9057 - val_accuracy: 0.6154\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6662 - accuracy: 0.7259 - val_loss: 0.9288 - val_accuracy: 0.6068\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6424 - accuracy: 0.7444 - val_loss: 0.9206 - val_accuracy: 0.6068\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6478 - accuracy: 0.7370 - val_loss: 0.8945 - val_accuracy: 0.6068\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6473 - accuracy: 0.7407 - val_loss: 0.9054 - val_accuracy: 0.5641\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7199 - accuracy: 0.6963 - val_loss: 0.9079 - val_accuracy: 0.5726\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6545 - accuracy: 0.7296 - val_loss: 1.2644 - val_accuracy: 0.5299\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6931 - accuracy: 0.7074 - val_loss: 0.9310 - val_accuracy: 0.5726\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7360 - accuracy: 0.7000 - val_loss: 0.9005 - val_accuracy: 0.6068\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6434 - accuracy: 0.7370 - val_loss: 1.0971 - val_accuracy: 0.5385\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 295us/step - loss: 0.6755 - accuracy: 0.7148 - val_loss: 0.8970 - val_accuracy: 0.5983\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.6739 - accuracy: 0.7074 - val_loss: 0.8851 - val_accuracy: 0.6154\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 413us/step - loss: 0.6296 - accuracy: 0.7556 - val_loss: 0.8846 - val_accuracy: 0.6239\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6259 - accuracy: 0.7407 - val_loss: 0.8678 - val_accuracy: 0.6239\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6348 - accuracy: 0.7481 - val_loss: 0.8880 - val_accuracy: 0.6154\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 374us/step - loss: 0.6257 - accuracy: 0.7481 - val_loss: 0.8821 - val_accuracy: 0.6068\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6291 - accuracy: 0.7370 - val_loss: 0.8917 - val_accuracy: 0.5983\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6306 - accuracy: 0.7519 - val_loss: 0.9108 - val_accuracy: 0.6154\n",
      "Epoch 723/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 74us/step - loss: 0.6347 - accuracy: 0.7444 - val_loss: 0.8745 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6297 - accuracy: 0.7444 - val_loss: 0.8736 - val_accuracy: 0.6068\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.6331 - accuracy: 0.7259 - val_loss: 0.8811 - val_accuracy: 0.6325\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6233 - accuracy: 0.7481 - val_loss: 0.8897 - val_accuracy: 0.6068\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6174 - accuracy: 0.7519 - val_loss: 0.8744 - val_accuracy: 0.6410\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.6285 - accuracy: 0.7444 - val_loss: 0.8656 - val_accuracy: 0.6410\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6362 - accuracy: 0.7407 - val_loss: 0.8955 - val_accuracy: 0.6325\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6317 - accuracy: 0.7519 - val_loss: 0.8820 - val_accuracy: 0.6239\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6216 - accuracy: 0.7519 - val_loss: 0.8874 - val_accuracy: 0.6068\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6335 - accuracy: 0.7370 - val_loss: 0.8860 - val_accuracy: 0.6325\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6497 - accuracy: 0.7222 - val_loss: 0.8855 - val_accuracy: 0.6239\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6209 - accuracy: 0.7519 - val_loss: 0.9362 - val_accuracy: 0.5897\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6321 - accuracy: 0.7333 - val_loss: 0.8871 - val_accuracy: 0.6239\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6322 - accuracy: 0.7333 - val_loss: 0.9185 - val_accuracy: 0.6068\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6278 - accuracy: 0.7407 - val_loss: 0.8958 - val_accuracy: 0.6154\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6396 - accuracy: 0.7519 - val_loss: 0.8859 - val_accuracy: 0.5897\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6404 - accuracy: 0.7333 - val_loss: 0.9370 - val_accuracy: 0.6239\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6474 - accuracy: 0.7259 - val_loss: 0.8780 - val_accuracy: 0.6325\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6390 - accuracy: 0.7556 - val_loss: 0.8675 - val_accuracy: 0.6325\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6245 - accuracy: 0.7444 - val_loss: 0.8602 - val_accuracy: 0.6410\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6189 - accuracy: 0.7519 - val_loss: 0.8861 - val_accuracy: 0.6154\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6240 - accuracy: 0.7444 - val_loss: 0.8681 - val_accuracy: 0.6239\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6219 - accuracy: 0.7481 - val_loss: 0.8796 - val_accuracy: 0.6239\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6220 - accuracy: 0.7481 - val_loss: 0.8766 - val_accuracy: 0.6239\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6259 - accuracy: 0.7370 - val_loss: 0.8958 - val_accuracy: 0.6068\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6413 - accuracy: 0.7407 - val_loss: 0.8925 - val_accuracy: 0.6068\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6580 - accuracy: 0.7407 - val_loss: 0.8765 - val_accuracy: 0.6325\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6948 - accuracy: 0.7444 - val_loss: 0.9539 - val_accuracy: 0.5983\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6271 - accuracy: 0.7444 - val_loss: 0.9545 - val_accuracy: 0.6325\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6718 - accuracy: 0.7074 - val_loss: 0.8863 - val_accuracy: 0.6068\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6388 - accuracy: 0.7444 - val_loss: 0.9212 - val_accuracy: 0.5897\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6379 - accuracy: 0.7481 - val_loss: 0.9097 - val_accuracy: 0.6154\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6389 - accuracy: 0.7407 - val_loss: 0.8648 - val_accuracy: 0.6325\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6354 - accuracy: 0.7296 - val_loss: 0.8680 - val_accuracy: 0.6239\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6351 - accuracy: 0.7222 - val_loss: 0.8633 - val_accuracy: 0.6496\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6305 - accuracy: 0.7296 - val_loss: 0.8775 - val_accuracy: 0.6239\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6229 - accuracy: 0.7407 - val_loss: 0.8832 - val_accuracy: 0.6410\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6177 - accuracy: 0.7519 - val_loss: 0.8887 - val_accuracy: 0.6154\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6218 - accuracy: 0.7444 - val_loss: 0.8749 - val_accuracy: 0.6239\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6258 - accuracy: 0.7481 - val_loss: 0.8785 - val_accuracy: 0.6154\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6583 - accuracy: 0.7259 - val_loss: 0.8731 - val_accuracy: 0.6239\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6371 - accuracy: 0.7407 - val_loss: 0.9416 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6340 - accuracy: 0.7444 - val_loss: 0.9106 - val_accuracy: 0.5983\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6375 - accuracy: 0.7259 - val_loss: 0.8816 - val_accuracy: 0.6239\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6201 - accuracy: 0.7407 - val_loss: 0.8631 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6532 - accuracy: 0.7222 - val_loss: 0.8573 - val_accuracy: 0.6496\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6253 - accuracy: 0.7333 - val_loss: 0.8941 - val_accuracy: 0.6068\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6201 - accuracy: 0.7519 - val_loss: 0.8879 - val_accuracy: 0.6154\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6563 - accuracy: 0.7222 - val_loss: 0.8736 - val_accuracy: 0.6068\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6546 - accuracy: 0.7222 - val_loss: 0.8630 - val_accuracy: 0.6325\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6993 - accuracy: 0.7259 - val_loss: 0.9534 - val_accuracy: 0.5812\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6645 - accuracy: 0.7222 - val_loss: 0.8816 - val_accuracy: 0.6239\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7165 - accuracy: 0.6852 - val_loss: 0.9958 - val_accuracy: 0.5470\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7395 - accuracy: 0.7037 - val_loss: 0.9519 - val_accuracy: 0.5726\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6860 - accuracy: 0.7074 - val_loss: 0.9626 - val_accuracy: 0.6154\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6429 - accuracy: 0.7222 - val_loss: 0.9101 - val_accuracy: 0.5983\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6788 - accuracy: 0.7222 - val_loss: 0.9627 - val_accuracy: 0.6239\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6775 - accuracy: 0.7370 - val_loss: 0.9784 - val_accuracy: 0.6410\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6642 - accuracy: 0.7074 - val_loss: 0.9435 - val_accuracy: 0.6154\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6429 - accuracy: 0.7370 - val_loss: 0.9479 - val_accuracy: 0.6068\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6327 - accuracy: 0.7259 - val_loss: 0.8797 - val_accuracy: 0.6496\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6738 - accuracy: 0.7222 - val_loss: 0.8756 - val_accuracy: 0.6325\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6371 - accuracy: 0.7296 - val_loss: 0.9291 - val_accuracy: 0.6239\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6512 - accuracy: 0.7222 - val_loss: 0.9360 - val_accuracy: 0.6068\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6435 - accuracy: 0.7444 - val_loss: 0.9261 - val_accuracy: 0.6154\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6407 - accuracy: 0.7370 - val_loss: 0.8853 - val_accuracy: 0.6325\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6200 - accuracy: 0.7444 - val_loss: 0.9009 - val_accuracy: 0.6154\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6126 - accuracy: 0.7407 - val_loss: 0.8820 - val_accuracy: 0.6239\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6226 - accuracy: 0.7407 - val_loss: 0.9099 - val_accuracy: 0.6239\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6236 - accuracy: 0.7444 - val_loss: 0.8900 - val_accuracy: 0.6325\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6357 - accuracy: 0.7222 - val_loss: 0.8742 - val_accuracy: 0.6239\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6201 - accuracy: 0.7481 - val_loss: 0.8890 - val_accuracy: 0.6410\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6236 - accuracy: 0.7407 - val_loss: 0.8725 - val_accuracy: 0.6239\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6188 - accuracy: 0.7407 - val_loss: 0.8738 - val_accuracy: 0.6239\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6160 - accuracy: 0.7444 - val_loss: 0.8992 - val_accuracy: 0.5983\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6218 - accuracy: 0.7481 - val_loss: 0.8618 - val_accuracy: 0.6496\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.6462 - accuracy: 0.7222 - val_loss: 0.9326 - val_accuracy: 0.5983\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6462 - accuracy: 0.7296 - val_loss: 0.8876 - val_accuracy: 0.6239\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6746 - accuracy: 0.7111 - val_loss: 0.9021 - val_accuracy: 0.6154\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6307 - accuracy: 0.7407 - val_loss: 0.9146 - val_accuracy: 0.6239\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6262 - accuracy: 0.7444 - val_loss: 0.8647 - val_accuracy: 0.6496\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6878 - accuracy: 0.7407 - val_loss: 0.8961 - val_accuracy: 0.6068\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7130 - accuracy: 0.7037 - val_loss: 1.0263 - val_accuracy: 0.6154\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6662 - accuracy: 0.7296 - val_loss: 0.8930 - val_accuracy: 0.6068\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6532 - accuracy: 0.7259 - val_loss: 0.8640 - val_accuracy: 0.6325\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6389 - accuracy: 0.7370 - val_loss: 0.9022 - val_accuracy: 0.5897\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6688 - accuracy: 0.7074 - val_loss: 0.9002 - val_accuracy: 0.5983\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6290 - accuracy: 0.7407 - val_loss: 0.9447 - val_accuracy: 0.5726\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6309 - accuracy: 0.7407 - val_loss: 0.8955 - val_accuracy: 0.6239\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6583 - accuracy: 0.7111 - val_loss: 0.8636 - val_accuracy: 0.6325\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6284 - accuracy: 0.7370 - val_loss: 0.8785 - val_accuracy: 0.6154\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6666 - accuracy: 0.7185 - val_loss: 0.8864 - val_accuracy: 0.6325\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6441 - accuracy: 0.7296 - val_loss: 0.9098 - val_accuracy: 0.6154\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.6395 - accuracy: 0.7407 - val_loss: 0.9228 - val_accuracy: 0.5983\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.6518 - accuracy: 0.7333 - val_loss: 0.8929 - val_accuracy: 0.6239\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6136 - accuracy: 0.7481 - val_loss: 0.8697 - val_accuracy: 0.6325\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6174 - accuracy: 0.7296 - val_loss: 0.8904 - val_accuracy: 0.6410\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6153 - accuracy: 0.7481 - val_loss: 0.8715 - val_accuracy: 0.6496\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6153 - accuracy: 0.7407 - val_loss: 0.8901 - val_accuracy: 0.6239\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6154 - accuracy: 0.7481 - val_loss: 0.8740 - val_accuracy: 0.6239\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6192 - accuracy: 0.7370 - val_loss: 0.9339 - val_accuracy: 0.6239\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6307 - accuracy: 0.7370 - val_loss: 0.8783 - val_accuracy: 0.6496\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6118 - accuracy: 0.7556 - val_loss: 0.8736 - val_accuracy: 0.6410\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6185 - accuracy: 0.7407 - val_loss: 0.8709 - val_accuracy: 0.6410\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6167 - accuracy: 0.7370 - val_loss: 0.9008 - val_accuracy: 0.6410\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6174 - accuracy: 0.7444 - val_loss: 0.8677 - val_accuracy: 0.6325\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6166 - accuracy: 0.7519 - val_loss: 0.8731 - val_accuracy: 0.6154\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6159 - accuracy: 0.7444 - val_loss: 0.8606 - val_accuracy: 0.6239\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6309 - accuracy: 0.7259 - val_loss: 0.8719 - val_accuracy: 0.6325\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6287 - accuracy: 0.7407 - val_loss: 0.8680 - val_accuracy: 0.6239\n",
      "Epoch 833/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 124us/step - loss: 0.6352 - accuracy: 0.7222 - val_loss: 0.9266 - val_accuracy: 0.6154\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6391 - accuracy: 0.7444 - val_loss: 0.9235 - val_accuracy: 0.6154\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6409 - accuracy: 0.7333 - val_loss: 0.8867 - val_accuracy: 0.6068\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6242 - accuracy: 0.7407 - val_loss: 0.8717 - val_accuracy: 0.6325\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6162 - accuracy: 0.7444 - val_loss: 0.8552 - val_accuracy: 0.6410\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6156 - accuracy: 0.7481 - val_loss: 0.8784 - val_accuracy: 0.6154\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6163 - accuracy: 0.7556 - val_loss: 0.8757 - val_accuracy: 0.6325\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6132 - accuracy: 0.7519 - val_loss: 0.8871 - val_accuracy: 0.6068\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6119 - accuracy: 0.7519 - val_loss: 0.8947 - val_accuracy: 0.5983\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6159 - accuracy: 0.7481 - val_loss: 0.8778 - val_accuracy: 0.6154\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6276 - accuracy: 0.7333 - val_loss: 0.8639 - val_accuracy: 0.6325\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6698 - accuracy: 0.7185 - val_loss: 0.9667 - val_accuracy: 0.6239\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9885 - accuracy: 0.7185 - val_loss: 1.7506 - val_accuracy: 0.6239\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9856 - accuracy: 0.7074 - val_loss: 1.2217 - val_accuracy: 0.5897\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7319 - accuracy: 0.7148 - val_loss: 1.3163 - val_accuracy: 0.5641\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8379 - accuracy: 0.6889 - val_loss: 1.1272 - val_accuracy: 0.6239\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7257 - accuracy: 0.7370 - val_loss: 1.2150 - val_accuracy: 0.6325\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.7481 - accuracy: 0.7296 - val_loss: 0.9071 - val_accuracy: 0.6154\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6168 - accuracy: 0.7481 - val_loss: 1.0330 - val_accuracy: 0.5983\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6523 - accuracy: 0.7296 - val_loss: 0.9545 - val_accuracy: 0.6154\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6537 - accuracy: 0.7370 - val_loss: 0.9391 - val_accuracy: 0.6068\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6116 - accuracy: 0.7444 - val_loss: 0.9546 - val_accuracy: 0.5983\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7896 - accuracy: 0.7222 - val_loss: 0.9821 - val_accuracy: 0.6154\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.7028 - accuracy: 0.7333 - val_loss: 1.3227 - val_accuracy: 0.6154\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.8145 - accuracy: 0.7259 - val_loss: 1.1155 - val_accuracy: 0.6154\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 306us/step - loss: 0.6550 - accuracy: 0.7407 - val_loss: 1.0228 - val_accuracy: 0.6068\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6860 - accuracy: 0.7185 - val_loss: 0.8990 - val_accuracy: 0.6068\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6175 - accuracy: 0.7481 - val_loss: 0.9323 - val_accuracy: 0.6239\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6437 - accuracy: 0.7407 - val_loss: 0.8966 - val_accuracy: 0.6239\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6321 - accuracy: 0.7444 - val_loss: 0.8733 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6109 - accuracy: 0.7519 - val_loss: 0.9256 - val_accuracy: 0.6068\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.67 - 0s 78us/step - loss: 0.6296 - accuracy: 0.7333 - val_loss: 0.8702 - val_accuracy: 0.6154\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6266 - accuracy: 0.7296 - val_loss: 0.8662 - val_accuracy: 0.6410\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6143 - accuracy: 0.7444 - val_loss: 0.8761 - val_accuracy: 0.6410\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6337 - accuracy: 0.7148 - val_loss: 0.8886 - val_accuracy: 0.6239\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6302 - accuracy: 0.7444 - val_loss: 0.8826 - val_accuracy: 0.6154\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6204 - accuracy: 0.7444 - val_loss: 0.8869 - val_accuracy: 0.6068\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6244 - accuracy: 0.7370 - val_loss: 0.8882 - val_accuracy: 0.6325\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6168 - accuracy: 0.7556 - val_loss: 0.8573 - val_accuracy: 0.6581\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6232 - accuracy: 0.7259 - val_loss: 0.9317 - val_accuracy: 0.5983\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6257 - accuracy: 0.7259 - val_loss: 0.8980 - val_accuracy: 0.5983\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7065 - accuracy: 0.7111 - val_loss: 0.9367 - val_accuracy: 0.6239\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6528 - accuracy: 0.7296 - val_loss: 0.9578 - val_accuracy: 0.6154\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6252 - accuracy: 0.7556 - val_loss: 0.8947 - val_accuracy: 0.6239\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6120 - accuracy: 0.7519 - val_loss: 0.8878 - val_accuracy: 0.6325\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6307 - accuracy: 0.7296 - val_loss: 0.8845 - val_accuracy: 0.6239\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6209 - accuracy: 0.7407 - val_loss: 0.8863 - val_accuracy: 0.6239\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6114 - accuracy: 0.7481 - val_loss: 0.8937 - val_accuracy: 0.6068\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6217 - accuracy: 0.7370 - val_loss: 0.8924 - val_accuracy: 0.6239\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6153 - accuracy: 0.7444 - val_loss: 0.8828 - val_accuracy: 0.6239\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6096 - accuracy: 0.7444 - val_loss: 0.9150 - val_accuracy: 0.5897\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6170 - accuracy: 0.7370 - val_loss: 0.8812 - val_accuracy: 0.6239\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6115 - accuracy: 0.7407 - val_loss: 0.8765 - val_accuracy: 0.6325\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6052 - accuracy: 0.7519 - val_loss: 0.8978 - val_accuracy: 0.6154\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6135 - accuracy: 0.7481 - val_loss: 0.8663 - val_accuracy: 0.6496\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6363 - accuracy: 0.7259 - val_loss: 0.9129 - val_accuracy: 0.6239\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6332 - accuracy: 0.7407 - val_loss: 0.9007 - val_accuracy: 0.6068\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6747 - accuracy: 0.7333 - val_loss: 0.9185 - val_accuracy: 0.6239\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6372 - accuracy: 0.7259 - val_loss: 0.9582 - val_accuracy: 0.6068\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6256 - accuracy: 0.7296 - val_loss: 0.8976 - val_accuracy: 0.6239\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6432 - accuracy: 0.7296 - val_loss: 0.9005 - val_accuracy: 0.6068\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6286 - accuracy: 0.7481 - val_loss: 0.9385 - val_accuracy: 0.5983\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6495 - accuracy: 0.7148 - val_loss: 0.8954 - val_accuracy: 0.6154\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6228 - accuracy: 0.7370 - val_loss: 0.8765 - val_accuracy: 0.6410\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6519 - accuracy: 0.7222 - val_loss: 0.8772 - val_accuracy: 0.6410\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6447 - accuracy: 0.7370 - val_loss: 0.9182 - val_accuracy: 0.6410\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6309 - accuracy: 0.7185 - val_loss: 0.9259 - val_accuracy: 0.6154\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6272 - accuracy: 0.7519 - val_loss: 0.8928 - val_accuracy: 0.6068\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6517 - accuracy: 0.7407 - val_loss: 0.9092 - val_accuracy: 0.6154\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6042 - accuracy: 0.7481 - val_loss: 0.9353 - val_accuracy: 0.5897\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6223 - accuracy: 0.7667 - val_loss: 0.8807 - val_accuracy: 0.6239\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6307 - accuracy: 0.7333 - val_loss: 0.9023 - val_accuracy: 0.6154\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.6280 - accuracy: 0.7333 - val_loss: 0.8971 - val_accuracy: 0.6068\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6218 - accuracy: 0.7370 - val_loss: 0.9148 - val_accuracy: 0.5983\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6283 - accuracy: 0.7481 - val_loss: 0.9149 - val_accuracy: 0.6154\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6490 - accuracy: 0.7370 - val_loss: 0.9329 - val_accuracy: 0.6154\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6067 - accuracy: 0.7333 - val_loss: 0.8960 - val_accuracy: 0.6325\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6128 - accuracy: 0.7519 - val_loss: 0.8888 - val_accuracy: 0.6239\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6278 - accuracy: 0.7370 - val_loss: 0.8811 - val_accuracy: 0.6239\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6281 - accuracy: 0.7444 - val_loss: 0.8804 - val_accuracy: 0.6325\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6157 - accuracy: 0.7481 - val_loss: 1.0655 - val_accuracy: 0.6239\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6983 - accuracy: 0.7259 - val_loss: 0.9353 - val_accuracy: 0.5983\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7135 - accuracy: 0.7259 - val_loss: 1.0181 - val_accuracy: 0.5983\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6506 - accuracy: 0.7259 - val_loss: 0.8752 - val_accuracy: 0.6325\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6165 - accuracy: 0.7519 - val_loss: 0.9508 - val_accuracy: 0.5812\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6213 - accuracy: 0.7296 - val_loss: 0.8886 - val_accuracy: 0.6068\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6476 - accuracy: 0.7185 - val_loss: 0.9539 - val_accuracy: 0.5983\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6695 - accuracy: 0.7185 - val_loss: 1.0143 - val_accuracy: 0.6325\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7064 - accuracy: 0.7259 - val_loss: 0.9623 - val_accuracy: 0.5983\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8168 - accuracy: 0.7111 - val_loss: 1.5051 - val_accuracy: 0.6068\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0330 - accuracy: 0.7037 - val_loss: 1.6571 - val_accuracy: 0.5897\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.1088 - accuracy: 0.7037 - val_loss: 1.8884 - val_accuracy: 0.5726\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 1.0490 - accuracy: 0.7111 - val_loss: 1.3719 - val_accuracy: 0.6239\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8140 - accuracy: 0.7185 - val_loss: 1.0864 - val_accuracy: 0.5299\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7203 - accuracy: 0.6778 - val_loss: 1.0095 - val_accuracy: 0.5812\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6580 - accuracy: 0.7333 - val_loss: 1.0762 - val_accuracy: 0.6239\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7245 - accuracy: 0.7185 - val_loss: 1.1889 - val_accuracy: 0.5812\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6834 - accuracy: 0.7222 - val_loss: 0.9041 - val_accuracy: 0.5983\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6645 - accuracy: 0.7185 - val_loss: 0.9674 - val_accuracy: 0.5897\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6435 - accuracy: 0.7333 - val_loss: 0.9266 - val_accuracy: 0.5897\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.7757 - accuracy: 0.6815 - val_loss: 0.8864 - val_accuracy: 0.6239\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6486 - accuracy: 0.7259 - val_loss: 0.8747 - val_accuracy: 0.6410\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6347 - accuracy: 0.7259 - val_loss: 0.8665 - val_accuracy: 0.6325\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6323 - accuracy: 0.7370 - val_loss: 0.8491 - val_accuracy: 0.6496\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6471 - accuracy: 0.7296 - val_loss: 0.9235 - val_accuracy: 0.6154\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6535 - accuracy: 0.7333 - val_loss: 0.9029 - val_accuracy: 0.5897\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6181 - accuracy: 0.7519 - val_loss: 1.0220 - val_accuracy: 0.6154\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6684 - accuracy: 0.7296 - val_loss: 0.9301 - val_accuracy: 0.6068\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6279 - accuracy: 0.7444 - val_loss: 0.9884 - val_accuracy: 0.5726\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6340 - accuracy: 0.7370 - val_loss: 0.9313 - val_accuracy: 0.6154\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 124us/step - loss: 0.6485 - accuracy: 0.7296 - val_loss: 0.8910 - val_accuracy: 0.6325\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6502 - accuracy: 0.7481 - val_loss: 0.9034 - val_accuracy: 0.6154\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.6194 - accuracy: 0.7370 - val_loss: 0.8923 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 313us/step - loss: 0.6294 - accuracy: 0.7556 - val_loss: 0.9974 - val_accuracy: 0.5812\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.6284 - accuracy: 0.7667 - val_loss: 0.9237 - val_accuracy: 0.6239\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6806 - accuracy: 0.7296 - val_loss: 0.8804 - val_accuracy: 0.6325\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6972 - accuracy: 0.6926 - val_loss: 0.9099 - val_accuracy: 0.5641\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6502 - accuracy: 0.7259 - val_loss: 0.9564 - val_accuracy: 0.5897\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6644 - accuracy: 0.7259 - val_loss: 0.9104 - val_accuracy: 0.5983\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6448 - accuracy: 0.7185 - val_loss: 0.8915 - val_accuracy: 0.6068\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6320 - accuracy: 0.7222 - val_loss: 0.8898 - val_accuracy: 0.6239\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6370 - accuracy: 0.7185 - val_loss: 0.8664 - val_accuracy: 0.6496\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6575 - accuracy: 0.7148 - val_loss: 1.0452 - val_accuracy: 0.6154\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7129 - accuracy: 0.7074 - val_loss: 0.9195 - val_accuracy: 0.5812\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6704 - accuracy: 0.7222 - val_loss: 0.9945 - val_accuracy: 0.5897\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.6597 - accuracy: 0.7370 - val_loss: 0.9124 - val_accuracy: 0.5897\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6998 - accuracy: 0.7111 - val_loss: 0.9116 - val_accuracy: 0.6154\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6157 - accuracy: 0.7407 - val_loss: 0.9781 - val_accuracy: 0.6068\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6238 - accuracy: 0.7481 - val_loss: 0.9206 - val_accuracy: 0.6325\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6490 - accuracy: 0.7185 - val_loss: 0.9296 - val_accuracy: 0.6239\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6219 - accuracy: 0.7444 - val_loss: 0.8772 - val_accuracy: 0.6239\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6215 - accuracy: 0.7259 - val_loss: 0.9053 - val_accuracy: 0.6154\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6142 - accuracy: 0.7333 - val_loss: 0.9129 - val_accuracy: 0.6239\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6207 - accuracy: 0.7556 - val_loss: 0.8768 - val_accuracy: 0.6410\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6391 - accuracy: 0.7259 - val_loss: 0.8904 - val_accuracy: 0.6154\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6365 - accuracy: 0.7444 - val_loss: 0.8866 - val_accuracy: 0.6154\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6257 - accuracy: 0.7481 - val_loss: 0.8858 - val_accuracy: 0.6239\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6115 - accuracy: 0.7333 - val_loss: 0.8919 - val_accuracy: 0.6068\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6246 - accuracy: 0.7185 - val_loss: 0.8784 - val_accuracy: 0.6325\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6329 - accuracy: 0.7296 - val_loss: 0.9093 - val_accuracy: 0.6154\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6591 - accuracy: 0.7111 - val_loss: 0.9235 - val_accuracy: 0.6068\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6898 - accuracy: 0.7259 - val_loss: 0.9579 - val_accuracy: 0.5726\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7411 - accuracy: 0.7333 - val_loss: 1.2953 - val_accuracy: 0.6239\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7521 - accuracy: 0.7407 - val_loss: 0.9103 - val_accuracy: 0.6154\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6581 - accuracy: 0.7407 - val_loss: 0.9450 - val_accuracy: 0.6068\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8197 - accuracy: 0.7296 - val_loss: 1.8226 - val_accuracy: 0.5983\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 291us/step - loss: 1.1418 - accuracy: 0.7111 - val_loss: 1.8150 - val_accuracy: 0.5983\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0290 - accuracy: 0.7148 - val_loss: 1.2873 - val_accuracy: 0.6239\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8128 - accuracy: 0.7185 - val_loss: 1.0475 - val_accuracy: 0.5385\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7169 - accuracy: 0.6889 - val_loss: 0.9682 - val_accuracy: 0.5983\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6647 - accuracy: 0.7481 - val_loss: 1.0414 - val_accuracy: 0.6239\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6712 - accuracy: 0.7444 - val_loss: 0.9082 - val_accuracy: 0.5983\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6921 - accuracy: 0.7370 - val_loss: 0.9663 - val_accuracy: 0.6239\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7989 - accuracy: 0.7370 - val_loss: 1.4788 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8417 - accuracy: 0.7259 - val_loss: 1.0548 - val_accuracy: 0.6068\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7291 - accuracy: 0.7222 - val_loss: 0.9704 - val_accuracy: 0.5983\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6536 - accuracy: 0.7333 - val_loss: 1.0137 - val_accuracy: 0.5983\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.6472 - accuracy: 0.7333 - val_loss: 0.9029 - val_accuracy: 0.6239\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6161 - accuracy: 0.7556 - val_loss: 0.8948 - val_accuracy: 0.6239\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6233 - accuracy: 0.7296 - val_loss: 0.9591 - val_accuracy: 0.5983\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6279 - accuracy: 0.7333 - val_loss: 0.8712 - val_accuracy: 0.6410\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.5997 - accuracy: 0.7481 - val_loss: 0.9036 - val_accuracy: 0.6068\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6010 - accuracy: 0.7630 - val_loss: 0.8870 - val_accuracy: 0.6154\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6044 - accuracy: 0.7556 - val_loss: 0.8922 - val_accuracy: 0.6068\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6109 - accuracy: 0.7481 - val_loss: 0.9039 - val_accuracy: 0.5983\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6165 - accuracy: 0.7333 - val_loss: 0.9039 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6252 - accuracy: 0.7556 - val_loss: 0.9039 - val_accuracy: 0.6068\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6146 - accuracy: 0.7444 - val_loss: 0.9147 - val_accuracy: 0.6154\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 72.40%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 3.58270770e-12, 3.05519420e-32],\n",
       "       [5.79007450e-01, 4.16257500e-01, 4.73508150e-03],\n",
       "       [7.00390250e-03, 4.20621600e-01, 5.72374500e-01],\n",
       "       [2.20451350e-02, 9.65308500e-02, 8.81423950e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.20507850e-03, 3.14842800e-03, 9.94646500e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.20451350e-02, 9.65308500e-02, 8.81423950e-01],\n",
       "       [7.01771260e-01, 2.03304290e-01, 9.49244500e-02],\n",
       "       [2.20451350e-02, 9.65308500e-02, 8.81423950e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [4.34442550e-01, 5.58801900e-01, 6.75554400e-03],\n",
       "       [1.28606190e-01, 4.65022770e-01, 4.06371030e-01],\n",
       "       [5.73673840e-01, 3.75396500e-01, 5.09297030e-02],\n",
       "       [7.22713300e-02, 9.27728350e-01, 3.11534250e-07],\n",
       "       [7.70858940e-01, 1.99726660e-01, 2.94143670e-02],\n",
       "       [1.00141570e-03, 8.93397300e-03, 9.90064700e-01],\n",
       "       [4.03541770e-01, 4.73057750e-01, 1.23400490e-01],\n",
       "       [5.61649000e-01, 4.34309750e-01, 4.04123960e-03],\n",
       "       [5.61649000e-01, 4.34309750e-01, 4.04123960e-03],\n",
       "       [2.83760220e-01, 6.71442100e-01, 4.47976500e-02],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.51442330e-03, 1.53305650e-02, 9.82155100e-01],\n",
       "       [2.84824500e-02, 1.88559400e-02, 9.52661600e-01],\n",
       "       [7.01771260e-01, 2.03304290e-01, 9.49244500e-02],\n",
       "       [7.72963760e-01, 2.27031050e-01, 5.12070160e-06],\n",
       "       [1.51898010e-01, 6.93306200e-01, 1.54795740e-01],\n",
       "       [4.26511170e-01, 1.91919370e-01, 3.81569470e-01],\n",
       "       [1.51898010e-01, 6.93306200e-01, 1.54795740e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [9.99156500e-01, 4.90498900e-04, 3.53000600e-04],\n",
       "       [5.17574200e-02, 4.34159130e-01, 5.14083400e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [3.83252020e-01, 5.63941960e-01, 5.28061050e-02],\n",
       "       [4.26511170e-01, 1.91919370e-01, 3.81569470e-01],\n",
       "       [6.46604400e-01, 6.65333100e-02, 2.86862280e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [3.26570870e-01, 2.09564920e-01, 4.63864240e-01],\n",
       "       [3.65434500e-01, 3.89652500e-01, 2.44913030e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [7.01771260e-01, 2.03304290e-01, 9.49244500e-02],\n",
       "       [3.17868350e-01, 5.37095550e-01, 1.45036090e-01],\n",
       "       [1.27523800e-01, 2.18374500e-01, 6.54101700e-01],\n",
       "       [2.55839530e-03, 1.36275930e-01, 8.61165700e-01],\n",
       "       [5.47188500e-03, 6.64780500e-02, 9.28050040e-01],\n",
       "       [9.99780500e-01, 2.19549420e-04, 1.20575740e-13],\n",
       "       [1.08507335e-01, 1.59488110e-01, 7.32004500e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [5.61649000e-01, 4.34309750e-01, 4.04123960e-03],\n",
       "       [5.17574200e-02, 4.34159130e-01, 5.14083400e-01],\n",
       "       [4.23095350e-01, 4.02450440e-01, 1.74454300e-01],\n",
       "       [9.62125600e-04, 3.03075440e-03, 9.96007140e-01],\n",
       "       [3.10137150e-01, 5.90572130e-02, 6.30805700e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [3.29637740e-01, 5.16306700e-01, 1.54055540e-01],\n",
       "       [2.51442330e-03, 1.53305650e-02, 9.82155100e-01],\n",
       "       [5.61649000e-01, 4.34309750e-01, 4.04123960e-03],\n",
       "       [5.62230100e-01, 4.31941630e-01, 5.82828700e-03],\n",
       "       [4.34442550e-01, 5.58801900e-01, 6.75554400e-03],\n",
       "       [1.08507335e-01, 1.59488110e-01, 7.32004500e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [9.11346850e-01, 8.86341600e-02, 1.90247250e-05],\n",
       "       [3.17868350e-01, 5.37095550e-01, 1.45036090e-01],\n",
       "       [5.51788660e-02, 1.42890130e-01, 8.01931100e-01],\n",
       "       [5.83277170e-01, 3.69651230e-01, 4.70716800e-02],\n",
       "       [5.21557750e-01, 2.31708340e-02, 4.55271360e-01],\n",
       "       [9.99156500e-01, 4.90498900e-04, 3.53000600e-04],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.83760220e-01, 6.71442100e-01, 4.47976500e-02],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [4.26511170e-01, 1.91919370e-01, 3.81569470e-01],\n",
       "       [6.04783400e-03, 1.90624970e-01, 8.03327200e-01],\n",
       "       [2.83760220e-01, 6.71442100e-01, 4.47976500e-02],\n",
       "       [1.08507335e-01, 1.59488110e-01, 7.32004500e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [1.27523800e-01, 2.18374500e-01, 6.54101700e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.16122680e-06, 8.65354400e-06, 9.99989150e-01],\n",
       "       [7.72963760e-01, 2.27031050e-01, 5.12070160e-06],\n",
       "       [7.00390250e-03, 4.20621600e-01, 5.72374500e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [6.05186000e-04, 9.99131000e-01, 2.63877850e-04],\n",
       "       [6.04783400e-03, 1.90624970e-01, 8.03327200e-01],\n",
       "       [9.71344800e-01, 2.36355900e-02, 5.01950400e-03],\n",
       "       [4.34442550e-01, 5.58801900e-01, 6.75554400e-03],\n",
       "       [1.51898010e-01, 6.93306200e-01, 1.54795740e-01],\n",
       "       [9.81071900e-03, 7.10254000e-02, 9.19163940e-01],\n",
       "       [5.62230100e-01, 4.31941630e-01, 5.82828700e-03],\n",
       "       [2.93896000e-03, 2.60897200e-01, 7.36163850e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.20507850e-03, 3.14842800e-03, 9.94646500e-01],\n",
       "       [2.20451350e-02, 9.65308500e-02, 8.81423950e-01],\n",
       "       [1.40902130e-01, 5.22555770e-01, 3.36542040e-01],\n",
       "       [2.84824500e-02, 1.88559400e-02, 9.52661600e-01],\n",
       "       [2.93896000e-03, 2.60897200e-01, 7.36163850e-01],\n",
       "       [4.03541770e-01, 4.73057750e-01, 1.23400490e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [5.62230100e-01, 4.31941630e-01, 5.82828700e-03],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [3.10511530e-04, 7.99654050e-03, 9.91692960e-01],\n",
       "       [3.97108800e-01, 3.80763620e-01, 2.22127570e-01],\n",
       "       [1.51898010e-01, 6.93306200e-01, 1.54795740e-01],\n",
       "       [6.13006000e-01, 2.22979130e-01, 1.64014820e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.93896000e-03, 2.60897200e-01, 7.36163850e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [9.28451360e-01, 7.15016900e-02, 4.69070400e-05],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01],\n",
       "       [8.91823200e-01, 9.33942350e-02, 1.47825960e-02],\n",
       "       [4.03541770e-01, 4.73057750e-01, 1.23400490e-01],\n",
       "       [2.18926730e-01, 6.35420000e-01, 1.45653280e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794214332675871"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794214332675871"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa25     1\n",
       "1       CFBRSa07     0\n",
       "2         NRS247     0\n",
       "3          NY439     2\n",
       "4    CFBREBSa110     1\n",
       "..           ...   ...\n",
       "112       SR1129     0\n",
       "113       NRS172     0\n",
       "114       NRS205     2\n",
       "115        NY439     2\n",
       "116       NRS249     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 494us/step - loss: 20.6109 - accuracy: 0.3444 - val_loss: 10.8528 - val_accuracy: 0.3162\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 16.2454 - accuracy: 0.3444 - val_loss: 8.5011 - val_accuracy: 0.3162\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 12.1546 - accuracy: 0.3407 - val_loss: 6.7370 - val_accuracy: 0.3846\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 9.6727 - accuracy: 0.3333 - val_loss: 6.9285 - val_accuracy: 0.4615\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 9.3167 - accuracy: 0.4000 - val_loss: 6.4189 - val_accuracy: 0.4615\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 8.4144 - accuracy: 0.4074 - val_loss: 5.5204 - val_accuracy: 0.4615\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 7.1365 - accuracy: 0.4333 - val_loss: 4.3494 - val_accuracy: 0.4786\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 5.5840 - accuracy: 0.4407 - val_loss: 3.4556 - val_accuracy: 0.4786\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 4.9112 - accuracy: 0.4148 - val_loss: 2.6885 - val_accuracy: 0.4530\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 3.7385 - accuracy: 0.3963 - val_loss: 2.5989 - val_accuracy: 0.4701\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 3.2068 - accuracy: 0.3963 - val_loss: 2.0789 - val_accuracy: 0.4786\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 2.3071 - accuracy: 0.4111 - val_loss: 1.8110 - val_accuracy: 0.4359\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 2.4865 - accuracy: 0.3926 - val_loss: 1.4212 - val_accuracy: 0.4274\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.8525 - accuracy: 0.3778 - val_loss: 1.3648 - val_accuracy: 0.4359\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.8102 - accuracy: 0.3963 - val_loss: 1.2264 - val_accuracy: 0.4615\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.6001 - accuracy: 0.4444 - val_loss: 1.2559 - val_accuracy: 0.4615\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.5751 - accuracy: 0.4185 - val_loss: 1.2339 - val_accuracy: 0.4274\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.5116 - accuracy: 0.4074 - val_loss: 1.2173 - val_accuracy: 0.4359\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.4720 - accuracy: 0.4148 - val_loss: 1.1776 - val_accuracy: 0.4530\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.5140 - accuracy: 0.4259 - val_loss: 1.1495 - val_accuracy: 0.4274\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.4178 - accuracy: 0.4037 - val_loss: 1.2026 - val_accuracy: 0.4188\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.4203 - accuracy: 0.3889 - val_loss: 1.2297 - val_accuracy: 0.4103\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.3739 - accuracy: 0.3852 - val_loss: 1.1019 - val_accuracy: 0.4359\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.2996 - accuracy: 0.3889 - val_loss: 1.1013 - val_accuracy: 0.4615\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.2836 - accuracy: 0.3704 - val_loss: 1.2225 - val_accuracy: 0.4188\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.3058 - accuracy: 0.3741 - val_loss: 1.1673 - val_accuracy: 0.4444\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.2205 - accuracy: 0.3778 - val_loss: 1.0797 - val_accuracy: 0.4872\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.1826 - accuracy: 0.4444 - val_loss: 1.0835 - val_accuracy: 0.4957\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.1450 - accuracy: 0.4074 - val_loss: 1.0833 - val_accuracy: 0.4530\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.1489 - accuracy: 0.4148 - val_loss: 1.0729 - val_accuracy: 0.4615\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.1318 - accuracy: 0.4037 - val_loss: 1.0963 - val_accuracy: 0.4615\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.1245 - accuracy: 0.4593 - val_loss: 1.0663 - val_accuracy: 0.4872\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0807 - accuracy: 0.4815 - val_loss: 1.0568 - val_accuracy: 0.5299\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0642 - accuracy: 0.4556 - val_loss: 1.0697 - val_accuracy: 0.4444\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0473 - accuracy: 0.4778 - val_loss: 1.0495 - val_accuracy: 0.5214\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0635 - accuracy: 0.4630 - val_loss: 1.0466 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0280 - accuracy: 0.4704 - val_loss: 1.0493 - val_accuracy: 0.4274\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0246 - accuracy: 0.4704 - val_loss: 1.0700 - val_accuracy: 0.5299\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0695 - accuracy: 0.5222 - val_loss: 1.0564 - val_accuracy: 0.4701\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0494 - accuracy: 0.4519 - val_loss: 1.0769 - val_accuracy: 0.5214\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0992 - accuracy: 0.5333 - val_loss: 1.0423 - val_accuracy: 0.5385\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1420 - accuracy: 0.4741 - val_loss: 1.0416 - val_accuracy: 0.5470\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 1.0276 - accuracy: 0.5185 - val_loss: 1.0412 - val_accuracy: 0.5214\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 1.0345 - accuracy: 0.5074 - val_loss: 1.0838 - val_accuracy: 0.5385\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0590 - accuracy: 0.5222 - val_loss: 1.0383 - val_accuracy: 0.4786\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.9902 - accuracy: 0.5370 - val_loss: 1.0344 - val_accuracy: 0.5214\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9982 - accuracy: 0.5259 - val_loss: 1.0374 - val_accuracy: 0.5214\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0049 - accuracy: 0.5259 - val_loss: 1.0360 - val_accuracy: 0.5470\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0148 - accuracy: 0.5111 - val_loss: 1.0463 - val_accuracy: 0.5299\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0360 - accuracy: 0.5259 - val_loss: 1.0411 - val_accuracy: 0.5214\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9957 - accuracy: 0.5222 - val_loss: 1.0319 - val_accuracy: 0.5556\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9957 - accuracy: 0.5222 - val_loss: 1.0330 - val_accuracy: 0.5299\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0086 - accuracy: 0.5074 - val_loss: 1.0488 - val_accuracy: 0.5128\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9879 - accuracy: 0.5222 - val_loss: 1.0276 - val_accuracy: 0.5556\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9860 - accuracy: 0.5111 - val_loss: 1.0335 - val_accuracy: 0.5299\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0506 - accuracy: 0.5296 - val_loss: 1.1129 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.1689 - accuracy: 0.5889 - val_loss: 1.1299 - val_accuracy: 0.5385\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9860 - accuracy: 0.5852 - val_loss: 1.1243 - val_accuracy: 0.5214\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.1285 - accuracy: 0.5222 - val_loss: 1.1082 - val_accuracy: 0.5470\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.0950 - accuracy: 0.5815 - val_loss: 1.0600 - val_accuracy: 0.5128\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9796 - accuracy: 0.5407 - val_loss: 1.0755 - val_accuracy: 0.5128\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0639 - accuracy: 0.5481 - val_loss: 1.1134 - val_accuracy: 0.5470\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0536 - accuracy: 0.5889 - val_loss: 1.0247 - val_accuracy: 0.5299\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0301 - accuracy: 0.5185 - val_loss: 1.0488 - val_accuracy: 0.5470\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0425 - accuracy: 0.5852 - val_loss: 1.0831 - val_accuracy: 0.5470\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0119 - accuracy: 0.5926 - val_loss: 1.0452 - val_accuracy: 0.5299\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9993 - accuracy: 0.5593 - val_loss: 1.0286 - val_accuracy: 0.5470\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9689 - accuracy: 0.5963 - val_loss: 1.0593 - val_accuracy: 0.5385\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.2208 - accuracy: 0.5741 - val_loss: 1.3396 - val_accuracy: 0.5385\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.3753 - accuracy: 0.5741 - val_loss: 1.2094 - val_accuracy: 0.5470\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.1146 - accuracy: 0.5556 - val_loss: 1.0497 - val_accuracy: 0.4957\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0106 - accuracy: 0.5111 - val_loss: 1.0596 - val_accuracy: 0.5385\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0409 - accuracy: 0.5370 - val_loss: 1.1298 - val_accuracy: 0.5470\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 1.0708 - accuracy: 0.5778 - val_loss: 1.0269 - val_accuracy: 0.5556\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.0102 - accuracy: 0.5556 - val_loss: 1.0463 - val_accuracy: 0.5556\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 1.2236 - accuracy: 0.5519 - val_loss: 1.2492 - val_accuracy: 0.4530\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.1809 - accuracy: 0.5296 - val_loss: 1.0281 - val_accuracy: 0.5470\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0501 - accuracy: 0.5741 - val_loss: 1.0661 - val_accuracy: 0.5641\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.2067 - accuracy: 0.5704 - val_loss: 1.3958 - val_accuracy: 0.5556\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.4601 - accuracy: 0.5741 - val_loss: 1.2954 - val_accuracy: 0.5470\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 1.2444 - accuracy: 0.5185 - val_loss: 1.0731 - val_accuracy: 0.5043\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.9939 - accuracy: 0.5111 - val_loss: 1.0902 - val_accuracy: 0.4872\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0451 - accuracy: 0.5519 - val_loss: 1.1784 - val_accuracy: 0.5556\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1154 - accuracy: 0.5852 - val_loss: 1.0711 - val_accuracy: 0.5299\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0069 - accuracy: 0.5481 - val_loss: 1.0282 - val_accuracy: 0.5641\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9433 - accuracy: 0.6000 - val_loss: 1.0352 - val_accuracy: 0.5470\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9507 - accuracy: 0.5815 - val_loss: 1.0358 - val_accuracy: 0.5726\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9337 - accuracy: 0.6222 - val_loss: 1.0555 - val_accuracy: 0.5641\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9572 - accuracy: 0.6074 - val_loss: 1.0274 - val_accuracy: 0.5641\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.9250 - accuracy: 0.5815 - val_loss: 1.0265 - val_accuracy: 0.5726\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9214 - accuracy: 0.6000 - val_loss: 1.0386 - val_accuracy: 0.5470\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9409 - accuracy: 0.6000 - val_loss: 1.0258 - val_accuracy: 0.5556\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9978 - accuracy: 0.5889 - val_loss: 1.0432 - val_accuracy: 0.5470\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9572 - accuracy: 0.5815 - val_loss: 1.0531 - val_accuracy: 0.5299\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9442 - accuracy: 0.5926 - val_loss: 1.0335 - val_accuracy: 0.5556\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9138 - accuracy: 0.5963 - val_loss: 1.0238 - val_accuracy: 0.5726\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9180 - accuracy: 0.5889 - val_loss: 1.0108 - val_accuracy: 0.5726\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9046 - accuracy: 0.6037 - val_loss: 1.0068 - val_accuracy: 0.5812\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9039 - accuracy: 0.6222 - val_loss: 1.0073 - val_accuracy: 0.5556\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9110 - accuracy: 0.5889 - val_loss: 1.0094 - val_accuracy: 0.5556\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9080 - accuracy: 0.6148 - val_loss: 1.0132 - val_accuracy: 0.5385\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9067 - accuracy: 0.6185 - val_loss: 1.0113 - val_accuracy: 0.5470\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8988 - accuracy: 0.6074 - val_loss: 1.0089 - val_accuracy: 0.5470\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8970 - accuracy: 0.6259 - val_loss: 1.0046 - val_accuracy: 0.5470\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9012 - accuracy: 0.6148 - val_loss: 1.0004 - val_accuracy: 0.5641\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8973 - accuracy: 0.6148 - val_loss: 0.9990 - val_accuracy: 0.5726\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8988 - accuracy: 0.6296 - val_loss: 0.9972 - val_accuracy: 0.5641\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9010 - accuracy: 0.6185 - val_loss: 0.9948 - val_accuracy: 0.5726\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8989 - accuracy: 0.6333 - val_loss: 0.9988 - val_accuracy: 0.5556\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9010 - accuracy: 0.5741 - val_loss: 1.0031 - val_accuracy: 0.5128\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9009 - accuracy: 0.5778 - val_loss: 0.9947 - val_accuracy: 0.5556\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8881 - accuracy: 0.6259 - val_loss: 0.9917 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9274 - accuracy: 0.6074 - val_loss: 0.9881 - val_accuracy: 0.5641\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9210 - accuracy: 0.5963 - val_loss: 1.0149 - val_accuracy: 0.5470\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9234 - accuracy: 0.6000 - val_loss: 1.0112 - val_accuracy: 0.5726\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8977 - accuracy: 0.6074 - val_loss: 1.0047 - val_accuracy: 0.5641\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9228 - accuracy: 0.6222 - val_loss: 0.9996 - val_accuracy: 0.5641\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8974 - accuracy: 0.6222 - val_loss: 0.9877 - val_accuracy: 0.5556\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8852 - accuracy: 0.6370 - val_loss: 0.9967 - val_accuracy: 0.5470\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8911 - accuracy: 0.6296 - val_loss: 0.9877 - val_accuracy: 0.5556\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8804 - accuracy: 0.6296 - val_loss: 0.9834 - val_accuracy: 0.5641\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8808 - accuracy: 0.6259 - val_loss: 0.9868 - val_accuracy: 0.5812\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9030 - accuracy: 0.6259 - val_loss: 1.0215 - val_accuracy: 0.5726\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9742 - accuracy: 0.6037 - val_loss: 1.0107 - val_accuracy: 0.5726\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8944 - accuracy: 0.6148 - val_loss: 1.0195 - val_accuracy: 0.5214\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8997 - accuracy: 0.6185 - val_loss: 1.0305 - val_accuracy: 0.5641\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.9445 - accuracy: 0.6148 - val_loss: 0.9828 - val_accuracy: 0.5641\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9440 - accuracy: 0.6185 - val_loss: 1.0130 - val_accuracy: 0.5556\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9476 - accuracy: 0.6111 - val_loss: 1.0031 - val_accuracy: 0.5641\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8669 - accuracy: 0.6444 - val_loss: 1.0407 - val_accuracy: 0.5641\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0113 - accuracy: 0.6148 - val_loss: 1.0972 - val_accuracy: 0.5556\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0066 - accuracy: 0.6037 - val_loss: 1.0029 - val_accuracy: 0.5470\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8949 - accuracy: 0.6370 - val_loss: 1.0044 - val_accuracy: 0.4957\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8855 - accuracy: 0.6519 - val_loss: 0.9820 - val_accuracy: 0.5641\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8806 - accuracy: 0.6259 - val_loss: 0.9876 - val_accuracy: 0.5641\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8766 - accuracy: 0.6111 - val_loss: 0.9805 - val_accuracy: 0.5556\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8643 - accuracy: 0.6296 - val_loss: 0.9864 - val_accuracy: 0.5641\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8984 - accuracy: 0.5963 - val_loss: 0.9759 - val_accuracy: 0.5470\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8792 - accuracy: 0.6333 - val_loss: 0.9959 - val_accuracy: 0.5470\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9059 - accuracy: 0.6185 - val_loss: 0.9778 - val_accuracy: 0.5385\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8938 - accuracy: 0.5889 - val_loss: 0.9893 - val_accuracy: 0.5470\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8668 - accuracy: 0.6148 - val_loss: 0.9896 - val_accuracy: 0.5470\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8734 - accuracy: 0.6556 - val_loss: 1.0062 - val_accuracy: 0.5726\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9267 - accuracy: 0.5926 - val_loss: 1.0488 - val_accuracy: 0.4786\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0198 - accuracy: 0.5815 - val_loss: 1.0283 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8964 - accuracy: 0.6444 - val_loss: 1.0212 - val_accuracy: 0.5214\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8719 - accuracy: 0.6630 - val_loss: 1.0212 - val_accuracy: 0.5897\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9240 - accuracy: 0.6333 - val_loss: 0.9837 - val_accuracy: 0.5385\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8710 - accuracy: 0.6296 - val_loss: 0.9804 - val_accuracy: 0.5385\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8727 - accuracy: 0.6481 - val_loss: 0.9817 - val_accuracy: 0.5641\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8654 - accuracy: 0.6259 - val_loss: 0.9761 - val_accuracy: 0.5470\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8569 - accuracy: 0.6407 - val_loss: 0.9808 - val_accuracy: 0.5556\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8586 - accuracy: 0.6481 - val_loss: 0.9805 - val_accuracy: 0.5641\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8557 - accuracy: 0.6593 - val_loss: 0.9765 - val_accuracy: 0.5556\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8608 - accuracy: 0.6148 - val_loss: 0.9808 - val_accuracy: 0.5726\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8779 - accuracy: 0.6259 - val_loss: 1.0248 - val_accuracy: 0.5812\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9449 - accuracy: 0.6111 - val_loss: 0.9712 - val_accuracy: 0.5641\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8826 - accuracy: 0.6111 - val_loss: 0.9825 - val_accuracy: 0.5556\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8974 - accuracy: 0.6593 - val_loss: 0.9924 - val_accuracy: 0.5556\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8628 - accuracy: 0.6519 - val_loss: 0.9959 - val_accuracy: 0.5299\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8563 - accuracy: 0.6407 - val_loss: 0.9857 - val_accuracy: 0.5385\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8733 - accuracy: 0.6407 - val_loss: 0.9688 - val_accuracy: 0.5385\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8537 - accuracy: 0.6222 - val_loss: 0.9711 - val_accuracy: 0.5470\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8499 - accuracy: 0.6407 - val_loss: 0.9719 - val_accuracy: 0.5641\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8717 - accuracy: 0.6519 - val_loss: 0.9845 - val_accuracy: 0.5726\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8504 - accuracy: 0.6519 - val_loss: 0.9900 - val_accuracy: 0.5726\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8548 - accuracy: 0.6593 - val_loss: 1.0206 - val_accuracy: 0.5983\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9481 - accuracy: 0.6296 - val_loss: 0.9841 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.2215 - accuracy: 0.6037 - val_loss: 0.9846 - val_accuracy: 0.5641\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.9233 - accuracy: 0.6222 - val_loss: 1.1958 - val_accuracy: 0.6239\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.1523 - accuracy: 0.6185 - val_loss: 1.0909 - val_accuracy: 0.5470\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9485 - accuracy: 0.6037 - val_loss: 1.0260 - val_accuracy: 0.5214\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8661 - accuracy: 0.6370 - val_loss: 0.9958 - val_accuracy: 0.5641\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8711 - accuracy: 0.6222 - val_loss: 0.9983 - val_accuracy: 0.5641\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8629 - accuracy: 0.6333 - val_loss: 1.0012 - val_accuracy: 0.5641\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8865 - accuracy: 0.6444 - val_loss: 0.9792 - val_accuracy: 0.5556\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8664 - accuracy: 0.6556 - val_loss: 0.9770 - val_accuracy: 0.5641\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8715 - accuracy: 0.6593 - val_loss: 0.9733 - val_accuracy: 0.5641\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8610 - accuracy: 0.6704 - val_loss: 0.9740 - val_accuracy: 0.5641\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8561 - accuracy: 0.6630 - val_loss: 0.9960 - val_accuracy: 0.5726\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0750 - accuracy: 0.6259 - val_loss: 1.2002 - val_accuracy: 0.5726\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.6025 - accuracy: 0.5370 - val_loss: 2.2837 - val_accuracy: 0.4957\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 2.6513 - accuracy: 0.5444 - val_loss: 2.1454 - val_accuracy: 0.5641\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 2.3961 - accuracy: 0.5667 - val_loss: 1.8073 - val_accuracy: 0.5470\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.8863 - accuracy: 0.5741 - val_loss: 1.5170 - val_accuracy: 0.5043\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.3520 - accuracy: 0.5259 - val_loss: 1.0765 - val_accuracy: 0.4444\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0600 - accuracy: 0.5370 - val_loss: 1.0565 - val_accuracy: 0.5385\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0226 - accuracy: 0.6111 - val_loss: 1.1389 - val_accuracy: 0.5641\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0042 - accuracy: 0.6185 - val_loss: 1.0003 - val_accuracy: 0.5556\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8970 - accuracy: 0.6481 - val_loss: 1.0133 - val_accuracy: 0.5641\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9649 - accuracy: 0.6481 - val_loss: 1.1144 - val_accuracy: 0.5897\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9751 - accuracy: 0.6444 - val_loss: 1.0161 - val_accuracy: 0.5556\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8889 - accuracy: 0.6407 - val_loss: 1.0429 - val_accuracy: 0.5299\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0160 - accuracy: 0.6444 - val_loss: 1.0642 - val_accuracy: 0.5470\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8817 - accuracy: 0.5963 - val_loss: 1.0427 - val_accuracy: 0.5556\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9071 - accuracy: 0.6481 - val_loss: 1.0656 - val_accuracy: 0.5556\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9118 - accuracy: 0.6593 - val_loss: 1.0061 - val_accuracy: 0.5641\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8516 - accuracy: 0.6593 - val_loss: 1.0017 - val_accuracy: 0.5641\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9202 - accuracy: 0.6111 - val_loss: 1.0344 - val_accuracy: 0.5897\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8756 - accuracy: 0.6556 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8605 - accuracy: 0.6519 - val_loss: 1.0061 - val_accuracy: 0.5726\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8639 - accuracy: 0.6185 - val_loss: 0.9999 - val_accuracy: 0.5641\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9224 - accuracy: 0.6370 - val_loss: 1.0202 - val_accuracy: 0.5128\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8667 - accuracy: 0.6519 - val_loss: 0.9907 - val_accuracy: 0.5470\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8370 - accuracy: 0.6519 - val_loss: 1.0012 - val_accuracy: 0.5299\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8452 - accuracy: 0.6556 - val_loss: 0.9954 - val_accuracy: 0.5726\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8392 - accuracy: 0.6519 - val_loss: 0.9847 - val_accuracy: 0.5726\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8290 - accuracy: 0.6481 - val_loss: 0.9955 - val_accuracy: 0.5726\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8411 - accuracy: 0.6630 - val_loss: 0.9920 - val_accuracy: 0.5556\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8659 - accuracy: 0.6259 - val_loss: 0.9896 - val_accuracy: 0.5556\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8342 - accuracy: 0.6556 - val_loss: 0.9953 - val_accuracy: 0.5726\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8319 - accuracy: 0.6593 - val_loss: 0.9879 - val_accuracy: 0.5641\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8387 - accuracy: 0.6593 - val_loss: 0.9799 - val_accuracy: 0.5556\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 407us/step - loss: 0.8420 - accuracy: 0.6556 - val_loss: 0.9798 - val_accuracy: 0.5726\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8330 - accuracy: 0.6519 - val_loss: 0.9902 - val_accuracy: 0.5726\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8377 - accuracy: 0.6370 - val_loss: 0.9897 - val_accuracy: 0.5726\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8494 - accuracy: 0.6556 - val_loss: 0.9998 - val_accuracy: 0.5812\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8586 - accuracy: 0.6667 - val_loss: 0.9913 - val_accuracy: 0.5641\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8393 - accuracy: 0.6667 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8302 - accuracy: 0.6593 - val_loss: 0.9744 - val_accuracy: 0.5556\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8284 - accuracy: 0.6667 - val_loss: 0.9711 - val_accuracy: 0.5470\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8256 - accuracy: 0.6630 - val_loss: 0.9731 - val_accuracy: 0.5385\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8356 - accuracy: 0.6556 - val_loss: 0.9721 - val_accuracy: 0.5470\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8306 - accuracy: 0.6704 - val_loss: 0.9811 - val_accuracy: 0.5641\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8643 - accuracy: 0.6667 - val_loss: 1.0487 - val_accuracy: 0.5641\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9020 - accuracy: 0.6481 - val_loss: 0.9776 - val_accuracy: 0.5385\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8383 - accuracy: 0.6519 - val_loss: 0.9767 - val_accuracy: 0.5641\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8455 - accuracy: 0.6667 - val_loss: 0.9734 - val_accuracy: 0.5556\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8290 - accuracy: 0.6667 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8304 - accuracy: 0.6593 - val_loss: 0.9785 - val_accuracy: 0.5641\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8347 - accuracy: 0.6556 - val_loss: 0.9876 - val_accuracy: 0.5641\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8205 - accuracy: 0.6815 - val_loss: 0.9835 - val_accuracy: 0.5897\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8670 - accuracy: 0.6481 - val_loss: 0.9647 - val_accuracy: 0.5556\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8475 - accuracy: 0.6630 - val_loss: 1.0025 - val_accuracy: 0.5812\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8677 - accuracy: 0.6815 - val_loss: 0.9755 - val_accuracy: 0.5385\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8423 - accuracy: 0.6333 - val_loss: 0.9735 - val_accuracy: 0.5556\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8198 - accuracy: 0.6667 - val_loss: 0.9762 - val_accuracy: 0.5556\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8187 - accuracy: 0.6519 - val_loss: 0.9760 - val_accuracy: 0.5726\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8335 - accuracy: 0.6667 - val_loss: 0.9655 - val_accuracy: 0.5726\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8195 - accuracy: 0.6630 - val_loss: 0.9692 - val_accuracy: 0.5641\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8250 - accuracy: 0.6778 - val_loss: 0.9764 - val_accuracy: 0.5641\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8204 - accuracy: 0.6704 - val_loss: 0.9699 - val_accuracy: 0.5726\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8245 - accuracy: 0.6556 - val_loss: 0.9691 - val_accuracy: 0.5641\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8205 - accuracy: 0.6667 - val_loss: 0.9695 - val_accuracy: 0.5726\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8249 - accuracy: 0.6741 - val_loss: 0.9741 - val_accuracy: 0.5470\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8253 - accuracy: 0.6667 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8268 - accuracy: 0.6889 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8231 - accuracy: 0.6778 - val_loss: 0.9798 - val_accuracy: 0.5556\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8340 - accuracy: 0.6815 - val_loss: 0.9929 - val_accuracy: 0.5299\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8415 - accuracy: 0.6778 - val_loss: 1.0002 - val_accuracy: 0.5641\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8649 - accuracy: 0.6444 - val_loss: 0.9786 - val_accuracy: 0.5385\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8268 - accuracy: 0.6704 - val_loss: 0.9845 - val_accuracy: 0.5299\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8139 - accuracy: 0.6815 - val_loss: 0.9783 - val_accuracy: 0.5470\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8203 - accuracy: 0.6556 - val_loss: 0.9772 - val_accuracy: 0.5556\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8676 - accuracy: 0.6630 - val_loss: 1.0101 - val_accuracy: 0.5043\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8376 - accuracy: 0.6556 - val_loss: 0.9954 - val_accuracy: 0.5556\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8234 - accuracy: 0.6481 - val_loss: 0.9724 - val_accuracy: 0.5556\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8288 - accuracy: 0.6815 - val_loss: 0.9822 - val_accuracy: 0.5470\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8539 - accuracy: 0.6556 - val_loss: 1.0062 - val_accuracy: 0.5726\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9205 - accuracy: 0.6630 - val_loss: 1.0288 - val_accuracy: 0.5983\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8851 - accuracy: 0.6148 - val_loss: 1.0292 - val_accuracy: 0.5385\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8531 - accuracy: 0.6556 - val_loss: 1.0521 - val_accuracy: 0.5641\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9304 - accuracy: 0.6519 - val_loss: 0.9953 - val_accuracy: 0.5726\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8174 - accuracy: 0.6704 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8163 - accuracy: 0.6704 - val_loss: 0.9762 - val_accuracy: 0.5641\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8247 - accuracy: 0.6481 - val_loss: 0.9706 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8145 - accuracy: 0.6778 - val_loss: 0.9779 - val_accuracy: 0.5556\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8141 - accuracy: 0.6556 - val_loss: 0.9757 - val_accuracy: 0.5470\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7998 - accuracy: 0.6630 - val_loss: 0.9853 - val_accuracy: 0.5983\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8368 - accuracy: 0.6519 - val_loss: 0.9700 - val_accuracy: 0.5385\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8095 - accuracy: 0.6556 - val_loss: 0.9679 - val_accuracy: 0.5641\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8085 - accuracy: 0.6704 - val_loss: 0.9644 - val_accuracy: 0.5556\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8027 - accuracy: 0.6778 - val_loss: 0.9651 - val_accuracy: 0.5641\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8049 - accuracy: 0.6704 - val_loss: 0.9796 - val_accuracy: 0.5556\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8113 - accuracy: 0.6556 - val_loss: 0.9923 - val_accuracy: 0.6068\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8340 - accuracy: 0.6667 - val_loss: 0.9704 - val_accuracy: 0.5385\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8051 - accuracy: 0.6667 - val_loss: 0.9693 - val_accuracy: 0.5385\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8027 - accuracy: 0.6370 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8018 - accuracy: 0.6593 - val_loss: 0.9708 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8086 - accuracy: 0.6704 - val_loss: 0.9778 - val_accuracy: 0.6154\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8481 - accuracy: 0.6519 - val_loss: 0.9807 - val_accuracy: 0.6068\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8050 - accuracy: 0.6741 - val_loss: 0.9735 - val_accuracy: 0.5556\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7966 - accuracy: 0.6704 - val_loss: 0.9867 - val_accuracy: 0.6239\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8200 - accuracy: 0.6630 - val_loss: 0.9721 - val_accuracy: 0.5556\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8119 - accuracy: 0.6741 - val_loss: 0.9753 - val_accuracy: 0.5641\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8237 - accuracy: 0.6630 - val_loss: 0.9876 - val_accuracy: 0.5641\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8259 - accuracy: 0.6593 - val_loss: 0.9944 - val_accuracy: 0.5897\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8329 - accuracy: 0.6704 - val_loss: 0.9804 - val_accuracy: 0.5641\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8093 - accuracy: 0.6630 - val_loss: 0.9711 - val_accuracy: 0.5470\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8297 - accuracy: 0.6704 - val_loss: 0.9837 - val_accuracy: 0.5812\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8197 - accuracy: 0.6704 - val_loss: 0.9676 - val_accuracy: 0.5556\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8026 - accuracy: 0.6852 - val_loss: 0.9706 - val_accuracy: 0.5470\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7936 - accuracy: 0.6926 - val_loss: 0.9840 - val_accuracy: 0.5726\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8219 - accuracy: 0.6704 - val_loss: 0.9824 - val_accuracy: 0.5470\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8089 - accuracy: 0.6778 - val_loss: 0.9696 - val_accuracy: 0.5556\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8011 - accuracy: 0.6815 - val_loss: 0.9712 - val_accuracy: 0.5641\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7929 - accuracy: 0.6704 - val_loss: 0.9899 - val_accuracy: 0.5470\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8143 - accuracy: 0.6593 - val_loss: 0.9906 - val_accuracy: 0.5812\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8342 - accuracy: 0.6556 - val_loss: 0.9767 - val_accuracy: 0.5641\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8027 - accuracy: 0.6815 - val_loss: 0.9756 - val_accuracy: 0.5641\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8818 - accuracy: 0.6667 - val_loss: 1.0050 - val_accuracy: 0.6154\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8931 - accuracy: 0.6593 - val_loss: 0.9944 - val_accuracy: 0.5641\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9097 - accuracy: 0.6556 - val_loss: 1.2651 - val_accuracy: 0.5897\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1614 - accuracy: 0.6333 - val_loss: 1.1096 - val_accuracy: 0.5726\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8764 - accuracy: 0.6000 - val_loss: 1.2331 - val_accuracy: 0.4786\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 1.1213 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.5470\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.1083 - accuracy: 0.6444 - val_loss: 1.1511 - val_accuracy: 0.5726\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9664 - accuracy: 0.6222 - val_loss: 1.0158 - val_accuracy: 0.5641\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9298 - accuracy: 0.6333 - val_loss: 1.1670 - val_accuracy: 0.5470\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.0071 - accuracy: 0.6185 - val_loss: 1.0303 - val_accuracy: 0.6154\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8930 - accuracy: 0.6259 - val_loss: 1.0065 - val_accuracy: 0.5556\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8405 - accuracy: 0.6704 - val_loss: 1.0788 - val_accuracy: 0.5641\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8600 - accuracy: 0.6667 - val_loss: 1.0235 - val_accuracy: 0.5641\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9562 - accuracy: 0.6333 - val_loss: 1.0467 - val_accuracy: 0.5641\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 1.3209 - accuracy: 0.6148 - val_loss: 1.8688 - val_accuracy: 0.5641\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.6337 - accuracy: 0.5926 - val_loss: 1.4510 - val_accuracy: 0.5214\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.1778 - accuracy: 0.6000 - val_loss: 1.2033 - val_accuracy: 0.4957\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9233 - accuracy: 0.6037 - val_loss: 1.2495 - val_accuracy: 0.5385\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0743 - accuracy: 0.5963 - val_loss: 1.1396 - val_accuracy: 0.5726\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8994 - accuracy: 0.6667 - val_loss: 1.0494 - val_accuracy: 0.5641\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8523 - accuracy: 0.6556 - val_loss: 1.0316 - val_accuracy: 0.5641\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8369 - accuracy: 0.6593 - val_loss: 1.0229 - val_accuracy: 0.5556\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8067 - accuracy: 0.6556 - val_loss: 1.0177 - val_accuracy: 0.5385\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8114 - accuracy: 0.6519 - val_loss: 1.0384 - val_accuracy: 0.5641\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8203 - accuracy: 0.6519 - val_loss: 1.0289 - val_accuracy: 0.5641\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8079 - accuracy: 0.6778 - val_loss: 1.0032 - val_accuracy: 0.5556\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7963 - accuracy: 0.6704 - val_loss: 1.0050 - val_accuracy: 0.5641\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8061 - accuracy: 0.6778 - val_loss: 0.9997 - val_accuracy: 0.5470\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7988 - accuracy: 0.6889 - val_loss: 1.0001 - val_accuracy: 0.5641\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8140 - accuracy: 0.6556 - val_loss: 1.0098 - val_accuracy: 0.5556\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7942 - accuracy: 0.6593 - val_loss: 0.9924 - val_accuracy: 0.4701\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7976 - accuracy: 0.6333 - val_loss: 0.9937 - val_accuracy: 0.4530\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8006 - accuracy: 0.6074 - val_loss: 1.0043 - val_accuracy: 0.5726\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8012 - accuracy: 0.6630 - val_loss: 1.0022 - val_accuracy: 0.5641\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8009 - accuracy: 0.6704 - val_loss: 0.9877 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8010 - accuracy: 0.6778 - val_loss: 0.9843 - val_accuracy: 0.5641\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8052 - accuracy: 0.6704 - val_loss: 0.9864 - val_accuracy: 0.5556\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7962 - accuracy: 0.6667 - val_loss: 0.9825 - val_accuracy: 0.5726\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8037 - accuracy: 0.6778 - val_loss: 0.9769 - val_accuracy: 0.5470\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7882 - accuracy: 0.6778 - val_loss: 0.9822 - val_accuracy: 0.5556\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7858 - accuracy: 0.6741 - val_loss: 0.9771 - val_accuracy: 0.5641\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7883 - accuracy: 0.6926 - val_loss: 0.9800 - val_accuracy: 0.5470\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7865 - accuracy: 0.6815 - val_loss: 0.9751 - val_accuracy: 0.5641\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7894 - accuracy: 0.6630 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7902 - accuracy: 0.6778 - val_loss: 0.9682 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8035 - accuracy: 0.6815 - val_loss: 0.9665 - val_accuracy: 0.5726\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7868 - accuracy: 0.6889 - val_loss: 0.9743 - val_accuracy: 0.5641\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7878 - accuracy: 0.6852 - val_loss: 0.9693 - val_accuracy: 0.5641\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7794 - accuracy: 0.6926 - val_loss: 0.9759 - val_accuracy: 0.5556\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7937 - accuracy: 0.6630 - val_loss: 0.9765 - val_accuracy: 0.6154\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8015 - accuracy: 0.6704 - val_loss: 0.9739 - val_accuracy: 0.5556\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7820 - accuracy: 0.6778 - val_loss: 0.9741 - val_accuracy: 0.5556\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7780 - accuracy: 0.6889 - val_loss: 0.9781 - val_accuracy: 0.6154\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8517 - accuracy: 0.6815 - val_loss: 0.9941 - val_accuracy: 0.6239\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8216 - accuracy: 0.6667 - val_loss: 0.9876 - val_accuracy: 0.5641\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7787 - accuracy: 0.6815 - val_loss: 0.9781 - val_accuracy: 0.5726\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7934 - accuracy: 0.6815 - val_loss: 0.9754 - val_accuracy: 0.5556\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7927 - accuracy: 0.6741 - val_loss: 0.9809 - val_accuracy: 0.5470\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7841 - accuracy: 0.6667 - val_loss: 0.9749 - val_accuracy: 0.5641\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8078 - accuracy: 0.6593 - val_loss: 0.9750 - val_accuracy: 0.5641\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8461 - accuracy: 0.6741 - val_loss: 1.0186 - val_accuracy: 0.6325\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8602 - accuracy: 0.6741 - val_loss: 0.9892 - val_accuracy: 0.5812\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7947 - accuracy: 0.6667 - val_loss: 1.0120 - val_accuracy: 0.5128\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8388 - accuracy: 0.6481 - val_loss: 1.0415 - val_accuracy: 0.5043\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8258 - accuracy: 0.6704 - val_loss: 0.9803 - val_accuracy: 0.5556\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8255 - accuracy: 0.6444 - val_loss: 1.0593 - val_accuracy: 0.5470\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8364 - accuracy: 0.6630 - val_loss: 1.0193 - val_accuracy: 0.4957\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8942 - accuracy: 0.6222 - val_loss: 0.9999 - val_accuracy: 0.5299\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8021 - accuracy: 0.6704 - val_loss: 0.9808 - val_accuracy: 0.5556\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8454 - accuracy: 0.6519 - val_loss: 1.0413 - val_accuracy: 0.5470\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8804 - accuracy: 0.6296 - val_loss: 1.0137 - val_accuracy: 0.6239\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8341 - accuracy: 0.6630 - val_loss: 1.0750 - val_accuracy: 0.5470\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8333 - accuracy: 0.6333 - val_loss: 1.0195 - val_accuracy: 0.5556\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8647 - accuracy: 0.6444 - val_loss: 1.1312 - val_accuracy: 0.5812\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.4528 - accuracy: 0.6111 - val_loss: 1.7914 - val_accuracy: 0.5812\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 1.8871 - accuracy: 0.6481 - val_loss: 1.7348 - val_accuracy: 0.5641\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.7333 - accuracy: 0.6148 - val_loss: 1.3892 - val_accuracy: 0.5983\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.2257 - accuracy: 0.5778 - val_loss: 1.1469 - val_accuracy: 0.4274\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0470 - accuracy: 0.5556 - val_loss: 1.0277 - val_accuracy: 0.5470\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8244 - accuracy: 0.6630 - val_loss: 1.1491 - val_accuracy: 0.5641\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9616 - accuracy: 0.6370 - val_loss: 1.0199 - val_accuracy: 0.5726\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8135 - accuracy: 0.6593 - val_loss: 0.9957 - val_accuracy: 0.5641\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8317 - accuracy: 0.6741 - val_loss: 1.0302 - val_accuracy: 0.5726\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8139 - accuracy: 0.6778 - val_loss: 1.0232 - val_accuracy: 0.5641\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8065 - accuracy: 0.6667 - val_loss: 1.0066 - val_accuracy: 0.5641\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7840 - accuracy: 0.6704 - val_loss: 0.9959 - val_accuracy: 0.5641\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7928 - accuracy: 0.6815 - val_loss: 0.9998 - val_accuracy: 0.5470\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7815 - accuracy: 0.6630 - val_loss: 1.0005 - val_accuracy: 0.5470\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7792 - accuracy: 0.6852 - val_loss: 0.9916 - val_accuracy: 0.5556\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7758 - accuracy: 0.6889 - val_loss: 1.0002 - val_accuracy: 0.5556\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7746 - accuracy: 0.6815 - val_loss: 0.9886 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7778 - accuracy: 0.7000 - val_loss: 0.9910 - val_accuracy: 0.5556\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7801 - accuracy: 0.6741 - val_loss: 0.9953 - val_accuracy: 0.5556\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7811 - accuracy: 0.6852 - val_loss: 0.9908 - val_accuracy: 0.5812\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7743 - accuracy: 0.7037 - val_loss: 0.9918 - val_accuracy: 0.5641\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7763 - accuracy: 0.6852 - val_loss: 0.9831 - val_accuracy: 0.5641\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8052 - accuracy: 0.6630 - val_loss: 0.9807 - val_accuracy: 0.5641\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7767 - accuracy: 0.6852 - val_loss: 1.0093 - val_accuracy: 0.6239\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8938 - accuracy: 0.6593 - val_loss: 1.0960 - val_accuracy: 0.6325\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8611 - accuracy: 0.6815 - val_loss: 1.0473 - val_accuracy: 0.5641\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8550 - accuracy: 0.6630 - val_loss: 1.0105 - val_accuracy: 0.5897\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8155 - accuracy: 0.6704 - val_loss: 1.0028 - val_accuracy: 0.5726\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7804 - accuracy: 0.6852 - val_loss: 1.0004 - val_accuracy: 0.5812\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8114 - accuracy: 0.6630 - val_loss: 1.0199 - val_accuracy: 0.5897\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7898 - accuracy: 0.6741 - val_loss: 0.9938 - val_accuracy: 0.5641\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7932 - accuracy: 0.6889 - val_loss: 0.9957 - val_accuracy: 0.5812\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7900 - accuracy: 0.6926 - val_loss: 0.9952 - val_accuracy: 0.5556\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7719 - accuracy: 0.6778 - val_loss: 0.9761 - val_accuracy: 0.5641\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7818 - accuracy: 0.6926 - val_loss: 0.9762 - val_accuracy: 0.5641\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7707 - accuracy: 0.6963 - val_loss: 0.9933 - val_accuracy: 0.5641\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7718 - accuracy: 0.6889 - val_loss: 0.9892 - val_accuracy: 0.5726\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7703 - accuracy: 0.6963 - val_loss: 0.9899 - val_accuracy: 0.5556\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7781 - accuracy: 0.6778 - val_loss: 0.9820 - val_accuracy: 0.5726\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7657 - accuracy: 0.6815 - val_loss: 0.9811 - val_accuracy: 0.5556\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7713 - accuracy: 0.6778 - val_loss: 0.9791 - val_accuracy: 0.5641\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7613 - accuracy: 0.6926 - val_loss: 0.9887 - val_accuracy: 0.5726\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7881 - accuracy: 0.6778 - val_loss: 0.9777 - val_accuracy: 0.5641\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.7960 - accuracy: 0.6852 - val_loss: 1.0139 - val_accuracy: 0.6325\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8680 - accuracy: 0.6704 - val_loss: 1.0159 - val_accuracy: 0.6239\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7918 - accuracy: 0.6889 - val_loss: 1.0007 - val_accuracy: 0.5726\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7655 - accuracy: 0.6852 - val_loss: 1.0045 - val_accuracy: 0.6239\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7914 - accuracy: 0.6667 - val_loss: 0.9826 - val_accuracy: 0.5556\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7671 - accuracy: 0.6852 - val_loss: 0.9796 - val_accuracy: 0.5641\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7865 - accuracy: 0.6741 - val_loss: 0.9766 - val_accuracy: 0.5641\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7667 - accuracy: 0.6778 - val_loss: 0.9780 - val_accuracy: 0.5470\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7898 - accuracy: 0.6704 - val_loss: 0.9821 - val_accuracy: 0.5897\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7706 - accuracy: 0.6926 - val_loss: 0.9853 - val_accuracy: 0.5385\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7721 - accuracy: 0.6963 - val_loss: 0.9731 - val_accuracy: 0.5470\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7865 - accuracy: 0.6852 - val_loss: 1.0068 - val_accuracy: 0.5214\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7977 - accuracy: 0.6778 - val_loss: 0.9735 - val_accuracy: 0.5983\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7677 - accuracy: 0.6852 - val_loss: 0.9739 - val_accuracy: 0.5983\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7716 - accuracy: 0.7000 - val_loss: 0.9738 - val_accuracy: 0.5470\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7663 - accuracy: 0.7000 - val_loss: 0.9744 - val_accuracy: 0.5470\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7640 - accuracy: 0.6963 - val_loss: 0.9883 - val_accuracy: 0.5470\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7605 - accuracy: 0.6852 - val_loss: 0.9706 - val_accuracy: 0.5470\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7699 - accuracy: 0.7000 - val_loss: 0.9747 - val_accuracy: 0.5641\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7628 - accuracy: 0.6963 - val_loss: 0.9784 - val_accuracy: 0.5470\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7643 - accuracy: 0.6852 - val_loss: 0.9796 - val_accuracy: 0.5470\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7594 - accuracy: 0.6889 - val_loss: 0.9745 - val_accuracy: 0.5641\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7618 - accuracy: 0.6889 - val_loss: 0.9748 - val_accuracy: 0.5983\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7582 - accuracy: 0.6926 - val_loss: 0.9777 - val_accuracy: 0.5983\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7628 - accuracy: 0.6815 - val_loss: 0.9813 - val_accuracy: 0.5641\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7587 - accuracy: 0.6778 - val_loss: 0.9748 - val_accuracy: 0.5641\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7575 - accuracy: 0.6926 - val_loss: 0.9753 - val_accuracy: 0.5983\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7642 - accuracy: 0.6852 - val_loss: 0.9716 - val_accuracy: 0.5641\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7552 - accuracy: 0.6926 - val_loss: 0.9705 - val_accuracy: 0.6068\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7625 - accuracy: 0.6963 - val_loss: 0.9713 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7572 - accuracy: 0.6963 - val_loss: 0.9772 - val_accuracy: 0.6154\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7759 - accuracy: 0.6704 - val_loss: 0.9863 - val_accuracy: 0.5726\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7841 - accuracy: 0.6667 - val_loss: 0.9878 - val_accuracy: 0.6239\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8005 - accuracy: 0.6704 - val_loss: 0.9788 - val_accuracy: 0.5641\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8217 - accuracy: 0.6667 - val_loss: 0.9916 - val_accuracy: 0.6239\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8035 - accuracy: 0.6667 - val_loss: 1.0022 - val_accuracy: 0.6239\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7890 - accuracy: 0.6593 - val_loss: 0.9814 - val_accuracy: 0.5641\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7635 - accuracy: 0.6815 - val_loss: 0.9796 - val_accuracy: 0.6239\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7647 - accuracy: 0.6815 - val_loss: 0.9766 - val_accuracy: 0.5641\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7628 - accuracy: 0.6815 - val_loss: 0.9793 - val_accuracy: 0.5726\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7553 - accuracy: 0.6852 - val_loss: 0.9708 - val_accuracy: 0.5641\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7531 - accuracy: 0.6963 - val_loss: 0.9687 - val_accuracy: 0.5641\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7597 - accuracy: 0.6963 - val_loss: 0.9676 - val_accuracy: 0.5726\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7608 - accuracy: 0.6852 - val_loss: 0.9684 - val_accuracy: 0.5641\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7541 - accuracy: 0.7000 - val_loss: 0.9647 - val_accuracy: 0.5726\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7568 - accuracy: 0.7000 - val_loss: 0.9627 - val_accuracy: 0.5641\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7518 - accuracy: 0.7037 - val_loss: 0.9723 - val_accuracy: 0.5897\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7601 - accuracy: 0.7074 - val_loss: 0.9637 - val_accuracy: 0.6325\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7571 - accuracy: 0.7000 - val_loss: 0.9693 - val_accuracy: 0.5641\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7553 - accuracy: 0.6963 - val_loss: 0.9710 - val_accuracy: 0.5641\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7579 - accuracy: 0.6926 - val_loss: 0.9655 - val_accuracy: 0.5556\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7588 - accuracy: 0.6889 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7845 - accuracy: 0.6815 - val_loss: 0.9652 - val_accuracy: 0.5556\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7748 - accuracy: 0.6852 - val_loss: 0.9695 - val_accuracy: 0.6068\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7587 - accuracy: 0.6741 - val_loss: 0.9649 - val_accuracy: 0.5641\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7564 - accuracy: 0.6926 - val_loss: 0.9709 - val_accuracy: 0.5641\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7781 - accuracy: 0.6741 - val_loss: 0.9887 - val_accuracy: 0.6154\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7858 - accuracy: 0.6704 - val_loss: 0.9946 - val_accuracy: 0.6239\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9704 - accuracy: 0.6556 - val_loss: 1.2313 - val_accuracy: 0.5812\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0414 - accuracy: 0.6370 - val_loss: 1.0069 - val_accuracy: 0.5812\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8824 - accuracy: 0.6556 - val_loss: 1.0631 - val_accuracy: 0.5641\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8028 - accuracy: 0.6815 - val_loss: 1.0268 - val_accuracy: 0.6239\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7713 - accuracy: 0.6889 - val_loss: 1.0316 - val_accuracy: 0.5726\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8334 - accuracy: 0.6556 - val_loss: 1.0791 - val_accuracy: 0.6325\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0052 - accuracy: 0.6481 - val_loss: 1.1715 - val_accuracy: 0.5897\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9240 - accuracy: 0.6630 - val_loss: 1.0097 - val_accuracy: 0.5726\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8060 - accuracy: 0.6667 - val_loss: 1.0286 - val_accuracy: 0.5983\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8835 - accuracy: 0.6704 - val_loss: 1.0295 - val_accuracy: 0.5983\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7699 - accuracy: 0.6815 - val_loss: 1.0790 - val_accuracy: 0.5726\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8284 - accuracy: 0.6704 - val_loss: 1.0733 - val_accuracy: 0.6325\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0288 - accuracy: 0.6593 - val_loss: 1.1178 - val_accuracy: 0.6325\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8462 - accuracy: 0.6926 - val_loss: 1.0655 - val_accuracy: 0.5556\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8872 - accuracy: 0.6630 - val_loss: 1.0237 - val_accuracy: 0.5897\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.7871 - accuracy: 0.6926 - val_loss: 1.0091 - val_accuracy: 0.5641\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7681 - accuracy: 0.6963 - val_loss: 1.0107 - val_accuracy: 0.6068\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7647 - accuracy: 0.7037 - val_loss: 0.9965 - val_accuracy: 0.5556\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7686 - accuracy: 0.6852 - val_loss: 0.9889 - val_accuracy: 0.5556\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7935 - accuracy: 0.6889 - val_loss: 0.9900 - val_accuracy: 0.5556\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7557 - accuracy: 0.6852 - val_loss: 1.0008 - val_accuracy: 0.5726\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7565 - accuracy: 0.7000 - val_loss: 0.9894 - val_accuracy: 0.5556\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7570 - accuracy: 0.7000 - val_loss: 1.0029 - val_accuracy: 0.5385\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7541 - accuracy: 0.6704 - val_loss: 0.9929 - val_accuracy: 0.5385\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7607 - accuracy: 0.6963 - val_loss: 0.9896 - val_accuracy: 0.5470\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7485 - accuracy: 0.7000 - val_loss: 0.9971 - val_accuracy: 0.5641\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7525 - accuracy: 0.6852 - val_loss: 0.9964 - val_accuracy: 0.5556\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7920 - accuracy: 0.6926 - val_loss: 0.9844 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7752 - accuracy: 0.6778 - val_loss: 0.9888 - val_accuracy: 0.6154\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7737 - accuracy: 0.6889 - val_loss: 0.9941 - val_accuracy: 0.5726\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7561 - accuracy: 0.6852 - val_loss: 0.9882 - val_accuracy: 0.5470\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7467 - accuracy: 0.6926 - val_loss: 0.9917 - val_accuracy: 0.6068\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7569 - accuracy: 0.6815 - val_loss: 0.9982 - val_accuracy: 0.5470\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7593 - accuracy: 0.6815 - val_loss: 0.9911 - val_accuracy: 0.5726\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7528 - accuracy: 0.6963 - val_loss: 0.9972 - val_accuracy: 0.5556\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7572 - accuracy: 0.6815 - val_loss: 0.9930 - val_accuracy: 0.5641\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7804 - accuracy: 0.6704 - val_loss: 0.9906 - val_accuracy: 0.6154\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7714 - accuracy: 0.6926 - val_loss: 1.0386 - val_accuracy: 0.5299\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7784 - accuracy: 0.6926 - val_loss: 1.0192 - val_accuracy: 0.6154\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7938 - accuracy: 0.6815 - val_loss: 1.0020 - val_accuracy: 0.5983\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7526 - accuracy: 0.6963 - val_loss: 1.0005 - val_accuracy: 0.5470\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7691 - accuracy: 0.7000 - val_loss: 0.9927 - val_accuracy: 0.5641\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7786 - accuracy: 0.6741 - val_loss: 0.9942 - val_accuracy: 0.5556\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7674 - accuracy: 0.6852 - val_loss: 0.9955 - val_accuracy: 0.6154\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7550 - accuracy: 0.6889 - val_loss: 0.9997 - val_accuracy: 0.5641\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7534 - accuracy: 0.6963 - val_loss: 1.0092 - val_accuracy: 0.5983\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7464 - accuracy: 0.6889 - val_loss: 1.0088 - val_accuracy: 0.5641\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7584 - accuracy: 0.6963 - val_loss: 1.0010 - val_accuracy: 0.6068\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7872 - accuracy: 0.6815 - val_loss: 0.9986 - val_accuracy: 0.5385\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7623 - accuracy: 0.6815 - val_loss: 0.9952 - val_accuracy: 0.6239\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7660 - accuracy: 0.6630 - val_loss: 0.9857 - val_accuracy: 0.5641\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7564 - accuracy: 0.6741 - val_loss: 0.9917 - val_accuracy: 0.5641\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.7510 - accuracy: 0.6963 - val_loss: 0.9869 - val_accuracy: 0.5897\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7434 - accuracy: 0.7037 - val_loss: 0.9951 - val_accuracy: 0.5726\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7424 - accuracy: 0.7037 - val_loss: 0.9844 - val_accuracy: 0.5983\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7874 - accuracy: 0.6741 - val_loss: 1.0140 - val_accuracy: 0.5214\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7717 - accuracy: 0.7037 - val_loss: 0.9948 - val_accuracy: 0.6068\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7573 - accuracy: 0.6926 - val_loss: 0.9860 - val_accuracy: 0.5897\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7468 - accuracy: 0.7000 - val_loss: 0.9846 - val_accuracy: 0.5812\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7445 - accuracy: 0.6963 - val_loss: 0.9927 - val_accuracy: 0.5470\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7436 - accuracy: 0.6926 - val_loss: 0.9888 - val_accuracy: 0.6068\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7798 - accuracy: 0.6815 - val_loss: 0.9882 - val_accuracy: 0.5470\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7524 - accuracy: 0.7000 - val_loss: 1.0253 - val_accuracy: 0.6239\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7972 - accuracy: 0.6741 - val_loss: 0.9965 - val_accuracy: 0.5556\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7435 - accuracy: 0.7074 - val_loss: 0.9858 - val_accuracy: 0.5470\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7473 - accuracy: 0.6889 - val_loss: 0.9937 - val_accuracy: 0.5726\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7586 - accuracy: 0.6963 - val_loss: 0.9874 - val_accuracy: 0.5641\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7564 - accuracy: 0.6815 - val_loss: 0.9877 - val_accuracy: 0.6068\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7796 - accuracy: 0.6778 - val_loss: 0.9906 - val_accuracy: 0.5641\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8309 - accuracy: 0.6815 - val_loss: 1.0290 - val_accuracy: 0.6325\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8771 - accuracy: 0.6852 - val_loss: 1.0522 - val_accuracy: 0.6239\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8141 - accuracy: 0.6481 - val_loss: 1.0510 - val_accuracy: 0.5556\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7779 - accuracy: 0.6852 - val_loss: 1.0440 - val_accuracy: 0.6325\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8135 - accuracy: 0.6852 - val_loss: 0.9961 - val_accuracy: 0.6154\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7504 - accuracy: 0.6852 - val_loss: 0.9933 - val_accuracy: 0.5726\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7481 - accuracy: 0.6815 - val_loss: 0.9884 - val_accuracy: 0.6325\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7623 - accuracy: 0.6852 - val_loss: 0.9898 - val_accuracy: 0.5641\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7500 - accuracy: 0.7000 - val_loss: 0.9962 - val_accuracy: 0.5470\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7664 - accuracy: 0.7000 - val_loss: 1.0078 - val_accuracy: 0.6325\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8216 - accuracy: 0.6852 - val_loss: 0.9993 - val_accuracy: 0.5897\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7790 - accuracy: 0.6667 - val_loss: 1.0014 - val_accuracy: 0.5641\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7420 - accuracy: 0.7000 - val_loss: 0.9986 - val_accuracy: 0.5641\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7552 - accuracy: 0.6926 - val_loss: 1.0007 - val_accuracy: 0.5812\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7562 - accuracy: 0.7037 - val_loss: 0.9971 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7538 - accuracy: 0.6778 - val_loss: 1.0194 - val_accuracy: 0.6154\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7762 - accuracy: 0.6963 - val_loss: 1.0006 - val_accuracy: 0.5385\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7447 - accuracy: 0.6852 - val_loss: 0.9948 - val_accuracy: 0.5641\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7596 - accuracy: 0.6815 - val_loss: 0.9962 - val_accuracy: 0.5556\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7459 - accuracy: 0.6704 - val_loss: 1.0001 - val_accuracy: 0.5726\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7534 - accuracy: 0.6889 - val_loss: 1.0065 - val_accuracy: 0.5812\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7611 - accuracy: 0.6667 - val_loss: 0.9969 - val_accuracy: 0.5556\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7386 - accuracy: 0.6889 - val_loss: 0.9877 - val_accuracy: 0.5641\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7401 - accuracy: 0.7000 - val_loss: 0.9852 - val_accuracy: 0.5641\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7626 - accuracy: 0.6741 - val_loss: 0.9854 - val_accuracy: 0.5641\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7906 - accuracy: 0.6852 - val_loss: 0.9787 - val_accuracy: 0.5641\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8654 - accuracy: 0.6630 - val_loss: 1.0097 - val_accuracy: 0.6239\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8114 - accuracy: 0.6852 - val_loss: 1.0606 - val_accuracy: 0.6068\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7908 - accuracy: 0.6741 - val_loss: 1.0666 - val_accuracy: 0.5556\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8116 - accuracy: 0.6741 - val_loss: 1.0368 - val_accuracy: 0.6325\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8377 - accuracy: 0.6815 - val_loss: 0.9890 - val_accuracy: 0.5556\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7551 - accuracy: 0.6815 - val_loss: 0.9960 - val_accuracy: 0.5556\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7437 - accuracy: 0.6889 - val_loss: 0.9937 - val_accuracy: 0.5726\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7574 - accuracy: 0.6889 - val_loss: 0.9947 - val_accuracy: 0.5556\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7914 - accuracy: 0.6704 - val_loss: 1.0619 - val_accuracy: 0.6325\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8789 - accuracy: 0.6815 - val_loss: 1.0845 - val_accuracy: 0.6325\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8045 - accuracy: 0.6778 - val_loss: 1.0296 - val_accuracy: 0.5556\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8563 - accuracy: 0.6630 - val_loss: 1.0411 - val_accuracy: 0.6496\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9118 - accuracy: 0.6852 - val_loss: 1.0860 - val_accuracy: 0.6496\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7994 - accuracy: 0.7000 - val_loss: 1.0629 - val_accuracy: 0.5726\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7838 - accuracy: 0.6778 - val_loss: 1.0438 - val_accuracy: 0.6325\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8326 - accuracy: 0.6926 - val_loss: 1.0104 - val_accuracy: 0.5812\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8574 - accuracy: 0.6556 - val_loss: 1.0426 - val_accuracy: 0.6325\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8534 - accuracy: 0.6889 - val_loss: 1.0664 - val_accuracy: 0.6325\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8396 - accuracy: 0.6778 - val_loss: 1.0082 - val_accuracy: 0.5726\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9174 - accuracy: 0.6889 - val_loss: 1.2039 - val_accuracy: 0.6068\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0013 - accuracy: 0.6593 - val_loss: 1.0587 - val_accuracy: 0.5470\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7842 - accuracy: 0.6778 - val_loss: 1.0506 - val_accuracy: 0.5641\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7891 - accuracy: 0.6667 - val_loss: 1.0206 - val_accuracy: 0.5812\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7709 - accuracy: 0.6852 - val_loss: 1.0486 - val_accuracy: 0.5470\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7852 - accuracy: 0.6741 - val_loss: 1.0567 - val_accuracy: 0.5726\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8365 - accuracy: 0.6667 - val_loss: 1.0224 - val_accuracy: 0.5556\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 447us/step - loss: 0.7556 - accuracy: 0.6963 - val_loss: 1.0541 - val_accuracy: 0.5556\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7960 - accuracy: 0.6926 - val_loss: 1.0375 - val_accuracy: 0.5641\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7826 - accuracy: 0.7037 - val_loss: 1.0243 - val_accuracy: 0.5812\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7475 - accuracy: 0.6852 - val_loss: 1.0293 - val_accuracy: 0.5556\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7519 - accuracy: 0.6963 - val_loss: 1.0136 - val_accuracy: 0.5641\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7686 - accuracy: 0.6852 - val_loss: 1.0510 - val_accuracy: 0.6239\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8495 - accuracy: 0.6815 - val_loss: 1.0349 - val_accuracy: 0.6325\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7692 - accuracy: 0.6852 - val_loss: 1.0277 - val_accuracy: 0.5726\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7374 - accuracy: 0.6852 - val_loss: 1.0126 - val_accuracy: 0.5812\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7703 - accuracy: 0.6852 - val_loss: 1.0068 - val_accuracy: 0.5641\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7984 - accuracy: 0.6741 - val_loss: 1.0307 - val_accuracy: 0.6068\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8700 - accuracy: 0.6889 - val_loss: 1.0653 - val_accuracy: 0.6068\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8144 - accuracy: 0.6741 - val_loss: 1.1492 - val_accuracy: 0.5556\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9296 - accuracy: 0.6889 - val_loss: 1.1292 - val_accuracy: 0.6496\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9860 - accuracy: 0.6778 - val_loss: 1.1853 - val_accuracy: 0.6068\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8852 - accuracy: 0.6667 - val_loss: 1.0634 - val_accuracy: 0.5556\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7807 - accuracy: 0.6667 - val_loss: 1.0100 - val_accuracy: 0.5641\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7412 - accuracy: 0.6889 - val_loss: 1.0164 - val_accuracy: 0.5556\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7401 - accuracy: 0.7037 - val_loss: 1.0208 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7956 - accuracy: 0.6815 - val_loss: 1.0155 - val_accuracy: 0.5726\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7646 - accuracy: 0.6852 - val_loss: 1.0327 - val_accuracy: 0.5812\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7606 - accuracy: 0.6926 - val_loss: 1.0158 - val_accuracy: 0.6068\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7403 - accuracy: 0.7000 - val_loss: 1.0437 - val_accuracy: 0.5556\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7397 - accuracy: 0.6852 - val_loss: 1.0192 - val_accuracy: 0.5726\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7677 - accuracy: 0.6926 - val_loss: 1.0079 - val_accuracy: 0.5470\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7496 - accuracy: 0.6778 - val_loss: 1.0179 - val_accuracy: 0.5470\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7419 - accuracy: 0.6889 - val_loss: 1.0007 - val_accuracy: 0.5726\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7366 - accuracy: 0.6963 - val_loss: 1.0039 - val_accuracy: 0.6068\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7318 - accuracy: 0.6815 - val_loss: 1.0262 - val_accuracy: 0.5812\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7644 - accuracy: 0.6815 - val_loss: 1.0303 - val_accuracy: 0.6581\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7767 - accuracy: 0.7000 - val_loss: 1.0112 - val_accuracy: 0.5897\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7446 - accuracy: 0.6926 - val_loss: 1.0080 - val_accuracy: 0.5897\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7348 - accuracy: 0.6963 - val_loss: 0.9973 - val_accuracy: 0.5812\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7419 - accuracy: 0.7000 - val_loss: 0.9992 - val_accuracy: 0.5726\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7419 - accuracy: 0.6963 - val_loss: 0.9871 - val_accuracy: 0.6239\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7425 - accuracy: 0.6889 - val_loss: 0.9884 - val_accuracy: 0.5556\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7375 - accuracy: 0.7000 - val_loss: 0.9868 - val_accuracy: 0.5726\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8207 - accuracy: 0.6704 - val_loss: 1.0695 - val_accuracy: 0.5128\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7958 - accuracy: 0.6704 - val_loss: 1.0600 - val_accuracy: 0.6239\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9139 - accuracy: 0.6667 - val_loss: 1.1120 - val_accuracy: 0.6325\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8688 - accuracy: 0.6852 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8536 - accuracy: 0.6519 - val_loss: 1.0357 - val_accuracy: 0.6325\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7429 - accuracy: 0.7037 - val_loss: 1.0457 - val_accuracy: 0.5812\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7555 - accuracy: 0.6926 - val_loss: 1.0425 - val_accuracy: 0.6410\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8167 - accuracy: 0.6889 - val_loss: 1.0124 - val_accuracy: 0.5556\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7549 - accuracy: 0.6852 - val_loss: 1.0083 - val_accuracy: 0.5556\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7756 - accuracy: 0.6889 - val_loss: 1.0236 - val_accuracy: 0.5897\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7705 - accuracy: 0.6889 - val_loss: 1.0132 - val_accuracy: 0.5726\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7361 - accuracy: 0.6926 - val_loss: 1.0075 - val_accuracy: 0.6325\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7503 - accuracy: 0.6852 - val_loss: 0.9977 - val_accuracy: 0.5726\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7461 - accuracy: 0.7111 - val_loss: 1.0042 - val_accuracy: 0.5641\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7332 - accuracy: 0.7000 - val_loss: 1.0114 - val_accuracy: 0.5812\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7376 - accuracy: 0.7074 - val_loss: 1.0013 - val_accuracy: 0.5726\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7313 - accuracy: 0.7037 - val_loss: 1.0037 - val_accuracy: 0.5641\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7331 - accuracy: 0.7000 - val_loss: 1.0034 - val_accuracy: 0.6239\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7387 - accuracy: 0.6926 - val_loss: 0.9983 - val_accuracy: 0.5556\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7261 - accuracy: 0.7037 - val_loss: 0.9935 - val_accuracy: 0.5641\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7418 - accuracy: 0.7074 - val_loss: 1.0007 - val_accuracy: 0.5556\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7371 - accuracy: 0.7074 - val_loss: 1.0055 - val_accuracy: 0.5556\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7321 - accuracy: 0.7074 - val_loss: 1.0040 - val_accuracy: 0.5641\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7295 - accuracy: 0.7111 - val_loss: 1.0019 - val_accuracy: 0.5556\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7344 - accuracy: 0.6926 - val_loss: 1.0015 - val_accuracy: 0.6068\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7320 - accuracy: 0.6963 - val_loss: 0.9962 - val_accuracy: 0.6154\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7311 - accuracy: 0.7000 - val_loss: 0.9963 - val_accuracy: 0.6068\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7332 - accuracy: 0.6926 - val_loss: 0.9972 - val_accuracy: 0.6068\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7254 - accuracy: 0.7000 - val_loss: 1.0058 - val_accuracy: 0.6154\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7380 - accuracy: 0.7037 - val_loss: 0.9928 - val_accuracy: 0.6068\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7313 - accuracy: 0.7037 - val_loss: 0.9960 - val_accuracy: 0.6068\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7299 - accuracy: 0.7000 - val_loss: 1.0030 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7298 - accuracy: 0.6889 - val_loss: 1.0101 - val_accuracy: 0.5641\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7332 - accuracy: 0.6963 - val_loss: 0.9975 - val_accuracy: 0.5897\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7327 - accuracy: 0.7111 - val_loss: 1.0013 - val_accuracy: 0.6068\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7722 - accuracy: 0.7000 - val_loss: 1.0132 - val_accuracy: 0.6325\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7357 - accuracy: 0.7074 - val_loss: 1.0099 - val_accuracy: 0.6325\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9302 - accuracy: 0.6741 - val_loss: 1.2131 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9930 - accuracy: 0.6852 - val_loss: 1.0828 - val_accuracy: 0.6325\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8330 - accuracy: 0.6741 - val_loss: 1.0925 - val_accuracy: 0.5726\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7979 - accuracy: 0.6630 - val_loss: 1.1039 - val_accuracy: 0.6239\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8612 - accuracy: 0.6667 - val_loss: 1.0575 - val_accuracy: 0.6239\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7751 - accuracy: 0.6889 - val_loss: 1.0677 - val_accuracy: 0.6068\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7419 - accuracy: 0.6889 - val_loss: 1.0330 - val_accuracy: 0.5897\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7835 - accuracy: 0.6889 - val_loss: 1.0027 - val_accuracy: 0.5812\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8071 - accuracy: 0.6852 - val_loss: 1.0216 - val_accuracy: 0.5897\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7522 - accuracy: 0.7000 - val_loss: 1.0114 - val_accuracy: 0.5641\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7414 - accuracy: 0.7000 - val_loss: 1.0168 - val_accuracy: 0.5812\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7412 - accuracy: 0.6963 - val_loss: 1.0179 - val_accuracy: 0.5641\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7392 - accuracy: 0.7000 - val_loss: 1.0165 - val_accuracy: 0.5641\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7296 - accuracy: 0.6889 - val_loss: 1.0153 - val_accuracy: 0.5812\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7257 - accuracy: 0.7074 - val_loss: 1.0112 - val_accuracy: 0.5726\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7361 - accuracy: 0.7000 - val_loss: 1.0102 - val_accuracy: 0.5726\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7296 - accuracy: 0.7037 - val_loss: 1.0081 - val_accuracy: 0.5812\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7473 - accuracy: 0.6926 - val_loss: 1.0023 - val_accuracy: 0.5812\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7326 - accuracy: 0.6889 - val_loss: 1.0034 - val_accuracy: 0.5726\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7301 - accuracy: 0.7000 - val_loss: 0.9975 - val_accuracy: 0.5726\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7353 - accuracy: 0.7148 - val_loss: 1.0020 - val_accuracy: 0.5556\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7331 - accuracy: 0.7037 - val_loss: 1.0171 - val_accuracy: 0.5897\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7377 - accuracy: 0.6963 - val_loss: 1.0047 - val_accuracy: 0.5556\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7391 - accuracy: 0.6963 - val_loss: 1.0168 - val_accuracy: 0.5726\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7435 - accuracy: 0.6852 - val_loss: 1.0144 - val_accuracy: 0.5897\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7358 - accuracy: 0.6926 - val_loss: 1.0164 - val_accuracy: 0.5726\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7390 - accuracy: 0.7074 - val_loss: 1.0064 - val_accuracy: 0.5897\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7375 - accuracy: 0.6926 - val_loss: 1.0264 - val_accuracy: 0.5812\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7421 - accuracy: 0.6963 - val_loss: 1.0018 - val_accuracy: 0.5812\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7240 - accuracy: 0.7074 - val_loss: 1.0128 - val_accuracy: 0.5726\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7280 - accuracy: 0.7074 - val_loss: 1.0061 - val_accuracy: 0.5812\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7583 - accuracy: 0.6963 - val_loss: 1.0033 - val_accuracy: 0.5812\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7345 - accuracy: 0.6889 - val_loss: 1.0171 - val_accuracy: 0.6410\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9720 - accuracy: 0.6741 - val_loss: 1.1474 - val_accuracy: 0.6496\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8002 - accuracy: 0.6815 - val_loss: 1.1424 - val_accuracy: 0.5812\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9463 - accuracy: 0.6704 - val_loss: 1.1175 - val_accuracy: 0.6410\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0229 - accuracy: 0.6815 - val_loss: 1.1184 - val_accuracy: 0.6325\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7722 - accuracy: 0.6889 - val_loss: 1.1859 - val_accuracy: 0.5812\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9961 - accuracy: 0.6778 - val_loss: 1.0701 - val_accuracy: 0.6581\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8430 - accuracy: 0.6926 - val_loss: 1.0490 - val_accuracy: 0.5983\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7685 - accuracy: 0.6926 - val_loss: 1.0444 - val_accuracy: 0.5812\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7608 - accuracy: 0.6630 - val_loss: 1.0311 - val_accuracy: 0.5726\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8865 - accuracy: 0.6556 - val_loss: 1.1204 - val_accuracy: 0.6068\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 1.0198 - accuracy: 0.6444 - val_loss: 1.1998 - val_accuracy: 0.6752\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.9200 - accuracy: 0.6778 - val_loss: 1.0879 - val_accuracy: 0.5641\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9065 - accuracy: 0.6519 - val_loss: 1.0926 - val_accuracy: 0.5812\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9424 - accuracy: 0.6741 - val_loss: 1.1222 - val_accuracy: 0.6239\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8087 - accuracy: 0.7037 - val_loss: 1.0791 - val_accuracy: 0.5897\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7600 - accuracy: 0.6926 - val_loss: 1.0695 - val_accuracy: 0.5983\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8198 - accuracy: 0.6852 - val_loss: 1.0381 - val_accuracy: 0.5726\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7385 - accuracy: 0.6889 - val_loss: 1.0748 - val_accuracy: 0.5641\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7475 - accuracy: 0.6815 - val_loss: 1.0507 - val_accuracy: 0.5983\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7444 - accuracy: 0.6926 - val_loss: 1.0543 - val_accuracy: 0.5983\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7838 - accuracy: 0.6852 - val_loss: 1.0488 - val_accuracy: 0.6068\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7767 - accuracy: 0.7074 - val_loss: 1.0409 - val_accuracy: 0.5983\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7302 - accuracy: 0.7222 - val_loss: 1.0549 - val_accuracy: 0.5897\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7237 - accuracy: 0.6963 - val_loss: 1.0371 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7570 - accuracy: 0.6963 - val_loss: 1.0241 - val_accuracy: 0.5641\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7313 - accuracy: 0.7037 - val_loss: 1.0308 - val_accuracy: 0.5470\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7235 - accuracy: 0.6963 - val_loss: 1.0254 - val_accuracy: 0.5812\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7303 - accuracy: 0.7037 - val_loss: 1.0206 - val_accuracy: 0.5726\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7254 - accuracy: 0.7074 - val_loss: 1.0242 - val_accuracy: 0.5641\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7262 - accuracy: 0.6926 - val_loss: 1.0259 - val_accuracy: 0.5726\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7227 - accuracy: 0.6963 - val_loss: 1.0190 - val_accuracy: 0.5812\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7445 - accuracy: 0.6741 - val_loss: 1.0177 - val_accuracy: 0.5812\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7299 - accuracy: 0.6963 - val_loss: 1.0297 - val_accuracy: 0.5726\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7387 - accuracy: 0.6963 - val_loss: 1.0108 - val_accuracy: 0.5812\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7303 - accuracy: 0.6963 - val_loss: 1.0173 - val_accuracy: 0.6068\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7256 - accuracy: 0.6889 - val_loss: 1.0665 - val_accuracy: 0.6239\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8277 - accuracy: 0.6704 - val_loss: 1.0681 - val_accuracy: 0.6410\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7683 - accuracy: 0.6963 - val_loss: 1.0520 - val_accuracy: 0.5812\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7530 - accuracy: 0.6926 - val_loss: 1.0162 - val_accuracy: 0.5556\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7302 - accuracy: 0.7000 - val_loss: 1.0152 - val_accuracy: 0.5556\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7369 - accuracy: 0.7074 - val_loss: 1.0323 - val_accuracy: 0.5556\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7419 - accuracy: 0.7111 - val_loss: 1.0238 - val_accuracy: 0.5726\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7276 - accuracy: 0.6963 - val_loss: 1.0375 - val_accuracy: 0.6154\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7421 - accuracy: 0.6926 - val_loss: 1.0180 - val_accuracy: 0.6068\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7535 - accuracy: 0.6889 - val_loss: 1.0306 - val_accuracy: 0.6068\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7428 - accuracy: 0.7111 - val_loss: 1.0354 - val_accuracy: 0.5812\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7582 - accuracy: 0.6778 - val_loss: 1.0620 - val_accuracy: 0.6325\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8211 - accuracy: 0.6778 - val_loss: 1.0292 - val_accuracy: 0.6239\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7553 - accuracy: 0.6926 - val_loss: 1.0256 - val_accuracy: 0.6239\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7354 - accuracy: 0.6926 - val_loss: 1.0348 - val_accuracy: 0.6325\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7336 - accuracy: 0.6852 - val_loss: 1.0208 - val_accuracy: 0.5556\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7204 - accuracy: 0.7074 - val_loss: 1.0108 - val_accuracy: 0.5556\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.7278 - accuracy: 0.7000 - val_loss: 1.0188 - val_accuracy: 0.5470\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 276us/step - loss: 0.7237 - accuracy: 0.6778 - val_loss: 1.0261 - val_accuracy: 0.5812\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.7239 - accuracy: 0.7037 - val_loss: 1.0230 - val_accuracy: 0.5726\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.7193 - accuracy: 0.7000 - val_loss: 1.0483 - val_accuracy: 0.5812\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.7692 - accuracy: 0.6778 - val_loss: 1.0489 - val_accuracy: 0.6410\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7538 - accuracy: 0.68 - 0s 269us/step - loss: 0.7493 - accuracy: 0.6852 - val_loss: 1.0255 - val_accuracy: 0.5641\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7364 - accuracy: 0.6889 - val_loss: 1.0215 - val_accuracy: 0.5556\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.7980 - accuracy: 0.6852 - val_loss: 1.0495 - val_accuracy: 0.6325\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 1.0343 - accuracy: 0.6593 - val_loss: 1.3459 - val_accuracy: 0.6239\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.1187 - accuracy: 0.6778 - val_loss: 1.1669 - val_accuracy: 0.6068\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8365 - accuracy: 0.6852 - val_loss: 1.1664 - val_accuracy: 0.5385\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8175 - accuracy: 0.6556 - val_loss: 1.1064 - val_accuracy: 0.6325\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8608 - accuracy: 0.6815 - val_loss: 1.0835 - val_accuracy: 0.5812\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7670 - accuracy: 0.6889 - val_loss: 1.0728 - val_accuracy: 0.5897\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7608 - accuracy: 0.6926 - val_loss: 1.0616 - val_accuracy: 0.6325\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7867 - accuracy: 0.6889 - val_loss: 1.0698 - val_accuracy: 0.5641\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7417 - accuracy: 0.6852 - val_loss: 1.0400 - val_accuracy: 0.5726\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7584 - accuracy: 0.7037 - val_loss: 1.0461 - val_accuracy: 0.5812\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7453 - accuracy: 0.7037 - val_loss: 1.0653 - val_accuracy: 0.5897\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7525 - accuracy: 0.6889 - val_loss: 1.0378 - val_accuracy: 0.5470\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7384 - accuracy: 0.7037 - val_loss: 1.0288 - val_accuracy: 0.5470\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7421 - accuracy: 0.6926 - val_loss: 1.0169 - val_accuracy: 0.5726\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7299 - accuracy: 0.7000 - val_loss: 1.0778 - val_accuracy: 0.6068\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 1.2015 - accuracy: 0.6407 - val_loss: 1.9496 - val_accuracy: 0.5641\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.6109 - accuracy: 0.6148 - val_loss: 1.8032 - val_accuracy: 0.5043\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.3087 - accuracy: 0.6259 - val_loss: 1.2977 - val_accuracy: 0.5983\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8891 - accuracy: 0.6370 - val_loss: 1.3897 - val_accuracy: 0.5470\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9872 - accuracy: 0.6148 - val_loss: 1.1167 - val_accuracy: 0.5214\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8672 - accuracy: 0.6667 - val_loss: 1.1333 - val_accuracy: 0.5385\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7884 - accuracy: 0.6963 - val_loss: 1.0968 - val_accuracy: 0.5641\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7647 - accuracy: 0.6815 - val_loss: 1.0554 - val_accuracy: 0.5556\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8082 - accuracy: 0.6815 - val_loss: 1.0889 - val_accuracy: 0.6410\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7670 - accuracy: 0.7111 - val_loss: 1.0920 - val_accuracy: 0.5812\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7365 - accuracy: 0.7148 - val_loss: 1.0947 - val_accuracy: 0.5897\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8425 - accuracy: 0.7000 - val_loss: 1.1381 - val_accuracy: 0.6068\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8122 - accuracy: 0.6704 - val_loss: 1.0878 - val_accuracy: 0.5812\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7448 - accuracy: 0.6963 - val_loss: 1.0553 - val_accuracy: 0.5897\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7389 - accuracy: 0.6852 - val_loss: 1.0644 - val_accuracy: 0.5726\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7282 - accuracy: 0.6963 - val_loss: 1.0509 - val_accuracy: 0.5897\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7334 - accuracy: 0.7000 - val_loss: 1.0397 - val_accuracy: 0.5726\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7156 - accuracy: 0.7000 - val_loss: 1.0464 - val_accuracy: 0.5385\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7264 - accuracy: 0.7111 - val_loss: 1.0400 - val_accuracy: 0.5726\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7338 - accuracy: 0.7074 - val_loss: 1.0442 - val_accuracy: 0.5641\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7289 - accuracy: 0.7148 - val_loss: 1.0478 - val_accuracy: 0.5897\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7289 - accuracy: 0.7148 - val_loss: 1.0370 - val_accuracy: 0.5556\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7163 - accuracy: 0.6963 - val_loss: 1.0299 - val_accuracy: 0.5726\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7204 - accuracy: 0.7000 - val_loss: 1.0344 - val_accuracy: 0.5726\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7160 - accuracy: 0.7037 - val_loss: 1.0400 - val_accuracy: 0.5812\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7227 - accuracy: 0.7000 - val_loss: 1.0306 - val_accuracy: 0.5812\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7428 - accuracy: 0.6926 - val_loss: 1.0349 - val_accuracy: 0.6325\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7482 - accuracy: 0.6852 - val_loss: 1.0279 - val_accuracy: 0.5726\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7578 - accuracy: 0.6815 - val_loss: 1.0840 - val_accuracy: 0.6496\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8813 - accuracy: 0.6815 - val_loss: 1.1627 - val_accuracy: 0.6496\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8432 - accuracy: 0.7000 - val_loss: 1.0366 - val_accuracy: 0.5726\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8062 - accuracy: 0.6889 - val_loss: 1.1002 - val_accuracy: 0.6496\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.1582 - accuracy: 0.6852 - val_loss: 1.7271 - val_accuracy: 0.6154\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.6837 - accuracy: 0.6667 - val_loss: 1.5700 - val_accuracy: 0.6410\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.2766 - accuracy: 0.6667 - val_loss: 1.1333 - val_accuracy: 0.6068\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8879 - accuracy: 0.6556 - val_loss: 1.1862 - val_accuracy: 0.5726\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8569 - accuracy: 0.6778 - val_loss: 1.2398 - val_accuracy: 0.6068\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9713 - accuracy: 0.6741 - val_loss: 1.1410 - val_accuracy: 0.6325\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8236 - accuracy: 0.6556 - val_loss: 1.1128 - val_accuracy: 0.5897\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7908 - accuracy: 0.6741 - val_loss: 1.0571 - val_accuracy: 0.5812\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7571 - accuracy: 0.7074 - val_loss: 1.0433 - val_accuracy: 0.5726\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7367 - accuracy: 0.7000 - val_loss: 1.0647 - val_accuracy: 0.5983\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7339 - accuracy: 0.7148 - val_loss: 1.0507 - val_accuracy: 0.5726\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7239 - accuracy: 0.7111 - val_loss: 1.0527 - val_accuracy: 0.5812\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7330 - accuracy: 0.6963 - val_loss: 1.0364 - val_accuracy: 0.5470\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7387 - accuracy: 0.6963 - val_loss: 1.0385 - val_accuracy: 0.5641\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7886 - accuracy: 0.6815 - val_loss: 1.1228 - val_accuracy: 0.6496\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8792 - accuracy: 0.7111 - val_loss: 1.1097 - val_accuracy: 0.6496\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7479 - accuracy: 0.7000 - val_loss: 1.1096 - val_accuracy: 0.5983\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7729 - accuracy: 0.6741 - val_loss: 1.0629 - val_accuracy: 0.6239\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7425 - accuracy: 0.7000 - val_loss: 1.0414 - val_accuracy: 0.5641\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7171 - accuracy: 0.7000 - val_loss: 1.0514 - val_accuracy: 0.5897\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7252 - accuracy: 0.7000 - val_loss: 1.0327 - val_accuracy: 0.5983\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7247 - accuracy: 0.7000 - val_loss: 1.0291 - val_accuracy: 0.6068\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7423 - accuracy: 0.7296 - val_loss: 1.0588 - val_accuracy: 0.6325\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7343 - accuracy: 0.7185 - val_loss: 1.0706 - val_accuracy: 0.5897\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7390 - accuracy: 0.7000 - val_loss: 1.0364 - val_accuracy: 0.5726\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7257 - accuracy: 0.7111 - val_loss: 1.0359 - val_accuracy: 0.5812\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7664 - accuracy: 0.7037 - val_loss: 1.0198 - val_accuracy: 0.5897\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8011 - accuracy: 0.7111 - val_loss: 1.1093 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8201 - accuracy: 0.6815 - val_loss: 1.0933 - val_accuracy: 0.5983\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7501 - accuracy: 0.6778 - val_loss: 1.0732 - val_accuracy: 0.6325\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7841 - accuracy: 0.7000 - val_loss: 1.0606 - val_accuracy: 0.5983\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7275 - accuracy: 0.7111 - val_loss: 1.0702 - val_accuracy: 0.5897\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7206 - accuracy: 0.7074 - val_loss: 1.0507 - val_accuracy: 0.6154\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7213 - accuracy: 0.7259 - val_loss: 1.0318 - val_accuracy: 0.5641\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7238 - accuracy: 0.7000 - val_loss: 1.0318 - val_accuracy: 0.5641\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7135 - accuracy: 0.7037 - val_loss: 1.0289 - val_accuracy: 0.5897\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7362 - accuracy: 0.6815 - val_loss: 1.0486 - val_accuracy: 0.5812\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0517 - accuracy: 0.6667 - val_loss: 1.0683 - val_accuracy: 0.6325\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9825 - accuracy: 0.6630 - val_loss: 1.5923 - val_accuracy: 0.6239\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.4610 - accuracy: 0.6556 - val_loss: 1.4627 - val_accuracy: 0.6496\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.1457 - accuracy: 0.6556 - val_loss: 1.1298 - val_accuracy: 0.5983\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8475 - accuracy: 0.6741 - val_loss: 1.1353 - val_accuracy: 0.5983\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8032 - accuracy: 0.6815 - val_loss: 1.1043 - val_accuracy: 0.5983\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7807 - accuracy: 0.6926 - val_loss: 1.0923 - val_accuracy: 0.5897\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7588 - accuracy: 0.6852 - val_loss: 1.0709 - val_accuracy: 0.5983\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7828 - accuracy: 0.6852 - val_loss: 1.1134 - val_accuracy: 0.5470\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7888 - accuracy: 0.6926 - val_loss: 1.0548 - val_accuracy: 0.5726\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7340 - accuracy: 0.7037 - val_loss: 1.0901 - val_accuracy: 0.5897\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7289 - accuracy: 0.7074 - val_loss: 1.0579 - val_accuracy: 0.5897\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7688 - accuracy: 0.7037 - val_loss: 1.0625 - val_accuracy: 0.5812\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7399 - accuracy: 0.7148 - val_loss: 1.0442 - val_accuracy: 0.5897\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7307 - accuracy: 0.6926 - val_loss: 1.0535 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7213 - accuracy: 0.7000 - val_loss: 1.0423 - val_accuracy: 0.5897\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7361 - accuracy: 0.7000 - val_loss: 1.0524 - val_accuracy: 0.5726\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7314 - accuracy: 0.7000 - val_loss: 1.0394 - val_accuracy: 0.5812\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7369 - accuracy: 0.7111 - val_loss: 1.0557 - val_accuracy: 0.5812\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7547 - accuracy: 0.7000 - val_loss: 1.0505 - val_accuracy: 0.6410\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7263 - accuracy: 0.7037 - val_loss: 1.0499 - val_accuracy: 0.5726\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7137 - accuracy: 0.7037 - val_loss: 1.0579 - val_accuracy: 0.6410\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7452 - accuracy: 0.6963 - val_loss: 1.0364 - val_accuracy: 0.5726\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7363 - accuracy: 0.7074 - val_loss: 1.0415 - val_accuracy: 0.5983\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7191 - accuracy: 0.7111 - val_loss: 1.0306 - val_accuracy: 0.6068\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7178 - accuracy: 0.7148 - val_loss: 1.0352 - val_accuracy: 0.5983\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7089 - accuracy: 0.7074 - val_loss: 1.0325 - val_accuracy: 0.5897\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7168 - accuracy: 0.7148 - val_loss: 1.0287 - val_accuracy: 0.5983\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7149 - accuracy: 0.7185 - val_loss: 1.0328 - val_accuracy: 0.5983\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7175 - accuracy: 0.7037 - val_loss: 1.0339 - val_accuracy: 0.5897\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7122 - accuracy: 0.7148 - val_loss: 1.0237 - val_accuracy: 0.5983\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7194 - accuracy: 0.7074 - val_loss: 1.0372 - val_accuracy: 0.5726\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7178 - accuracy: 0.6963 - val_loss: 1.0197 - val_accuracy: 0.5812\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7264 - accuracy: 0.7148 - val_loss: 1.0207 - val_accuracy: 0.5812\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7115 - accuracy: 0.7185 - val_loss: 1.0281 - val_accuracy: 0.5897\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7446 - accuracy: 0.7000 - val_loss: 1.0298 - val_accuracy: 0.5897\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7108 - accuracy: 0.7148 - val_loss: 1.0541 - val_accuracy: 0.5812\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7295 - accuracy: 0.7148 - val_loss: 1.0325 - val_accuracy: 0.5897\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7206 - accuracy: 0.7185 - val_loss: 1.0308 - val_accuracy: 0.5812\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7143 - accuracy: 0.7148 - val_loss: 1.0343 - val_accuracy: 0.6068\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7101 - accuracy: 0.7185 - val_loss: 1.0312 - val_accuracy: 0.6068\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7135 - accuracy: 0.7074 - val_loss: 1.0248 - val_accuracy: 0.5983\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7132 - accuracy: 0.7111 - val_loss: 1.0303 - val_accuracy: 0.6410\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7100 - accuracy: 0.7296 - val_loss: 1.0236 - val_accuracy: 0.6325\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7060 - accuracy: 0.7074 - val_loss: 1.0305 - val_accuracy: 0.5812\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7078 - accuracy: 0.7185 - val_loss: 1.0348 - val_accuracy: 0.5812\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7054 - accuracy: 0.7111 - val_loss: 1.0364 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7075 - accuracy: 0.7185 - val_loss: 1.0262 - val_accuracy: 0.5812\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7209 - accuracy: 0.7000 - val_loss: 1.0244 - val_accuracy: 0.5812\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7104 - accuracy: 0.7148 - val_loss: 1.0412 - val_accuracy: 0.5812\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7131 - accuracy: 0.7111 - val_loss: 1.0230 - val_accuracy: 0.6410\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7330 - accuracy: 0.6963 - val_loss: 1.0219 - val_accuracy: 0.5812\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7185 - accuracy: 0.7037 - val_loss: 1.0127 - val_accuracy: 0.5983\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7141 - accuracy: 0.7296 - val_loss: 1.0130 - val_accuracy: 0.5983\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7099 - accuracy: 0.7074 - val_loss: 1.0140 - val_accuracy: 0.6068\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7192 - accuracy: 0.7111 - val_loss: 1.0094 - val_accuracy: 0.6068\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7167 - accuracy: 0.6889 - val_loss: 1.0146 - val_accuracy: 0.6068\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7171 - accuracy: 0.6926 - val_loss: 1.0377 - val_accuracy: 0.6325\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7317 - accuracy: 0.7000 - val_loss: 1.0391 - val_accuracy: 0.5983\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7323 - accuracy: 0.6852 - val_loss: 1.0388 - val_accuracy: 0.5812\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7062 - accuracy: 0.7148 - val_loss: 1.0288 - val_accuracy: 0.6410\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7145 - accuracy: 0.7111 - val_loss: 1.0225 - val_accuracy: 0.5983\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7046 - accuracy: 0.7111 - val_loss: 1.0275 - val_accuracy: 0.6410\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7142 - accuracy: 0.7000 - val_loss: 1.0234 - val_accuracy: 0.6068\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7217 - accuracy: 0.7000 - val_loss: 1.0239 - val_accuracy: 0.5726\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7206 - accuracy: 0.6926 - val_loss: 1.0336 - val_accuracy: 0.5983\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8790 - accuracy: 0.6741 - val_loss: 1.0554 - val_accuracy: 0.6496\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8417 - accuracy: 0.7000 - val_loss: 1.1808 - val_accuracy: 0.6496\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8548 - accuracy: 0.7000 - val_loss: 1.0471 - val_accuracy: 0.5812\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8447 - accuracy: 0.6778 - val_loss: 1.0546 - val_accuracy: 0.5726\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8396 - accuracy: 0.7000 - val_loss: 1.1273 - val_accuracy: 0.6410\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8206 - accuracy: 0.6926 - val_loss: 1.0650 - val_accuracy: 0.5812\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7549 - accuracy: 0.6852 - val_loss: 1.0712 - val_accuracy: 0.6667\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7713 - accuracy: 0.6963 - val_loss: 1.0589 - val_accuracy: 0.6410\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7413 - accuracy: 0.7074 - val_loss: 1.0354 - val_accuracy: 0.5726\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7217 - accuracy: 0.6963 - val_loss: 1.0242 - val_accuracy: 0.5812\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7206 - accuracy: 0.7037 - val_loss: 1.0240 - val_accuracy: 0.5726\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7148 - accuracy: 0.7037 - val_loss: 1.0237 - val_accuracy: 0.5812\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7176 - accuracy: 0.6963 - val_loss: 1.0200 - val_accuracy: 0.6068\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7126 - accuracy: 0.7185 - val_loss: 1.0361 - val_accuracy: 0.5983\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7330 - accuracy: 0.7111 - val_loss: 1.0509 - val_accuracy: 0.6496\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7497 - accuracy: 0.7037 - val_loss: 1.0252 - val_accuracy: 0.5897\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7173 - accuracy: 0.6926 - val_loss: 1.0413 - val_accuracy: 0.5812\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7122 - accuracy: 0.6889 - val_loss: 1.0289 - val_accuracy: 0.5812\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7145 - accuracy: 0.7000 - val_loss: 1.0427 - val_accuracy: 0.5812\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7207 - accuracy: 0.7074 - val_loss: 1.0334 - val_accuracy: 0.5812\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7139 - accuracy: 0.7111 - val_loss: 1.0370 - val_accuracy: 0.5812\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7043 - accuracy: 0.7222 - val_loss: 1.0308 - val_accuracy: 0.5726\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7098 - accuracy: 0.7000 - val_loss: 1.0369 - val_accuracy: 0.5726\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7017 - accuracy: 0.7074 - val_loss: 1.0471 - val_accuracy: 0.6068\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7188 - accuracy: 0.7111 - val_loss: 1.0373 - val_accuracy: 0.5812\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7072 - accuracy: 0.7074 - val_loss: 1.0444 - val_accuracy: 0.5812\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7092 - accuracy: 0.7037 - val_loss: 1.0377 - val_accuracy: 0.6410\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7084 - accuracy: 0.7185 - val_loss: 1.0276 - val_accuracy: 0.6068\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7112 - accuracy: 0.6852 - val_loss: 1.0229 - val_accuracy: 0.6068\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7082 - accuracy: 0.7111 - val_loss: 1.0232 - val_accuracy: 0.6325\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7103 - accuracy: 0.7111 - val_loss: 1.0299 - val_accuracy: 0.5812\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7035 - accuracy: 0.7111 - val_loss: 1.0399 - val_accuracy: 0.5812\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7063 - accuracy: 0.7037 - val_loss: 1.0309 - val_accuracy: 0.6496\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7068 - accuracy: 0.7185 - val_loss: 1.0330 - val_accuracy: 0.6068\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7104 - accuracy: 0.7111 - val_loss: 1.0202 - val_accuracy: 0.6325\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7020 - accuracy: 0.7037 - val_loss: 1.0260 - val_accuracy: 0.6325\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7023 - accuracy: 0.7037 - val_loss: 1.0437 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7099 - accuracy: 0.7074 - val_loss: 1.0335 - val_accuracy: 0.5812\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7079 - accuracy: 0.7111 - val_loss: 1.0355 - val_accuracy: 0.6410\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7190 - accuracy: 0.7148 - val_loss: 1.0369 - val_accuracy: 0.6496\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7073 - accuracy: 0.7111 - val_loss: 1.0435 - val_accuracy: 0.5983\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7168 - accuracy: 0.7000 - val_loss: 1.0231 - val_accuracy: 0.6410\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7106 - accuracy: 0.7074 - val_loss: 1.0233 - val_accuracy: 0.5726\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7113 - accuracy: 0.6963 - val_loss: 1.0266 - val_accuracy: 0.5726\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7028 - accuracy: 0.7000 - val_loss: 1.0326 - val_accuracy: 0.6581\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7091 - accuracy: 0.7148 - val_loss: 1.0553 - val_accuracy: 0.5897\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7121 - accuracy: 0.7074 - val_loss: 1.0385 - val_accuracy: 0.6239\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7084 - accuracy: 0.6889 - val_loss: 1.0411 - val_accuracy: 0.5983\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7034 - accuracy: 0.7037 - val_loss: 1.0241 - val_accuracy: 0.6410\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7081 - accuracy: 0.6963 - val_loss: 1.0271 - val_accuracy: 0.5983\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7115 - accuracy: 0.7000 - val_loss: 1.0259 - val_accuracy: 0.5983\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7059 - accuracy: 0.7037 - val_loss: 1.0198 - val_accuracy: 0.6325\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7205 - accuracy: 0.6963 - val_loss: 1.0180 - val_accuracy: 0.6325\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6969 - accuracy: 0.7185 - val_loss: 1.0314 - val_accuracy: 0.5983\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7009 - accuracy: 0.7148 - val_loss: 1.0383 - val_accuracy: 0.6410\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7109 - accuracy: 0.7074 - val_loss: 1.0517 - val_accuracy: 0.5812\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7079 - accuracy: 0.7074 - val_loss: 1.0331 - val_accuracy: 0.6325\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7117 - accuracy: 0.7037 - val_loss: 1.0295 - val_accuracy: 0.5897\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8006 - accuracy: 0.6852 - val_loss: 1.0682 - val_accuracy: 0.6667\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8455 - accuracy: 0.7037 - val_loss: 1.1439 - val_accuracy: 0.6667\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8041 - accuracy: 0.7000 - val_loss: 1.0731 - val_accuracy: 0.5897\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7799 - accuracy: 0.6852 - val_loss: 1.1615 - val_accuracy: 0.6496\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0202 - accuracy: 0.6926 - val_loss: 1.2160 - val_accuracy: 0.6581\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8190 - accuracy: 0.7074 - val_loss: 1.0471 - val_accuracy: 0.5726\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7469 - accuracy: 0.7185 - val_loss: 1.1735 - val_accuracy: 0.6667\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9309 - accuracy: 0.7037 - val_loss: 1.0875 - val_accuracy: 0.6239\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8103 - accuracy: 0.6778 - val_loss: 1.1073 - val_accuracy: 0.5983\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7408 - accuracy: 0.6815 - val_loss: 1.0734 - val_accuracy: 0.6239\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7192 - accuracy: 0.7222 - val_loss: 1.0694 - val_accuracy: 0.5897\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7361 - accuracy: 0.6926 - val_loss: 1.0719 - val_accuracy: 0.6667\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8134 - accuracy: 0.7037 - val_loss: 1.0829 - val_accuracy: 0.6667\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.7562 - accuracy: 0.6889 - val_loss: 1.0543 - val_accuracy: 0.5897\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7494 - accuracy: 0.7148 - val_loss: 1.1870 - val_accuracy: 0.6496\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8858 - accuracy: 0.7000 - val_loss: 1.0811 - val_accuracy: 0.6068\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7443 - accuracy: 0.7037 - val_loss: 1.0558 - val_accuracy: 0.5812\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7557 - accuracy: 0.7000 - val_loss: 1.0529 - val_accuracy: 0.5812\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7793 - accuracy: 0.7037 - val_loss: 1.0808 - val_accuracy: 0.5983\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7315 - accuracy: 0.7222 - val_loss: 1.1291 - val_accuracy: 0.6496\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7991 - accuracy: 0.6963 - val_loss: 1.0611 - val_accuracy: 0.5983\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7132 - accuracy: 0.7148 - val_loss: 1.0735 - val_accuracy: 0.5812\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7248 - accuracy: 0.7111 - val_loss: 1.0670 - val_accuracy: 0.6410\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7431 - accuracy: 0.7148 - val_loss: 1.0602 - val_accuracy: 0.5983\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7015 - accuracy: 0.7148 - val_loss: 1.0818 - val_accuracy: 0.5983\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7081 - accuracy: 0.7222 - val_loss: 1.0692 - val_accuracy: 0.6667\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7752 - accuracy: 0.7111 - val_loss: 1.0460 - val_accuracy: 0.6154\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7540 - accuracy: 0.7037 - val_loss: 1.1012 - val_accuracy: 0.6154\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7213 - accuracy: 0.7185 - val_loss: 1.0712 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c57eba8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 83us/step\n",
      "over-sampling test accuracy: 60.68%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 1, 2, 2,\n",
       "       1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1,\n",
       "       1, 2, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 1, 2, 2, 1,\n",
       "       2, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 0, 2, 2, 0, 1,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 1, 2, 0, 1, 1, 2, 1, 1, 2, 2, 1,\n",
       "       0, 1, 0, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa25     1     1\n",
       "1       CFBRSa07     0     0\n",
       "2         NRS247     0     0\n",
       "3          NY439     2     2\n",
       "4    CFBREBSa110     1     0\n",
       "..           ...   ...   ...\n",
       "112       SR1129     0     0\n",
       "113       NRS172     0     2\n",
       "114       NRS205     2     2\n",
       "115        NY439     2     2\n",
       "116       NRS249     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.273088</td>\n",
       "      <td>0.561901</td>\n",
       "      <td>0.165011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612003</td>\n",
       "      <td>0.292165</td>\n",
       "      <td>0.095832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.703594</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>0.010025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.996195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.901155</td>\n",
       "      <td>0.043834</td>\n",
       "      <td>0.055011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.588236</td>\n",
       "      <td>0.231665</td>\n",
       "      <td>0.180099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.349461</td>\n",
       "      <td>0.234379</td>\n",
       "      <td>0.416160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.985784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.996195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.349461</td>\n",
       "      <td>0.234379</td>\n",
       "      <td>0.416160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.273088  0.561901  0.165011\n",
       "1    0.612003  0.292165  0.095832\n",
       "2    0.703594  0.286382  0.010025\n",
       "3    0.000912  0.002892  0.996195\n",
       "4    0.901155  0.043834  0.055011\n",
       "..        ...       ...       ...\n",
       "112  0.588236  0.231665  0.180099\n",
       "113  0.349461  0.234379  0.416160\n",
       "114  0.014172  0.000044  0.985784\n",
       "115  0.000912  0.002892  0.996195\n",
       "116  0.349461  0.234379  0.416160\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.7487 - accuracy: 0.6926 - val_loss: 1.0754 - val_accuracy: 0.5385\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8105 - accuracy: 0.6630 - val_loss: 1.1082 - val_accuracy: 0.6154\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9931 - accuracy: 0.6407 - val_loss: 1.1000 - val_accuracy: 0.5812\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7994 - accuracy: 0.6815 - val_loss: 1.0535 - val_accuracy: 0.5726\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7899 - accuracy: 0.6704 - val_loss: 1.0287 - val_accuracy: 0.6410\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7671 - accuracy: 0.6852 - val_loss: 1.0359 - val_accuracy: 0.5470\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8124 - accuracy: 0.6815 - val_loss: 1.0461 - val_accuracy: 0.6496\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8979 - accuracy: 0.6630 - val_loss: 1.0790 - val_accuracy: 0.6239\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7814 - accuracy: 0.6815 - val_loss: 1.0424 - val_accuracy: 0.5641\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7575 - accuracy: 0.6852 - val_loss: 1.0414 - val_accuracy: 0.6239\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8256 - accuracy: 0.6815 - val_loss: 1.0162 - val_accuracy: 0.6239\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7378 - accuracy: 0.6815 - val_loss: 1.0668 - val_accuracy: 0.5641\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7924 - accuracy: 0.6667 - val_loss: 1.0660 - val_accuracy: 0.6239\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8567 - accuracy: 0.6852 - val_loss: 1.0249 - val_accuracy: 0.6239\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8287 - accuracy: 0.6852 - val_loss: 1.0354 - val_accuracy: 0.6154\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9270 - accuracy: 0.6778 - val_loss: 1.1157 - val_accuracy: 0.6154\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8458 - accuracy: 0.6778 - val_loss: 1.0327 - val_accuracy: 0.5470\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7735 - accuracy: 0.6407 - val_loss: 1.0194 - val_accuracy: 0.5556\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7477 - accuracy: 0.6815 - val_loss: 1.0170 - val_accuracy: 0.6068\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7803 - accuracy: 0.6741 - val_loss: 1.0118 - val_accuracy: 0.5470\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7453 - accuracy: 0.6852 - val_loss: 1.0143 - val_accuracy: 0.6154\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7520 - accuracy: 0.6889 - val_loss: 1.0112 - val_accuracy: 0.5470\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7490 - accuracy: 0.6741 - val_loss: 1.0357 - val_accuracy: 0.5385\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8302 - accuracy: 0.6593 - val_loss: 1.0700 - val_accuracy: 0.6239\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8347 - accuracy: 0.6852 - val_loss: 1.0047 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8058 - accuracy: 0.6593 - val_loss: 1.0161 - val_accuracy: 0.6154\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8391 - accuracy: 0.6815 - val_loss: 1.0156 - val_accuracy: 0.6239\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7427 - accuracy: 0.6852 - val_loss: 1.0521 - val_accuracy: 0.5385\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7935 - accuracy: 0.6630 - val_loss: 1.0424 - val_accuracy: 0.5897\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7744 - accuracy: 0.6852 - val_loss: 1.0402 - val_accuracy: 0.5641\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8144 - accuracy: 0.6741 - val_loss: 1.0269 - val_accuracy: 0.6154\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8283 - accuracy: 0.6815 - val_loss: 1.0334 - val_accuracy: 0.6325\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7560 - accuracy: 0.6963 - val_loss: 1.0448 - val_accuracy: 0.5812\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7661 - accuracy: 0.6852 - val_loss: 1.0959 - val_accuracy: 0.6410\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9630 - accuracy: 0.6815 - val_loss: 1.1014 - val_accuracy: 0.6410\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7743 - accuracy: 0.6741 - val_loss: 1.1123 - val_accuracy: 0.5299\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7953 - accuracy: 0.6556 - val_loss: 1.0792 - val_accuracy: 0.6410\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9436 - accuracy: 0.6778 - val_loss: 1.0957 - val_accuracy: 0.6496\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7649 - accuracy: 0.7000 - val_loss: 1.1403 - val_accuracy: 0.5556\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9419 - accuracy: 0.6593 - val_loss: 1.1201 - val_accuracy: 0.6325\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9530 - accuracy: 0.6704 - val_loss: 1.1416 - val_accuracy: 0.6068\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8323 - accuracy: 0.6630 - val_loss: 1.0676 - val_accuracy: 0.5299\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8660 - accuracy: 0.6444 - val_loss: 1.0284 - val_accuracy: 0.5897\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8314 - accuracy: 0.6778 - val_loss: 1.1010 - val_accuracy: 0.6239\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8416 - accuracy: 0.6778 - val_loss: 1.0083 - val_accuracy: 0.5470\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7479 - accuracy: 0.6778 - val_loss: 1.0230 - val_accuracy: 0.5299\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7465 - accuracy: 0.6889 - val_loss: 1.0020 - val_accuracy: 0.6068\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7642 - accuracy: 0.6889 - val_loss: 1.0015 - val_accuracy: 0.5726\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7336 - accuracy: 0.6963 - val_loss: 1.0199 - val_accuracy: 0.5470\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7381 - accuracy: 0.6889 - val_loss: 1.0033 - val_accuracy: 0.6154\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7683 - accuracy: 0.7000 - val_loss: 1.0055 - val_accuracy: 0.5726\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9970 - accuracy: 0.6519 - val_loss: 1.0163 - val_accuracy: 0.5812\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9854 - accuracy: 0.6741 - val_loss: 1.3688 - val_accuracy: 0.6496\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.2710 - accuracy: 0.6556 - val_loss: 1.2216 - val_accuracy: 0.6410\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9482 - accuracy: 0.6370 - val_loss: 1.0450 - val_accuracy: 0.5299\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8215 - accuracy: 0.6481 - val_loss: 1.0705 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8033 - accuracy: 0.6593 - val_loss: 1.0235 - val_accuracy: 0.6068\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7562 - accuracy: 0.6926 - val_loss: 1.0218 - val_accuracy: 0.5641\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7567 - accuracy: 0.6889 - val_loss: 1.0093 - val_accuracy: 0.5385\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7578 - accuracy: 0.6963 - val_loss: 1.0017 - val_accuracy: 0.5556\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7397 - accuracy: 0.6963 - val_loss: 1.0137 - val_accuracy: 0.5556\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7407 - accuracy: 0.6963 - val_loss: 1.0054 - val_accuracy: 0.6154\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8043 - accuracy: 0.6741 - val_loss: 1.0541 - val_accuracy: 0.6410\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7722 - accuracy: 0.6852 - val_loss: 1.0378 - val_accuracy: 0.5641\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7554 - accuracy: 0.6741 - val_loss: 1.0087 - val_accuracy: 0.5983\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7382 - accuracy: 0.6852 - val_loss: 1.0298 - val_accuracy: 0.5983\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7691 - accuracy: 0.6852 - val_loss: 1.0079 - val_accuracy: 0.5641\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7499 - accuracy: 0.6926 - val_loss: 1.0000 - val_accuracy: 0.5897\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7342 - accuracy: 0.6889 - val_loss: 1.0020 - val_accuracy: 0.6068\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7342 - accuracy: 0.6926 - val_loss: 1.0084 - val_accuracy: 0.5897\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7506 - accuracy: 0.6926 - val_loss: 1.0044 - val_accuracy: 0.5983\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7418 - accuracy: 0.6852 - val_loss: 1.0084 - val_accuracy: 0.5897\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7318 - accuracy: 0.6852 - val_loss: 1.0028 - val_accuracy: 0.6154\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7445 - accuracy: 0.6778 - val_loss: 0.9966 - val_accuracy: 0.5897\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7466 - accuracy: 0.6926 - val_loss: 0.9978 - val_accuracy: 0.5983\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7406 - accuracy: 0.6778 - val_loss: 1.0096 - val_accuracy: 0.5897\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7381 - accuracy: 0.6852 - val_loss: 0.9982 - val_accuracy: 0.5983\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7469 - accuracy: 0.6815 - val_loss: 1.0078 - val_accuracy: 0.5983\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7364 - accuracy: 0.6852 - val_loss: 1.0048 - val_accuracy: 0.6410\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8054 - accuracy: 0.6815 - val_loss: 0.9932 - val_accuracy: 0.5897\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7590 - accuracy: 0.6667 - val_loss: 0.9932 - val_accuracy: 0.6068\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7578 - accuracy: 0.6815 - val_loss: 1.0073 - val_accuracy: 0.6239\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7638 - accuracy: 0.6852 - val_loss: 1.0066 - val_accuracy: 0.6068\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7451 - accuracy: 0.6778 - val_loss: 1.0052 - val_accuracy: 0.6154\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7414 - accuracy: 0.6926 - val_loss: 0.9972 - val_accuracy: 0.6068\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7416 - accuracy: 0.6926 - val_loss: 0.9904 - val_accuracy: 0.6154\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7284 - accuracy: 0.6926 - val_loss: 1.0016 - val_accuracy: 0.6154\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7369 - accuracy: 0.6815 - val_loss: 0.9956 - val_accuracy: 0.6154\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7333 - accuracy: 0.6852 - val_loss: 1.0070 - val_accuracy: 0.6154\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7416 - accuracy: 0.6852 - val_loss: 0.9918 - val_accuracy: 0.6325\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7327 - accuracy: 0.6852 - val_loss: 0.9936 - val_accuracy: 0.6154\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7438 - accuracy: 0.6815 - val_loss: 0.9858 - val_accuracy: 0.6068\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7534 - accuracy: 0.6889 - val_loss: 0.9925 - val_accuracy: 0.6325\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7599 - accuracy: 0.6889 - val_loss: 0.9930 - val_accuracy: 0.6325\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7320 - accuracy: 0.7000 - val_loss: 1.0047 - val_accuracy: 0.6154\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7335 - accuracy: 0.6889 - val_loss: 1.0155 - val_accuracy: 0.6410\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8067 - accuracy: 0.6815 - val_loss: 0.9994 - val_accuracy: 0.6239\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8121 - accuracy: 0.6630 - val_loss: 0.9988 - val_accuracy: 0.6325\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7898 - accuracy: 0.6852 - val_loss: 1.0242 - val_accuracy: 0.6410\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7789 - accuracy: 0.6667 - val_loss: 0.9995 - val_accuracy: 0.6410\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9485 - accuracy: 0.6778 - val_loss: 1.2168 - val_accuracy: 0.6325\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0249 - accuracy: 0.6778 - val_loss: 1.0348 - val_accuracy: 0.6410\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7522 - accuracy: 0.6926 - val_loss: 1.0904 - val_accuracy: 0.5556\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8259 - accuracy: 0.6593 - val_loss: 1.0456 - val_accuracy: 0.6325\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8108 - accuracy: 0.6815 - val_loss: 1.0028 - val_accuracy: 0.5726\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7703 - accuracy: 0.6778 - val_loss: 0.9960 - val_accuracy: 0.5812\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7342 - accuracy: 0.7000 - val_loss: 0.9967 - val_accuracy: 0.5726\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7688 - accuracy: 0.6778 - val_loss: 1.0033 - val_accuracy: 0.6410\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7610 - accuracy: 0.6889 - val_loss: 1.0047 - val_accuracy: 0.5726\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7620 - accuracy: 0.6741 - val_loss: 1.0106 - val_accuracy: 0.6410\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7679 - accuracy: 0.6852 - val_loss: 1.0177 - val_accuracy: 0.6325\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7516 - accuracy: 0.6778 - val_loss: 1.0262 - val_accuracy: 0.5726\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 45us/step - loss: 0.7449 - accuracy: 0.6889 - val_loss: 1.0076 - val_accuracy: 0.5726\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7533 - accuracy: 0.7000 - val_loss: 0.9954 - val_accuracy: 0.6154\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7311 - accuracy: 0.6963 - val_loss: 1.0045 - val_accuracy: 0.5641\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7390 - accuracy: 0.6889 - val_loss: 0.9936 - val_accuracy: 0.5983\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7336 - accuracy: 0.6889 - val_loss: 0.9937 - val_accuracy: 0.6154\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7351 - accuracy: 0.6741 - val_loss: 1.0067 - val_accuracy: 0.5812\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7302 - accuracy: 0.7037 - val_loss: 1.0022 - val_accuracy: 0.5726\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7345 - accuracy: 0.6852 - val_loss: 1.0076 - val_accuracy: 0.5641\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7456 - accuracy: 0.6926 - val_loss: 1.0452 - val_accuracy: 0.6496\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8545 - accuracy: 0.6778 - val_loss: 1.0084 - val_accuracy: 0.6410\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7608 - accuracy: 0.6519 - val_loss: 0.9991 - val_accuracy: 0.5726\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7627 - accuracy: 0.6852 - val_loss: 1.0082 - val_accuracy: 0.6410\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7246 - accuracy: 0.6926 - val_loss: 1.0322 - val_accuracy: 0.5812\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7613 - accuracy: 0.6852 - val_loss: 0.9948 - val_accuracy: 0.6410\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7419 - accuracy: 0.6889 - val_loss: 0.9929 - val_accuracy: 0.5726\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7346 - accuracy: 0.6963 - val_loss: 0.9982 - val_accuracy: 0.5641\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7406 - accuracy: 0.7000 - val_loss: 0.9929 - val_accuracy: 0.5726\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7313 - accuracy: 0.6852 - val_loss: 1.0093 - val_accuracy: 0.5726\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7243 - accuracy: 0.6889 - val_loss: 0.9949 - val_accuracy: 0.6154\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7246 - accuracy: 0.6926 - val_loss: 1.0049 - val_accuracy: 0.5726\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7446 - accuracy: 0.6815 - val_loss: 0.9822 - val_accuracy: 0.6154\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7413 - accuracy: 0.6815 - val_loss: 0.9894 - val_accuracy: 0.6068\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7289 - accuracy: 0.6889 - val_loss: 0.9994 - val_accuracy: 0.6154\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7313 - accuracy: 0.7000 - val_loss: 0.9907 - val_accuracy: 0.6239\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7354 - accuracy: 0.6889 - val_loss: 0.9923 - val_accuracy: 0.6154\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7540 - accuracy: 0.6852 - val_loss: 1.0186 - val_accuracy: 0.5897\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7604 - accuracy: 0.6778 - val_loss: 1.0079 - val_accuracy: 0.5812\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7514 - accuracy: 0.6778 - val_loss: 1.0417 - val_accuracy: 0.6496\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9138 - accuracy: 0.6741 - val_loss: 1.0393 - val_accuracy: 0.6496\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7520 - accuracy: 0.6852 - val_loss: 1.0522 - val_accuracy: 0.5641\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7826 - accuracy: 0.6741 - val_loss: 1.0270 - val_accuracy: 0.6239\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7709 - accuracy: 0.6852 - val_loss: 1.0296 - val_accuracy: 0.5556\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7427 - accuracy: 0.6963 - val_loss: 0.9954 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7604 - accuracy: 0.6778 - val_loss: 0.9875 - val_accuracy: 0.5897\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7240 - accuracy: 0.6889 - val_loss: 1.0282 - val_accuracy: 0.5641\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8052 - accuracy: 0.6815 - val_loss: 1.0666 - val_accuracy: 0.6154\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7994 - accuracy: 0.6852 - val_loss: 1.0609 - val_accuracy: 0.5641\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7864 - accuracy: 0.6481 - val_loss: 1.0314 - val_accuracy: 0.6239\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7605 - accuracy: 0.6704 - val_loss: 1.0110 - val_accuracy: 0.5983\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7584 - accuracy: 0.6852 - val_loss: 1.0001 - val_accuracy: 0.6068\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7244 - accuracy: 0.6852 - val_loss: 1.0102 - val_accuracy: 0.6068\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7427 - accuracy: 0.6815 - val_loss: 0.9966 - val_accuracy: 0.5983\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7406 - accuracy: 0.6926 - val_loss: 1.0006 - val_accuracy: 0.5897\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7373 - accuracy: 0.6889 - val_loss: 1.0114 - val_accuracy: 0.5983\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7297 - accuracy: 0.6963 - val_loss: 1.0033 - val_accuracy: 0.5641\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7466 - accuracy: 0.6889 - val_loss: 1.0102 - val_accuracy: 0.5556\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7910 - accuracy: 0.6704 - val_loss: 1.0649 - val_accuracy: 0.6496\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8689 - accuracy: 0.6704 - val_loss: 1.0372 - val_accuracy: 0.6410\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7510 - accuracy: 0.6852 - val_loss: 1.0246 - val_accuracy: 0.5556\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7472 - accuracy: 0.6889 - val_loss: 0.9945 - val_accuracy: 0.6239\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7270 - accuracy: 0.6815 - val_loss: 1.0172 - val_accuracy: 0.5812\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7232 - accuracy: 0.7037 - val_loss: 1.0054 - val_accuracy: 0.6239\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7431 - accuracy: 0.6778 - val_loss: 1.0493 - val_accuracy: 0.5812\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0055 - accuracy: 0.6519 - val_loss: 1.0432 - val_accuracy: 0.6410\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8794 - accuracy: 0.6889 - val_loss: 1.1698 - val_accuracy: 0.6325\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9143 - accuracy: 0.6889 - val_loss: 1.0154 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8325 - accuracy: 0.6407 - val_loss: 1.0390 - val_accuracy: 0.5385\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8299 - accuracy: 0.6704 - val_loss: 1.0603 - val_accuracy: 0.6154\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8009 - accuracy: 0.6741 - val_loss: 1.0572 - val_accuracy: 0.5470\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7568 - accuracy: 0.6815 - val_loss: 1.0254 - val_accuracy: 0.6239\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7662 - accuracy: 0.6667 - val_loss: 1.0221 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7309 - accuracy: 0.7037 - val_loss: 1.0148 - val_accuracy: 0.6239\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8061 - accuracy: 0.6778 - val_loss: 1.0415 - val_accuracy: 0.6239\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7387 - accuracy: 0.7111 - val_loss: 1.0499 - val_accuracy: 0.5556\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7591 - accuracy: 0.6630 - val_loss: 1.0167 - val_accuracy: 0.5726\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7388 - accuracy: 0.6852 - val_loss: 1.0189 - val_accuracy: 0.5470\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7398 - accuracy: 0.6852 - val_loss: 1.0011 - val_accuracy: 0.5812\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7321 - accuracy: 0.6963 - val_loss: 1.0010 - val_accuracy: 0.6239\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7338 - accuracy: 0.6889 - val_loss: 1.0069 - val_accuracy: 0.5556\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7297 - accuracy: 0.7000 - val_loss: 1.0038 - val_accuracy: 0.5641\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7234 - accuracy: 0.7074 - val_loss: 1.0164 - val_accuracy: 0.5556\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7323 - accuracy: 0.6889 - val_loss: 1.0106 - val_accuracy: 0.5556\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7633 - accuracy: 0.6963 - val_loss: 1.0145 - val_accuracy: 0.6154\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8040 - accuracy: 0.6852 - val_loss: 1.0476 - val_accuracy: 0.6239\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7534 - accuracy: 0.6963 - val_loss: 1.0676 - val_accuracy: 0.5385\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9071 - accuracy: 0.64 - 0s 48us/step - loss: 0.8023 - accuracy: 0.6852 - val_loss: 1.0573 - val_accuracy: 0.6239\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8621 - accuracy: 0.6852 - val_loss: 1.0274 - val_accuracy: 0.6239\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8756 - accuracy: 0.6593 - val_loss: 1.0105 - val_accuracy: 0.5385\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8702 - accuracy: 0.6630 - val_loss: 1.1561 - val_accuracy: 0.6496\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8856 - accuracy: 0.6889 - val_loss: 1.0536 - val_accuracy: 0.5641\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7842 - accuracy: 0.6556 - val_loss: 1.0642 - val_accuracy: 0.6154\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8416 - accuracy: 0.6704 - val_loss: 1.0069 - val_accuracy: 0.5726\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7535 - accuracy: 0.6926 - val_loss: 1.0820 - val_accuracy: 0.5556\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8078 - accuracy: 0.6926 - val_loss: 1.0725 - val_accuracy: 0.6068\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8480 - accuracy: 0.6741 - val_loss: 1.0353 - val_accuracy: 0.5556\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7737 - accuracy: 0.6926 - val_loss: 1.0316 - val_accuracy: 0.5726\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7435 - accuracy: 0.6889 - val_loss: 1.0188 - val_accuracy: 0.6154\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7686 - accuracy: 0.6963 - val_loss: 1.0098 - val_accuracy: 0.6068\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7438 - accuracy: 0.6778 - val_loss: 1.0336 - val_accuracy: 0.5726\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7277 - accuracy: 0.6889 - val_loss: 1.0118 - val_accuracy: 0.6068\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7374 - accuracy: 0.6852 - val_loss: 1.0076 - val_accuracy: 0.6068\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7278 - accuracy: 0.7000 - val_loss: 1.0113 - val_accuracy: 0.5812\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7272 - accuracy: 0.6926 - val_loss: 0.9951 - val_accuracy: 0.6154\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7354 - accuracy: 0.6815 - val_loss: 0.9961 - val_accuracy: 0.5897\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7286 - accuracy: 0.6889 - val_loss: 1.0081 - val_accuracy: 0.5641\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7325 - accuracy: 0.7000 - val_loss: 0.9997 - val_accuracy: 0.6154\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7257 - accuracy: 0.6963 - val_loss: 1.0046 - val_accuracy: 0.5641\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7560 - accuracy: 0.6815 - val_loss: 1.0111 - val_accuracy: 0.6239\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.7886 - accuracy: 0.6815 - val_loss: 1.0058 - val_accuracy: 0.6154\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7264 - accuracy: 0.7111 - val_loss: 0.9971 - val_accuracy: 0.6068\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7230 - accuracy: 0.6963 - val_loss: 0.9904 - val_accuracy: 0.6068\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7274 - accuracy: 0.6889 - val_loss: 1.0010 - val_accuracy: 0.6068\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7184 - accuracy: 0.6852 - val_loss: 0.9962 - val_accuracy: 0.6410\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7874 - accuracy: 0.6926 - val_loss: 0.9916 - val_accuracy: 0.6410\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7296 - accuracy: 0.6815 - val_loss: 1.0212 - val_accuracy: 0.5812\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7263 - accuracy: 0.6815 - val_loss: 1.0236 - val_accuracy: 0.6410\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7932 - accuracy: 0.6852 - val_loss: 0.9947 - val_accuracy: 0.6068\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7324 - accuracy: 0.6889 - val_loss: 0.9930 - val_accuracy: 0.6410\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 330us/step - loss: 0.7585 - accuracy: 0.6741 - val_loss: 0.9916 - val_accuracy: 0.6410\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 786us/step - loss: 0.7377 - accuracy: 0.6889 - val_loss: 1.0053 - val_accuracy: 0.5726\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7206 - accuracy: 0.7000 - val_loss: 0.9954 - val_accuracy: 0.6410\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7831 - accuracy: 0.6852 - val_loss: 0.9967 - val_accuracy: 0.6410\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7158 - accuracy: 0.6889 - val_loss: 0.9900 - val_accuracy: 0.6068\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7666 - accuracy: 0.6963 - val_loss: 1.0508 - val_accuracy: 0.6410\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.7589 - accuracy: 0.6852 - val_loss: 1.0384 - val_accuracy: 0.5812\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7777 - accuracy: 0.6444 - val_loss: 1.0808 - val_accuracy: 0.6410\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 416us/step - loss: 0.9225 - accuracy: 0.6741 - val_loss: 1.0475 - val_accuracy: 0.6410\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7658 - accuracy: 0.6852 - val_loss: 1.1613 - val_accuracy: 0.5556\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9449 - accuracy: 0.6667 - val_loss: 1.2293 - val_accuracy: 0.5983\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.2290 - accuracy: 0.6185 - val_loss: 1.1913 - val_accuracy: 0.6325\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8617 - accuracy: 0.6593 - val_loss: 1.1935 - val_accuracy: 0.5214\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0076 - accuracy: 0.6296 - val_loss: 1.1052 - val_accuracy: 0.6239\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0858 - accuracy: 0.6852 - val_loss: 1.3481 - val_accuracy: 0.6581\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.1658 - accuracy: 0.6741 - val_loss: 1.1838 - val_accuracy: 0.6154\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 319us/step - loss: 0.8495 - accuracy: 0.6852 - val_loss: 1.2372 - val_accuracy: 0.5214\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9907 - accuracy: 0.6370 - val_loss: 1.0888 - val_accuracy: 0.5983\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8204 - accuracy: 0.6778 - val_loss: 1.0199 - val_accuracy: 0.5556\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7664 - accuracy: 0.6926 - val_loss: 1.0252 - val_accuracy: 0.5812\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8071 - accuracy: 0.6704 - val_loss: 1.0306 - val_accuracy: 0.5812\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7501 - accuracy: 0.6926 - val_loss: 1.0629 - val_accuracy: 0.5726\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7577 - accuracy: 0.6926 - val_loss: 1.0595 - val_accuracy: 0.6325\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8187 - accuracy: 0.6852 - val_loss: 1.0257 - val_accuracy: 0.5812\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7398 - accuracy: 0.6778 - val_loss: 1.0230 - val_accuracy: 0.5726\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7875 - accuracy: 0.6741 - val_loss: 1.0271 - val_accuracy: 0.6325\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8010 - accuracy: 0.6556 - val_loss: 1.0280 - val_accuracy: 0.5812\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7591 - accuracy: 0.7000 - val_loss: 1.0568 - val_accuracy: 0.6410\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7472 - accuracy: 0.6889 - val_loss: 1.0666 - val_accuracy: 0.5812\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8254 - accuracy: 0.6741 - val_loss: 1.1501 - val_accuracy: 0.6325\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9987 - accuracy: 0.6704 - val_loss: 1.1340 - val_accuracy: 0.6154\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8210 - accuracy: 0.6593 - val_loss: 1.2135 - val_accuracy: 0.5299\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9527 - accuracy: 0.6037 - val_loss: 1.1531 - val_accuracy: 0.5726\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8839 - accuracy: 0.6704 - val_loss: 1.0529 - val_accuracy: 0.5726\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7576 - accuracy: 0.6889 - val_loss: 1.0573 - val_accuracy: 0.5470\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7788 - accuracy: 0.6889 - val_loss: 1.0761 - val_accuracy: 0.5983\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8799 - accuracy: 0.6741 - val_loss: 1.0546 - val_accuracy: 0.6239\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7354 - accuracy: 0.6889 - val_loss: 1.0666 - val_accuracy: 0.5556\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7864 - accuracy: 0.6741 - val_loss: 1.1525 - val_accuracy: 0.6325\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0843 - accuracy: 0.6630 - val_loss: 1.2554 - val_accuracy: 0.6496\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0091 - accuracy: 0.6741 - val_loss: 1.0670 - val_accuracy: 0.5726\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8187 - accuracy: 0.6407 - val_loss: 1.0450 - val_accuracy: 0.5556\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7764 - accuracy: 0.6667 - val_loss: 1.0238 - val_accuracy: 0.5897\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7481 - accuracy: 0.6778 - val_loss: 1.0359 - val_accuracy: 0.5641\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7560 - accuracy: 0.6926 - val_loss: 1.0307 - val_accuracy: 0.5726\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7440 - accuracy: 0.6889 - val_loss: 1.0371 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7328 - accuracy: 0.6963 - val_loss: 1.0167 - val_accuracy: 0.5726\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7348 - accuracy: 0.7037 - val_loss: 1.0213 - val_accuracy: 0.5812\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7319 - accuracy: 0.7037 - val_loss: 1.0175 - val_accuracy: 0.5726\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7331 - accuracy: 0.6852 - val_loss: 1.0163 - val_accuracy: 0.5556\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7212 - accuracy: 0.6926 - val_loss: 1.0432 - val_accuracy: 0.5641\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7467 - accuracy: 0.6889 - val_loss: 1.0162 - val_accuracy: 0.5641\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.7221 - accuracy: 0.6963 - val_loss: 1.0118 - val_accuracy: 0.5726\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7236 - accuracy: 0.6889 - val_loss: 1.0098 - val_accuracy: 0.5983\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.7188 - accuracy: 0.6852 - val_loss: 1.0133 - val_accuracy: 0.6068\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.7278 - accuracy: 0.6926 - val_loss: 1.0212 - val_accuracy: 0.5726\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 299us/step - loss: 0.7280 - accuracy: 0.6889 - val_loss: 1.0118 - val_accuracy: 0.6068\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7266 - accuracy: 0.6852 - val_loss: 1.0242 - val_accuracy: 0.6154\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 965us/step - loss: 0.7316 - accuracy: 0.6778 - val_loss: 1.0071 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7198 - accuracy: 0.6926 - val_loss: 0.9991 - val_accuracy: 0.6239\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7306 - accuracy: 0.6741 - val_loss: 1.0003 - val_accuracy: 0.6068\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.7268 - accuracy: 0.6889 - val_loss: 1.0067 - val_accuracy: 0.6068\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7183 - accuracy: 0.6926 - val_loss: 1.0079 - val_accuracy: 0.6239\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7255 - accuracy: 0.6926 - val_loss: 1.0034 - val_accuracy: 0.6068\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7179 - accuracy: 0.6889 - val_loss: 1.0015 - val_accuracy: 0.6068\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7335 - accuracy: 0.6815 - val_loss: 0.9985 - val_accuracy: 0.6239\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7573 - accuracy: 0.6815 - val_loss: 0.9957 - val_accuracy: 0.6068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7591 - accuracy: 0.6815 - val_loss: 1.0197 - val_accuracy: 0.6410\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8330 - accuracy: 0.6741 - val_loss: 1.1059 - val_accuracy: 0.6239\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8139 - accuracy: 0.6889 - val_loss: 1.0308 - val_accuracy: 0.5556\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8087 - accuracy: 0.6519 - val_loss: 1.0185 - val_accuracy: 0.6154\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7871 - accuracy: 0.6778 - val_loss: 1.0397 - val_accuracy: 0.6410\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7619 - accuracy: 0.6741 - val_loss: 1.0240 - val_accuracy: 0.5556\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7473 - accuracy: 0.6926 - val_loss: 1.0141 - val_accuracy: 0.6154\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 1.0299 - val_accuracy: 0.6068\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7381 - accuracy: 0.6815 - val_loss: 1.0202 - val_accuracy: 0.6239\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8488 - accuracy: 0.6778 - val_loss: 1.0628 - val_accuracy: 0.6325\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7707 - accuracy: 0.6815 - val_loss: 1.0230 - val_accuracy: 0.5812\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7641 - accuracy: 0.6815 - val_loss: 1.0300 - val_accuracy: 0.6410\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7503 - accuracy: 0.6889 - val_loss: 1.0216 - val_accuracy: 0.5726\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7263 - accuracy: 0.6926 - val_loss: 1.0054 - val_accuracy: 0.6239\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8323 - accuracy: 0.6852 - val_loss: 1.0288 - val_accuracy: 0.6496\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0108 - accuracy: 0.6556 - val_loss: 1.0505 - val_accuracy: 0.5812\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7459 - accuracy: 0.6704 - val_loss: 1.0174 - val_accuracy: 0.6496\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7552 - accuracy: 0.7000 - val_loss: 1.0268 - val_accuracy: 0.5812\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7226 - accuracy: 0.7037 - val_loss: 1.0112 - val_accuracy: 0.6410\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7330 - accuracy: 0.6889 - val_loss: 1.0082 - val_accuracy: 0.5556\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7337 - accuracy: 0.6926 - val_loss: 1.0286 - val_accuracy: 0.5726\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7457 - accuracy: 0.6741 - val_loss: 1.0499 - val_accuracy: 0.6325\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8168 - accuracy: 0.6778 - val_loss: 1.0173 - val_accuracy: 0.6410\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7414 - accuracy: 0.6889 - val_loss: 0.9996 - val_accuracy: 0.6410\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8853 - accuracy: 0.6704 - val_loss: 1.2073 - val_accuracy: 0.6581\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9863 - accuracy: 0.6778 - val_loss: 1.0837 - val_accuracy: 0.6325\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8329 - accuracy: 0.6519 - val_loss: 1.0736 - val_accuracy: 0.5556\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7806 - accuracy: 0.6519 - val_loss: 1.0265 - val_accuracy: 0.6239\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7525 - accuracy: 0.6815 - val_loss: 1.0020 - val_accuracy: 0.5812\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7429 - accuracy: 0.6889 - val_loss: 0.9978 - val_accuracy: 0.6410\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.7533 - accuracy: 0.6963 - val_loss: 1.0776 - val_accuracy: 0.5726\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7689 - accuracy: 0.6852 - val_loss: 1.0721 - val_accuracy: 0.6410\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8446 - accuracy: 0.6778 - val_loss: 1.0227 - val_accuracy: 0.5983\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8084 - accuracy: 0.6852 - val_loss: 1.0233 - val_accuracy: 0.5641\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7837 - accuracy: 0.6889 - val_loss: 1.0251 - val_accuracy: 0.6154\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7668 - accuracy: 0.6630 - val_loss: 1.0247 - val_accuracy: 0.6325\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7592 - accuracy: 0.6852 - val_loss: 1.0255 - val_accuracy: 0.6496\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7297 - accuracy: 0.6963 - val_loss: 1.0339 - val_accuracy: 0.5812\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7552 - accuracy: 0.6926 - val_loss: 1.0515 - val_accuracy: 0.6410\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9090 - accuracy: 0.6778 - val_loss: 1.0980 - val_accuracy: 0.6325\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8309 - accuracy: 0.6481 - val_loss: 1.1287 - val_accuracy: 0.5812\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8585 - accuracy: 0.6889 - val_loss: 1.1368 - val_accuracy: 0.6410\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9836 - accuracy: 0.6667 - val_loss: 1.1095 - val_accuracy: 0.6410\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8052 - accuracy: 0.6741 - val_loss: 1.2336 - val_accuracy: 0.5470\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9585 - accuracy: 0.6556 - val_loss: 1.1198 - val_accuracy: 0.6496\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0916 - accuracy: 0.6630 - val_loss: 1.2678 - val_accuracy: 0.6581\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.0146 - accuracy: 0.6889 - val_loss: 1.0636 - val_accuracy: 0.5812\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7703 - accuracy: 0.6593 - val_loss: 1.0477 - val_accuracy: 0.5470\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.7529 - accuracy: 0.6630 - val_loss: 1.0248 - val_accuracy: 0.5897\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7380 - accuracy: 0.6852 - val_loss: 1.0365 - val_accuracy: 0.5726\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7135 - accuracy: 0.6926 - val_loss: 1.0084 - val_accuracy: 0.6325\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7517 - accuracy: 0.6593 - val_loss: 1.0064 - val_accuracy: 0.5726\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7441 - accuracy: 0.6852 - val_loss: 1.0043 - val_accuracy: 0.5556\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7327 - accuracy: 0.6926 - val_loss: 1.0077 - val_accuracy: 0.6068\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7163 - accuracy: 0.7111 - val_loss: 1.0185 - val_accuracy: 0.5641\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7243 - accuracy: 0.6926 - val_loss: 1.0137 - val_accuracy: 0.5812\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7213 - accuracy: 0.7037 - val_loss: 1.0066 - val_accuracy: 0.6068\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7169 - accuracy: 0.7000 - val_loss: 1.0082 - val_accuracy: 0.5983\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7203 - accuracy: 0.6778 - val_loss: 1.0066 - val_accuracy: 0.5556\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7360 - accuracy: 0.6926 - val_loss: 1.0046 - val_accuracy: 0.5983\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7514 - accuracy: 0.6926 - val_loss: 1.0265 - val_accuracy: 0.6239\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7509 - accuracy: 0.7000 - val_loss: 1.0202 - val_accuracy: 0.5726\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7254 - accuracy: 0.6963 - val_loss: 0.9994 - val_accuracy: 0.5983\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7221 - accuracy: 0.6963 - val_loss: 0.9983 - val_accuracy: 0.5556\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7407 - accuracy: 0.6963 - val_loss: 1.0492 - val_accuracy: 0.5641\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7765 - accuracy: 0.6778 - val_loss: 1.1685 - val_accuracy: 0.5726\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8900 - accuracy: 0.6296 - val_loss: 1.1058 - val_accuracy: 0.5470\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7815 - accuracy: 0.6778 - val_loss: 1.1273 - val_accuracy: 0.6068\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8106 - accuracy: 0.6667 - val_loss: 1.0141 - val_accuracy: 0.6154\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7502 - accuracy: 0.6889 - val_loss: 1.0123 - val_accuracy: 0.6410\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9229 - accuracy: 0.6815 - val_loss: 1.1347 - val_accuracy: 0.6325\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8330 - accuracy: 0.6778 - val_loss: 1.1355 - val_accuracy: 0.5641\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9553 - accuracy: 0.6556 - val_loss: 1.2780 - val_accuracy: 0.5641\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.0358 - accuracy: 0.6296 - val_loss: 1.0798 - val_accuracy: 0.5214\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7511 - accuracy: 0.6889 - val_loss: 1.0529 - val_accuracy: 0.5470\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8323 - accuracy: 0.6741 - val_loss: 1.2337 - val_accuracy: 0.5556\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9149 - accuracy: 0.6296 - val_loss: 1.1038 - val_accuracy: 0.5641\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7605 - accuracy: 0.6889 - val_loss: 1.0593 - val_accuracy: 0.5812\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7684 - accuracy: 0.6741 - val_loss: 1.0388 - val_accuracy: 0.5556\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8359 - accuracy: 0.6815 - val_loss: 1.0525 - val_accuracy: 0.6239\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8571 - accuracy: 0.6852 - val_loss: 1.1490 - val_accuracy: 0.6239\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8329 - accuracy: 0.6815 - val_loss: 1.0629 - val_accuracy: 0.5470\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9177 - accuracy: 0.6519 - val_loss: 1.0537 - val_accuracy: 0.6239\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8732 - accuracy: 0.6852 - val_loss: 1.1452 - val_accuracy: 0.6410\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.8506 - accuracy: 0.6852 - val_loss: 1.0422 - val_accuracy: 0.5556\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8010 - accuracy: 0.6704 - val_loss: 1.1278 - val_accuracy: 0.5556\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9133 - accuracy: 0.6370 - val_loss: 1.0757 - val_accuracy: 0.5812\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7678 - accuracy: 0.6815 - val_loss: 1.0768 - val_accuracy: 0.5897\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8655 - accuracy: 0.6704 - val_loss: 1.2190 - val_accuracy: 0.6496\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.9695 - accuracy: 0.6704 - val_loss: 1.0386 - val_accuracy: 0.5812\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7722 - accuracy: 0.6741 - val_loss: 1.0394 - val_accuracy: 0.5641\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7405 - accuracy: 0.6815 - val_loss: 1.0418 - val_accuracy: 0.5726\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.7447 - accuracy: 0.6852 - val_loss: 1.0337 - val_accuracy: 0.5726\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7593 - accuracy: 0.6741 - val_loss: 1.0577 - val_accuracy: 0.6325\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7578 - accuracy: 0.6926 - val_loss: 1.0610 - val_accuracy: 0.5726\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7480 - accuracy: 0.6852 - val_loss: 1.0283 - val_accuracy: 0.6325\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7529 - accuracy: 0.6926 - val_loss: 1.0291 - val_accuracy: 0.5641\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7250 - accuracy: 0.6963 - val_loss: 1.0485 - val_accuracy: 0.5470\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7195 - accuracy: 0.7074 - val_loss: 1.0283 - val_accuracy: 0.5556\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7146 - accuracy: 0.7111 - val_loss: 1.0344 - val_accuracy: 0.5556\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7224 - accuracy: 0.6963 - val_loss: 1.0180 - val_accuracy: 0.5556\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7178 - accuracy: 0.7000 - val_loss: 1.0152 - val_accuracy: 0.5556\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7244 - accuracy: 0.6963 - val_loss: 1.0153 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7092 - accuracy: 0.6852 - val_loss: 1.0305 - val_accuracy: 0.5726\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7159 - accuracy: 0.6926 - val_loss: 1.0283 - val_accuracy: 0.5556\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7218 - accuracy: 0.7000 - val_loss: 1.0224 - val_accuracy: 0.5983\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7306 - accuracy: 0.6778 - val_loss: 1.0374 - val_accuracy: 0.5470\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7171 - accuracy: 0.6963 - val_loss: 1.0578 - val_accuracy: 0.5470\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7346 - accuracy: 0.6852 - val_loss: 1.0229 - val_accuracy: 0.5897\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7158 - accuracy: 0.7037 - val_loss: 1.0220 - val_accuracy: 0.5470\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7198 - accuracy: 0.6963 - val_loss: 1.0222 - val_accuracy: 0.5556\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7146 - accuracy: 0.7074 - val_loss: 1.0143 - val_accuracy: 0.5470\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7355 - accuracy: 0.6963 - val_loss: 1.0065 - val_accuracy: 0.5983\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7364 - accuracy: 0.6815 - val_loss: 1.0308 - val_accuracy: 0.6239\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7351 - accuracy: 0.6889 - val_loss: 1.0082 - val_accuracy: 0.5812\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7453 - accuracy: 0.6815 - val_loss: 1.0060 - val_accuracy: 0.5983\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7473 - accuracy: 0.6704 - val_loss: 1.0087 - val_accuracy: 0.5897\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7098 - accuracy: 0.7037 - val_loss: 1.0090 - val_accuracy: 0.5897\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7196 - accuracy: 0.7000 - val_loss: 1.0161 - val_accuracy: 0.5470\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7074 - accuracy: 0.6963 - val_loss: 1.0060 - val_accuracy: 0.5812\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7194 - accuracy: 0.6963 - val_loss: 1.0068 - val_accuracy: 0.5897\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7061 - accuracy: 0.7037 - val_loss: 1.0036 - val_accuracy: 0.6068\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7273 - accuracy: 0.6963 - val_loss: 1.0197 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8628 - accuracy: 0.6704 - val_loss: 1.1043 - val_accuracy: 0.5812\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8143 - accuracy: 0.6741 - val_loss: 1.0856 - val_accuracy: 0.5470\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7369 - accuracy: 0.6741 - val_loss: 1.0655 - val_accuracy: 0.6154\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7862 - accuracy: 0.6704 - val_loss: 1.0997 - val_accuracy: 0.5470\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8024 - accuracy: 0.6778 - val_loss: 1.0499 - val_accuracy: 0.5812\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7510 - accuracy: 0.6852 - val_loss: 1.0797 - val_accuracy: 0.5726\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.7236 - accuracy: 0.6889 - val_loss: 1.0245 - val_accuracy: 0.5812\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7463 - accuracy: 0.6963 - val_loss: 1.0382 - val_accuracy: 0.5897\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7435 - accuracy: 0.7000 - val_loss: 1.0276 - val_accuracy: 0.5812\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7336 - accuracy: 0.6889 - val_loss: 1.0412 - val_accuracy: 0.5812\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7089 - accuracy: 0.7000 - val_loss: 1.0377 - val_accuracy: 0.5812\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7313 - accuracy: 0.7000 - val_loss: 1.0284 - val_accuracy: 0.5983\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7454 - accuracy: 0.6889 - val_loss: 1.0177 - val_accuracy: 0.6068\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7505 - accuracy: 0.6815 - val_loss: 1.0276 - val_accuracy: 0.6325\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7180 - accuracy: 0.6926 - val_loss: 1.0174 - val_accuracy: 0.6154\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7139 - accuracy: 0.6926 - val_loss: 1.0103 - val_accuracy: 0.5983\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7139 - accuracy: 0.6889 - val_loss: 1.0141 - val_accuracy: 0.6154\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7133 - accuracy: 0.6852 - val_loss: 1.0064 - val_accuracy: 0.6068\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7193 - accuracy: 0.6889 - val_loss: 0.9958 - val_accuracy: 0.6239\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7298 - accuracy: 0.6815 - val_loss: 0.9962 - val_accuracy: 0.6068\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7124 - accuracy: 0.7000 - val_loss: 1.0052 - val_accuracy: 0.5983\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7076 - accuracy: 0.6926 - val_loss: 1.0087 - val_accuracy: 0.6068\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7253 - accuracy: 0.6926 - val_loss: 1.0244 - val_accuracy: 0.5812\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7280 - accuracy: 0.7000 - val_loss: 1.0132 - val_accuracy: 0.5897\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7413 - accuracy: 0.6778 - val_loss: 1.0115 - val_accuracy: 0.5726\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7193 - accuracy: 0.6926 - val_loss: 1.0159 - val_accuracy: 0.5897\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7084 - accuracy: 0.6852 - val_loss: 1.0310 - val_accuracy: 0.5983\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7402 - accuracy: 0.6852 - val_loss: 1.0187 - val_accuracy: 0.6068\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7411 - accuracy: 0.6963 - val_loss: 1.0260 - val_accuracy: 0.5897\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7121 - accuracy: 0.6889 - val_loss: 1.0190 - val_accuracy: 0.5812\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7128 - accuracy: 0.6778 - val_loss: 1.0030 - val_accuracy: 0.5983\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7211 - accuracy: 0.6926 - val_loss: 1.0030 - val_accuracy: 0.5983\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7141 - accuracy: 0.6926 - val_loss: 1.0078 - val_accuracy: 0.6068\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7267 - accuracy: 0.6889 - val_loss: 1.0113 - val_accuracy: 0.6154\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7852 - accuracy: 0.6778 - val_loss: 1.0079 - val_accuracy: 0.5983\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7540 - accuracy: 0.7000 - val_loss: 1.0564 - val_accuracy: 0.6325\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8592 - accuracy: 0.6852 - val_loss: 1.0664 - val_accuracy: 0.6068\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7698 - accuracy: 0.7000 - val_loss: 1.0772 - val_accuracy: 0.5556\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9068 - accuracy: 0.6704 - val_loss: 1.2777 - val_accuracy: 0.6325\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1211 - accuracy: 0.6778 - val_loss: 1.1802 - val_accuracy: 0.6154\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8082 - accuracy: 0.6704 - val_loss: 1.1244 - val_accuracy: 0.5385\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8321 - accuracy: 0.6593 - val_loss: 1.1387 - val_accuracy: 0.5983\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9385 - accuracy: 0.6778 - val_loss: 1.0876 - val_accuracy: 0.6154\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7862 - accuracy: 0.6815 - val_loss: 1.0400 - val_accuracy: 0.5641\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8604 - accuracy: 0.6926 - val_loss: 1.1922 - val_accuracy: 0.6068\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8983 - accuracy: 0.6852 - val_loss: 1.0466 - val_accuracy: 0.5556\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7323 - accuracy: 0.6889 - val_loss: 1.0699 - val_accuracy: 0.5726\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7137 - accuracy: 0.6889 - val_loss: 1.0335 - val_accuracy: 0.6239\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7429 - accuracy: 0.6852 - val_loss: 1.0251 - val_accuracy: 0.5641\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7276 - accuracy: 0.6926 - val_loss: 1.0129 - val_accuracy: 0.5641\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7232 - accuracy: 0.6778 - val_loss: 1.0140 - val_accuracy: 0.5556\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7095 - accuracy: 0.6852 - val_loss: 1.0162 - val_accuracy: 0.5641\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7553 - accuracy: 0.6852 - val_loss: 1.0251 - val_accuracy: 0.6581\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7080 - accuracy: 0.7037 - val_loss: 1.0276 - val_accuracy: 0.5641\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7099 - accuracy: 0.6852 - val_loss: 1.0021 - val_accuracy: 0.6154\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7325 - accuracy: 0.6889 - val_loss: 1.0061 - val_accuracy: 0.5556\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7557 - accuracy: 0.6815 - val_loss: 1.0049 - val_accuracy: 0.6239\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7350 - accuracy: 0.6889 - val_loss: 1.0077 - val_accuracy: 0.5556\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7463 - accuracy: 0.6704 - val_loss: 1.0247 - val_accuracy: 0.5726\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7413 - accuracy: 0.6778 - val_loss: 1.0118 - val_accuracy: 0.6154\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7930 - accuracy: 0.6741 - val_loss: 1.1141 - val_accuracy: 0.6239\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.3321 - accuracy: 0.6593 - val_loss: 2.0293 - val_accuracy: 0.5726\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 2.2704 - accuracy: 0.6481 - val_loss: 2.0738 - val_accuracy: 0.6154\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 2.0731 - accuracy: 0.6593 - val_loss: 1.7439 - val_accuracy: 0.6068\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 1.5318 - accuracy: 0.6593 - val_loss: 1.2989 - val_accuracy: 0.5897\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9883 - accuracy: 0.6222 - val_loss: 1.2472 - val_accuracy: 0.4872\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9021 - accuracy: 0.6370 - val_loss: 1.0800 - val_accuracy: 0.6667\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8936 - accuracy: 0.6815 - val_loss: 1.1938 - val_accuracy: 0.6496\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9357 - accuracy: 0.6815 - val_loss: 1.0366 - val_accuracy: 0.5812\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7551 - accuracy: 0.6963 - val_loss: 1.0360 - val_accuracy: 0.5983\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7753 - accuracy: 0.7000 - val_loss: 1.0604 - val_accuracy: 0.5812\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7584 - accuracy: 0.6778 - val_loss: 1.0731 - val_accuracy: 0.5641\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7064 - accuracy: 0.7148 - val_loss: 1.0437 - val_accuracy: 0.6239\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7466 - accuracy: 0.6815 - val_loss: 1.0254 - val_accuracy: 0.6068\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7085 - accuracy: 0.7074 - val_loss: 1.0812 - val_accuracy: 0.5983\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.7462 - accuracy: 0.6889 - val_loss: 1.0901 - val_accuracy: 0.6581\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8306 - accuracy: 0.6926 - val_loss: 1.0322 - val_accuracy: 0.5812\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7157 - accuracy: 0.6963 - val_loss: 1.0750 - val_accuracy: 0.5556\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7319 - accuracy: 0.6741 - val_loss: 1.0197 - val_accuracy: 0.5812\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7037 - accuracy: 0.7074 - val_loss: 1.0262 - val_accuracy: 0.5556\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7122 - accuracy: 0.6963 - val_loss: 1.0072 - val_accuracy: 0.5556\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7057 - accuracy: 0.6889 - val_loss: 1.0109 - val_accuracy: 0.5812\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7048 - accuracy: 0.7222 - val_loss: 1.0089 - val_accuracy: 0.5726\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7024 - accuracy: 0.7074 - val_loss: 1.0126 - val_accuracy: 0.5470\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7000 - accuracy: 0.7000 - val_loss: 1.0183 - val_accuracy: 0.5641\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7070 - accuracy: 0.7000 - val_loss: 1.0135 - val_accuracy: 0.5470\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7014 - accuracy: 0.7000 - val_loss: 1.0168 - val_accuracy: 0.5470\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7083 - accuracy: 0.6963 - val_loss: 1.0065 - val_accuracy: 0.5812\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7057 - accuracy: 0.7037 - val_loss: 1.0057 - val_accuracy: 0.5812\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.7047 - accuracy: 0.6926 - val_loss: 1.0075 - val_accuracy: 0.6154\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7884 - accuracy: 0.6889 - val_loss: 1.0471 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7835 - accuracy: 0.6889 - val_loss: 1.0389 - val_accuracy: 0.6239\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0348 - accuracy: 0.6778 - val_loss: 1.4440 - val_accuracy: 0.6410\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.3345 - accuracy: 0.6593 - val_loss: 1.3124 - val_accuracy: 0.6239\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.9986 - accuracy: 0.6630 - val_loss: 1.0658 - val_accuracy: 0.6239\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7990 - accuracy: 0.6630 - val_loss: 1.1393 - val_accuracy: 0.5299\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8304 - accuracy: 0.6519 - val_loss: 1.0566 - val_accuracy: 0.6496\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7464 - accuracy: 0.7000 - val_loss: 1.1764 - val_accuracy: 0.5726\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9825 - accuracy: 0.6630 - val_loss: 1.0697 - val_accuracy: 0.6410\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0818 - accuracy: 0.6370 - val_loss: 1.2983 - val_accuracy: 0.6325\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9733 - accuracy: 0.6815 - val_loss: 1.1196 - val_accuracy: 0.5641\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8687 - accuracy: 0.6556 - val_loss: 1.0860 - val_accuracy: 0.5897\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8690 - accuracy: 0.6741 - val_loss: 1.1230 - val_accuracy: 0.5641\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7860 - accuracy: 0.6926 - val_loss: 1.0941 - val_accuracy: 0.5726\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7456 - accuracy: 0.6926 - val_loss: 1.0581 - val_accuracy: 0.5812\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7193 - accuracy: 0.6926 - val_loss: 1.0407 - val_accuracy: 0.5385\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7477 - accuracy: 0.6963 - val_loss: 1.0598 - val_accuracy: 0.5556\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7201 - accuracy: 0.7111 - val_loss: 1.0455 - val_accuracy: 0.5385\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7090 - accuracy: 0.7037 - val_loss: 1.0724 - val_accuracy: 0.5812\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7289 - accuracy: 0.7000 - val_loss: 1.0376 - val_accuracy: 0.5726\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7195 - accuracy: 0.7074 - val_loss: 1.0436 - val_accuracy: 0.5726\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7196 - accuracy: 0.7037 - val_loss: 1.0361 - val_accuracy: 0.5726\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7150 - accuracy: 0.7037 - val_loss: 1.0466 - val_accuracy: 0.5726\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7215 - accuracy: 0.6926 - val_loss: 1.0442 - val_accuracy: 0.6154\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7129 - accuracy: 0.7074 - val_loss: 1.0474 - val_accuracy: 0.5641\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7065 - accuracy: 0.7074 - val_loss: 1.0262 - val_accuracy: 0.5726\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7110 - accuracy: 0.7222 - val_loss: 1.0173 - val_accuracy: 0.5812\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7141 - accuracy: 0.6889 - val_loss: 1.0193 - val_accuracy: 0.6068\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7137 - accuracy: 0.6889 - val_loss: 1.0270 - val_accuracy: 0.5983\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7023 - accuracy: 0.7037 - val_loss: 1.0154 - val_accuracy: 0.6496\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7107 - accuracy: 0.7074 - val_loss: 1.0147 - val_accuracy: 0.6325\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7032 - accuracy: 0.7074 - val_loss: 1.0223 - val_accuracy: 0.5983\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7542 - accuracy: 0.6741 - val_loss: 1.0325 - val_accuracy: 0.6496\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.7489 - accuracy: 0.6889 - val_loss: 1.0329 - val_accuracy: 0.5983\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7336 - accuracy: 0.7000 - val_loss: 1.0364 - val_accuracy: 0.6154\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7194 - accuracy: 0.7074 - val_loss: 1.0501 - val_accuracy: 0.5812\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7092 - accuracy: 0.7074 - val_loss: 1.0392 - val_accuracy: 0.6154\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7213 - accuracy: 0.7000 - val_loss: 1.0309 - val_accuracy: 0.6068\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7265 - accuracy: 0.6963 - val_loss: 1.0510 - val_accuracy: 0.5726\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7476 - accuracy: 0.6852 - val_loss: 1.0231 - val_accuracy: 0.6581\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7003 - accuracy: 0.7037 - val_loss: 1.0642 - val_accuracy: 0.6068\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7807 - accuracy: 0.6815 - val_loss: 1.0218 - val_accuracy: 0.6581\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7089 - accuracy: 0.7111 - val_loss: 1.0608 - val_accuracy: 0.6068\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7383 - accuracy: 0.7037 - val_loss: 1.0365 - val_accuracy: 0.6581\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7960 - accuracy: 0.6926 - val_loss: 1.0319 - val_accuracy: 0.6581\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7797 - accuracy: 0.6815 - val_loss: 1.0329 - val_accuracy: 0.6667\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8189 - accuracy: 0.6889 - val_loss: 1.2053 - val_accuracy: 0.6410\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9307 - accuracy: 0.6926 - val_loss: 1.0670 - val_accuracy: 0.6154\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7985 - accuracy: 0.6815 - val_loss: 1.0492 - val_accuracy: 0.5385\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7567 - accuracy: 0.6741 - val_loss: 1.0508 - val_accuracy: 0.6154\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7362 - accuracy: 0.6963 - val_loss: 1.0639 - val_accuracy: 0.6068\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7247 - accuracy: 0.7074 - val_loss: 1.0215 - val_accuracy: 0.6496\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7234 - accuracy: 0.6963 - val_loss: 1.0203 - val_accuracy: 0.5726\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7134 - accuracy: 0.7074 - val_loss: 1.0287 - val_accuracy: 0.5812\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7213 - accuracy: 0.7000 - val_loss: 1.0274 - val_accuracy: 0.5470\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7665 - accuracy: 0.6815 - val_loss: 1.0510 - val_accuracy: 0.6325\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8973 - accuracy: 0.6815 - val_loss: 1.1178 - val_accuracy: 0.6239\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8049 - accuracy: 0.6815 - val_loss: 1.0954 - val_accuracy: 0.5726\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8472 - accuracy: 0.6667 - val_loss: 1.0422 - val_accuracy: 0.6239\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7524 - accuracy: 0.6815 - val_loss: 1.0118 - val_accuracy: 0.5641\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7308 - accuracy: 0.6889 - val_loss: 1.0109 - val_accuracy: 0.5983\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7045 - accuracy: 0.7000 - val_loss: 1.0571 - val_accuracy: 0.6581\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7697 - accuracy: 0.6889 - val_loss: 1.0165 - val_accuracy: 0.6068\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7461 - accuracy: 0.7074 - val_loss: 1.0199 - val_accuracy: 0.5897\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7038 - accuracy: 0.7111 - val_loss: 1.0239 - val_accuracy: 0.6410\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7206 - accuracy: 0.7000 - val_loss: 1.0161 - val_accuracy: 0.5897\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7027 - accuracy: 0.6963 - val_loss: 1.0117 - val_accuracy: 0.6410\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8031 - accuracy: 0.7000 - val_loss: 1.1116 - val_accuracy: 0.6581\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8160 - accuracy: 0.6889 - val_loss: 1.0980 - val_accuracy: 0.5556\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8572 - accuracy: 0.6519 - val_loss: 1.1598 - val_accuracy: 0.5897\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8150 - accuracy: 0.6852 - val_loss: 1.0421 - val_accuracy: 0.5983\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.7402 - accuracy: 0.6852 - val_loss: 1.0154 - val_accuracy: 0.6325\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.7187 - accuracy: 0.6852 - val_loss: 1.0285 - val_accuracy: 0.6154\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7297 - accuracy: 0.7148 - val_loss: 1.0333 - val_accuracy: 0.5812\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7115 - accuracy: 0.7111 - val_loss: 1.0440 - val_accuracy: 0.5812\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7022 - accuracy: 0.7000 - val_loss: 1.0198 - val_accuracy: 0.5897\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7005 - accuracy: 0.7037 - val_loss: 1.0153 - val_accuracy: 0.6239\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.7054 - accuracy: 0.6963 - val_loss: 1.0188 - val_accuracy: 0.6325\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6979 - accuracy: 0.7185 - val_loss: 1.0284 - val_accuracy: 0.5983\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7055 - accuracy: 0.7111 - val_loss: 1.0184 - val_accuracy: 0.6239\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7035 - accuracy: 0.7074 - val_loss: 1.0145 - val_accuracy: 0.6239\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7131 - accuracy: 0.6963 - val_loss: 1.0148 - val_accuracy: 0.6154\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7300 - accuracy: 0.6889 - val_loss: 1.0220 - val_accuracy: 0.6239\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7347 - accuracy: 0.7000 - val_loss: 1.0273 - val_accuracy: 0.6496\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6981 - accuracy: 0.7037 - val_loss: 1.0708 - val_accuracy: 0.5897\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7268 - accuracy: 0.6926 - val_loss: 1.0567 - val_accuracy: 0.6581\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8129 - accuracy: 0.6926 - val_loss: 1.0176 - val_accuracy: 0.6410\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8133 - accuracy: 0.6778 - val_loss: 1.0337 - val_accuracy: 0.5983\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7236 - accuracy: 0.7000 - val_loss: 1.0366 - val_accuracy: 0.6496\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7437 - accuracy: 0.6926 - val_loss: 1.0281 - val_accuracy: 0.5983\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8061 - accuracy: 0.6852 - val_loss: 1.0109 - val_accuracy: 0.5983\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7839 - accuracy: 0.6852 - val_loss: 1.0569 - val_accuracy: 0.6667\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.7295 - accuracy: 0.7000 - val_loss: 1.0321 - val_accuracy: 0.5983\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.7135 - accuracy: 0.7037 - val_loss: 1.0148 - val_accuracy: 0.5983\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.7139 - accuracy: 0.7037 - val_loss: 1.0226 - val_accuracy: 0.6496\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.7097 - accuracy: 0.7148 - val_loss: 1.0142 - val_accuracy: 0.5983\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6975 - accuracy: 0.7074 - val_loss: 0.9995 - val_accuracy: 0.5983\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6968 - accuracy: 0.7111 - val_loss: 0.9969 - val_accuracy: 0.6325\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6992 - accuracy: 0.6963 - val_loss: 1.0064 - val_accuracy: 0.6325\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6996 - accuracy: 0.7111 - val_loss: 1.0110 - val_accuracy: 0.5983\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7098 - accuracy: 0.7037 - val_loss: 1.0258 - val_accuracy: 0.5812\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7120 - accuracy: 0.6963 - val_loss: 1.0233 - val_accuracy: 0.6154\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6973 - accuracy: 0.7074 - val_loss: 1.0551 - val_accuracy: 0.6068\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7445 - accuracy: 0.6704 - val_loss: 1.0391 - val_accuracy: 0.6496\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7694 - accuracy: 0.7037 - val_loss: 1.0247 - val_accuracy: 0.6410\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7038 - accuracy: 0.7037 - val_loss: 1.0848 - val_accuracy: 0.6068\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7816 - accuracy: 0.6889 - val_loss: 1.0595 - val_accuracy: 0.6581\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7876 - accuracy: 0.6963 - val_loss: 1.0188 - val_accuracy: 0.6325\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.7172 - accuracy: 0.6963 - val_loss: 1.0131 - val_accuracy: 0.5897\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.7051 - accuracy: 0.6963 - val_loss: 1.0091 - val_accuracy: 0.6667\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.7237 - accuracy: 0.7000 - val_loss: 1.0020 - val_accuracy: 0.5983\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 116us/step - loss: 0.7040 - accuracy: 0.7037 - val_loss: 1.0128 - val_accuracy: 0.6410\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7081 - accuracy: 0.7111 - val_loss: 1.0234 - val_accuracy: 0.5897\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.7011 - accuracy: 0.7074 - val_loss: 1.0402 - val_accuracy: 0.5983\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7124 - accuracy: 0.7000 - val_loss: 1.0175 - val_accuracy: 0.6325\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7324 - accuracy: 0.6963 - val_loss: 1.0164 - val_accuracy: 0.6410\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7155 - accuracy: 0.7000 - val_loss: 1.0154 - val_accuracy: 0.6410\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7358 - accuracy: 0.7000 - val_loss: 1.0395 - val_accuracy: 0.6410\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7287 - accuracy: 0.6889 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7926 - accuracy: 0.6889 - val_loss: 1.0462 - val_accuracy: 0.6410\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7945 - accuracy: 0.6963 - val_loss: 1.0717 - val_accuracy: 0.5897\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7643 - accuracy: 0.6741 - val_loss: 1.0987 - val_accuracy: 0.5299\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7969 - accuracy: 0.6852 - val_loss: 1.0516 - val_accuracy: 0.6410\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7631 - accuracy: 0.6926 - val_loss: 1.0234 - val_accuracy: 0.6154\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7856 - accuracy: 0.6926 - val_loss: 1.0455 - val_accuracy: 0.5983\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8152 - accuracy: 0.6741 - val_loss: 1.1594 - val_accuracy: 0.5812\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8276 - accuracy: 0.6852 - val_loss: 1.0465 - val_accuracy: 0.6154\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7261 - accuracy: 0.7000 - val_loss: 1.0585 - val_accuracy: 0.6325\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.0243 - accuracy: 0.6481 - val_loss: 1.5204 - val_accuracy: 0.5470\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 1.0224 - accuracy: 0.6370 - val_loss: 1.1569 - val_accuracy: 0.5897\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8372 - accuracy: 0.6852 - val_loss: 1.2659 - val_accuracy: 0.5983\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9716 - accuracy: 0.6704 - val_loss: 1.1571 - val_accuracy: 0.6410\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8046 - accuracy: 0.6778 - val_loss: 1.1093 - val_accuracy: 0.5556\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8795 - accuracy: 0.6778 - val_loss: 1.0666 - val_accuracy: 0.5470\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7728 - accuracy: 0.6963 - val_loss: 1.1031 - val_accuracy: 0.6410\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8363 - accuracy: 0.6630 - val_loss: 1.2333 - val_accuracy: 0.5470\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 1.0197 - accuracy: 0.6370 - val_loss: 1.1989 - val_accuracy: 0.6239\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8210 - accuracy: 0.6889 - val_loss: 1.0861 - val_accuracy: 0.5897\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7677 - accuracy: 0.6704 - val_loss: 1.0514 - val_accuracy: 0.6496\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7188 - accuracy: 0.6926 - val_loss: 1.0586 - val_accuracy: 0.5812\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7218 - accuracy: 0.6963 - val_loss: 1.0478 - val_accuracy: 0.6154\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7115 - accuracy: 0.7074 - val_loss: 1.0520 - val_accuracy: 0.6068\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7012 - accuracy: 0.6963 - val_loss: 1.0547 - val_accuracy: 0.5983\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7125 - accuracy: 0.6926 - val_loss: 1.0474 - val_accuracy: 0.6581\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7329 - accuracy: 0.6889 - val_loss: 1.0365 - val_accuracy: 0.6239\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6963 - accuracy: 0.6963 - val_loss: 1.0467 - val_accuracy: 0.6068\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6971 - accuracy: 0.6963 - val_loss: 1.0244 - val_accuracy: 0.6410\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7020 - accuracy: 0.6889 - val_loss: 1.0337 - val_accuracy: 0.5812\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6996 - accuracy: 0.7000 - val_loss: 1.0236 - val_accuracy: 0.5470\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6948 - accuracy: 0.7000 - val_loss: 1.0182 - val_accuracy: 0.6154\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6929 - accuracy: 0.7037 - val_loss: 1.0368 - val_accuracy: 0.6325\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7047 - accuracy: 0.6889 - val_loss: 1.0275 - val_accuracy: 0.6239\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7711 - accuracy: 0.6889 - val_loss: 1.0302 - val_accuracy: 0.6581\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8661 - accuracy: 0.6852 - val_loss: 1.0743 - val_accuracy: 0.6581\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8067 - accuracy: 0.6778 - val_loss: 1.1827 - val_accuracy: 0.5983\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8977 - accuracy: 0.6704 - val_loss: 1.0577 - val_accuracy: 0.6496\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8874 - accuracy: 0.6815 - val_loss: 1.1561 - val_accuracy: 0.6325\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8197 - accuracy: 0.6926 - val_loss: 1.0808 - val_accuracy: 0.5812\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7608 - accuracy: 0.6741 - val_loss: 1.0367 - val_accuracy: 0.6325\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7013 - accuracy: 0.7037 - val_loss: 1.0771 - val_accuracy: 0.5726\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.7760 - accuracy: 0.7037 - val_loss: 1.0525 - val_accuracy: 0.6239\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.7327 - accuracy: 0.7037 - val_loss: 1.0420 - val_accuracy: 0.6325\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7136 - accuracy: 0.7000 - val_loss: 1.0483 - val_accuracy: 0.5897\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.7100 - accuracy: 0.7000 - val_loss: 1.0562 - val_accuracy: 0.6581\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7235 - accuracy: 0.6926 - val_loss: 1.0505 - val_accuracy: 0.5983\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7313 - accuracy: 0.6852 - val_loss: 1.0552 - val_accuracy: 0.6667\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7535 - accuracy: 0.6852 - val_loss: 1.0391 - val_accuracy: 0.6667\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6971 - accuracy: 0.7111 - val_loss: 1.0602 - val_accuracy: 0.6068\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7176 - accuracy: 0.6926 - val_loss: 1.1413 - val_accuracy: 0.6752\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8883 - accuracy: 0.6889 - val_loss: 1.0498 - val_accuracy: 0.6667\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7420 - accuracy: 0.6889 - val_loss: 1.0526 - val_accuracy: 0.5812\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6931 - accuracy: 0.7111 - val_loss: 1.0443 - val_accuracy: 0.6667\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7275 - accuracy: 0.6889 - val_loss: 1.0558 - val_accuracy: 0.5897\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7185 - accuracy: 0.6926 - val_loss: 1.0196 - val_accuracy: 0.6068\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6928 - accuracy: 0.7111 - val_loss: 1.0108 - val_accuracy: 0.5897\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6939 - accuracy: 0.7037 - val_loss: 1.0146 - val_accuracy: 0.6752\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7061 - accuracy: 0.6926 - val_loss: 1.0239 - val_accuracy: 0.5897\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7031 - accuracy: 0.6926 - val_loss: 1.0209 - val_accuracy: 0.5726\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7019 - accuracy: 0.6852 - val_loss: 1.0360 - val_accuracy: 0.6496\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7077 - accuracy: 0.6963 - val_loss: 1.0233 - val_accuracy: 0.5812\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6974 - accuracy: 0.7000 - val_loss: 1.0073 - val_accuracy: 0.6239\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7083 - accuracy: 0.6926 - val_loss: 1.0061 - val_accuracy: 0.6410\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6897 - accuracy: 0.7111 - val_loss: 1.0237 - val_accuracy: 0.6068\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6941 - accuracy: 0.7074 - val_loss: 1.0134 - val_accuracy: 0.6068\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6957 - accuracy: 0.7000 - val_loss: 1.0111 - val_accuracy: 0.6068\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6881 - accuracy: 0.7148 - val_loss: 1.0394 - val_accuracy: 0.5897\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7282 - accuracy: 0.7074 - val_loss: 1.0257 - val_accuracy: 0.6410\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7624 - accuracy: 0.6926 - val_loss: 1.0177 - val_accuracy: 0.6154\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7022 - accuracy: 0.6963 - val_loss: 1.0464 - val_accuracy: 0.5897\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7145 - accuracy: 0.7111 - val_loss: 1.0125 - val_accuracy: 0.6239\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6898 - accuracy: 0.6963 - val_loss: 1.0165 - val_accuracy: 0.5983\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6912 - accuracy: 0.7000 - val_loss: 1.0022 - val_accuracy: 0.6410\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6934 - accuracy: 0.7037 - val_loss: 1.0045 - val_accuracy: 0.6239\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6934 - accuracy: 0.7000 - val_loss: 1.0031 - val_accuracy: 0.6410\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6884 - accuracy: 0.7148 - val_loss: 0.9985 - val_accuracy: 0.6410\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6936 - accuracy: 0.7037 - val_loss: 1.0029 - val_accuracy: 0.6239\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6890 - accuracy: 0.7074 - val_loss: 1.0077 - val_accuracy: 0.6154\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6888 - accuracy: 0.7074 - val_loss: 1.0071 - val_accuracy: 0.6410\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.7343 - accuracy: 0.7037 - val_loss: 1.0169 - val_accuracy: 0.6410\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 342us/step - loss: 0.7276 - accuracy: 0.6778 - val_loss: 1.1184 - val_accuracy: 0.6410\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.2335 - accuracy: 0.6593 - val_loss: 1.9670 - val_accuracy: 0.6325\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 2.0874 - accuracy: 0.6519 - val_loss: 1.9292 - val_accuracy: 0.6667\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 1.8919 - accuracy: 0.6630 - val_loss: 1.6898 - val_accuracy: 0.6410\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 1.3937 - accuracy: 0.6593 - val_loss: 1.2729 - val_accuracy: 0.6239\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 451us/step - loss: 0.9301 - accuracy: 0.6407 - val_loss: 1.3147 - val_accuracy: 0.5214\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 319us/step - loss: 1.2089 - accuracy: 0.6296 - val_loss: 1.0747 - val_accuracy: 0.6496\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 282us/step - loss: 0.9001 - accuracy: 0.6889 - val_loss: 1.1916 - val_accuracy: 0.6410\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9165 - accuracy: 0.6704 - val_loss: 1.0237 - val_accuracy: 0.5641\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7271 - accuracy: 0.7000 - val_loss: 1.0528 - val_accuracy: 0.5641\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7349 - accuracy: 0.7074 - val_loss: 1.0364 - val_accuracy: 0.5897\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7177 - accuracy: 0.7074 - val_loss: 1.0344 - val_accuracy: 0.5897\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7045 - accuracy: 0.7111 - val_loss: 1.0181 - val_accuracy: 0.5726\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7319 - accuracy: 0.6889 - val_loss: 1.0494 - val_accuracy: 0.6581\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7182 - accuracy: 0.7148 - val_loss: 1.0416 - val_accuracy: 0.5812\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7283 - accuracy: 0.6889 - val_loss: 1.0243 - val_accuracy: 0.5897\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7213 - accuracy: 0.7037 - val_loss: 1.0254 - val_accuracy: 0.5812\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6964 - accuracy: 0.7148 - val_loss: 1.0180 - val_accuracy: 0.5641\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7171 - accuracy: 0.7074 - val_loss: 1.0216 - val_accuracy: 0.5641\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7260 - accuracy: 0.7074 - val_loss: 1.0143 - val_accuracy: 0.6068\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7024 - accuracy: 0.7000 - val_loss: 1.0268 - val_accuracy: 0.5897\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6902 - accuracy: 0.7148 - val_loss: 1.0236 - val_accuracy: 0.5726\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 63us/step - loss: 0.7053 - accuracy: 0.7074 - val_loss: 1.0360 - val_accuracy: 0.5726\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7025 - accuracy: 0.6926 - val_loss: 1.0411 - val_accuracy: 0.5812\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7069 - accuracy: 0.7000 - val_loss: 1.0367 - val_accuracy: 0.5726\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6952 - accuracy: 0.7000 - val_loss: 1.0175 - val_accuracy: 0.6154\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7007 - accuracy: 0.7037 - val_loss: 1.0222 - val_accuracy: 0.5812\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.75 - 0s 96us/step - loss: 0.7162 - accuracy: 0.6889 - val_loss: 1.0137 - val_accuracy: 0.6581\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7344 - accuracy: 0.7000 - val_loss: 1.0393 - val_accuracy: 0.6496\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7128 - accuracy: 0.7074 - val_loss: 1.0221 - val_accuracy: 0.5983\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7035 - accuracy: 0.7074 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6919 - accuracy: 0.7074 - val_loss: 1.0123 - val_accuracy: 0.5812\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6950 - accuracy: 0.7111 - val_loss: 1.0179 - val_accuracy: 0.5812\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7082 - accuracy: 0.6963 - val_loss: 1.0426 - val_accuracy: 0.6410\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7197 - accuracy: 0.6889 - val_loss: 1.0349 - val_accuracy: 0.5812\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7176 - accuracy: 0.6889 - val_loss: 1.0169 - val_accuracy: 0.5726\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6988 - accuracy: 0.6963 - val_loss: 1.0054 - val_accuracy: 0.6496\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6908 - accuracy: 0.7074 - val_loss: 1.0141 - val_accuracy: 0.5897\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6896 - accuracy: 0.7074 - val_loss: 1.0177 - val_accuracy: 0.6154\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6862 - accuracy: 0.7111 - val_loss: 1.0160 - val_accuracy: 0.6154\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6921 - accuracy: 0.7000 - val_loss: 1.0171 - val_accuracy: 0.6068\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6836 - accuracy: 0.7037 - val_loss: 1.0153 - val_accuracy: 0.6154\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6955 - accuracy: 0.7074 - val_loss: 1.0016 - val_accuracy: 0.6325\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6949 - accuracy: 0.7037 - val_loss: 1.0085 - val_accuracy: 0.6239\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7112 - accuracy: 0.7037 - val_loss: 1.0091 - val_accuracy: 0.6325\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6983 - accuracy: 0.7037 - val_loss: 1.0029 - val_accuracy: 0.6239\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7144 - accuracy: 0.6926 - val_loss: 1.0101 - val_accuracy: 0.6325\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7002 - accuracy: 0.7074 - val_loss: 0.9940 - val_accuracy: 0.6325\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7330 - accuracy: 0.6889 - val_loss: 1.0295 - val_accuracy: 0.6667\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7076 - accuracy: 0.6963 - val_loss: 1.0294 - val_accuracy: 0.5983\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7318 - accuracy: 0.7074 - val_loss: 1.0200 - val_accuracy: 0.6325\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7179 - accuracy: 0.6926 - val_loss: 1.0324 - val_accuracy: 0.6154\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7575 - accuracy: 0.6778 - val_loss: 1.0384 - val_accuracy: 0.5897\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7651 - accuracy: 0.6889 - val_loss: 1.0627 - val_accuracy: 0.6068\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7534 - accuracy: 0.7074 - val_loss: 1.0484 - val_accuracy: 0.6068\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7074 - accuracy: 0.6889 - val_loss: 1.0714 - val_accuracy: 0.6581\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7920 - accuracy: 0.6778 - val_loss: 1.0108 - val_accuracy: 0.6752\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7178 - accuracy: 0.6926 - val_loss: 1.0337 - val_accuracy: 0.6068\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6983 - accuracy: 0.7074 - val_loss: 1.0303 - val_accuracy: 0.6581\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7179 - accuracy: 0.6889 - val_loss: 1.0292 - val_accuracy: 0.6325\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6928 - accuracy: 0.6963 - val_loss: 1.0103 - val_accuracy: 0.6325\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6883 - accuracy: 0.7111 - val_loss: 1.0042 - val_accuracy: 0.6496\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6842 - accuracy: 0.6963 - val_loss: 1.0167 - val_accuracy: 0.6239\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6899 - accuracy: 0.7111 - val_loss: 1.0176 - val_accuracy: 0.6154\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6884 - accuracy: 0.7111 - val_loss: 1.0116 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6880 - accuracy: 0.7074 - val_loss: 1.0078 - val_accuracy: 0.6154\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6857 - accuracy: 0.7000 - val_loss: 1.0024 - val_accuracy: 0.6154\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6851 - accuracy: 0.7111 - val_loss: 1.0043 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6853 - accuracy: 0.6926 - val_loss: 1.0090 - val_accuracy: 0.6154\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6854 - accuracy: 0.7037 - val_loss: 1.0173 - val_accuracy: 0.6154\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6954 - accuracy: 0.7037 - val_loss: 1.0089 - val_accuracy: 0.6154\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7026 - accuracy: 0.7037 - val_loss: 1.0048 - val_accuracy: 0.6154\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7181 - accuracy: 0.6852 - val_loss: 1.0180 - val_accuracy: 0.6410\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.7165 - accuracy: 0.6963 - val_loss: 1.0311 - val_accuracy: 0.6410\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6963 - accuracy: 0.7037 - val_loss: 1.0393 - val_accuracy: 0.5897\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6993 - accuracy: 0.7000 - val_loss: 1.0099 - val_accuracy: 0.6496\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7008 - accuracy: 0.7074 - val_loss: 1.0050 - val_accuracy: 0.6325\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6842 - accuracy: 0.7111 - val_loss: 0.9967 - val_accuracy: 0.6239\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6849 - accuracy: 0.7000 - val_loss: 0.9975 - val_accuracy: 0.6239\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.75 - 0s 66us/step - loss: 0.6815 - accuracy: 0.6926 - val_loss: 1.0015 - val_accuracy: 0.6325\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6899 - accuracy: 0.7074 - val_loss: 0.9984 - val_accuracy: 0.6325\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6974 - accuracy: 0.7000 - val_loss: 1.0051 - val_accuracy: 0.6239\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7108 - accuracy: 0.6926 - val_loss: 1.0017 - val_accuracy: 0.6239\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6978 - accuracy: 0.7000 - val_loss: 1.0010 - val_accuracy: 0.6410\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7368 - accuracy: 0.7000 - val_loss: 1.0027 - val_accuracy: 0.6239\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7460 - accuracy: 0.6852 - val_loss: 1.0360 - val_accuracy: 0.6410\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9587 - accuracy: 0.6741 - val_loss: 1.2749 - val_accuracy: 0.6581\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9924 - accuracy: 0.6852 - val_loss: 1.0785 - val_accuracy: 0.5726\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8075 - accuracy: 0.6815 - val_loss: 1.0400 - val_accuracy: 0.6410\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7399 - accuracy: 0.6889 - val_loss: 1.1177 - val_accuracy: 0.6410\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8002 - accuracy: 0.6926 - val_loss: 1.0480 - val_accuracy: 0.5812\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7749 - accuracy: 0.6926 - val_loss: 1.1087 - val_accuracy: 0.6410\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8938 - accuracy: 0.6926 - val_loss: 1.1273 - val_accuracy: 0.6496\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7983 - accuracy: 0.7000 - val_loss: 1.0431 - val_accuracy: 0.5897\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7417 - accuracy: 0.6852 - val_loss: 1.0382 - val_accuracy: 0.6496\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7884 - accuracy: 0.6963 - val_loss: 1.0296 - val_accuracy: 0.6581\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7087 - accuracy: 0.7111 - val_loss: 1.0956 - val_accuracy: 0.5983\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7355 - accuracy: 0.7000 - val_loss: 1.0186 - val_accuracy: 0.5897\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7030 - accuracy: 0.7037 - val_loss: 1.0183 - val_accuracy: 0.5983\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6883 - accuracy: 0.7074 - val_loss: 1.0283 - val_accuracy: 0.6068\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6937 - accuracy: 0.7185 - val_loss: 1.0208 - val_accuracy: 0.6068\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7177 - accuracy: 0.7074 - val_loss: 1.0227 - val_accuracy: 0.6496\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7115 - accuracy: 0.7037 - val_loss: 1.0636 - val_accuracy: 0.6325\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7467 - accuracy: 0.6889 - val_loss: 1.0562 - val_accuracy: 0.5726\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7848 - accuracy: 0.6741 - val_loss: 1.0622 - val_accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7263 - accuracy: 0.7074 - val_loss: 1.0346 - val_accuracy: 0.6154\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.7608 - accuracy: 0.6815 - val_loss: 1.0289 - val_accuracy: 0.6068\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7251 - accuracy: 0.7037 - val_loss: 1.0797 - val_accuracy: 0.5470\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7948 - accuracy: 0.6852 - val_loss: 1.0349 - val_accuracy: 0.6410\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7247 - accuracy: 0.6926 - val_loss: 1.0257 - val_accuracy: 0.6154\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6898 - accuracy: 0.6963 - val_loss: 1.0589 - val_accuracy: 0.5812\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7122 - accuracy: 0.6926 - val_loss: 1.0642 - val_accuracy: 0.6325\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7514 - accuracy: 0.6926 - val_loss: 1.0696 - val_accuracy: 0.5812\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6995 - accuracy: 0.6889 - val_loss: 1.0479 - val_accuracy: 0.6325\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7119 - accuracy: 0.6889 - val_loss: 1.0311 - val_accuracy: 0.5897\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6832 - accuracy: 0.7074 - val_loss: 1.0351 - val_accuracy: 0.5897\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6932 - accuracy: 0.7111 - val_loss: 1.0175 - val_accuracy: 0.6154\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6843 - accuracy: 0.7000 - val_loss: 1.0204 - val_accuracy: 0.5726\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6872 - accuracy: 0.7111 - val_loss: 1.0233 - val_accuracy: 0.5812\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6843 - accuracy: 0.7074 - val_loss: 1.0237 - val_accuracy: 0.6154\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6879 - accuracy: 0.7037 - val_loss: 1.0194 - val_accuracy: 0.6068\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6927 - accuracy: 0.7000 - val_loss: 1.0255 - val_accuracy: 0.6154\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7681 - accuracy: 0.6963 - val_loss: 1.0565 - val_accuracy: 0.6496\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7081 - accuracy: 0.7037 - val_loss: 1.0344 - val_accuracy: 0.5812\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6994 - accuracy: 0.7000 - val_loss: 1.0115 - val_accuracy: 0.6325\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6924 - accuracy: 0.7000 - val_loss: 1.0169 - val_accuracy: 0.6154\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7408 - accuracy: 0.6889 - val_loss: 1.0726 - val_accuracy: 0.6581\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8249 - accuracy: 0.6852 - val_loss: 1.0359 - val_accuracy: 0.6154\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8818 - accuracy: 0.6667 - val_loss: 1.0934 - val_accuracy: 0.6410\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8467 - accuracy: 0.6852 - val_loss: 1.1471 - val_accuracy: 0.6410\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8230 - accuracy: 0.6889 - val_loss: 1.0247 - val_accuracy: 0.5983\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7564 - accuracy: 0.6741 - val_loss: 1.0283 - val_accuracy: 0.6581\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 100us/step - loss: 0.7080 - accuracy: 0.7111 - val_loss: 1.0215 - val_accuracy: 0.5726\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6910 - accuracy: 0.7000 - val_loss: 1.0127 - val_accuracy: 0.5812\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6930 - accuracy: 0.7074 - val_loss: 1.0321 - val_accuracy: 0.5812\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.7555 - accuracy: 0.6852 - val_loss: 1.1423 - val_accuracy: 0.6410\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.8865 - accuracy: 0.6963 - val_loss: 1.0908 - val_accuracy: 0.6581\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7416 - accuracy: 0.6852 - val_loss: 1.0856 - val_accuracy: 0.5812\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.7329 - accuracy: 0.6926 - val_loss: 1.0522 - val_accuracy: 0.6667\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.7974 - accuracy: 0.6926 - val_loss: 1.0313 - val_accuracy: 0.6581\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6940 - accuracy: 0.7148 - val_loss: 1.0654 - val_accuracy: 0.6068\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7598 - accuracy: 0.6926 - val_loss: 1.0843 - val_accuracy: 0.6752\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8617 - accuracy: 0.6963 - val_loss: 1.0409 - val_accuracy: 0.6496\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7247 - accuracy: 0.7222 - val_loss: 1.0331 - val_accuracy: 0.5812\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6756 - accuracy: 0.7185 - val_loss: 1.0359 - val_accuracy: 0.6410\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 275us/step - loss: 0.7178 - accuracy: 0.7000 - val_loss: 1.0184 - val_accuracy: 0.5726\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7099 - accuracy: 0.7000 - val_loss: 1.0341 - val_accuracy: 0.5556\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7144 - accuracy: 0.7111 - val_loss: 1.0200 - val_accuracy: 0.5812\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6867 - accuracy: 0.7185 - val_loss: 1.0222 - val_accuracy: 0.5897\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7010 - accuracy: 0.7111 - val_loss: 1.0205 - val_accuracy: 0.5897\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6914 - accuracy: 0.7148 - val_loss: 1.0171 - val_accuracy: 0.5726\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6924 - accuracy: 0.7074 - val_loss: 1.0258 - val_accuracy: 0.5812\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6928 - accuracy: 0.7000 - val_loss: 1.0168 - val_accuracy: 0.5812\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6977 - accuracy: 0.7111 - val_loss: 1.0245 - val_accuracy: 0.6667\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6930 - accuracy: 0.7111 - val_loss: 1.0310 - val_accuracy: 0.6068\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6972 - accuracy: 0.7074 - val_loss: 1.0055 - val_accuracy: 0.6410\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6803 - accuracy: 0.7111 - val_loss: 1.0149 - val_accuracy: 0.6581\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6998 - accuracy: 0.7000 - val_loss: 1.0158 - val_accuracy: 0.5897\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6933 - accuracy: 0.7074 - val_loss: 1.0239 - val_accuracy: 0.6068\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8084 - accuracy: 0.6778 - val_loss: 1.0994 - val_accuracy: 0.6581\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9286 - accuracy: 0.6889 - val_loss: 1.2377 - val_accuracy: 0.6667\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9105 - accuracy: 0.7000 - val_loss: 1.1010 - val_accuracy: 0.5897\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9268 - accuracy: 0.6630 - val_loss: 1.0801 - val_accuracy: 0.6581\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8835 - accuracy: 0.6889 - val_loss: 1.1899 - val_accuracy: 0.6752\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9175 - accuracy: 0.6778 - val_loss: 1.0221 - val_accuracy: 0.5812\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.7815 - accuracy: 0.6852 - val_loss: 1.0366 - val_accuracy: 0.5556\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7142 - accuracy: 0.7074 - val_loss: 1.0262 - val_accuracy: 0.6410\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6995 - accuracy: 0.7037 - val_loss: 1.0618 - val_accuracy: 0.5897\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6917 - accuracy: 0.7111 - val_loss: 1.0316 - val_accuracy: 0.6581\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7294 - accuracy: 0.6926 - val_loss: 1.0093 - val_accuracy: 0.5983\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6753 - accuracy: 0.7037 - val_loss: 1.0334 - val_accuracy: 0.5897\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7156 - accuracy: 0.6852 - val_loss: 1.0429 - val_accuracy: 0.6239\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7564 - accuracy: 0.6889 - val_loss: 1.0238 - val_accuracy: 0.5812\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6930 - accuracy: 0.7111 - val_loss: 1.0441 - val_accuracy: 0.5983\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6939 - accuracy: 0.7148 - val_loss: 1.0188 - val_accuracy: 0.6325\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6928 - accuracy: 0.7037 - val_loss: 1.0206 - val_accuracy: 0.6068\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6923 - accuracy: 0.7148 - val_loss: 1.0030 - val_accuracy: 0.6410\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6929 - accuracy: 0.6963 - val_loss: 1.0048 - val_accuracy: 0.6325\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6837 - accuracy: 0.7000 - val_loss: 1.0139 - val_accuracy: 0.6239\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6822 - accuracy: 0.7074 - val_loss: 1.0237 - val_accuracy: 0.6410\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7285 - accuracy: 0.6963 - val_loss: 1.0453 - val_accuracy: 0.6410\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9248 - accuracy: 0.6630 - val_loss: 1.0176 - val_accuracy: 0.6410\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8474 - accuracy: 0.6963 - val_loss: 1.1419 - val_accuracy: 0.6496\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8211 - accuracy: 0.6963 - val_loss: 1.0277 - val_accuracy: 0.5812\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7210 - accuracy: 0.6963 - val_loss: 1.0217 - val_accuracy: 0.6154\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.7169 - accuracy: 0.6926 - val_loss: 1.0163 - val_accuracy: 0.5812\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6838 - accuracy: 0.7074 - val_loss: 1.0222 - val_accuracy: 0.5897\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6821 - accuracy: 0.7148 - val_loss: 1.0040 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6828 - accuracy: 0.7148 - val_loss: 1.0088 - val_accuracy: 0.5812\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7014 - accuracy: 0.7000 - val_loss: 1.0347 - val_accuracy: 0.6496\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7045 - accuracy: 0.6926 - val_loss: 1.0457 - val_accuracy: 0.6410\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6882 - accuracy: 0.7037 - val_loss: 1.0325 - val_accuracy: 0.5897\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7009 - accuracy: 0.6926 - val_loss: 1.0106 - val_accuracy: 0.6581\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7007 - accuracy: 0.7000 - val_loss: 1.0206 - val_accuracy: 0.5983\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6844 - accuracy: 0.7037 - val_loss: 1.0114 - val_accuracy: 0.6068\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6880 - accuracy: 0.7111 - val_loss: 1.0132 - val_accuracy: 0.6581\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7300 - accuracy: 0.7037 - val_loss: 1.0193 - val_accuracy: 0.5726\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6939 - accuracy: 0.7111 - val_loss: 1.0166 - val_accuracy: 0.5983\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6973 - accuracy: 0.7037 - val_loss: 1.0205 - val_accuracy: 0.6325\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7004 - accuracy: 0.6963 - val_loss: 1.0352 - val_accuracy: 0.5812\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6877 - accuracy: 0.7037 - val_loss: 1.0564 - val_accuracy: 0.6154\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6917 - accuracy: 0.6926 - val_loss: 1.0160 - val_accuracy: 0.6667\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7315 - accuracy: 0.6926 - val_loss: 1.0134 - val_accuracy: 0.6410\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7664 - accuracy: 0.6667 - val_loss: 1.0485 - val_accuracy: 0.6496\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8083 - accuracy: 0.6926 - val_loss: 1.0388 - val_accuracy: 0.6581\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8413 - accuracy: 0.6444 - val_loss: 1.0415 - val_accuracy: 0.6581\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9208 - accuracy: 0.6889 - val_loss: 1.2220 - val_accuracy: 0.6667\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9328 - accuracy: 0.6926 - val_loss: 1.0378 - val_accuracy: 0.6581\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7207 - accuracy: 0.6926 - val_loss: 1.0235 - val_accuracy: 0.5983\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7730 - accuracy: 0.6889 - val_loss: 1.0264 - val_accuracy: 0.6068\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7154 - accuracy: 0.6741 - val_loss: 1.0162 - val_accuracy: 0.5983\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7063 - accuracy: 0.6963 - val_loss: 1.0078 - val_accuracy: 0.5983\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6926 - accuracy: 0.7037 - val_loss: 1.0031 - val_accuracy: 0.5983\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6853 - accuracy: 0.7037 - val_loss: 1.0126 - val_accuracy: 0.6667\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6882 - accuracy: 0.7185 - val_loss: 1.0134 - val_accuracy: 0.5983\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7010 - accuracy: 0.7000 - val_loss: 1.0070 - val_accuracy: 0.5983\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6936 - accuracy: 0.7000 - val_loss: 1.0055 - val_accuracy: 0.5983\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6760 - accuracy: 0.7111 - val_loss: 1.0350 - val_accuracy: 0.6068\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6865 - accuracy: 0.7148 - val_loss: 1.0003 - val_accuracy: 0.6410\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6959 - accuracy: 0.7074 - val_loss: 0.9997 - val_accuracy: 0.5983\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6810 - accuracy: 0.7000 - val_loss: 1.0107 - val_accuracy: 0.6068\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6836 - accuracy: 0.7259 - val_loss: 0.9982 - val_accuracy: 0.6410\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6780 - accuracy: 0.7111 - val_loss: 1.0023 - val_accuracy: 0.5983\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6713 - accuracy: 0.7111 - val_loss: 1.0021 - val_accuracy: 0.6325\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6743 - accuracy: 0.7111 - val_loss: 1.0013 - val_accuracy: 0.6410\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6778 - accuracy: 0.7111 - val_loss: 1.0171 - val_accuracy: 0.5983\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7003 - accuracy: 0.7000 - val_loss: 1.0030 - val_accuracy: 0.6325\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6763 - accuracy: 0.7111 - val_loss: 1.0159 - val_accuracy: 0.6154\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6739 - accuracy: 0.7111 - val_loss: 1.0084 - val_accuracy: 0.6154\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6846 - accuracy: 0.6926 - val_loss: 1.0315 - val_accuracy: 0.5812\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7031 - accuracy: 0.6963 - val_loss: 1.0366 - val_accuracy: 0.6410\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8042 - accuracy: 0.6926 - val_loss: 1.0975 - val_accuracy: 0.6410\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7799 - accuracy: 0.6926 - val_loss: 1.0514 - val_accuracy: 0.5812\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6793 - accuracy: 0.7037 - val_loss: 1.0194 - val_accuracy: 0.6154\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6788 - accuracy: 0.7148 - val_loss: 1.0104 - val_accuracy: 0.6325\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6773 - accuracy: 0.7000 - val_loss: 1.0176 - val_accuracy: 0.6154\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6909 - accuracy: 0.7037 - val_loss: 1.0065 - val_accuracy: 0.6239\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.7106 - accuracy: 0.7000 - val_loss: 1.0118 - val_accuracy: 0.6239\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.6779 - accuracy: 0.7111 - val_loss: 1.0524 - val_accuracy: 0.5812\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7227 - accuracy: 0.7074 - val_loss: 1.0371 - val_accuracy: 0.6154\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7046 - accuracy: 0.7074 - val_loss: 1.0295 - val_accuracy: 0.6154\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7549 - accuracy: 0.6704 - val_loss: 1.2974 - val_accuracy: 0.5214\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0135 - accuracy: 0.6370 - val_loss: 1.1113 - val_accuracy: 0.6239\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7668 - accuracy: 0.6778 - val_loss: 1.0911 - val_accuracy: 0.5641\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7072 - accuracy: 0.6889 - val_loss: 1.0515 - val_accuracy: 0.6410\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7603 - accuracy: 0.6926 - val_loss: 1.0254 - val_accuracy: 0.6239\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6977 - accuracy: 0.7148 - val_loss: 1.0374 - val_accuracy: 0.5897\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6863 - accuracy: 0.7074 - val_loss: 1.0241 - val_accuracy: 0.6325\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6877 - accuracy: 0.6963 - val_loss: 1.0216 - val_accuracy: 0.6239\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6858 - accuracy: 0.7000 - val_loss: 1.0498 - val_accuracy: 0.6239\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6799 - accuracy: 0.7111 - val_loss: 1.0376 - val_accuracy: 0.6581\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7569 - accuracy: 0.7074 - val_loss: 1.0430 - val_accuracy: 0.6154\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7076 - accuracy: 0.7000 - val_loss: 1.0438 - val_accuracy: 0.6154\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6979 - accuracy: 0.7037 - val_loss: 1.0404 - val_accuracy: 0.6325\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7093 - accuracy: 0.7000 - val_loss: 1.0683 - val_accuracy: 0.6325\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7368 - accuracy: 0.6852 - val_loss: 1.0568 - val_accuracy: 0.5897\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8171 - accuracy: 0.7000 - val_loss: 1.0824 - val_accuracy: 0.6581\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8873 - accuracy: 0.6815 - val_loss: 1.2182 - val_accuracy: 0.6496\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8850 - accuracy: 0.6778 - val_loss: 1.0272 - val_accuracy: 0.6325\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8611 - accuracy: 0.6704 - val_loss: 1.0836 - val_accuracy: 0.6581\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8863 - accuracy: 0.6926 - val_loss: 1.1128 - val_accuracy: 0.6581\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7645 - accuracy: 0.6926 - val_loss: 1.0954 - val_accuracy: 0.5983\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7994 - accuracy: 0.6815 - val_loss: 1.0717 - val_accuracy: 0.6581\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7902 - accuracy: 0.6889 - val_loss: 1.0301 - val_accuracy: 0.6581\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7075 - accuracy: 0.7074 - val_loss: 1.0252 - val_accuracy: 0.5983\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9305 - accuracy: 0.6704 - val_loss: 1.5259 - val_accuracy: 0.5812\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0937 - accuracy: 0.6296 - val_loss: 1.0912 - val_accuracy: 0.5812\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8047 - accuracy: 0.6593 - val_loss: 1.2891 - val_accuracy: 0.5385\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0717 - accuracy: 0.6407 - val_loss: 1.4502 - val_accuracy: 0.5726\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0975 - accuracy: 0.6370 - val_loss: 1.2978 - val_accuracy: 0.5214\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8497 - accuracy: 0.6556 - val_loss: 1.2187 - val_accuracy: 0.5556\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8593 - accuracy: 0.6519 - val_loss: 1.0985 - val_accuracy: 0.5983\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8289 - accuracy: 0.6815 - val_loss: 1.1520 - val_accuracy: 0.5641\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7760 - accuracy: 0.7037 - val_loss: 1.0611 - val_accuracy: 0.5812\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7376 - accuracy: 0.6815 - val_loss: 1.0847 - val_accuracy: 0.5726\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7183 - accuracy: 0.6926 - val_loss: 1.0828 - val_accuracy: 0.5897\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7359 - accuracy: 0.7148 - val_loss: 1.0873 - val_accuracy: 0.5812\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.7100 - accuracy: 0.7037 - val_loss: 1.0787 - val_accuracy: 0.5726\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6941 - accuracy: 0.7037 - val_loss: 1.0998 - val_accuracy: 0.5726\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6965 - accuracy: 0.7037 - val_loss: 1.0742 - val_accuracy: 0.5726\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6889 - accuracy: 0.7037 - val_loss: 1.0523 - val_accuracy: 0.6154\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7059 - accuracy: 0.7037 - val_loss: 1.0408 - val_accuracy: 0.6325\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6969 - accuracy: 0.6889 - val_loss: 1.0495 - val_accuracy: 0.6239\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6951 - accuracy: 0.6889 - val_loss: 1.0574 - val_accuracy: 0.6325\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6806 - accuracy: 0.6963 - val_loss: 1.0582 - val_accuracy: 0.5897\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7106 - accuracy: 0.6926 - val_loss: 1.0917 - val_accuracy: 0.6667\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8648 - accuracy: 0.6963 - val_loss: 1.0830 - val_accuracy: 0.6667\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7371 - accuracy: 0.6963 - val_loss: 1.1191 - val_accuracy: 0.6068\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7259 - accuracy: 0.6852 - val_loss: 1.0402 - val_accuracy: 0.6410\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.7277 - accuracy: 0.6926 - val_loss: 1.0424 - val_accuracy: 0.5897\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6874 - accuracy: 0.7111 - val_loss: 1.0336 - val_accuracy: 0.5812\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6750 - accuracy: 0.7074 - val_loss: 1.0211 - val_accuracy: 0.6496\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6805 - accuracy: 0.7037 - val_loss: 1.0206 - val_accuracy: 0.6068\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6964 - accuracy: 0.7037 - val_loss: 1.0172 - val_accuracy: 0.6496\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.7011 - accuracy: 0.6963 - val_loss: 1.0198 - val_accuracy: 0.5897\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6781 - accuracy: 0.7074 - val_loss: 1.0520 - val_accuracy: 0.5897\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6788 - accuracy: 0.7037 - val_loss: 1.0182 - val_accuracy: 0.5897\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6990 - accuracy: 0.6963 - val_loss: 1.0150 - val_accuracy: 0.6068\n",
      "Epoch 998/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 134us/step - loss: 0.7010 - accuracy: 0.7000 - val_loss: 1.0439 - val_accuracy: 0.6325\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7139 - accuracy: 0.6852 - val_loss: 1.0205 - val_accuracy: 0.5812\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7012 - accuracy: 0.6926 - val_loss: 1.0252 - val_accuracy: 0.5897\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 68.87%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [6.12003100e-01, 2.92164980e-01, 9.58318400e-02],\n",
       "       [7.03594000e-01, 2.86381500e-01, 1.00245120e-02],\n",
       "       [9.12392860e-04, 2.89244740e-03, 9.96195200e-01],\n",
       "       [9.01154800e-01, 4.38343960e-02, 5.50107600e-02],\n",
       "       [5.17113900e-01, 9.89344000e-02, 3.83951700e-01],\n",
       "       [3.01279630e-01, 1.96160030e-01, 5.02560300e-01],\n",
       "       [5.88236100e-01, 2.31664760e-01, 1.80099110e-01],\n",
       "       [3.27735320e-02, 1.49786170e-02, 9.52247800e-01],\n",
       "       [4.35468400e-01, 4.20245050e-01, 1.44286560e-01],\n",
       "       [1.98399540e-02, 1.24554420e-01, 8.55605600e-01],\n",
       "       [2.25273170e-02, 4.97500040e-02, 9.27722700e-01],\n",
       "       [3.27735320e-02, 1.49786170e-02, 9.52247800e-01],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.75274690e-02, 1.12088960e-01, 8.70383560e-01],\n",
       "       [5.66983630e-02, 9.73544400e-02, 8.45947200e-01],\n",
       "       [2.75113300e-01, 9.11081400e-03, 7.15775850e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [1.21845860e-01, 1.68894050e-01, 7.09260100e-01],\n",
       "       [3.27735320e-02, 1.49786170e-02, 9.52247800e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [9.74876340e-01, 3.48441560e-03, 2.16392000e-02],\n",
       "       [3.63309140e-01, 5.03914500e-01, 1.32776360e-01],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [1.44320300e-02, 1.19737840e-02, 9.73594200e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.29068980e-06, 2.27243550e-06, 9.99994400e-01],\n",
       "       [8.75576400e-03, 2.50299930e-02, 9.66214240e-01],\n",
       "       [3.56596080e-01, 6.36655400e-01, 6.74862830e-03],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [7.36667100e-03, 1.84464560e-01, 8.08168700e-01],\n",
       "       [7.22997100e-02, 1.61035550e-02, 9.11596700e-01],\n",
       "       [1.10728350e-01, 5.15805560e-02, 8.37691100e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [4.89341880e-01, 3.87781170e-01, 1.22876960e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [3.19674130e-02, 4.04307750e-01, 5.63724800e-01],\n",
       "       [1.37312360e-03, 1.06945710e-02, 9.87932260e-01],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [3.45971800e-02, 8.53716900e-01, 1.11685910e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.28741130e-01, 3.63567440e-01, 5.07691440e-01],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.24528660e-01, 7.28345900e-01, 1.47125480e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [9.01154800e-01, 4.38343960e-02, 5.50107600e-02],\n",
       "       [9.77249600e-01, 2.05769040e-02, 2.17344430e-03],\n",
       "       [7.27455800e-03, 1.14502340e-02, 9.81275260e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.63309140e-01, 5.03914500e-01, 1.32776360e-01],\n",
       "       [6.74308240e-01, 3.14197000e-01, 1.14948000e-02],\n",
       "       [9.01154800e-01, 4.38343960e-02, 5.50107600e-02],\n",
       "       [7.22997100e-02, 1.61035550e-02, 9.11596700e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [4.35468400e-01, 4.20245050e-01, 1.44286560e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.01279630e-01, 1.96160030e-01, 5.02560300e-01],\n",
       "       [7.36667100e-03, 1.84464560e-01, 8.08168700e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.21845860e-01, 1.68894050e-01, 7.09260100e-01],\n",
       "       [3.49461400e-01, 2.34378710e-01, 4.16159870e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.29389600e-01, 5.51341920e-02, 6.15476250e-01],\n",
       "       [9.29467200e-01, 5.61138430e-02, 1.44189930e-02],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.01279630e-01, 1.96160030e-01, 5.02560300e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.10728350e-01, 5.15805560e-02, 8.37691100e-01],\n",
       "       [1.24528660e-01, 7.28345900e-01, 1.47125480e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [3.49461400e-01, 2.34378710e-01, 4.16159870e-01],\n",
       "       [5.66983630e-02, 9.73544400e-02, 8.45947200e-01],\n",
       "       [1.28615500e-01, 7.22767400e-01, 1.48617040e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [1.22094296e-01, 7.51704800e-01, 1.26200930e-01],\n",
       "       [4.35468400e-01, 4.20245050e-01, 1.44286560e-01],\n",
       "       [5.81605730e-01, 2.89255470e-01, 1.29138770e-01],\n",
       "       [1.75274690e-02, 1.12088960e-01, 8.70383560e-01],\n",
       "       [7.22997100e-02, 1.61035550e-02, 9.11596700e-01],\n",
       "       [4.63134560e-01, 2.81625800e-01, 2.55239640e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [8.75576400e-03, 2.50299930e-02, 9.66214240e-01],\n",
       "       [3.12926000e-03, 2.47660280e-05, 9.96845900e-01],\n",
       "       [1.41715030e-02, 4.40270900e-05, 9.85784500e-01],\n",
       "       [7.22997100e-02, 1.61035550e-02, 9.11596700e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [5.46549820e-02, 4.38295040e-01, 5.07050040e-01],\n",
       "       [1.42693680e-01, 1.40316160e-01, 7.16990100e-01],\n",
       "       [3.49461400e-01, 2.34378710e-01, 4.16159870e-01],\n",
       "       [5.17144860e-01, 4.71866430e-01, 1.09887040e-02],\n",
       "       [4.35468400e-01, 4.20245050e-01, 1.44286560e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [3.63309140e-01, 5.03914500e-01, 1.32776360e-01],\n",
       "       [1.37312360e-03, 1.06945710e-02, 9.87932260e-01],\n",
       "       [5.88236100e-01, 2.31664760e-01, 1.80099110e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [8.31491350e-02, 9.16602430e-01, 2.48427560e-04],\n",
       "       [7.22997100e-02, 1.61035550e-02, 9.11596700e-01],\n",
       "       [3.63309140e-01, 5.03914500e-01, 1.32776360e-01],\n",
       "       [3.63309140e-01, 5.03914500e-01, 1.32776360e-01],\n",
       "       [1.75274690e-02, 1.12088960e-01, 8.70383560e-01],\n",
       "       [4.17393300e-02, 3.78565850e-01, 5.79694800e-01],\n",
       "       [2.73087800e-01, 5.61901400e-01, 1.65010820e-01],\n",
       "       [6.90982460e-01, 1.39595640e-01, 1.69421900e-01],\n",
       "       [1.64433760e-01, 8.08857440e-01, 2.67087580e-02],\n",
       "       [5.88236100e-01, 2.31664760e-01, 1.80099110e-01],\n",
       "       [3.49461400e-01, 2.34378710e-01, 4.16159870e-01],\n",
       "       [1.41715030e-02, 4.40270900e-05, 9.85784500e-01],\n",
       "       [9.12392860e-04, 2.89244740e-03, 9.96195200e-01],\n",
       "       [3.49461400e-01, 2.34378710e-01, 4.16159870e-01]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599167214551829"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599167214551829"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753122945430637"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015787556019189943"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7753122945430637"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015787556019189943"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 62.82%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.03226424780028013\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 70.38%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.04090423\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 20\n",
      "selected features: 17\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  4,  5,  6,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18,\n",
       "        19]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTGTTATAGTC', 'TTAATTTAATAGA', 'TTAACATAATAAT', 'TATTATGTTAATG',\n",
       "       'TACATACCGAT', 'GTGTATCATAAT', 'GCAAACATGCG', 'GAGTCCTGTT',\n",
       "       'GAGTCCTGTTT',\n",
       "       'GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG',\n",
       "       'CTTTTTCACCTGT', 'CTTGTGAATTTAG', 'CGCCATTATGTT', 'CAGAAAAGCGT',\n",
       "       'ACAATTACTATATTT', 'ST', 'CC'], dtype='<U99')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>GAGTCCTGTTT</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>CAGAAAAGCGT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TATTATGTTAATG  TACATACCGAT  \\\n",
       "0              1              1              1              1            1   \n",
       "1              1              1              1              1            1   \n",
       "2              1              1              1              1            1   \n",
       "3              1              1              1              1            1   \n",
       "4              1              1              1              1            1   \n",
       "..           ...            ...            ...            ...          ...   \n",
       "248            1              1              1              1            1   \n",
       "249            1              1              1              1            1   \n",
       "250            1              1              1              1            1   \n",
       "251            1              1              1              1            1   \n",
       "252            1              1              1              1            1   \n",
       "\n",
       "     GTGTATCATAAT  GCAAACATGCG  GAGTCCTGTT  GAGTCCTGTTT  \\\n",
       "0               1            1           1            1   \n",
       "1               1            1           1            1   \n",
       "2               1            1           1            1   \n",
       "3               1            1           1            1   \n",
       "4               1            1           1            1   \n",
       "..            ...          ...         ...          ...   \n",
       "248             1            1           1            1   \n",
       "249             1            1           1            1   \n",
       "250             1            1           1            1   \n",
       "251             1            1           1            1   \n",
       "252             1            1           1            1   \n",
       "\n",
       "     GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                    0                                                     \n",
       "1                                                    0                                                     \n",
       "2                                                    0                                                     \n",
       "3                                                    0                                                     \n",
       "4                                                    0                                                     \n",
       "..                                                 ...                                                     \n",
       "248                                                  0                                                     \n",
       "249                                                  0                                                     \n",
       "250                                                  0                                                     \n",
       "251                                                  0                                                     \n",
       "252                                                  0                                                     \n",
       "\n",
       "     CTTTTTCACCTGT  CTTGTGAATTTAG  CGCCATTATGTT  CAGAAAAGCGT  ACAATTACTATATTT  \\\n",
       "0                1              1             0            1                1   \n",
       "1                1              1             0            1                1   \n",
       "2                1              1             1            1                1   \n",
       "3                1              1             0            1                1   \n",
       "4                1              1             0            1                1   \n",
       "..             ...            ...           ...          ...              ...   \n",
       "248              1              1             0            1                1   \n",
       "249              1              1             0            1                1   \n",
       "250              1              1             0            1                1   \n",
       "251              1              1             0            1                1   \n",
       "252              1              1             0            1                1   \n",
       "\n",
       "       ST  CC  pheno  strain  \n",
       "0       5   5      1     107  \n",
       "1       8   8      0     109  \n",
       "2       5   5      1     115  \n",
       "3       5   5      1  120335  \n",
       "4       5   5      1  120337  \n",
       "..    ...  ..    ...     ...  \n",
       "248     5   5      1  SR4152  \n",
       "249  3812   5      0  SR4153  \n",
       "250     5   5      0  SR4155  \n",
       "251     5   5      0  SR4156  \n",
       "252  3812   5      0  SR4187  \n",
       "\n",
       "[253 rows x 19 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 18) (253,) (253, 19)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS245     1\n",
       "1          NY439     2\n",
       "2          CA544     1\n",
       "3          CA541     2\n",
       "4          EUH15     1\n",
       "..           ...   ...\n",
       "112       NRS112     0\n",
       "113     CFBRSa51     2\n",
       "114       NRS383     1\n",
       "115       NRS247     0\n",
       "116  CFBREBSa103     0\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 490us/step - loss: 12.7994 - accuracy: 0.3074 - val_loss: 13.0135 - val_accuracy: 0.2821\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 10.3844 - accuracy: 0.3296 - val_loss: 10.4013 - val_accuracy: 0.3846\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 8.3810 - accuracy: 0.4370 - val_loss: 8.0674 - val_accuracy: 0.3932\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 6.3687 - accuracy: 0.4407 - val_loss: 5.9722 - val_accuracy: 0.3932\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 4.6766 - accuracy: 0.4185 - val_loss: 4.2208 - val_accuracy: 0.3590\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 2.8230 - accuracy: 0.3963 - val_loss: 2.4689 - val_accuracy: 0.3590\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.4429 - accuracy: 0.3593 - val_loss: 1.9001 - val_accuracy: 0.3162\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.6716 - accuracy: 0.3593 - val_loss: 1.8467 - val_accuracy: 0.3333\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.6862 - accuracy: 0.4037 - val_loss: 2.1905 - val_accuracy: 0.4017\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.8978 - accuracy: 0.4111 - val_loss: 1.9960 - val_accuracy: 0.4017\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.5932 - accuracy: 0.4185 - val_loss: 1.6941 - val_accuracy: 0.4103\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 1.3586 - accuracy: 0.4333 - val_loss: 1.4354 - val_accuracy: 0.4615\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 1.3128 - accuracy: 0.4185 - val_loss: 1.3763 - val_accuracy: 0.3675\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.3379 - accuracy: 0.4259 - val_loss: 1.5528 - val_accuracy: 0.4872\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.2512 - accuracy: 0.4407 - val_loss: 1.2227 - val_accuracy: 0.3761\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 1.1758 - accuracy: 0.4222 - val_loss: 1.3001 - val_accuracy: 0.4188\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 1.1676 - accuracy: 0.4444 - val_loss: 1.3675 - val_accuracy: 0.3846\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.1849 - accuracy: 0.4296 - val_loss: 1.4616 - val_accuracy: 0.3846\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 1.1398 - accuracy: 0.4778 - val_loss: 1.3128 - val_accuracy: 0.4701\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 1.0827 - accuracy: 0.4889 - val_loss: 1.2127 - val_accuracy: 0.4103\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 1.0968 - accuracy: 0.4741 - val_loss: 1.2190 - val_accuracy: 0.4359\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 1.0931 - accuracy: 0.4963 - val_loss: 1.1741 - val_accuracy: 0.4274\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 1.0851 - accuracy: 0.5000 - val_loss: 1.4543 - val_accuracy: 0.4359\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 335us/step - loss: 1.2511 - accuracy: 0.5037 - val_loss: 1.1799 - val_accuracy: 0.4274\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 1.0711 - accuracy: 0.5000 - val_loss: 1.1680 - val_accuracy: 0.4957\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 1.0926 - accuracy: 0.4852 - val_loss: 1.1273 - val_accuracy: 0.5043\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1149 - accuracy: 0.5185 - val_loss: 1.2780 - val_accuracy: 0.5299\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 1.0532 - accuracy: 0.4889 - val_loss: 1.1866 - val_accuracy: 0.4103\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 1.0383 - accuracy: 0.4519 - val_loss: 1.2153 - val_accuracy: 0.5128\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 1.1186 - accuracy: 0.5000 - val_loss: 1.5218 - val_accuracy: 0.3932\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.2521 - accuracy: 0.4741 - val_loss: 1.4952 - val_accuracy: 0.5043\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.1598 - accuracy: 0.5074 - val_loss: 1.1597 - val_accuracy: 0.5043\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.9932 - accuracy: 0.5185 - val_loss: 1.1552 - val_accuracy: 0.4615\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 1.0150 - accuracy: 0.4815 - val_loss: 1.2020 - val_accuracy: 0.4359\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 1.0836 - accuracy: 0.4889 - val_loss: 1.1964 - val_accuracy: 0.4701\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.0207 - accuracy: 0.5407 - val_loss: 1.2259 - val_accuracy: 0.5385\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 1.0458 - accuracy: 0.5296 - val_loss: 1.1273 - val_accuracy: 0.4872\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 1.1182 - accuracy: 0.5185 - val_loss: 1.6433 - val_accuracy: 0.4957\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 1.4376 - accuracy: 0.5148 - val_loss: 1.4339 - val_accuracy: 0.4957\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 1.1726 - accuracy: 0.4852 - val_loss: 1.1711 - val_accuracy: 0.4444\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 1.0616 - accuracy: 0.5148 - val_loss: 1.1889 - val_accuracy: 0.5043\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 1.1674 - accuracy: 0.4704 - val_loss: 1.6223 - val_accuracy: 0.3932\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 1.1680 - accuracy: 0.4815 - val_loss: 1.1890 - val_accuracy: 0.5470\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 1.0626 - accuracy: 0.5000 - val_loss: 1.2496 - val_accuracy: 0.4274\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.0572 - accuracy: 0.5222 - val_loss: 1.2847 - val_accuracy: 0.5299\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.2737 - accuracy: 0.5333 - val_loss: 1.6518 - val_accuracy: 0.4872\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.3162 - accuracy: 0.5037 - val_loss: 1.1227 - val_accuracy: 0.5470\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 1.0783 - accuracy: 0.5333 - val_loss: 1.2843 - val_accuracy: 0.4615\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9890 - accuracy: 0.5185 - val_loss: 1.0736 - val_accuracy: 0.5641\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.0137 - accuracy: 0.5667 - val_loss: 1.0665 - val_accuracy: 0.5983\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9406 - accuracy: 0.5741 - val_loss: 1.0936 - val_accuracy: 0.4957\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9386 - accuracy: 0.5630 - val_loss: 1.1442 - val_accuracy: 0.5299\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9897 - accuracy: 0.5333 - val_loss: 1.0829 - val_accuracy: 0.4701\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9889 - accuracy: 0.5185 - val_loss: 1.2082 - val_accuracy: 0.5470\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1003 - accuracy: 0.5667 - val_loss: 1.1347 - val_accuracy: 0.5897\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9660 - accuracy: 0.5741 - val_loss: 1.1651 - val_accuracy: 0.4786\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9912 - accuracy: 0.5444 - val_loss: 1.0707 - val_accuracy: 0.5299\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9984 - accuracy: 0.5593 - val_loss: 1.0468 - val_accuracy: 0.5299\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9945 - accuracy: 0.5667 - val_loss: 1.2681 - val_accuracy: 0.5043\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0951 - accuracy: 0.5704 - val_loss: 1.0756 - val_accuracy: 0.5299\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0091 - accuracy: 0.5370 - val_loss: 1.2132 - val_accuracy: 0.5043\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9782 - accuracy: 0.5704 - val_loss: 1.3132 - val_accuracy: 0.5470\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.1012 - accuracy: 0.5519 - val_loss: 1.2375 - val_accuracy: 0.5043\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9677 - accuracy: 0.5519 - val_loss: 1.1779 - val_accuracy: 0.4615\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9830 - accuracy: 0.5370 - val_loss: 1.0750 - val_accuracy: 0.5043\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0614 - accuracy: 0.5741 - val_loss: 1.1275 - val_accuracy: 0.5556\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.0935 - accuracy: 0.5481 - val_loss: 1.1475 - val_accuracy: 0.4872\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 1.0584 - accuracy: 0.5370 - val_loss: 1.5385 - val_accuracy: 0.4786\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 1.1187 - accuracy: 0.5370 - val_loss: 1.1940 - val_accuracy: 0.4957\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 1.0894 - accuracy: 0.5519 - val_loss: 1.9346 - val_accuracy: 0.4701\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 1.4240 - accuracy: 0.5148 - val_loss: 1.8162 - val_accuracy: 0.4103\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.0597 - accuracy: 0.5556 - val_loss: 1.1161 - val_accuracy: 0.5641\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 1.0780 - accuracy: 0.5593 - val_loss: 1.1857 - val_accuracy: 0.4957\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.0171 - accuracy: 0.5481 - val_loss: 1.2469 - val_accuracy: 0.5299\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0749 - accuracy: 0.5222 - val_loss: 1.1608 - val_accuracy: 0.5299\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.0238 - accuracy: 0.5259 - val_loss: 1.4059 - val_accuracy: 0.4359\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.0338 - accuracy: 0.5741 - val_loss: 1.3500 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 1.0886 - accuracy: 0.5852 - val_loss: 1.1874 - val_accuracy: 0.4615\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.0107 - accuracy: 0.5185 - val_loss: 1.1578 - val_accuracy: 0.5556\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7630 - accuracy: 0.65 - 0s 135us/step - loss: 0.9561 - accuracy: 0.5667 - val_loss: 1.1207 - val_accuracy: 0.4957\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9802 - accuracy: 0.5519 - val_loss: 1.1271 - val_accuracy: 0.4359\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9412 - accuracy: 0.5519 - val_loss: 1.1104 - val_accuracy: 0.5470\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9186 - accuracy: 0.6000 - val_loss: 1.2516 - val_accuracy: 0.4957\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.1053 - accuracy: 0.5444 - val_loss: 1.3668 - val_accuracy: 0.5556\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0505 - accuracy: 0.5778 - val_loss: 1.1159 - val_accuracy: 0.5043\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 1.0149 - accuracy: 0.5148 - val_loss: 1.0869 - val_accuracy: 0.4701\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.9476 - accuracy: 0.5407 - val_loss: 1.1702 - val_accuracy: 0.4530\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9546 - accuracy: 0.5630 - val_loss: 1.1211 - val_accuracy: 0.5556\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9476 - accuracy: 0.5815 - val_loss: 1.0882 - val_accuracy: 0.5128\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.0319 - accuracy: 0.5667 - val_loss: 1.3508 - val_accuracy: 0.4872\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 1.0546 - accuracy: 0.5481 - val_loss: 1.1718 - val_accuracy: 0.4444\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9683 - accuracy: 0.5407 - val_loss: 1.0779 - val_accuracy: 0.4957\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9270 - accuracy: 0.5852 - val_loss: 1.0955 - val_accuracy: 0.5641\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9170 - accuracy: 0.5815 - val_loss: 1.0533 - val_accuracy: 0.4957\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8981 - accuracy: 0.5815 - val_loss: 1.0348 - val_accuracy: 0.5299\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9248 - accuracy: 0.5667 - val_loss: 1.0738 - val_accuracy: 0.4957\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9076 - accuracy: 0.5741 - val_loss: 1.1073 - val_accuracy: 0.5043\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0396 - accuracy: 0.5852 - val_loss: 1.3753 - val_accuracy: 0.5385\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0944 - accuracy: 0.5852 - val_loss: 1.2925 - val_accuracy: 0.4188\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9786 - accuracy: 0.5037 - val_loss: 1.1031 - val_accuracy: 0.5043\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9163 - accuracy: 0.5593 - val_loss: 1.1845 - val_accuracy: 0.4530\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.1172 - accuracy: 0.5444 - val_loss: 1.6166 - val_accuracy: 0.5128\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.1988 - accuracy: 0.5778 - val_loss: 1.1577 - val_accuracy: 0.5641\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.1182 - accuracy: 0.5111 - val_loss: 1.9358 - val_accuracy: 0.3846\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.2566 - accuracy: 0.5037 - val_loss: 1.5112 - val_accuracy: 0.5214\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.1161 - accuracy: 0.5630 - val_loss: 1.2061 - val_accuracy: 0.5043\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 1.5825 - accuracy: 0.5185 - val_loss: 3.1146 - val_accuracy: 0.3846\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 1.9855 - accuracy: 0.4926 - val_loss: 2.5692 - val_accuracy: 0.4530\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.5049 - accuracy: 0.5481 - val_loss: 1.4385 - val_accuracy: 0.5043\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9907 - accuracy: 0.5852 - val_loss: 1.1613 - val_accuracy: 0.5299\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 79us/step - loss: 0.8962 - accuracy: 0.5778 - val_loss: 1.1656 - val_accuracy: 0.5128\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9288 - accuracy: 0.5593 - val_loss: 1.1898 - val_accuracy: 0.4957\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9647 - accuracy: 0.5741 - val_loss: 1.1962 - val_accuracy: 0.5470\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0155 - accuracy: 0.5370 - val_loss: 1.1661 - val_accuracy: 0.5214\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0360 - accuracy: 0.5741 - val_loss: 1.1000 - val_accuracy: 0.5385\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8952 - accuracy: 0.5741 - val_loss: 1.1725 - val_accuracy: 0.5128\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9394 - accuracy: 0.5370 - val_loss: 1.0626 - val_accuracy: 0.4786\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0030 - accuracy: 0.5630 - val_loss: 1.2080 - val_accuracy: 0.5556\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9988 - accuracy: 0.5519 - val_loss: 1.2729 - val_accuracy: 0.5043\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.9547 - accuracy: 0.5778 - val_loss: 1.1688 - val_accuracy: 0.4957\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 1.0621 - accuracy: 0.5926 - val_loss: 1.1604 - val_accuracy: 0.5470\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9062 - accuracy: 0.5778 - val_loss: 1.0593 - val_accuracy: 0.4872\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9303 - accuracy: 0.5519 - val_loss: 1.0442 - val_accuracy: 0.4957\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.9505 - accuracy: 0.5889 - val_loss: 1.0531 - val_accuracy: 0.5214\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9856 - accuracy: 0.5704 - val_loss: 1.1852 - val_accuracy: 0.5043\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 1.0321 - accuracy: 0.5741 - val_loss: 1.1431 - val_accuracy: 0.5470\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.0710 - accuracy: 0.6037 - val_loss: 1.2300 - val_accuracy: 0.5299\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0345 - accuracy: 0.5333 - val_loss: 1.1176 - val_accuracy: 0.5043\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.3943 - accuracy: 0.5407 - val_loss: 1.5753 - val_accuracy: 0.5299\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0755 - accuracy: 0.5630 - val_loss: 1.4097 - val_accuracy: 0.4530\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0640 - accuracy: 0.5222 - val_loss: 1.2632 - val_accuracy: 0.4274\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9137 - accuracy: 0.6037 - val_loss: 1.2370 - val_accuracy: 0.5556\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9949 - accuracy: 0.5778 - val_loss: 1.0326 - val_accuracy: 0.4872\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8859 - accuracy: 0.5444 - val_loss: 1.0657 - val_accuracy: 0.4786\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8696 - accuracy: 0.5815 - val_loss: 1.0306 - val_accuracy: 0.5128\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8608 - accuracy: 0.6074 - val_loss: 1.0784 - val_accuracy: 0.5043\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9198 - accuracy: 0.6037 - val_loss: 1.3478 - val_accuracy: 0.5043\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0728 - accuracy: 0.5963 - val_loss: 1.0735 - val_accuracy: 0.5385\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.2237 - accuracy: 0.5407 - val_loss: 1.3938 - val_accuracy: 0.4701\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.1606 - accuracy: 0.5370 - val_loss: 1.2025 - val_accuracy: 0.5385\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9666 - accuracy: 0.5444 - val_loss: 1.2372 - val_accuracy: 0.4274\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9285 - accuracy: 0.5444 - val_loss: 1.0613 - val_accuracy: 0.5214\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8607 - accuracy: 0.6111 - val_loss: 1.0462 - val_accuracy: 0.5299\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8863 - accuracy: 0.5926 - val_loss: 1.1361 - val_accuracy: 0.5385\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.1598 - accuracy: 0.6000 - val_loss: 1.3244 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.0558 - accuracy: 0.5407 - val_loss: 1.2064 - val_accuracy: 0.4274\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9219 - accuracy: 0.5370 - val_loss: 1.0456 - val_accuracy: 0.5556\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8818 - accuracy: 0.5778 - val_loss: 1.0608 - val_accuracy: 0.5385\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8685 - accuracy: 0.6000 - val_loss: 1.1043 - val_accuracy: 0.5043\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9660 - accuracy: 0.6222 - val_loss: 1.1549 - val_accuracy: 0.6068\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8718 - accuracy: 0.5963 - val_loss: 1.0519 - val_accuracy: 0.5128\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0447 - val_accuracy: 0.4872\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8586 - accuracy: 0.5741 - val_loss: 1.0270 - val_accuracy: 0.5214\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8636 - accuracy: 0.6000 - val_loss: 1.0560 - val_accuracy: 0.5385\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9031 - accuracy: 0.5593 - val_loss: 1.0319 - val_accuracy: 0.5128\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8850 - accuracy: 0.5778 - val_loss: 1.1255 - val_accuracy: 0.5556\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.9368 - accuracy: 0.5815 - val_loss: 1.1519 - val_accuracy: 0.5043\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.9332 - accuracy: 0.5963 - val_loss: 1.1357 - val_accuracy: 0.5641\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.9152 - accuracy: 0.6148 - val_loss: 1.1674 - val_accuracy: 0.5726\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9376 - accuracy: 0.6000 - val_loss: 1.0196 - val_accuracy: 0.5128\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8546 - accuracy: 0.5889 - val_loss: 1.0948 - val_accuracy: 0.5726\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8759 - accuracy: 0.6296 - val_loss: 1.0913 - val_accuracy: 0.5043\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.0133 - accuracy: 0.6148 - val_loss: 1.1337 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8521 - accuracy: 0.6111 - val_loss: 1.0410 - val_accuracy: 0.5214\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8479 - accuracy: 0.5926 - val_loss: 1.0409 - val_accuracy: 0.5299\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8557 - accuracy: 0.6296 - val_loss: 1.0459 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8688 - accuracy: 0.6444 - val_loss: 1.0304 - val_accuracy: 0.5385\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8721 - accuracy: 0.6185 - val_loss: 1.1514 - val_accuracy: 0.5641\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9196 - accuracy: 0.6111 - val_loss: 1.1125 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9459 - accuracy: 0.6074 - val_loss: 1.0759 - val_accuracy: 0.5299\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9327 - accuracy: 0.5963 - val_loss: 1.2786 - val_accuracy: 0.5385\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9773 - accuracy: 0.5963 - val_loss: 1.3392 - val_accuracy: 0.5299\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0264 - accuracy: 0.6037 - val_loss: 1.1876 - val_accuracy: 0.5812\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8867 - accuracy: 0.6259 - val_loss: 1.1966 - val_accuracy: 0.5214\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9517 - accuracy: 0.6370 - val_loss: 1.2588 - val_accuracy: 0.5812\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9331 - accuracy: 0.6185 - val_loss: 1.0334 - val_accuracy: 0.5470\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8792 - accuracy: 0.6111 - val_loss: 1.0209 - val_accuracy: 0.5556\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9483 - accuracy: 0.6037 - val_loss: 1.2594 - val_accuracy: 0.5556\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8800 - accuracy: 0.6630 - val_loss: 1.1461 - val_accuracy: 0.5556\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0365 - accuracy: 0.6259 - val_loss: 1.5873 - val_accuracy: 0.5043\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.3711 - accuracy: 0.6074 - val_loss: 1.4946 - val_accuracy: 0.5299\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0048 - accuracy: 0.5778 - val_loss: 1.3302 - val_accuracy: 0.4359\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 1.0035 - accuracy: 0.5593 - val_loss: 1.0865 - val_accuracy: 0.6068\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8962 - accuracy: 0.6333 - val_loss: 1.3166 - val_accuracy: 0.4786\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9942 - accuracy: 0.5815 - val_loss: 1.2419 - val_accuracy: 0.4615\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9413 - accuracy: 0.56 - 0s 148us/step - loss: 0.9817 - accuracy: 0.5963 - val_loss: 1.3230 - val_accuracy: 0.5897\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.9648 - accuracy: 0.6222 - val_loss: 1.1635 - val_accuracy: 0.5299\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9378 - accuracy: 0.6296 - val_loss: 1.1190 - val_accuracy: 0.5812\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8644 - accuracy: 0.6296 - val_loss: 1.0080 - val_accuracy: 0.5556\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8247 - accuracy: 0.6444 - val_loss: 1.0235 - val_accuracy: 0.5556\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8286 - accuracy: 0.6556 - val_loss: 1.0467 - val_accuracy: 0.5812\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8289 - accuracy: 0.6444 - val_loss: 1.0611 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8457 - accuracy: 0.6778 - val_loss: 1.0191 - val_accuracy: 0.5812\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8820 - accuracy: 0.6333 - val_loss: 1.0925 - val_accuracy: 0.5470\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8856 - accuracy: 0.6481 - val_loss: 1.1397 - val_accuracy: 0.5726\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8868 - accuracy: 0.6519 - val_loss: 0.9985 - val_accuracy: 0.5641\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8868 - accuracy: 0.6556 - val_loss: 1.1030 - val_accuracy: 0.5470\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9699 - accuracy: 0.6519 - val_loss: 1.2193 - val_accuracy: 0.6068\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8934 - accuracy: 0.6741 - val_loss: 1.2186 - val_accuracy: 0.5385\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9655 - accuracy: 0.6148 - val_loss: 1.3927 - val_accuracy: 0.5043\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0736 - accuracy: 0.6296 - val_loss: 1.0130 - val_accuracy: 0.6239\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8273 - accuracy: 0.6704 - val_loss: 1.0898 - val_accuracy: 0.5299\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8349 - accuracy: 0.6630 - val_loss: 1.0077 - val_accuracy: 0.6239\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8232 - accuracy: 0.6741 - val_loss: 1.0115 - val_accuracy: 0.5641\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8253 - accuracy: 0.6370 - val_loss: 1.0299 - val_accuracy: 0.5726\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8361 - accuracy: 0.6667 - val_loss: 1.0100 - val_accuracy: 0.5128\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8553 - accuracy: 0.6556 - val_loss: 1.0373 - val_accuracy: 0.6154\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8138 - accuracy: 0.6852 - val_loss: 1.1121 - val_accuracy: 0.5556\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8519 - accuracy: 0.6556 - val_loss: 1.0533 - val_accuracy: 0.5897\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8795 - accuracy: 0.6519 - val_loss: 1.0510 - val_accuracy: 0.5983\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8605 - accuracy: 0.6630 - val_loss: 0.9997 - val_accuracy: 0.5812\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8412 - accuracy: 0.6667 - val_loss: 1.1519 - val_accuracy: 0.6239\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9198 - accuracy: 0.6667 - val_loss: 0.9793 - val_accuracy: 0.5556\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8990 - accuracy: 0.6778 - val_loss: 1.2187 - val_accuracy: 0.6239\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9524 - accuracy: 0.6704 - val_loss: 1.2144 - val_accuracy: 0.5556\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9235 - accuracy: 0.6556 - val_loss: 1.0169 - val_accuracy: 0.5983\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8093 - accuracy: 0.6741 - val_loss: 1.0344 - val_accuracy: 0.5641\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9340 - accuracy: 0.6407 - val_loss: 1.0718 - val_accuracy: 0.6154\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8129 - accuracy: 0.6704 - val_loss: 0.9895 - val_accuracy: 0.5641\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8252 - accuracy: 0.6630 - val_loss: 1.0112 - val_accuracy: 0.5812\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0136 - accuracy: 0.6556 - val_loss: 1.6108 - val_accuracy: 0.5385\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.3254 - accuracy: 0.6444 - val_loss: 1.3943 - val_accuracy: 0.6068\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9911 - accuracy: 0.6407 - val_loss: 1.4046 - val_accuracy: 0.4872\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0879 - accuracy: 0.5815 - val_loss: 1.2104 - val_accuracy: 0.4615\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9119 - accuracy: 0.6259 - val_loss: 1.6469 - val_accuracy: 0.5385\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0807 - accuracy: 0.6111 - val_loss: 1.2652 - val_accuracy: 0.5385\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0367 - accuracy: 0.6333 - val_loss: 1.2647 - val_accuracy: 0.5983\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9435 - accuracy: 0.6444 - val_loss: 1.1757 - val_accuracy: 0.5128\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.9092 - accuracy: 0.6593 - val_loss: 1.1073 - val_accuracy: 0.6068\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8357 - accuracy: 0.6815 - val_loss: 1.0047 - val_accuracy: 0.6068\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8110 - accuracy: 0.6704 - val_loss: 1.0393 - val_accuracy: 0.5897\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8176 - accuracy: 0.6630 - val_loss: 1.0258 - val_accuracy: 0.5812\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8097 - accuracy: 0.6704 - val_loss: 1.0001 - val_accuracy: 0.6239\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8005 - accuracy: 0.6963 - val_loss: 0.9912 - val_accuracy: 0.6325\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7987 - accuracy: 0.6926 - val_loss: 1.0120 - val_accuracy: 0.5897\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8034 - accuracy: 0.6704 - val_loss: 0.9771 - val_accuracy: 0.6325\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8010 - accuracy: 0.7074 - val_loss: 0.9933 - val_accuracy: 0.6068\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7960 - accuracy: 0.6741 - val_loss: 0.9969 - val_accuracy: 0.6068\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8058 - accuracy: 0.6667 - val_loss: 1.0806 - val_accuracy: 0.5641\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8708 - accuracy: 0.6778 - val_loss: 1.1269 - val_accuracy: 0.6239\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8870 - accuracy: 0.6667 - val_loss: 1.1358 - val_accuracy: 0.6239\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9336 - accuracy: 0.6630 - val_loss: 0.9822 - val_accuracy: 0.6068\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8091 - accuracy: 0.6556 - val_loss: 1.1409 - val_accuracy: 0.5556\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8452 - accuracy: 0.6481 - val_loss: 1.0067 - val_accuracy: 0.6068\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8467 - accuracy: 0.6593 - val_loss: 1.0576 - val_accuracy: 0.5812\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8280 - accuracy: 0.6593 - val_loss: 1.0207 - val_accuracy: 0.5556\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7850 - accuracy: 0.6889 - val_loss: 1.0424 - val_accuracy: 0.6239\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8221 - accuracy: 0.6630 - val_loss: 1.0372 - val_accuracy: 0.5812\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8211 - accuracy: 0.6926 - val_loss: 1.0864 - val_accuracy: 0.6239\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8180 - accuracy: 0.6593 - val_loss: 1.0040 - val_accuracy: 0.5641\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8076 - accuracy: 0.6519 - val_loss: 0.9883 - val_accuracy: 0.5983\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7945 - accuracy: 0.6704 - val_loss: 1.0009 - val_accuracy: 0.5983\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7877 - accuracy: 0.6815 - val_loss: 1.0094 - val_accuracy: 0.6154\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8470 - accuracy: 0.6852 - val_loss: 1.4290 - val_accuracy: 0.5726\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.1886 - accuracy: 0.6556 - val_loss: 1.2063 - val_accuracy: 0.5897\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8838 - accuracy: 0.6481 - val_loss: 1.2452 - val_accuracy: 0.5214\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8715 - accuracy: 0.6407 - val_loss: 1.0644 - val_accuracy: 0.5556\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9434 - accuracy: 0.6296 - val_loss: 1.3605 - val_accuracy: 0.5385\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8801 - accuracy: 0.6407 - val_loss: 1.0881 - val_accuracy: 0.5470\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8709 - accuracy: 0.6556 - val_loss: 1.0618 - val_accuracy: 0.6239\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8554 - accuracy: 0.6704 - val_loss: 1.1074 - val_accuracy: 0.5726\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8950 - accuracy: 0.6519 - val_loss: 0.9791 - val_accuracy: 0.5641\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8304 - accuracy: 0.6741 - val_loss: 1.0157 - val_accuracy: 0.5812\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7952 - accuracy: 0.6667 - val_loss: 1.0853 - val_accuracy: 0.6068\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8363 - accuracy: 0.6926 - val_loss: 0.9804 - val_accuracy: 0.6239\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7838 - accuracy: 0.6741 - val_loss: 1.0076 - val_accuracy: 0.5812\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7968 - accuracy: 0.6741 - val_loss: 1.0112 - val_accuracy: 0.5983\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8289 - accuracy: 0.6963 - val_loss: 1.0191 - val_accuracy: 0.5897\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8672 - accuracy: 0.6481 - val_loss: 1.0866 - val_accuracy: 0.5470\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8419 - accuracy: 0.6630 - val_loss: 1.0049 - val_accuracy: 0.6154\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8045 - accuracy: 0.6741 - val_loss: 1.0961 - val_accuracy: 0.5470\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8556 - accuracy: 0.6778 - val_loss: 1.1987 - val_accuracy: 0.6325\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9284 - accuracy: 0.6704 - val_loss: 0.9895 - val_accuracy: 0.6239\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8177 - accuracy: 0.6778 - val_loss: 1.1364 - val_accuracy: 0.5641\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8304 - accuracy: 0.6556 - val_loss: 0.9745 - val_accuracy: 0.5812\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7834 - accuracy: 0.6815 - val_loss: 0.9854 - val_accuracy: 0.6154\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8152 - accuracy: 0.6778 - val_loss: 1.0188 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7726 - accuracy: 0.6741 - val_loss: 0.9768 - val_accuracy: 0.6068\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7807 - accuracy: 0.6926 - val_loss: 0.9874 - val_accuracy: 0.6068\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7778 - accuracy: 0.6852 - val_loss: 0.9950 - val_accuracy: 0.6068\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7850 - accuracy: 0.6778 - val_loss: 1.0762 - val_accuracy: 0.6239\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8338 - accuracy: 0.6741 - val_loss: 1.0494 - val_accuracy: 0.5556\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8162 - accuracy: 0.6667 - val_loss: 1.1120 - val_accuracy: 0.6239\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9436 - accuracy: 0.6667 - val_loss: 0.9771 - val_accuracy: 0.6154\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8451 - accuracy: 0.6852 - val_loss: 1.0336 - val_accuracy: 0.6325\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8355 - accuracy: 0.6741 - val_loss: 1.0041 - val_accuracy: 0.6154\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8748 - accuracy: 0.6889 - val_loss: 0.9565 - val_accuracy: 0.6154\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7772 - accuracy: 0.6741 - val_loss: 0.9970 - val_accuracy: 0.6068\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7725 - accuracy: 0.6815 - val_loss: 1.0080 - val_accuracy: 0.5983\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8023 - accuracy: 0.6815 - val_loss: 0.9645 - val_accuracy: 0.6410\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.7981 - accuracy: 0.6778 - val_loss: 1.0247 - val_accuracy: 0.5983\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7774 - accuracy: 0.6815 - val_loss: 0.9932 - val_accuracy: 0.6325\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8124 - accuracy: 0.6926 - val_loss: 0.9858 - val_accuracy: 0.5983\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.7760 - accuracy: 0.6815 - val_loss: 0.9970 - val_accuracy: 0.6154\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.7606 - accuracy: 0.7000 - val_loss: 0.9683 - val_accuracy: 0.6410\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7742 - accuracy: 0.6963 - val_loss: 0.9717 - val_accuracy: 0.6239\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7877 - accuracy: 0.6741 - val_loss: 1.0520 - val_accuracy: 0.5726\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7862 - accuracy: 0.6815 - val_loss: 0.9492 - val_accuracy: 0.6410\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7994 - accuracy: 0.6963 - val_loss: 0.9861 - val_accuracy: 0.6154\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8782 - accuracy: 0.6889 - val_loss: 1.0879 - val_accuracy: 0.6239\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8076 - accuracy: 0.6815 - val_loss: 1.1263 - val_accuracy: 0.5897\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9026 - accuracy: 0.6741 - val_loss: 1.0752 - val_accuracy: 0.6325\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7811 - accuracy: 0.6852 - val_loss: 1.1612 - val_accuracy: 0.5470\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9551 - accuracy: 0.6852 - val_loss: 1.1630 - val_accuracy: 0.6325\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8094 - accuracy: 0.6815 - val_loss: 1.0663 - val_accuracy: 0.5385\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8642 - accuracy: 0.6704 - val_loss: 1.1190 - val_accuracy: 0.5812\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8022 - accuracy: 0.7037 - val_loss: 1.0138 - val_accuracy: 0.5897\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8100 - accuracy: 0.6741 - val_loss: 1.0769 - val_accuracy: 0.5641\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8249 - accuracy: 0.6741 - val_loss: 1.3986 - val_accuracy: 0.5726\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0768 - accuracy: 0.6704 - val_loss: 1.0756 - val_accuracy: 0.5983\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8622 - accuracy: 0.6741 - val_loss: 1.2190 - val_accuracy: 0.5470\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9555 - accuracy: 0.6778 - val_loss: 0.9693 - val_accuracy: 0.6325\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8950 - accuracy: 0.6630 - val_loss: 1.8524 - val_accuracy: 0.5043\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.1349 - accuracy: 0.6222 - val_loss: 1.3665 - val_accuracy: 0.4786\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8482 - accuracy: 0.6259 - val_loss: 1.1877 - val_accuracy: 0.6239\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8253 - accuracy: 0.7111 - val_loss: 1.1749 - val_accuracy: 0.5812\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8823 - accuracy: 0.6963 - val_loss: 1.1372 - val_accuracy: 0.6410\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8440 - accuracy: 0.6704 - val_loss: 0.9673 - val_accuracy: 0.6154\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8551 - accuracy: 0.6963 - val_loss: 0.9768 - val_accuracy: 0.6239\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8503 - accuracy: 0.6778 - val_loss: 1.0761 - val_accuracy: 0.6410\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9813 - accuracy: 0.6704 - val_loss: 0.9994 - val_accuracy: 0.5983\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8320 - accuracy: 0.6815 - val_loss: 1.0104 - val_accuracy: 0.6325\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7864 - accuracy: 0.6852 - val_loss: 0.9991 - val_accuracy: 0.5897\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8113 - accuracy: 0.6778 - val_loss: 0.9794 - val_accuracy: 0.6410\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7883 - accuracy: 0.6778 - val_loss: 0.9883 - val_accuracy: 0.6154\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7630 - accuracy: 0.6926 - val_loss: 1.0419 - val_accuracy: 0.6239\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7871 - accuracy: 0.6778 - val_loss: 1.0142 - val_accuracy: 0.6325\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7615 - accuracy: 0.7000 - val_loss: 0.9668 - val_accuracy: 0.6496\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7518 - accuracy: 0.7074 - val_loss: 0.9820 - val_accuracy: 0.6239\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7549 - accuracy: 0.7074 - val_loss: 0.9755 - val_accuracy: 0.6239\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7631 - accuracy: 0.6852 - val_loss: 1.0847 - val_accuracy: 0.6325\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8079 - accuracy: 0.6926 - val_loss: 1.0260 - val_accuracy: 0.5812\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8914 - accuracy: 0.6667 - val_loss: 1.3023 - val_accuracy: 0.5897\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9932 - accuracy: 0.6815 - val_loss: 0.9830 - val_accuracy: 0.5983\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8057 - accuracy: 0.6778 - val_loss: 1.1837 - val_accuracy: 0.5556\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8612 - accuracy: 0.6778 - val_loss: 1.0472 - val_accuracy: 0.5812\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8256 - accuracy: 0.6926 - val_loss: 1.1856 - val_accuracy: 0.5812\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8273 - accuracy: 0.6852 - val_loss: 1.0946 - val_accuracy: 0.5726\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7902 - accuracy: 0.6889 - val_loss: 1.0250 - val_accuracy: 0.6410\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7763 - accuracy: 0.6889 - val_loss: 1.0475 - val_accuracy: 0.5641\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7690 - accuracy: 0.6852 - val_loss: 0.9654 - val_accuracy: 0.6410\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7577 - accuracy: 0.7037 - val_loss: 0.9798 - val_accuracy: 0.6068\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7559 - accuracy: 0.6963 - val_loss: 0.9559 - val_accuracy: 0.6068\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7503 - accuracy: 0.7037 - val_loss: 0.9586 - val_accuracy: 0.6325\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7496 - accuracy: 0.6889 - val_loss: 0.9965 - val_accuracy: 0.6154\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7490 - accuracy: 0.7037 - val_loss: 0.9767 - val_accuracy: 0.6239\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7448 - accuracy: 0.6963 - val_loss: 1.0287 - val_accuracy: 0.5726\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7926 - accuracy: 0.6926 - val_loss: 0.9948 - val_accuracy: 0.5385\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7636 - accuracy: 0.6963 - val_loss: 1.1085 - val_accuracy: 0.6154\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8186 - accuracy: 0.6889 - val_loss: 1.0636 - val_accuracy: 0.5812\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7707 - accuracy: 0.6926 - val_loss: 1.0046 - val_accuracy: 0.6154\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8535 - accuracy: 0.6778 - val_loss: 1.2440 - val_accuracy: 0.5897\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.1230 - accuracy: 0.6630 - val_loss: 1.1665 - val_accuracy: 0.6154\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0372 - accuracy: 0.6407 - val_loss: 1.8171 - val_accuracy: 0.4872\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.2002 - accuracy: 0.6111 - val_loss: 1.5194 - val_accuracy: 0.5385\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.1105 - accuracy: 0.6296 - val_loss: 1.1765 - val_accuracy: 0.5983\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9892 - accuracy: 0.6481 - val_loss: 1.1277 - val_accuracy: 0.5214\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8231 - accuracy: 0.6704 - val_loss: 1.0407 - val_accuracy: 0.5641\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8146 - accuracy: 0.6333 - val_loss: 1.2992 - val_accuracy: 0.5128\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8395 - accuracy: 0.6778 - val_loss: 0.9991 - val_accuracy: 0.5726\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8453 - accuracy: 0.6852 - val_loss: 1.1592 - val_accuracy: 0.5385\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8040 - accuracy: 0.6519 - val_loss: 1.1421 - val_accuracy: 0.5556\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8205 - accuracy: 0.6778 - val_loss: 1.7648 - val_accuracy: 0.5470\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.4054 - accuracy: 0.6333 - val_loss: 1.2118 - val_accuracy: 0.5470\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8542 - accuracy: 0.6556 - val_loss: 1.1640 - val_accuracy: 0.6325\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9467 - accuracy: 0.6667 - val_loss: 0.9877 - val_accuracy: 0.5726\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1332 - accuracy: 0.6704 - val_loss: 1.1926 - val_accuracy: 0.6068\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9456 - accuracy: 0.6778 - val_loss: 1.0026 - val_accuracy: 0.5897\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8792 - accuracy: 0.6889 - val_loss: 1.1463 - val_accuracy: 0.6410\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8414 - accuracy: 0.6704 - val_loss: 1.0133 - val_accuracy: 0.5726\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7848 - accuracy: 0.6741 - val_loss: 1.0324 - val_accuracy: 0.6325\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8047 - accuracy: 0.6667 - val_loss: 1.0010 - val_accuracy: 0.5556\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8024 - accuracy: 0.6852 - val_loss: 0.9903 - val_accuracy: 0.6239\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9755 - accuracy: 0.6889 - val_loss: 1.4655 - val_accuracy: 0.6068\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.0649 - accuracy: 0.6815 - val_loss: 0.9992 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9614 - accuracy: 0.6407 - val_loss: 1.2825 - val_accuracy: 0.5299\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8627 - accuracy: 0.6704 - val_loss: 1.0960 - val_accuracy: 0.5641\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8897 - accuracy: 0.6741 - val_loss: 1.1756 - val_accuracy: 0.5983\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8612 - accuracy: 0.6852 - val_loss: 1.0979 - val_accuracy: 0.6410\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9016 - accuracy: 0.6926 - val_loss: 0.9938 - val_accuracy: 0.6154\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8041 - accuracy: 0.6667 - val_loss: 0.9964 - val_accuracy: 0.5812\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7578 - accuracy: 0.6926 - val_loss: 0.9983 - val_accuracy: 0.6154\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7478 - accuracy: 0.7037 - val_loss: 0.9859 - val_accuracy: 0.6325\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7487 - accuracy: 0.7074 - val_loss: 0.9819 - val_accuracy: 0.6325\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7870 - accuracy: 0.6778 - val_loss: 0.9789 - val_accuracy: 0.6154\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7818 - accuracy: 0.7000 - val_loss: 0.9621 - val_accuracy: 0.5897\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7401 - accuracy: 0.6926 - val_loss: 0.9913 - val_accuracy: 0.6068\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7430 - accuracy: 0.7037 - val_loss: 0.9859 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7505 - accuracy: 0.6889 - val_loss: 0.9648 - val_accuracy: 0.6239\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7593 - accuracy: 0.6926 - val_loss: 1.0670 - val_accuracy: 0.6410\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8253 - accuracy: 0.6889 - val_loss: 0.9764 - val_accuracy: 0.6239\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.0690 - accuracy: 0.6741 - val_loss: 1.2571 - val_accuracy: 0.6410\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8528 - accuracy: 0.6778 - val_loss: 1.0472 - val_accuracy: 0.5385\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1583 - accuracy: 0.6296 - val_loss: 1.7526 - val_accuracy: 0.4872\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9032 - accuracy: 0.6185 - val_loss: 1.0312 - val_accuracy: 0.5897\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8983 - accuracy: 0.6333 - val_loss: 1.4987 - val_accuracy: 0.5299\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9672 - accuracy: 0.6370 - val_loss: 1.1149 - val_accuracy: 0.5299\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7845 - accuracy: 0.6444 - val_loss: 0.9757 - val_accuracy: 0.5812\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7641 - accuracy: 0.6963 - val_loss: 1.0689 - val_accuracy: 0.5726\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7991 - accuracy: 0.6926 - val_loss: 1.2063 - val_accuracy: 0.6410\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8966 - accuracy: 0.6778 - val_loss: 0.9981 - val_accuracy: 0.5641\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7790 - accuracy: 0.6815 - val_loss: 1.2716 - val_accuracy: 0.5299\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8479 - accuracy: 0.6519 - val_loss: 1.0054 - val_accuracy: 0.5983\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7463 - accuracy: 0.7111 - val_loss: 0.9885 - val_accuracy: 0.6239\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7617 - accuracy: 0.6963 - val_loss: 0.9771 - val_accuracy: 0.6154\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7482 - accuracy: 0.7000 - val_loss: 0.9696 - val_accuracy: 0.6068\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7402 - accuracy: 0.7111 - val_loss: 0.9781 - val_accuracy: 0.6325\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7422 - accuracy: 0.7037 - val_loss: 1.0132 - val_accuracy: 0.6325\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7710 - accuracy: 0.7000 - val_loss: 1.1306 - val_accuracy: 0.5726\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8576 - accuracy: 0.6778 - val_loss: 1.0705 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7887 - accuracy: 0.6889 - val_loss: 1.0331 - val_accuracy: 0.5812\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7711 - accuracy: 0.6963 - val_loss: 0.9690 - val_accuracy: 0.6068\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7393 - accuracy: 0.6889 - val_loss: 0.9740 - val_accuracy: 0.6325\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7745 - accuracy: 0.6889 - val_loss: 0.9875 - val_accuracy: 0.6154\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7537 - accuracy: 0.6926 - val_loss: 1.0138 - val_accuracy: 0.6325\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7661 - accuracy: 0.6852 - val_loss: 1.3393 - val_accuracy: 0.5556\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.0904 - accuracy: 0.6519 - val_loss: 1.0192 - val_accuracy: 0.5983\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8418 - accuracy: 0.6630 - val_loss: 1.3003 - val_accuracy: 0.5897\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8737 - accuracy: 0.6741 - val_loss: 0.9609 - val_accuracy: 0.5897\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7624 - accuracy: 0.6741 - val_loss: 1.0384 - val_accuracy: 0.6068\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7730 - accuracy: 0.6926 - val_loss: 1.0134 - val_accuracy: 0.6325\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7769 - accuracy: 0.6852 - val_loss: 1.0643 - val_accuracy: 0.5556\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7669 - accuracy: 0.7074 - val_loss: 1.0001 - val_accuracy: 0.5983\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7519 - accuracy: 0.6926 - val_loss: 0.9519 - val_accuracy: 0.6068\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7390 - accuracy: 0.7074 - val_loss: 0.9870 - val_accuracy: 0.6068\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7749 - accuracy: 0.6852 - val_loss: 1.0115 - val_accuracy: 0.6239\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7382 - accuracy: 0.7037 - val_loss: 0.9688 - val_accuracy: 0.6068\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7467 - accuracy: 0.6926 - val_loss: 0.9890 - val_accuracy: 0.6068\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8026 - accuracy: 0.6815 - val_loss: 1.1363 - val_accuracy: 0.6410\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8379 - accuracy: 0.6963 - val_loss: 1.3630 - val_accuracy: 0.5385\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0266 - accuracy: 0.6852 - val_loss: 1.2791 - val_accuracy: 0.5812\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8949 - accuracy: 0.6926 - val_loss: 1.1833 - val_accuracy: 0.5214\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8248 - accuracy: 0.6963 - val_loss: 1.2699 - val_accuracy: 0.6239\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8422 - accuracy: 0.6963 - val_loss: 1.0122 - val_accuracy: 0.5726\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7632 - accuracy: 0.6963 - val_loss: 0.9989 - val_accuracy: 0.6068\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7608 - accuracy: 0.6963 - val_loss: 0.9910 - val_accuracy: 0.6154\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7481 - accuracy: 0.6926 - val_loss: 0.9828 - val_accuracy: 0.6239\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7392 - accuracy: 0.7037 - val_loss: 0.9701 - val_accuracy: 0.5897\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7339 - accuracy: 0.7037 - val_loss: 0.9980 - val_accuracy: 0.5812\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7338 - accuracy: 0.6963 - val_loss: 0.9798 - val_accuracy: 0.6325\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7324 - accuracy: 0.7037 - val_loss: 0.9824 - val_accuracy: 0.6325\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7572 - accuracy: 0.6815 - val_loss: 0.9845 - val_accuracy: 0.5897\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7286 - accuracy: 0.7000 - val_loss: 0.9958 - val_accuracy: 0.6239\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7498 - accuracy: 0.6963 - val_loss: 1.0319 - val_accuracy: 0.5897\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8112 - accuracy: 0.6852 - val_loss: 0.9692 - val_accuracy: 0.6325\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7516 - accuracy: 0.7000 - val_loss: 0.9892 - val_accuracy: 0.6239\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7811 - accuracy: 0.6963 - val_loss: 1.0007 - val_accuracy: 0.5812\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7491 - accuracy: 0.6963 - val_loss: 1.0721 - val_accuracy: 0.5897\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7898 - accuracy: 0.6963 - val_loss: 1.0819 - val_accuracy: 0.5556\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0752 - accuracy: 0.6444 - val_loss: 1.0656 - val_accuracy: 0.5983\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8180 - accuracy: 0.6741 - val_loss: 1.1206 - val_accuracy: 0.5214\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8015 - accuracy: 0.6556 - val_loss: 1.0097 - val_accuracy: 0.5983\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7494 - accuracy: 0.7037 - val_loss: 1.1307 - val_accuracy: 0.6410\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7766 - accuracy: 0.6926 - val_loss: 1.0364 - val_accuracy: 0.5812\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7874 - accuracy: 0.7000 - val_loss: 0.9733 - val_accuracy: 0.6239\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8060 - accuracy: 0.6741 - val_loss: 1.0861 - val_accuracy: 0.6239\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8689 - accuracy: 0.6963 - val_loss: 0.9757 - val_accuracy: 0.5983\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7503 - accuracy: 0.6926 - val_loss: 1.0383 - val_accuracy: 0.6154\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7512 - accuracy: 0.6963 - val_loss: 0.9818 - val_accuracy: 0.5983\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7293 - accuracy: 0.7037 - val_loss: 0.9670 - val_accuracy: 0.6410\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7248 - accuracy: 0.7148 - val_loss: 0.9863 - val_accuracy: 0.6154\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.7407 - accuracy: 0.7074 - val_loss: 0.9878 - val_accuracy: 0.6239\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7485 - accuracy: 0.6889 - val_loss: 1.0049 - val_accuracy: 0.6154\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7812 - accuracy: 0.6963 - val_loss: 1.0487 - val_accuracy: 0.6325\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8755 - accuracy: 0.6889 - val_loss: 0.9629 - val_accuracy: 0.6239\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.0178 - accuracy: 0.6778 - val_loss: 1.1640 - val_accuracy: 0.5983\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0749 - accuracy: 0.6519 - val_loss: 1.1443 - val_accuracy: 0.6325\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7573 - accuracy: 0.6889 - val_loss: 1.0558 - val_accuracy: 0.5299\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7316 - accuracy: 0.6963 - val_loss: 1.0202 - val_accuracy: 0.6068\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7861 - accuracy: 0.7037 - val_loss: 1.1163 - val_accuracy: 0.5812\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8432 - accuracy: 0.7148 - val_loss: 1.4279 - val_accuracy: 0.5897\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9280 - accuracy: 0.6778 - val_loss: 0.9835 - val_accuracy: 0.6068\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8138 - accuracy: 0.6630 - val_loss: 1.1578 - val_accuracy: 0.5214\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7930 - accuracy: 0.6852 - val_loss: 1.0016 - val_accuracy: 0.6068\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9057 - accuracy: 0.6556 - val_loss: 1.1472 - val_accuracy: 0.5385\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7581 - accuracy: 0.6852 - val_loss: 1.0163 - val_accuracy: 0.6239\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7588 - accuracy: 0.6852 - val_loss: 1.0695 - val_accuracy: 0.5897\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8291 - accuracy: 0.6704 - val_loss: 1.1273 - val_accuracy: 0.5897\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7710 - accuracy: 0.7000 - val_loss: 1.1031 - val_accuracy: 0.6239\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8764 - accuracy: 0.6963 - val_loss: 0.9975 - val_accuracy: 0.5726\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8226 - accuracy: 0.6926 - val_loss: 1.1763 - val_accuracy: 0.6325\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8083 - accuracy: 0.6963 - val_loss: 1.0101 - val_accuracy: 0.5556\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8233 - accuracy: 0.6815 - val_loss: 1.0024 - val_accuracy: 0.6068\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7386 - accuracy: 0.7000 - val_loss: 0.9871 - val_accuracy: 0.6239\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7363 - accuracy: 0.7000 - val_loss: 0.9896 - val_accuracy: 0.6068\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7294 - accuracy: 0.7074 - val_loss: 0.9634 - val_accuracy: 0.6410\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7292 - accuracy: 0.7185 - val_loss: 0.9622 - val_accuracy: 0.6239\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7424 - accuracy: 0.7000 - val_loss: 0.9743 - val_accuracy: 0.5983\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7304 - accuracy: 0.7000 - val_loss: 0.9894 - val_accuracy: 0.6068\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7311 - accuracy: 0.7037 - val_loss: 0.9797 - val_accuracy: 0.6239\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7352 - accuracy: 0.6926 - val_loss: 0.9643 - val_accuracy: 0.6325\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7309 - accuracy: 0.6963 - val_loss: 1.0955 - val_accuracy: 0.5470\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.7573 - accuracy: 0.6926 - val_loss: 0.9747 - val_accuracy: 0.5983\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 357us/step - loss: 0.7233 - accuracy: 0.7111 - val_loss: 0.9788 - val_accuracy: 0.6325\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 335us/step - loss: 0.7322 - accuracy: 0.6963 - val_loss: 0.9769 - val_accuracy: 0.6325\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8560 - accuracy: 0.7037 - val_loss: 0.9599 - val_accuracy: 0.6325\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8765 - accuracy: 0.6963 - val_loss: 1.5009 - val_accuracy: 0.5897\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.1623 - accuracy: 0.6741 - val_loss: 1.0850 - val_accuracy: 0.5983\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 99us/step - loss: 0.8912 - accuracy: 0.6741 - val_loss: 1.2141 - val_accuracy: 0.5128\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9485 - accuracy: 0.6667 - val_loss: 1.0043 - val_accuracy: 0.5983\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 1.0615 - accuracy: 0.6630 - val_loss: 1.7851 - val_accuracy: 0.4872\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 248us/step - loss: 0.9855 - accuracy: 0.6333 - val_loss: 1.0455 - val_accuracy: 0.6154\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9640 - accuracy: 0.6815 - val_loss: 1.2281 - val_accuracy: 0.6239\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7597 - accuracy: 0.6926 - val_loss: 1.1638 - val_accuracy: 0.5385\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7974 - accuracy: 0.7000 - val_loss: 1.0265 - val_accuracy: 0.5897\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7281 - accuracy: 0.7148 - val_loss: 0.9927 - val_accuracy: 0.5897\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7980 - accuracy: 0.6815 - val_loss: 1.4300 - val_accuracy: 0.5299\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9015 - accuracy: 0.6519 - val_loss: 1.1052 - val_accuracy: 0.6068\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8855 - accuracy: 0.6630 - val_loss: 1.0245 - val_accuracy: 0.6239\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8154 - accuracy: 0.7000 - val_loss: 1.1431 - val_accuracy: 0.5897\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9448 - accuracy: 0.7037 - val_loss: 1.0161 - val_accuracy: 0.6325\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7441 - accuracy: 0.7037 - val_loss: 1.1100 - val_accuracy: 0.5385\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7600 - accuracy: 0.6852 - val_loss: 1.0512 - val_accuracy: 0.6239\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7625 - accuracy: 0.6963 - val_loss: 1.0456 - val_accuracy: 0.6154\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7900 - accuracy: 0.6704 - val_loss: 1.2240 - val_accuracy: 0.4957\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8090 - accuracy: 0.7000 - val_loss: 1.2758 - val_accuracy: 0.6154\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8971 - accuracy: 0.6852 - val_loss: 1.0307 - val_accuracy: 0.5812\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7897 - accuracy: 0.6963 - val_loss: 1.0766 - val_accuracy: 0.5983\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7575 - accuracy: 0.7000 - val_loss: 1.0041 - val_accuracy: 0.6239\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7296 - accuracy: 0.7148 - val_loss: 0.9991 - val_accuracy: 0.6410\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7338 - accuracy: 0.7000 - val_loss: 1.0011 - val_accuracy: 0.6154\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7348 - accuracy: 0.7000 - val_loss: 1.0053 - val_accuracy: 0.6154\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7359 - accuracy: 0.7000 - val_loss: 1.0154 - val_accuracy: 0.5897\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7281 - accuracy: 0.7074 - val_loss: 0.9667 - val_accuracy: 0.6410\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7190 - accuracy: 0.7111 - val_loss: 0.9940 - val_accuracy: 0.5983\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7258 - accuracy: 0.7074 - val_loss: 0.9917 - val_accuracy: 0.5983\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7167 - accuracy: 0.7074 - val_loss: 0.9872 - val_accuracy: 0.6154\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7304 - accuracy: 0.7111 - val_loss: 0.9605 - val_accuracy: 0.6239\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7388 - accuracy: 0.7074 - val_loss: 1.0328 - val_accuracy: 0.5897\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7832 - accuracy: 0.7074 - val_loss: 1.1422 - val_accuracy: 0.6154\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7984 - accuracy: 0.6963 - val_loss: 1.0277 - val_accuracy: 0.5897\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8664 - accuracy: 0.6926 - val_loss: 1.1255 - val_accuracy: 0.6325\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.7376 - accuracy: 0.7111 - val_loss: 1.1303 - val_accuracy: 0.5726\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8494 - accuracy: 0.6815 - val_loss: 1.1173 - val_accuracy: 0.6239\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7942 - accuracy: 0.6556 - val_loss: 1.0435 - val_accuracy: 0.5556\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7471 - accuracy: 0.6963 - val_loss: 0.9930 - val_accuracy: 0.6068\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7557 - accuracy: 0.6926 - val_loss: 1.1232 - val_accuracy: 0.5726\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8235 - accuracy: 0.6630 - val_loss: 1.1927 - val_accuracy: 0.5299\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9165 - accuracy: 0.6815 - val_loss: 1.3471 - val_accuracy: 0.6239\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8224 - accuracy: 0.6963 - val_loss: 1.2019 - val_accuracy: 0.5470\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9525 - accuracy: 0.6556 - val_loss: 1.3428 - val_accuracy: 0.5726\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9043 - accuracy: 0.6926 - val_loss: 1.0216 - val_accuracy: 0.5897\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7740 - accuracy: 0.6889 - val_loss: 1.0826 - val_accuracy: 0.6239\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7583 - accuracy: 0.7000 - val_loss: 1.0412 - val_accuracy: 0.5556\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7845 - accuracy: 0.6889 - val_loss: 0.9839 - val_accuracy: 0.6154\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7219 - accuracy: 0.7037 - val_loss: 0.9763 - val_accuracy: 0.6154\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7118 - accuracy: 0.7148 - val_loss: 0.9965 - val_accuracy: 0.5983\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7166 - accuracy: 0.7148 - val_loss: 1.0502 - val_accuracy: 0.5897\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8082 - accuracy: 0.7000 - val_loss: 1.5304 - val_accuracy: 0.5897\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.5432 - accuracy: 0.6556 - val_loss: 1.6179 - val_accuracy: 0.6410\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1243 - accuracy: 0.6667 - val_loss: 1.2783 - val_accuracy: 0.5214\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0045 - accuracy: 0.6185 - val_loss: 1.3215 - val_accuracy: 0.5556\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9141 - accuracy: 0.6963 - val_loss: 1.0655 - val_accuracy: 0.6239\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7825 - accuracy: 0.6852 - val_loss: 1.1195 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7553 - accuracy: 0.7000 - val_loss: 0.9969 - val_accuracy: 0.6325\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7796 - accuracy: 0.7000 - val_loss: 0.9935 - val_accuracy: 0.5897\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7239 - accuracy: 0.7111 - val_loss: 1.0349 - val_accuracy: 0.5897\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7255 - accuracy: 0.7037 - val_loss: 1.0031 - val_accuracy: 0.6154\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7193 - accuracy: 0.7148 - val_loss: 1.0305 - val_accuracy: 0.5812\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8174 - accuracy: 0.7074 - val_loss: 1.0562 - val_accuracy: 0.6239\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7114 - accuracy: 0.7148 - val_loss: 1.0277 - val_accuracy: 0.5897\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7242 - accuracy: 0.7000 - val_loss: 1.0064 - val_accuracy: 0.6154\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7251 - accuracy: 0.7074 - val_loss: 1.0066 - val_accuracy: 0.6239\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7371 - accuracy: 0.7037 - val_loss: 1.0580 - val_accuracy: 0.5726\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7934 - accuracy: 0.6889 - val_loss: 1.2759 - val_accuracy: 0.5812\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9305 - accuracy: 0.6815 - val_loss: 0.9735 - val_accuracy: 0.6239\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7690 - accuracy: 0.7000 - val_loss: 1.1578 - val_accuracy: 0.5556\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7478 - accuracy: 0.7037 - val_loss: 1.0556 - val_accuracy: 0.5983\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8201 - accuracy: 0.6852 - val_loss: 1.4262 - val_accuracy: 0.5470\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8295 - accuracy: 0.6741 - val_loss: 1.2558 - val_accuracy: 0.5641\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 1.0936 - accuracy: 0.6593 - val_loss: 1.4855 - val_accuracy: 0.5470\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8500 - accuracy: 0.6704 - val_loss: 1.0016 - val_accuracy: 0.5897\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8294 - accuracy: 0.6778 - val_loss: 1.1049 - val_accuracy: 0.6068\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7611 - accuracy: 0.7000 - val_loss: 1.0263 - val_accuracy: 0.6154\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7367 - accuracy: 0.7000 - val_loss: 0.9950 - val_accuracy: 0.6154\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7146 - accuracy: 0.7111 - val_loss: 1.0385 - val_accuracy: 0.6068\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7231 - accuracy: 0.7111 - val_loss: 1.0178 - val_accuracy: 0.6239\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7279 - accuracy: 0.7037 - val_loss: 1.0190 - val_accuracy: 0.6239\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7227 - accuracy: 0.6963 - val_loss: 1.0173 - val_accuracy: 0.5983\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7270 - accuracy: 0.7000 - val_loss: 0.9795 - val_accuracy: 0.6410\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7099 - accuracy: 0.7111 - val_loss: 1.0190 - val_accuracy: 0.6239\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7182 - accuracy: 0.7000 - val_loss: 0.9866 - val_accuracy: 0.6239\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7375 - accuracy: 0.6963 - val_loss: 1.0002 - val_accuracy: 0.6068\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7202 - accuracy: 0.7111 - val_loss: 1.0032 - val_accuracy: 0.5983\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7108 - accuracy: 0.7074 - val_loss: 0.9770 - val_accuracy: 0.6325\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7198 - accuracy: 0.7148 - val_loss: 0.9785 - val_accuracy: 0.5983\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7232 - accuracy: 0.6926 - val_loss: 0.9898 - val_accuracy: 0.6410\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7098 - accuracy: 0.7185 - val_loss: 1.0104 - val_accuracy: 0.6239\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7347 - accuracy: 0.7037 - val_loss: 0.9883 - val_accuracy: 0.6239\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7198 - accuracy: 0.7000 - val_loss: 1.0815 - val_accuracy: 0.5812\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7866 - accuracy: 0.6926 - val_loss: 0.9818 - val_accuracy: 0.6068\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7778 - accuracy: 0.6852 - val_loss: 1.3034 - val_accuracy: 0.5385\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.1058 - accuracy: 0.6407 - val_loss: 1.1639 - val_accuracy: 0.5983\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8704 - accuracy: 0.6704 - val_loss: 1.5026 - val_accuracy: 0.5128\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.0479 - accuracy: 0.6556 - val_loss: 1.1783 - val_accuracy: 0.5385\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8364 - accuracy: 0.6630 - val_loss: 1.2318 - val_accuracy: 0.5812\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8167 - accuracy: 0.6889 - val_loss: 1.1093 - val_accuracy: 0.5726\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7809 - accuracy: 0.7185 - val_loss: 0.9835 - val_accuracy: 0.5983\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7200 - accuracy: 0.7074 - val_loss: 1.0273 - val_accuracy: 0.6154\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7395 - accuracy: 0.7037 - val_loss: 1.0778 - val_accuracy: 0.6154\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7863 - accuracy: 0.7000 - val_loss: 1.1510 - val_accuracy: 0.5897\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.0445 - accuracy: 0.6815 - val_loss: 1.3647 - val_accuracy: 0.6410\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9150 - accuracy: 0.7037 - val_loss: 1.0413 - val_accuracy: 0.5726\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7721 - accuracy: 0.7074 - val_loss: 1.0266 - val_accuracy: 0.6068\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7191 - accuracy: 0.7074 - val_loss: 0.9852 - val_accuracy: 0.6239\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7210 - accuracy: 0.7037 - val_loss: 1.0026 - val_accuracy: 0.6410\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7094 - accuracy: 0.7148 - val_loss: 0.9978 - val_accuracy: 0.6239\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7096 - accuracy: 0.7148 - val_loss: 0.9873 - val_accuracy: 0.5983\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7062 - accuracy: 0.7185 - val_loss: 0.9822 - val_accuracy: 0.6154\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7071 - accuracy: 0.7222 - val_loss: 1.0019 - val_accuracy: 0.6154\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7081 - accuracy: 0.7148 - val_loss: 1.0182 - val_accuracy: 0.6154\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7089 - accuracy: 0.7148 - val_loss: 0.9916 - val_accuracy: 0.5897\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7113 - accuracy: 0.7148 - val_loss: 1.0161 - val_accuracy: 0.6068\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7177 - accuracy: 0.7037 - val_loss: 0.9903 - val_accuracy: 0.5983\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7071 - accuracy: 0.7185 - val_loss: 0.9793 - val_accuracy: 0.6239\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7131 - accuracy: 0.7148 - val_loss: 1.0022 - val_accuracy: 0.6325\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7156 - accuracy: 0.7037 - val_loss: 1.0090 - val_accuracy: 0.5897\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7205 - accuracy: 0.6926 - val_loss: 0.9948 - val_accuracy: 0.6154\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7082 - accuracy: 0.7222 - val_loss: 0.9718 - val_accuracy: 0.6154\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7219 - accuracy: 0.7111 - val_loss: 1.0135 - val_accuracy: 0.5726\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7275 - accuracy: 0.6926 - val_loss: 0.9789 - val_accuracy: 0.6154\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7050 - accuracy: 0.7259 - val_loss: 0.9983 - val_accuracy: 0.6239\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7042 - accuracy: 0.7185 - val_loss: 0.9773 - val_accuracy: 0.6239\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7042 - accuracy: 0.7148 - val_loss: 0.9729 - val_accuracy: 0.6068\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7130 - accuracy: 0.6963 - val_loss: 1.0135 - val_accuracy: 0.5897\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7275 - accuracy: 0.6963 - val_loss: 1.0419 - val_accuracy: 0.5897\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7692 - accuracy: 0.6778 - val_loss: 1.1483 - val_accuracy: 0.5556\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7239 - accuracy: 0.7111 - val_loss: 1.0014 - val_accuracy: 0.5983\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7345 - accuracy: 0.6963 - val_loss: 1.0530 - val_accuracy: 0.6068\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7006 - accuracy: 0.7259 - val_loss: 0.9724 - val_accuracy: 0.6410\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7089 - accuracy: 0.7037 - val_loss: 1.0710 - val_accuracy: 0.5812\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7299 - accuracy: 0.6963 - val_loss: 1.0645 - val_accuracy: 0.6068\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7230 - accuracy: 0.7037 - val_loss: 0.9819 - val_accuracy: 0.6325\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7164 - accuracy: 0.7074 - val_loss: 1.0026 - val_accuracy: 0.6325\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7108 - accuracy: 0.7074 - val_loss: 1.0104 - val_accuracy: 0.6154\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7625 - accuracy: 0.6889 - val_loss: 1.0265 - val_accuracy: 0.6154\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7206 - accuracy: 0.7111 - val_loss: 1.0248 - val_accuracy: 0.6239\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7148 - accuracy: 0.7111 - val_loss: 0.9844 - val_accuracy: 0.6154\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7013 - accuracy: 0.7222 - val_loss: 0.9947 - val_accuracy: 0.6239\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6990 - accuracy: 0.7296 - val_loss: 0.9936 - val_accuracy: 0.6068\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7015 - accuracy: 0.7296 - val_loss: 0.9871 - val_accuracy: 0.5983\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7002 - accuracy: 0.7259 - val_loss: 0.9935 - val_accuracy: 0.6154\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7071 - accuracy: 0.7222 - val_loss: 1.1198 - val_accuracy: 0.5726\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7637 - accuracy: 0.6889 - val_loss: 1.1800 - val_accuracy: 0.5470\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7407 - accuracy: 0.7037 - val_loss: 1.0395 - val_accuracy: 0.6239\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7654 - accuracy: 0.6926 - val_loss: 1.3586 - val_accuracy: 0.5641\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9959 - accuracy: 0.6667 - val_loss: 1.0793 - val_accuracy: 0.5897\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9393 - accuracy: 0.6704 - val_loss: 1.4257 - val_accuracy: 0.5385\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8074 - accuracy: 0.6815 - val_loss: 1.1863 - val_accuracy: 0.5726\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8115 - accuracy: 0.6852 - val_loss: 1.4106 - val_accuracy: 0.5299\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8156 - accuracy: 0.6741 - val_loss: 1.1674 - val_accuracy: 0.5897\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8193 - accuracy: 0.6963 - val_loss: 1.1195 - val_accuracy: 0.6239\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7475 - accuracy: 0.6963 - val_loss: 1.0194 - val_accuracy: 0.5812\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7429 - accuracy: 0.6963 - val_loss: 1.0497 - val_accuracy: 0.6154\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7892 - accuracy: 0.7111 - val_loss: 1.2786 - val_accuracy: 0.6410\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9152 - accuracy: 0.6815 - val_loss: 1.6137 - val_accuracy: 0.5214\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.2787 - accuracy: 0.6407 - val_loss: 2.0084 - val_accuracy: 0.4530\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9808 - accuracy: 0.6407 - val_loss: 1.4282 - val_accuracy: 0.5385\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8749 - accuracy: 0.6593 - val_loss: 1.2259 - val_accuracy: 0.5214\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8423 - accuracy: 0.6630 - val_loss: 1.0716 - val_accuracy: 0.6068\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7520 - accuracy: 0.6889 - val_loss: 1.0828 - val_accuracy: 0.5897\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8028 - accuracy: 0.6704 - val_loss: 1.1319 - val_accuracy: 0.5556\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7558 - accuracy: 0.7037 - val_loss: 1.0127 - val_accuracy: 0.6068\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7508 - accuracy: 0.7074 - val_loss: 1.0704 - val_accuracy: 0.6068\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7209 - accuracy: 0.7037 - val_loss: 1.0170 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7260 - accuracy: 0.7074 - val_loss: 0.9949 - val_accuracy: 0.6154\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7118 - accuracy: 0.7111 - val_loss: 1.0289 - val_accuracy: 0.5812\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7055 - accuracy: 0.7148 - val_loss: 0.9978 - val_accuracy: 0.6154\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7021 - accuracy: 0.7037 - val_loss: 1.0036 - val_accuracy: 0.6154\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7103 - accuracy: 0.7148 - val_loss: 1.0449 - val_accuracy: 0.5897\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7106 - accuracy: 0.7000 - val_loss: 0.9839 - val_accuracy: 0.6239\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7421 - accuracy: 0.7000 - val_loss: 1.2045 - val_accuracy: 0.6325\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8084 - accuracy: 0.7037 - val_loss: 1.1400 - val_accuracy: 0.5726\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7908 - accuracy: 0.7111 - val_loss: 1.1871 - val_accuracy: 0.6410\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7623 - accuracy: 0.7037 - val_loss: 1.1542 - val_accuracy: 0.5726\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8383 - accuracy: 0.6889 - val_loss: 1.3838 - val_accuracy: 0.6154\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9539 - accuracy: 0.6963 - val_loss: 1.0591 - val_accuracy: 0.5726\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8977 - accuracy: 0.7074 - val_loss: 1.6975 - val_accuracy: 0.5470\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.1325 - accuracy: 0.6519 - val_loss: 1.1442 - val_accuracy: 0.5897\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8309 - accuracy: 0.6370 - val_loss: 1.3047 - val_accuracy: 0.5299\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8160 - accuracy: 0.6519 - val_loss: 1.0362 - val_accuracy: 0.6325\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8064 - accuracy: 0.6963 - val_loss: 1.0500 - val_accuracy: 0.6325\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7379 - accuracy: 0.6963 - val_loss: 1.0482 - val_accuracy: 0.5726\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7350 - accuracy: 0.7111 - val_loss: 1.0434 - val_accuracy: 0.6154\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7147 - accuracy: 0.7222 - val_loss: 0.9879 - val_accuracy: 0.6410\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6988 - accuracy: 0.7222 - val_loss: 0.9851 - val_accuracy: 0.6239\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7009 - accuracy: 0.7185 - val_loss: 1.0208 - val_accuracy: 0.6154\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7065 - accuracy: 0.7111 - val_loss: 1.0238 - val_accuracy: 0.6068\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7211 - accuracy: 0.7148 - val_loss: 1.0757 - val_accuracy: 0.5897\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7483 - accuracy: 0.6963 - val_loss: 1.0035 - val_accuracy: 0.6239\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7857 - accuracy: 0.6963 - val_loss: 1.3040 - val_accuracy: 0.5556\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8042 - accuracy: 0.6963 - val_loss: 1.0835 - val_accuracy: 0.5726\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8144 - accuracy: 0.6889 - val_loss: 1.1516 - val_accuracy: 0.6239\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7223 - accuracy: 0.7037 - val_loss: 1.0360 - val_accuracy: 0.6325\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6990 - accuracy: 0.7259 - val_loss: 0.9998 - val_accuracy: 0.6239\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6980 - accuracy: 0.7296 - val_loss: 1.0414 - val_accuracy: 0.5812\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7119 - accuracy: 0.7148 - val_loss: 1.0002 - val_accuracy: 0.6239\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7006 - accuracy: 0.7148 - val_loss: 1.0126 - val_accuracy: 0.5983\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7083 - accuracy: 0.7185 - val_loss: 1.0487 - val_accuracy: 0.5897\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7345 - accuracy: 0.7074 - val_loss: 1.0004 - val_accuracy: 0.6410\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7414 - accuracy: 0.6889 - val_loss: 1.2933 - val_accuracy: 0.5726\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8581 - accuracy: 0.6852 - val_loss: 1.0340 - val_accuracy: 0.5812\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9004 - accuracy: 0.6926 - val_loss: 1.1602 - val_accuracy: 0.6325\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 1.0830 - accuracy: 0.7000 - val_loss: 1.3314 - val_accuracy: 0.6239\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 402us/step - loss: 0.8547 - accuracy: 0.6852 - val_loss: 1.4070 - val_accuracy: 0.5043\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9211 - accuracy: 0.6630 - val_loss: 1.1553 - val_accuracy: 0.6068\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7531 - accuracy: 0.6963 - val_loss: 1.0697 - val_accuracy: 0.6154\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7399 - accuracy: 0.7000 - val_loss: 1.1978 - val_accuracy: 0.5299\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7411 - accuracy: 0.7074 - val_loss: 1.0154 - val_accuracy: 0.6068\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7728 - accuracy: 0.7037 - val_loss: 1.2012 - val_accuracy: 0.6325\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.9131 - accuracy: 0.7111 - val_loss: 1.0192 - val_accuracy: 0.6239\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6996 - accuracy: 0.7259 - val_loss: 1.0319 - val_accuracy: 0.5897\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7112 - accuracy: 0.7222 - val_loss: 1.0184 - val_accuracy: 0.6325\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.7120 - accuracy: 0.7111 - val_loss: 1.0437 - val_accuracy: 0.6325\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 424us/step - loss: 0.7108 - accuracy: 0.7222 - val_loss: 1.0695 - val_accuracy: 0.6154\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 1.2151 - accuracy: 0.6741 - val_loss: 1.4046 - val_accuracy: 0.6239\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8885 - accuracy: 0.6815 - val_loss: 1.3541 - val_accuracy: 0.5299\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9986 - accuracy: 0.6370 - val_loss: 1.3820 - val_accuracy: 0.4957\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7984 - accuracy: 0.6778 - val_loss: 1.2276 - val_accuracy: 0.5897\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8144 - accuracy: 0.6889 - val_loss: 1.4384 - val_accuracy: 0.4872\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8496 - accuracy: 0.6815 - val_loss: 1.3516 - val_accuracy: 0.6410\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8180 - accuracy: 0.7037 - val_loss: 1.1753 - val_accuracy: 0.5897\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.1385 - accuracy: 0.6815 - val_loss: 1.7188 - val_accuracy: 0.5641\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0367 - accuracy: 0.6889 - val_loss: 1.1367 - val_accuracy: 0.5726\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9842 - accuracy: 0.6741 - val_loss: 1.8822 - val_accuracy: 0.5214\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.2345 - accuracy: 0.6148 - val_loss: 1.4477 - val_accuracy: 0.4957\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7721 - accuracy: 0.6444 - val_loss: 1.2737 - val_accuracy: 0.5556\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7575 - accuracy: 0.6630 - val_loss: 1.1800 - val_accuracy: 0.5470\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7576 - accuracy: 0.6926 - val_loss: 1.1010 - val_accuracy: 0.5641\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7313 - accuracy: 0.7111 - val_loss: 1.0361 - val_accuracy: 0.6325\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7426 - accuracy: 0.7111 - val_loss: 1.1428 - val_accuracy: 0.6325\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8066 - accuracy: 0.6889 - val_loss: 1.1112 - val_accuracy: 0.6154\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9613 - accuracy: 0.6926 - val_loss: 1.1920 - val_accuracy: 0.6154\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8982 - accuracy: 0.6963 - val_loss: 1.1325 - val_accuracy: 0.5726\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7841 - accuracy: 0.6815 - val_loss: 1.2030 - val_accuracy: 0.5812\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7877 - accuracy: 0.6889 - val_loss: 1.0499 - val_accuracy: 0.6239\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7622 - accuracy: 0.7000 - val_loss: 1.0322 - val_accuracy: 0.5983\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7299 - accuracy: 0.7222 - val_loss: 1.0409 - val_accuracy: 0.6239\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7973 - accuracy: 0.7037 - val_loss: 1.0023 - val_accuracy: 0.6239\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9043 - accuracy: 0.7074 - val_loss: 1.2195 - val_accuracy: 0.6154\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8510 - accuracy: 0.7000 - val_loss: 1.0326 - val_accuracy: 0.5812\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8352 - accuracy: 0.6926 - val_loss: 1.0499 - val_accuracy: 0.6154\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7792 - accuracy: 0.7000 - val_loss: 1.0863 - val_accuracy: 0.6154\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7852 - accuracy: 0.6926 - val_loss: 1.0633 - val_accuracy: 0.6068\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7979 - accuracy: 0.6889 - val_loss: 1.0882 - val_accuracy: 0.6154\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8399 - accuracy: 0.7037 - val_loss: 1.0049 - val_accuracy: 0.6239\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7190 - accuracy: 0.7148 - val_loss: 1.0620 - val_accuracy: 0.6239\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7305 - accuracy: 0.7111 - val_loss: 1.0237 - val_accuracy: 0.6239\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6997 - accuracy: 0.7148 - val_loss: 1.0236 - val_accuracy: 0.5897\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7024 - accuracy: 0.7185 - val_loss: 1.0014 - val_accuracy: 0.6239\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6976 - accuracy: 0.7000 - val_loss: 1.0151 - val_accuracy: 0.6325\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7121 - accuracy: 0.7111 - val_loss: 1.0840 - val_accuracy: 0.5897\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7854 - accuracy: 0.6667 - val_loss: 1.2036 - val_accuracy: 0.5812\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7590 - accuracy: 0.7000 - val_loss: 1.0703 - val_accuracy: 0.5983\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7093 - accuracy: 0.7185 - val_loss: 1.1194 - val_accuracy: 0.6154\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7865 - accuracy: 0.6926 - val_loss: 1.0212 - val_accuracy: 0.6068\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7523 - accuracy: 0.7148 - val_loss: 1.0220 - val_accuracy: 0.6068\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7273 - accuracy: 0.7074 - val_loss: 1.0227 - val_accuracy: 0.6239\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7094 - accuracy: 0.7037 - val_loss: 1.1407 - val_accuracy: 0.5726\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8248 - accuracy: 0.6926 - val_loss: 1.3153 - val_accuracy: 0.6410\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9479 - accuracy: 0.6926 - val_loss: 1.1180 - val_accuracy: 0.5726\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.1138 - accuracy: 0.6296 - val_loss: 1.9656 - val_accuracy: 0.4872\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.0492 - accuracy: 0.6148 - val_loss: 1.1725 - val_accuracy: 0.6068\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8205 - accuracy: 0.6926 - val_loss: 1.0508 - val_accuracy: 0.6325\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7099 - accuracy: 0.7148 - val_loss: 1.0839 - val_accuracy: 0.5983\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7285 - accuracy: 0.7111 - val_loss: 1.0577 - val_accuracy: 0.6154\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7402 - accuracy: 0.7074 - val_loss: 1.0359 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7298 - accuracy: 0.7111 - val_loss: 1.1536 - val_accuracy: 0.5470\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7321 - accuracy: 0.7185 - val_loss: 1.1421 - val_accuracy: 0.6239\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7873 - accuracy: 0.7111 - val_loss: 1.1346 - val_accuracy: 0.5726\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7217 - accuracy: 0.7296 - val_loss: 1.0802 - val_accuracy: 0.6325\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7263 - accuracy: 0.7259 - val_loss: 1.0296 - val_accuracy: 0.5983\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7146 - accuracy: 0.7185 - val_loss: 1.0277 - val_accuracy: 0.6154\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6938 - accuracy: 0.7185 - val_loss: 1.0222 - val_accuracy: 0.6068\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6891 - accuracy: 0.7222 - val_loss: 0.9957 - val_accuracy: 0.6068\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6898 - accuracy: 0.7185 - val_loss: 1.0170 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6894 - accuracy: 0.7296 - val_loss: 0.9868 - val_accuracy: 0.6410\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6965 - accuracy: 0.7259 - val_loss: 1.0094 - val_accuracy: 0.6068\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7024 - accuracy: 0.7148 - val_loss: 1.0566 - val_accuracy: 0.6154\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7003 - accuracy: 0.7074 - val_loss: 0.9955 - val_accuracy: 0.6068\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6898 - accuracy: 0.7148 - val_loss: 0.9903 - val_accuracy: 0.6325\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7453 - accuracy: 0.7185 - val_loss: 1.6294 - val_accuracy: 0.5812\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.1458 - accuracy: 0.6815 - val_loss: 1.1717 - val_accuracy: 0.6239\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8772 - accuracy: 0.6630 - val_loss: 1.2204 - val_accuracy: 0.5299\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8675 - accuracy: 0.6778 - val_loss: 1.0835 - val_accuracy: 0.6068\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.7834 - accuracy: 0.7037 - val_loss: 1.2111 - val_accuracy: 0.5812\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8917 - accuracy: 0.6852 - val_loss: 1.0848 - val_accuracy: 0.5897\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.7426 - accuracy: 0.7037 - val_loss: 1.0656 - val_accuracy: 0.6325\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7669 - accuracy: 0.7037 - val_loss: 1.0134 - val_accuracy: 0.6154\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7620 - accuracy: 0.7111 - val_loss: 1.0743 - val_accuracy: 0.5983\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7626 - accuracy: 0.7037 - val_loss: 1.0991 - val_accuracy: 0.5726\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7848 - accuracy: 0.6926 - val_loss: 1.1256 - val_accuracy: 0.6325\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7991 - accuracy: 0.6889 - val_loss: 1.0177 - val_accuracy: 0.5983\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.7877 - accuracy: 0.7037 - val_loss: 1.1121 - val_accuracy: 0.6154\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7980 - accuracy: 0.7074 - val_loss: 1.1258 - val_accuracy: 0.5726\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7237 - accuracy: 0.7148 - val_loss: 1.3377 - val_accuracy: 0.6496\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8453 - accuracy: 0.7074 - val_loss: 1.0585 - val_accuracy: 0.5726\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7447 - accuracy: 0.7111 - val_loss: 1.1422 - val_accuracy: 0.6154\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7474 - accuracy: 0.7111 - val_loss: 1.0446 - val_accuracy: 0.5897\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7963 - accuracy: 0.7074 - val_loss: 1.0083 - val_accuracy: 0.6239\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7791 - accuracy: 0.7185 - val_loss: 1.0406 - val_accuracy: 0.6154\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7186 - accuracy: 0.7222 - val_loss: 1.0223 - val_accuracy: 0.6154\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7022 - accuracy: 0.7222 - val_loss: 1.0287 - val_accuracy: 0.5983\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6954 - accuracy: 0.7074 - val_loss: 1.0009 - val_accuracy: 0.6325\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6844 - accuracy: 0.7296 - val_loss: 0.9946 - val_accuracy: 0.6068\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6857 - accuracy: 0.7296 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6921 - accuracy: 0.7222 - val_loss: 1.0319 - val_accuracy: 0.6325\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6880 - accuracy: 0.7222 - val_loss: 0.9926 - val_accuracy: 0.6239\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6854 - accuracy: 0.7222 - val_loss: 1.0195 - val_accuracy: 0.6154\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6925 - accuracy: 0.7148 - val_loss: 0.9984 - val_accuracy: 0.6154\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6874 - accuracy: 0.7259 - val_loss: 1.0079 - val_accuracy: 0.6239\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6846 - accuracy: 0.7111 - val_loss: 1.0155 - val_accuracy: 0.5897\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6859 - accuracy: 0.7333 - val_loss: 0.9893 - val_accuracy: 0.6068\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6860 - accuracy: 0.7222 - val_loss: 1.0371 - val_accuracy: 0.6068\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6893 - accuracy: 0.7148 - val_loss: 1.0181 - val_accuracy: 0.6154\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6872 - accuracy: 0.7222 - val_loss: 1.0148 - val_accuracy: 0.6410\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6835 - accuracy: 0.7222 - val_loss: 1.0428 - val_accuracy: 0.6154\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6889 - accuracy: 0.7148 - val_loss: 0.9861 - val_accuracy: 0.6410\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7196 - accuracy: 0.7000 - val_loss: 1.0729 - val_accuracy: 0.5812\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.8174 - accuracy: 0.6741 - val_loss: 1.6519 - val_accuracy: 0.5470\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9427 - accuracy: 0.6815 - val_loss: 1.2318 - val_accuracy: 0.5812\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9270 - accuracy: 0.6889 - val_loss: 1.2211 - val_accuracy: 0.5897\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8952 - accuracy: 0.7074 - val_loss: 1.0264 - val_accuracy: 0.6410\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7692 - accuracy: 0.6815 - val_loss: 1.7064 - val_accuracy: 0.5128\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.1802 - accuracy: 0.6296 - val_loss: 1.4576 - val_accuracy: 0.4957\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7837 - accuracy: 0.6630 - val_loss: 1.0613 - val_accuracy: 0.5641\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8050 - accuracy: 0.6889 - val_loss: 1.4089 - val_accuracy: 0.5385\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8316 - accuracy: 0.6926 - val_loss: 1.2297 - val_accuracy: 0.5726\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8567 - accuracy: 0.7037 - val_loss: 1.2976 - val_accuracy: 0.5983\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8823 - accuracy: 0.6852 - val_loss: 1.4128 - val_accuracy: 0.5641\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8415 - accuracy: 0.7111 - val_loss: 1.1551 - val_accuracy: 0.6239\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8392 - accuracy: 0.6963 - val_loss: 1.1239 - val_accuracy: 0.5726\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9670 - accuracy: 0.6778 - val_loss: 1.1283 - val_accuracy: 0.5726\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7752 - accuracy: 0.6963 - val_loss: 1.1357 - val_accuracy: 0.5983\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8374 - accuracy: 0.6963 - val_loss: 1.1104 - val_accuracy: 0.5897\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7597 - accuracy: 0.7037 - val_loss: 1.0888 - val_accuracy: 0.6239\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7846 - accuracy: 0.7000 - val_loss: 1.1365 - val_accuracy: 0.5726\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 248us/step - loss: 0.9382 - accuracy: 0.6778 - val_loss: 1.4946 - val_accuracy: 0.5983\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.9468 - accuracy: 0.6963 - val_loss: 1.0963 - val_accuracy: 0.5897\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.7405 - accuracy: 0.7222 - val_loss: 1.1263 - val_accuracy: 0.6239\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 404us/step - loss: 0.7471 - accuracy: 0.7185 - val_loss: 1.0887 - val_accuracy: 0.5726\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7148 - accuracy: 0.7074 - val_loss: 1.0255 - val_accuracy: 0.6325\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7390 - accuracy: 0.7148 - val_loss: 1.0314 - val_accuracy: 0.6154\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6894 - accuracy: 0.7185 - val_loss: 1.0256 - val_accuracy: 0.5983\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6826 - accuracy: 0.7370 - val_loss: 1.0189 - val_accuracy: 0.6325\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6911 - accuracy: 0.7222 - val_loss: 1.0365 - val_accuracy: 0.6325\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6836 - accuracy: 0.7259 - val_loss: 1.0119 - val_accuracy: 0.6410\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 394us/step - loss: 0.6847 - accuracy: 0.7222 - val_loss: 1.0094 - val_accuracy: 0.6068\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.6823 - accuracy: 0.7259 - val_loss: 1.0098 - val_accuracy: 0.6410\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 445us/step - loss: 0.6840 - accuracy: 0.7296 - val_loss: 0.9910 - val_accuracy: 0.5983\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 861us/step - loss: 0.6923 - accuracy: 0.7259 - val_loss: 1.0240 - val_accuracy: 0.6154\n",
      "Epoch 852/1000\n",
      "128/270 [=============>................] - ETA: 0s - loss: 0.7153 - accuracy: 0.6953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.102664). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 405us/step - loss: 0.6935 - accuracy: 0.7148 - val_loss: 1.1076 - val_accuracy: 0.6325\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 314us/step - loss: 0.7166 - accuracy: 0.7000 - val_loss: 1.0725 - val_accuracy: 0.5897\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 422us/step - loss: 0.7224 - accuracy: 0.7074 - val_loss: 1.0355 - val_accuracy: 0.6154\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6978 - accuracy: 0.7185 - val_loss: 1.0245 - val_accuracy: 0.6154\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 316us/step - loss: 0.7188 - accuracy: 0.7037 - val_loss: 1.1583 - val_accuracy: 0.5897\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.7136 - accuracy: 0.7074 - val_loss: 1.0438 - val_accuracy: 0.6239\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6932 - accuracy: 0.7222 - val_loss: 1.0673 - val_accuracy: 0.5812\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.7386 - accuracy: 0.6963 - val_loss: 1.1414 - val_accuracy: 0.5641\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7049 - accuracy: 0.7111 - val_loss: 1.0178 - val_accuracy: 0.6410\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.7031 - accuracy: 0.7000 - val_loss: 1.0098 - val_accuracy: 0.6410\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6868 - accuracy: 0.7296 - val_loss: 1.0302 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6947 - accuracy: 0.7148 - val_loss: 1.0158 - val_accuracy: 0.6325\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7046 - accuracy: 0.7259 - val_loss: 1.0184 - val_accuracy: 0.6239\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6954 - accuracy: 0.7222 - val_loss: 1.1059 - val_accuracy: 0.5812\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7167 - accuracy: 0.7074 - val_loss: 1.0260 - val_accuracy: 0.6239\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6861 - accuracy: 0.7259 - val_loss: 0.9935 - val_accuracy: 0.6410\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.6802 - accuracy: 0.7333 - val_loss: 1.0318 - val_accuracy: 0.6154\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6784 - accuracy: 0.7111 - val_loss: 0.9929 - val_accuracy: 0.6239\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 419us/step - loss: 0.7041 - accuracy: 0.7037 - val_loss: 1.1435 - val_accuracy: 0.5641\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 291us/step - loss: 0.8032 - accuracy: 0.6778 - val_loss: 1.1944 - val_accuracy: 0.5897\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7799 - accuracy: 0.7074 - val_loss: 1.1549 - val_accuracy: 0.5897\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8709 - accuracy: 0.6704 - val_loss: 1.2006 - val_accuracy: 0.5641\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 322us/step - loss: 0.7436 - accuracy: 0.6926 - val_loss: 1.0749 - val_accuracy: 0.5812\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7103 - accuracy: 0.7074 - val_loss: 1.0101 - val_accuracy: 0.6068\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7170 - accuracy: 0.7074 - val_loss: 1.0291 - val_accuracy: 0.6154\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6957 - accuracy: 0.7185 - val_loss: 1.0097 - val_accuracy: 0.6154\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6944 - accuracy: 0.7148 - val_loss: 1.0447 - val_accuracy: 0.5983\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.7162 - accuracy: 0.7074 - val_loss: 1.2534 - val_accuracy: 0.5812\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8176 - accuracy: 0.6667 - val_loss: 1.3452 - val_accuracy: 0.5299\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0232 - accuracy: 0.6926 - val_loss: 1.3192 - val_accuracy: 0.5812\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 1.4585 - accuracy: 0.6519 - val_loss: 2.1038 - val_accuracy: 0.5385\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0350 - accuracy: 0.6519 - val_loss: 1.4327 - val_accuracy: 0.5470\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8981 - accuracy: 0.6778 - val_loss: 1.3657 - val_accuracy: 0.6068\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.8789 - accuracy: 0.7000 - val_loss: 1.0838 - val_accuracy: 0.5641\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8071 - accuracy: 0.6963 - val_loss: 1.0308 - val_accuracy: 0.6154\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7672 - accuracy: 0.7111 - val_loss: 1.0322 - val_accuracy: 0.5983\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.7344 - accuracy: 0.7111 - val_loss: 1.1049 - val_accuracy: 0.6239\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8654 - accuracy: 0.7111 - val_loss: 1.0204 - val_accuracy: 0.5983\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7620 - accuracy: 0.7037 - val_loss: 1.0474 - val_accuracy: 0.6239\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6995 - accuracy: 0.7185 - val_loss: 1.0453 - val_accuracy: 0.5897\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.7242 - accuracy: 0.6963 - val_loss: 1.0196 - val_accuracy: 0.5983\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8047 - accuracy: 0.7148 - val_loss: 1.0128 - val_accuracy: 0.5983\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7434 - accuracy: 0.7185 - val_loss: 1.0701 - val_accuracy: 0.6239\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.7308 - accuracy: 0.7148 - val_loss: 1.0792 - val_accuracy: 0.5983\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 309us/step - loss: 0.7426 - accuracy: 0.7000 - val_loss: 1.4238 - val_accuracy: 0.5043\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7835 - accuracy: 0.6704 - val_loss: 1.1295 - val_accuracy: 0.5726\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7871 - accuracy: 0.6926 - val_loss: 1.0971 - val_accuracy: 0.6068\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7439 - accuracy: 0.7037 - val_loss: 1.3192 - val_accuracy: 0.5556\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7653 - accuracy: 0.7074 - val_loss: 1.0543 - val_accuracy: 0.6239\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 407us/step - loss: 0.7217 - accuracy: 0.7148 - val_loss: 1.2309 - val_accuracy: 0.5470\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7639 - accuracy: 0.6889 - val_loss: 1.0841 - val_accuracy: 0.5983\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6974 - accuracy: 0.7222 - val_loss: 0.9974 - val_accuracy: 0.6410\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7044 - accuracy: 0.7185 - val_loss: 1.0750 - val_accuracy: 0.5983\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7613 - accuracy: 0.7037 - val_loss: 1.2003 - val_accuracy: 0.6325\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.7695 - accuracy: 0.6963 - val_loss: 1.1697 - val_accuracy: 0.5726\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 333us/step - loss: 0.7342 - accuracy: 0.7259 - val_loss: 1.1931 - val_accuracy: 0.6154\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 332us/step - loss: 0.7259 - accuracy: 0.7296 - val_loss: 1.0675 - val_accuracy: 0.5812\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8036 - accuracy: 0.6963 - val_loss: 1.2790 - val_accuracy: 0.5726\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8114 - accuracy: 0.7111 - val_loss: 1.1397 - val_accuracy: 0.5556\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6843 - accuracy: 0.7333 - val_loss: 1.0206 - val_accuracy: 0.6325\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6825 - accuracy: 0.7222 - val_loss: 1.0225 - val_accuracy: 0.6154\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6781 - accuracy: 0.7259 - val_loss: 1.0219 - val_accuracy: 0.6068\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.6773 - accuracy: 0.7296 - val_loss: 1.0320 - val_accuracy: 0.5983\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7039 - accuracy: 0.7222 - val_loss: 1.1325 - val_accuracy: 0.6154\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8980 - accuracy: 0.7074 - val_loss: 0.9968 - val_accuracy: 0.6239\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.4234 - accuracy: 0.6815 - val_loss: 1.0709 - val_accuracy: 0.5897\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9795 - accuracy: 0.7111 - val_loss: 1.3529 - val_accuracy: 0.6410\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7435 - accuracy: 0.7111 - val_loss: 1.0501 - val_accuracy: 0.5812\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.7580 - accuracy: 0.7222 - val_loss: 1.0669 - val_accuracy: 0.6154\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.7114 - accuracy: 0.7037 - val_loss: 1.0237 - val_accuracy: 0.6239\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6775 - accuracy: 0.7222 - val_loss: 1.0226 - val_accuracy: 0.6325\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6750 - accuracy: 0.7296 - val_loss: 0.9945 - val_accuracy: 0.6068\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6759 - accuracy: 0.7296 - val_loss: 1.0130 - val_accuracy: 0.6154\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6930 - accuracy: 0.7222 - val_loss: 1.0627 - val_accuracy: 0.5897\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.7141 - accuracy: 0.7000 - val_loss: 1.2602 - val_accuracy: 0.5470\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8531 - accuracy: 0.6926 - val_loss: 1.8305 - val_accuracy: 0.6068\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.2426 - accuracy: 0.6778 - val_loss: 1.2648 - val_accuracy: 0.6068\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0177 - accuracy: 0.6593 - val_loss: 2.3726 - val_accuracy: 0.5043\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.5362 - accuracy: 0.6111 - val_loss: 2.3811 - val_accuracy: 0.4957\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 1.1811 - accuracy: 0.6296 - val_loss: 1.1708 - val_accuracy: 0.5726\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7945 - accuracy: 0.6519 - val_loss: 1.0858 - val_accuracy: 0.6154\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7333 - accuracy: 0.7148 - val_loss: 1.2274 - val_accuracy: 0.5385\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 314us/step - loss: 0.7183 - accuracy: 0.7185 - val_loss: 1.0459 - val_accuracy: 0.6154\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6862 - accuracy: 0.7185 - val_loss: 1.0063 - val_accuracy: 0.6325\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 490us/step - loss: 0.6919 - accuracy: 0.7111 - val_loss: 1.0119 - val_accuracy: 0.6325\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6913 - accuracy: 0.7296 - val_loss: 1.0195 - val_accuracy: 0.6154\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6920 - accuracy: 0.7185 - val_loss: 1.0513 - val_accuracy: 0.6239\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6800 - accuracy: 0.7222 - val_loss: 1.0265 - val_accuracy: 0.6325\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7208 - accuracy: 0.7111 - val_loss: 1.0200 - val_accuracy: 0.6239\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6959 - accuracy: 0.7185 - val_loss: 1.0131 - val_accuracy: 0.6154\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6797 - accuracy: 0.7296 - val_loss: 1.0050 - val_accuracy: 0.6410\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6777 - accuracy: 0.7296 - val_loss: 1.0483 - val_accuracy: 0.6325\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6965 - accuracy: 0.7037 - val_loss: 1.0070 - val_accuracy: 0.6239\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6886 - accuracy: 0.7222 - val_loss: 1.0167 - val_accuracy: 0.6068\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6970 - accuracy: 0.7185 - val_loss: 0.9997 - val_accuracy: 0.6325\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6801 - accuracy: 0.7333 - val_loss: 1.0099 - val_accuracy: 0.6154\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.6774 - accuracy: 0.7370 - val_loss: 0.9815 - val_accuracy: 0.6239\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.6761 - accuracy: 0.7333 - val_loss: 1.0322 - val_accuracy: 0.6239\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6826 - accuracy: 0.7185 - val_loss: 1.0125 - val_accuracy: 0.6325\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6761 - accuracy: 0.7259 - val_loss: 1.0198 - val_accuracy: 0.6154\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6807 - accuracy: 0.7185 - val_loss: 1.0256 - val_accuracy: 0.6239\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6779 - accuracy: 0.7222 - val_loss: 0.9841 - val_accuracy: 0.6068\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6732 - accuracy: 0.7333 - val_loss: 1.0134 - val_accuracy: 0.6154\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6914 - accuracy: 0.7185 - val_loss: 1.0374 - val_accuracy: 0.6239\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7340 - accuracy: 0.7185 - val_loss: 1.0803 - val_accuracy: 0.5983\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.6830 - accuracy: 0.7222 - val_loss: 1.0285 - val_accuracy: 0.6154\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.6883 - accuracy: 0.7148 - val_loss: 1.0455 - val_accuracy: 0.6068\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7020 - accuracy: 0.7222 - val_loss: 0.9739 - val_accuracy: 0.6239\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7152 - accuracy: 0.7000 - val_loss: 1.1188 - val_accuracy: 0.5556\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.7190 - accuracy: 0.7000 - val_loss: 1.0203 - val_accuracy: 0.6068\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 185us/step - loss: 0.6894 - accuracy: 0.7111 - val_loss: 0.9876 - val_accuracy: 0.6325\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6817 - accuracy: 0.7296 - val_loss: 1.0179 - val_accuracy: 0.6239\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6863 - accuracy: 0.7074 - val_loss: 1.0005 - val_accuracy: 0.6325\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6871 - accuracy: 0.7111 - val_loss: 1.0812 - val_accuracy: 0.5983\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6856 - accuracy: 0.7296 - val_loss: 1.0013 - val_accuracy: 0.6410\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6772 - accuracy: 0.7296 - val_loss: 1.0112 - val_accuracy: 0.6325\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6786 - accuracy: 0.7148 - val_loss: 1.0369 - val_accuracy: 0.6154\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6752 - accuracy: 0.7185 - val_loss: 1.0039 - val_accuracy: 0.6325\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6686 - accuracy: 0.7074 - val_loss: 1.0033 - val_accuracy: 0.6154\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6723 - accuracy: 0.7296 - val_loss: 1.0115 - val_accuracy: 0.5897\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6726 - accuracy: 0.7333 - val_loss: 1.0747 - val_accuracy: 0.6154\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6991 - accuracy: 0.7185 - val_loss: 1.0236 - val_accuracy: 0.6154\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7070 - accuracy: 0.7074 - val_loss: 1.0176 - val_accuracy: 0.6154\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6902 - accuracy: 0.7074 - val_loss: 1.0459 - val_accuracy: 0.6068\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7173 - accuracy: 0.7111 - val_loss: 1.0812 - val_accuracy: 0.5983\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6853 - accuracy: 0.7222 - val_loss: 1.1021 - val_accuracy: 0.6068\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7735 - accuracy: 0.7037 - val_loss: 1.0724 - val_accuracy: 0.6239\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6933 - accuracy: 0.7259 - val_loss: 1.0708 - val_accuracy: 0.6154\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7213 - accuracy: 0.7111 - val_loss: 1.0758 - val_accuracy: 0.6068\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6980 - accuracy: 0.7148 - val_loss: 1.0663 - val_accuracy: 0.6239\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6830 - accuracy: 0.7259 - val_loss: 1.0151 - val_accuracy: 0.6239\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6727 - accuracy: 0.7148 - val_loss: 1.0255 - val_accuracy: 0.6325\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 558us/step - loss: 0.6694 - accuracy: 0.7333 - val_loss: 1.0083 - val_accuracy: 0.6325\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6684 - accuracy: 0.7333 - val_loss: 1.0051 - val_accuracy: 0.6325\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6930 - accuracy: 0.7259 - val_loss: 1.0210 - val_accuracy: 0.6068\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6657 - accuracy: 0.7296 - val_loss: 1.0010 - val_accuracy: 0.5983\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.6723 - accuracy: 0.7333 - val_loss: 1.0082 - val_accuracy: 0.6154\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6773 - accuracy: 0.7296 - val_loss: 1.0400 - val_accuracy: 0.5983\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7056 - accuracy: 0.7148 - val_loss: 1.0508 - val_accuracy: 0.5983\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7321 - accuracy: 0.7185 - val_loss: 1.2325 - val_accuracy: 0.6325\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7929 - accuracy: 0.7259 - val_loss: 1.1929 - val_accuracy: 0.5812\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8925 - accuracy: 0.7037 - val_loss: 1.3708 - val_accuracy: 0.5385\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8961 - accuracy: 0.6815 - val_loss: 1.0764 - val_accuracy: 0.5812\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7463 - accuracy: 0.6926 - val_loss: 1.1233 - val_accuracy: 0.6068\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7373 - accuracy: 0.7037 - val_loss: 1.1012 - val_accuracy: 0.6068\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6929 - accuracy: 0.7222 - val_loss: 1.0351 - val_accuracy: 0.6154\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.7002 - accuracy: 0.7074 - val_loss: 1.0167 - val_accuracy: 0.6410\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 308us/step - loss: 0.6976 - accuracy: 0.7037 - val_loss: 1.0226 - val_accuracy: 0.6239\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.6922 - accuracy: 0.7185 - val_loss: 1.0510 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d06feb8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 70us/step\n",
      "over-sampling test accuracy: 59.83%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 1, 0, 0, 1, 0, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 2, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1, 0, 2, 0, 0, 2, 2, 1, 1,\n",
       "       1, 0, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0,\n",
       "       1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 2, 0, 0, 2, 0, 2, 1, 1,\n",
       "       1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       2, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS245     1     2\n",
       "1          NY439     2     2\n",
       "2          CA544     1     1\n",
       "3          CA541     2     1\n",
       "4          EUH15     1     1\n",
       "..           ...   ...   ...\n",
       "112       NRS112     0     0\n",
       "113     CFBRSa51     2     1\n",
       "114       NRS383     1     0\n",
       "115       NRS247     0     1\n",
       "116  CFBREBSa103     0     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.156677</td>\n",
       "      <td>0.706534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.997449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297093</td>\n",
       "      <td>0.563622</td>\n",
       "      <td>0.139284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.297093</td>\n",
       "      <td>0.563622</td>\n",
       "      <td>0.139284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.297093</td>\n",
       "      <td>0.563622</td>\n",
       "      <td>0.139284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.701488</td>\n",
       "      <td>0.289887</td>\n",
       "      <td>0.008625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.297093</td>\n",
       "      <td>0.563622</td>\n",
       "      <td>0.139284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.942912</td>\n",
       "      <td>0.056282</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.408348</td>\n",
       "      <td>0.581091</td>\n",
       "      <td>0.010561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.047137</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.136788  0.156677  0.706534\n",
       "1    0.000259  0.002292  0.997449\n",
       "2    0.297093  0.563622  0.139284\n",
       "3    0.297093  0.563622  0.139284\n",
       "4    0.297093  0.563622  0.139284\n",
       "..        ...       ...       ...\n",
       "112  0.701488  0.289887  0.008625\n",
       "113  0.297093  0.563622  0.139284\n",
       "114  0.942912  0.056282  0.000806\n",
       "115  0.408348  0.581091  0.010561\n",
       "116  0.047137  0.952000  0.000863\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6863 - accuracy: 0.7074 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7281 - accuracy: 0.7000 - val_loss: 1.0597 - val_accuracy: 0.5556\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7126 - accuracy: 0.7000 - val_loss: 0.9970 - val_accuracy: 0.6325\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6874 - accuracy: 0.7074 - val_loss: 0.9825 - val_accuracy: 0.6154\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6885 - accuracy: 0.7148 - val_loss: 0.9594 - val_accuracy: 0.6239\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6817 - accuracy: 0.7222 - val_loss: 1.0169 - val_accuracy: 0.6239\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7101 - accuracy: 0.7222 - val_loss: 1.0066 - val_accuracy: 0.5726\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6826 - accuracy: 0.7185 - val_loss: 0.9975 - val_accuracy: 0.6154\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6934 - accuracy: 0.7111 - val_loss: 0.9719 - val_accuracy: 0.6154\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6801 - accuracy: 0.7185 - val_loss: 0.9782 - val_accuracy: 0.6154\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6940 - accuracy: 0.6852 - val_loss: 0.9890 - val_accuracy: 0.6325\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7005 - accuracy: 0.7185 - val_loss: 0.9582 - val_accuracy: 0.6154\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6882 - accuracy: 0.7185 - val_loss: 0.9851 - val_accuracy: 0.6239\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7147 - accuracy: 0.7111 - val_loss: 1.0639 - val_accuracy: 0.5641\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7165 - accuracy: 0.7148 - val_loss: 1.1194 - val_accuracy: 0.6410\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7277 - accuracy: 0.7296 - val_loss: 1.0306 - val_accuracy: 0.5641\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7415 - accuracy: 0.7000 - val_loss: 1.1663 - val_accuracy: 0.6410\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8603 - accuracy: 0.7074 - val_loss: 0.9632 - val_accuracy: 0.6154\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7165 - accuracy: 0.7037 - val_loss: 1.0407 - val_accuracy: 0.6068\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7580 - accuracy: 0.7185 - val_loss: 1.0044 - val_accuracy: 0.6239\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7187 - accuracy: 0.7037 - val_loss: 1.1720 - val_accuracy: 0.5726\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8704 - accuracy: 0.6926 - val_loss: 0.9860 - val_accuracy: 0.6154\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8782 - accuracy: 0.6667 - val_loss: 1.9389 - val_accuracy: 0.5043\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.1423 - accuracy: 0.6630 - val_loss: 1.4362 - val_accuracy: 0.5299\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7399 - accuracy: 0.6889 - val_loss: 1.4684 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8963 - accuracy: 0.6667 - val_loss: 1.6491 - val_accuracy: 0.5214\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.1324 - accuracy: 0.6370 - val_loss: 1.6067 - val_accuracy: 0.4872\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8128 - accuracy: 0.6889 - val_loss: 1.3143 - val_accuracy: 0.6581\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9141 - accuracy: 0.6889 - val_loss: 1.1093 - val_accuracy: 0.5983\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7477 - accuracy: 0.6852 - val_loss: 1.1283 - val_accuracy: 0.5470\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7487 - accuracy: 0.7000 - val_loss: 1.2011 - val_accuracy: 0.6239\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8524 - accuracy: 0.6963 - val_loss: 0.9779 - val_accuracy: 0.6239\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7550 - accuracy: 0.7074 - val_loss: 1.3080 - val_accuracy: 0.5556\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8816 - accuracy: 0.6481 - val_loss: 1.0562 - val_accuracy: 0.5897\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7573 - accuracy: 0.7185 - val_loss: 1.0193 - val_accuracy: 0.6068\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.7064 - accuracy: 0.7222 - val_loss: 1.0477 - val_accuracy: 0.5812\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7188 - accuracy: 0.7037 - val_loss: 0.9919 - val_accuracy: 0.5983\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7029 - accuracy: 0.7111 - val_loss: 1.0099 - val_accuracy: 0.6325\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6897 - accuracy: 0.7185 - val_loss: 0.9698 - val_accuracy: 0.5983\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6773 - accuracy: 0.7111 - val_loss: 0.9830 - val_accuracy: 0.5983\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6758 - accuracy: 0.7074 - val_loss: 0.9723 - val_accuracy: 0.6325\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6754 - accuracy: 0.7185 - val_loss: 0.9649 - val_accuracy: 0.6410\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6725 - accuracy: 0.7111 - val_loss: 0.9832 - val_accuracy: 0.6154\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6755 - accuracy: 0.7148 - val_loss: 0.9694 - val_accuracy: 0.6410\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6792 - accuracy: 0.7222 - val_loss: 0.9625 - val_accuracy: 0.6239\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6899 - accuracy: 0.7111 - val_loss: 0.9724 - val_accuracy: 0.6068\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6927 - accuracy: 0.7222 - val_loss: 0.9694 - val_accuracy: 0.6325\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6761 - accuracy: 0.7148 - val_loss: 0.9884 - val_accuracy: 0.6068\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6787 - accuracy: 0.7148 - val_loss: 0.9780 - val_accuracy: 0.6068\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6808 - accuracy: 0.7037 - val_loss: 0.9712 - val_accuracy: 0.6239\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6703 - accuracy: 0.7111 - val_loss: 1.0052 - val_accuracy: 0.6068\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6860 - accuracy: 0.7074 - val_loss: 1.0336 - val_accuracy: 0.5641\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7301 - accuracy: 0.6963 - val_loss: 0.9915 - val_accuracy: 0.6239\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8241 - accuracy: 0.7037 - val_loss: 1.0029 - val_accuracy: 0.6154\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8240 - accuracy: 0.6926 - val_loss: 1.1865 - val_accuracy: 0.6239\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.8140 - accuracy: 0.6926 - val_loss: 0.9785 - val_accuracy: 0.6325\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.8748 - accuracy: 0.6889 - val_loss: 1.2585 - val_accuracy: 0.6154\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.7644 - accuracy: 0.7000 - val_loss: 1.1058 - val_accuracy: 0.5641\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8518 - accuracy: 0.6963 - val_loss: 1.2126 - val_accuracy: 0.6325\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8333 - accuracy: 0.7074 - val_loss: 1.0666 - val_accuracy: 0.5641\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7755 - accuracy: 0.6778 - val_loss: 1.1170 - val_accuracy: 0.5726\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7437 - accuracy: 0.7074 - val_loss: 1.0298 - val_accuracy: 0.6154\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7343 - accuracy: 0.6963 - val_loss: 1.1319 - val_accuracy: 0.5385\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6868 - accuracy: 0.6963 - val_loss: 0.9841 - val_accuracy: 0.6239\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6850 - accuracy: 0.7259 - val_loss: 0.9995 - val_accuracy: 0.5983\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6773 - accuracy: 0.7185 - val_loss: 0.9828 - val_accuracy: 0.5897\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6818 - accuracy: 0.7185 - val_loss: 0.9639 - val_accuracy: 0.6154\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6995 - accuracy: 0.7074 - val_loss: 0.9719 - val_accuracy: 0.6068\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6859 - accuracy: 0.6963 - val_loss: 0.9791 - val_accuracy: 0.6325\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6917 - accuracy: 0.7148 - val_loss: 0.9960 - val_accuracy: 0.5726\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7631 - accuracy: 0.7185 - val_loss: 1.3137 - val_accuracy: 0.6325\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8707 - accuracy: 0.7074 - val_loss: 0.9738 - val_accuracy: 0.6154\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8208 - accuracy: 0.7037 - val_loss: 1.2053 - val_accuracy: 0.6410\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0679 - accuracy: 0.6926 - val_loss: 1.2814 - val_accuracy: 0.6325\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8841 - accuracy: 0.6963 - val_loss: 1.0019 - val_accuracy: 0.5556\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7036 - accuracy: 0.7037 - val_loss: 1.0408 - val_accuracy: 0.5897\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.7601 - accuracy: 0.7000 - val_loss: 1.0481 - val_accuracy: 0.6239\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8856 - accuracy: 0.7185 - val_loss: 1.1553 - val_accuracy: 0.6410\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7093 - accuracy: 0.7185 - val_loss: 0.9758 - val_accuracy: 0.5983\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7027 - accuracy: 0.7111 - val_loss: 0.9768 - val_accuracy: 0.5983\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6932 - accuracy: 0.6889 - val_loss: 1.1064 - val_accuracy: 0.6325\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.7947 - accuracy: 0.7111 - val_loss: 0.9764 - val_accuracy: 0.5897\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7059 - accuracy: 0.7185 - val_loss: 1.0048 - val_accuracy: 0.6154\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6930 - accuracy: 0.7000 - val_loss: 0.9988 - val_accuracy: 0.5812\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6838 - accuracy: 0.7000 - val_loss: 0.9724 - val_accuracy: 0.6410\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6780 - accuracy: 0.7333 - val_loss: 0.9892 - val_accuracy: 0.6068\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6757 - accuracy: 0.7000 - val_loss: 0.9676 - val_accuracy: 0.6239\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7152 - accuracy: 0.7000 - val_loss: 0.9823 - val_accuracy: 0.5726\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8341 - accuracy: 0.6963 - val_loss: 1.1546 - val_accuracy: 0.6410\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9210 - accuracy: 0.7148 - val_loss: 1.1574 - val_accuracy: 0.6410\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8181 - accuracy: 0.7037 - val_loss: 0.9840 - val_accuracy: 0.5897\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7390 - accuracy: 0.7037 - val_loss: 1.0275 - val_accuracy: 0.5983\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7000 - accuracy: 0.7111 - val_loss: 1.0001 - val_accuracy: 0.6154\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7117 - accuracy: 0.6926 - val_loss: 1.0021 - val_accuracy: 0.5641\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6964 - accuracy: 0.7185 - val_loss: 1.0472 - val_accuracy: 0.6154\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7279 - accuracy: 0.7148 - val_loss: 1.0198 - val_accuracy: 0.5641\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7918 - accuracy: 0.7111 - val_loss: 1.1615 - val_accuracy: 0.6410\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.7439 - accuracy: 0.7111 - val_loss: 0.9750 - val_accuracy: 0.5983\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.7455 - accuracy: 0.7259 - val_loss: 1.0357 - val_accuracy: 0.6154\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6847 - accuracy: 0.7259 - val_loss: 1.0172 - val_accuracy: 0.5812\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6837 - accuracy: 0.7037 - val_loss: 1.0051 - val_accuracy: 0.6154\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6836 - accuracy: 0.7148 - val_loss: 0.9973 - val_accuracy: 0.5726\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7095 - accuracy: 0.6889 - val_loss: 1.0335 - val_accuracy: 0.6154\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7172 - accuracy: 0.7037 - val_loss: 1.0356 - val_accuracy: 0.5641\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7256 - accuracy: 0.6889 - val_loss: 1.0207 - val_accuracy: 0.6239\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7094 - accuracy: 0.6963 - val_loss: 0.9808 - val_accuracy: 0.6154\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6950 - accuracy: 0.7074 - val_loss: 1.0512 - val_accuracy: 0.6325\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7527 - accuracy: 0.7037 - val_loss: 1.0388 - val_accuracy: 0.5812\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7359 - accuracy: 0.6889 - val_loss: 1.1088 - val_accuracy: 0.5726\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6984 - accuracy: 0.7111 - val_loss: 0.9864 - val_accuracy: 0.6154\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6765 - accuracy: 0.7222 - val_loss: 0.9864 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6896 - accuracy: 0.6852 - val_loss: 0.9858 - val_accuracy: 0.5897\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7144 - accuracy: 0.7074 - val_loss: 0.9685 - val_accuracy: 0.6410\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6793 - accuracy: 0.7222 - val_loss: 1.0809 - val_accuracy: 0.6154\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7227 - accuracy: 0.7000 - val_loss: 1.0976 - val_accuracy: 0.5641\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7246 - accuracy: 0.7037 - val_loss: 1.0062 - val_accuracy: 0.6154\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6758 - accuracy: 0.7074 - val_loss: 0.9779 - val_accuracy: 0.6239\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7212 - accuracy: 0.7111 - val_loss: 0.9860 - val_accuracy: 0.5983\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9144 - accuracy: 0.6963 - val_loss: 1.0997 - val_accuracy: 0.6239\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8301 - accuracy: 0.7111 - val_loss: 0.9722 - val_accuracy: 0.6239\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7352 - accuracy: 0.7037 - val_loss: 1.1354 - val_accuracy: 0.6325\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9502 - accuracy: 0.7000 - val_loss: 1.1832 - val_accuracy: 0.6325\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7881 - accuracy: 0.7074 - val_loss: 0.9779 - val_accuracy: 0.5897\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6761 - accuracy: 0.7111 - val_loss: 1.0088 - val_accuracy: 0.5983\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7247 - accuracy: 0.6963 - val_loss: 1.0735 - val_accuracy: 0.6325\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8653 - accuracy: 0.7074 - val_loss: 1.1082 - val_accuracy: 0.6410\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7366 - accuracy: 0.7259 - val_loss: 1.1185 - val_accuracy: 0.5641\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7316 - accuracy: 0.7185 - val_loss: 1.1195 - val_accuracy: 0.6410\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7545 - accuracy: 0.7148 - val_loss: 1.0955 - val_accuracy: 0.5983\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8008 - accuracy: 0.7000 - val_loss: 1.1901 - val_accuracy: 0.5556\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7378 - accuracy: 0.6926 - val_loss: 1.1610 - val_accuracy: 0.5983\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9260 - accuracy: 0.6963 - val_loss: 1.2701 - val_accuracy: 0.6410\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0227 - accuracy: 0.7000 - val_loss: 1.2565 - val_accuracy: 0.6410\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8327 - accuracy: 0.7111 - val_loss: 1.1809 - val_accuracy: 0.5641\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.9066 - accuracy: 0.7074 - val_loss: 1.2688 - val_accuracy: 0.6410\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8642 - accuracy: 0.7000 - val_loss: 1.0034 - val_accuracy: 0.6154\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6944 - accuracy: 0.7037 - val_loss: 1.0197 - val_accuracy: 0.5726\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6935 - accuracy: 0.7148 - val_loss: 0.9784 - val_accuracy: 0.6154\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6749 - accuracy: 0.7259 - val_loss: 1.0049 - val_accuracy: 0.6068\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6857 - accuracy: 0.7074 - val_loss: 0.9978 - val_accuracy: 0.5897\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6737 - accuracy: 0.7111 - val_loss: 0.9673 - val_accuracy: 0.6154\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6686 - accuracy: 0.7185 - val_loss: 0.9810 - val_accuracy: 0.5983\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6834 - accuracy: 0.7037 - val_loss: 0.9773 - val_accuracy: 0.6154\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6928 - accuracy: 0.6926 - val_loss: 0.9842 - val_accuracy: 0.6154\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6753 - accuracy: 0.7148 - val_loss: 0.9927 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6839 - accuracy: 0.7074 - val_loss: 0.9950 - val_accuracy: 0.5983\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6805 - accuracy: 0.7074 - val_loss: 0.9731 - val_accuracy: 0.6154\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6830 - accuracy: 0.7148 - val_loss: 0.9979 - val_accuracy: 0.5726\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6958 - accuracy: 0.7148 - val_loss: 1.0500 - val_accuracy: 0.6325\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7355 - accuracy: 0.7074 - val_loss: 0.9788 - val_accuracy: 0.5983\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6908 - accuracy: 0.7111 - val_loss: 1.0202 - val_accuracy: 0.5897\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6703 - accuracy: 0.7222 - val_loss: 1.0106 - val_accuracy: 0.6239\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7102 - accuracy: 0.7185 - val_loss: 1.0195 - val_accuracy: 0.5897\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8702 - accuracy: 0.6778 - val_loss: 1.3496 - val_accuracy: 0.5897\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8826 - accuracy: 0.7037 - val_loss: 1.0184 - val_accuracy: 0.5726\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7969 - accuracy: 0.7074 - val_loss: 1.2458 - val_accuracy: 0.5983\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8133 - accuracy: 0.7111 - val_loss: 0.9755 - val_accuracy: 0.5983\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7197 - accuracy: 0.7074 - val_loss: 1.1207 - val_accuracy: 0.6068\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7505 - accuracy: 0.7111 - val_loss: 0.9976 - val_accuracy: 0.5897\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6997 - accuracy: 0.7111 - val_loss: 0.9674 - val_accuracy: 0.6239\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6778 - accuracy: 0.7370 - val_loss: 1.0001 - val_accuracy: 0.6239\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6969 - accuracy: 0.6926 - val_loss: 1.0172 - val_accuracy: 0.5641\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7067 - accuracy: 0.7037 - val_loss: 0.9853 - val_accuracy: 0.6154\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6804 - accuracy: 0.7222 - val_loss: 0.9724 - val_accuracy: 0.5812\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6741 - accuracy: 0.7222 - val_loss: 0.9656 - val_accuracy: 0.6239\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6759 - accuracy: 0.7111 - val_loss: 0.9900 - val_accuracy: 0.5726\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6930 - accuracy: 0.7333 - val_loss: 1.0673 - val_accuracy: 0.6239\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7558 - accuracy: 0.7111 - val_loss: 0.9649 - val_accuracy: 0.5983\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7763 - accuracy: 0.7037 - val_loss: 1.0772 - val_accuracy: 0.6325\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7980 - accuracy: 0.7111 - val_loss: 0.9831 - val_accuracy: 0.6154\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7000 - accuracy: 0.7000 - val_loss: 1.0292 - val_accuracy: 0.6325\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7105 - accuracy: 0.7148 - val_loss: 0.9666 - val_accuracy: 0.6239\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7209 - accuracy: 0.7000 - val_loss: 1.0363 - val_accuracy: 0.6239\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6925 - accuracy: 0.7185 - val_loss: 1.0413 - val_accuracy: 0.5812\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7740 - accuracy: 0.7037 - val_loss: 1.0452 - val_accuracy: 0.6154\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6930 - accuracy: 0.7222 - val_loss: 1.0061 - val_accuracy: 0.5897\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6769 - accuracy: 0.7259 - val_loss: 0.9936 - val_accuracy: 0.5983\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6865 - accuracy: 0.7222 - val_loss: 0.9840 - val_accuracy: 0.5897\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6794 - accuracy: 0.7185 - val_loss: 0.9811 - val_accuracy: 0.6154\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6737 - accuracy: 0.7185 - val_loss: 0.9754 - val_accuracy: 0.6068\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6721 - accuracy: 0.7259 - val_loss: 0.9627 - val_accuracy: 0.6410\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6788 - accuracy: 0.7296 - val_loss: 0.9876 - val_accuracy: 0.5641\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6800 - accuracy: 0.7296 - val_loss: 1.0297 - val_accuracy: 0.6154\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7206 - accuracy: 0.7000 - val_loss: 1.0067 - val_accuracy: 0.6154\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7045 - accuracy: 0.7148 - val_loss: 0.9656 - val_accuracy: 0.6068\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7180 - accuracy: 0.7111 - val_loss: 1.0662 - val_accuracy: 0.6239\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7381 - accuracy: 0.7148 - val_loss: 0.9810 - val_accuracy: 0.5726\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6801 - accuracy: 0.7259 - val_loss: 0.9776 - val_accuracy: 0.6154\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6802 - accuracy: 0.7222 - val_loss: 0.9821 - val_accuracy: 0.5897\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6777 - accuracy: 0.7037 - val_loss: 0.9794 - val_accuracy: 0.6239\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6602 - accuracy: 0.7185 - val_loss: 1.0363 - val_accuracy: 0.5641\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7032 - accuracy: 0.7074 - val_loss: 1.0396 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7228 - accuracy: 0.6963 - val_loss: 0.9832 - val_accuracy: 0.5983\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6893 - accuracy: 0.7111 - val_loss: 0.9751 - val_accuracy: 0.5983\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6719 - accuracy: 0.7148 - val_loss: 0.9631 - val_accuracy: 0.6325\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6727 - accuracy: 0.7185 - val_loss: 1.0006 - val_accuracy: 0.6239\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6960 - accuracy: 0.7037 - val_loss: 0.9844 - val_accuracy: 0.5897\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6980 - accuracy: 0.7000 - val_loss: 0.9625 - val_accuracy: 0.6239\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6740 - accuracy: 0.7111 - val_loss: 0.9616 - val_accuracy: 0.6154\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6697 - accuracy: 0.7185 - val_loss: 0.9962 - val_accuracy: 0.6239\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7308 - accuracy: 0.7000 - val_loss: 1.0770 - val_accuracy: 0.6325\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8657 - accuracy: 0.7074 - val_loss: 1.0322 - val_accuracy: 0.6154\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7226 - accuracy: 0.6963 - val_loss: 0.9807 - val_accuracy: 0.5897\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6798 - accuracy: 0.7222 - val_loss: 0.9756 - val_accuracy: 0.6068\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6759 - accuracy: 0.7111 - val_loss: 0.9794 - val_accuracy: 0.6410\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7018 - accuracy: 0.7111 - val_loss: 0.9735 - val_accuracy: 0.5812\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7304 - accuracy: 0.7185 - val_loss: 1.0788 - val_accuracy: 0.6410\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7357 - accuracy: 0.7000 - val_loss: 0.9661 - val_accuracy: 0.6325\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6809 - accuracy: 0.7185 - val_loss: 0.9532 - val_accuracy: 0.6325\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6692 - accuracy: 0.7074 - val_loss: 0.9587 - val_accuracy: 0.6154\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6745 - accuracy: 0.7111 - val_loss: 0.9905 - val_accuracy: 0.5726\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6905 - accuracy: 0.7111 - val_loss: 0.9871 - val_accuracy: 0.6068\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6823 - accuracy: 0.7037 - val_loss: 1.0557 - val_accuracy: 0.6410\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7976 - accuracy: 0.7074 - val_loss: 0.9925 - val_accuracy: 0.6239\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7637 - accuracy: 0.6926 - val_loss: 0.9903 - val_accuracy: 0.5983\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7826 - accuracy: 0.7111 - val_loss: 1.0125 - val_accuracy: 0.6239\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7097 - accuracy: 0.7000 - val_loss: 0.9835 - val_accuracy: 0.6068\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6841 - accuracy: 0.7000 - val_loss: 0.9913 - val_accuracy: 0.5812\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.6683 - accuracy: 0.7185 - val_loss: 0.9840 - val_accuracy: 0.6410\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6909 - accuracy: 0.7148 - val_loss: 0.9799 - val_accuracy: 0.6154\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7232 - accuracy: 0.7037 - val_loss: 1.0058 - val_accuracy: 0.6239\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 119us/step - loss: 0.6930 - accuracy: 0.7148 - val_loss: 1.0778 - val_accuracy: 0.6239\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7572 - accuracy: 0.6926 - val_loss: 0.9682 - val_accuracy: 0.6239\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7366 - accuracy: 0.7074 - val_loss: 0.9925 - val_accuracy: 0.6068\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7028 - accuracy: 0.6926 - val_loss: 1.0290 - val_accuracy: 0.6239\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7175 - accuracy: 0.6852 - val_loss: 0.9785 - val_accuracy: 0.5983\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6675 - accuracy: 0.7074 - val_loss: 1.0860 - val_accuracy: 0.5812\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7214 - accuracy: 0.7000 - val_loss: 1.0538 - val_accuracy: 0.5812\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7100 - accuracy: 0.7185 - val_loss: 1.0444 - val_accuracy: 0.6239\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6910 - accuracy: 0.7148 - val_loss: 1.0254 - val_accuracy: 0.5897\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6949 - accuracy: 0.7074 - val_loss: 1.0101 - val_accuracy: 0.6239\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6752 - accuracy: 0.7296 - val_loss: 0.9941 - val_accuracy: 0.5726\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6881 - accuracy: 0.6963 - val_loss: 0.9902 - val_accuracy: 0.6325\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6709 - accuracy: 0.7259 - val_loss: 1.0029 - val_accuracy: 0.5726\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7257 - accuracy: 0.7000 - val_loss: 1.0892 - val_accuracy: 0.5983\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7348 - accuracy: 0.7000 - val_loss: 1.0326 - val_accuracy: 0.6068\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6861 - accuracy: 0.7074 - val_loss: 1.0099 - val_accuracy: 0.5983\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7244 - accuracy: 0.7222 - val_loss: 0.9963 - val_accuracy: 0.6068\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6787 - accuracy: 0.7296 - val_loss: 0.9657 - val_accuracy: 0.6154\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6875 - accuracy: 0.6963 - val_loss: 0.9742 - val_accuracy: 0.6239\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7357 - accuracy: 0.7185 - val_loss: 1.0184 - val_accuracy: 0.6239\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6980 - accuracy: 0.7074 - val_loss: 1.0241 - val_accuracy: 0.5983\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7059 - accuracy: 0.7037 - val_loss: 0.9877 - val_accuracy: 0.5641\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7050 - accuracy: 0.7148 - val_loss: 1.0974 - val_accuracy: 0.6325\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8078 - accuracy: 0.7037 - val_loss: 1.0081 - val_accuracy: 0.5983\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6855 - accuracy: 0.7111 - val_loss: 0.9628 - val_accuracy: 0.6239\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6747 - accuracy: 0.7185 - val_loss: 1.0600 - val_accuracy: 0.5726\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7222 - accuracy: 0.6852 - val_loss: 1.0241 - val_accuracy: 0.5983\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7360 - accuracy: 0.7074 - val_loss: 1.1151 - val_accuracy: 0.5812\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0451 - accuracy: 0.6556 - val_loss: 1.4515 - val_accuracy: 0.5385\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7897 - accuracy: 0.6963 - val_loss: 1.0030 - val_accuracy: 0.6325\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7846 - accuracy: 0.7074 - val_loss: 0.9964 - val_accuracy: 0.6239\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7286 - accuracy: 0.7185 - val_loss: 0.9840 - val_accuracy: 0.5983\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7457 - accuracy: 0.7185 - val_loss: 0.9694 - val_accuracy: 0.6154\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7136 - accuracy: 0.7333 - val_loss: 1.0612 - val_accuracy: 0.6154\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7589 - accuracy: 0.7185 - val_loss: 0.9814 - val_accuracy: 0.5897\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7869 - accuracy: 0.7148 - val_loss: 1.0271 - val_accuracy: 0.6239\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7290 - accuracy: 0.7222 - val_loss: 1.0269 - val_accuracy: 0.5641\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7072 - accuracy: 0.7037 - val_loss: 0.9893 - val_accuracy: 0.6154\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6744 - accuracy: 0.7259 - val_loss: 1.0510 - val_accuracy: 0.5556\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7178 - accuracy: 0.7074 - val_loss: 1.1982 - val_accuracy: 0.6325\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8221 - accuracy: 0.6963 - val_loss: 0.9550 - val_accuracy: 0.6239\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6921 - accuracy: 0.7185 - val_loss: 1.0300 - val_accuracy: 0.6154\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6747 - accuracy: 0.7296 - val_loss: 0.9670 - val_accuracy: 0.6410\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6798 - accuracy: 0.7296 - val_loss: 1.0027 - val_accuracy: 0.6068\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6715 - accuracy: 0.7148 - val_loss: 0.9717 - val_accuracy: 0.5983\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6660 - accuracy: 0.7222 - val_loss: 0.9517 - val_accuracy: 0.6325\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6689 - accuracy: 0.7259 - val_loss: 0.9621 - val_accuracy: 0.6410\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6737 - accuracy: 0.7111 - val_loss: 0.9731 - val_accuracy: 0.5983\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7461 - accuracy: 0.7037 - val_loss: 0.9964 - val_accuracy: 0.6239\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8754 - accuracy: 0.6963 - val_loss: 1.0061 - val_accuracy: 0.6239\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7834 - accuracy: 0.7111 - val_loss: 1.1143 - val_accuracy: 0.6325\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7223 - accuracy: 0.7185 - val_loss: 0.9704 - val_accuracy: 0.5897\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7030 - accuracy: 0.7000 - val_loss: 1.0325 - val_accuracy: 0.6068\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6656 - accuracy: 0.7185 - val_loss: 0.9816 - val_accuracy: 0.6325\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6826 - accuracy: 0.7037 - val_loss: 1.0129 - val_accuracy: 0.5641\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6859 - accuracy: 0.7296 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6788 - accuracy: 0.7185 - val_loss: 0.9906 - val_accuracy: 0.6325\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7014 - accuracy: 0.7111 - val_loss: 1.0017 - val_accuracy: 0.6154\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6772 - accuracy: 0.7259 - val_loss: 1.0078 - val_accuracy: 0.6154\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7207 - accuracy: 0.7148 - val_loss: 0.9871 - val_accuracy: 0.5983\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7169 - accuracy: 0.7000 - val_loss: 1.1695 - val_accuracy: 0.6325\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8628 - accuracy: 0.6926 - val_loss: 0.9800 - val_accuracy: 0.6239\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8210 - accuracy: 0.6704 - val_loss: 1.2830 - val_accuracy: 0.5641\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8977 - accuracy: 0.6815 - val_loss: 1.1033 - val_accuracy: 0.6239\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7294 - accuracy: 0.7111 - val_loss: 1.0963 - val_accuracy: 0.5556\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7035 - accuracy: 0.7000 - val_loss: 1.0333 - val_accuracy: 0.6068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6721 - accuracy: 0.7259 - val_loss: 1.0076 - val_accuracy: 0.6068\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6893 - accuracy: 0.7259 - val_loss: 0.9636 - val_accuracy: 0.6154\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6680 - accuracy: 0.7222 - val_loss: 0.9839 - val_accuracy: 0.5897\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6786 - accuracy: 0.6926 - val_loss: 0.9766 - val_accuracy: 0.6325\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6694 - accuracy: 0.7259 - val_loss: 0.9895 - val_accuracy: 0.6154\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6700 - accuracy: 0.7111 - val_loss: 0.9515 - val_accuracy: 0.6410\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6791 - accuracy: 0.7185 - val_loss: 0.9558 - val_accuracy: 0.6239\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7770 - accuracy: 0.7037 - val_loss: 0.9981 - val_accuracy: 0.6325\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6846 - accuracy: 0.7185 - val_loss: 0.9851 - val_accuracy: 0.5726\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6969 - accuracy: 0.7037 - val_loss: 0.9617 - val_accuracy: 0.6239\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6952 - accuracy: 0.6963 - val_loss: 0.9687 - val_accuracy: 0.6154\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7398 - accuracy: 0.6963 - val_loss: 1.0319 - val_accuracy: 0.6239\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7764 - accuracy: 0.7074 - val_loss: 1.0381 - val_accuracy: 0.6154\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7320 - accuracy: 0.7111 - val_loss: 1.0209 - val_accuracy: 0.6068\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9404 - accuracy: 0.6852 - val_loss: 1.4108 - val_accuracy: 0.6496\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9059 - accuracy: 0.7074 - val_loss: 1.0152 - val_accuracy: 0.5556\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7927 - accuracy: 0.6741 - val_loss: 1.3673 - val_accuracy: 0.5812\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0133 - accuracy: 0.6778 - val_loss: 1.1747 - val_accuracy: 0.6410\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7788 - accuracy: 0.7111 - val_loss: 1.2165 - val_accuracy: 0.5385\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8012 - accuracy: 0.6926 - val_loss: 1.1826 - val_accuracy: 0.6068\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7985 - accuracy: 0.6889 - val_loss: 1.0553 - val_accuracy: 0.5726\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9517 - accuracy: 0.6741 - val_loss: 1.5082 - val_accuracy: 0.5043\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7784 - accuracy: 0.6778 - val_loss: 1.0248 - val_accuracy: 0.6068\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7030 - accuracy: 0.7185 - val_loss: 1.0740 - val_accuracy: 0.5470\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7248 - accuracy: 0.6963 - val_loss: 1.0637 - val_accuracy: 0.5897\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7047 - accuracy: 0.7259 - val_loss: 1.0524 - val_accuracy: 0.5983\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7620 - accuracy: 0.7074 - val_loss: 1.1565 - val_accuracy: 0.6239\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7887 - accuracy: 0.7074 - val_loss: 0.9892 - val_accuracy: 0.5641\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7027 - accuracy: 0.7148 - val_loss: 1.1169 - val_accuracy: 0.6410\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7468 - accuracy: 0.7259 - val_loss: 1.0325 - val_accuracy: 0.6068\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6959 - accuracy: 0.7259 - val_loss: 1.0211 - val_accuracy: 0.6154\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7103 - accuracy: 0.7148 - val_loss: 0.9709 - val_accuracy: 0.6154\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6783 - accuracy: 0.7111 - val_loss: 0.9857 - val_accuracy: 0.5897\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7934 - accuracy: 0.6889 - val_loss: 1.1044 - val_accuracy: 0.6239\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7320 - accuracy: 0.7111 - val_loss: 0.9846 - val_accuracy: 0.5897\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7703 - accuracy: 0.7074 - val_loss: 1.1299 - val_accuracy: 0.6239\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7047 - accuracy: 0.6963 - val_loss: 0.9992 - val_accuracy: 0.5641\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7176 - accuracy: 0.7037 - val_loss: 1.0461 - val_accuracy: 0.6068\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7138 - accuracy: 0.7111 - val_loss: 1.0200 - val_accuracy: 0.5897\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6918 - accuracy: 0.7111 - val_loss: 0.9854 - val_accuracy: 0.6239\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6917 - accuracy: 0.7185 - val_loss: 1.0287 - val_accuracy: 0.6239\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7128 - accuracy: 0.6815 - val_loss: 0.9799 - val_accuracy: 0.6239\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7378 - accuracy: 0.7111 - val_loss: 0.9591 - val_accuracy: 0.6154\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7301 - accuracy: 0.6926 - val_loss: 1.0484 - val_accuracy: 0.6239\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6962 - accuracy: 0.7148 - val_loss: 1.0519 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7543 - accuracy: 0.6926 - val_loss: 1.0244 - val_accuracy: 0.6154\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6948 - accuracy: 0.7148 - val_loss: 0.9871 - val_accuracy: 0.5983\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6863 - accuracy: 0.6889 - val_loss: 0.9764 - val_accuracy: 0.5983\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6718 - accuracy: 0.7111 - val_loss: 0.9748 - val_accuracy: 0.6154\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6668 - accuracy: 0.7037 - val_loss: 0.9962 - val_accuracy: 0.5641\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6986 - accuracy: 0.7111 - val_loss: 1.0033 - val_accuracy: 0.6154\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6972 - accuracy: 0.6926 - val_loss: 1.0227 - val_accuracy: 0.6154\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7920 - accuracy: 0.7148 - val_loss: 1.0559 - val_accuracy: 0.6154\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7644 - accuracy: 0.7000 - val_loss: 1.0223 - val_accuracy: 0.6154\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8337 - accuracy: 0.7111 - val_loss: 1.0798 - val_accuracy: 0.6325\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7954 - accuracy: 0.7148 - val_loss: 0.9614 - val_accuracy: 0.6068\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8283 - accuracy: 0.7037 - val_loss: 1.1796 - val_accuracy: 0.6239\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7784 - accuracy: 0.7037 - val_loss: 1.0380 - val_accuracy: 0.5812\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6947 - accuracy: 0.7148 - val_loss: 1.0151 - val_accuracy: 0.6239\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6858 - accuracy: 0.6963 - val_loss: 0.9804 - val_accuracy: 0.5983\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7675 - accuracy: 0.7111 - val_loss: 0.9948 - val_accuracy: 0.6154\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7190 - accuracy: 0.7185 - val_loss: 1.0065 - val_accuracy: 0.6154\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7267 - accuracy: 0.7185 - val_loss: 0.9763 - val_accuracy: 0.6154\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7079 - accuracy: 0.6926 - val_loss: 1.0679 - val_accuracy: 0.5897\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8017 - accuracy: 0.7111 - val_loss: 0.9977 - val_accuracy: 0.6154\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7653 - accuracy: 0.7185 - val_loss: 0.9908 - val_accuracy: 0.6154\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8611 - accuracy: 0.7074 - val_loss: 1.3324 - val_accuracy: 0.5812\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8042 - accuracy: 0.6963 - val_loss: 1.0240 - val_accuracy: 0.5812\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7614 - accuracy: 0.7037 - val_loss: 1.0411 - val_accuracy: 0.6154\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6716 - accuracy: 0.7259 - val_loss: 0.9788 - val_accuracy: 0.6068\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7034 - accuracy: 0.6963 - val_loss: 0.9759 - val_accuracy: 0.6154\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6739 - accuracy: 0.7259 - val_loss: 1.0781 - val_accuracy: 0.6068\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7513 - accuracy: 0.7037 - val_loss: 1.0185 - val_accuracy: 0.6068\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7118 - accuracy: 0.7074 - val_loss: 0.9876 - val_accuracy: 0.6325\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6701 - accuracy: 0.7296 - val_loss: 0.9750 - val_accuracy: 0.5897\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7770 - accuracy: 0.7222 - val_loss: 1.1107 - val_accuracy: 0.6325\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7365 - accuracy: 0.7074 - val_loss: 0.9721 - val_accuracy: 0.5897\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.6884 - accuracy: 0.7074 - val_loss: 0.9831 - val_accuracy: 0.6154\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 312us/step - loss: 0.6798 - accuracy: 0.7074 - val_loss: 0.9954 - val_accuracy: 0.5897\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6736 - accuracy: 0.7074 - val_loss: 0.9819 - val_accuracy: 0.5983\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.6926 - accuracy: 0.7111 - val_loss: 1.0551 - val_accuracy: 0.5812\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6892 - accuracy: 0.7111 - val_loss: 0.9801 - val_accuracy: 0.6325\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6809 - accuracy: 0.7296 - val_loss: 0.9914 - val_accuracy: 0.6154\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6707 - accuracy: 0.7333 - val_loss: 0.9530 - val_accuracy: 0.5983\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6831 - accuracy: 0.7148 - val_loss: 0.9788 - val_accuracy: 0.6068\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6694 - accuracy: 0.7185 - val_loss: 0.9760 - val_accuracy: 0.6239\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6743 - accuracy: 0.7259 - val_loss: 1.0088 - val_accuracy: 0.5983\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.7174 - accuracy: 0.7037 - val_loss: 1.1616 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8102 - accuracy: 0.7148 - val_loss: 0.9772 - val_accuracy: 0.6239\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 274us/step - loss: 0.6858 - accuracy: 0.7222 - val_loss: 1.0231 - val_accuracy: 0.5897\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6812 - accuracy: 0.7148 - val_loss: 0.9684 - val_accuracy: 0.6239\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6761 - accuracy: 0.7148 - val_loss: 0.9926 - val_accuracy: 0.5983\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6680 - accuracy: 0.7259 - val_loss: 0.9780 - val_accuracy: 0.6154\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6908 - accuracy: 0.6963 - val_loss: 1.0437 - val_accuracy: 0.6068\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7106 - accuracy: 0.7037 - val_loss: 0.9641 - val_accuracy: 0.6325\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6663 - accuracy: 0.7185 - val_loss: 1.0015 - val_accuracy: 0.6154\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6847 - accuracy: 0.7111 - val_loss: 0.9852 - val_accuracy: 0.5556\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6732 - accuracy: 0.7111 - val_loss: 0.9831 - val_accuracy: 0.6410\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6702 - accuracy: 0.7148 - val_loss: 1.0102 - val_accuracy: 0.5812\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6937 - accuracy: 0.7074 - val_loss: 0.9621 - val_accuracy: 0.6239\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7277 - accuracy: 0.7222 - val_loss: 1.1867 - val_accuracy: 0.6325\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9580 - accuracy: 0.6889 - val_loss: 1.1349 - val_accuracy: 0.6325\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7268 - accuracy: 0.7111 - val_loss: 1.0543 - val_accuracy: 0.5470\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7179 - accuracy: 0.7037 - val_loss: 1.0769 - val_accuracy: 0.6068\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7146 - accuracy: 0.7074 - val_loss: 1.0015 - val_accuracy: 0.6154\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7166 - accuracy: 0.7185 - val_loss: 0.9784 - val_accuracy: 0.6239\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7005 - accuracy: 0.7000 - val_loss: 1.0191 - val_accuracy: 0.6239\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6783 - accuracy: 0.6963 - val_loss: 0.9675 - val_accuracy: 0.6325\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6700 - accuracy: 0.7111 - val_loss: 0.9608 - val_accuracy: 0.6068\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6649 - accuracy: 0.7296 - val_loss: 0.9822 - val_accuracy: 0.5983\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6653 - accuracy: 0.7185 - val_loss: 0.9803 - val_accuracy: 0.5983\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6659 - accuracy: 0.7222 - val_loss: 0.9731 - val_accuracy: 0.6325\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6627 - accuracy: 0.7148 - val_loss: 0.9509 - val_accuracy: 0.6410\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6635 - accuracy: 0.7333 - val_loss: 0.9549 - val_accuracy: 0.6410\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6655 - accuracy: 0.7222 - val_loss: 0.9779 - val_accuracy: 0.6154\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6700 - accuracy: 0.7148 - val_loss: 0.9565 - val_accuracy: 0.6154\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6671 - accuracy: 0.7222 - val_loss: 0.9994 - val_accuracy: 0.6154\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6746 - accuracy: 0.7074 - val_loss: 0.9729 - val_accuracy: 0.6154\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6779 - accuracy: 0.7074 - val_loss: 0.9865 - val_accuracy: 0.5983\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6663 - accuracy: 0.7222 - val_loss: 0.9686 - val_accuracy: 0.6239\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6644 - accuracy: 0.7148 - val_loss: 0.9727 - val_accuracy: 0.5897\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7153 - accuracy: 0.7037 - val_loss: 1.0225 - val_accuracy: 0.6239\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6940 - accuracy: 0.7000 - val_loss: 1.0000 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6840 - accuracy: 0.7037 - val_loss: 0.9697 - val_accuracy: 0.6154\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6846 - accuracy: 0.7037 - val_loss: 1.0195 - val_accuracy: 0.6068\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6685 - accuracy: 0.7037 - val_loss: 0.9670 - val_accuracy: 0.6239\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6751 - accuracy: 0.7148 - val_loss: 0.9818 - val_accuracy: 0.5983\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7292 - accuracy: 0.7000 - val_loss: 1.0494 - val_accuracy: 0.6239\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7932 - accuracy: 0.7000 - val_loss: 0.9816 - val_accuracy: 0.6239\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6655 - accuracy: 0.7222 - val_loss: 0.9957 - val_accuracy: 0.6068\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7345 - accuracy: 0.7037 - val_loss: 1.0388 - val_accuracy: 0.6068\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6904 - accuracy: 0.7222 - val_loss: 0.9906 - val_accuracy: 0.6154\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7035 - accuracy: 0.7111 - val_loss: 1.0232 - val_accuracy: 0.5897\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6771 - accuracy: 0.7074 - val_loss: 0.9657 - val_accuracy: 0.6154\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6912 - accuracy: 0.7148 - val_loss: 1.0866 - val_accuracy: 0.5812\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7198 - accuracy: 0.6926 - val_loss: 1.0140 - val_accuracy: 0.6068\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6989 - accuracy: 0.7074 - val_loss: 1.0598 - val_accuracy: 0.5897\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7465 - accuracy: 0.6815 - val_loss: 1.0854 - val_accuracy: 0.5897\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8750 - accuracy: 0.6889 - val_loss: 1.1149 - val_accuracy: 0.6410\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7308 - accuracy: 0.6926 - val_loss: 1.0647 - val_accuracy: 0.5726\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8539 - accuracy: 0.6889 - val_loss: 1.0063 - val_accuracy: 0.6068\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6892 - accuracy: 0.7185 - val_loss: 1.0560 - val_accuracy: 0.6068\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7224 - accuracy: 0.6963 - val_loss: 1.0385 - val_accuracy: 0.6068\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6797 - accuracy: 0.7185 - val_loss: 0.9571 - val_accuracy: 0.6581\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6706 - accuracy: 0.7370 - val_loss: 0.9691 - val_accuracy: 0.6325\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6743 - accuracy: 0.7148 - val_loss: 1.0052 - val_accuracy: 0.6154\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7028 - accuracy: 0.7259 - val_loss: 1.0011 - val_accuracy: 0.5983\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6881 - accuracy: 0.7259 - val_loss: 0.9965 - val_accuracy: 0.6154\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7039 - accuracy: 0.7296 - val_loss: 0.9772 - val_accuracy: 0.6154\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7175 - accuracy: 0.7148 - val_loss: 0.9752 - val_accuracy: 0.6068\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7166 - accuracy: 0.7000 - val_loss: 0.9984 - val_accuracy: 0.6239\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7567 - accuracy: 0.7000 - val_loss: 1.0336 - val_accuracy: 0.6239\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7982 - accuracy: 0.7185 - val_loss: 0.9683 - val_accuracy: 0.6154\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7787 - accuracy: 0.7111 - val_loss: 1.3875 - val_accuracy: 0.6325\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0894 - accuracy: 0.6963 - val_loss: 1.2451 - val_accuracy: 0.6410\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7774 - accuracy: 0.7148 - val_loss: 1.1160 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8313 - accuracy: 0.6815 - val_loss: 1.1975 - val_accuracy: 0.6154\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8021 - accuracy: 0.7222 - val_loss: 0.9954 - val_accuracy: 0.6068\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7568 - accuracy: 0.6963 - val_loss: 1.1132 - val_accuracy: 0.6068\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8181 - accuracy: 0.6926 - val_loss: 1.0148 - val_accuracy: 0.6325\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7775 - accuracy: 0.7148 - val_loss: 1.1411 - val_accuracy: 0.6410\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7403 - accuracy: 0.7037 - val_loss: 1.0394 - val_accuracy: 0.5726\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6936 - accuracy: 0.7148 - val_loss: 1.0209 - val_accuracy: 0.6068\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6783 - accuracy: 0.7259 - val_loss: 1.0186 - val_accuracy: 0.6068\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7119 - accuracy: 0.7148 - val_loss: 1.0076 - val_accuracy: 0.6239\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7704 - accuracy: 0.7074 - val_loss: 1.0032 - val_accuracy: 0.6239\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7704 - accuracy: 0.7111 - val_loss: 1.1475 - val_accuracy: 0.6239\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7826 - accuracy: 0.6963 - val_loss: 0.9680 - val_accuracy: 0.5983\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7247 - accuracy: 0.7148 - val_loss: 1.0392 - val_accuracy: 0.6154\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6964 - accuracy: 0.7111 - val_loss: 1.0004 - val_accuracy: 0.6154\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7169 - accuracy: 0.7111 - val_loss: 0.9681 - val_accuracy: 0.6068\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6860 - accuracy: 0.7037 - val_loss: 0.9845 - val_accuracy: 0.6154\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6757 - accuracy: 0.7259 - val_loss: 0.9745 - val_accuracy: 0.6068\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6629 - accuracy: 0.7222 - val_loss: 0.9714 - val_accuracy: 0.6068\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6697 - accuracy: 0.7222 - val_loss: 0.9716 - val_accuracy: 0.5983\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6833 - accuracy: 0.7074 - val_loss: 1.0634 - val_accuracy: 0.6325\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7329 - accuracy: 0.7000 - val_loss: 1.0899 - val_accuracy: 0.5812\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7201 - accuracy: 0.7111 - val_loss: 1.3118 - val_accuracy: 0.5983\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0090 - accuracy: 0.6889 - val_loss: 1.1844 - val_accuracy: 0.6239\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7000 - accuracy: 0.7074 - val_loss: 0.9806 - val_accuracy: 0.5726\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6856 - accuracy: 0.6926 - val_loss: 0.9815 - val_accuracy: 0.6325\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6645 - accuracy: 0.7407 - val_loss: 0.9813 - val_accuracy: 0.6239\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6809 - accuracy: 0.7000 - val_loss: 0.9794 - val_accuracy: 0.5983\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6687 - accuracy: 0.7259 - val_loss: 0.9631 - val_accuracy: 0.6154\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6855 - accuracy: 0.7185 - val_loss: 0.9794 - val_accuracy: 0.5897\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6696 - accuracy: 0.7074 - val_loss: 0.9858 - val_accuracy: 0.6239\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6690 - accuracy: 0.7185 - val_loss: 0.9826 - val_accuracy: 0.6068\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7838 - accuracy: 0.6963 - val_loss: 1.1957 - val_accuracy: 0.5385\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7175 - accuracy: 0.7111 - val_loss: 1.0071 - val_accuracy: 0.6325\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6943 - accuracy: 0.7111 - val_loss: 0.9941 - val_accuracy: 0.6239\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8912 - accuracy: 0.7259 - val_loss: 1.2941 - val_accuracy: 0.6239\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8345 - accuracy: 0.7259 - val_loss: 0.9907 - val_accuracy: 0.5726\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7096 - accuracy: 0.6889 - val_loss: 1.0124 - val_accuracy: 0.5897\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6852 - accuracy: 0.6926 - val_loss: 0.9884 - val_accuracy: 0.6239\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6737 - accuracy: 0.7185 - val_loss: 0.9615 - val_accuracy: 0.6325\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7019 - accuracy: 0.7074 - val_loss: 0.9838 - val_accuracy: 0.5726\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7411 - accuracy: 0.6926 - val_loss: 1.0830 - val_accuracy: 0.6239\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7140 - accuracy: 0.7037 - val_loss: 0.9805 - val_accuracy: 0.6068\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6773 - accuracy: 0.7111 - val_loss: 1.0702 - val_accuracy: 0.6410\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7134 - accuracy: 0.7185 - val_loss: 0.9950 - val_accuracy: 0.5983\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6710 - accuracy: 0.7074 - val_loss: 0.9865 - val_accuracy: 0.5983\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6734 - accuracy: 0.7111 - val_loss: 0.9725 - val_accuracy: 0.6325\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6824 - accuracy: 0.7185 - val_loss: 0.9969 - val_accuracy: 0.6068\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6706 - accuracy: 0.7037 - val_loss: 0.9668 - val_accuracy: 0.6239\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6661 - accuracy: 0.7111 - val_loss: 0.9575 - val_accuracy: 0.6239\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6625 - accuracy: 0.7148 - val_loss: 0.9560 - val_accuracy: 0.6068\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6597 - accuracy: 0.7296 - val_loss: 0.9531 - val_accuracy: 0.6239\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6833 - accuracy: 0.7111 - val_loss: 1.0462 - val_accuracy: 0.5812\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6963 - accuracy: 0.6889 - val_loss: 1.0472 - val_accuracy: 0.5983\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7546 - accuracy: 0.7111 - val_loss: 0.9790 - val_accuracy: 0.6325\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6903 - accuracy: 0.7000 - val_loss: 1.0878 - val_accuracy: 0.5812\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7052 - accuracy: 0.7148 - val_loss: 1.0184 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6926 - accuracy: 0.7185 - val_loss: 1.1522 - val_accuracy: 0.5556\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7845 - accuracy: 0.6778 - val_loss: 1.0910 - val_accuracy: 0.5726\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0656 - accuracy: 0.7000 - val_loss: 1.4355 - val_accuracy: 0.6325\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9682 - accuracy: 0.7000 - val_loss: 1.0215 - val_accuracy: 0.5812\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7743 - accuracy: 0.6778 - val_loss: 1.1388 - val_accuracy: 0.5726\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6939 - accuracy: 0.7148 - val_loss: 1.0088 - val_accuracy: 0.6239\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7127 - accuracy: 0.7296 - val_loss: 1.0227 - val_accuracy: 0.5897\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6896 - accuracy: 0.7074 - val_loss: 1.0851 - val_accuracy: 0.5470\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6834 - accuracy: 0.7148 - val_loss: 0.9879 - val_accuracy: 0.6325\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6758 - accuracy: 0.7259 - val_loss: 1.0851 - val_accuracy: 0.5641\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8036 - accuracy: 0.7000 - val_loss: 1.2514 - val_accuracy: 0.5385\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7068 - accuracy: 0.6889 - val_loss: 1.1909 - val_accuracy: 0.5556\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7709 - accuracy: 0.7185 - val_loss: 1.0990 - val_accuracy: 0.5556\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7335 - accuracy: 0.6926 - val_loss: 1.0262 - val_accuracy: 0.5983\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7141 - accuracy: 0.7222 - val_loss: 0.9789 - val_accuracy: 0.6239\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7404 - accuracy: 0.7111 - val_loss: 1.1733 - val_accuracy: 0.6410\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7873 - accuracy: 0.7074 - val_loss: 0.9575 - val_accuracy: 0.6496\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7686 - accuracy: 0.6926 - val_loss: 1.1201 - val_accuracy: 0.6325\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7819 - accuracy: 0.7148 - val_loss: 0.9586 - val_accuracy: 0.6154\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7735 - accuracy: 0.7074 - val_loss: 1.1484 - val_accuracy: 0.6325\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7587 - accuracy: 0.7111 - val_loss: 0.9672 - val_accuracy: 0.6239\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0480 - accuracy: 0.6852 - val_loss: 1.0268 - val_accuracy: 0.6239\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9205 - accuracy: 0.7111 - val_loss: 1.1950 - val_accuracy: 0.6239\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7996 - accuracy: 0.7259 - val_loss: 1.0934 - val_accuracy: 0.5641\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7239 - accuracy: 0.6963 - val_loss: 0.9931 - val_accuracy: 0.6239\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6704 - accuracy: 0.7111 - val_loss: 0.9994 - val_accuracy: 0.5983\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6719 - accuracy: 0.7037 - val_loss: 0.9898 - val_accuracy: 0.5897\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6838 - accuracy: 0.7259 - val_loss: 0.9592 - val_accuracy: 0.6239\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6869 - accuracy: 0.7222 - val_loss: 1.0875 - val_accuracy: 0.6410\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7386 - accuracy: 0.7148 - val_loss: 0.9645 - val_accuracy: 0.6239\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6813 - accuracy: 0.7333 - val_loss: 1.0140 - val_accuracy: 0.6154\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7073 - accuracy: 0.7111 - val_loss: 0.9866 - val_accuracy: 0.5897\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6716 - accuracy: 0.7222 - val_loss: 0.9826 - val_accuracy: 0.6068\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6745 - accuracy: 0.7111 - val_loss: 0.9868 - val_accuracy: 0.5897\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6692 - accuracy: 0.7185 - val_loss: 0.9682 - val_accuracy: 0.6325\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6600 - accuracy: 0.7296 - val_loss: 0.9695 - val_accuracy: 0.5897\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6636 - accuracy: 0.7222 - val_loss: 0.9561 - val_accuracy: 0.6325\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6584 - accuracy: 0.7296 - val_loss: 0.9720 - val_accuracy: 0.5983\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6620 - accuracy: 0.7185 - val_loss: 0.9682 - val_accuracy: 0.6410\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6681 - accuracy: 0.7333 - val_loss: 0.9787 - val_accuracy: 0.6154\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6649 - accuracy: 0.7259 - val_loss: 0.9652 - val_accuracy: 0.6325\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6699 - accuracy: 0.7148 - val_loss: 0.9729 - val_accuracy: 0.5983\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6590 - accuracy: 0.7296 - val_loss: 0.9637 - val_accuracy: 0.6154\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6697 - accuracy: 0.7259 - val_loss: 0.9880 - val_accuracy: 0.5983\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6710 - accuracy: 0.7148 - val_loss: 1.0030 - val_accuracy: 0.6239\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6606 - accuracy: 0.7148 - val_loss: 0.9746 - val_accuracy: 0.6410\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6669 - accuracy: 0.7222 - val_loss: 0.9709 - val_accuracy: 0.6239\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6718 - accuracy: 0.7074 - val_loss: 0.9764 - val_accuracy: 0.6068\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6638 - accuracy: 0.7222 - val_loss: 0.9608 - val_accuracy: 0.6410\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6622 - accuracy: 0.7259 - val_loss: 0.9640 - val_accuracy: 0.6154\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6903 - accuracy: 0.7185 - val_loss: 0.9944 - val_accuracy: 0.6239\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6663 - accuracy: 0.7185 - val_loss: 0.9767 - val_accuracy: 0.6239\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6793 - accuracy: 0.7037 - val_loss: 0.9585 - val_accuracy: 0.6239\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6623 - accuracy: 0.7111 - val_loss: 0.9727 - val_accuracy: 0.6325\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6572 - accuracy: 0.7148 - val_loss: 0.9652 - val_accuracy: 0.6325\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6610 - accuracy: 0.7296 - val_loss: 0.9692 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6582 - accuracy: 0.7333 - val_loss: 0.9658 - val_accuracy: 0.6239\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6623 - accuracy: 0.7259 - val_loss: 0.9534 - val_accuracy: 0.6410\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6577 - accuracy: 0.7111 - val_loss: 0.9718 - val_accuracy: 0.6410\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6604 - accuracy: 0.7259 - val_loss: 0.9684 - val_accuracy: 0.6325\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6729 - accuracy: 0.7148 - val_loss: 1.0054 - val_accuracy: 0.6068\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6677 - accuracy: 0.7185 - val_loss: 0.9716 - val_accuracy: 0.6068\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6680 - accuracy: 0.7222 - val_loss: 0.9605 - val_accuracy: 0.6154\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6730 - accuracy: 0.7185 - val_loss: 0.9657 - val_accuracy: 0.6239\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6576 - accuracy: 0.7296 - val_loss: 0.9560 - val_accuracy: 0.6410\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6592 - accuracy: 0.7148 - val_loss: 0.9601 - val_accuracy: 0.6410\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6600 - accuracy: 0.7037 - val_loss: 0.9569 - val_accuracy: 0.6410\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6627 - accuracy: 0.7259 - val_loss: 0.9938 - val_accuracy: 0.6239\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6767 - accuracy: 0.7111 - val_loss: 0.9841 - val_accuracy: 0.6068\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6671 - accuracy: 0.7037 - val_loss: 0.9797 - val_accuracy: 0.6239\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6812 - accuracy: 0.7222 - val_loss: 0.9946 - val_accuracy: 0.5726\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6899 - accuracy: 0.7111 - val_loss: 0.9935 - val_accuracy: 0.6154\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6705 - accuracy: 0.7148 - val_loss: 1.0122 - val_accuracy: 0.5983\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7353 - accuracy: 0.7000 - val_loss: 1.0434 - val_accuracy: 0.5812\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7848 - accuracy: 0.7000 - val_loss: 1.2000 - val_accuracy: 0.6239\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8468 - accuracy: 0.7074 - val_loss: 0.9494 - val_accuracy: 0.6068\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7634 - accuracy: 0.7111 - val_loss: 1.0347 - val_accuracy: 0.6239\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9009 - accuracy: 0.6963 - val_loss: 1.2901 - val_accuracy: 0.5897\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8310 - accuracy: 0.7074 - val_loss: 1.0307 - val_accuracy: 0.5726\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8075 - accuracy: 0.7037 - val_loss: 1.1295 - val_accuracy: 0.6068\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7148 - accuracy: 0.7074 - val_loss: 1.0046 - val_accuracy: 0.6325\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7020 - accuracy: 0.7333 - val_loss: 0.9930 - val_accuracy: 0.6068\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7872 - accuracy: 0.7037 - val_loss: 1.0631 - val_accuracy: 0.6325\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7527 - accuracy: 0.7148 - val_loss: 0.9718 - val_accuracy: 0.6410\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6967 - accuracy: 0.7000 - val_loss: 1.0177 - val_accuracy: 0.6068\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8212 - accuracy: 0.7111 - val_loss: 1.1706 - val_accuracy: 0.6410\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7420 - accuracy: 0.7296 - val_loss: 1.0725 - val_accuracy: 0.5726\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7753 - accuracy: 0.7148 - val_loss: 1.3113 - val_accuracy: 0.6154\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8959 - accuracy: 0.7111 - val_loss: 1.1012 - val_accuracy: 0.6154\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7124 - accuracy: 0.7148 - val_loss: 1.0195 - val_accuracy: 0.5897\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7120 - accuracy: 0.6852 - val_loss: 0.9944 - val_accuracy: 0.5897\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6998 - accuracy: 0.7000 - val_loss: 1.0761 - val_accuracy: 0.6410\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7291 - accuracy: 0.7185 - val_loss: 0.9921 - val_accuracy: 0.5897\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6950 - accuracy: 0.7037 - val_loss: 1.0337 - val_accuracy: 0.6068\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6982 - accuracy: 0.7148 - val_loss: 1.0070 - val_accuracy: 0.5897\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6774 - accuracy: 0.7000 - val_loss: 1.0017 - val_accuracy: 0.6068\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6770 - accuracy: 0.7148 - val_loss: 0.9640 - val_accuracy: 0.6239\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7109 - accuracy: 0.7074 - val_loss: 1.0620 - val_accuracy: 0.6154\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8151 - accuracy: 0.7000 - val_loss: 1.0462 - val_accuracy: 0.6239\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6973 - accuracy: 0.7074 - val_loss: 0.9721 - val_accuracy: 0.5983\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6695 - accuracy: 0.7148 - val_loss: 0.9647 - val_accuracy: 0.6154\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6654 - accuracy: 0.7148 - val_loss: 0.9801 - val_accuracy: 0.6154\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6643 - accuracy: 0.6963 - val_loss: 0.9811 - val_accuracy: 0.5726\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6800 - accuracy: 0.6889 - val_loss: 0.9652 - val_accuracy: 0.6154\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7462 - accuracy: 0.6926 - val_loss: 1.4267 - val_accuracy: 0.6068\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.1353 - accuracy: 0.6741 - val_loss: 1.3158 - val_accuracy: 0.6325\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8304 - accuracy: 0.6593 - val_loss: 1.0177 - val_accuracy: 0.5641\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9322 - accuracy: 0.6852 - val_loss: 1.4761 - val_accuracy: 0.5641\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8365 - accuracy: 0.6889 - val_loss: 1.0317 - val_accuracy: 0.6325\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7496 - accuracy: 0.7222 - val_loss: 1.0862 - val_accuracy: 0.6325\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6807 - accuracy: 0.7370 - val_loss: 1.0103 - val_accuracy: 0.5641\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7031 - accuracy: 0.7037 - val_loss: 1.0238 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6776 - accuracy: 0.7296 - val_loss: 1.0266 - val_accuracy: 0.5812\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6762 - accuracy: 0.7111 - val_loss: 1.0215 - val_accuracy: 0.5897\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6819 - accuracy: 0.7000 - val_loss: 1.0074 - val_accuracy: 0.5897\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6764 - accuracy: 0.7074 - val_loss: 0.9759 - val_accuracy: 0.6068\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6637 - accuracy: 0.7074 - val_loss: 0.9906 - val_accuracy: 0.6068\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6604 - accuracy: 0.7111 - val_loss: 0.9837 - val_accuracy: 0.6239\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6801 - accuracy: 0.7185 - val_loss: 0.9736 - val_accuracy: 0.6154\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6895 - accuracy: 0.7074 - val_loss: 0.9692 - val_accuracy: 0.6239\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6675 - accuracy: 0.7259 - val_loss: 0.9774 - val_accuracy: 0.5983\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6702 - accuracy: 0.7037 - val_loss: 0.9877 - val_accuracy: 0.6239\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7182 - accuracy: 0.6852 - val_loss: 1.0286 - val_accuracy: 0.5812\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6732 - accuracy: 0.7222 - val_loss: 0.9788 - val_accuracy: 0.5983\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6718 - accuracy: 0.7111 - val_loss: 1.0290 - val_accuracy: 0.6068\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6870 - accuracy: 0.6963 - val_loss: 1.0604 - val_accuracy: 0.6239\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7505 - accuracy: 0.7111 - val_loss: 1.0021 - val_accuracy: 0.6239\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7195 - accuracy: 0.6852 - val_loss: 1.1238 - val_accuracy: 0.5556\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7350 - accuracy: 0.7000 - val_loss: 1.0021 - val_accuracy: 0.6239\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6615 - accuracy: 0.7481 - val_loss: 1.0535 - val_accuracy: 0.6239\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7186 - accuracy: 0.7111 - val_loss: 0.9675 - val_accuracy: 0.6154\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6790 - accuracy: 0.7296 - val_loss: 0.9819 - val_accuracy: 0.6154\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6824 - accuracy: 0.7111 - val_loss: 1.0129 - val_accuracy: 0.6068\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8425 - accuracy: 0.6926 - val_loss: 1.2664 - val_accuracy: 0.6154\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8070 - accuracy: 0.7037 - val_loss: 1.0605 - val_accuracy: 0.5726\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7128 - accuracy: 0.7222 - val_loss: 1.0537 - val_accuracy: 0.5983\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6876 - accuracy: 0.7111 - val_loss: 1.0187 - val_accuracy: 0.5983\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7546 - accuracy: 0.7111 - val_loss: 1.1518 - val_accuracy: 0.6325\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7180 - accuracy: 0.7037 - val_loss: 1.0272 - val_accuracy: 0.5812\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7352 - accuracy: 0.7074 - val_loss: 1.0381 - val_accuracy: 0.6496\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6977 - accuracy: 0.7296 - val_loss: 1.0651 - val_accuracy: 0.6239\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7427 - accuracy: 0.7148 - val_loss: 0.9889 - val_accuracy: 0.5897\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6951 - accuracy: 0.7148 - val_loss: 0.9831 - val_accuracy: 0.6154\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6949 - accuracy: 0.6926 - val_loss: 0.9988 - val_accuracy: 0.5726\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6964 - accuracy: 0.7148 - val_loss: 0.9737 - val_accuracy: 0.6068\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7549 - accuracy: 0.7148 - val_loss: 0.9798 - val_accuracy: 0.5812\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7427 - accuracy: 0.7185 - val_loss: 0.9712 - val_accuracy: 0.6154\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6689 - accuracy: 0.7407 - val_loss: 1.0096 - val_accuracy: 0.6068\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6930 - accuracy: 0.7037 - val_loss: 1.0753 - val_accuracy: 0.5556\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6603 - accuracy: 0.7185 - val_loss: 1.0297 - val_accuracy: 0.6154\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7165 - accuracy: 0.7074 - val_loss: 0.9657 - val_accuracy: 0.6325\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6933 - accuracy: 0.6963 - val_loss: 1.0518 - val_accuracy: 0.6068\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6846 - accuracy: 0.7111 - val_loss: 0.9734 - val_accuracy: 0.6239\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6677 - accuracy: 0.7333 - val_loss: 0.9725 - val_accuracy: 0.6239\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6574 - accuracy: 0.7111 - val_loss: 0.9638 - val_accuracy: 0.6154\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7005 - accuracy: 0.6963 - val_loss: 1.1571 - val_accuracy: 0.6239\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7990 - accuracy: 0.7185 - val_loss: 1.0075 - val_accuracy: 0.5812\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6760 - accuracy: 0.7296 - val_loss: 0.9871 - val_accuracy: 0.6325\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6617 - accuracy: 0.7074 - val_loss: 0.9625 - val_accuracy: 0.6239\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6622 - accuracy: 0.7259 - val_loss: 0.9688 - val_accuracy: 0.6239\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6572 - accuracy: 0.7111 - val_loss: 0.9716 - val_accuracy: 0.6325\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6732 - accuracy: 0.7148 - val_loss: 0.9624 - val_accuracy: 0.6239\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6667 - accuracy: 0.7000 - val_loss: 0.9964 - val_accuracy: 0.6154\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6875 - accuracy: 0.7111 - val_loss: 0.9949 - val_accuracy: 0.5812\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6943 - accuracy: 0.7259 - val_loss: 1.0877 - val_accuracy: 0.6068\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6957 - accuracy: 0.7148 - val_loss: 1.0128 - val_accuracy: 0.5897\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7105 - accuracy: 0.7111 - val_loss: 0.9688 - val_accuracy: 0.6496\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7733 - accuracy: 0.7148 - val_loss: 0.9783 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7490 - accuracy: 0.7037 - val_loss: 1.0556 - val_accuracy: 0.6325\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7283 - accuracy: 0.7185 - val_loss: 1.0136 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7033 - accuracy: 0.6889 - val_loss: 1.0060 - val_accuracy: 0.6154\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7025 - accuracy: 0.7000 - val_loss: 0.9731 - val_accuracy: 0.6154\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6967 - accuracy: 0.7148 - val_loss: 0.9585 - val_accuracy: 0.6239\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6687 - accuracy: 0.7148 - val_loss: 0.9818 - val_accuracy: 0.6239\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6759 - accuracy: 0.7000 - val_loss: 0.9868 - val_accuracy: 0.6239\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7178 - accuracy: 0.7222 - val_loss: 0.9559 - val_accuracy: 0.6325\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6778 - accuracy: 0.7296 - val_loss: 0.9726 - val_accuracy: 0.6154\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6615 - accuracy: 0.7222 - val_loss: 0.9541 - val_accuracy: 0.6325\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6637 - accuracy: 0.7259 - val_loss: 0.9761 - val_accuracy: 0.6068\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6559 - accuracy: 0.7185 - val_loss: 0.9717 - val_accuracy: 0.6325\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6568 - accuracy: 0.7185 - val_loss: 0.9660 - val_accuracy: 0.6239\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6585 - accuracy: 0.7222 - val_loss: 0.9581 - val_accuracy: 0.6239\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6599 - accuracy: 0.7296 - val_loss: 0.9546 - val_accuracy: 0.6410\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6602 - accuracy: 0.7222 - val_loss: 0.9780 - val_accuracy: 0.6154\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6715 - accuracy: 0.7185 - val_loss: 0.9895 - val_accuracy: 0.6239\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6617 - accuracy: 0.7222 - val_loss: 1.0151 - val_accuracy: 0.5726\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6771 - accuracy: 0.7074 - val_loss: 0.9717 - val_accuracy: 0.6239\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6615 - accuracy: 0.6926 - val_loss: 0.9630 - val_accuracy: 0.6239\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6600 - accuracy: 0.7185 - val_loss: 0.9523 - val_accuracy: 0.6068\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6535 - accuracy: 0.7370 - val_loss: 0.9970 - val_accuracy: 0.6068\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6763 - accuracy: 0.7148 - val_loss: 1.0523 - val_accuracy: 0.5556\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7129 - accuracy: 0.7000 - val_loss: 0.9976 - val_accuracy: 0.6154\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6896 - accuracy: 0.7037 - val_loss: 0.9774 - val_accuracy: 0.6068\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8894 - accuracy: 0.6926 - val_loss: 1.1969 - val_accuracy: 0.6239\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7834 - accuracy: 0.7074 - val_loss: 1.0887 - val_accuracy: 0.5726\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6986 - accuracy: 0.7148 - val_loss: 0.9917 - val_accuracy: 0.6239\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6731 - accuracy: 0.7185 - val_loss: 1.0251 - val_accuracy: 0.5726\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6811 - accuracy: 0.6963 - val_loss: 0.9870 - val_accuracy: 0.6239\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6868 - accuracy: 0.7185 - val_loss: 1.0369 - val_accuracy: 0.5726\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7163 - accuracy: 0.7037 - val_loss: 1.0100 - val_accuracy: 0.6068\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6653 - accuracy: 0.7148 - val_loss: 0.9625 - val_accuracy: 0.6496\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6617 - accuracy: 0.7222 - val_loss: 1.0205 - val_accuracy: 0.6154\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6813 - accuracy: 0.7000 - val_loss: 1.0195 - val_accuracy: 0.6154\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6844 - accuracy: 0.7111 - val_loss: 0.9669 - val_accuracy: 0.6239\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6769 - accuracy: 0.7259 - val_loss: 0.9597 - val_accuracy: 0.6325\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7255 - accuracy: 0.6889 - val_loss: 1.0685 - val_accuracy: 0.6325\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7655 - accuracy: 0.7037 - val_loss: 0.9410 - val_accuracy: 0.6410\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6916 - accuracy: 0.7111 - val_loss: 1.0268 - val_accuracy: 0.6239\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7209 - accuracy: 0.7074 - val_loss: 1.0155 - val_accuracy: 0.5726\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6613 - accuracy: 0.7074 - val_loss: 1.0687 - val_accuracy: 0.6325\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7311 - accuracy: 0.7111 - val_loss: 1.0074 - val_accuracy: 0.5812\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6929 - accuracy: 0.7111 - val_loss: 0.9633 - val_accuracy: 0.6154\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6669 - accuracy: 0.7148 - val_loss: 1.0092 - val_accuracy: 0.6239\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6968 - accuracy: 0.7148 - val_loss: 0.9711 - val_accuracy: 0.5983\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6814 - accuracy: 0.7000 - val_loss: 0.9640 - val_accuracy: 0.6239\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6514 - accuracy: 0.7185 - val_loss: 0.9661 - val_accuracy: 0.6154\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7015 - accuracy: 0.7037 - val_loss: 1.4622 - val_accuracy: 0.5299\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8976 - accuracy: 0.6667 - val_loss: 1.0546 - val_accuracy: 0.6154\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6712 - accuracy: 0.7333 - val_loss: 1.0113 - val_accuracy: 0.6068\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6741 - accuracy: 0.7185 - val_loss: 1.0201 - val_accuracy: 0.5983\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6594 - accuracy: 0.7185 - val_loss: 0.9648 - val_accuracy: 0.6410\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6596 - accuracy: 0.7259 - val_loss: 0.9735 - val_accuracy: 0.6068\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6601 - accuracy: 0.7259 - val_loss: 0.9749 - val_accuracy: 0.6239\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6724 - accuracy: 0.7222 - val_loss: 0.9603 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6563 - accuracy: 0.7259 - val_loss: 0.9624 - val_accuracy: 0.6325\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6557 - accuracy: 0.7259 - val_loss: 0.9571 - val_accuracy: 0.6239\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6589 - accuracy: 0.7296 - val_loss: 0.9812 - val_accuracy: 0.6068\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6670 - accuracy: 0.7148 - val_loss: 0.9806 - val_accuracy: 0.5983\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6826 - accuracy: 0.6778 - val_loss: 1.0977 - val_accuracy: 0.6239\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7265 - accuracy: 0.7074 - val_loss: 0.9709 - val_accuracy: 0.6154\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7152 - accuracy: 0.6889 - val_loss: 0.9714 - val_accuracy: 0.6154\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6517 - accuracy: 0.7222 - val_loss: 0.9914 - val_accuracy: 0.6239\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7008 - accuracy: 0.6963 - val_loss: 0.9788 - val_accuracy: 0.5983\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6795 - accuracy: 0.7074 - val_loss: 0.9844 - val_accuracy: 0.5812\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6745 - accuracy: 0.7185 - val_loss: 1.0352 - val_accuracy: 0.6154\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6983 - accuracy: 0.7074 - val_loss: 0.9651 - val_accuracy: 0.6239\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7350 - accuracy: 0.7185 - val_loss: 1.1151 - val_accuracy: 0.6325\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6909 - accuracy: 0.7296 - val_loss: 1.0452 - val_accuracy: 0.5470\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7724 - accuracy: 0.6741 - val_loss: 1.1046 - val_accuracy: 0.5897\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7044 - accuracy: 0.7037 - val_loss: 1.0824 - val_accuracy: 0.6410\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8448 - accuracy: 0.6852 - val_loss: 1.0963 - val_accuracy: 0.6239\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6958 - accuracy: 0.7333 - val_loss: 1.0852 - val_accuracy: 0.5641\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7224 - accuracy: 0.7074 - val_loss: 1.0031 - val_accuracy: 0.5983\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6645 - accuracy: 0.7222 - val_loss: 0.9629 - val_accuracy: 0.6239\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6614 - accuracy: 0.7185 - val_loss: 0.9779 - val_accuracy: 0.5983\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6566 - accuracy: 0.7259 - val_loss: 0.9608 - val_accuracy: 0.6752\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6543 - accuracy: 0.7185 - val_loss: 0.9756 - val_accuracy: 0.6154\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6753 - accuracy: 0.7111 - val_loss: 0.9606 - val_accuracy: 0.6325\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6632 - accuracy: 0.7074 - val_loss: 0.9891 - val_accuracy: 0.6068\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7029 - accuracy: 0.6926 - val_loss: 0.9933 - val_accuracy: 0.6068\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.6579 - accuracy: 0.7074 - val_loss: 0.9596 - val_accuracy: 0.6239\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6659 - accuracy: 0.7111 - val_loss: 0.9754 - val_accuracy: 0.5726\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7196 - accuracy: 0.6963 - val_loss: 1.0018 - val_accuracy: 0.6068\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6587 - accuracy: 0.7222 - val_loss: 0.9754 - val_accuracy: 0.6325\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6553 - accuracy: 0.7222 - val_loss: 0.9764 - val_accuracy: 0.6325\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6633 - accuracy: 0.7333 - val_loss: 0.9557 - val_accuracy: 0.6239\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6716 - accuracy: 0.7111 - val_loss: 1.0026 - val_accuracy: 0.5897\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7155 - accuracy: 0.7111 - val_loss: 0.9658 - val_accuracy: 0.6239\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6654 - accuracy: 0.7037 - val_loss: 0.9431 - val_accuracy: 0.6325\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6568 - accuracy: 0.7222 - val_loss: 0.9641 - val_accuracy: 0.6068\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6552 - accuracy: 0.7296 - val_loss: 0.9820 - val_accuracy: 0.6068\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6957 - accuracy: 0.6963 - val_loss: 0.9973 - val_accuracy: 0.6239\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6652 - accuracy: 0.7037 - val_loss: 0.9486 - val_accuracy: 0.6325\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.6570 - accuracy: 0.7185 - val_loss: 0.9749 - val_accuracy: 0.6239\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6599 - accuracy: 0.7148 - val_loss: 0.9708 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6811 - accuracy: 0.7037 - val_loss: 0.9597 - val_accuracy: 0.6239\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6547 - accuracy: 0.7407 - val_loss: 0.9603 - val_accuracy: 0.6325\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6911 - accuracy: 0.7148 - val_loss: 0.9725 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6814 - accuracy: 0.7222 - val_loss: 1.0327 - val_accuracy: 0.6239\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6840 - accuracy: 0.7111 - val_loss: 1.0546 - val_accuracy: 0.5726\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7630 - accuracy: 0.7037 - val_loss: 1.1291 - val_accuracy: 0.6325\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7685 - accuracy: 0.7111 - val_loss: 1.0145 - val_accuracy: 0.5726\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7635 - accuracy: 0.6926 - val_loss: 1.0679 - val_accuracy: 0.6325\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6776 - accuracy: 0.6889 - val_loss: 1.0232 - val_accuracy: 0.5983\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7173 - accuracy: 0.7037 - val_loss: 1.0231 - val_accuracy: 0.6239\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6915 - accuracy: 0.7259 - val_loss: 0.9816 - val_accuracy: 0.6239\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7541 - accuracy: 0.7222 - val_loss: 1.0467 - val_accuracy: 0.6325\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7072 - accuracy: 0.7148 - val_loss: 0.9885 - val_accuracy: 0.6239\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7047 - accuracy: 0.7148 - val_loss: 0.9557 - val_accuracy: 0.6239\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6749 - accuracy: 0.7222 - val_loss: 1.0115 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6686 - accuracy: 0.7333 - val_loss: 1.0241 - val_accuracy: 0.5983\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6861 - accuracy: 0.7111 - val_loss: 0.9977 - val_accuracy: 0.6068\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6673 - accuracy: 0.7222 - val_loss: 0.9770 - val_accuracy: 0.6068\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6713 - accuracy: 0.7074 - val_loss: 1.0025 - val_accuracy: 0.6068\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6626 - accuracy: 0.7111 - val_loss: 0.9789 - val_accuracy: 0.6410\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6808 - accuracy: 0.7148 - val_loss: 1.0240 - val_accuracy: 0.5983\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7035 - accuracy: 0.7074 - val_loss: 0.9817 - val_accuracy: 0.6154\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7390 - accuracy: 0.7185 - val_loss: 0.9778 - val_accuracy: 0.6410\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6878 - accuracy: 0.7111 - val_loss: 1.2705 - val_accuracy: 0.5726\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9035 - accuracy: 0.6815 - val_loss: 1.0538 - val_accuracy: 0.6325\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7208 - accuracy: 0.7111 - val_loss: 1.1122 - val_accuracy: 0.5726\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7286 - accuracy: 0.7074 - val_loss: 1.0757 - val_accuracy: 0.5726\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6680 - accuracy: 0.7074 - val_loss: 0.9839 - val_accuracy: 0.6239\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6625 - accuracy: 0.7296 - val_loss: 1.0131 - val_accuracy: 0.5983\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6788 - accuracy: 0.7074 - val_loss: 1.0391 - val_accuracy: 0.5983\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6817 - accuracy: 0.7074 - val_loss: 0.9822 - val_accuracy: 0.6154\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6751 - accuracy: 0.7370 - val_loss: 1.0264 - val_accuracy: 0.6068\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6773 - accuracy: 0.7000 - val_loss: 0.9936 - val_accuracy: 0.6068\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6755 - accuracy: 0.7148 - val_loss: 0.9723 - val_accuracy: 0.6410\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7557 - accuracy: 0.7111 - val_loss: 1.1737 - val_accuracy: 0.6325\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8115 - accuracy: 0.7074 - val_loss: 0.9534 - val_accuracy: 0.6496\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6655 - accuracy: 0.7333 - val_loss: 1.0115 - val_accuracy: 0.6239\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6922 - accuracy: 0.7185 - val_loss: 0.9785 - val_accuracy: 0.6325\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6595 - accuracy: 0.7370 - val_loss: 0.9604 - val_accuracy: 0.6496\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6606 - accuracy: 0.7333 - val_loss: 0.9752 - val_accuracy: 0.6154\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6795 - accuracy: 0.7259 - val_loss: 0.9629 - val_accuracy: 0.6325\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7014 - accuracy: 0.7037 - val_loss: 1.0378 - val_accuracy: 0.6325\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7519 - accuracy: 0.6963 - val_loss: 0.9586 - val_accuracy: 0.6410\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6568 - accuracy: 0.7259 - val_loss: 0.9837 - val_accuracy: 0.5983\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6667 - accuracy: 0.7000 - val_loss: 1.0797 - val_accuracy: 0.6154\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7904 - accuracy: 0.7000 - val_loss: 0.9701 - val_accuracy: 0.6239\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6703 - accuracy: 0.7259 - val_loss: 1.0610 - val_accuracy: 0.5983\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7004 - accuracy: 0.6926 - val_loss: 0.9747 - val_accuracy: 0.6154\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6555 - accuracy: 0.7370 - val_loss: 0.9615 - val_accuracy: 0.6325\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6621 - accuracy: 0.7259 - val_loss: 1.0013 - val_accuracy: 0.6068\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6752 - accuracy: 0.7111 - val_loss: 0.9680 - val_accuracy: 0.5983\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6963 - accuracy: 0.7111 - val_loss: 1.1083 - val_accuracy: 0.5983\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7298 - accuracy: 0.6963 - val_loss: 1.0719 - val_accuracy: 0.5983\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6803 - accuracy: 0.7111 - val_loss: 0.9920 - val_accuracy: 0.6068\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7226 - accuracy: 0.7037 - val_loss: 1.1426 - val_accuracy: 0.6154\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7961 - accuracy: 0.7111 - val_loss: 0.9622 - val_accuracy: 0.6325\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6998 - accuracy: 0.7259 - val_loss: 1.0797 - val_accuracy: 0.6325\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6979 - accuracy: 0.7037 - val_loss: 1.0625 - val_accuracy: 0.5897\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6938 - accuracy: 0.7333 - val_loss: 0.9863 - val_accuracy: 0.6410\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6755 - accuracy: 0.7259 - val_loss: 0.9753 - val_accuracy: 0.6239\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6552 - accuracy: 0.7074 - val_loss: 0.9600 - val_accuracy: 0.6325\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6599 - accuracy: 0.7407 - val_loss: 0.9636 - val_accuracy: 0.6239\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6627 - accuracy: 0.7185 - val_loss: 0.9781 - val_accuracy: 0.6068\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6578 - accuracy: 0.7444 - val_loss: 0.9679 - val_accuracy: 0.6325\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6660 - accuracy: 0.7111 - val_loss: 0.9822 - val_accuracy: 0.5726\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7987 - accuracy: 0.7074 - val_loss: 1.1150 - val_accuracy: 0.6325\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7348 - accuracy: 0.7111 - val_loss: 1.1701 - val_accuracy: 0.5726\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7251 - accuracy: 0.7185 - val_loss: 1.1112 - val_accuracy: 0.6325\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7356 - accuracy: 0.7148 - val_loss: 0.9553 - val_accuracy: 0.6325\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6743 - accuracy: 0.7370 - val_loss: 0.9951 - val_accuracy: 0.5983\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7524 - accuracy: 0.7111 - val_loss: 0.9791 - val_accuracy: 0.6410\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6942 - accuracy: 0.7259 - val_loss: 0.9924 - val_accuracy: 0.6239\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6797 - accuracy: 0.6889 - val_loss: 1.0405 - val_accuracy: 0.6239\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7503 - accuracy: 0.6852 - val_loss: 0.9666 - val_accuracy: 0.6239\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7344 - accuracy: 0.7111 - val_loss: 1.0158 - val_accuracy: 0.6239\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7065 - accuracy: 0.7148 - val_loss: 1.1693 - val_accuracy: 0.6239\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9123 - accuracy: 0.6815 - val_loss: 1.1549 - val_accuracy: 0.6068\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8258 - accuracy: 0.6963 - val_loss: 1.2855 - val_accuracy: 0.5726\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7336 - accuracy: 0.7185 - val_loss: 1.1919 - val_accuracy: 0.6154\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8532 - accuracy: 0.6926 - val_loss: 1.0645 - val_accuracy: 0.5812\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6858 - accuracy: 0.7259 - val_loss: 1.0426 - val_accuracy: 0.6325\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7263 - accuracy: 0.7222 - val_loss: 0.9775 - val_accuracy: 0.6410\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6651 - accuracy: 0.7259 - val_loss: 0.9690 - val_accuracy: 0.6068\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6649 - accuracy: 0.7111 - val_loss: 0.9877 - val_accuracy: 0.6325\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6538 - accuracy: 0.7296 - val_loss: 0.9758 - val_accuracy: 0.5983\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6731 - accuracy: 0.7074 - val_loss: 0.9642 - val_accuracy: 0.6325\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6709 - accuracy: 0.7185 - val_loss: 0.9981 - val_accuracy: 0.6239\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6795 - accuracy: 0.6889 - val_loss: 0.9862 - val_accuracy: 0.6068\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6617 - accuracy: 0.7037 - val_loss: 0.9632 - val_accuracy: 0.6325\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6846 - accuracy: 0.7259 - val_loss: 1.0328 - val_accuracy: 0.5812\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6930 - accuracy: 0.7111 - val_loss: 0.9837 - val_accuracy: 0.6239\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6554 - accuracy: 0.7407 - val_loss: 0.9735 - val_accuracy: 0.6325\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6713 - accuracy: 0.7111 - val_loss: 0.9949 - val_accuracy: 0.6154\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6529 - accuracy: 0.7259 - val_loss: 0.9675 - val_accuracy: 0.6496\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6592 - accuracy: 0.7333 - val_loss: 0.9884 - val_accuracy: 0.6068\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6636 - accuracy: 0.7000 - val_loss: 0.9498 - val_accuracy: 0.6325\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6692 - accuracy: 0.7185 - val_loss: 1.0048 - val_accuracy: 0.6068\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6920 - accuracy: 0.7111 - val_loss: 1.0029 - val_accuracy: 0.5897\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6924 - accuracy: 0.7074 - val_loss: 0.9758 - val_accuracy: 0.6239\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7498 - accuracy: 0.6963 - val_loss: 1.1664 - val_accuracy: 0.6325\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7914 - accuracy: 0.7185 - val_loss: 0.9570 - val_accuracy: 0.6239\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7268 - accuracy: 0.7148 - val_loss: 1.5299 - val_accuracy: 0.5299\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9887 - accuracy: 0.6741 - val_loss: 1.1188 - val_accuracy: 0.5641\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6961 - accuracy: 0.7259 - val_loss: 0.9883 - val_accuracy: 0.6239\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6702 - accuracy: 0.7259 - val_loss: 1.0041 - val_accuracy: 0.6068\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6564 - accuracy: 0.7222 - val_loss: 0.9782 - val_accuracy: 0.6410\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6546 - accuracy: 0.7407 - val_loss: 0.9591 - val_accuracy: 0.6239\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6556 - accuracy: 0.7296 - val_loss: 0.9582 - val_accuracy: 0.6239\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6540 - accuracy: 0.7407 - val_loss: 0.9769 - val_accuracy: 0.6154\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6657 - accuracy: 0.7037 - val_loss: 0.9922 - val_accuracy: 0.5812\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6614 - accuracy: 0.7148 - val_loss: 0.9668 - val_accuracy: 0.6239\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6716 - accuracy: 0.7111 - val_loss: 1.0068 - val_accuracy: 0.5641\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6772 - accuracy: 0.7111 - val_loss: 1.0101 - val_accuracy: 0.6154\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6775 - accuracy: 0.7185 - val_loss: 1.0391 - val_accuracy: 0.6068\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7391 - accuracy: 0.7074 - val_loss: 1.1836 - val_accuracy: 0.6325\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7428 - accuracy: 0.7074 - val_loss: 0.9618 - val_accuracy: 0.6068\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8175 - accuracy: 0.7000 - val_loss: 1.1128 - val_accuracy: 0.6068\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7596 - accuracy: 0.7000 - val_loss: 0.9705 - val_accuracy: 0.6325\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6769 - accuracy: 0.7333 - val_loss: 0.9673 - val_accuracy: 0.6068\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6799 - accuracy: 0.7000 - val_loss: 1.0902 - val_accuracy: 0.6325\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7597 - accuracy: 0.7037 - val_loss: 0.9569 - val_accuracy: 0.6239\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6908 - accuracy: 0.7370 - val_loss: 1.0702 - val_accuracy: 0.6325\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7126 - accuracy: 0.7222 - val_loss: 1.0232 - val_accuracy: 0.6068\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6884 - accuracy: 0.7185 - val_loss: 1.0460 - val_accuracy: 0.6154\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7075 - accuracy: 0.7148 - val_loss: 0.9693 - val_accuracy: 0.6239\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6624 - accuracy: 0.7185 - val_loss: 0.9651 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6579 - accuracy: 0.7111 - val_loss: 0.9680 - val_accuracy: 0.5897\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6532 - accuracy: 0.7259 - val_loss: 0.9685 - val_accuracy: 0.6154\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6556 - accuracy: 0.7444 - val_loss: 0.9780 - val_accuracy: 0.6496\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6544 - accuracy: 0.7259 - val_loss: 0.9627 - val_accuracy: 0.6325\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6583 - accuracy: 0.7222 - val_loss: 0.9694 - val_accuracy: 0.6068\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6683 - accuracy: 0.7148 - val_loss: 0.9622 - val_accuracy: 0.6325\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7001 - accuracy: 0.7259 - val_loss: 1.0786 - val_accuracy: 0.6154\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7107 - accuracy: 0.7296 - val_loss: 0.9636 - val_accuracy: 0.5983\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6670 - accuracy: 0.7185 - val_loss: 0.9745 - val_accuracy: 0.6154\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6494 - accuracy: 0.7074 - val_loss: 1.0284 - val_accuracy: 0.5641\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7475 - accuracy: 0.6963 - val_loss: 1.1350 - val_accuracy: 0.6239\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7393 - accuracy: 0.7185 - val_loss: 0.9814 - val_accuracy: 0.5897\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6687 - accuracy: 0.7148 - val_loss: 1.0104 - val_accuracy: 0.5983\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6881 - accuracy: 0.7111 - val_loss: 0.9619 - val_accuracy: 0.6239\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7719 - accuracy: 0.7037 - val_loss: 1.0875 - val_accuracy: 0.5983\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.5951 - accuracy: 0.6815 - val_loss: 2.2514 - val_accuracy: 0.5983\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.6277 - accuracy: 0.7037 - val_loss: 1.7114 - val_accuracy: 0.6325\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.1307 - accuracy: 0.6778 - val_loss: 1.0085 - val_accuracy: 0.5556\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8212 - accuracy: 0.6926 - val_loss: 1.1752 - val_accuracy: 0.6239\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8252 - accuracy: 0.7111 - val_loss: 1.1262 - val_accuracy: 0.6325\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6782 - accuracy: 0.7333 - val_loss: 1.0708 - val_accuracy: 0.5470\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7229 - accuracy: 0.6889 - val_loss: 1.0205 - val_accuracy: 0.5897\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6754 - accuracy: 0.7259 - val_loss: 0.9886 - val_accuracy: 0.6154\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7066 - accuracy: 0.7259 - val_loss: 0.9696 - val_accuracy: 0.6154\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6888 - accuracy: 0.7037 - val_loss: 0.9875 - val_accuracy: 0.6239\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6745 - accuracy: 0.7000 - val_loss: 0.9685 - val_accuracy: 0.6239\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6662 - accuracy: 0.7148 - val_loss: 1.0387 - val_accuracy: 0.6154\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6997 - accuracy: 0.7259 - val_loss: 0.9816 - val_accuracy: 0.6068\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6925 - accuracy: 0.7185 - val_loss: 1.1531 - val_accuracy: 0.5812\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7673 - accuracy: 0.6889 - val_loss: 1.0531 - val_accuracy: 0.5726\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6738 - accuracy: 0.7407 - val_loss: 1.0180 - val_accuracy: 0.6239\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6947 - accuracy: 0.7259 - val_loss: 0.9834 - val_accuracy: 0.6239\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6809 - accuracy: 0.7185 - val_loss: 0.9935 - val_accuracy: 0.6410\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7095 - accuracy: 0.7074 - val_loss: 1.0530 - val_accuracy: 0.6154\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7018 - accuracy: 0.7222 - val_loss: 0.9765 - val_accuracy: 0.6154\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6623 - accuracy: 0.7185 - val_loss: 1.0164 - val_accuracy: 0.6068\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7066 - accuracy: 0.7000 - val_loss: 0.9767 - val_accuracy: 0.6410\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6889 - accuracy: 0.7111 - val_loss: 1.0003 - val_accuracy: 0.6325\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6743 - accuracy: 0.6926 - val_loss: 0.9680 - val_accuracy: 0.6410\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6535 - accuracy: 0.7370 - val_loss: 0.9680 - val_accuracy: 0.6154\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6642 - accuracy: 0.7111 - val_loss: 0.9763 - val_accuracy: 0.6239\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6557 - accuracy: 0.7148 - val_loss: 0.9545 - val_accuracy: 0.6154\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6522 - accuracy: 0.7259 - val_loss: 0.9579 - val_accuracy: 0.6239\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6615 - accuracy: 0.7148 - val_loss: 0.9747 - val_accuracy: 0.5897\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6546 - accuracy: 0.7185 - val_loss: 0.9599 - val_accuracy: 0.5983\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6575 - accuracy: 0.7074 - val_loss: 1.0079 - val_accuracy: 0.6068\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6668 - accuracy: 0.7222 - val_loss: 0.9845 - val_accuracy: 0.6068\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6684 - accuracy: 0.7296 - val_loss: 1.0552 - val_accuracy: 0.5897\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7827 - accuracy: 0.6741 - val_loss: 1.1056 - val_accuracy: 0.5897\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7295 - accuracy: 0.7222 - val_loss: 1.1220 - val_accuracy: 0.6410\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7598 - accuracy: 0.7259 - val_loss: 0.9495 - val_accuracy: 0.6410\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8354 - accuracy: 0.7037 - val_loss: 1.0395 - val_accuracy: 0.6154\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8563 - accuracy: 0.6963 - val_loss: 1.2052 - val_accuracy: 0.6325\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7884 - accuracy: 0.7074 - val_loss: 0.9613 - val_accuracy: 0.6239\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6873 - accuracy: 0.7148 - val_loss: 0.9734 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8323 - accuracy: 0.6852 - val_loss: 1.0825 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.3572 - accuracy: 0.6704 - val_loss: 2.1860 - val_accuracy: 0.5897\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.6198 - accuracy: 0.6889 - val_loss: 1.8257 - val_accuracy: 0.6068\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.2316 - accuracy: 0.6815 - val_loss: 1.0899 - val_accuracy: 0.5897\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7310 - accuracy: 0.6963 - val_loss: 1.0917 - val_accuracy: 0.5726\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7452 - accuracy: 0.7074 - val_loss: 1.1257 - val_accuracy: 0.6239\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6873 - accuracy: 0.7259 - val_loss: 1.0667 - val_accuracy: 0.5385\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6833 - accuracy: 0.7037 - val_loss: 1.1044 - val_accuracy: 0.6325\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7394 - accuracy: 0.7296 - val_loss: 0.9644 - val_accuracy: 0.6154\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6628 - accuracy: 0.7185 - val_loss: 0.9761 - val_accuracy: 0.5897\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6663 - accuracy: 0.7148 - val_loss: 0.9814 - val_accuracy: 0.6154\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6716 - accuracy: 0.7222 - val_loss: 1.0246 - val_accuracy: 0.5812\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6979 - accuracy: 0.7037 - val_loss: 1.0167 - val_accuracy: 0.6068\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6743 - accuracy: 0.7148 - val_loss: 1.0111 - val_accuracy: 0.6068\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7246 - accuracy: 0.6778 - val_loss: 1.1360 - val_accuracy: 0.5385\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6923 - accuracy: 0.7185 - val_loss: 1.0177 - val_accuracy: 0.6239\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7000 - accuracy: 0.7259 - val_loss: 1.0057 - val_accuracy: 0.5897\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6883 - accuracy: 0.7074 - val_loss: 1.0632 - val_accuracy: 0.6068\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7017 - accuracy: 0.7185 - val_loss: 0.9828 - val_accuracy: 0.6154\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6745 - accuracy: 0.6963 - val_loss: 1.0507 - val_accuracy: 0.6239\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7166 - accuracy: 0.7000 - val_loss: 0.9570 - val_accuracy: 0.6325\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7080 - accuracy: 0.7074 - val_loss: 1.0899 - val_accuracy: 0.5812\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6892 - accuracy: 0.6926 - val_loss: 0.9902 - val_accuracy: 0.6154\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6726 - accuracy: 0.7222 - val_loss: 0.9657 - val_accuracy: 0.6410\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6634 - accuracy: 0.7111 - val_loss: 0.9852 - val_accuracy: 0.6154\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6514 - accuracy: 0.7222 - val_loss: 0.9619 - val_accuracy: 0.6410\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6658 - accuracy: 0.7259 - val_loss: 0.9587 - val_accuracy: 0.6410\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7065 - accuracy: 0.7074 - val_loss: 1.0564 - val_accuracy: 0.6325\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6790 - accuracy: 0.7333 - val_loss: 1.0926 - val_accuracy: 0.6068\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8313 - accuracy: 0.7037 - val_loss: 1.1621 - val_accuracy: 0.6325\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7290 - accuracy: 0.6926 - val_loss: 0.9719 - val_accuracy: 0.5983\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6688 - accuracy: 0.7111 - val_loss: 0.9784 - val_accuracy: 0.6239\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6536 - accuracy: 0.7148 - val_loss: 0.9792 - val_accuracy: 0.6239\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6442 - accuracy: 0.7259 - val_loss: 1.0199 - val_accuracy: 0.6239\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7115 - accuracy: 0.7148 - val_loss: 0.9476 - val_accuracy: 0.6068\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6750 - accuracy: 0.7111 - val_loss: 0.9729 - val_accuracy: 0.6068\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6727 - accuracy: 0.7222 - val_loss: 1.0571 - val_accuracy: 0.5983\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7891 - accuracy: 0.7074 - val_loss: 1.0413 - val_accuracy: 0.5983\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6872 - accuracy: 0.7111 - val_loss: 1.0008 - val_accuracy: 0.6325\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7082 - accuracy: 0.7148 - val_loss: 0.9618 - val_accuracy: 0.6325\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6884 - accuracy: 0.6778 - val_loss: 1.0388 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7073 - accuracy: 0.7222 - val_loss: 0.9558 - val_accuracy: 0.6154\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6591 - accuracy: 0.7296 - val_loss: 0.9951 - val_accuracy: 0.6325\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6666 - accuracy: 0.7111 - val_loss: 0.9528 - val_accuracy: 0.6154\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6525 - accuracy: 0.7370 - val_loss: 0.9948 - val_accuracy: 0.6154\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6776 - accuracy: 0.7222 - val_loss: 0.9737 - val_accuracy: 0.6239\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6551 - accuracy: 0.7222 - val_loss: 0.9433 - val_accuracy: 0.6325\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6549 - accuracy: 0.7259 - val_loss: 0.9473 - val_accuracy: 0.6410\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6519 - accuracy: 0.7222 - val_loss: 0.9543 - val_accuracy: 0.6496\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6608 - accuracy: 0.7148 - val_loss: 1.0349 - val_accuracy: 0.6325\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7819 - accuracy: 0.7037 - val_loss: 0.9784 - val_accuracy: 0.6410\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6612 - accuracy: 0.7222 - val_loss: 1.0152 - val_accuracy: 0.6068\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7073 - accuracy: 0.7074 - val_loss: 1.0445 - val_accuracy: 0.5812\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6705 - accuracy: 0.7111 - val_loss: 1.1484 - val_accuracy: 0.5983\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7540 - accuracy: 0.6889 - val_loss: 1.0477 - val_accuracy: 0.5812\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 71.04%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.36788460e-01, 1.56677300e-01, 7.06534270e-01],\n",
       "       [2.58510400e-04, 2.29230870e-03, 9.97449100e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [8.08099800e-01, 1.57598400e-01, 3.43017840e-02],\n",
       "       [5.32192850e-02, 9.09106400e-01, 3.76744050e-02],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [7.14723840e-02, 6.93003700e-01, 2.35523980e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [2.36267240e-02, 9.51616240e-02, 8.81211640e-01],\n",
       "       [1.18916640e-02, 5.16688500e-03, 9.82941450e-01],\n",
       "       [5.24063600e-01, 4.48216530e-01, 2.77199020e-02],\n",
       "       [3.85296640e-01, 3.30152570e-04, 6.14373200e-01],\n",
       "       [1.17519476e-01, 2.02449370e-01, 6.80031240e-01],\n",
       "       [1.87709470e-01, 1.86848540e-01, 6.25441970e-01],\n",
       "       [2.07614730e-01, 2.25955840e-01, 5.66429440e-01],\n",
       "       [7.28507200e-02, 1.12122700e-02, 9.15937000e-01],\n",
       "       [3.41856630e-01, 4.04747070e-01, 2.53396330e-01],\n",
       "       [2.13231290e-05, 8.67062600e-03, 9.91308030e-01],\n",
       "       [2.34120900e-02, 3.43882100e-01, 6.32705750e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.36788460e-01, 1.56677300e-01, 7.06534270e-01],\n",
       "       [1.05993830e-01, 1.51452200e-02, 8.78860950e-01],\n",
       "       [7.28507200e-02, 1.12122700e-02, 9.15937000e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [3.41856630e-01, 4.04747070e-01, 2.53396330e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [3.38905050e-05, 5.48076400e-07, 9.99965550e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.36788460e-01, 1.56677300e-01, 7.06534270e-01],\n",
       "       [5.90018700e-01, 3.92079350e-01, 1.79019810e-02],\n",
       "       [7.28507200e-02, 1.12122700e-02, 9.15937000e-01],\n",
       "       [4.08348050e-01, 5.81091300e-01, 1.05606970e-02],\n",
       "       [6.47400700e-01, 8.82915500e-02, 2.64307770e-01],\n",
       "       [2.02996970e-02, 4.25910580e-02, 9.37109230e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [5.38208250e-01, 3.84908170e-01, 7.68836100e-02],\n",
       "       [1.18916640e-02, 5.16688500e-03, 9.82941450e-01],\n",
       "       [2.07614730e-01, 2.25955840e-01, 5.66429440e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.78321690e-01, 7.46347070e-01, 7.53312400e-02],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [2.58510400e-04, 2.29230870e-03, 9.97449100e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.17519476e-01, 2.02449370e-01, 6.80031240e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.15536580e-01, 7.19097800e-01, 6.53656000e-02],\n",
       "       [2.58510400e-04, 2.29230870e-03, 9.97449100e-01],\n",
       "       [7.28507200e-02, 1.12122700e-02, 9.15937000e-01],\n",
       "       [4.57193000e-01, 4.25389000e-01, 1.17418010e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.49746650e-02, 1.57240330e-01, 8.17785000e-01],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [3.11938880e-01, 5.16961460e-01, 1.71099720e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.95437740e-02, 3.61846000e-01, 6.18610260e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [9.39128900e-01, 5.90081140e-02, 1.86300110e-03],\n",
       "       [9.40574940e-01, 8.44278000e-04, 5.85807520e-02],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [7.83461100e-03, 9.91602100e-01, 5.63210900e-04],\n",
       "       [2.46250580e-01, 6.56485200e-01, 9.72642000e-02],\n",
       "       [1.57438520e-01, 8.40797100e-01, 1.76432180e-03],\n",
       "       [2.45513980e-01, 8.93720200e-04, 7.53592300e-01],\n",
       "       [3.55593860e-02, 7.76625800e-02, 8.86778060e-01],\n",
       "       [1.35411860e-03, 9.98443070e-01, 2.02777620e-04],\n",
       "       [5.43794040e-02, 3.74191880e-01, 5.71428700e-01],\n",
       "       [9.55248850e-02, 7.32413350e-01, 1.72061670e-01],\n",
       "       [6.54258800e-04, 2.06301220e-03, 9.97282740e-01],\n",
       "       [9.28758200e-02, 7.98036400e-01, 1.09087795e-01],\n",
       "       [2.34120900e-02, 3.43882100e-01, 6.32705750e-01],\n",
       "       [9.74476900e-01, 1.28493990e-02, 1.26736380e-02],\n",
       "       [2.71873000e-01, 7.17929600e-01, 1.01973960e-02],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [6.10739240e-06, 2.35493620e-07, 9.99993700e-01],\n",
       "       [5.61770860e-01, 4.38065350e-01, 1.63742170e-04],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [1.87709470e-01, 1.86848540e-01, 6.25441970e-01],\n",
       "       [6.12741700e-01, 3.41895160e-01, 4.53631300e-02],\n",
       "       [1.36788460e-01, 1.56677300e-01, 7.06534270e-01],\n",
       "       [2.46250580e-01, 6.56485200e-01, 9.72642000e-02],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [3.11938880e-01, 5.16961460e-01, 1.71099720e-01],\n",
       "       [5.23032960e-01, 3.38179950e-01, 1.38787180e-01],\n",
       "       [4.71365820e-02, 9.52000440e-01, 8.62951400e-04],\n",
       "       [1.95437740e-02, 3.61846000e-01, 6.18610260e-01],\n",
       "       [4.77125800e-01, 4.42857330e-01, 8.00169200e-02],\n",
       "       [7.01487700e-01, 2.89887250e-01, 8.62501500e-03],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.77565350e-04, 1.97228160e-02, 9.80099600e-01],\n",
       "       [3.38905050e-05, 5.48076400e-07, 9.99965550e-01],\n",
       "       [1.17519476e-01, 2.02449370e-01, 6.80031240e-01],\n",
       "       [9.40391350e-02, 7.39142360e-01, 1.66818510e-01],\n",
       "       [5.90018700e-01, 3.92079350e-01, 1.79019810e-02],\n",
       "       [1.63038770e-03, 1.69327720e-02, 9.81436900e-01],\n",
       "       [5.23032960e-01, 3.38179950e-01, 1.38787180e-01],\n",
       "       [9.39128900e-01, 5.90081140e-02, 1.86300110e-03],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [5.90018700e-01, 3.92079350e-01, 1.79019810e-02],\n",
       "       [2.46250580e-01, 6.56485200e-01, 9.72642000e-02],\n",
       "       [4.87148970e-01, 1.45918260e-01, 3.66932720e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [1.87709470e-01, 1.86848540e-01, 6.25441970e-01],\n",
       "       [2.00001850e-01, 7.86191400e-01, 1.38067360e-02],\n",
       "       [7.01487700e-01, 2.89887250e-01, 8.62501500e-03],\n",
       "       [2.97093330e-01, 5.63622240e-01, 1.39284450e-01],\n",
       "       [9.42912100e-01, 5.62817040e-02, 8.06152000e-04],\n",
       "       [4.08348050e-01, 5.81091300e-01, 1.05606970e-02],\n",
       "       [4.71365820e-02, 9.52000440e-01, 8.62951400e-04]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400832785448169"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400832785448169"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS249     2\n",
       "1         NRS188     1\n",
       "2         NRS232     2\n",
       "3          NY439     2\n",
       "4           GA27     2\n",
       "..           ...   ...\n",
       "112       SR3569     0\n",
       "113       NRS204     0\n",
       "114       NRS203     0\n",
       "115     CFBRSa25     1\n",
       "116  CFBREBSa131     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 436us/step - loss: 17.0411 - accuracy: 0.3593 - val_loss: 8.0796 - val_accuracy: 0.3504\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 13.7429 - accuracy: 0.3481 - val_loss: 5.9167 - val_accuracy: 0.3077\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 10.6352 - accuracy: 0.3259 - val_loss: 4.6846 - val_accuracy: 0.2991\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 9.2271 - accuracy: 0.3667 - val_loss: 3.8483 - val_accuracy: 0.3761\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 7.2309 - accuracy: 0.3556 - val_loss: 2.9778 - val_accuracy: 0.3932\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 5.2570 - accuracy: 0.4222 - val_loss: 2.4321 - val_accuracy: 0.4017\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 3.4122 - accuracy: 0.4148 - val_loss: 1.6448 - val_accuracy: 0.4103\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.8021 - accuracy: 0.4000 - val_loss: 1.7977 - val_accuracy: 0.4188\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.9156 - accuracy: 0.4148 - val_loss: 2.3189 - val_accuracy: 0.4188\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 2.0462 - accuracy: 0.3815 - val_loss: 2.2381 - val_accuracy: 0.4188\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.8646 - accuracy: 0.4481 - val_loss: 1.8300 - val_accuracy: 0.4359\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.5390 - accuracy: 0.4481 - val_loss: 1.3990 - val_accuracy: 0.3761\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.3205 - accuracy: 0.4444 - val_loss: 1.2843 - val_accuracy: 0.4188\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.3048 - accuracy: 0.4481 - val_loss: 1.3743 - val_accuracy: 0.4017\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.2853 - accuracy: 0.4630 - val_loss: 1.3850 - val_accuracy: 0.4188\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.2581 - accuracy: 0.4556 - val_loss: 1.2681 - val_accuracy: 0.4274\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.1917 - accuracy: 0.4704 - val_loss: 1.1826 - val_accuracy: 0.4530\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.1719 - accuracy: 0.4704 - val_loss: 1.1745 - val_accuracy: 0.4359\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.1484 - accuracy: 0.4778 - val_loss: 1.1880 - val_accuracy: 0.4359\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.1417 - accuracy: 0.4815 - val_loss: 1.1683 - val_accuracy: 0.4274\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.1248 - accuracy: 0.4778 - val_loss: 1.1556 - val_accuracy: 0.3932\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.1150 - accuracy: 0.4815 - val_loss: 1.1557 - val_accuracy: 0.4359\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.1012 - accuracy: 0.5000 - val_loss: 1.1372 - val_accuracy: 0.4359\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0917 - accuracy: 0.5074 - val_loss: 1.1239 - val_accuracy: 0.4274\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0814 - accuracy: 0.5000 - val_loss: 1.1152 - val_accuracy: 0.4274\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0784 - accuracy: 0.5000 - val_loss: 1.1208 - val_accuracy: 0.4359\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.0681 - accuracy: 0.5185 - val_loss: 1.1171 - val_accuracy: 0.4444\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0683 - accuracy: 0.5185 - val_loss: 1.1261 - val_accuracy: 0.4444\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0566 - accuracy: 0.5222 - val_loss: 1.1107 - val_accuracy: 0.4359\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0517 - accuracy: 0.5148 - val_loss: 1.1127 - val_accuracy: 0.4444\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.0460 - accuracy: 0.5222 - val_loss: 1.1001 - val_accuracy: 0.4444\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 1.0402 - accuracy: 0.4926 - val_loss: 1.1088 - val_accuracy: 0.4274\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.0546 - accuracy: 0.4778 - val_loss: 1.1167 - val_accuracy: 0.4444\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0326 - accuracy: 0.5222 - val_loss: 1.1151 - val_accuracy: 0.4103\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0345 - accuracy: 0.5148 - val_loss: 1.1131 - val_accuracy: 0.4530\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0237 - accuracy: 0.5259 - val_loss: 1.0734 - val_accuracy: 0.4615\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0256 - accuracy: 0.5296 - val_loss: 1.0733 - val_accuracy: 0.4530\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.56 - 0s 75us/step - loss: 1.0107 - accuracy: 0.5222 - val_loss: 1.0847 - val_accuracy: 0.4444\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0374 - accuracy: 0.5259 - val_loss: 1.1265 - val_accuracy: 0.4188\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0233 - accuracy: 0.5259 - val_loss: 1.0620 - val_accuracy: 0.4615\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0286 - accuracy: 0.5148 - val_loss: 1.1776 - val_accuracy: 0.4359\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 1.0439 - accuracy: 0.5222 - val_loss: 1.1553 - val_accuracy: 0.4188\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0137 - accuracy: 0.5333 - val_loss: 1.0648 - val_accuracy: 0.4444\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0120 - accuracy: 0.5000 - val_loss: 1.0964 - val_accuracy: 0.4359\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0427 - accuracy: 0.4926 - val_loss: 1.1516 - val_accuracy: 0.4701\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0016 - accuracy: 0.5444 - val_loss: 1.1914 - val_accuracy: 0.4274\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0460 - accuracy: 0.5333 - val_loss: 1.1354 - val_accuracy: 0.4359\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0206 - accuracy: 0.5148 - val_loss: 1.1233 - val_accuracy: 0.4530\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0379 - accuracy: 0.5222 - val_loss: 1.1678 - val_accuracy: 0.4701\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0192 - accuracy: 0.5407 - val_loss: 1.1367 - val_accuracy: 0.4359\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0102 - accuracy: 0.5296 - val_loss: 1.0685 - val_accuracy: 0.4615\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9938 - accuracy: 0.5185 - val_loss: 1.0728 - val_accuracy: 0.4444\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9897 - accuracy: 0.5148 - val_loss: 1.0583 - val_accuracy: 0.4530\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9636 - accuracy: 0.5407 - val_loss: 1.0624 - val_accuracy: 0.4359\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9634 - accuracy: 0.5593 - val_loss: 1.0834 - val_accuracy: 0.4359\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9609 - accuracy: 0.5481 - val_loss: 1.0406 - val_accuracy: 0.4444\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9488 - accuracy: 0.5519 - val_loss: 1.0278 - val_accuracy: 0.4615\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9581 - accuracy: 0.5444 - val_loss: 1.1222 - val_accuracy: 0.4444\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9813 - accuracy: 0.5630 - val_loss: 1.0813 - val_accuracy: 0.4359\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9477 - accuracy: 0.5630 - val_loss: 1.0155 - val_accuracy: 0.4786\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9548 - accuracy: 0.5444 - val_loss: 1.0315 - val_accuracy: 0.4615\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9856 - accuracy: 0.5259 - val_loss: 1.0850 - val_accuracy: 0.4530\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9582 - accuracy: 0.5444 - val_loss: 1.1390 - val_accuracy: 0.4444\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9649 - accuracy: 0.5593 - val_loss: 1.0480 - val_accuracy: 0.4359\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9588 - accuracy: 0.5333 - val_loss: 1.1432 - val_accuracy: 0.4615\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.1219 - accuracy: 0.5667 - val_loss: 1.6490 - val_accuracy: 0.5385\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.2404 - accuracy: 0.5778 - val_loss: 1.4726 - val_accuracy: 0.4786\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.1123 - accuracy: 0.5630 - val_loss: 1.2484 - val_accuracy: 0.4701\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9918 - accuracy: 0.5630 - val_loss: 1.0600 - val_accuracy: 0.4615\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9606 - accuracy: 0.5556 - val_loss: 1.0608 - val_accuracy: 0.4359\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9238 - accuracy: 0.5630 - val_loss: 1.0817 - val_accuracy: 0.4274\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9418 - accuracy: 0.5556 - val_loss: 1.0758 - val_accuracy: 0.4444\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9352 - accuracy: 0.5593 - val_loss: 1.0232 - val_accuracy: 0.4957\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9249 - accuracy: 0.5407 - val_loss: 1.0458 - val_accuracy: 0.4530\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9464 - accuracy: 0.5704 - val_loss: 1.1750 - val_accuracy: 0.4786\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9641 - accuracy: 0.5852 - val_loss: 1.0551 - val_accuracy: 0.4957\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9446 - accuracy: 0.5556 - val_loss: 1.0442 - val_accuracy: 0.4615\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9366 - accuracy: 0.5630 - val_loss: 1.0437 - val_accuracy: 0.4530\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9190 - accuracy: 0.5593 - val_loss: 1.0320 - val_accuracy: 0.4530\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9180 - accuracy: 0.5667 - val_loss: 1.0602 - val_accuracy: 0.4786\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9119 - accuracy: 0.5815 - val_loss: 0.9929 - val_accuracy: 0.4957\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9419 - accuracy: 0.5259 - val_loss: 1.0595 - val_accuracy: 0.4701\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9394 - accuracy: 0.5444 - val_loss: 1.0053 - val_accuracy: 0.4701\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8964 - accuracy: 0.5593 - val_loss: 1.0379 - val_accuracy: 0.4957\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9126 - accuracy: 0.5852 - val_loss: 1.0550 - val_accuracy: 0.4786\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8987 - accuracy: 0.5667 - val_loss: 1.0011 - val_accuracy: 0.4530\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9627 - accuracy: 0.5296 - val_loss: 1.0639 - val_accuracy: 0.4530\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9291 - accuracy: 0.5667 - val_loss: 1.1168 - val_accuracy: 0.4786\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9183 - accuracy: 0.5889 - val_loss: 1.0399 - val_accuracy: 0.4701\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8822 - accuracy: 0.5667 - val_loss: 1.0050 - val_accuracy: 0.4530\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9731 - accuracy: 0.5370 - val_loss: 1.1312 - val_accuracy: 0.4872\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9723 - accuracy: 0.5815 - val_loss: 1.2738 - val_accuracy: 0.4786\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9951 - accuracy: 0.5889 - val_loss: 1.2133 - val_accuracy: 0.4786\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9461 - accuracy: 0.5815 - val_loss: 1.0524 - val_accuracy: 0.4701\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8971 - accuracy: 0.5593 - val_loss: 1.0159 - val_accuracy: 0.4701\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9430 - accuracy: 0.5778 - val_loss: 1.2497 - val_accuracy: 0.5299\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.0657 - accuracy: 0.5852 - val_loss: 1.4107 - val_accuracy: 0.5043\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0608 - accuracy: 0.5704 - val_loss: 1.3123 - val_accuracy: 0.4701\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9923 - accuracy: 0.5704 - val_loss: 1.1100 - val_accuracy: 0.4701\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9100 - accuracy: 0.5704 - val_loss: 1.0293 - val_accuracy: 0.4530\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9278 - accuracy: 0.5630 - val_loss: 1.0982 - val_accuracy: 0.4786\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9277 - accuracy: 0.5889 - val_loss: 1.1752 - val_accuracy: 0.4957\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9378 - accuracy: 0.5852 - val_loss: 1.0724 - val_accuracy: 0.5043\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8786 - accuracy: 0.5778 - val_loss: 0.9989 - val_accuracy: 0.4701\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0470 - accuracy: 0.5741 - val_loss: 1.0003 - val_accuracy: 0.4615\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8697 - accuracy: 0.5741 - val_loss: 1.0672 - val_accuracy: 0.4957\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8850 - accuracy: 0.5852 - val_loss: 0.9954 - val_accuracy: 0.4701\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8658 - accuracy: 0.5778 - val_loss: 0.9866 - val_accuracy: 0.4786\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8659 - accuracy: 0.5778 - val_loss: 1.0205 - val_accuracy: 0.4872\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8691 - accuracy: 0.5889 - val_loss: 1.0029 - val_accuracy: 0.4872\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8699 - accuracy: 0.5926 - val_loss: 0.9896 - val_accuracy: 0.5043\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 68us/step - loss: 0.8691 - accuracy: 0.5741 - val_loss: 1.0162 - val_accuracy: 0.5128\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8651 - accuracy: 0.5852 - val_loss: 0.9838 - val_accuracy: 0.5128\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 0.9812 - val_accuracy: 0.5128\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8879 - accuracy: 0.5667 - val_loss: 1.0324 - val_accuracy: 0.5043\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8922 - accuracy: 0.5889 - val_loss: 1.1744 - val_accuracy: 0.5128\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9162 - accuracy: 0.5926 - val_loss: 1.0504 - val_accuracy: 0.5043\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8631 - accuracy: 0.5630 - val_loss: 0.9979 - val_accuracy: 0.4872\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9103 - accuracy: 0.5815 - val_loss: 1.1008 - val_accuracy: 0.5043\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8839 - accuracy: 0.5704 - val_loss: 1.0074 - val_accuracy: 0.4786\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8653 - accuracy: 0.5741 - val_loss: 1.0020 - val_accuracy: 0.4530\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8745 - accuracy: 0.5741 - val_loss: 1.0423 - val_accuracy: 0.4701\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8666 - accuracy: 0.5852 - val_loss: 0.9911 - val_accuracy: 0.4786\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8628 - accuracy: 0.5778 - val_loss: 0.9922 - val_accuracy: 0.4957\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8528 - accuracy: 0.5852 - val_loss: 0.9797 - val_accuracy: 0.5299\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8504 - accuracy: 0.5852 - val_loss: 0.9978 - val_accuracy: 0.5128\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8516 - accuracy: 0.5852 - val_loss: 0.9920 - val_accuracy: 0.5043\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8514 - accuracy: 0.5667 - val_loss: 0.9734 - val_accuracy: 0.5299\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8533 - accuracy: 0.5926 - val_loss: 0.9746 - val_accuracy: 0.5043\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8629 - accuracy: 0.5630 - val_loss: 1.0147 - val_accuracy: 0.5128\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8681 - accuracy: 0.5926 - val_loss: 1.0923 - val_accuracy: 0.5128\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8850 - accuracy: 0.5926 - val_loss: 1.0059 - val_accuracy: 0.4957\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8437 - accuracy: 0.5926 - val_loss: 0.9777 - val_accuracy: 0.5214\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8476 - accuracy: 0.5852 - val_loss: 1.0053 - val_accuracy: 0.4957\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8483 - accuracy: 0.5926 - val_loss: 0.9946 - val_accuracy: 0.4872\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8511 - accuracy: 0.5852 - val_loss: 0.9937 - val_accuracy: 0.4872\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8417 - accuracy: 0.5889 - val_loss: 0.9886 - val_accuracy: 0.4872\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8418 - accuracy: 0.5889 - val_loss: 0.9798 - val_accuracy: 0.4872\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8416 - accuracy: 0.5852 - val_loss: 0.9871 - val_accuracy: 0.5043\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8386 - accuracy: 0.6074 - val_loss: 0.9774 - val_accuracy: 0.5128\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8476 - accuracy: 0.6000 - val_loss: 0.9944 - val_accuracy: 0.5128\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8420 - accuracy: 0.5963 - val_loss: 0.9748 - val_accuracy: 0.4872\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8365 - accuracy: 0.5852 - val_loss: 0.9759 - val_accuracy: 0.4872\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8361 - accuracy: 0.5852 - val_loss: 0.9875 - val_accuracy: 0.4872\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8412 - accuracy: 0.5963 - val_loss: 1.0052 - val_accuracy: 0.4786\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8393 - accuracy: 0.5926 - val_loss: 0.9826 - val_accuracy: 0.4872\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8376 - accuracy: 0.5852 - val_loss: 0.9868 - val_accuracy: 0.4957\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8372 - accuracy: 0.5963 - val_loss: 0.9789 - val_accuracy: 0.4957\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8344 - accuracy: 0.5852 - val_loss: 0.9785 - val_accuracy: 0.5043\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8365 - accuracy: 0.6000 - val_loss: 0.9986 - val_accuracy: 0.5128\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.8401 - accuracy: 0.6000 - val_loss: 0.9674 - val_accuracy: 0.5128\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8413 - accuracy: 0.5963 - val_loss: 1.0517 - val_accuracy: 0.5299\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8669 - accuracy: 0.5963 - val_loss: 1.0428 - val_accuracy: 0.5214\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8436 - accuracy: 0.6037 - val_loss: 0.9717 - val_accuracy: 0.5128\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8537 - accuracy: 0.5926 - val_loss: 1.1186 - val_accuracy: 0.5726\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9121 - accuracy: 0.6037 - val_loss: 1.0889 - val_accuracy: 0.5214\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8700 - accuracy: 0.5889 - val_loss: 1.0222 - val_accuracy: 0.4872\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9015 - accuracy: 0.6037 - val_loss: 1.3282 - val_accuracy: 0.5556\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9486 - accuracy: 0.6148 - val_loss: 1.0569 - val_accuracy: 0.4872\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9027 - accuracy: 0.5556 - val_loss: 1.0440 - val_accuracy: 0.4444\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9038 - accuracy: 0.5778 - val_loss: 1.2096 - val_accuracy: 0.5470\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9241 - accuracy: 0.5963 - val_loss: 1.2004 - val_accuracy: 0.4701\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9241 - accuracy: 0.5741 - val_loss: 1.1161 - val_accuracy: 0.4957\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8791 - accuracy: 0.6000 - val_loss: 1.0358 - val_accuracy: 0.4530\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8796 - accuracy: 0.5741 - val_loss: 1.0214 - val_accuracy: 0.4957\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8527 - accuracy: 0.6074 - val_loss: 1.0662 - val_accuracy: 0.4957\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8442 - accuracy: 0.5963 - val_loss: 0.9780 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8634 - accuracy: 0.6037 - val_loss: 1.0310 - val_accuracy: 0.5128\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8504 - accuracy: 0.5963 - val_loss: 1.0406 - val_accuracy: 0.5043\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8371 - accuracy: 0.5926 - val_loss: 0.9762 - val_accuracy: 0.4957\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8203 - accuracy: 0.5963 - val_loss: 0.9871 - val_accuracy: 0.4957\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8249 - accuracy: 0.5889 - val_loss: 1.0049 - val_accuracy: 0.4872\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8214 - accuracy: 0.5963 - val_loss: 0.9748 - val_accuracy: 0.4957\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8168 - accuracy: 0.5852 - val_loss: 0.9874 - val_accuracy: 0.5043\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8212 - accuracy: 0.6074 - val_loss: 0.9812 - val_accuracy: 0.5043\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8175 - accuracy: 0.5926 - val_loss: 0.9858 - val_accuracy: 0.5128\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8303 - accuracy: 0.6259 - val_loss: 1.0078 - val_accuracy: 0.5128\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8187 - accuracy: 0.6111 - val_loss: 0.9743 - val_accuracy: 0.5043\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8162 - accuracy: 0.6111 - val_loss: 1.0040 - val_accuracy: 0.5214\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8242 - accuracy: 0.6185 - val_loss: 0.9873 - val_accuracy: 0.5214\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8146 - accuracy: 0.5963 - val_loss: 0.9798 - val_accuracy: 0.4957\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8134 - accuracy: 0.6000 - val_loss: 0.9794 - val_accuracy: 0.4957\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8169 - accuracy: 0.6148 - val_loss: 0.9737 - val_accuracy: 0.5299\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8137 - accuracy: 0.6037 - val_loss: 0.9725 - val_accuracy: 0.5385\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8142 - accuracy: 0.6259 - val_loss: 0.9954 - val_accuracy: 0.5641\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8202 - accuracy: 0.6185 - val_loss: 0.9892 - val_accuracy: 0.5385\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8126 - accuracy: 0.6111 - val_loss: 0.9694 - val_accuracy: 0.5385\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8180 - accuracy: 0.6259 - val_loss: 1.0198 - val_accuracy: 0.5214\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8279 - accuracy: 0.6185 - val_loss: 1.0152 - val_accuracy: 0.4957\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8189 - accuracy: 0.6111 - val_loss: 0.9880 - val_accuracy: 0.5299\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8159 - accuracy: 0.6296 - val_loss: 1.0237 - val_accuracy: 0.5214\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8323 - accuracy: 0.6111 - val_loss: 1.0059 - val_accuracy: 0.4957\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8149 - accuracy: 0.5852 - val_loss: 0.9794 - val_accuracy: 0.5556\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8301 - accuracy: 0.6333 - val_loss: 1.0447 - val_accuracy: 0.5470\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8239 - accuracy: 0.6407 - val_loss: 0.9811 - val_accuracy: 0.5043\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8135 - accuracy: 0.5889 - val_loss: 0.9766 - val_accuracy: 0.5299\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8089 - accuracy: 0.6111 - val_loss: 0.9951 - val_accuracy: 0.5214\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8149 - accuracy: 0.6111 - val_loss: 0.9907 - val_accuracy: 0.4957\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8033 - accuracy: 0.6296 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8112 - accuracy: 0.6370 - val_loss: 1.0040 - val_accuracy: 0.5556\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8120 - accuracy: 0.6333 - val_loss: 0.9844 - val_accuracy: 0.5043\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8176 - accuracy: 0.5815 - val_loss: 0.9934 - val_accuracy: 0.5299\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8296 - accuracy: 0.6333 - val_loss: 1.0360 - val_accuracy: 0.5299\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8126 - accuracy: 0.6074 - val_loss: 0.9815 - val_accuracy: 0.5214\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8505 - accuracy: 0.6000 - val_loss: 1.0477 - val_accuracy: 0.5299\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8058 - accuracy: 0.6111 - val_loss: 0.9739 - val_accuracy: 0.5128\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8175 - accuracy: 0.5852 - val_loss: 1.0643 - val_accuracy: 0.5556\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8547 - accuracy: 0.6259 - val_loss: 1.0941 - val_accuracy: 0.5556\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8323 - accuracy: 0.6222 - val_loss: 0.9732 - val_accuracy: 0.5043\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8179 - accuracy: 0.6037 - val_loss: 1.0285 - val_accuracy: 0.5385\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8321 - accuracy: 0.6370 - val_loss: 1.0237 - val_accuracy: 0.5299\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8155 - accuracy: 0.6074 - val_loss: 1.0090 - val_accuracy: 0.5556\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9057 - accuracy: 0.6148 - val_loss: 1.2767 - val_accuracy: 0.5299\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9723 - accuracy: 0.6111 - val_loss: 1.0443 - val_accuracy: 0.4957\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8697 - accuracy: 0.5926 - val_loss: 1.1606 - val_accuracy: 0.5128\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9227 - accuracy: 0.5963 - val_loss: 1.2494 - val_accuracy: 0.5641\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9043 - accuracy: 0.6259 - val_loss: 1.0706 - val_accuracy: 0.5299\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8540 - accuracy: 0.5815 - val_loss: 1.0048 - val_accuracy: 0.5214\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9053 - accuracy: 0.6259 - val_loss: 1.4217 - val_accuracy: 0.5556\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0037 - accuracy: 0.6148 - val_loss: 1.3062 - val_accuracy: 0.4957\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9217 - accuracy: 0.5889 - val_loss: 1.0867 - val_accuracy: 0.4957\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8274 - accuracy: 0.6074 - val_loss: 1.0575 - val_accuracy: 0.4530\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9091 - accuracy: 0.5741 - val_loss: 1.2349 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9153 - accuracy: 0.6222 - val_loss: 1.3270 - val_accuracy: 0.5043\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9483 - accuracy: 0.5852 - val_loss: 1.1572 - val_accuracy: 0.5299\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8232 - accuracy: 0.6148 - val_loss: 1.0640 - val_accuracy: 0.4530\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8992 - accuracy: 0.5815 - val_loss: 1.1689 - val_accuracy: 0.5470\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8702 - accuracy: 0.6222 - val_loss: 1.0946 - val_accuracy: 0.5043\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8422 - accuracy: 0.5926 - val_loss: 0.9820 - val_accuracy: 0.5214\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7952 - accuracy: 0.6259 - val_loss: 0.9853 - val_accuracy: 0.5470\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8012 - accuracy: 0.6296 - val_loss: 0.9804 - val_accuracy: 0.5556\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7923 - accuracy: 0.6444 - val_loss: 0.9807 - val_accuracy: 0.5299\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7955 - accuracy: 0.6185 - val_loss: 0.9823 - val_accuracy: 0.5299\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7976 - accuracy: 0.6370 - val_loss: 0.9790 - val_accuracy: 0.5299\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7930 - accuracy: 0.6222 - val_loss: 0.9713 - val_accuracy: 0.5385\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7953 - accuracy: 0.6333 - val_loss: 0.9953 - val_accuracy: 0.5385\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7982 - accuracy: 0.6481 - val_loss: 0.9867 - val_accuracy: 0.5556\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7967 - accuracy: 0.6222 - val_loss: 0.9784 - val_accuracy: 0.5556\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7910 - accuracy: 0.6519 - val_loss: 0.9961 - val_accuracy: 0.5726\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7944 - accuracy: 0.6370 - val_loss: 0.9824 - val_accuracy: 0.5299\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7948 - accuracy: 0.6296 - val_loss: 0.9782 - val_accuracy: 0.5556\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7900 - accuracy: 0.6407 - val_loss: 0.9970 - val_accuracy: 0.5726\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7997 - accuracy: 0.6556 - val_loss: 0.9852 - val_accuracy: 0.5812\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7915 - accuracy: 0.6259 - val_loss: 0.9831 - val_accuracy: 0.4701\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7948 - accuracy: 0.6148 - val_loss: 1.0017 - val_accuracy: 0.5812\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8026 - accuracy: 0.6704 - val_loss: 0.9833 - val_accuracy: 0.5556\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8087 - accuracy: 0.6296 - val_loss: 1.0018 - val_accuracy: 0.5641\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8272 - accuracy: 0.6444 - val_loss: 1.1492 - val_accuracy: 0.5726\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8385 - accuracy: 0.6259 - val_loss: 0.9785 - val_accuracy: 0.5128\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8017 - accuracy: 0.5926 - val_loss: 0.9825 - val_accuracy: 0.5299\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7938 - accuracy: 0.6222 - val_loss: 1.0030 - val_accuracy: 0.5214\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7902 - accuracy: 0.6370 - val_loss: 0.9757 - val_accuracy: 0.5299\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7936 - accuracy: 0.6222 - val_loss: 1.0005 - val_accuracy: 0.5299\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7917 - accuracy: 0.6222 - val_loss: 0.9802 - val_accuracy: 0.5128\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7912 - accuracy: 0.6259 - val_loss: 0.9678 - val_accuracy: 0.5641\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7907 - accuracy: 0.6444 - val_loss: 0.9751 - val_accuracy: 0.5641\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7927 - accuracy: 0.6370 - val_loss: 0.9706 - val_accuracy: 0.5641\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7911 - accuracy: 0.6519 - val_loss: 0.9651 - val_accuracy: 0.5556\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7858 - accuracy: 0.6407 - val_loss: 0.9931 - val_accuracy: 0.5812\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7924 - accuracy: 0.6556 - val_loss: 0.9869 - val_accuracy: 0.5812\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7851 - accuracy: 0.6519 - val_loss: 0.9688 - val_accuracy: 0.5641\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7885 - accuracy: 0.6333 - val_loss: 0.9796 - val_accuracy: 0.5812\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7880 - accuracy: 0.6593 - val_loss: 0.9800 - val_accuracy: 0.5470\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7860 - accuracy: 0.6444 - val_loss: 1.0184 - val_accuracy: 0.5556\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7977 - accuracy: 0.6407 - val_loss: 0.9796 - val_accuracy: 0.5641\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7820 - accuracy: 0.6444 - val_loss: 0.9671 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8037 - accuracy: 0.6556 - val_loss: 1.0312 - val_accuracy: 0.5897\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7840 - accuracy: 0.6519 - val_loss: 0.9751 - val_accuracy: 0.5385\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8100 - accuracy: 0.6296 - val_loss: 1.0290 - val_accuracy: 0.5556\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7932 - accuracy: 0.6259 - val_loss: 0.9753 - val_accuracy: 0.5641\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7876 - accuracy: 0.6556 - val_loss: 1.0387 - val_accuracy: 0.5897\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7944 - accuracy: 0.6556 - val_loss: 0.9745 - val_accuracy: 0.5385\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7842 - accuracy: 0.6333 - val_loss: 0.9778 - val_accuracy: 0.5385\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7842 - accuracy: 0.6444 - val_loss: 0.9957 - val_accuracy: 0.5556\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7846 - accuracy: 0.6407 - val_loss: 0.9807 - val_accuracy: 0.5556\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7834 - accuracy: 0.6333 - val_loss: 0.9776 - val_accuracy: 0.5385\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7839 - accuracy: 0.6296 - val_loss: 0.9807 - val_accuracy: 0.5299\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7847 - accuracy: 0.6185 - val_loss: 0.9870 - val_accuracy: 0.5470\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7848 - accuracy: 0.6444 - val_loss: 1.0079 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7855 - accuracy: 0.6481 - val_loss: 0.9667 - val_accuracy: 0.5556\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7904 - accuracy: 0.6222 - val_loss: 1.0273 - val_accuracy: 0.5897\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8187 - accuracy: 0.6481 - val_loss: 1.0610 - val_accuracy: 0.5983\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7922 - accuracy: 0.6519 - val_loss: 0.9685 - val_accuracy: 0.5556\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7956 - accuracy: 0.6222 - val_loss: 1.0059 - val_accuracy: 0.5556\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8036 - accuracy: 0.6519 - val_loss: 1.0178 - val_accuracy: 0.5556\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7800 - accuracy: 0.6889 - val_loss: 0.9626 - val_accuracy: 0.5812\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7776 - accuracy: 0.6778 - val_loss: 0.9877 - val_accuracy: 0.6068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7779 - accuracy: 0.6852 - val_loss: 0.9671 - val_accuracy: 0.6068\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7768 - accuracy: 0.6926 - val_loss: 0.9811 - val_accuracy: 0.5812\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7805 - accuracy: 0.6778 - val_loss: 0.9819 - val_accuracy: 0.5641\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7767 - accuracy: 0.6778 - val_loss: 0.9742 - val_accuracy: 0.5897\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7783 - accuracy: 0.6704 - val_loss: 0.9789 - val_accuracy: 0.6068\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.7807 - accuracy: 0.6741 - val_loss: 0.9694 - val_accuracy: 0.5812\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7749 - accuracy: 0.6741 - val_loss: 0.9702 - val_accuracy: 0.6154\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7766 - accuracy: 0.6926 - val_loss: 0.9772 - val_accuracy: 0.6154\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7759 - accuracy: 0.6963 - val_loss: 0.9623 - val_accuracy: 0.5812\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7740 - accuracy: 0.6815 - val_loss: 0.9924 - val_accuracy: 0.5556\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7920 - accuracy: 0.6741 - val_loss: 0.9991 - val_accuracy: 0.5812\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7766 - accuracy: 0.6519 - val_loss: 0.9759 - val_accuracy: 0.5385\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7734 - accuracy: 0.6481 - val_loss: 1.0118 - val_accuracy: 0.6154\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7808 - accuracy: 0.6889 - val_loss: 0.9700 - val_accuracy: 0.5983\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7726 - accuracy: 0.6889 - val_loss: 0.9628 - val_accuracy: 0.6154\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7790 - accuracy: 0.6815 - val_loss: 0.9886 - val_accuracy: 0.5983\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7754 - accuracy: 0.6963 - val_loss: 0.9636 - val_accuracy: 0.6068\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8334 - accuracy: 0.6407 - val_loss: 1.0496 - val_accuracy: 0.5897\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8505 - accuracy: 0.6630 - val_loss: 1.3035 - val_accuracy: 0.5812\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8998 - accuracy: 0.6407 - val_loss: 1.1393 - val_accuracy: 0.5128\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8190 - accuracy: 0.5963 - val_loss: 0.9941 - val_accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8105 - accuracy: 0.6037 - val_loss: 1.0477 - val_accuracy: 0.5043\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8109 - accuracy: 0.6222 - val_loss: 1.0388 - val_accuracy: 0.5214\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7941 - accuracy: 0.6370 - val_loss: 0.9973 - val_accuracy: 0.5812\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7691 - accuracy: 0.6926 - val_loss: 0.9740 - val_accuracy: 0.5812\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7983 - accuracy: 0.6593 - val_loss: 0.9970 - val_accuracy: 0.5983\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7738 - accuracy: 0.6963 - val_loss: 0.9667 - val_accuracy: 0.5897\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7726 - accuracy: 0.6852 - val_loss: 0.9676 - val_accuracy: 0.5897\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7683 - accuracy: 0.6704 - val_loss: 0.9754 - val_accuracy: 0.6154\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7701 - accuracy: 0.6889 - val_loss: 0.9766 - val_accuracy: 0.6154\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7684 - accuracy: 0.6926 - val_loss: 0.9719 - val_accuracy: 0.5897\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7817 - accuracy: 0.6667 - val_loss: 0.9785 - val_accuracy: 0.5897\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7819 - accuracy: 0.6963 - val_loss: 0.9938 - val_accuracy: 0.6068\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7774 - accuracy: 0.6370 - val_loss: 0.9705 - val_accuracy: 0.5812\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7734 - accuracy: 0.6556 - val_loss: 1.0337 - val_accuracy: 0.5983\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7805 - accuracy: 0.6667 - val_loss: 0.9724 - val_accuracy: 0.5812\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8417 - accuracy: 0.6111 - val_loss: 1.0634 - val_accuracy: 0.5897\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9705 - accuracy: 0.6630 - val_loss: 1.5856 - val_accuracy: 0.5983\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0270 - accuracy: 0.6741 - val_loss: 1.4347 - val_accuracy: 0.5726\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9514 - accuracy: 0.6593 - val_loss: 1.1363 - val_accuracy: 0.5470\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8032 - accuracy: 0.6407 - val_loss: 1.0212 - val_accuracy: 0.5470\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8292 - accuracy: 0.6370 - val_loss: 1.0581 - val_accuracy: 0.6068\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7982 - accuracy: 0.6778 - val_loss: 1.0218 - val_accuracy: 0.5812\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7745 - accuracy: 0.6889 - val_loss: 1.0221 - val_accuracy: 0.5897\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8002 - accuracy: 0.6630 - val_loss: 0.9886 - val_accuracy: 0.5897\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7740 - accuracy: 0.6815 - val_loss: 1.0059 - val_accuracy: 0.5556\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7765 - accuracy: 0.6704 - val_loss: 0.9811 - val_accuracy: 0.5897\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7741 - accuracy: 0.6778 - val_loss: 0.9904 - val_accuracy: 0.5983\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7651 - accuracy: 0.6889 - val_loss: 0.9879 - val_accuracy: 0.5812\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7757 - accuracy: 0.6778 - val_loss: 0.9760 - val_accuracy: 0.5812\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7652 - accuracy: 0.6778 - val_loss: 0.9617 - val_accuracy: 0.6068\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7643 - accuracy: 0.6852 - val_loss: 0.9845 - val_accuracy: 0.6068\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7622 - accuracy: 0.6852 - val_loss: 0.9606 - val_accuracy: 0.6068\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7598 - accuracy: 0.6815 - val_loss: 0.9746 - val_accuracy: 0.6068\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7608 - accuracy: 0.6815 - val_loss: 0.9832 - val_accuracy: 0.6068\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7597 - accuracy: 0.6852 - val_loss: 0.9719 - val_accuracy: 0.5983\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.76 - 0s 69us/step - loss: 0.7614 - accuracy: 0.6852 - val_loss: 0.9745 - val_accuracy: 0.6068\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7649 - accuracy: 0.6778 - val_loss: 0.9839 - val_accuracy: 0.6154\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7851 - accuracy: 0.6963 - val_loss: 1.0242 - val_accuracy: 0.6239\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8041 - accuracy: 0.6778 - val_loss: 0.9820 - val_accuracy: 0.6154\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7836 - accuracy: 0.7037 - val_loss: 1.0024 - val_accuracy: 0.6239\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8041 - accuracy: 0.6704 - val_loss: 0.9697 - val_accuracy: 0.5983\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7943 - accuracy: 0.6778 - val_loss: 1.2742 - val_accuracy: 0.5983\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8763 - accuracy: 0.6815 - val_loss: 1.1626 - val_accuracy: 0.5983\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7991 - accuracy: 0.6333 - val_loss: 0.9868 - val_accuracy: 0.5470\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9344 - accuracy: 0.6185 - val_loss: 1.2226 - val_accuracy: 0.5983\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9163 - accuracy: 0.6630 - val_loss: 1.4392 - val_accuracy: 0.6068\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9420 - accuracy: 0.6815 - val_loss: 1.2403 - val_accuracy: 0.5726\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8383 - accuracy: 0.6593 - val_loss: 0.9745 - val_accuracy: 0.5641\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7968 - accuracy: 0.6556 - val_loss: 1.0498 - val_accuracy: 0.5726\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7983 - accuracy: 0.6593 - val_loss: 0.9993 - val_accuracy: 0.5983\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7592 - accuracy: 0.6778 - val_loss: 0.9795 - val_accuracy: 0.5812\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7612 - accuracy: 0.6667 - val_loss: 0.9898 - val_accuracy: 0.5983\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7628 - accuracy: 0.6741 - val_loss: 0.9828 - val_accuracy: 0.5983\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7518 - accuracy: 0.6852 - val_loss: 0.9712 - val_accuracy: 0.5812\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7740 - accuracy: 0.6704 - val_loss: 0.9987 - val_accuracy: 0.6068\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7719 - accuracy: 0.6926 - val_loss: 1.0414 - val_accuracy: 0.5897\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7764 - accuracy: 0.6778 - val_loss: 0.9728 - val_accuracy: 0.5641\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7550 - accuracy: 0.6889 - val_loss: 1.0119 - val_accuracy: 0.5726\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7748 - accuracy: 0.6778 - val_loss: 0.9919 - val_accuracy: 0.6154\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7560 - accuracy: 0.6926 - val_loss: 0.9729 - val_accuracy: 0.5812\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7568 - accuracy: 0.6852 - val_loss: 0.9713 - val_accuracy: 0.5726\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7616 - accuracy: 0.6593 - val_loss: 0.9752 - val_accuracy: 0.5641\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7533 - accuracy: 0.6778 - val_loss: 0.9801 - val_accuracy: 0.6068\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7553 - accuracy: 0.6852 - val_loss: 0.9691 - val_accuracy: 0.5897\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7515 - accuracy: 0.6741 - val_loss: 0.9786 - val_accuracy: 0.6154\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7524 - accuracy: 0.6926 - val_loss: 0.9688 - val_accuracy: 0.5983\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7585 - accuracy: 0.6963 - val_loss: 0.9712 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7507 - accuracy: 0.7037 - val_loss: 0.9696 - val_accuracy: 0.5983\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7548 - accuracy: 0.6852 - val_loss: 1.0159 - val_accuracy: 0.5897\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8124 - accuracy: 0.6778 - val_loss: 1.1572 - val_accuracy: 0.6068\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7981 - accuracy: 0.6889 - val_loss: 1.0109 - val_accuracy: 0.5385\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7597 - accuracy: 0.6667 - val_loss: 0.9900 - val_accuracy: 0.5726\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7906 - accuracy: 0.6704 - val_loss: 1.0002 - val_accuracy: 0.5897\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8055 - accuracy: 0.6593 - val_loss: 0.9879 - val_accuracy: 0.5726\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7789 - accuracy: 0.6741 - val_loss: 1.0807 - val_accuracy: 0.6154\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7962 - accuracy: 0.6963 - val_loss: 1.0173 - val_accuracy: 0.6239\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7566 - accuracy: 0.6815 - val_loss: 0.9868 - val_accuracy: 0.6068\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7559 - accuracy: 0.6815 - val_loss: 1.0106 - val_accuracy: 0.5897\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7559 - accuracy: 0.6852 - val_loss: 1.0056 - val_accuracy: 0.5983\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7591 - accuracy: 0.6704 - val_loss: 0.9717 - val_accuracy: 0.5983\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7562 - accuracy: 0.6815 - val_loss: 0.9910 - val_accuracy: 0.5897\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 56us/step - loss: 0.7592 - accuracy: 0.6963 - val_loss: 0.9922 - val_accuracy: 0.6154\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7513 - accuracy: 0.6963 - val_loss: 0.9823 - val_accuracy: 0.5641\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7508 - accuracy: 0.6963 - val_loss: 0.9767 - val_accuracy: 0.6068\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7489 - accuracy: 0.6815 - val_loss: 0.9826 - val_accuracy: 0.6068\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7488 - accuracy: 0.7037 - val_loss: 0.9683 - val_accuracy: 0.6068\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7574 - accuracy: 0.6815 - val_loss: 1.0141 - val_accuracy: 0.6068\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7690 - accuracy: 0.6889 - val_loss: 1.0071 - val_accuracy: 0.6154\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7590 - accuracy: 0.6815 - val_loss: 0.9742 - val_accuracy: 0.5983\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7822 - accuracy: 0.7000 - val_loss: 1.0515 - val_accuracy: 0.6239\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7719 - accuracy: 0.6704 - val_loss: 1.0174 - val_accuracy: 0.6239\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7910 - accuracy: 0.6889 - val_loss: 1.3514 - val_accuracy: 0.5983\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8933 - accuracy: 0.6852 - val_loss: 1.2212 - val_accuracy: 0.5983\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8201 - accuracy: 0.6741 - val_loss: 1.0060 - val_accuracy: 0.5983\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7663 - accuracy: 0.6889 - val_loss: 1.0147 - val_accuracy: 0.5726\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7675 - accuracy: 0.6741 - val_loss: 1.0209 - val_accuracy: 0.5983\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7566 - accuracy: 0.6963 - val_loss: 1.0099 - val_accuracy: 0.6068\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7479 - accuracy: 0.7000 - val_loss: 0.9704 - val_accuracy: 0.5983\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7540 - accuracy: 0.6852 - val_loss: 1.0255 - val_accuracy: 0.6068\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7586 - accuracy: 0.6926 - val_loss: 1.0132 - val_accuracy: 0.6154\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7553 - accuracy: 0.6778 - val_loss: 0.9815 - val_accuracy: 0.5983\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7604 - accuracy: 0.6889 - val_loss: 1.0174 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7560 - accuracy: 0.6889 - val_loss: 0.9907 - val_accuracy: 0.6068\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7546 - accuracy: 0.6926 - val_loss: 0.9680 - val_accuracy: 0.5983\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7478 - accuracy: 0.6926 - val_loss: 1.0048 - val_accuracy: 0.6239\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7507 - accuracy: 0.6926 - val_loss: 1.0043 - val_accuracy: 0.5983\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7585 - accuracy: 0.6889 - val_loss: 0.9876 - val_accuracy: 0.5726\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7493 - accuracy: 0.6778 - val_loss: 1.0071 - val_accuracy: 0.6068\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7555 - accuracy: 0.6889 - val_loss: 0.9851 - val_accuracy: 0.6068\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7528 - accuracy: 0.6963 - val_loss: 0.9909 - val_accuracy: 0.6068\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7640 - accuracy: 0.7000 - val_loss: 1.0118 - val_accuracy: 0.6154\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7454 - accuracy: 0.6963 - val_loss: 0.9720 - val_accuracy: 0.5897\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7487 - accuracy: 0.6852 - val_loss: 0.9794 - val_accuracy: 0.5897\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7452 - accuracy: 0.6926 - val_loss: 0.9946 - val_accuracy: 0.6068\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7424 - accuracy: 0.6963 - val_loss: 0.9709 - val_accuracy: 0.6154\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7500 - accuracy: 0.7000 - val_loss: 0.9807 - val_accuracy: 0.6239\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7528 - accuracy: 0.6926 - val_loss: 1.0177 - val_accuracy: 0.6154\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7508 - accuracy: 0.6926 - val_loss: 0.9657 - val_accuracy: 0.6239\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7433 - accuracy: 0.6852 - val_loss: 0.9779 - val_accuracy: 0.6325\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7417 - accuracy: 0.7037 - val_loss: 0.9778 - val_accuracy: 0.6325\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7435 - accuracy: 0.6778 - val_loss: 0.9643 - val_accuracy: 0.6068\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7407 - accuracy: 0.6926 - val_loss: 0.9807 - val_accuracy: 0.6154\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7389 - accuracy: 0.7037 - val_loss: 0.9779 - val_accuracy: 0.5726\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7445 - accuracy: 0.6926 - val_loss: 0.9629 - val_accuracy: 0.6068\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7465 - accuracy: 0.6815 - val_loss: 1.0162 - val_accuracy: 0.6154\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7702 - accuracy: 0.6889 - val_loss: 1.0602 - val_accuracy: 0.6239\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7566 - accuracy: 0.7037 - val_loss: 0.9686 - val_accuracy: 0.6068\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7471 - accuracy: 0.6593 - val_loss: 0.9989 - val_accuracy: 0.5983\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7412 - accuracy: 0.6741 - val_loss: 0.9781 - val_accuracy: 0.5897\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7563 - accuracy: 0.6630 - val_loss: 0.9818 - val_accuracy: 0.5897\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7355 - accuracy: 0.6778 - val_loss: 1.0146 - val_accuracy: 0.5983\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7487 - accuracy: 0.6778 - val_loss: 0.9809 - val_accuracy: 0.6154\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7455 - accuracy: 0.6852 - val_loss: 0.9673 - val_accuracy: 0.5983\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7369 - accuracy: 0.6889 - val_loss: 0.9846 - val_accuracy: 0.6154\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7387 - accuracy: 0.6889 - val_loss: 0.9744 - val_accuracy: 0.5983\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7370 - accuracy: 0.6852 - val_loss: 0.9748 - val_accuracy: 0.5983\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7410 - accuracy: 0.6889 - val_loss: 0.9851 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7487 - accuracy: 0.6667 - val_loss: 0.9832 - val_accuracy: 0.5726\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7415 - accuracy: 0.6741 - val_loss: 1.0063 - val_accuracy: 0.5983\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7385 - accuracy: 0.6926 - val_loss: 0.9773 - val_accuracy: 0.5641\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7457 - accuracy: 0.6667 - val_loss: 1.0118 - val_accuracy: 0.5983\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7730 - accuracy: 0.6815 - val_loss: 1.0830 - val_accuracy: 0.6068\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7472 - accuracy: 0.6852 - val_loss: 0.9853 - val_accuracy: 0.5812\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7463 - accuracy: 0.6667 - val_loss: 1.0147 - val_accuracy: 0.6068\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7711 - accuracy: 0.6815 - val_loss: 1.1556 - val_accuracy: 0.5983\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7895 - accuracy: 0.6852 - val_loss: 0.9742 - val_accuracy: 0.5983\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7643 - accuracy: 0.6593 - val_loss: 0.9813 - val_accuracy: 0.6068\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7364 - accuracy: 0.6926 - val_loss: 1.0393 - val_accuracy: 0.5897\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7565 - accuracy: 0.6926 - val_loss: 0.9746 - val_accuracy: 0.6068\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7426 - accuracy: 0.6889 - val_loss: 0.9805 - val_accuracy: 0.5897\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7353 - accuracy: 0.7111 - val_loss: 1.0012 - val_accuracy: 0.6154\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7562 - accuracy: 0.6926 - val_loss: 0.9873 - val_accuracy: 0.6068\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7532 - accuracy: 0.6741 - val_loss: 0.9955 - val_accuracy: 0.6239\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7620 - accuracy: 0.7037 - val_loss: 1.0651 - val_accuracy: 0.6239\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7464 - accuracy: 0.7037 - val_loss: 0.9872 - val_accuracy: 0.5897\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7497 - accuracy: 0.6667 - val_loss: 1.0268 - val_accuracy: 0.6154\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7499 - accuracy: 0.6741 - val_loss: 0.9921 - val_accuracy: 0.5983\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7329 - accuracy: 0.6815 - val_loss: 0.9712 - val_accuracy: 0.6068\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7397 - accuracy: 0.6815 - val_loss: 0.9663 - val_accuracy: 0.6068\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7349 - accuracy: 0.6889 - val_loss: 0.9753 - val_accuracy: 0.6068\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7344 - accuracy: 0.6963 - val_loss: 0.9714 - val_accuracy: 0.6068\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7367 - accuracy: 0.6852 - val_loss: 0.9706 - val_accuracy: 0.5983\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7299 - accuracy: 0.6963 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7485 - accuracy: 0.6889 - val_loss: 1.0058 - val_accuracy: 0.6154\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7379 - accuracy: 0.6852 - val_loss: 0.9702 - val_accuracy: 0.6068\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7397 - accuracy: 0.6815 - val_loss: 0.9866 - val_accuracy: 0.6154\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7315 - accuracy: 0.6889 - val_loss: 0.9747 - val_accuracy: 0.5983\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7404 - accuracy: 0.6815 - val_loss: 0.9813 - val_accuracy: 0.6154\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7443 - accuracy: 0.6926 - val_loss: 1.0465 - val_accuracy: 0.6154\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7420 - accuracy: 0.6889 - val_loss: 0.9680 - val_accuracy: 0.5983\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7330 - accuracy: 0.6852 - val_loss: 0.9721 - val_accuracy: 0.5983\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7377 - accuracy: 0.6778 - val_loss: 0.9932 - val_accuracy: 0.5897\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7422 - accuracy: 0.6852 - val_loss: 1.0325 - val_accuracy: 0.6068\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7441 - accuracy: 0.6815 - val_loss: 0.9835 - val_accuracy: 0.5983\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7316 - accuracy: 0.6889 - val_loss: 1.0294 - val_accuracy: 0.6154\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7566 - accuracy: 0.6852 - val_loss: 1.0081 - val_accuracy: 0.6154\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7317 - accuracy: 0.6889 - val_loss: 0.9695 - val_accuracy: 0.5812\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7471 - accuracy: 0.6815 - val_loss: 0.9788 - val_accuracy: 0.6325\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7304 - accuracy: 0.6926 - val_loss: 0.9715 - val_accuracy: 0.6154\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7299 - accuracy: 0.6926 - val_loss: 1.0026 - val_accuracy: 0.6325\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7396 - accuracy: 0.7111 - val_loss: 0.9816 - val_accuracy: 0.6239\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7326 - accuracy: 0.7000 - val_loss: 0.9915 - val_accuracy: 0.6154\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7385 - accuracy: 0.7037 - val_loss: 1.0302 - val_accuracy: 0.6154\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7388 - accuracy: 0.6926 - val_loss: 0.9777 - val_accuracy: 0.6154\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7353 - accuracy: 0.6889 - val_loss: 0.9766 - val_accuracy: 0.5983\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.7308 - accuracy: 0.6815 - val_loss: 0.9940 - val_accuracy: 0.6068\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7319 - accuracy: 0.6889 - val_loss: 0.9798 - val_accuracy: 0.6068\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7340 - accuracy: 0.6815 - val_loss: 1.0058 - val_accuracy: 0.6154\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7721 - accuracy: 0.7000 - val_loss: 1.2338 - val_accuracy: 0.6239\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8237 - accuracy: 0.6852 - val_loss: 1.0648 - val_accuracy: 0.5983\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7392 - accuracy: 0.6926 - val_loss: 0.9967 - val_accuracy: 0.5812\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7497 - accuracy: 0.6741 - val_loss: 1.0256 - val_accuracy: 0.5897\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7341 - accuracy: 0.6815 - val_loss: 0.9820 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7312 - accuracy: 0.7074 - val_loss: 0.9769 - val_accuracy: 0.6239\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7259 - accuracy: 0.6926 - val_loss: 0.9868 - val_accuracy: 0.6068\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7395 - accuracy: 0.6889 - val_loss: 0.9812 - val_accuracy: 0.5983\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7415 - accuracy: 0.6889 - val_loss: 0.9917 - val_accuracy: 0.6154\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7352 - accuracy: 0.6963 - val_loss: 0.9665 - val_accuracy: 0.6154\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7332 - accuracy: 0.6926 - val_loss: 0.9880 - val_accuracy: 0.6154\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7314 - accuracy: 0.7000 - val_loss: 0.9780 - val_accuracy: 0.6154\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7297 - accuracy: 0.7037 - val_loss: 0.9754 - val_accuracy: 0.6154\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7260 - accuracy: 0.7037 - val_loss: 0.9854 - val_accuracy: 0.6068\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7359 - accuracy: 0.6926 - val_loss: 0.9816 - val_accuracy: 0.6068\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7294 - accuracy: 0.6889 - val_loss: 0.9713 - val_accuracy: 0.6068\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7403 - accuracy: 0.6852 - val_loss: 1.0045 - val_accuracy: 0.6154\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7334 - accuracy: 0.7000 - val_loss: 0.9988 - val_accuracy: 0.5983\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7301 - accuracy: 0.6889 - val_loss: 0.9839 - val_accuracy: 0.5983\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7281 - accuracy: 0.6889 - val_loss: 0.9916 - val_accuracy: 0.5897\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7327 - accuracy: 0.6815 - val_loss: 1.0090 - val_accuracy: 0.5897\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7286 - accuracy: 0.6815 - val_loss: 0.9767 - val_accuracy: 0.5897\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7251 - accuracy: 0.6963 - val_loss: 0.9822 - val_accuracy: 0.6239\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7315 - accuracy: 0.7185 - val_loss: 1.0037 - val_accuracy: 0.6325\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7567 - accuracy: 0.7111 - val_loss: 1.0854 - val_accuracy: 0.6325\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7483 - accuracy: 0.7074 - val_loss: 0.9720 - val_accuracy: 0.6154\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7404 - accuracy: 0.6630 - val_loss: 1.0181 - val_accuracy: 0.6325\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7352 - accuracy: 0.6926 - val_loss: 0.9752 - val_accuracy: 0.6068\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7297 - accuracy: 0.7000 - val_loss: 0.9756 - val_accuracy: 0.5983\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7275 - accuracy: 0.7037 - val_loss: 0.9849 - val_accuracy: 0.6068\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7311 - accuracy: 0.6815 - val_loss: 0.9775 - val_accuracy: 0.5983\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7267 - accuracy: 0.6889 - val_loss: 1.0066 - val_accuracy: 0.6068\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7275 - accuracy: 0.6926 - val_loss: 0.9772 - val_accuracy: 0.6068\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7291 - accuracy: 0.7000 - val_loss: 0.9813 - val_accuracy: 0.5983\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7357 - accuracy: 0.6852 - val_loss: 0.9819 - val_accuracy: 0.5812\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7274 - accuracy: 0.6852 - val_loss: 0.9844 - val_accuracy: 0.5983\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7248 - accuracy: 0.6852 - val_loss: 0.9721 - val_accuracy: 0.6154\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7292 - accuracy: 0.7111 - val_loss: 0.9847 - val_accuracy: 0.6239\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7322 - accuracy: 0.7000 - val_loss: 0.9860 - val_accuracy: 0.6068\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7308 - accuracy: 0.6815 - val_loss: 0.9676 - val_accuracy: 0.6154\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7383 - accuracy: 0.6852 - val_loss: 1.0386 - val_accuracy: 0.6239\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7415 - accuracy: 0.6852 - val_loss: 1.0032 - val_accuracy: 0.6154\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7337 - accuracy: 0.7000 - val_loss: 0.9819 - val_accuracy: 0.6154\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7279 - accuracy: 0.6963 - val_loss: 1.0116 - val_accuracy: 0.6068\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7401 - accuracy: 0.6963 - val_loss: 1.0212 - val_accuracy: 0.6239\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7239 - accuracy: 0.6963 - val_loss: 0.9766 - val_accuracy: 0.5983\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7277 - accuracy: 0.6889 - val_loss: 0.9651 - val_accuracy: 0.5983\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7268 - accuracy: 0.6926 - val_loss: 0.9617 - val_accuracy: 0.6068\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7291 - accuracy: 0.6926 - val_loss: 0.9717 - val_accuracy: 0.6068\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7292 - accuracy: 0.7000 - val_loss: 0.9672 - val_accuracy: 0.6068\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7214 - accuracy: 0.6926 - val_loss: 0.9880 - val_accuracy: 0.6154\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7243 - accuracy: 0.7000 - val_loss: 0.9805 - val_accuracy: 0.5983\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7225 - accuracy: 0.6852 - val_loss: 0.9803 - val_accuracy: 0.5897\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7230 - accuracy: 0.6778 - val_loss: 0.9776 - val_accuracy: 0.6325\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7209 - accuracy: 0.7000 - val_loss: 0.9719 - val_accuracy: 0.6154\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7234 - accuracy: 0.7111 - val_loss: 0.9754 - val_accuracy: 0.6068\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7252 - accuracy: 0.6963 - val_loss: 0.9695 - val_accuracy: 0.6239\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7352 - accuracy: 0.6889 - val_loss: 0.9993 - val_accuracy: 0.6239\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7298 - accuracy: 0.7111 - val_loss: 0.9741 - val_accuracy: 0.6068\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7236 - accuracy: 0.7000 - val_loss: 0.9963 - val_accuracy: 0.5983\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7318 - accuracy: 0.6889 - val_loss: 1.0163 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7245 - accuracy: 0.6852 - val_loss: 0.9797 - val_accuracy: 0.6068\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7328 - accuracy: 0.6889 - val_loss: 0.9775 - val_accuracy: 0.6154\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7321 - accuracy: 0.6926 - val_loss: 1.0024 - val_accuracy: 0.6154\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7341 - accuracy: 0.6963 - val_loss: 0.9655 - val_accuracy: 0.6239\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7209 - accuracy: 0.7037 - val_loss: 0.9700 - val_accuracy: 0.6239\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7233 - accuracy: 0.7185 - val_loss: 0.9827 - val_accuracy: 0.6325\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7231 - accuracy: 0.7000 - val_loss: 0.9714 - val_accuracy: 0.5983\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7238 - accuracy: 0.6815 - val_loss: 1.0209 - val_accuracy: 0.6325\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7411 - accuracy: 0.7037 - val_loss: 1.0442 - val_accuracy: 0.6325\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7283 - accuracy: 0.7074 - val_loss: 0.9774 - val_accuracy: 0.6068\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7238 - accuracy: 0.6852 - val_loss: 0.9867 - val_accuracy: 0.5983\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7204 - accuracy: 0.6889 - val_loss: 0.9758 - val_accuracy: 0.6068\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7333 - accuracy: 0.6889 - val_loss: 0.9726 - val_accuracy: 0.6068\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7419 - accuracy: 0.6926 - val_loss: 0.9938 - val_accuracy: 0.6068\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7368 - accuracy: 0.6963 - val_loss: 0.9724 - val_accuracy: 0.6154\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7394 - accuracy: 0.6852 - val_loss: 0.9749 - val_accuracy: 0.6068\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7189 - accuracy: 0.6926 - val_loss: 1.0036 - val_accuracy: 0.6154\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7238 - accuracy: 0.6778 - val_loss: 0.9839 - val_accuracy: 0.5812\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7225 - accuracy: 0.6815 - val_loss: 0.9879 - val_accuracy: 0.5897\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7242 - accuracy: 0.7037 - val_loss: 0.9797 - val_accuracy: 0.6154\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7493 - accuracy: 0.6704 - val_loss: 1.0594 - val_accuracy: 0.6239\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7692 - accuracy: 0.7148 - val_loss: 1.0625 - val_accuracy: 0.6154\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7414 - accuracy: 0.7259 - val_loss: 0.9782 - val_accuracy: 0.6068\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7307 - accuracy: 0.6815 - val_loss: 1.1319 - val_accuracy: 0.5897\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7892 - accuracy: 0.6889 - val_loss: 1.0061 - val_accuracy: 0.6068\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8385 - accuracy: 0.6519 - val_loss: 0.9731 - val_accuracy: 0.6068\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7545 - accuracy: 0.6963 - val_loss: 1.2284 - val_accuracy: 0.5983\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7999 - accuracy: 0.6741 - val_loss: 0.9839 - val_accuracy: 0.6068\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7577 - accuracy: 0.6630 - val_loss: 0.9878 - val_accuracy: 0.6239\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7220 - accuracy: 0.7074 - val_loss: 1.1117 - val_accuracy: 0.5983\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7594 - accuracy: 0.6889 - val_loss: 0.9760 - val_accuracy: 0.6154\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7237 - accuracy: 0.6852 - val_loss: 0.9722 - val_accuracy: 0.6325\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7200 - accuracy: 0.7074 - val_loss: 0.9927 - val_accuracy: 0.6154\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7195 - accuracy: 0.7037 - val_loss: 0.9706 - val_accuracy: 0.6154\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7235 - accuracy: 0.7000 - val_loss: 0.9773 - val_accuracy: 0.6068\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7204 - accuracy: 0.7074 - val_loss: 0.9904 - val_accuracy: 0.6154\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7184 - accuracy: 0.6963 - val_loss: 0.9783 - val_accuracy: 0.6068\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7247 - accuracy: 0.6889 - val_loss: 0.9752 - val_accuracy: 0.6239\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7217 - accuracy: 0.7000 - val_loss: 1.0175 - val_accuracy: 0.6154\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7308 - accuracy: 0.7037 - val_loss: 0.9723 - val_accuracy: 0.6068\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7248 - accuracy: 0.7000 - val_loss: 0.9782 - val_accuracy: 0.5983\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7181 - accuracy: 0.7000 - val_loss: 0.9840 - val_accuracy: 0.6068\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7175 - accuracy: 0.7037 - val_loss: 0.9853 - val_accuracy: 0.5983\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7192 - accuracy: 0.6926 - val_loss: 0.9871 - val_accuracy: 0.5983\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7163 - accuracy: 0.7037 - val_loss: 0.9796 - val_accuracy: 0.5983\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7259 - accuracy: 0.6852 - val_loss: 0.9827 - val_accuracy: 0.6154\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7151 - accuracy: 0.7111 - val_loss: 0.9824 - val_accuracy: 0.6068\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7176 - accuracy: 0.7037 - val_loss: 0.9729 - val_accuracy: 0.6068\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7150 - accuracy: 0.7111 - val_loss: 0.9742 - val_accuracy: 0.6154\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7177 - accuracy: 0.6963 - val_loss: 0.9730 - val_accuracy: 0.5897\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7221 - accuracy: 0.6852 - val_loss: 0.9877 - val_accuracy: 0.6239\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7231 - accuracy: 0.7148 - val_loss: 1.0121 - val_accuracy: 0.6239\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7229 - accuracy: 0.7037 - val_loss: 0.9674 - val_accuracy: 0.6068\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7174 - accuracy: 0.6963 - val_loss: 0.9685 - val_accuracy: 0.6239\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7271 - accuracy: 0.6852 - val_loss: 1.0447 - val_accuracy: 0.6154\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7356 - accuracy: 0.7000 - val_loss: 1.0082 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7162 - accuracy: 0.7000 - val_loss: 0.9738 - val_accuracy: 0.5983\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7222 - accuracy: 0.6852 - val_loss: 0.9713 - val_accuracy: 0.6068\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7268 - accuracy: 0.7037 - val_loss: 0.9973 - val_accuracy: 0.6239\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7361 - accuracy: 0.7111 - val_loss: 1.0295 - val_accuracy: 0.6239\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7196 - accuracy: 0.7037 - val_loss: 0.9799 - val_accuracy: 0.6239\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7235 - accuracy: 0.6778 - val_loss: 1.0286 - val_accuracy: 0.5983\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7282 - accuracy: 0.6815 - val_loss: 0.9903 - val_accuracy: 0.6068\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7162 - accuracy: 0.7000 - val_loss: 0.9689 - val_accuracy: 0.6068\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7233 - accuracy: 0.7037 - val_loss: 0.9845 - val_accuracy: 0.6325\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7218 - accuracy: 0.7037 - val_loss: 0.9874 - val_accuracy: 0.6068\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7172 - accuracy: 0.6926 - val_loss: 0.9778 - val_accuracy: 0.6068\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7183 - accuracy: 0.6963 - val_loss: 0.9906 - val_accuracy: 0.6068\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7154 - accuracy: 0.7037 - val_loss: 0.9991 - val_accuracy: 0.6068\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7186 - accuracy: 0.6852 - val_loss: 0.9799 - val_accuracy: 0.5983\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7260 - accuracy: 0.6852 - val_loss: 1.0534 - val_accuracy: 0.6239\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7495 - accuracy: 0.7148 - val_loss: 1.0441 - val_accuracy: 0.6239\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7190 - accuracy: 0.7185 - val_loss: 0.9816 - val_accuracy: 0.5983\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7447 - accuracy: 0.6926 - val_loss: 1.0802 - val_accuracy: 0.6239\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7435 - accuracy: 0.7000 - val_loss: 0.9830 - val_accuracy: 0.5983\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7134 - accuracy: 0.6852 - val_loss: 0.9817 - val_accuracy: 0.5983\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.7157 - accuracy: 0.6815 - val_loss: 0.9799 - val_accuracy: 0.5983\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.7180 - accuracy: 0.6926 - val_loss: 0.9984 - val_accuracy: 0.6154\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.7300 - accuracy: 0.7111 - val_loss: 1.0365 - val_accuracy: 0.6239\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7198 - accuracy: 0.6963 - val_loss: 0.9842 - val_accuracy: 0.5983\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7156 - accuracy: 0.6926 - val_loss: 0.9772 - val_accuracy: 0.5983\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.7416 - accuracy: 0.6815 - val_loss: 1.0193 - val_accuracy: 0.6239\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7872 - accuracy: 0.7111 - val_loss: 1.3400 - val_accuracy: 0.6325\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8147 - accuracy: 0.6926 - val_loss: 1.0667 - val_accuracy: 0.6154\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7607 - accuracy: 0.6926 - val_loss: 1.0307 - val_accuracy: 0.5812\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7686 - accuracy: 0.6741 - val_loss: 1.0229 - val_accuracy: 0.6239\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7233 - accuracy: 0.6852 - val_loss: 1.0196 - val_accuracy: 0.6154\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 1.0480 - accuracy: 0.6667 - val_loss: 1.5370 - val_accuracy: 0.5641\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1871 - accuracy: 0.6148 - val_loss: 1.2027 - val_accuracy: 0.5726\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8306 - accuracy: 0.6593 - val_loss: 1.1924 - val_accuracy: 0.5812\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7809 - accuracy: 0.6667 - val_loss: 1.0322 - val_accuracy: 0.6154\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7568 - accuracy: 0.6889 - val_loss: 1.0583 - val_accuracy: 0.5726\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7595 - accuracy: 0.6778 - val_loss: 1.1433 - val_accuracy: 0.6239\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7775 - accuracy: 0.7000 - val_loss: 1.0888 - val_accuracy: 0.5983\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7518 - accuracy: 0.6741 - val_loss: 0.9826 - val_accuracy: 0.6068\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7190 - accuracy: 0.6889 - val_loss: 1.0230 - val_accuracy: 0.6239\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.7263 - accuracy: 0.6926 - val_loss: 0.9966 - val_accuracy: 0.6154\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7163 - accuracy: 0.6889 - val_loss: 0.9886 - val_accuracy: 0.5897\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.7263 - accuracy: 0.6889 - val_loss: 0.9847 - val_accuracy: 0.6239\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7222 - accuracy: 0.6963 - val_loss: 1.0064 - val_accuracy: 0.6068\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7239 - accuracy: 0.7000 - val_loss: 1.0702 - val_accuracy: 0.6239\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.7252 - accuracy: 0.6926 - val_loss: 0.9863 - val_accuracy: 0.6154\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7185 - accuracy: 0.6889 - val_loss: 0.9864 - val_accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7127 - accuracy: 0.7037 - val_loss: 1.0247 - val_accuracy: 0.6068\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7257 - accuracy: 0.6889 - val_loss: 1.0181 - val_accuracy: 0.6068\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7154 - accuracy: 0.6963 - val_loss: 0.9734 - val_accuracy: 0.6154\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7278 - accuracy: 0.6926 - val_loss: 0.9977 - val_accuracy: 0.6410\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7286 - accuracy: 0.7037 - val_loss: 1.0333 - val_accuracy: 0.6325\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7165 - accuracy: 0.6778 - val_loss: 0.9919 - val_accuracy: 0.5983\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7204 - accuracy: 0.6852 - val_loss: 1.0767 - val_accuracy: 0.6239\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7398 - accuracy: 0.6889 - val_loss: 1.0416 - val_accuracy: 0.6154\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7209 - accuracy: 0.6926 - val_loss: 0.9763 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7207 - accuracy: 0.6963 - val_loss: 0.9918 - val_accuracy: 0.6325\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7138 - accuracy: 0.6963 - val_loss: 0.9765 - val_accuracy: 0.6239\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7149 - accuracy: 0.7037 - val_loss: 0.9736 - val_accuracy: 0.6154\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7162 - accuracy: 0.7037 - val_loss: 0.9921 - val_accuracy: 0.6325\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7130 - accuracy: 0.6963 - val_loss: 0.9762 - val_accuracy: 0.6068\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7106 - accuracy: 0.6852 - val_loss: 0.9949 - val_accuracy: 0.6325\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7163 - accuracy: 0.6963 - val_loss: 0.9921 - val_accuracy: 0.6325\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7127 - accuracy: 0.7037 - val_loss: 0.9764 - val_accuracy: 0.6239\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7230 - accuracy: 0.6963 - val_loss: 0.9868 - val_accuracy: 0.6410\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7149 - accuracy: 0.7111 - val_loss: 0.9979 - val_accuracy: 0.6325\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7266 - accuracy: 0.6926 - val_loss: 0.9904 - val_accuracy: 0.6154\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7317 - accuracy: 0.6889 - val_loss: 1.0185 - val_accuracy: 0.6154\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7085 - accuracy: 0.7000 - val_loss: 0.9747 - val_accuracy: 0.6154\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7401 - accuracy: 0.6889 - val_loss: 1.0527 - val_accuracy: 0.6239\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7631 - accuracy: 0.7037 - val_loss: 1.1465 - val_accuracy: 0.6239\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7529 - accuracy: 0.6852 - val_loss: 1.0009 - val_accuracy: 0.6154\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7247 - accuracy: 0.6815 - val_loss: 0.9986 - val_accuracy: 0.5897\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7106 - accuracy: 0.6889 - val_loss: 1.0448 - val_accuracy: 0.6239\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7234 - accuracy: 0.6963 - val_loss: 0.9765 - val_accuracy: 0.6325\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7090 - accuracy: 0.6926 - val_loss: 0.9743 - val_accuracy: 0.6154\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7131 - accuracy: 0.6926 - val_loss: 0.9874 - val_accuracy: 0.6154\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7103 - accuracy: 0.6963 - val_loss: 0.9987 - val_accuracy: 0.6239\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7118 - accuracy: 0.7111 - val_loss: 0.9744 - val_accuracy: 0.6154\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7136 - accuracy: 0.6926 - val_loss: 0.9769 - val_accuracy: 0.6068\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.7087 - accuracy: 0.7000 - val_loss: 0.9915 - val_accuracy: 0.6239\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7179 - accuracy: 0.7037 - val_loss: 0.9904 - val_accuracy: 0.6239\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7088 - accuracy: 0.7000 - val_loss: 0.9770 - val_accuracy: 0.6154\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7116 - accuracy: 0.6926 - val_loss: 0.9930 - val_accuracy: 0.6154\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7095 - accuracy: 0.7037 - val_loss: 0.9908 - val_accuracy: 0.6154\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7122 - accuracy: 0.7074 - val_loss: 0.9846 - val_accuracy: 0.6154\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7106 - accuracy: 0.6926 - val_loss: 0.9801 - val_accuracy: 0.6154\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7134 - accuracy: 0.6963 - val_loss: 0.9850 - val_accuracy: 0.6154\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7105 - accuracy: 0.7000 - val_loss: 0.9783 - val_accuracy: 0.6239\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7083 - accuracy: 0.7037 - val_loss: 0.9765 - val_accuracy: 0.6154\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7122 - accuracy: 0.6926 - val_loss: 0.9812 - val_accuracy: 0.6068\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7097 - accuracy: 0.6889 - val_loss: 0.9864 - val_accuracy: 0.6068\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7136 - accuracy: 0.6815 - val_loss: 0.9807 - val_accuracy: 0.6068\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7045 - accuracy: 0.7000 - val_loss: 0.9980 - val_accuracy: 0.6410\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7122 - accuracy: 0.7000 - val_loss: 0.9817 - val_accuracy: 0.6496\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7071 - accuracy: 0.7037 - val_loss: 0.9716 - val_accuracy: 0.6068\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7098 - accuracy: 0.6926 - val_loss: 0.9954 - val_accuracy: 0.6325\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7184 - accuracy: 0.6889 - val_loss: 0.9763 - val_accuracy: 0.6154\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7227 - accuracy: 0.6852 - val_loss: 1.0044 - val_accuracy: 0.6239\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7114 - accuracy: 0.6963 - val_loss: 0.9847 - val_accuracy: 0.6068\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7240 - accuracy: 0.6852 - val_loss: 0.9898 - val_accuracy: 0.5897\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7340 - accuracy: 0.6852 - val_loss: 1.1550 - val_accuracy: 0.5983\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7784 - accuracy: 0.6963 - val_loss: 1.0841 - val_accuracy: 0.6239\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7145 - accuracy: 0.7000 - val_loss: 0.9907 - val_accuracy: 0.6325\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7243 - accuracy: 0.6741 - val_loss: 1.1118 - val_accuracy: 0.6154\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7563 - accuracy: 0.6852 - val_loss: 1.0578 - val_accuracy: 0.6068\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7129 - accuracy: 0.7000 - val_loss: 0.9817 - val_accuracy: 0.6068\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7184 - accuracy: 0.6926 - val_loss: 0.9872 - val_accuracy: 0.6239\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7165 - accuracy: 0.6926 - val_loss: 0.9745 - val_accuracy: 0.6239\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7233 - accuracy: 0.6889 - val_loss: 1.0156 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7238 - accuracy: 0.7037 - val_loss: 1.0274 - val_accuracy: 0.6325\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7262 - accuracy: 0.6889 - val_loss: 0.9848 - val_accuracy: 0.6239\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7171 - accuracy: 0.6926 - val_loss: 0.9918 - val_accuracy: 0.6325\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7094 - accuracy: 0.7037 - val_loss: 0.9905 - val_accuracy: 0.6239\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7215 - accuracy: 0.6889 - val_loss: 0.9754 - val_accuracy: 0.6239\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7052 - accuracy: 0.7037 - val_loss: 1.0166 - val_accuracy: 0.6239\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7275 - accuracy: 0.7000 - val_loss: 0.9755 - val_accuracy: 0.6325\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7088 - accuracy: 0.7074 - val_loss: 0.9900 - val_accuracy: 0.6325\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7156 - accuracy: 0.6963 - val_loss: 0.9881 - val_accuracy: 0.6325\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7131 - accuracy: 0.6889 - val_loss: 0.9685 - val_accuracy: 0.6154\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7243 - accuracy: 0.6815 - val_loss: 0.9693 - val_accuracy: 0.6239\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7117 - accuracy: 0.7074 - val_loss: 1.0034 - val_accuracy: 0.6325\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7093 - accuracy: 0.7037 - val_loss: 0.9728 - val_accuracy: 0.6068\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7208 - accuracy: 0.6778 - val_loss: 1.0206 - val_accuracy: 0.6239\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7277 - accuracy: 0.7037 - val_loss: 1.0407 - val_accuracy: 0.6325\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7163 - accuracy: 0.6926 - val_loss: 0.9769 - val_accuracy: 0.6154\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7166 - accuracy: 0.6963 - val_loss: 0.9776 - val_accuracy: 0.6239\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7163 - accuracy: 0.6963 - val_loss: 0.9794 - val_accuracy: 0.6325\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7078 - accuracy: 0.6963 - val_loss: 0.9780 - val_accuracy: 0.6325\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7120 - accuracy: 0.6852 - val_loss: 1.0180 - val_accuracy: 0.6325\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7202 - accuracy: 0.7000 - val_loss: 0.9907 - val_accuracy: 0.6410\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7235 - accuracy: 0.6852 - val_loss: 0.9758 - val_accuracy: 0.6239\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7037 - accuracy: 0.6963 - val_loss: 1.0461 - val_accuracy: 0.6410\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7198 - accuracy: 0.6926 - val_loss: 0.9937 - val_accuracy: 0.6068\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7084 - accuracy: 0.6852 - val_loss: 0.9785 - val_accuracy: 0.6239\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7061 - accuracy: 0.6963 - val_loss: 0.9877 - val_accuracy: 0.6325\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7151 - accuracy: 0.6963 - val_loss: 0.9906 - val_accuracy: 0.6154\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7113 - accuracy: 0.6889 - val_loss: 1.0009 - val_accuracy: 0.6239\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7076 - accuracy: 0.6889 - val_loss: 0.9817 - val_accuracy: 0.6239\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7047 - accuracy: 0.7111 - val_loss: 0.9731 - val_accuracy: 0.6239\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7091 - accuracy: 0.7037 - val_loss: 0.9745 - val_accuracy: 0.6154\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7159 - accuracy: 0.6889 - val_loss: 0.9755 - val_accuracy: 0.6325\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.7185 - accuracy: 0.6852 - val_loss: 0.9825 - val_accuracy: 0.6410\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.7143 - accuracy: 0.7000 - val_loss: 0.9846 - val_accuracy: 0.6239\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7367 - accuracy: 0.6815 - val_loss: 1.0607 - val_accuracy: 0.6325\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.8087 - accuracy: 0.7000 - val_loss: 1.3674 - val_accuracy: 0.6410\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8365 - accuracy: 0.6926 - val_loss: 1.0874 - val_accuracy: 0.6239\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7253 - accuracy: 0.6926 - val_loss: 1.0322 - val_accuracy: 0.6154\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8118 - accuracy: 0.6667 - val_loss: 1.4839 - val_accuracy: 0.6154\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8867 - accuracy: 0.6778 - val_loss: 1.1277 - val_accuracy: 0.6154\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7663 - accuracy: 0.6963 - val_loss: 0.9995 - val_accuracy: 0.5897\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7272 - accuracy: 0.6815 - val_loss: 1.1028 - val_accuracy: 0.6154\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7484 - accuracy: 0.6852 - val_loss: 0.9961 - val_accuracy: 0.6068\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7368 - accuracy: 0.6852 - val_loss: 1.0073 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7241 - accuracy: 0.7000 - val_loss: 1.0303 - val_accuracy: 0.6325\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7093 - accuracy: 0.7074 - val_loss: 0.9938 - val_accuracy: 0.5897\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7628 - accuracy: 0.6704 - val_loss: 1.1250 - val_accuracy: 0.6325\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7752 - accuracy: 0.7037 - val_loss: 1.1205 - val_accuracy: 0.6325\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7260 - accuracy: 0.7037 - val_loss: 0.9853 - val_accuracy: 0.5983\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7367 - accuracy: 0.6815 - val_loss: 1.1017 - val_accuracy: 0.6325\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7494 - accuracy: 0.7037 - val_loss: 1.0315 - val_accuracy: 0.6239\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7041 - accuracy: 0.7037 - val_loss: 0.9876 - val_accuracy: 0.5897\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7140 - accuracy: 0.6815 - val_loss: 0.9929 - val_accuracy: 0.6154\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7071 - accuracy: 0.7037 - val_loss: 0.9818 - val_accuracy: 0.6239\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7066 - accuracy: 0.7148 - val_loss: 0.9761 - val_accuracy: 0.6239\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7049 - accuracy: 0.7111 - val_loss: 0.9880 - val_accuracy: 0.6325\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7078 - accuracy: 0.7000 - val_loss: 1.0084 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7070 - accuracy: 0.7000 - val_loss: 0.9797 - val_accuracy: 0.6154\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7039 - accuracy: 0.7000 - val_loss: 0.9804 - val_accuracy: 0.6325\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7099 - accuracy: 0.6852 - val_loss: 0.9969 - val_accuracy: 0.6410\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7158 - accuracy: 0.7000 - val_loss: 0.9931 - val_accuracy: 0.6410\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7097 - accuracy: 0.7037 - val_loss: 0.9688 - val_accuracy: 0.6239\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7105 - accuracy: 0.7000 - val_loss: 0.9871 - val_accuracy: 0.6325\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7116 - accuracy: 0.6889 - val_loss: 0.9782 - val_accuracy: 0.6325\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7105 - accuracy: 0.6963 - val_loss: 0.9681 - val_accuracy: 0.6239\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7300 - accuracy: 0.6926 - val_loss: 1.0339 - val_accuracy: 0.6325\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7090 - accuracy: 0.6926 - val_loss: 0.9794 - val_accuracy: 0.6154\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7101 - accuracy: 0.6852 - val_loss: 0.9774 - val_accuracy: 0.6239\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7090 - accuracy: 0.7037 - val_loss: 0.9946 - val_accuracy: 0.6239\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7072 - accuracy: 0.7000 - val_loss: 0.9745 - val_accuracy: 0.6154\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7066 - accuracy: 0.6852 - val_loss: 1.0192 - val_accuracy: 0.6239\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7108 - accuracy: 0.6926 - val_loss: 0.9761 - val_accuracy: 0.6154\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7303 - accuracy: 0.6667 - val_loss: 1.0112 - val_accuracy: 0.6325\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7139 - accuracy: 0.7000 - val_loss: 0.9927 - val_accuracy: 0.6496\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7008 - accuracy: 0.7074 - val_loss: 0.9755 - val_accuracy: 0.6239\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7076 - accuracy: 0.6926 - val_loss: 1.0076 - val_accuracy: 0.6325\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7155 - accuracy: 0.7074 - val_loss: 1.0477 - val_accuracy: 0.6325\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7142 - accuracy: 0.7111 - val_loss: 0.9768 - val_accuracy: 0.6239\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7020 - accuracy: 0.6889 - val_loss: 0.9722 - val_accuracy: 0.6325\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7065 - accuracy: 0.7037 - val_loss: 1.0317 - val_accuracy: 0.6325\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7161 - accuracy: 0.7000 - val_loss: 1.0074 - val_accuracy: 0.6325\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7055 - accuracy: 0.7074 - val_loss: 0.9757 - val_accuracy: 0.6154\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7180 - accuracy: 0.6963 - val_loss: 1.0080 - val_accuracy: 0.6325\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7469 - accuracy: 0.6556 - val_loss: 1.0165 - val_accuracy: 0.6325\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7528 - accuracy: 0.7000 - val_loss: 1.3223 - val_accuracy: 0.6239\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8291 - accuracy: 0.6963 - val_loss: 1.1690 - val_accuracy: 0.6239\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7470 - accuracy: 0.6815 - val_loss: 0.9978 - val_accuracy: 0.5897\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7390 - accuracy: 0.6815 - val_loss: 1.0993 - val_accuracy: 0.5983\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7788 - accuracy: 0.6778 - val_loss: 1.1219 - val_accuracy: 0.6239\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7412 - accuracy: 0.7000 - val_loss: 1.0031 - val_accuracy: 0.5983\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7273 - accuracy: 0.6963 - val_loss: 1.0848 - val_accuracy: 0.6239\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7492 - accuracy: 0.6926 - val_loss: 1.0417 - val_accuracy: 0.6239\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7192 - accuracy: 0.6889 - val_loss: 0.9876 - val_accuracy: 0.5983\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7161 - accuracy: 0.7111 - val_loss: 1.1289 - val_accuracy: 0.6239\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7694 - accuracy: 0.6852 - val_loss: 1.0774 - val_accuracy: 0.6239\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7267 - accuracy: 0.6889 - val_loss: 0.9915 - val_accuracy: 0.5897\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7170 - accuracy: 0.6815 - val_loss: 1.0640 - val_accuracy: 0.6496\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7188 - accuracy: 0.6963 - val_loss: 0.9809 - val_accuracy: 0.5897\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7159 - accuracy: 0.6963 - val_loss: 1.0038 - val_accuracy: 0.6239\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7208 - accuracy: 0.7037 - val_loss: 1.0539 - val_accuracy: 0.6325\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7078 - accuracy: 0.7000 - val_loss: 0.9852 - val_accuracy: 0.5983\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7345 - accuracy: 0.6704 - val_loss: 1.0429 - val_accuracy: 0.6239\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7278 - accuracy: 0.6889 - val_loss: 1.0023 - val_accuracy: 0.6325\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7732 - accuracy: 0.6852 - val_loss: 1.0067 - val_accuracy: 0.6154\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7171 - accuracy: 0.6889 - val_loss: 1.2167 - val_accuracy: 0.6496\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8281 - accuracy: 0.6963 - val_loss: 1.2451 - val_accuracy: 0.6410\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7715 - accuracy: 0.6815 - val_loss: 1.0042 - val_accuracy: 0.6239\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7184 - accuracy: 0.6778 - val_loss: 1.0061 - val_accuracy: 0.5983\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7253 - accuracy: 0.6889 - val_loss: 1.0655 - val_accuracy: 0.6239\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7121 - accuracy: 0.6815 - val_loss: 0.9815 - val_accuracy: 0.6239\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7149 - accuracy: 0.7148 - val_loss: 0.9815 - val_accuracy: 0.6239\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7177 - accuracy: 0.6926 - val_loss: 1.0662 - val_accuracy: 0.6239\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7337 - accuracy: 0.7037 - val_loss: 1.0017 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7174 - accuracy: 0.6889 - val_loss: 0.9875 - val_accuracy: 0.5897\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6978 - accuracy: 0.7111 - val_loss: 1.0564 - val_accuracy: 0.6239\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7409 - accuracy: 0.7000 - val_loss: 1.0462 - val_accuracy: 0.6325\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7124 - accuracy: 0.7037 - val_loss: 0.9923 - val_accuracy: 0.5897\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7112 - accuracy: 0.6889 - val_loss: 1.0203 - val_accuracy: 0.6325\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7222 - accuracy: 0.7074 - val_loss: 1.0345 - val_accuracy: 0.6325\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7144 - accuracy: 0.7037 - val_loss: 0.9842 - val_accuracy: 0.6154\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7000 - accuracy: 0.6889 - val_loss: 1.0498 - val_accuracy: 0.6325\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7173 - accuracy: 0.7000 - val_loss: 1.0059 - val_accuracy: 0.6239\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7030 - accuracy: 0.6926 - val_loss: 0.9847 - val_accuracy: 0.6154\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7035 - accuracy: 0.7074 - val_loss: 0.9825 - val_accuracy: 0.6410\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6991 - accuracy: 0.7000 - val_loss: 0.9760 - val_accuracy: 0.5812\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7109 - accuracy: 0.6852 - val_loss: 1.0029 - val_accuracy: 0.6239\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7046 - accuracy: 0.7000 - val_loss: 1.0070 - val_accuracy: 0.6239\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7007 - accuracy: 0.7037 - val_loss: 0.9739 - val_accuracy: 0.6239\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7033 - accuracy: 0.6926 - val_loss: 0.9877 - val_accuracy: 0.6239\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6983 - accuracy: 0.7111 - val_loss: 1.0274 - val_accuracy: 0.6325\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7098 - accuracy: 0.7111 - val_loss: 0.9981 - val_accuracy: 0.6325\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7008 - accuracy: 0.7148 - val_loss: 0.9778 - val_accuracy: 0.6239\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7024 - accuracy: 0.7037 - val_loss: 0.9915 - val_accuracy: 0.6325\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7043 - accuracy: 0.7000 - val_loss: 1.0256 - val_accuracy: 0.6325\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7061 - accuracy: 0.7000 - val_loss: 0.9788 - val_accuracy: 0.6410\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7058 - accuracy: 0.7037 - val_loss: 0.9757 - val_accuracy: 0.6239\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7030 - accuracy: 0.7037 - val_loss: 1.0034 - val_accuracy: 0.6154\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7105 - accuracy: 0.6926 - val_loss: 0.9864 - val_accuracy: 0.6154\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7012 - accuracy: 0.6926 - val_loss: 0.9743 - val_accuracy: 0.6325\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7060 - accuracy: 0.7000 - val_loss: 0.9909 - val_accuracy: 0.6239\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7062 - accuracy: 0.7111 - val_loss: 1.0396 - val_accuracy: 0.6239\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7254 - accuracy: 0.6963 - val_loss: 1.0159 - val_accuracy: 0.6239\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7060 - accuracy: 0.6963 - val_loss: 0.9765 - val_accuracy: 0.6410\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7040 - accuracy: 0.6926 - val_loss: 0.9953 - val_accuracy: 0.6325\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6973 - accuracy: 0.7000 - val_loss: 0.9908 - val_accuracy: 0.6154\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6999 - accuracy: 0.6852 - val_loss: 0.9901 - val_accuracy: 0.6154\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7023 - accuracy: 0.6963 - val_loss: 0.9806 - val_accuracy: 0.6325\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7035 - accuracy: 0.6963 - val_loss: 0.9722 - val_accuracy: 0.6325\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7006 - accuracy: 0.7074 - val_loss: 1.0278 - val_accuracy: 0.6410\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7055 - accuracy: 0.6889 - val_loss: 0.9817 - val_accuracy: 0.6239\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7145 - accuracy: 0.6815 - val_loss: 0.9822 - val_accuracy: 0.6239\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7060 - accuracy: 0.7000 - val_loss: 1.0149 - val_accuracy: 0.6325\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6963 - accuracy: 0.6963 - val_loss: 0.9827 - val_accuracy: 0.6068\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7112 - accuracy: 0.6889 - val_loss: 0.9944 - val_accuracy: 0.6325\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6977 - accuracy: 0.7111 - val_loss: 0.9794 - val_accuracy: 0.6239\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7005 - accuracy: 0.7037 - val_loss: 0.9857 - val_accuracy: 0.6239\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7038 - accuracy: 0.7037 - val_loss: 1.0010 - val_accuracy: 0.6239\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6998 - accuracy: 0.7037 - val_loss: 0.9884 - val_accuracy: 0.6325\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6996 - accuracy: 0.6852 - val_loss: 0.9787 - val_accuracy: 0.6410\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6918 - accuracy: 0.7074 - val_loss: 1.0374 - val_accuracy: 0.6325\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7454 - accuracy: 0.7037 - val_loss: 1.1069 - val_accuracy: 0.6325\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7308 - accuracy: 0.7000 - val_loss: 0.9754 - val_accuracy: 0.6154\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7178 - accuracy: 0.6852 - val_loss: 1.0031 - val_accuracy: 0.6239\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7044 - accuracy: 0.6889 - val_loss: 1.0138 - val_accuracy: 0.6239\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6963 - accuracy: 0.6889 - val_loss: 0.9792 - val_accuracy: 0.6154\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7089 - accuracy: 0.6889 - val_loss: 1.0338 - val_accuracy: 0.6325\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7296 - accuracy: 0.7000 - val_loss: 1.0296 - val_accuracy: 0.6239\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6996 - accuracy: 0.7074 - val_loss: 0.9725 - val_accuracy: 0.6239\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7023 - accuracy: 0.6926 - val_loss: 1.0001 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7042 - accuracy: 0.6963 - val_loss: 0.9869 - val_accuracy: 0.6154\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6985 - accuracy: 0.7000 - val_loss: 0.9864 - val_accuracy: 0.6325\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6947 - accuracy: 0.7148 - val_loss: 0.9793 - val_accuracy: 0.6410\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6954 - accuracy: 0.7148 - val_loss: 0.9806 - val_accuracy: 0.6239\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6989 - accuracy: 0.7000 - val_loss: 0.9868 - val_accuracy: 0.6325\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6984 - accuracy: 0.7000 - val_loss: 0.9950 - val_accuracy: 0.6410\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6996 - accuracy: 0.7037 - val_loss: 0.9923 - val_accuracy: 0.6325\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7081 - accuracy: 0.6926 - val_loss: 1.0519 - val_accuracy: 0.6154\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7137 - accuracy: 0.6889 - val_loss: 0.9968 - val_accuracy: 0.5983\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7000 - accuracy: 0.6852 - val_loss: 0.9753 - val_accuracy: 0.6068\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6985 - accuracy: 0.7037 - val_loss: 0.9724 - val_accuracy: 0.6325\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7085 - accuracy: 0.6963 - val_loss: 0.9851 - val_accuracy: 0.6154\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7262 - accuracy: 0.6926 - val_loss: 1.0607 - val_accuracy: 0.6325\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7471 - accuracy: 0.7000 - val_loss: 1.1588 - val_accuracy: 0.6325\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7419 - accuracy: 0.7000 - val_loss: 0.9830 - val_accuracy: 0.6154\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7035 - accuracy: 0.7000 - val_loss: 0.9869 - val_accuracy: 0.5983\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7007 - accuracy: 0.6852 - val_loss: 1.0214 - val_accuracy: 0.6239\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7038 - accuracy: 0.7074 - val_loss: 0.9846 - val_accuracy: 0.6239\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7023 - accuracy: 0.7148 - val_loss: 0.9771 - val_accuracy: 0.6239\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6988 - accuracy: 0.7148 - val_loss: 0.9841 - val_accuracy: 0.6068\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7169 - accuracy: 0.6741 - val_loss: 1.0045 - val_accuracy: 0.6068\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7038 - accuracy: 0.6889 - val_loss: 0.9921 - val_accuracy: 0.6068\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7066 - accuracy: 0.6852 - val_loss: 0.9852 - val_accuracy: 0.5983\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7087 - accuracy: 0.7000 - val_loss: 0.9970 - val_accuracy: 0.6325\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7027 - accuracy: 0.7000 - val_loss: 0.9948 - val_accuracy: 0.6325\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7074 - accuracy: 0.7000 - val_loss: 0.9757 - val_accuracy: 0.6154\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7053 - accuracy: 0.7000 - val_loss: 1.0180 - val_accuracy: 0.6154\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7018 - accuracy: 0.7037 - val_loss: 0.9982 - val_accuracy: 0.6325\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6934 - accuracy: 0.7074 - val_loss: 0.9813 - val_accuracy: 0.6154\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7004 - accuracy: 0.7037 - val_loss: 0.9751 - val_accuracy: 0.6239\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7010 - accuracy: 0.6926 - val_loss: 0.9832 - val_accuracy: 0.6325\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6924 - accuracy: 0.6889 - val_loss: 1.0179 - val_accuracy: 0.6410\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7082 - accuracy: 0.6926 - val_loss: 0.9950 - val_accuracy: 0.6239\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7154 - accuracy: 0.6704 - val_loss: 0.9953 - val_accuracy: 0.6325\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6956 - accuracy: 0.6963 - val_loss: 1.0090 - val_accuracy: 0.6410\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6985 - accuracy: 0.6926 - val_loss: 0.9817 - val_accuracy: 0.6325\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7026 - accuracy: 0.6889 - val_loss: 0.9833 - val_accuracy: 0.6325\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6996 - accuracy: 0.6926 - val_loss: 1.0010 - val_accuracy: 0.6239\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7101 - accuracy: 0.6926 - val_loss: 0.9864 - val_accuracy: 0.6239\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6985 - accuracy: 0.7074 - val_loss: 0.9696 - val_accuracy: 0.6239\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7118 - accuracy: 0.7000 - val_loss: 0.9816 - val_accuracy: 0.6239\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7067 - accuracy: 0.6852 - val_loss: 0.9734 - val_accuracy: 0.6410\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6921 - accuracy: 0.6926 - val_loss: 1.0147 - val_accuracy: 0.6496\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7031 - accuracy: 0.7037 - val_loss: 1.0075 - val_accuracy: 0.6496\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6931 - accuracy: 0.7037 - val_loss: 0.9772 - val_accuracy: 0.6154\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7076 - accuracy: 0.6926 - val_loss: 1.0265 - val_accuracy: 0.6496\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7111 - accuracy: 0.7037 - val_loss: 0.9794 - val_accuracy: 0.6325\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6929 - accuracy: 0.7074 - val_loss: 0.9711 - val_accuracy: 0.6239\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7585 - accuracy: 0.68 - 0s 52us/step - loss: 0.7003 - accuracy: 0.6852 - val_loss: 0.9801 - val_accuracy: 0.6325\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6960 - accuracy: 0.6926 - val_loss: 0.9745 - val_accuracy: 0.6325\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6962 - accuracy: 0.7074 - val_loss: 0.9769 - val_accuracy: 0.6325\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.6936 - accuracy: 0.7074 - val_loss: 0.9730 - val_accuracy: 0.6410\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6963 - accuracy: 0.6963 - val_loss: 0.9871 - val_accuracy: 0.6410\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6919 - accuracy: 0.7222 - val_loss: 0.9807 - val_accuracy: 0.6410\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7020 - accuracy: 0.7111 - val_loss: 0.9779 - val_accuracy: 0.6239\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6980 - accuracy: 0.7148 - val_loss: 1.0590 - val_accuracy: 0.6325\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7098 - accuracy: 0.7000 - val_loss: 0.9767 - val_accuracy: 0.6154\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6976 - accuracy: 0.6963 - val_loss: 0.9776 - val_accuracy: 0.6068\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6999 - accuracy: 0.6926 - val_loss: 1.0086 - val_accuracy: 0.6325\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6976 - accuracy: 0.6963 - val_loss: 0.9747 - val_accuracy: 0.6239\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7101 - accuracy: 0.6963 - val_loss: 1.1524 - val_accuracy: 0.6325\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8098 - accuracy: 0.7000 - val_loss: 1.2331 - val_accuracy: 0.6410\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7742 - accuracy: 0.7000 - val_loss: 1.1334 - val_accuracy: 0.6325\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9640 - accuracy: 0.6667 - val_loss: 2.2516 - val_accuracy: 0.6154\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.2717 - accuracy: 0.6741 - val_loss: 2.0414 - val_accuracy: 0.6239\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1998 - accuracy: 0.6815 - val_loss: 1.7596 - val_accuracy: 0.6410\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9526 - accuracy: 0.6852 - val_loss: 1.2772 - val_accuracy: 0.6410\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7703 - accuracy: 0.6741 - val_loss: 1.1506 - val_accuracy: 0.5897\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9257 - accuracy: 0.6407 - val_loss: 1.1281 - val_accuracy: 0.6325\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8168 - accuracy: 0.6926 - val_loss: 1.3576 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8287 - accuracy: 0.6778 - val_loss: 1.1285 - val_accuracy: 0.6154\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7486 - accuracy: 0.6741 - val_loss: 1.0568 - val_accuracy: 0.6068\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7464 - accuracy: 0.6630 - val_loss: 1.0881 - val_accuracy: 0.5726\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7297 - accuracy: 0.6667 - val_loss: 1.0656 - val_accuracy: 0.6154\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7046 - accuracy: 0.6926 - val_loss: 1.0018 - val_accuracy: 0.5983\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6983 - accuracy: 0.7074 - val_loss: 1.0422 - val_accuracy: 0.5897\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7110 - accuracy: 0.7111 - val_loss: 1.0018 - val_accuracy: 0.5897\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7076 - accuracy: 0.6963 - val_loss: 1.0010 - val_accuracy: 0.5983\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7296 - accuracy: 0.7111 - val_loss: 1.1915 - val_accuracy: 0.6239\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7547 - accuracy: 0.6926 - val_loss: 1.0698 - val_accuracy: 0.6154\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7089 - accuracy: 0.6963 - val_loss: 1.0058 - val_accuracy: 0.5641\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7030 - accuracy: 0.7000 - val_loss: 1.0057 - val_accuracy: 0.5897\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7124 - accuracy: 0.7111 - val_loss: 1.0025 - val_accuracy: 0.5983\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6922 - accuracy: 0.7074 - val_loss: 0.9919 - val_accuracy: 0.5897\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6974 - accuracy: 0.6963 - val_loss: 1.0007 - val_accuracy: 0.6154\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6954 - accuracy: 0.7037 - val_loss: 1.0108 - val_accuracy: 0.6239\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7130 - accuracy: 0.7000 - val_loss: 1.0218 - val_accuracy: 0.6239\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7126 - accuracy: 0.7000 - val_loss: 1.0185 - val_accuracy: 0.6154\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7057 - accuracy: 0.7000 - val_loss: 0.9945 - val_accuracy: 0.6068\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7026 - accuracy: 0.6852 - val_loss: 1.0339 - val_accuracy: 0.6410\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7024 - accuracy: 0.7000 - val_loss: 0.9823 - val_accuracy: 0.6068\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7102 - accuracy: 0.6889 - val_loss: 0.9877 - val_accuracy: 0.6068\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7055 - accuracy: 0.7074 - val_loss: 0.9954 - val_accuracy: 0.6154\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7075 - accuracy: 0.6815 - val_loss: 0.9804 - val_accuracy: 0.5812\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6890 - accuracy: 0.7074 - val_loss: 1.0435 - val_accuracy: 0.6325\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7058 - accuracy: 0.7000 - val_loss: 1.0073 - val_accuracy: 0.6325\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6944 - accuracy: 0.6926 - val_loss: 0.9910 - val_accuracy: 0.6068\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6940 - accuracy: 0.7000 - val_loss: 0.9944 - val_accuracy: 0.6154\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6915 - accuracy: 0.7074 - val_loss: 0.9995 - val_accuracy: 0.6325\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6968 - accuracy: 0.7037 - val_loss: 0.9791 - val_accuracy: 0.5897\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6985 - accuracy: 0.7000 - val_loss: 0.9919 - val_accuracy: 0.6239\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6902 - accuracy: 0.7074 - val_loss: 0.9995 - val_accuracy: 0.6068\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6942 - accuracy: 0.6852 - val_loss: 1.0283 - val_accuracy: 0.6154\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6957 - accuracy: 0.6963 - val_loss: 1.0063 - val_accuracy: 0.6325\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6919 - accuracy: 0.7000 - val_loss: 0.9973 - val_accuracy: 0.6154\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6918 - accuracy: 0.7074 - val_loss: 0.9887 - val_accuracy: 0.6239\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6944 - accuracy: 0.7222 - val_loss: 0.9805 - val_accuracy: 0.6239\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6961 - accuracy: 0.7222 - val_loss: 0.9931 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d5a60b8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 89us/step\n",
      "over-sampling test accuracy: 58.12%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 1, 1,\n",
       "       1, 1, 2, 0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0,\n",
       "       0, 1, 0, 2, 2, 2, 1, 2, 2, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 0,\n",
       "       0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 2, 0, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2,\n",
       "       0, 0, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS249     2     2\n",
       "1         NRS188     1     0\n",
       "2         NRS232     2     2\n",
       "3          NY439     2     2\n",
       "4           GA27     2     0\n",
       "..           ...   ...   ...\n",
       "112       SR3569     0     0\n",
       "113       NRS204     0     0\n",
       "114       NRS203     0     0\n",
       "115     CFBRSa25     1     1\n",
       "116  CFBREBSa131     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287155</td>\n",
       "      <td>0.095654</td>\n",
       "      <td>0.617191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.867139</td>\n",
       "      <td>0.086886</td>\n",
       "      <td>0.045975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402464</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.566951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.981951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.692081</td>\n",
       "      <td>0.158598</td>\n",
       "      <td>0.149321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.407915</td>\n",
       "      <td>0.333097</td>\n",
       "      <td>0.258988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.861852</td>\n",
       "      <td>0.138041</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.527203</td>\n",
       "      <td>0.437141</td>\n",
       "      <td>0.035656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.347299</td>\n",
       "      <td>0.557314</td>\n",
       "      <td>0.095387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.881352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.287155  0.095654  0.617191\n",
       "1    0.867139  0.086886  0.045975\n",
       "2    0.402464  0.030584  0.566951\n",
       "3    0.004070  0.013978  0.981951\n",
       "4    0.692081  0.158598  0.149321\n",
       "..        ...       ...       ...\n",
       "112  0.407915  0.333097  0.258988\n",
       "113  0.861852  0.138041  0.000107\n",
       "114  0.527203  0.437141  0.035656\n",
       "115  0.347299  0.557314  0.095387\n",
       "116  0.094259  0.024389  0.881352\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7064 - accuracy: 0.7111 - val_loss: 1.0693 - val_accuracy: 0.5983\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6952 - accuracy: 0.6963 - val_loss: 1.0539 - val_accuracy: 0.5641\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6988 - accuracy: 0.7037 - val_loss: 1.0925 - val_accuracy: 0.6154\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7138 - accuracy: 0.7185 - val_loss: 1.2496 - val_accuracy: 0.6239\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7450 - accuracy: 0.7185 - val_loss: 1.0480 - val_accuracy: 0.6154\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7010 - accuracy: 0.7074 - val_loss: 1.0435 - val_accuracy: 0.5812\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6881 - accuracy: 0.7148 - val_loss: 1.0575 - val_accuracy: 0.6154\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6897 - accuracy: 0.7074 - val_loss: 1.0615 - val_accuracy: 0.6068\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6921 - accuracy: 0.7259 - val_loss: 1.0639 - val_accuracy: 0.6154\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6903 - accuracy: 0.7333 - val_loss: 1.0482 - val_accuracy: 0.5641\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6936 - accuracy: 0.7148 - val_loss: 1.0516 - val_accuracy: 0.6154\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6890 - accuracy: 0.7185 - val_loss: 1.0366 - val_accuracy: 0.5726\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6983 - accuracy: 0.7037 - val_loss: 1.0299 - val_accuracy: 0.5641\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6926 - accuracy: 0.7037 - val_loss: 1.0333 - val_accuracy: 0.5897\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6878 - accuracy: 0.7296 - val_loss: 1.0411 - val_accuracy: 0.6154\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6938 - accuracy: 0.7259 - val_loss: 1.0419 - val_accuracy: 0.6239\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6966 - accuracy: 0.7037 - val_loss: 1.0374 - val_accuracy: 0.6154\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7144 - accuracy: 0.7148 - val_loss: 1.1277 - val_accuracy: 0.6239\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7032 - accuracy: 0.7148 - val_loss: 1.0346 - val_accuracy: 0.6068\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7030 - accuracy: 0.6963 - val_loss: 1.0854 - val_accuracy: 0.6154\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6997 - accuracy: 0.7222 - val_loss: 1.1047 - val_accuracy: 0.6239\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7017 - accuracy: 0.7222 - val_loss: 1.0286 - val_accuracy: 0.5897\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6931 - accuracy: 0.7185 - val_loss: 1.0413 - val_accuracy: 0.5897\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6965 - accuracy: 0.7037 - val_loss: 1.0698 - val_accuracy: 0.5897\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7035 - accuracy: 0.7037 - val_loss: 1.0489 - val_accuracy: 0.5983\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7038 - accuracy: 0.7074 - val_loss: 1.0444 - val_accuracy: 0.5897\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6994 - accuracy: 0.7185 - val_loss: 1.0881 - val_accuracy: 0.5897\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7023 - accuracy: 0.7000 - val_loss: 1.0389 - val_accuracy: 0.5641\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6969 - accuracy: 0.7037 - val_loss: 1.0982 - val_accuracy: 0.6239\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7087 - accuracy: 0.7185 - val_loss: 1.1318 - val_accuracy: 0.6239\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7374 - accuracy: 0.6741 - val_loss: 1.1304 - val_accuracy: 0.6239\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8072 - accuracy: 0.7222 - val_loss: 1.4369 - val_accuracy: 0.6325\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8308 - accuracy: 0.7111 - val_loss: 1.2156 - val_accuracy: 0.6068\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7537 - accuracy: 0.7000 - val_loss: 1.0744 - val_accuracy: 0.5385\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7266 - accuracy: 0.6852 - val_loss: 1.1899 - val_accuracy: 0.5812\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7196 - accuracy: 0.6963 - val_loss: 1.0422 - val_accuracy: 0.5726\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6980 - accuracy: 0.7222 - val_loss: 1.0505 - val_accuracy: 0.5897\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6926 - accuracy: 0.7185 - val_loss: 1.0579 - val_accuracy: 0.5812\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6949 - accuracy: 0.7370 - val_loss: 1.0420 - val_accuracy: 0.5726\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7296 - accuracy: 0.7037 - val_loss: 1.1622 - val_accuracy: 0.6154\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7588 - accuracy: 0.7185 - val_loss: 1.2844 - val_accuracy: 0.6154\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7321 - accuracy: 0.7185 - val_loss: 1.0539 - val_accuracy: 0.5812\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7053 - accuracy: 0.7000 - val_loss: 1.1015 - val_accuracy: 0.6239\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6935 - accuracy: 0.7296 - val_loss: 1.0417 - val_accuracy: 0.5812\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7229 - accuracy: 0.7000 - val_loss: 1.1514 - val_accuracy: 0.6154\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7589 - accuracy: 0.7111 - val_loss: 1.2947 - val_accuracy: 0.6154\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7479 - accuracy: 0.7148 - val_loss: 1.0719 - val_accuracy: 0.5897\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6916 - accuracy: 0.7000 - val_loss: 1.0694 - val_accuracy: 0.5641\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7012 - accuracy: 0.6963 - val_loss: 1.1012 - val_accuracy: 0.6154\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6952 - accuracy: 0.7185 - val_loss: 1.0838 - val_accuracy: 0.5983\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6904 - accuracy: 0.7185 - val_loss: 1.0452 - val_accuracy: 0.5812\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6961 - accuracy: 0.7000 - val_loss: 1.1175 - val_accuracy: 0.6154\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7333 - accuracy: 0.7185 - val_loss: 1.3585 - val_accuracy: 0.6325\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7893 - accuracy: 0.7037 - val_loss: 1.1012 - val_accuracy: 0.6239\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8056 - accuracy: 0.6630 - val_loss: 1.2326 - val_accuracy: 0.5812\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0258 - accuracy: 0.6481 - val_loss: 2.0639 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0955 - accuracy: 0.6852 - val_loss: 1.6722 - val_accuracy: 0.5983\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9683 - accuracy: 0.6704 - val_loss: 1.3269 - val_accuracy: 0.5983\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8304 - accuracy: 0.6815 - val_loss: 1.2275 - val_accuracy: 0.4701\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8021 - accuracy: 0.6630 - val_loss: 1.2389 - val_accuracy: 0.5726\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9943 - accuracy: 0.6852 - val_loss: 2.0198 - val_accuracy: 0.5556\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.1136 - accuracy: 0.6296 - val_loss: 1.1504 - val_accuracy: 0.5641\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0102 - accuracy: 0.6815 - val_loss: 1.6194 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.1056 - accuracy: 0.6556 - val_loss: 1.4876 - val_accuracy: 0.5983\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9268 - accuracy: 0.6778 - val_loss: 1.3943 - val_accuracy: 0.5641\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7733 - accuracy: 0.6852 - val_loss: 1.1830 - val_accuracy: 0.5726\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9649 - accuracy: 0.6556 - val_loss: 1.2148 - val_accuracy: 0.5812\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9048 - accuracy: 0.6926 - val_loss: 1.5993 - val_accuracy: 0.6068\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8410 - accuracy: 0.6889 - val_loss: 1.0822 - val_accuracy: 0.5812\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7537 - accuracy: 0.6852 - val_loss: 1.0964 - val_accuracy: 0.5812\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6993 - accuracy: 0.7185 - val_loss: 1.2350 - val_accuracy: 0.5812\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7363 - accuracy: 0.7148 - val_loss: 1.1227 - val_accuracy: 0.5897\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7571 - accuracy: 0.6815 - val_loss: 1.1036 - val_accuracy: 0.5812\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7348 - accuracy: 0.7037 - val_loss: 1.2880 - val_accuracy: 0.6154\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7088 - accuracy: 0.7074 - val_loss: 1.1076 - val_accuracy: 0.5812\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7412 - accuracy: 0.6778 - val_loss: 1.2117 - val_accuracy: 0.5812\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7226 - accuracy: 0.7074 - val_loss: 1.2362 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7234 - accuracy: 0.7148 - val_loss: 1.1175 - val_accuracy: 0.5641\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7121 - accuracy: 0.7037 - val_loss: 1.0993 - val_accuracy: 0.5641\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7009 - accuracy: 0.7185 - val_loss: 1.1517 - val_accuracy: 0.5812\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7144 - accuracy: 0.7222 - val_loss: 1.1012 - val_accuracy: 0.5726\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7747 - accuracy: 0.6704 - val_loss: 1.0879 - val_accuracy: 0.5726\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6901 - accuracy: 0.7222 - val_loss: 1.2097 - val_accuracy: 0.5897\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7417 - accuracy: 0.7148 - val_loss: 1.1685 - val_accuracy: 0.5726\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6945 - accuracy: 0.7185 - val_loss: 1.1027 - val_accuracy: 0.5556\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7085 - accuracy: 0.6889 - val_loss: 1.1021 - val_accuracy: 0.5556\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7030 - accuracy: 0.7074 - val_loss: 1.1119 - val_accuracy: 0.5812\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6900 - accuracy: 0.7037 - val_loss: 1.0784 - val_accuracy: 0.5726\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6955 - accuracy: 0.7185 - val_loss: 1.0896 - val_accuracy: 0.5812\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6903 - accuracy: 0.7259 - val_loss: 1.0883 - val_accuracy: 0.5812\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6929 - accuracy: 0.7185 - val_loss: 1.0722 - val_accuracy: 0.5641\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6874 - accuracy: 0.7259 - val_loss: 1.0881 - val_accuracy: 0.5897\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6901 - accuracy: 0.7296 - val_loss: 1.0675 - val_accuracy: 0.5641\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6929 - accuracy: 0.7222 - val_loss: 1.0727 - val_accuracy: 0.5812\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6933 - accuracy: 0.7296 - val_loss: 1.0748 - val_accuracy: 0.5726\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6903 - accuracy: 0.7222 - val_loss: 1.0987 - val_accuracy: 0.5812\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6881 - accuracy: 0.7148 - val_loss: 1.1287 - val_accuracy: 0.6154\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7053 - accuracy: 0.7148 - val_loss: 1.0705 - val_accuracy: 0.5812\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8817 - accuracy: 0.6667 - val_loss: 1.0597 - val_accuracy: 0.5812\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7169 - accuracy: 0.7037 - val_loss: 1.1493 - val_accuracy: 0.6325\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7014 - accuracy: 0.7111 - val_loss: 1.0741 - val_accuracy: 0.5726\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.73 - 0s 63us/step - loss: 0.7051 - accuracy: 0.7000 - val_loss: 1.1197 - val_accuracy: 0.5812\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7096 - accuracy: 0.7185 - val_loss: 1.1446 - val_accuracy: 0.5983\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6957 - accuracy: 0.7111 - val_loss: 1.0737 - val_accuracy: 0.5556\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7114 - accuracy: 0.6963 - val_loss: 1.0649 - val_accuracy: 0.5726\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6924 - accuracy: 0.7185 - val_loss: 1.0838 - val_accuracy: 0.5983\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6872 - accuracy: 0.7259 - val_loss: 1.1077 - val_accuracy: 0.6239\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6884 - accuracy: 0.7222 - val_loss: 1.0624 - val_accuracy: 0.5812\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7167 - accuracy: 0.6926 - val_loss: 1.0616 - val_accuracy: 0.5812\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6913 - accuracy: 0.7333 - val_loss: 1.1749 - val_accuracy: 0.6239\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7207 - accuracy: 0.7185 - val_loss: 1.1021 - val_accuracy: 0.6068\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7025 - accuracy: 0.7037 - val_loss: 1.0620 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6849 - accuracy: 0.7148 - val_loss: 1.1068 - val_accuracy: 0.6239\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7206 - accuracy: 0.7185 - val_loss: 1.1981 - val_accuracy: 0.6068\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7061 - accuracy: 0.7222 - val_loss: 1.0570 - val_accuracy: 0.5556\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6959 - accuracy: 0.7074 - val_loss: 1.0560 - val_accuracy: 0.5726\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6901 - accuracy: 0.7111 - val_loss: 1.0752 - val_accuracy: 0.6154\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6862 - accuracy: 0.7296 - val_loss: 1.1392 - val_accuracy: 0.6068\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7059 - accuracy: 0.7296 - val_loss: 1.0607 - val_accuracy: 0.5897\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6877 - accuracy: 0.7148 - val_loss: 1.0586 - val_accuracy: 0.5726\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6928 - accuracy: 0.7111 - val_loss: 1.1064 - val_accuracy: 0.6239\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6901 - accuracy: 0.7259 - val_loss: 1.0539 - val_accuracy: 0.5897\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6883 - accuracy: 0.7296 - val_loss: 1.0512 - val_accuracy: 0.5812\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6898 - accuracy: 0.7000 - val_loss: 1.0731 - val_accuracy: 0.6239\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6991 - accuracy: 0.7148 - val_loss: 1.0576 - val_accuracy: 0.6154\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6935 - accuracy: 0.7222 - val_loss: 1.1165 - val_accuracy: 0.6154\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6980 - accuracy: 0.7185 - val_loss: 1.0577 - val_accuracy: 0.5983\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7144 - accuracy: 0.7074 - val_loss: 1.0918 - val_accuracy: 0.6068\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7134 - accuracy: 0.7111 - val_loss: 1.1603 - val_accuracy: 0.6154\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6978 - accuracy: 0.7111 - val_loss: 1.0608 - val_accuracy: 0.5726\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7044 - accuracy: 0.7000 - val_loss: 1.1236 - val_accuracy: 0.5983\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7289 - accuracy: 0.7074 - val_loss: 1.1116 - val_accuracy: 0.6068\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7893 - accuracy: 0.6704 - val_loss: 1.3068 - val_accuracy: 0.6239\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9295 - accuracy: 0.7000 - val_loss: 1.8127 - val_accuracy: 0.6410\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9405 - accuracy: 0.6963 - val_loss: 1.2974 - val_accuracy: 0.5812\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6992 - accuracy: 0.7148 - val_loss: 1.1987 - val_accuracy: 0.5385\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8433 - accuracy: 0.6556 - val_loss: 1.2894 - val_accuracy: 0.5470\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7596 - accuracy: 0.6926 - val_loss: 1.0766 - val_accuracy: 0.5556\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7020 - accuracy: 0.7074 - val_loss: 1.0789 - val_accuracy: 0.5983\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6910 - accuracy: 0.7222 - val_loss: 1.1163 - val_accuracy: 0.5983\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7109 - accuracy: 0.7259 - val_loss: 1.0890 - val_accuracy: 0.5812\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7118 - accuracy: 0.7037 - val_loss: 1.0509 - val_accuracy: 0.5812\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6886 - accuracy: 0.7259 - val_loss: 1.0925 - val_accuracy: 0.6068\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6985 - accuracy: 0.7185 - val_loss: 1.0918 - val_accuracy: 0.6325\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6916 - accuracy: 0.7111 - val_loss: 1.0659 - val_accuracy: 0.5726\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6886 - accuracy: 0.7148 - val_loss: 1.0604 - val_accuracy: 0.5726\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6962 - accuracy: 0.7185 - val_loss: 1.1008 - val_accuracy: 0.6154\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6998 - accuracy: 0.7037 - val_loss: 1.1002 - val_accuracy: 0.6239\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7254 - accuracy: 0.6963 - val_loss: 1.0674 - val_accuracy: 0.5726\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6957 - accuracy: 0.7148 - val_loss: 1.0956 - val_accuracy: 0.6154\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6982 - accuracy: 0.7185 - val_loss: 1.0508 - val_accuracy: 0.6154\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6823 - accuracy: 0.7185 - val_loss: 1.0713 - val_accuracy: 0.6239\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6906 - accuracy: 0.7185 - val_loss: 1.0617 - val_accuracy: 0.5897\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6973 - accuracy: 0.7148 - val_loss: 1.0471 - val_accuracy: 0.5726\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6875 - accuracy: 0.7296 - val_loss: 1.0939 - val_accuracy: 0.6068\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7012 - accuracy: 0.7148 - val_loss: 1.0734 - val_accuracy: 0.5983\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6942 - accuracy: 0.7074 - val_loss: 1.0533 - val_accuracy: 0.5812\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6921 - accuracy: 0.7037 - val_loss: 1.0902 - val_accuracy: 0.5983\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6968 - accuracy: 0.7148 - val_loss: 1.0773 - val_accuracy: 0.6068\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6806 - accuracy: 0.7185 - val_loss: 1.0539 - val_accuracy: 0.5470\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6911 - accuracy: 0.7111 - val_loss: 1.0594 - val_accuracy: 0.6154\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6830 - accuracy: 0.7185 - val_loss: 1.1289 - val_accuracy: 0.6068\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7043 - accuracy: 0.7074 - val_loss: 1.0622 - val_accuracy: 0.5983\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6946 - accuracy: 0.7185 - val_loss: 1.0689 - val_accuracy: 0.6068\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6801 - accuracy: 0.7222 - val_loss: 1.1041 - val_accuracy: 0.6154\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6889 - accuracy: 0.7222 - val_loss: 1.0556 - val_accuracy: 0.5726\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6982 - accuracy: 0.7037 - val_loss: 1.0788 - val_accuracy: 0.6239\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6852 - accuracy: 0.7259 - val_loss: 1.1008 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6891 - accuracy: 0.7148 - val_loss: 1.0814 - val_accuracy: 0.6154\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6822 - accuracy: 0.7222 - val_loss: 1.0750 - val_accuracy: 0.6239\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6826 - accuracy: 0.7185 - val_loss: 1.0533 - val_accuracy: 0.5983\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6866 - accuracy: 0.7222 - val_loss: 1.0504 - val_accuracy: 0.6068\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6866 - accuracy: 0.7185 - val_loss: 1.1006 - val_accuracy: 0.6154\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6931 - accuracy: 0.7185 - val_loss: 1.0443 - val_accuracy: 0.5983\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6861 - accuracy: 0.7185 - val_loss: 1.0384 - val_accuracy: 0.6154\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6827 - accuracy: 0.7222 - val_loss: 1.0463 - val_accuracy: 0.6154\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6789 - accuracy: 0.7222 - val_loss: 1.0755 - val_accuracy: 0.6239\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6836 - accuracy: 0.7037 - val_loss: 1.0479 - val_accuracy: 0.5897\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6846 - accuracy: 0.7185 - val_loss: 1.0474 - val_accuracy: 0.5983\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6849 - accuracy: 0.7185 - val_loss: 1.0902 - val_accuracy: 0.5983\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6888 - accuracy: 0.7148 - val_loss: 1.0380 - val_accuracy: 0.5641\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6855 - accuracy: 0.7222 - val_loss: 1.0408 - val_accuracy: 0.5726\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6792 - accuracy: 0.7259 - val_loss: 1.0800 - val_accuracy: 0.6068\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7065 - accuracy: 0.7111 - val_loss: 1.0847 - val_accuracy: 0.6239\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7117 - accuracy: 0.7037 - val_loss: 1.0521 - val_accuracy: 0.6154\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6976 - accuracy: 0.7148 - val_loss: 1.1198 - val_accuracy: 0.6239\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6945 - accuracy: 0.7222 - val_loss: 1.0417 - val_accuracy: 0.5812\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7242 - accuracy: 0.6926 - val_loss: 1.2824 - val_accuracy: 0.6239\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8002 - accuracy: 0.7148 - val_loss: 1.3931 - val_accuracy: 0.6325\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7625 - accuracy: 0.7074 - val_loss: 1.0684 - val_accuracy: 0.5812\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7036 - accuracy: 0.7222 - val_loss: 1.0730 - val_accuracy: 0.5641\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6864 - accuracy: 0.7111 - val_loss: 1.1451 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7061 - accuracy: 0.7185 - val_loss: 1.0751 - val_accuracy: 0.6154\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6833 - accuracy: 0.7259 - val_loss: 1.0608 - val_accuracy: 0.5812\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6896 - accuracy: 0.7074 - val_loss: 1.1067 - val_accuracy: 0.6154\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7007 - accuracy: 0.7185 - val_loss: 1.1012 - val_accuracy: 0.6068\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6787 - accuracy: 0.7222 - val_loss: 1.0609 - val_accuracy: 0.5726\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6911 - accuracy: 0.7037 - val_loss: 1.0778 - val_accuracy: 0.5983\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6886 - accuracy: 0.7185 - val_loss: 1.0728 - val_accuracy: 0.6068\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6768 - accuracy: 0.7222 - val_loss: 1.0470 - val_accuracy: 0.5812\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6836 - accuracy: 0.7333 - val_loss: 1.0669 - val_accuracy: 0.6154\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6870 - accuracy: 0.7185 - val_loss: 1.0611 - val_accuracy: 0.6154\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6830 - accuracy: 0.7185 - val_loss: 1.0310 - val_accuracy: 0.5897\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7011 - accuracy: 0.7074 - val_loss: 1.2170 - val_accuracy: 0.6154\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7932 - accuracy: 0.7074 - val_loss: 1.2399 - val_accuracy: 0.5983\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7126 - accuracy: 0.7148 - val_loss: 1.0946 - val_accuracy: 0.5897\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8380 - accuracy: 0.6852 - val_loss: 1.5719 - val_accuracy: 0.6325\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9985 - accuracy: 0.7111 - val_loss: 1.8088 - val_accuracy: 0.6325\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9387 - accuracy: 0.7074 - val_loss: 1.3848 - val_accuracy: 0.5983\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7119 - accuracy: 0.7074 - val_loss: 1.1047 - val_accuracy: 0.5641\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7263 - accuracy: 0.6926 - val_loss: 1.1163 - val_accuracy: 0.5641\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6869 - accuracy: 0.7074 - val_loss: 1.0560 - val_accuracy: 0.5812\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6889 - accuracy: 0.7185 - val_loss: 1.0820 - val_accuracy: 0.5983\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6985 - accuracy: 0.7148 - val_loss: 1.0809 - val_accuracy: 0.5897\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6873 - accuracy: 0.7148 - val_loss: 1.0531 - val_accuracy: 0.5897\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6846 - accuracy: 0.7296 - val_loss: 1.0723 - val_accuracy: 0.5983\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6802 - accuracy: 0.7333 - val_loss: 1.0639 - val_accuracy: 0.5812\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6824 - accuracy: 0.7222 - val_loss: 1.0635 - val_accuracy: 0.5812\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6916 - accuracy: 0.7037 - val_loss: 1.0699 - val_accuracy: 0.5726\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6823 - accuracy: 0.7185 - val_loss: 1.1173 - val_accuracy: 0.6068\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6869 - accuracy: 0.7333 - val_loss: 1.0499 - val_accuracy: 0.5726\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7143 - accuracy: 0.7000 - val_loss: 1.1005 - val_accuracy: 0.6154\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7008 - accuracy: 0.7222 - val_loss: 1.1095 - val_accuracy: 0.6154\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7519 - accuracy: 0.6926 - val_loss: 1.1037 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7548 - accuracy: 0.7000 - val_loss: 1.3404 - val_accuracy: 0.5983\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7515 - accuracy: 0.7000 - val_loss: 1.0732 - val_accuracy: 0.5726\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7857 - accuracy: 0.6963 - val_loss: 1.1124 - val_accuracy: 0.5897\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7470 - accuracy: 0.7148 - val_loss: 1.4582 - val_accuracy: 0.6325\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8870 - accuracy: 0.7000 - val_loss: 1.5282 - val_accuracy: 0.6325\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8082 - accuracy: 0.7111 - val_loss: 1.1354 - val_accuracy: 0.5812\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7253 - accuracy: 0.7074 - val_loss: 1.0798 - val_accuracy: 0.5641\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7174 - accuracy: 0.7111 - val_loss: 1.1271 - val_accuracy: 0.5897\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7070 - accuracy: 0.7037 - val_loss: 1.0681 - val_accuracy: 0.5726\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.7100 - accuracy: 0.7222 - val_loss: 1.2061 - val_accuracy: 0.6239\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7086 - accuracy: 0.7148 - val_loss: 1.0547 - val_accuracy: 0.5726\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.7004 - accuracy: 0.7074 - val_loss: 1.0487 - val_accuracy: 0.5726\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7005 - accuracy: 0.7296 - val_loss: 1.0711 - val_accuracy: 0.5983\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6963 - accuracy: 0.7148 - val_loss: 1.0509 - val_accuracy: 0.5726\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6942 - accuracy: 0.7148 - val_loss: 1.1633 - val_accuracy: 0.6239\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7040 - accuracy: 0.7259 - val_loss: 1.0656 - val_accuracy: 0.5897\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6866 - accuracy: 0.7222 - val_loss: 1.0646 - val_accuracy: 0.5726\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6818 - accuracy: 0.7259 - val_loss: 1.0968 - val_accuracy: 0.6239\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.6855 - accuracy: 0.7296 - val_loss: 1.0605 - val_accuracy: 0.5897\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6816 - accuracy: 0.7296 - val_loss: 1.0543 - val_accuracy: 0.5897\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6873 - accuracy: 0.7222 - val_loss: 1.0694 - val_accuracy: 0.6154\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6829 - accuracy: 0.7185 - val_loss: 1.0638 - val_accuracy: 0.5726\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6857 - accuracy: 0.7111 - val_loss: 1.0906 - val_accuracy: 0.6068\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6860 - accuracy: 0.7074 - val_loss: 1.0622 - val_accuracy: 0.5726\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6786 - accuracy: 0.7148 - val_loss: 1.0759 - val_accuracy: 0.6154\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6876 - accuracy: 0.7185 - val_loss: 1.0720 - val_accuracy: 0.6239\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6793 - accuracy: 0.7222 - val_loss: 1.0691 - val_accuracy: 0.5983\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 639us/step - loss: 0.6827 - accuracy: 0.7148 - val_loss: 1.0736 - val_accuracy: 0.6325\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6777 - accuracy: 0.7296 - val_loss: 1.0497 - val_accuracy: 0.6154\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 325us/step - loss: 0.6894 - accuracy: 0.7148 - val_loss: 1.0469 - val_accuracy: 0.6154\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6839 - accuracy: 0.7222 - val_loss: 1.0910 - val_accuracy: 0.6239\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6839 - accuracy: 0.7148 - val_loss: 1.0559 - val_accuracy: 0.5983\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6851 - accuracy: 0.7185 - val_loss: 1.0426 - val_accuracy: 0.6068\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6932 - accuracy: 0.7000 - val_loss: 1.0593 - val_accuracy: 0.6325\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.6889 - accuracy: 0.7185 - val_loss: 1.0492 - val_accuracy: 0.6239\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6842 - accuracy: 0.7185 - val_loss: 1.0388 - val_accuracy: 0.5726\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6836 - accuracy: 0.7037 - val_loss: 1.0955 - val_accuracy: 0.6239\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.6812 - accuracy: 0.7185 - val_loss: 1.0361 - val_accuracy: 0.5897\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.6794 - accuracy: 0.7222 - val_loss: 1.0490 - val_accuracy: 0.6068\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6769 - accuracy: 0.7222 - val_loss: 1.0521 - val_accuracy: 0.5983\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6775 - accuracy: 0.7148 - val_loss: 1.0691 - val_accuracy: 0.6068\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 483us/step - loss: 0.6963 - accuracy: 0.7185 - val_loss: 1.0643 - val_accuracy: 0.6154\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6870 - accuracy: 0.6889 - val_loss: 1.0538 - val_accuracy: 0.5897\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7050 - accuracy: 0.7037 - val_loss: 1.1895 - val_accuracy: 0.6154\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7345 - accuracy: 0.7111 - val_loss: 1.1030 - val_accuracy: 0.6154\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6935 - accuracy: 0.7222 - val_loss: 1.0419 - val_accuracy: 0.5812\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 540us/step - loss: 0.6886 - accuracy: 0.7148 - val_loss: 1.1716 - val_accuracy: 0.6154\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7552 - accuracy: 0.7185 - val_loss: 1.1743 - val_accuracy: 0.6154\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6933 - accuracy: 0.7148 - val_loss: 1.0455 - val_accuracy: 0.5812\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6762 - accuracy: 0.7148 - val_loss: 1.1512 - val_accuracy: 0.6154\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7185 - accuracy: 0.7185 - val_loss: 1.0640 - val_accuracy: 0.6068\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6912 - accuracy: 0.7000 - val_loss: 1.0592 - val_accuracy: 0.5983\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7179 - accuracy: 0.7185 - val_loss: 1.2421 - val_accuracy: 0.6154\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7239 - accuracy: 0.7111 - val_loss: 1.0459 - val_accuracy: 0.5641\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6929 - accuracy: 0.7000 - val_loss: 1.0549 - val_accuracy: 0.6154\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7150 - accuracy: 0.7259 - val_loss: 1.1925 - val_accuracy: 0.6154\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7055 - accuracy: 0.7185 - val_loss: 1.0484 - val_accuracy: 0.5897\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6876 - accuracy: 0.7037 - val_loss: 1.0926 - val_accuracy: 0.5641\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6983 - accuracy: 0.7148 - val_loss: 1.0992 - val_accuracy: 0.5897\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6780 - accuracy: 0.7111 - val_loss: 1.0665 - val_accuracy: 0.5812\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6862 - accuracy: 0.7111 - val_loss: 1.0466 - val_accuracy: 0.5641\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6795 - accuracy: 0.7185 - val_loss: 1.0363 - val_accuracy: 0.5556\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6803 - accuracy: 0.7111 - val_loss: 1.0740 - val_accuracy: 0.6068\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6840 - accuracy: 0.7185 - val_loss: 1.0405 - val_accuracy: 0.6068\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6849 - accuracy: 0.7222 - val_loss: 1.0315 - val_accuracy: 0.6154\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6768 - accuracy: 0.7259 - val_loss: 1.0584 - val_accuracy: 0.6239\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6801 - accuracy: 0.7259 - val_loss: 1.0537 - val_accuracy: 0.6239\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6779 - accuracy: 0.7259 - val_loss: 1.0365 - val_accuracy: 0.6154\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6778 - accuracy: 0.7185 - val_loss: 1.0348 - val_accuracy: 0.6154\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6747 - accuracy: 0.7296 - val_loss: 1.0660 - val_accuracy: 0.6239\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6767 - accuracy: 0.7259 - val_loss: 1.0463 - val_accuracy: 0.5812\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6873 - accuracy: 0.7111 - val_loss: 1.0546 - val_accuracy: 0.6068\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6880 - accuracy: 0.7185 - val_loss: 1.0717 - val_accuracy: 0.5983\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6832 - accuracy: 0.7185 - val_loss: 1.0373 - val_accuracy: 0.5897\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6772 - accuracy: 0.7111 - val_loss: 1.0560 - val_accuracy: 0.5983\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6773 - accuracy: 0.7185 - val_loss: 1.0364 - val_accuracy: 0.5983\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6721 - accuracy: 0.7296 - val_loss: 1.0376 - val_accuracy: 0.6154\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6772 - accuracy: 0.7333 - val_loss: 1.0651 - val_accuracy: 0.6068\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6877 - accuracy: 0.7111 - val_loss: 1.0519 - val_accuracy: 0.5983\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6843 - accuracy: 0.7111 - val_loss: 1.0371 - val_accuracy: 0.6154\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6761 - accuracy: 0.7259 - val_loss: 1.0508 - val_accuracy: 0.5897\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6779 - accuracy: 0.7111 - val_loss: 1.0376 - val_accuracy: 0.5812\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6754 - accuracy: 0.7074 - val_loss: 1.0617 - val_accuracy: 0.6154\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6813 - accuracy: 0.7185 - val_loss: 1.0392 - val_accuracy: 0.6068\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 514us/step - loss: 0.6811 - accuracy: 0.7185 - val_loss: 1.0364 - val_accuracy: 0.6154\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.6788 - accuracy: 0.7259 - val_loss: 1.0528 - val_accuracy: 0.6239\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6953 - accuracy: 0.7148 - val_loss: 1.0923 - val_accuracy: 0.6154\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7769 - accuracy: 0.6741 - val_loss: 1.2095 - val_accuracy: 0.5385\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7713 - accuracy: 0.6741 - val_loss: 1.0799 - val_accuracy: 0.6068\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7207 - accuracy: 0.7222 - val_loss: 1.1215 - val_accuracy: 0.6068\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 485us/step - loss: 0.7630 - accuracy: 0.6926 - val_loss: 1.1120 - val_accuracy: 0.6068\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.7726 - accuracy: 0.7000 - val_loss: 1.3917 - val_accuracy: 0.6325\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8655 - accuracy: 0.6926 - val_loss: 1.1442 - val_accuracy: 0.6154\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6932 - accuracy: 0.7148 - val_loss: 1.0759 - val_accuracy: 0.5812\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.7149 - accuracy: 0.7111 - val_loss: 1.1113 - val_accuracy: 0.5983\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.7349 - accuracy: 0.7111 - val_loss: 1.1099 - val_accuracy: 0.6068\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7837 - accuracy: 0.6963 - val_loss: 1.1431 - val_accuracy: 0.6154\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7209 - accuracy: 0.7185 - val_loss: 1.3598 - val_accuracy: 0.6154\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7770 - accuracy: 0.7148 - val_loss: 1.0864 - val_accuracy: 0.5812\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6834 - accuracy: 0.7111 - val_loss: 1.0523 - val_accuracy: 0.5726\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6756 - accuracy: 0.7259 - val_loss: 1.1009 - val_accuracy: 0.6068\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6928 - accuracy: 0.7185 - val_loss: 1.0633 - val_accuracy: 0.5897\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6736 - accuracy: 0.7259 - val_loss: 1.0529 - val_accuracy: 0.5641\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6830 - accuracy: 0.7222 - val_loss: 1.0632 - val_accuracy: 0.5897\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6753 - accuracy: 0.7333 - val_loss: 1.0476 - val_accuracy: 0.5812\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6933 - accuracy: 0.7074 - val_loss: 1.0887 - val_accuracy: 0.6068\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7203 - accuracy: 0.7148 - val_loss: 1.1577 - val_accuracy: 0.6068\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7415 - accuracy: 0.7037 - val_loss: 1.0714 - val_accuracy: 0.5897\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6988 - accuracy: 0.7259 - val_loss: 1.2149 - val_accuracy: 0.6154\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7359 - accuracy: 0.7148 - val_loss: 1.0885 - val_accuracy: 0.5812\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6860 - accuracy: 0.7111 - val_loss: 1.0661 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6999 - accuracy: 0.6963 - val_loss: 1.1398 - val_accuracy: 0.6068\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7018 - accuracy: 0.7074 - val_loss: 1.0844 - val_accuracy: 0.5983\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.6743 - accuracy: 0.7259 - val_loss: 1.0546 - val_accuracy: 0.5812\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6834 - accuracy: 0.7074 - val_loss: 1.0770 - val_accuracy: 0.6068\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6802 - accuracy: 0.7185 - val_loss: 1.0804 - val_accuracy: 0.6068\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6767 - accuracy: 0.7259 - val_loss: 1.0532 - val_accuracy: 0.5983\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6760 - accuracy: 0.7222 - val_loss: 1.0561 - val_accuracy: 0.6154\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6762 - accuracy: 0.7296 - val_loss: 1.0401 - val_accuracy: 0.6068\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6869 - accuracy: 0.7222 - val_loss: 1.0554 - val_accuracy: 0.6068\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6928 - accuracy: 0.7185 - val_loss: 1.1870 - val_accuracy: 0.6239\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7085 - accuracy: 0.7222 - val_loss: 1.0390 - val_accuracy: 0.5897\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7115 - accuracy: 0.7000 - val_loss: 1.1056 - val_accuracy: 0.6154\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7087 - accuracy: 0.7222 - val_loss: 1.2207 - val_accuracy: 0.6154\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7076 - accuracy: 0.7185 - val_loss: 1.0538 - val_accuracy: 0.5641\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7346 - accuracy: 0.6926 - val_loss: 1.1249 - val_accuracy: 0.6068\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6932 - accuracy: 0.7111 - val_loss: 1.1483 - val_accuracy: 0.5812\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7777 - accuracy: 0.6778 - val_loss: 1.3118 - val_accuracy: 0.5043\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8218 - accuracy: 0.6741 - val_loss: 1.0943 - val_accuracy: 0.5641\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6948 - accuracy: 0.7148 - val_loss: 1.1936 - val_accuracy: 0.6154\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7252 - accuracy: 0.7111 - val_loss: 1.1677 - val_accuracy: 0.6068\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7101 - accuracy: 0.7185 - val_loss: 1.0874 - val_accuracy: 0.5812\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6977 - accuracy: 0.7074 - val_loss: 1.0879 - val_accuracy: 0.6068\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.6996 - accuracy: 0.7148 - val_loss: 1.1644 - val_accuracy: 0.6068\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 304us/step - loss: 0.6980 - accuracy: 0.7148 - val_loss: 1.0692 - val_accuracy: 0.6068\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6863 - accuracy: 0.7185 - val_loss: 1.0878 - val_accuracy: 0.5897\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6837 - accuracy: 0.7074 - val_loss: 1.0932 - val_accuracy: 0.6154\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6788 - accuracy: 0.7111 - val_loss: 1.0472 - val_accuracy: 0.6068\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7066 - accuracy: 0.7185 - val_loss: 1.0570 - val_accuracy: 0.5983\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6892 - accuracy: 0.7185 - val_loss: 1.1239 - val_accuracy: 0.6068\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6790 - accuracy: 0.7222 - val_loss: 1.0461 - val_accuracy: 0.5726\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7228 - accuracy: 0.7074 - val_loss: 1.1736 - val_accuracy: 0.5983\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7644 - accuracy: 0.7111 - val_loss: 1.2177 - val_accuracy: 0.5726\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7311 - accuracy: 0.7074 - val_loss: 1.0645 - val_accuracy: 0.5812\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6857 - accuracy: 0.7222 - val_loss: 1.2086 - val_accuracy: 0.6154\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7302 - accuracy: 0.7148 - val_loss: 1.0689 - val_accuracy: 0.6239\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6952 - accuracy: 0.7148 - val_loss: 1.0889 - val_accuracy: 0.6068\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7549 - accuracy: 0.7259 - val_loss: 1.4777 - val_accuracy: 0.6239\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8249 - accuracy: 0.7111 - val_loss: 1.2407 - val_accuracy: 0.6154\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6902 - accuracy: 0.7148 - val_loss: 1.0690 - val_accuracy: 0.5641\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6842 - accuracy: 0.7111 - val_loss: 1.1284 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7021 - accuracy: 0.7148 - val_loss: 1.0900 - val_accuracy: 0.5983\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.6768 - accuracy: 0.7037 - val_loss: 1.0667 - val_accuracy: 0.5812\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6996 - accuracy: 0.7074 - val_loss: 1.3631 - val_accuracy: 0.6325\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8033 - accuracy: 0.7111 - val_loss: 1.3361 - val_accuracy: 0.6154\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7401 - accuracy: 0.7185 - val_loss: 1.0581 - val_accuracy: 0.5812\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6956 - accuracy: 0.7074 - val_loss: 1.0803 - val_accuracy: 0.5812\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6938 - accuracy: 0.7074 - val_loss: 1.1019 - val_accuracy: 0.5897\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6948 - accuracy: 0.6926 - val_loss: 1.0720 - val_accuracy: 0.5897\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6927 - accuracy: 0.7111 - val_loss: 1.2559 - val_accuracy: 0.6154\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7596 - accuracy: 0.7222 - val_loss: 1.1761 - val_accuracy: 0.6154\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7358 - accuracy: 0.6852 - val_loss: 1.0552 - val_accuracy: 0.5726\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7097 - accuracy: 0.7148 - val_loss: 1.1102 - val_accuracy: 0.6154\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.7149 - accuracy: 0.7037 - val_loss: 1.0675 - val_accuracy: 0.5726\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 312us/step - loss: 0.7088 - accuracy: 0.7185 - val_loss: 1.2431 - val_accuracy: 0.6154\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.7235 - accuracy: 0.7185 - val_loss: 1.0726 - val_accuracy: 0.5983\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7245 - accuracy: 0.6963 - val_loss: 1.0812 - val_accuracy: 0.5983\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7066 - accuracy: 0.7222 - val_loss: 1.1458 - val_accuracy: 0.6154\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6826 - accuracy: 0.7296 - val_loss: 1.0691 - val_accuracy: 0.5726\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6917 - accuracy: 0.6963 - val_loss: 1.0876 - val_accuracy: 0.6068\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6785 - accuracy: 0.7222 - val_loss: 1.1037 - val_accuracy: 0.6154\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6790 - accuracy: 0.7333 - val_loss: 1.0533 - val_accuracy: 0.5897\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6837 - accuracy: 0.7074 - val_loss: 1.0602 - val_accuracy: 0.6239\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6793 - accuracy: 0.7259 - val_loss: 1.0775 - val_accuracy: 0.6239\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6750 - accuracy: 0.7259 - val_loss: 1.0548 - val_accuracy: 0.5812\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6849 - accuracy: 0.7185 - val_loss: 1.0798 - val_accuracy: 0.6068\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6787 - accuracy: 0.7185 - val_loss: 1.0768 - val_accuracy: 0.6325\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6766 - accuracy: 0.7222 - val_loss: 1.0510 - val_accuracy: 0.5897\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6726 - accuracy: 0.7222 - val_loss: 1.0482 - val_accuracy: 0.5726\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.6755 - accuracy: 0.7148 - val_loss: 1.1207 - val_accuracy: 0.6239\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6935 - accuracy: 0.7185 - val_loss: 1.0539 - val_accuracy: 0.6154\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6773 - accuracy: 0.7148 - val_loss: 1.0503 - val_accuracy: 0.6068\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6741 - accuracy: 0.7259 - val_loss: 1.0736 - val_accuracy: 0.6154\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6731 - accuracy: 0.7259 - val_loss: 1.0518 - val_accuracy: 0.6068\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6733 - accuracy: 0.7185 - val_loss: 1.0593 - val_accuracy: 0.6239\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6757 - accuracy: 0.7296 - val_loss: 1.0553 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6709 - accuracy: 0.7222 - val_loss: 1.0460 - val_accuracy: 0.6068\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6777 - accuracy: 0.7185 - val_loss: 1.0470 - val_accuracy: 0.6239\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6743 - accuracy: 0.7259 - val_loss: 1.0751 - val_accuracy: 0.6239\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6726 - accuracy: 0.7259 - val_loss: 1.0359 - val_accuracy: 0.5983\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6910 - accuracy: 0.7185 - val_loss: 1.0414 - val_accuracy: 0.6154\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6729 - accuracy: 0.7296 - val_loss: 1.0656 - val_accuracy: 0.6239\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6739 - accuracy: 0.7296 - val_loss: 1.0309 - val_accuracy: 0.6154\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6759 - accuracy: 0.7148 - val_loss: 1.0350 - val_accuracy: 0.5897\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6725 - accuracy: 0.7259 - val_loss: 1.0489 - val_accuracy: 0.6068\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6731 - accuracy: 0.7259 - val_loss: 1.0498 - val_accuracy: 0.5897\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6906 - accuracy: 0.6778 - val_loss: 1.1149 - val_accuracy: 0.6068\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.7335 - accuracy: 0.7111 - val_loss: 1.4019 - val_accuracy: 0.6068\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7821 - accuracy: 0.7111 - val_loss: 1.1156 - val_accuracy: 0.5983\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6713 - accuracy: 0.7222 - val_loss: 1.0602 - val_accuracy: 0.5641\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6993 - accuracy: 0.7111 - val_loss: 1.1416 - val_accuracy: 0.5983\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6922 - accuracy: 0.7222 - val_loss: 1.0356 - val_accuracy: 0.5812\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7011 - accuracy: 0.7000 - val_loss: 1.0845 - val_accuracy: 0.6068\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7012 - accuracy: 0.7222 - val_loss: 1.0823 - val_accuracy: 0.6068\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.6813 - accuracy: 0.7037 - val_loss: 1.0640 - val_accuracy: 0.5812\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6913 - accuracy: 0.7000 - val_loss: 1.1336 - val_accuracy: 0.6239\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6975 - accuracy: 0.7148 - val_loss: 1.0711 - val_accuracy: 0.6068\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7016 - accuracy: 0.7037 - val_loss: 1.0575 - val_accuracy: 0.5812\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7113 - accuracy: 0.7111 - val_loss: 1.0944 - val_accuracy: 0.6068\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6975 - accuracy: 0.7000 - val_loss: 1.0317 - val_accuracy: 0.5812\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 394us/step - loss: 0.6628 - accuracy: 0.7333 - val_loss: 1.1114 - val_accuracy: 0.6154\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7138 - accuracy: 0.7185 - val_loss: 1.0654 - val_accuracy: 0.6154\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6872 - accuracy: 0.7074 - val_loss: 1.0611 - val_accuracy: 0.5726\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6815 - accuracy: 0.7074 - val_loss: 1.0765 - val_accuracy: 0.6154\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6774 - accuracy: 0.7185 - val_loss: 1.0326 - val_accuracy: 0.6154\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6725 - accuracy: 0.7222 - val_loss: 1.0418 - val_accuracy: 0.6239\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6730 - accuracy: 0.7333 - val_loss: 1.0441 - val_accuracy: 0.6239\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6717 - accuracy: 0.7185 - val_loss: 1.0296 - val_accuracy: 0.5641\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6743 - accuracy: 0.7296 - val_loss: 1.0615 - val_accuracy: 0.6068\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6759 - accuracy: 0.7259 - val_loss: 1.0538 - val_accuracy: 0.5983\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6721 - accuracy: 0.7259 - val_loss: 1.0467 - val_accuracy: 0.5983\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6735 - accuracy: 0.7037 - val_loss: 1.0489 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6690 - accuracy: 0.7296 - val_loss: 1.0455 - val_accuracy: 0.6239\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6932 - accuracy: 0.7148 - val_loss: 1.0736 - val_accuracy: 0.6154\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6928 - accuracy: 0.7148 - val_loss: 1.0569 - val_accuracy: 0.6068\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6938 - accuracy: 0.7111 - val_loss: 1.0819 - val_accuracy: 0.6239\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6691 - accuracy: 0.7259 - val_loss: 1.0465 - val_accuracy: 0.5812\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 296us/step - loss: 0.6767 - accuracy: 0.7111 - val_loss: 1.0762 - val_accuracy: 0.5897\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6906 - accuracy: 0.6963 - val_loss: 1.0657 - val_accuracy: 0.5897\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6817 - accuracy: 0.7148 - val_loss: 1.0294 - val_accuracy: 0.5983\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6765 - accuracy: 0.7111 - val_loss: 1.0606 - val_accuracy: 0.6154\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6866 - accuracy: 0.7185 - val_loss: 1.0499 - val_accuracy: 0.6068\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6727 - accuracy: 0.7185 - val_loss: 1.0423 - val_accuracy: 0.5812\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6799 - accuracy: 0.7074 - val_loss: 1.0735 - val_accuracy: 0.5812\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6822 - accuracy: 0.7037 - val_loss: 1.0301 - val_accuracy: 0.5983\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6699 - accuracy: 0.7185 - val_loss: 1.0522 - val_accuracy: 0.6239\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6839 - accuracy: 0.7185 - val_loss: 1.0441 - val_accuracy: 0.6239\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6681 - accuracy: 0.7259 - val_loss: 1.0299 - val_accuracy: 0.5812\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6787 - accuracy: 0.7037 - val_loss: 1.0463 - val_accuracy: 0.6239\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.6743 - accuracy: 0.7259 - val_loss: 1.0247 - val_accuracy: 0.6154\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6685 - accuracy: 0.7259 - val_loss: 1.0246 - val_accuracy: 0.6154\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6763 - accuracy: 0.7259 - val_loss: 1.0427 - val_accuracy: 0.6239\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6707 - accuracy: 0.7222 - val_loss: 1.0283 - val_accuracy: 0.6154\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6729 - accuracy: 0.7296 - val_loss: 1.0956 - val_accuracy: 0.6239\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6755 - accuracy: 0.7148 - val_loss: 1.0308 - val_accuracy: 0.5897\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6918 - accuracy: 0.7000 - val_loss: 1.1073 - val_accuracy: 0.6068\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6888 - accuracy: 0.7222 - val_loss: 1.0217 - val_accuracy: 0.5726\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6827 - accuracy: 0.7111 - val_loss: 1.0369 - val_accuracy: 0.5983\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6770 - accuracy: 0.7185 - val_loss: 1.0359 - val_accuracy: 0.5983\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6713 - accuracy: 0.7259 - val_loss: 1.0323 - val_accuracy: 0.5641\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6755 - accuracy: 0.7185 - val_loss: 1.0927 - val_accuracy: 0.5983\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.6850 - accuracy: 0.7222 - val_loss: 1.0588 - val_accuracy: 0.5983\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.6655 - accuracy: 0.7259 - val_loss: 1.0383 - val_accuracy: 0.5641\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.6840 - accuracy: 0.7000 - val_loss: 1.0574 - val_accuracy: 0.5897\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6758 - accuracy: 0.7222 - val_loss: 1.0331 - val_accuracy: 0.6068\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6680 - accuracy: 0.7222 - val_loss: 1.0278 - val_accuracy: 0.5726\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6697 - accuracy: 0.7185 - val_loss: 1.0739 - val_accuracy: 0.5983\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6834 - accuracy: 0.7222 - val_loss: 1.0349 - val_accuracy: 0.5983\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6833 - accuracy: 0.7111 - val_loss: 1.1135 - val_accuracy: 0.5726\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7161 - accuracy: 0.7111 - val_loss: 1.0975 - val_accuracy: 0.5983\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6851 - accuracy: 0.7185 - val_loss: 1.0312 - val_accuracy: 0.5897\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6655 - accuracy: 0.7148 - val_loss: 1.0478 - val_accuracy: 0.6239\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6715 - accuracy: 0.7296 - val_loss: 1.0466 - val_accuracy: 0.6239\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6685 - accuracy: 0.7259 - val_loss: 1.0275 - val_accuracy: 0.6068\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6774 - accuracy: 0.7222 - val_loss: 1.0415 - val_accuracy: 0.5897\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6733 - accuracy: 0.7222 - val_loss: 1.0487 - val_accuracy: 0.5983\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6704 - accuracy: 0.7259 - val_loss: 1.0470 - val_accuracy: 0.5897\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 294us/step - loss: 0.6759 - accuracy: 0.7185 - val_loss: 1.0351 - val_accuracy: 0.5641\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6738 - accuracy: 0.7259 - val_loss: 1.0668 - val_accuracy: 0.5983\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6748 - accuracy: 0.7259 - val_loss: 1.0236 - val_accuracy: 0.5983\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6808 - accuracy: 0.7111 - val_loss: 1.1287 - val_accuracy: 0.6154\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7144 - accuracy: 0.7222 - val_loss: 1.2542 - val_accuracy: 0.6154\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7165 - accuracy: 0.7222 - val_loss: 1.0335 - val_accuracy: 0.6154\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.7220 - accuracy: 0.7037 - val_loss: 1.1542 - val_accuracy: 0.6154\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7114 - accuracy: 0.7222 - val_loss: 1.0891 - val_accuracy: 0.6068\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6754 - accuracy: 0.7148 - val_loss: 1.0450 - val_accuracy: 0.5641\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6716 - accuracy: 0.7111 - val_loss: 1.1283 - val_accuracy: 0.5983\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6815 - accuracy: 0.7111 - val_loss: 1.0403 - val_accuracy: 0.5556\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6775 - accuracy: 0.7111 - val_loss: 1.0527 - val_accuracy: 0.5897\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6726 - accuracy: 0.7148 - val_loss: 1.0667 - val_accuracy: 0.6154\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6748 - accuracy: 0.7222 - val_loss: 1.0461 - val_accuracy: 0.5983\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6793 - accuracy: 0.7111 - val_loss: 1.0492 - val_accuracy: 0.6154\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6686 - accuracy: 0.7259 - val_loss: 1.0374 - val_accuracy: 0.6154\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6775 - accuracy: 0.7185 - val_loss: 1.0320 - val_accuracy: 0.6154\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6892 - accuracy: 0.7074 - val_loss: 1.0892 - val_accuracy: 0.6154\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6943 - accuracy: 0.7074 - val_loss: 1.1316 - val_accuracy: 0.6239\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7058 - accuracy: 0.6889 - val_loss: 1.0467 - val_accuracy: 0.6154\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6860 - accuracy: 0.7259 - val_loss: 1.2380 - val_accuracy: 0.6239\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7244 - accuracy: 0.7185 - val_loss: 1.0366 - val_accuracy: 0.5726\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8723 - accuracy: 0.6852 - val_loss: 1.2273 - val_accuracy: 0.6154\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8613 - accuracy: 0.7074 - val_loss: 2.0124 - val_accuracy: 0.6325\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0963 - accuracy: 0.7111 - val_loss: 1.8452 - val_accuracy: 0.6325\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9409 - accuracy: 0.7074 - val_loss: 1.2503 - val_accuracy: 0.5983\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7831 - accuracy: 0.6815 - val_loss: 1.1681 - val_accuracy: 0.5470\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7367 - accuracy: 0.7074 - val_loss: 1.3987 - val_accuracy: 0.6239\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7931 - accuracy: 0.7185 - val_loss: 1.1595 - val_accuracy: 0.5983\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6886 - accuracy: 0.7259 - val_loss: 1.0624 - val_accuracy: 0.5726\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6800 - accuracy: 0.7111 - val_loss: 1.1360 - val_accuracy: 0.5812\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6874 - accuracy: 0.7222 - val_loss: 1.1320 - val_accuracy: 0.5812\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7077 - accuracy: 0.7111 - val_loss: 1.2660 - val_accuracy: 0.5043\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7916 - accuracy: 0.6815 - val_loss: 1.1354 - val_accuracy: 0.5128\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7275 - accuracy: 0.6926 - val_loss: 1.1379 - val_accuracy: 0.6154\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7820 - accuracy: 0.7037 - val_loss: 1.5605 - val_accuracy: 0.6068\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8536 - accuracy: 0.7037 - val_loss: 1.2300 - val_accuracy: 0.6239\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.7214 - accuracy: 0.6852 - val_loss: 1.0691 - val_accuracy: 0.5897\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6701 - accuracy: 0.7333 - val_loss: 1.1916 - val_accuracy: 0.6154\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7049 - accuracy: 0.7185 - val_loss: 1.0880 - val_accuracy: 0.5897\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6890 - accuracy: 0.7074 - val_loss: 1.0598 - val_accuracy: 0.5812\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 311us/step - loss: 0.6721 - accuracy: 0.7222 - val_loss: 1.1020 - val_accuracy: 0.6068\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 321us/step - loss: 0.6832 - accuracy: 0.7296 - val_loss: 1.0683 - val_accuracy: 0.5812\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 419us/step - loss: 0.6710 - accuracy: 0.7185 - val_loss: 1.0562 - val_accuracy: 0.5470\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6762 - accuracy: 0.7037 - val_loss: 1.0805 - val_accuracy: 0.5726\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6875 - accuracy: 0.7259 - val_loss: 1.0799 - val_accuracy: 0.6068\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6742 - accuracy: 0.7148 - val_loss: 1.0774 - val_accuracy: 0.5470\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6947 - accuracy: 0.7074 - val_loss: 1.0614 - val_accuracy: 0.5812\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 346us/step - loss: 0.6752 - accuracy: 0.7222 - val_loss: 1.0923 - val_accuracy: 0.6068\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6694 - accuracy: 0.7148 - val_loss: 1.0423 - val_accuracy: 0.5897\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6701 - accuracy: 0.7185 - val_loss: 1.0408 - val_accuracy: 0.5812\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6678 - accuracy: 0.7259 - val_loss: 1.0508 - val_accuracy: 0.6239\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6769 - accuracy: 0.7222 - val_loss: 1.0488 - val_accuracy: 0.5812\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 436us/step - loss: 0.6785 - accuracy: 0.7000 - val_loss: 1.0753 - val_accuracy: 0.5983\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.6737 - accuracy: 0.7111 - val_loss: 1.1349 - val_accuracy: 0.6068\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6796 - accuracy: 0.7148 - val_loss: 1.0585 - val_accuracy: 0.5641\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7054 - accuracy: 0.7111 - val_loss: 1.2758 - val_accuracy: 0.5385\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7562 - accuracy: 0.6778 - val_loss: 1.0644 - val_accuracy: 0.5812\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6842 - accuracy: 0.7037 - val_loss: 1.1850 - val_accuracy: 0.6154\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7156 - accuracy: 0.7185 - val_loss: 1.1041 - val_accuracy: 0.6239\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6918 - accuracy: 0.7037 - val_loss: 1.0453 - val_accuracy: 0.5726\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6719 - accuracy: 0.7222 - val_loss: 1.1317 - val_accuracy: 0.6239\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6951 - accuracy: 0.7185 - val_loss: 1.0681 - val_accuracy: 0.5897\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6817 - accuracy: 0.7148 - val_loss: 1.0609 - val_accuracy: 0.5897\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6731 - accuracy: 0.7148 - val_loss: 1.1379 - val_accuracy: 0.6239\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6832 - accuracy: 0.7222 - val_loss: 1.0461 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6767 - accuracy: 0.7148 - val_loss: 1.0527 - val_accuracy: 0.6239\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.6783 - accuracy: 0.7148 - val_loss: 1.1094 - val_accuracy: 0.6239\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 488us/step - loss: 0.6722 - accuracy: 0.7185 - val_loss: 1.0390 - val_accuracy: 0.5726\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 0.6715 - accuracy: 0.7037 - val_loss: 1.0617 - val_accuracy: 0.6154\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6672 - accuracy: 0.7222 - val_loss: 1.0418 - val_accuracy: 0.6154\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6888 - accuracy: 0.7000 - val_loss: 1.1062 - val_accuracy: 0.6239\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6947 - accuracy: 0.7222 - val_loss: 1.0993 - val_accuracy: 0.6068\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6816 - accuracy: 0.7259 - val_loss: 1.0759 - val_accuracy: 0.5897\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7001 - accuracy: 0.7074 - val_loss: 1.1881 - val_accuracy: 0.5983\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.7084 - accuracy: 0.7111 - val_loss: 1.0565 - val_accuracy: 0.5641\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6837 - accuracy: 0.7000 - val_loss: 1.1022 - val_accuracy: 0.6154\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6852 - accuracy: 0.7111 - val_loss: 1.0969 - val_accuracy: 0.6068\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6849 - accuracy: 0.7185 - val_loss: 1.0670 - val_accuracy: 0.5812\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6859 - accuracy: 0.7185 - val_loss: 1.0465 - val_accuracy: 0.6068\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6826 - accuracy: 0.7111 - val_loss: 1.0585 - val_accuracy: 0.6239\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7022 - accuracy: 0.7185 - val_loss: 1.1241 - val_accuracy: 0.6154\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.6812 - accuracy: 0.7259 - val_loss: 1.0469 - val_accuracy: 0.6068\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6814 - accuracy: 0.7185 - val_loss: 1.0964 - val_accuracy: 0.6068\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6842 - accuracy: 0.7148 - val_loss: 1.0478 - val_accuracy: 0.6068\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 382us/step - loss: 0.6791 - accuracy: 0.7296 - val_loss: 1.0538 - val_accuracy: 0.6068\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6719 - accuracy: 0.7185 - val_loss: 1.0705 - val_accuracy: 0.6068\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6749 - accuracy: 0.7111 - val_loss: 1.0390 - val_accuracy: 0.6068\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6790 - accuracy: 0.7185 - val_loss: 1.0554 - val_accuracy: 0.6154\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6661 - accuracy: 0.7222 - val_loss: 1.0586 - val_accuracy: 0.5983\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6813 - accuracy: 0.7037 - val_loss: 1.0598 - val_accuracy: 0.5983\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6786 - accuracy: 0.7185 - val_loss: 1.1065 - val_accuracy: 0.6154\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6896 - accuracy: 0.7185 - val_loss: 1.0933 - val_accuracy: 0.5385\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7133 - accuracy: 0.7037 - val_loss: 1.1257 - val_accuracy: 0.5812\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6786 - accuracy: 0.7185 - val_loss: 1.0705 - val_accuracy: 0.6154\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6803 - accuracy: 0.7185 - val_loss: 1.0600 - val_accuracy: 0.6068\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6949 - accuracy: 0.7037 - val_loss: 1.0931 - val_accuracy: 0.6154\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 387us/step - loss: 0.6863 - accuracy: 0.7148 - val_loss: 1.0309 - val_accuracy: 0.5983\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6807 - accuracy: 0.7148 - val_loss: 1.0516 - val_accuracy: 0.6068\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.6714 - accuracy: 0.7296 - val_loss: 1.0373 - val_accuracy: 0.5726\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6726 - accuracy: 0.7037 - val_loss: 1.0466 - val_accuracy: 0.6068\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6660 - accuracy: 0.7259 - val_loss: 1.0351 - val_accuracy: 0.5726\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6686 - accuracy: 0.7370 - val_loss: 1.0626 - val_accuracy: 0.6068\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6748 - accuracy: 0.7222 - val_loss: 1.0513 - val_accuracy: 0.6068\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6668 - accuracy: 0.7333 - val_loss: 1.0465 - val_accuracy: 0.5641\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6793 - accuracy: 0.7222 - val_loss: 1.0661 - val_accuracy: 0.5983\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6750 - accuracy: 0.6926 - val_loss: 1.0483 - val_accuracy: 0.5983\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 468us/step - loss: 0.6688 - accuracy: 0.7074 - val_loss: 1.0877 - val_accuracy: 0.6068\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6757 - accuracy: 0.7222 - val_loss: 1.0360 - val_accuracy: 0.5983\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6682 - accuracy: 0.7222 - val_loss: 1.0449 - val_accuracy: 0.6068\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6772 - accuracy: 0.7111 - val_loss: 1.0740 - val_accuracy: 0.5983\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6685 - accuracy: 0.7222 - val_loss: 1.0212 - val_accuracy: 0.5812\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6737 - accuracy: 0.7222 - val_loss: 1.0270 - val_accuracy: 0.5983\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.6718 - accuracy: 0.7259 - val_loss: 1.0303 - val_accuracy: 0.5726\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6785 - accuracy: 0.7111 - val_loss: 1.0492 - val_accuracy: 0.5897\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6724 - accuracy: 0.7148 - val_loss: 1.0624 - val_accuracy: 0.6154\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6755 - accuracy: 0.7259 - val_loss: 1.0507 - val_accuracy: 0.6154\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6638 - accuracy: 0.7259 - val_loss: 1.0725 - val_accuracy: 0.5983\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6723 - accuracy: 0.7111 - val_loss: 1.0383 - val_accuracy: 0.5983\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6657 - accuracy: 0.7148 - val_loss: 1.0288 - val_accuracy: 0.6154\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6688 - accuracy: 0.7259 - val_loss: 1.0464 - val_accuracy: 0.6068\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6646 - accuracy: 0.7333 - val_loss: 1.0216 - val_accuracy: 0.5983\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6719 - accuracy: 0.7000 - val_loss: 1.0574 - val_accuracy: 0.6068\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6749 - accuracy: 0.7185 - val_loss: 1.0494 - val_accuracy: 0.5983\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6814 - accuracy: 0.7000 - val_loss: 1.2791 - val_accuracy: 0.5470\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7901 - accuracy: 0.6926 - val_loss: 1.0861 - val_accuracy: 0.5556\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8437 - accuracy: 0.7074 - val_loss: 1.2101 - val_accuracy: 0.5641\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9239 - accuracy: 0.6630 - val_loss: 1.5940 - val_accuracy: 0.5470\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8579 - accuracy: 0.6815 - val_loss: 1.0653 - val_accuracy: 0.5812\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9055 - accuracy: 0.6926 - val_loss: 1.3119 - val_accuracy: 0.5983\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8453 - accuracy: 0.6889 - val_loss: 1.5250 - val_accuracy: 0.5983\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8125 - accuracy: 0.6889 - val_loss: 1.0631 - val_accuracy: 0.5641\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7041 - accuracy: 0.7000 - val_loss: 1.1062 - val_accuracy: 0.5897\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6904 - accuracy: 0.7074 - val_loss: 1.0696 - val_accuracy: 0.6154\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6728 - accuracy: 0.7111 - val_loss: 1.0628 - val_accuracy: 0.5726\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6815 - accuracy: 0.7074 - val_loss: 1.0770 - val_accuracy: 0.6068\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.6802 - accuracy: 0.7111 - val_loss: 1.0601 - val_accuracy: 0.5897\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 321us/step - loss: 0.6757 - accuracy: 0.7259 - val_loss: 1.0607 - val_accuracy: 0.6239\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6643 - accuracy: 0.7333 - val_loss: 1.0481 - val_accuracy: 0.5812\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6654 - accuracy: 0.7185 - val_loss: 1.0587 - val_accuracy: 0.6239\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6677 - accuracy: 0.7296 - val_loss: 1.0802 - val_accuracy: 0.6154\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6780 - accuracy: 0.7148 - val_loss: 1.1184 - val_accuracy: 0.5897\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6773 - accuracy: 0.7185 - val_loss: 1.0475 - val_accuracy: 0.5641\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6722 - accuracy: 0.7148 - val_loss: 1.0609 - val_accuracy: 0.5812\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6647 - accuracy: 0.7222 - val_loss: 1.0766 - val_accuracy: 0.6068\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6724 - accuracy: 0.7222 - val_loss: 1.0403 - val_accuracy: 0.5726\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7407 - accuracy: 0.7185 - val_loss: 1.1674 - val_accuracy: 0.6154\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6966 - accuracy: 0.7148 - val_loss: 1.0414 - val_accuracy: 0.6068\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6688 - accuracy: 0.7074 - val_loss: 1.0455 - val_accuracy: 0.6154\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6702 - accuracy: 0.7259 - val_loss: 1.0500 - val_accuracy: 0.5897\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6768 - accuracy: 0.7185 - val_loss: 1.0518 - val_accuracy: 0.5983\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6664 - accuracy: 0.7222 - val_loss: 1.0685 - val_accuracy: 0.5983\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6720 - accuracy: 0.7185 - val_loss: 1.0414 - val_accuracy: 0.6068\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6642 - accuracy: 0.7296 - val_loss: 1.0329 - val_accuracy: 0.5897\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6724 - accuracy: 0.7111 - val_loss: 1.0469 - val_accuracy: 0.5983\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6673 - accuracy: 0.7185 - val_loss: 1.0381 - val_accuracy: 0.6068\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6646 - accuracy: 0.7259 - val_loss: 1.0341 - val_accuracy: 0.6239\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6703 - accuracy: 0.7185 - val_loss: 1.0533 - val_accuracy: 0.6239\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6702 - accuracy: 0.7222 - val_loss: 1.0480 - val_accuracy: 0.6154\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6737 - accuracy: 0.7222 - val_loss: 1.0368 - val_accuracy: 0.6154\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6850 - accuracy: 0.7222 - val_loss: 1.0898 - val_accuracy: 0.6239\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6961 - accuracy: 0.7222 - val_loss: 1.1106 - val_accuracy: 0.6154\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6696 - accuracy: 0.7074 - val_loss: 1.0478 - val_accuracy: 0.5726\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6957 - accuracy: 0.7148 - val_loss: 1.0917 - val_accuracy: 0.6154\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6671 - accuracy: 0.7296 - val_loss: 1.0293 - val_accuracy: 0.5897\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6616 - accuracy: 0.7185 - val_loss: 1.0846 - val_accuracy: 0.6239\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6760 - accuracy: 0.7222 - val_loss: 1.0313 - val_accuracy: 0.6154\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6648 - accuracy: 0.7185 - val_loss: 1.0421 - val_accuracy: 0.6239\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6735 - accuracy: 0.7259 - val_loss: 1.0757 - val_accuracy: 0.6239\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6690 - accuracy: 0.7259 - val_loss: 1.0414 - val_accuracy: 0.5897\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6815 - accuracy: 0.7185 - val_loss: 1.1468 - val_accuracy: 0.6239\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7154 - accuracy: 0.7185 - val_loss: 1.0996 - val_accuracy: 0.6239\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6788 - accuracy: 0.7074 - val_loss: 1.0324 - val_accuracy: 0.5812\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6753 - accuracy: 0.7222 - val_loss: 1.0888 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6636 - accuracy: 0.7296 - val_loss: 1.0413 - val_accuracy: 0.5897\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6691 - accuracy: 0.7148 - val_loss: 1.0688 - val_accuracy: 0.6239\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 84us/step - loss: 0.6689 - accuracy: 0.7259 - val_loss: 1.0513 - val_accuracy: 0.5812\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6848 - accuracy: 0.7037 - val_loss: 1.0553 - val_accuracy: 0.6154\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7005 - accuracy: 0.7222 - val_loss: 1.1494 - val_accuracy: 0.6239\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6827 - accuracy: 0.7074 - val_loss: 1.0665 - val_accuracy: 0.5470\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6766 - accuracy: 0.7222 - val_loss: 1.1984 - val_accuracy: 0.6068\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7020 - accuracy: 0.7222 - val_loss: 1.0371 - val_accuracy: 0.5641\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7416 - accuracy: 0.7000 - val_loss: 1.0410 - val_accuracy: 0.5641\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6699 - accuracy: 0.7000 - val_loss: 1.1260 - val_accuracy: 0.6068\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.6769 - accuracy: 0.7111 - val_loss: 1.0391 - val_accuracy: 0.5641\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.6710 - accuracy: 0.7259 - val_loss: 1.0479 - val_accuracy: 0.6068\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6652 - accuracy: 0.7259 - val_loss: 1.0468 - val_accuracy: 0.6239\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6646 - accuracy: 0.7185 - val_loss: 1.0448 - val_accuracy: 0.5726\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 311us/step - loss: 0.6626 - accuracy: 0.7222 - val_loss: 1.0487 - val_accuracy: 0.6068\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.6737 - accuracy: 0.7111 - val_loss: 1.0425 - val_accuracy: 0.5812\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6661 - accuracy: 0.7185 - val_loss: 1.0617 - val_accuracy: 0.6239\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6691 - accuracy: 0.7296 - val_loss: 1.0990 - val_accuracy: 0.6239\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6867 - accuracy: 0.7000 - val_loss: 1.1010 - val_accuracy: 0.5812\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.6987 - accuracy: 0.7074 - val_loss: 1.0811 - val_accuracy: 0.6154\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6691 - accuracy: 0.7185 - val_loss: 1.0432 - val_accuracy: 0.6154\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6764 - accuracy: 0.7222 - val_loss: 1.0519 - val_accuracy: 0.6154\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6693 - accuracy: 0.7148 - val_loss: 1.0828 - val_accuracy: 0.6154\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6756 - accuracy: 0.7148 - val_loss: 1.0579 - val_accuracy: 0.6154\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6694 - accuracy: 0.7296 - val_loss: 1.0777 - val_accuracy: 0.6154\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.6659 - accuracy: 0.7185 - val_loss: 1.0360 - val_accuracy: 0.5897\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6755 - accuracy: 0.7000 - val_loss: 1.1254 - val_accuracy: 0.6154\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6891 - accuracy: 0.7185 - val_loss: 1.0366 - val_accuracy: 0.6239\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6609 - accuracy: 0.7333 - val_loss: 1.0305 - val_accuracy: 0.5812\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6776 - accuracy: 0.7148 - val_loss: 1.0959 - val_accuracy: 0.6068\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6861 - accuracy: 0.7185 - val_loss: 1.0382 - val_accuracy: 0.6154\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6588 - accuracy: 0.7222 - val_loss: 1.0359 - val_accuracy: 0.5983\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6738 - accuracy: 0.7222 - val_loss: 1.0588 - val_accuracy: 0.6154\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6636 - accuracy: 0.7296 - val_loss: 1.0324 - val_accuracy: 0.6068\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6649 - accuracy: 0.7222 - val_loss: 1.0569 - val_accuracy: 0.6154\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6717 - accuracy: 0.7259 - val_loss: 1.0619 - val_accuracy: 0.5897\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6668 - accuracy: 0.7222 - val_loss: 1.0414 - val_accuracy: 0.5897\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6645 - accuracy: 0.7259 - val_loss: 1.0562 - val_accuracy: 0.6154\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6663 - accuracy: 0.7259 - val_loss: 1.0391 - val_accuracy: 0.6068\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6622 - accuracy: 0.7185 - val_loss: 1.0468 - val_accuracy: 0.5897\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6784 - accuracy: 0.7111 - val_loss: 1.0458 - val_accuracy: 0.6154\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6617 - accuracy: 0.7296 - val_loss: 1.0304 - val_accuracy: 0.6154\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6777 - accuracy: 0.7185 - val_loss: 1.1300 - val_accuracy: 0.6154\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7030 - accuracy: 0.7222 - val_loss: 1.1510 - val_accuracy: 0.6154\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6727 - accuracy: 0.7222 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6932 - accuracy: 0.6889 - val_loss: 1.0875 - val_accuracy: 0.6068\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6697 - accuracy: 0.7222 - val_loss: 1.0780 - val_accuracy: 0.6068\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.6730 - accuracy: 0.7148 - val_loss: 1.0601 - val_accuracy: 0.5897\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6747 - accuracy: 0.7185 - val_loss: 1.0598 - val_accuracy: 0.5897\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6864 - accuracy: 0.6852 - val_loss: 1.0812 - val_accuracy: 0.5983\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6941 - accuracy: 0.7185 - val_loss: 1.0383 - val_accuracy: 0.5726\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8794 - accuracy: 0.6852 - val_loss: 1.0473 - val_accuracy: 0.5726\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7066 - accuracy: 0.7037 - val_loss: 1.1805 - val_accuracy: 0.6154\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6859 - accuracy: 0.7222 - val_loss: 1.0675 - val_accuracy: 0.5641\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8060 - accuracy: 0.6815 - val_loss: 1.4566 - val_accuracy: 0.5470\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8501 - accuracy: 0.6889 - val_loss: 1.0916 - val_accuracy: 0.5641\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7365 - accuracy: 0.6963 - val_loss: 1.1747 - val_accuracy: 0.6154\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7334 - accuracy: 0.7148 - val_loss: 1.4236 - val_accuracy: 0.5983\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7910 - accuracy: 0.6926 - val_loss: 1.1372 - val_accuracy: 0.5641\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7009 - accuracy: 0.7074 - val_loss: 1.0684 - val_accuracy: 0.5897\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6876 - accuracy: 0.7111 - val_loss: 1.1277 - val_accuracy: 0.6154\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6867 - accuracy: 0.7111 - val_loss: 1.1238 - val_accuracy: 0.5641\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.6811 - accuracy: 0.7111 - val_loss: 1.0580 - val_accuracy: 0.5726\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6668 - accuracy: 0.7185 - val_loss: 1.0766 - val_accuracy: 0.5897\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6749 - accuracy: 0.7222 - val_loss: 1.0653 - val_accuracy: 0.5897\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6630 - accuracy: 0.7296 - val_loss: 1.0450 - val_accuracy: 0.5812\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6686 - accuracy: 0.7222 - val_loss: 1.0549 - val_accuracy: 0.6154\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6637 - accuracy: 0.7296 - val_loss: 1.0455 - val_accuracy: 0.5812\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6660 - accuracy: 0.7259 - val_loss: 1.0446 - val_accuracy: 0.5812\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6782 - accuracy: 0.7222 - val_loss: 1.1529 - val_accuracy: 0.6068\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6988 - accuracy: 0.7185 - val_loss: 1.0392 - val_accuracy: 0.5897\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.7061 - accuracy: 0.7148 - val_loss: 1.3008 - val_accuracy: 0.6154\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7382 - accuracy: 0.7259 - val_loss: 1.0874 - val_accuracy: 0.6068\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6672 - accuracy: 0.7111 - val_loss: 1.0686 - val_accuracy: 0.5556\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6738 - accuracy: 0.7222 - val_loss: 1.0890 - val_accuracy: 0.6068\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6723 - accuracy: 0.7185 - val_loss: 1.0465 - val_accuracy: 0.5726\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6703 - accuracy: 0.7111 - val_loss: 1.0360 - val_accuracy: 0.5983\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6702 - accuracy: 0.7259 - val_loss: 1.0480 - val_accuracy: 0.5983\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6650 - accuracy: 0.7259 - val_loss: 1.0571 - val_accuracy: 0.5897\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6720 - accuracy: 0.7259 - val_loss: 1.0542 - val_accuracy: 0.5726\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.7059 - accuracy: 0.7000 - val_loss: 1.3334 - val_accuracy: 0.6068\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8288 - accuracy: 0.6926 - val_loss: 1.4468 - val_accuracy: 0.5812\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7566 - accuracy: 0.7037 - val_loss: 1.0474 - val_accuracy: 0.5983\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6936 - accuracy: 0.7222 - val_loss: 1.0705 - val_accuracy: 0.5641\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6820 - accuracy: 0.7259 - val_loss: 1.3568 - val_accuracy: 0.6154\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8164 - accuracy: 0.6926 - val_loss: 1.1895 - val_accuracy: 0.5641\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7387 - accuracy: 0.6926 - val_loss: 1.0639 - val_accuracy: 0.5812\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6683 - accuracy: 0.7333 - val_loss: 1.4559 - val_accuracy: 0.6325\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8305 - accuracy: 0.7074 - val_loss: 1.3832 - val_accuracy: 0.6325\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.7434 - accuracy: 0.7037 - val_loss: 1.0544 - val_accuracy: 0.5897\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7415 - accuracy: 0.6963 - val_loss: 1.1567 - val_accuracy: 0.5983\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7151 - accuracy: 0.7185 - val_loss: 1.1946 - val_accuracy: 0.6154\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6829 - accuracy: 0.7296 - val_loss: 1.0563 - val_accuracy: 0.5812\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6771 - accuracy: 0.6963 - val_loss: 1.1015 - val_accuracy: 0.5812\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6745 - accuracy: 0.7111 - val_loss: 1.0768 - val_accuracy: 0.5897\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6671 - accuracy: 0.7222 - val_loss: 1.0539 - val_accuracy: 0.5812\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6663 - accuracy: 0.7370 - val_loss: 1.0663 - val_accuracy: 0.5983\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6713 - accuracy: 0.7296 - val_loss: 1.0436 - val_accuracy: 0.5897\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6784 - accuracy: 0.7148 - val_loss: 1.0812 - val_accuracy: 0.6068\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6876 - accuracy: 0.7222 - val_loss: 1.1081 - val_accuracy: 0.6154\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6743 - accuracy: 0.7259 - val_loss: 1.0635 - val_accuracy: 0.5897\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6930 - accuracy: 0.7037 - val_loss: 1.2558 - val_accuracy: 0.6239\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7677 - accuracy: 0.7148 - val_loss: 1.3487 - val_accuracy: 0.6239\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7449 - accuracy: 0.7148 - val_loss: 1.0522 - val_accuracy: 0.5812\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 554us/step - loss: 0.6710 - accuracy: 0.7259 - val_loss: 1.0550 - val_accuracy: 0.5812\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 351us/step - loss: 0.6627 - accuracy: 0.7407 - val_loss: 1.1028 - val_accuracy: 0.6154\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6729 - accuracy: 0.7222 - val_loss: 1.0531 - val_accuracy: 0.5556\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6815 - accuracy: 0.7000 - val_loss: 1.1215 - val_accuracy: 0.5897\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7002 - accuracy: 0.7148 - val_loss: 1.1548 - val_accuracy: 0.5983\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6740 - accuracy: 0.7185 - val_loss: 1.0744 - val_accuracy: 0.5812\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6677 - accuracy: 0.7222 - val_loss: 1.1053 - val_accuracy: 0.5983\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6619 - accuracy: 0.7296 - val_loss: 1.0491 - val_accuracy: 0.5641\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 65us/step - loss: 0.6890 - accuracy: 0.7111 - val_loss: 1.2204 - val_accuracy: 0.5812\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7690 - accuracy: 0.7111 - val_loss: 1.2332 - val_accuracy: 0.5641\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6994 - accuracy: 0.7000 - val_loss: 1.0664 - val_accuracy: 0.5726\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.6973 - accuracy: 0.6926 - val_loss: 1.2064 - val_accuracy: 0.5983\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7285 - accuracy: 0.7185 - val_loss: 1.1642 - val_accuracy: 0.6239\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6777 - accuracy: 0.7111 - val_loss: 1.0695 - val_accuracy: 0.5897\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7163 - accuracy: 0.6815 - val_loss: 1.4240 - val_accuracy: 0.6239\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8182 - accuracy: 0.7148 - val_loss: 1.4529 - val_accuracy: 0.6239\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7584 - accuracy: 0.7185 - val_loss: 1.0687 - val_accuracy: 0.5812\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7175 - accuracy: 0.7111 - val_loss: 1.1450 - val_accuracy: 0.6154\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7001 - accuracy: 0.7185 - val_loss: 1.2324 - val_accuracy: 0.6154\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6980 - accuracy: 0.7222 - val_loss: 1.0569 - val_accuracy: 0.5812\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6876 - accuracy: 0.6926 - val_loss: 1.0735 - val_accuracy: 0.5897\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6766 - accuracy: 0.7333 - val_loss: 1.0976 - val_accuracy: 0.5897\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7239 - accuracy: 0.7000 - val_loss: 1.2166 - val_accuracy: 0.5214\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7826 - accuracy: 0.6741 - val_loss: 1.3448 - val_accuracy: 0.5470\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7500 - accuracy: 0.7037 - val_loss: 1.0769 - val_accuracy: 0.5470\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6761 - accuracy: 0.7037 - val_loss: 1.1120 - val_accuracy: 0.5726\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7147 - accuracy: 0.7111 - val_loss: 1.1818 - val_accuracy: 0.5897\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7096 - accuracy: 0.7111 - val_loss: 1.1350 - val_accuracy: 0.5556\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6854 - accuracy: 0.7185 - val_loss: 1.0857 - val_accuracy: 0.5726\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7120 - accuracy: 0.7111 - val_loss: 1.1776 - val_accuracy: 0.6068\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7007 - accuracy: 0.7148 - val_loss: 1.1125 - val_accuracy: 0.6068\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6623 - accuracy: 0.7222 - val_loss: 1.0515 - val_accuracy: 0.5983\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6699 - accuracy: 0.7074 - val_loss: 1.1456 - val_accuracy: 0.6239\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6944 - accuracy: 0.7185 - val_loss: 1.1320 - val_accuracy: 0.6239\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6708 - accuracy: 0.7259 - val_loss: 1.0866 - val_accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6744 - accuracy: 0.7296 - val_loss: 1.1282 - val_accuracy: 0.5983\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6906 - accuracy: 0.7000 - val_loss: 1.0617 - val_accuracy: 0.5726\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.6873 - accuracy: 0.7148 - val_loss: 1.1791 - val_accuracy: 0.6239\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7325 - accuracy: 0.7074 - val_loss: 1.1318 - val_accuracy: 0.5897\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7260 - accuracy: 0.6963 - val_loss: 1.2324 - val_accuracy: 0.4957\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7509 - accuracy: 0.7000 - val_loss: 1.1280 - val_accuracy: 0.5812\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7068 - accuracy: 0.7111 - val_loss: 1.1797 - val_accuracy: 0.6154\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6885 - accuracy: 0.7148 - val_loss: 1.0914 - val_accuracy: 0.5812\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6870 - accuracy: 0.7000 - val_loss: 1.1985 - val_accuracy: 0.5897\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7091 - accuracy: 0.7074 - val_loss: 1.1292 - val_accuracy: 0.6154\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6719 - accuracy: 0.7185 - val_loss: 1.0640 - val_accuracy: 0.5897\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6602 - accuracy: 0.7296 - val_loss: 1.0794 - val_accuracy: 0.6239\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6665 - accuracy: 0.7222 - val_loss: 1.0637 - val_accuracy: 0.5897\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6654 - accuracy: 0.7259 - val_loss: 1.0622 - val_accuracy: 0.5726\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6618 - accuracy: 0.7259 - val_loss: 1.0932 - val_accuracy: 0.6239\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6713 - accuracy: 0.7222 - val_loss: 1.0886 - val_accuracy: 0.6239\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6679 - accuracy: 0.7296 - val_loss: 1.0780 - val_accuracy: 0.5470\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6905 - accuracy: 0.7074 - val_loss: 1.1176 - val_accuracy: 0.5812\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.6817 - accuracy: 0.7037 - val_loss: 1.0915 - val_accuracy: 0.5726\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6691 - accuracy: 0.7185 - val_loss: 1.0786 - val_accuracy: 0.5726\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6660 - accuracy: 0.7259 - val_loss: 1.0561 - val_accuracy: 0.5726\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6600 - accuracy: 0.7222 - val_loss: 1.0701 - val_accuracy: 0.6154\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6623 - accuracy: 0.7148 - val_loss: 1.0590 - val_accuracy: 0.6239\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6601 - accuracy: 0.7296 - val_loss: 1.0604 - val_accuracy: 0.6239\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.6652 - accuracy: 0.7296 - val_loss: 1.0730 - val_accuracy: 0.6154\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6616 - accuracy: 0.7296 - val_loss: 1.0514 - val_accuracy: 0.6154\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6669 - accuracy: 0.7074 - val_loss: 1.0587 - val_accuracy: 0.6239\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6622 - accuracy: 0.7296 - val_loss: 1.0571 - val_accuracy: 0.5897\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6677 - accuracy: 0.7296 - val_loss: 1.0730 - val_accuracy: 0.5556\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6708 - accuracy: 0.7185 - val_loss: 1.1210 - val_accuracy: 0.6068\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6806 - accuracy: 0.7259 - val_loss: 1.0503 - val_accuracy: 0.6154\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6785 - accuracy: 0.7000 - val_loss: 1.1622 - val_accuracy: 0.6239\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6979 - accuracy: 0.7148 - val_loss: 1.1351 - val_accuracy: 0.6068\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6876 - accuracy: 0.7111 - val_loss: 1.0742 - val_accuracy: 0.5726\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6641 - accuracy: 0.7185 - val_loss: 1.1131 - val_accuracy: 0.6154\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6934 - accuracy: 0.7185 - val_loss: 1.0721 - val_accuracy: 0.6239\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6600 - accuracy: 0.7222 - val_loss: 1.0548 - val_accuracy: 0.5897\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6731 - accuracy: 0.7111 - val_loss: 1.0770 - val_accuracy: 0.5897\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6732 - accuracy: 0.7148 - val_loss: 1.0446 - val_accuracy: 0.6154\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6612 - accuracy: 0.7296 - val_loss: 1.0668 - val_accuracy: 0.6239\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6612 - accuracy: 0.7259 - val_loss: 1.0406 - val_accuracy: 0.5897\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6681 - accuracy: 0.7148 - val_loss: 1.0628 - val_accuracy: 0.6239\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6677 - accuracy: 0.7259 - val_loss: 1.0435 - val_accuracy: 0.6239\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.78 - 0s 106us/step - loss: 0.7061 - accuracy: 0.7037 - val_loss: 1.0709 - val_accuracy: 0.6068\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6826 - accuracy: 0.7222 - val_loss: 1.0620 - val_accuracy: 0.5897\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7018 - accuracy: 0.6926 - val_loss: 1.1925 - val_accuracy: 0.6068\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7850 - accuracy: 0.7037 - val_loss: 1.3258 - val_accuracy: 0.6239\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7252 - accuracy: 0.7148 - val_loss: 1.1364 - val_accuracy: 0.5641\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8110 - accuracy: 0.7000 - val_loss: 1.5460 - val_accuracy: 0.5812\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9305 - accuracy: 0.6889 - val_loss: 1.6097 - val_accuracy: 0.6325\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8012 - accuracy: 0.7148 - val_loss: 1.1781 - val_accuracy: 0.5641\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.7288 - accuracy: 0.6889 - val_loss: 1.0865 - val_accuracy: 0.5214\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6791 - accuracy: 0.7111 - val_loss: 1.1380 - val_accuracy: 0.5897\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6693 - accuracy: 0.7222 - val_loss: 1.0537 - val_accuracy: 0.5812\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6947 - accuracy: 0.7037 - val_loss: 1.0850 - val_accuracy: 0.5983\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6847 - accuracy: 0.7333 - val_loss: 1.2578 - val_accuracy: 0.6239\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.7155 - accuracy: 0.7185 - val_loss: 1.0983 - val_accuracy: 0.5897\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6609 - accuracy: 0.7222 - val_loss: 1.0573 - val_accuracy: 0.5897\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6787 - accuracy: 0.6889 - val_loss: 1.1370 - val_accuracy: 0.6154\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.7008 - accuracy: 0.7222 - val_loss: 1.2159 - val_accuracy: 0.6239\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6835 - accuracy: 0.7222 - val_loss: 1.0546 - val_accuracy: 0.5726\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6946 - accuracy: 0.7037 - val_loss: 1.0618 - val_accuracy: 0.5897\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.6672 - accuracy: 0.7333 - val_loss: 1.1274 - val_accuracy: 0.6239\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 470us/step - loss: 0.6771 - accuracy: 0.7222 - val_loss: 1.0874 - val_accuracy: 0.5641\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6758 - accuracy: 0.7222 - val_loss: 1.0606 - val_accuracy: 0.5556\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6739 - accuracy: 0.7037 - val_loss: 1.0693 - val_accuracy: 0.5983\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6681 - accuracy: 0.7259 - val_loss: 1.1407 - val_accuracy: 0.6239\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7863 - accuracy: 0.6963 - val_loss: 1.5976 - val_accuracy: 0.5812\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7822 - accuracy: 0.7000 - val_loss: 1.0675 - val_accuracy: 0.5897\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8055 - accuracy: 0.6963 - val_loss: 1.1400 - val_accuracy: 0.5556\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8238 - accuracy: 0.6926 - val_loss: 1.4412 - val_accuracy: 0.5726\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7770 - accuracy: 0.7037 - val_loss: 1.2641 - val_accuracy: 0.5556\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8046 - accuracy: 0.6963 - val_loss: 1.1122 - val_accuracy: 0.5812\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6936 - accuracy: 0.7185 - val_loss: 1.3571 - val_accuracy: 0.5641\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7782 - accuracy: 0.7037 - val_loss: 1.1205 - val_accuracy: 0.5556\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6735 - accuracy: 0.7185 - val_loss: 1.0621 - val_accuracy: 0.5983\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6786 - accuracy: 0.7148 - val_loss: 1.1668 - val_accuracy: 0.6239\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7007 - accuracy: 0.7222 - val_loss: 1.1607 - val_accuracy: 0.5726\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6804 - accuracy: 0.7185 - val_loss: 1.0903 - val_accuracy: 0.5641\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6776 - accuracy: 0.7000 - val_loss: 1.0809 - val_accuracy: 0.5983\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6683 - accuracy: 0.7333 - val_loss: 1.0875 - val_accuracy: 0.5983\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6666 - accuracy: 0.7222 - val_loss: 1.0554 - val_accuracy: 0.5897\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6804 - accuracy: 0.7074 - val_loss: 1.0619 - val_accuracy: 0.5812\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 135us/step - loss: 0.6636 - accuracy: 0.7111 - val_loss: 1.1343 - val_accuracy: 0.6154\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6777 - accuracy: 0.7296 - val_loss: 1.0687 - val_accuracy: 0.5983\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6699 - accuracy: 0.7148 - val_loss: 1.1239 - val_accuracy: 0.5983\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6683 - accuracy: 0.7370 - val_loss: 1.0626 - val_accuracy: 0.5726\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6718 - accuracy: 0.7148 - val_loss: 1.0787 - val_accuracy: 0.5726\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6628 - accuracy: 0.7148 - val_loss: 1.0806 - val_accuracy: 0.6068\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6659 - accuracy: 0.7185 - val_loss: 1.0480 - val_accuracy: 0.5897\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7550 - accuracy: 0.6815 - val_loss: 1.2773 - val_accuracy: 0.6154\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7802 - accuracy: 0.7148 - val_loss: 1.3873 - val_accuracy: 0.6239\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.7495 - accuracy: 0.7111 - val_loss: 1.0880 - val_accuracy: 0.5726\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6609 - accuracy: 0.7148 - val_loss: 1.0514 - val_accuracy: 0.5641\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6756 - accuracy: 0.7296 - val_loss: 1.1734 - val_accuracy: 0.6068\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6978 - accuracy: 0.7148 - val_loss: 1.0493 - val_accuracy: 0.5641\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6593 - accuracy: 0.7259 - val_loss: 1.0630 - val_accuracy: 0.5812\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6619 - accuracy: 0.7185 - val_loss: 1.0611 - val_accuracy: 0.5897\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6628 - accuracy: 0.7185 - val_loss: 1.0438 - val_accuracy: 0.5641\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6620 - accuracy: 0.7333 - val_loss: 1.1194 - val_accuracy: 0.6154\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6727 - accuracy: 0.7222 - val_loss: 1.0484 - val_accuracy: 0.5897\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6771 - accuracy: 0.7259 - val_loss: 1.0857 - val_accuracy: 0.5983\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.7007 - accuracy: 0.7222 - val_loss: 1.2776 - val_accuracy: 0.6068\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.7239 - accuracy: 0.7222 - val_loss: 1.0617 - val_accuracy: 0.6068\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7595 - accuracy: 0.6815 - val_loss: 1.1105 - val_accuracy: 0.6068\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7261 - accuracy: 0.7185 - val_loss: 1.2768 - val_accuracy: 0.6068\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7003 - accuracy: 0.7222 - val_loss: 1.0459 - val_accuracy: 0.5641\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6687 - accuracy: 0.7074 - val_loss: 1.0518 - val_accuracy: 0.5214\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6638 - accuracy: 0.7111 - val_loss: 1.0654 - val_accuracy: 0.6154\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6632 - accuracy: 0.7296 - val_loss: 1.0385 - val_accuracy: 0.5812\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6590 - accuracy: 0.7333 - val_loss: 1.0611 - val_accuracy: 0.6154\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6578 - accuracy: 0.7296 - val_loss: 1.0464 - val_accuracy: 0.5812\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6590 - accuracy: 0.7296 - val_loss: 1.0916 - val_accuracy: 0.6154\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6804 - accuracy: 0.7222 - val_loss: 1.1822 - val_accuracy: 0.6068\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6815 - accuracy: 0.7185 - val_loss: 1.0491 - val_accuracy: 0.5726\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.7108 - accuracy: 0.7222 - val_loss: 1.0853 - val_accuracy: 0.6068\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.7026 - accuracy: 0.7222 - val_loss: 1.2023 - val_accuracy: 0.5983\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6883 - accuracy: 0.7185 - val_loss: 1.0611 - val_accuracy: 0.5641\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6991 - accuracy: 0.7148 - val_loss: 1.2389 - val_accuracy: 0.5983\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7560 - accuracy: 0.7111 - val_loss: 1.4303 - val_accuracy: 0.5812\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7869 - accuracy: 0.7222 - val_loss: 1.1477 - val_accuracy: 0.5983\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6606 - accuracy: 0.7259 - val_loss: 1.0615 - val_accuracy: 0.5214\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6901 - accuracy: 0.7148 - val_loss: 1.2959 - val_accuracy: 0.5214\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7835 - accuracy: 0.6926 - val_loss: 1.1199 - val_accuracy: 0.5214\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7746 - accuracy: 0.7037 - val_loss: 1.1737 - val_accuracy: 0.6068\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7980 - accuracy: 0.7111 - val_loss: 1.5963 - val_accuracy: 0.6325\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8783 - accuracy: 0.7111 - val_loss: 1.3227 - val_accuracy: 0.6154\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7094 - accuracy: 0.7074 - val_loss: 1.1275 - val_accuracy: 0.5470\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7687 - accuracy: 0.6963 - val_loss: 1.3288 - val_accuracy: 0.5641\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7768 - accuracy: 0.7148 - val_loss: 1.2621 - val_accuracy: 0.6068\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6930 - accuracy: 0.7259 - val_loss: 1.0662 - val_accuracy: 0.5556\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6896 - accuracy: 0.7037 - val_loss: 1.1046 - val_accuracy: 0.5897\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6943 - accuracy: 0.7037 - val_loss: 1.1753 - val_accuracy: 0.6068\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6824 - accuracy: 0.7185 - val_loss: 1.0746 - val_accuracy: 0.5726\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6610 - accuracy: 0.7222 - val_loss: 1.0567 - val_accuracy: 0.5812\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6579 - accuracy: 0.7296 - val_loss: 1.0648 - val_accuracy: 0.5812\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6575 - accuracy: 0.7296 - val_loss: 1.0713 - val_accuracy: 0.5897\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6581 - accuracy: 0.7333 - val_loss: 1.0704 - val_accuracy: 0.5897\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6595 - accuracy: 0.7333 - val_loss: 1.0597 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6583 - accuracy: 0.7296 - val_loss: 1.0547 - val_accuracy: 0.5812\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6618 - accuracy: 0.7259 - val_loss: 1.0697 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6581 - accuracy: 0.7296 - val_loss: 1.0607 - val_accuracy: 0.5726\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6597 - accuracy: 0.7222 - val_loss: 1.0937 - val_accuracy: 0.5983\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6819 - accuracy: 0.7185 - val_loss: 1.1505 - val_accuracy: 0.6154\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6667 - accuracy: 0.7259 - val_loss: 1.0557 - val_accuracy: 0.5641\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6714 - accuracy: 0.6926 - val_loss: 1.0485 - val_accuracy: 0.5641\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6606 - accuracy: 0.7259 - val_loss: 1.0638 - val_accuracy: 0.5812\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6666 - accuracy: 0.7259 - val_loss: 1.0946 - val_accuracy: 0.5983\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6693 - accuracy: 0.7074 - val_loss: 1.0417 - val_accuracy: 0.5556\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6647 - accuracy: 0.7185 - val_loss: 1.0720 - val_accuracy: 0.5983\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6604 - accuracy: 0.7296 - val_loss: 1.0404 - val_accuracy: 0.5556\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6620 - accuracy: 0.7111 - val_loss: 1.0789 - val_accuracy: 0.6154\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6987 - accuracy: 0.7222 - val_loss: 1.2043 - val_accuracy: 0.6239\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6815 - accuracy: 0.7185 - val_loss: 1.0328 - val_accuracy: 0.5983\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6737 - accuracy: 0.7037 - val_loss: 1.0559 - val_accuracy: 0.6068\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6670 - accuracy: 0.7222 - val_loss: 1.0491 - val_accuracy: 0.5812\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6632 - accuracy: 0.7111 - val_loss: 1.0373 - val_accuracy: 0.5983\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6581 - accuracy: 0.7370 - val_loss: 1.0638 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6634 - accuracy: 0.7296 - val_loss: 1.0367 - val_accuracy: 0.5983\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6566 - accuracy: 0.7296 - val_loss: 1.0472 - val_accuracy: 0.6239\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6585 - accuracy: 0.7259 - val_loss: 1.0664 - val_accuracy: 0.5897\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6699 - accuracy: 0.7148 - val_loss: 1.0459 - val_accuracy: 0.5641\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6639 - accuracy: 0.7259 - val_loss: 1.1123 - val_accuracy: 0.6239\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6832 - accuracy: 0.7222 - val_loss: 1.0385 - val_accuracy: 0.6239\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.7128 - accuracy: 0.7148 - val_loss: 1.0602 - val_accuracy: 0.6154\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.6978 - accuracy: 0.7259 - val_loss: 1.1676 - val_accuracy: 0.5983\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7210 - accuracy: 0.7037 - val_loss: 1.1588 - val_accuracy: 0.5128\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7824 - accuracy: 0.6926 - val_loss: 1.2622 - val_accuracy: 0.5299\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7345 - accuracy: 0.7037 - val_loss: 1.0641 - val_accuracy: 0.5641\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6855 - accuracy: 0.6963 - val_loss: 1.1851 - val_accuracy: 0.6154\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.7565 - accuracy: 0.7037 - val_loss: 1.2348 - val_accuracy: 0.6239\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.7144 - accuracy: 0.7111 - val_loss: 1.1095 - val_accuracy: 0.5726\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7190 - accuracy: 0.7000 - val_loss: 1.2422 - val_accuracy: 0.6239\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7947 - accuracy: 0.7074 - val_loss: 1.2678 - val_accuracy: 0.6154\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7077 - accuracy: 0.7148 - val_loss: 1.1454 - val_accuracy: 0.5299\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8327 - accuracy: 0.6741 - val_loss: 1.3171 - val_accuracy: 0.5470\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7470 - accuracy: 0.6926 - val_loss: 1.0907 - val_accuracy: 0.5897\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7041 - accuracy: 0.7111 - val_loss: 1.3392 - val_accuracy: 0.5983\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7592 - accuracy: 0.7074 - val_loss: 1.2248 - val_accuracy: 0.6068\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6978 - accuracy: 0.7111 - val_loss: 1.1488 - val_accuracy: 0.5470\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7262 - accuracy: 0.7000 - val_loss: 1.1050 - val_accuracy: 0.5556\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6713 - accuracy: 0.7259 - val_loss: 1.1289 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6943 - accuracy: 0.7222 - val_loss: 1.0952 - val_accuracy: 0.6154\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6708 - accuracy: 0.7111 - val_loss: 1.0690 - val_accuracy: 0.5812\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6638 - accuracy: 0.7148 - val_loss: 1.1286 - val_accuracy: 0.6068\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7011 - accuracy: 0.7222 - val_loss: 1.1471 - val_accuracy: 0.6154\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6781 - accuracy: 0.7185 - val_loss: 1.0663 - val_accuracy: 0.5897\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6744 - accuracy: 0.7296 - val_loss: 1.2368 - val_accuracy: 0.6068\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7345 - accuracy: 0.7185 - val_loss: 1.2503 - val_accuracy: 0.6068\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6860 - accuracy: 0.7185 - val_loss: 1.0866 - val_accuracy: 0.5556\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7055 - accuracy: 0.6889 - val_loss: 1.1733 - val_accuracy: 0.5812\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6927 - accuracy: 0.7111 - val_loss: 1.2041 - val_accuracy: 0.5897\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.6856 - accuracy: 0.7111 - val_loss: 1.0576 - val_accuracy: 0.5470\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6603 - accuracy: 0.7148 - val_loss: 1.0506 - val_accuracy: 0.5641\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6629 - accuracy: 0.7222 - val_loss: 1.1223 - val_accuracy: 0.6239\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6674 - accuracy: 0.7222 - val_loss: 1.0778 - val_accuracy: 0.5983\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 71.37%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.87154600e-01, 9.56542800e-02, 6.17191140e-01],\n",
       "       [8.67139100e-01, 8.68863760e-02, 4.59745750e-02],\n",
       "       [4.02464360e-01, 3.05844680e-02, 5.66951200e-01],\n",
       "       [4.07016800e-03, 1.39784740e-02, 9.81951360e-01],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [2.87154600e-01, 9.56542800e-02, 6.17191140e-01],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [5.79746900e-01, 3.15918860e-01, 1.04334330e-01],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [4.07016800e-03, 1.39784740e-02, 9.81951360e-01],\n",
       "       [4.27348500e-02, 1.08565520e-01, 8.48699600e-01],\n",
       "       [1.32498760e-01, 2.02864860e-01, 6.64636400e-01],\n",
       "       [1.84088360e-01, 2.97449180e-02, 7.86166700e-01],\n",
       "       [8.81933900e-01, 4.00584400e-02, 7.80076600e-02],\n",
       "       [1.25085180e-01, 5.62238160e-01, 3.12676700e-01],\n",
       "       [6.41439760e-03, 6.84890400e-04, 9.92900700e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [4.27348500e-02, 1.08565520e-01, 8.48699600e-01],\n",
       "       [6.90316500e-01, 1.72413800e-01, 1.37269680e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [3.01021280e-01, 3.51735600e-01, 3.47243100e-01],\n",
       "       [4.14006050e-01, 4.60042300e-01, 1.25951650e-01],\n",
       "       [6.41439760e-03, 6.84890400e-04, 9.92900700e-01],\n",
       "       [8.61852100e-01, 1.38041150e-01, 1.06740120e-04],\n",
       "       [1.55267610e-01, 2.60368380e-01, 5.84364000e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [5.90086460e-01, 2.38695200e-01, 1.71218290e-01],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [5.50719800e-01, 2.55107940e-01, 1.94172250e-01],\n",
       "       [3.81084560e-01, 3.85317500e-01, 2.33597900e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [3.71112940e-01, 6.28547100e-01, 3.40058850e-04],\n",
       "       [2.49961260e-01, 6.50421140e-01, 9.96175500e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [1.25085180e-01, 5.62238160e-01, 3.12676700e-01],\n",
       "       [1.45592140e-01, 1.25586750e-01, 7.28821040e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [5.27508000e-01, 4.02593260e-01, 6.98986900e-02],\n",
       "       [2.41404890e-01, 2.94040530e-01, 4.64554580e-01],\n",
       "       [4.98949050e-01, 4.84964820e-01, 1.60861310e-02],\n",
       "       [8.61852100e-01, 1.38041150e-01, 1.06740120e-04],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [2.79161420e-01, 4.42412850e-01, 2.78425750e-01],\n",
       "       [6.97795400e-01, 2.46341900e-01, 5.58627730e-02],\n",
       "       [2.41404890e-01, 2.94040530e-01, 4.64554580e-01],\n",
       "       [1.54651470e-03, 2.70218350e-02, 9.71431700e-01],\n",
       "       [2.13911160e-01, 1.27725740e-01, 6.58363100e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [1.55267610e-01, 2.60368380e-01, 5.84364000e-01],\n",
       "       [9.42590460e-02, 2.43890270e-02, 8.81351950e-01],\n",
       "       [1.54651470e-03, 2.70218350e-02, 9.71431700e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [8.67139100e-01, 8.68863760e-02, 4.59745750e-02],\n",
       "       [9.21475800e-01, 7.49478600e-02, 3.57629520e-03],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [9.21475800e-01, 7.49478600e-02, 3.57629520e-03],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [3.94877830e-02, 3.23082800e-01, 6.37429400e-01],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [7.49413250e-01, 1.48187610e-01, 1.02399185e-01],\n",
       "       [4.07914970e-01, 3.33096770e-01, 2.58988230e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [4.98949050e-01, 4.84964820e-01, 1.60861310e-02],\n",
       "       [4.14006050e-01, 4.60042300e-01, 1.25951650e-01],\n",
       "       [7.49413250e-01, 1.48187610e-01, 1.02399185e-01],\n",
       "       [2.17766520e-02, 1.11372490e-01, 8.66850900e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [2.13911160e-01, 1.27725740e-01, 6.58363100e-01],\n",
       "       [6.91721400e-01, 1.29240360e-01, 1.79038290e-01],\n",
       "       [1.84088360e-01, 2.97449180e-02, 7.86166700e-01],\n",
       "       [2.17766520e-02, 1.11372490e-01, 8.66850900e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [8.28283370e-01, 1.71630130e-01, 8.64520600e-05],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [1.36848660e-01, 5.47414720e-02, 8.08409870e-01],\n",
       "       [1.32498760e-01, 2.02864860e-01, 6.64636400e-01],\n",
       "       [4.14006050e-01, 4.60042300e-01, 1.25951650e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [6.92080700e-01, 1.58598290e-01, 1.49321110e-01],\n",
       "       [5.50719800e-01, 2.55107940e-01, 1.94172250e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [4.14006050e-01, 4.60042300e-01, 1.25951650e-01],\n",
       "       [3.94190160e-01, 6.02367400e-01, 3.44246250e-03],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [5.64260360e-01, 2.77372720e-01, 1.58366900e-01],\n",
       "       [6.97795400e-01, 2.46341900e-01, 5.58627730e-02],\n",
       "       [1.11338130e-01, 8.34743200e-01, 5.39187450e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [5.55014500e-01, 2.95870100e-01, 1.49115370e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [2.87154600e-01, 9.56542800e-02, 6.17191140e-01],\n",
       "       [5.27508000e-01, 4.02593260e-01, 6.98986900e-02],\n",
       "       [1.25085180e-01, 5.62238160e-01, 3.12676700e-01],\n",
       "       [3.90951100e-01, 3.79654560e-01, 2.29394300e-01],\n",
       "       [1.84088360e-01, 2.97449180e-02, 7.86166700e-01],\n",
       "       [1.84088360e-01, 2.97449180e-02, 7.86166700e-01],\n",
       "       [7.75724530e-01, 2.24067390e-01, 2.08186230e-04],\n",
       "       [1.55267610e-01, 2.60368380e-01, 5.84364000e-01],\n",
       "       [2.17766520e-02, 1.11372490e-01, 8.66850900e-01],\n",
       "       [4.07914970e-01, 3.33096770e-01, 2.58988230e-01],\n",
       "       [2.26163900e-04, 9.99542600e-01, 2.31327700e-04],\n",
       "       [3.22821700e-01, 4.34018900e-01, 2.43159400e-01],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [2.17766520e-02, 1.11372490e-01, 8.66850900e-01],\n",
       "       [8.61852100e-01, 1.38041150e-01, 1.06740120e-04],\n",
       "       [8.19277700e-01, 1.80644200e-01, 7.81190000e-05],\n",
       "       [4.07914970e-01, 3.33096770e-01, 2.58988230e-01],\n",
       "       [8.61852100e-01, 1.38041150e-01, 1.06740120e-04],\n",
       "       [5.27202840e-01, 4.37141300e-01, 3.56558260e-02],\n",
       "       [3.47299000e-01, 5.57314000e-01, 9.53869700e-02],\n",
       "       [9.42590460e-02, 2.43890270e-02, 8.81351950e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286872671488056"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286872671488056"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS210     0\n",
       "1         NRS205     2\n",
       "2            312     2\n",
       "3           GA15     2\n",
       "4         SR4035     0\n",
       "..           ...   ...\n",
       "112       NRS265     2\n",
       "113  CFBREBSa108     1\n",
       "114        NY224     1\n",
       "115       NRS386     2\n",
       "116       NRS168     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 472us/step - loss: 17.6857 - accuracy: 0.3333 - val_loss: 21.3819 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 12.5583 - accuracy: 0.3111 - val_loss: 15.3782 - val_accuracy: 0.3248\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 9.4249 - accuracy: 0.2704 - val_loss: 12.7497 - val_accuracy: 0.2991\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 7.6449 - accuracy: 0.2852 - val_loss: 10.1050 - val_accuracy: 0.2735\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 5.7325 - accuracy: 0.2519 - val_loss: 7.8803 - val_accuracy: 0.2906\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 4.6877 - accuracy: 0.3000 - val_loss: 5.8561 - val_accuracy: 0.3248\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 3.4576 - accuracy: 0.3000 - val_loss: 4.1356 - val_accuracy: 0.3419\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 2.4642 - accuracy: 0.3296 - val_loss: 2.4551 - val_accuracy: 0.3504\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.5412 - accuracy: 0.3963 - val_loss: 1.5471 - val_accuracy: 0.3675\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.4471 - accuracy: 0.3815 - val_loss: 1.5894 - val_accuracy: 0.3248\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.3208 - accuracy: 0.3667 - val_loss: 1.5732 - val_accuracy: 0.3590\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.3801 - accuracy: 0.4148 - val_loss: 1.3620 - val_accuracy: 0.4274\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.2978 - accuracy: 0.4259 - val_loss: 1.3601 - val_accuracy: 0.4188\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.1913 - accuracy: 0.4481 - val_loss: 1.2887 - val_accuracy: 0.5043\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.1600 - accuracy: 0.5556 - val_loss: 1.4333 - val_accuracy: 0.5128\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.1667 - accuracy: 0.5407 - val_loss: 1.2793 - val_accuracy: 0.4701\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.1791 - accuracy: 0.5148 - val_loss: 1.2755 - val_accuracy: 0.4444\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.2334 - accuracy: 0.5000 - val_loss: 1.2434 - val_accuracy: 0.4615\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 1.1965 - accuracy: 0.5407 - val_loss: 1.3029 - val_accuracy: 0.4188\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.1349 - accuracy: 0.5037 - val_loss: 1.3044 - val_accuracy: 0.4188\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.2926 - accuracy: 0.5148 - val_loss: 1.1963 - val_accuracy: 0.4872\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1807 - accuracy: 0.5296 - val_loss: 1.2129 - val_accuracy: 0.4786\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0914 - accuracy: 0.5000 - val_loss: 1.1738 - val_accuracy: 0.4872\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 1.0587 - accuracy: 0.5481 - val_loss: 1.1971 - val_accuracy: 0.4615\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.1135 - accuracy: 0.5519 - val_loss: 1.1678 - val_accuracy: 0.5299\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0589 - accuracy: 0.5778 - val_loss: 1.2879 - val_accuracy: 0.4701\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.0443 - accuracy: 0.5704 - val_loss: 1.1161 - val_accuracy: 0.4615\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.0106 - accuracy: 0.5630 - val_loss: 1.1388 - val_accuracy: 0.4615\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0010 - accuracy: 0.5741 - val_loss: 1.0809 - val_accuracy: 0.5385\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.0234 - accuracy: 0.5519 - val_loss: 1.2646 - val_accuracy: 0.4786\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 480us/step - loss: 1.0510 - accuracy: 0.5593 - val_loss: 1.1398 - val_accuracy: 0.4872\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.1869 - accuracy: 0.5370 - val_loss: 1.1929 - val_accuracy: 0.4957\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.0496 - accuracy: 0.5519 - val_loss: 1.1359 - val_accuracy: 0.5385\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 465us/step - loss: 1.0949 - accuracy: 0.5667 - val_loss: 1.1024 - val_accuracy: 0.5043\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 1.0643 - accuracy: 0.5333 - val_loss: 1.0982 - val_accuracy: 0.5128\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 548us/step - loss: 1.0179 - accuracy: 0.5741 - val_loss: 1.0971 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9772 - accuracy: 0.6000 - val_loss: 1.0370 - val_accuracy: 0.5214\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9734 - accuracy: 0.5741 - val_loss: 1.0632 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9912 - accuracy: 0.6000 - val_loss: 1.0420 - val_accuracy: 0.5214\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9702 - accuracy: 0.5963 - val_loss: 1.0221 - val_accuracy: 0.5385\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 457us/step - loss: 0.9545 - accuracy: 0.6000 - val_loss: 1.0569 - val_accuracy: 0.5299\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 1.0220 - accuracy: 0.6000 - val_loss: 1.0166 - val_accuracy: 0.5556\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 410us/step - loss: 0.9855 - accuracy: 0.5963 - val_loss: 1.0437 - val_accuracy: 0.5128\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9787 - accuracy: 0.5963 - val_loss: 1.0265 - val_accuracy: 0.5385\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.9848 - accuracy: 0.5852 - val_loss: 1.0507 - val_accuracy: 0.5385\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 1.0049 - accuracy: 0.5778 - val_loss: 1.1240 - val_accuracy: 0.5214\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.0960 - accuracy: 0.5889 - val_loss: 1.1662 - val_accuracy: 0.5470\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 1.3975 - accuracy: 0.5778 - val_loss: 1.1192 - val_accuracy: 0.5556\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 1.3284 - accuracy: 0.5667 - val_loss: 1.2172 - val_accuracy: 0.4957\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.1636 - accuracy: 0.5593 - val_loss: 1.1905 - val_accuracy: 0.5214\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 1.0657 - accuracy: 0.5963 - val_loss: 1.0941 - val_accuracy: 0.5214\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 1.0502 - accuracy: 0.6000 - val_loss: 1.0371 - val_accuracy: 0.5470\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9666 - accuracy: 0.5704 - val_loss: 1.0676 - val_accuracy: 0.5556\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0016 - accuracy: 0.6000 - val_loss: 1.0688 - val_accuracy: 0.5470\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0586 - accuracy: 0.6037 - val_loss: 1.0623 - val_accuracy: 0.5470\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9529 - accuracy: 0.6037 - val_loss: 1.0031 - val_accuracy: 0.5556\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9497 - accuracy: 0.6111 - val_loss: 1.0453 - val_accuracy: 0.5470\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9442 - accuracy: 0.6037 - val_loss: 0.9791 - val_accuracy: 0.5556\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9237 - accuracy: 0.6185 - val_loss: 1.0021 - val_accuracy: 0.5385\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9664 - accuracy: 0.6148 - val_loss: 0.9686 - val_accuracy: 0.5812\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 1.0822 - accuracy: 0.6148 - val_loss: 1.2462 - val_accuracy: 0.5385\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 1.3030 - accuracy: 0.5815 - val_loss: 1.1240 - val_accuracy: 0.5470\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 1.0906 - accuracy: 0.5852 - val_loss: 1.4953 - val_accuracy: 0.4957\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 1.2766 - accuracy: 0.5704 - val_loss: 1.8427 - val_accuracy: 0.4359\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.4331 - accuracy: 0.5741 - val_loss: 1.5808 - val_accuracy: 0.5299\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 1.0818 - accuracy: 0.5778 - val_loss: 1.2911 - val_accuracy: 0.5128\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.1710 - accuracy: 0.5778 - val_loss: 1.2064 - val_accuracy: 0.5128\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 1.0349 - accuracy: 0.5963 - val_loss: 1.0450 - val_accuracy: 0.5470\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.9977 - accuracy: 0.5889 - val_loss: 1.0018 - val_accuracy: 0.5641\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 1.1136 - accuracy: 0.5815 - val_loss: 1.2961 - val_accuracy: 0.5043\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.1391 - accuracy: 0.5963 - val_loss: 1.0162 - val_accuracy: 0.5641\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9355 - accuracy: 0.6000 - val_loss: 1.0356 - val_accuracy: 0.5299\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8973 - accuracy: 0.6037 - val_loss: 0.9922 - val_accuracy: 0.5299\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9327 - accuracy: 0.6074 - val_loss: 1.0119 - val_accuracy: 0.5556\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.2662 - accuracy: 0.6000 - val_loss: 1.3308 - val_accuracy: 0.5556\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 1.2021 - accuracy: 0.6000 - val_loss: 0.9794 - val_accuracy: 0.5641\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.9667 - accuracy: 0.5889 - val_loss: 1.0018 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 1.1487 - accuracy: 0.6148 - val_loss: 1.1898 - val_accuracy: 0.5726\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.0419 - accuracy: 0.6185 - val_loss: 1.0609 - val_accuracy: 0.5214\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.2168 - accuracy: 0.6000 - val_loss: 1.2292 - val_accuracy: 0.5983\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.2900 - accuracy: 0.6333 - val_loss: 1.2075 - val_accuracy: 0.5641\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0258 - accuracy: 0.5963 - val_loss: 1.1427 - val_accuracy: 0.5128\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9884 - accuracy: 0.6074 - val_loss: 0.9991 - val_accuracy: 0.5556\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8862 - accuracy: 0.6296 - val_loss: 1.0458 - val_accuracy: 0.5299\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9242 - accuracy: 0.6370 - val_loss: 1.0320 - val_accuracy: 0.5983\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9674 - accuracy: 0.6481 - val_loss: 0.9851 - val_accuracy: 0.5385\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8917 - accuracy: 0.6185 - val_loss: 0.9821 - val_accuracy: 0.5641\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.8716 - accuracy: 0.6296 - val_loss: 1.0954 - val_accuracy: 0.5556\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 1.0293 - accuracy: 0.6148 - val_loss: 0.9719 - val_accuracy: 0.5726\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.9102 - accuracy: 0.6259 - val_loss: 1.0430 - val_accuracy: 0.5556\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9006 - accuracy: 0.6222 - val_loss: 0.9580 - val_accuracy: 0.5726\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9222 - accuracy: 0.6111 - val_loss: 1.1513 - val_accuracy: 0.5128\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9579 - accuracy: 0.6000 - val_loss: 1.1121 - val_accuracy: 0.5641\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9619 - accuracy: 0.6222 - val_loss: 1.1485 - val_accuracy: 0.5470\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0370 - accuracy: 0.6000 - val_loss: 1.1079 - val_accuracy: 0.5556\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 1.2504 - accuracy: 0.6481 - val_loss: 1.1206 - val_accuracy: 0.5726\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.1023 - accuracy: 0.5815 - val_loss: 1.4112 - val_accuracy: 0.5385\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0254 - accuracy: 0.6000 - val_loss: 0.9495 - val_accuracy: 0.5556\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9238 - accuracy: 0.5815 - val_loss: 1.1197 - val_accuracy: 0.6154\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9660 - accuracy: 0.6370 - val_loss: 0.9586 - val_accuracy: 0.5641\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.0831 - accuracy: 0.6185 - val_loss: 0.9909 - val_accuracy: 0.5385\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9608 - accuracy: 0.6296 - val_loss: 0.9245 - val_accuracy: 0.5812\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9436 - accuracy: 0.6296 - val_loss: 0.9194 - val_accuracy: 0.5812\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9238 - accuracy: 0.6111 - val_loss: 0.9222 - val_accuracy: 0.5897\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 1.0368 - accuracy: 0.6185 - val_loss: 1.0107 - val_accuracy: 0.5470\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.9667 - accuracy: 0.6185 - val_loss: 0.9423 - val_accuracy: 0.5641\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8703 - accuracy: 0.6296 - val_loss: 1.1096 - val_accuracy: 0.5641\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.9990 - accuracy: 0.6037 - val_loss: 0.9403 - val_accuracy: 0.5812\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 1.0129 - accuracy: 0.6148 - val_loss: 0.9737 - val_accuracy: 0.5556\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8585 - accuracy: 0.6185 - val_loss: 1.0321 - val_accuracy: 0.5641\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8985 - accuracy: 0.6037 - val_loss: 0.9289 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9225 - accuracy: 0.6111 - val_loss: 0.9342 - val_accuracy: 0.6068\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9225 - accuracy: 0.6148 - val_loss: 0.9952 - val_accuracy: 0.5897\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0887 - accuracy: 0.6370 - val_loss: 0.9742 - val_accuracy: 0.5556\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8811 - accuracy: 0.6222 - val_loss: 0.9274 - val_accuracy: 0.5983\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.1196 - accuracy: 0.6519 - val_loss: 1.1413 - val_accuracy: 0.5641\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1813 - accuracy: 0.5815 - val_loss: 1.1548 - val_accuracy: 0.5043\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9324 - accuracy: 0.6185 - val_loss: 0.9372 - val_accuracy: 0.5214\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8531 - accuracy: 0.6148 - val_loss: 1.0047 - val_accuracy: 0.5470\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.9319 - accuracy: 0.6333 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.62 - 0s 97us/step - loss: 0.9331 - accuracy: 0.6222 - val_loss: 1.0516 - val_accuracy: 0.6068\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 1.0960 - accuracy: 0.6519 - val_loss: 0.9527 - val_accuracy: 0.6068\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8333 - accuracy: 0.68 - 0s 156us/step - loss: 0.9112 - accuracy: 0.6185 - val_loss: 0.9961 - val_accuracy: 0.5726\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8783 - accuracy: 0.6185 - val_loss: 0.9300 - val_accuracy: 0.5983\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8428 - accuracy: 0.6630 - val_loss: 0.9148 - val_accuracy: 0.5897\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8735 - accuracy: 0.6593 - val_loss: 0.9090 - val_accuracy: 0.6239\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8799 - accuracy: 0.6481 - val_loss: 0.8968 - val_accuracy: 0.6239\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9737 - accuracy: 0.6556 - val_loss: 0.9789 - val_accuracy: 0.5897\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8751 - accuracy: 0.6185 - val_loss: 1.0241 - val_accuracy: 0.5299\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8506 - accuracy: 0.6333 - val_loss: 0.8998 - val_accuracy: 0.6239\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8618 - accuracy: 0.6593 - val_loss: 1.0210 - val_accuracy: 0.5897\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.9280 - accuracy: 0.6519 - val_loss: 0.9723 - val_accuracy: 0.5897\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9016 - accuracy: 0.6407 - val_loss: 1.1493 - val_accuracy: 0.5641\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.0910 - accuracy: 0.6222 - val_loss: 0.9222 - val_accuracy: 0.5556\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.0392 - accuracy: 0.6333 - val_loss: 1.1281 - val_accuracy: 0.6068\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9663 - accuracy: 0.6259 - val_loss: 1.2932 - val_accuracy: 0.4872\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9721 - accuracy: 0.6296 - val_loss: 0.9957 - val_accuracy: 0.5897\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8912 - accuracy: 0.6630 - val_loss: 0.9033 - val_accuracy: 0.6325\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8843 - accuracy: 0.6667 - val_loss: 0.8907 - val_accuracy: 0.6325\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8462 - accuracy: 0.6630 - val_loss: 0.9393 - val_accuracy: 0.5812\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8791 - accuracy: 0.6630 - val_loss: 0.9164 - val_accuracy: 0.6154\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8279 - accuracy: 0.6519 - val_loss: 0.8937 - val_accuracy: 0.6154\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8227 - accuracy: 0.6593 - val_loss: 0.8904 - val_accuracy: 0.6154\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8398 - accuracy: 0.6593 - val_loss: 0.9104 - val_accuracy: 0.5983\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8441 - accuracy: 0.6593 - val_loss: 0.9388 - val_accuracy: 0.6068\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8565 - accuracy: 0.6519 - val_loss: 0.9156 - val_accuracy: 0.5897\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9262 - accuracy: 0.6444 - val_loss: 0.9776 - val_accuracy: 0.5897\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9837 - accuracy: 0.6667 - val_loss: 0.8969 - val_accuracy: 0.5897\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9157 - accuracy: 0.6259 - val_loss: 1.1142 - val_accuracy: 0.5897\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0243 - accuracy: 0.6222 - val_loss: 0.9216 - val_accuracy: 0.5556\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9051 - accuracy: 0.6148 - val_loss: 0.9435 - val_accuracy: 0.5897\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9205 - accuracy: 0.6185 - val_loss: 0.9137 - val_accuracy: 0.6068\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 1.0081 - accuracy: 0.6556 - val_loss: 0.9368 - val_accuracy: 0.5897\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8784 - accuracy: 0.6519 - val_loss: 0.9414 - val_accuracy: 0.6068\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9077 - accuracy: 0.6333 - val_loss: 0.9320 - val_accuracy: 0.6239\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 1.0461 - accuracy: 0.6481 - val_loss: 0.9768 - val_accuracy: 0.5983\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9555 - accuracy: 0.6000 - val_loss: 0.9486 - val_accuracy: 0.5897\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.0751 - accuracy: 0.6556 - val_loss: 1.0082 - val_accuracy: 0.5983\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.9635 - accuracy: 0.6556 - val_loss: 0.9659 - val_accuracy: 0.5556\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 0.9755 - accuracy: 0.6556 - val_loss: 1.0129 - val_accuracy: 0.5897\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8633 - accuracy: 0.6519 - val_loss: 1.0102 - val_accuracy: 0.5470\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.9340 - accuracy: 0.6481 - val_loss: 1.0880 - val_accuracy: 0.5812\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9721 - accuracy: 0.6630 - val_loss: 0.8908 - val_accuracy: 0.6068\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8503 - accuracy: 0.6556 - val_loss: 0.9184 - val_accuracy: 0.5812\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8994 - accuracy: 0.6444 - val_loss: 0.8767 - val_accuracy: 0.6068\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.9748 - accuracy: 0.6407 - val_loss: 1.2523 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9068 - accuracy: 0.6296 - val_loss: 0.9048 - val_accuracy: 0.5897\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.1805 - accuracy: 0.6222 - val_loss: 1.5372 - val_accuracy: 0.5470\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1411 - accuracy: 0.6185 - val_loss: 1.0043 - val_accuracy: 0.5897\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9489 - accuracy: 0.6296 - val_loss: 0.8981 - val_accuracy: 0.6154\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8757 - accuracy: 0.6481 - val_loss: 0.9819 - val_accuracy: 0.5897\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9426 - accuracy: 0.6407 - val_loss: 0.8866 - val_accuracy: 0.6154\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8069 - accuracy: 0.6667 - val_loss: 0.9993 - val_accuracy: 0.5641\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8845 - accuracy: 0.6556 - val_loss: 0.9526 - val_accuracy: 0.6068\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8165 - accuracy: 0.6630 - val_loss: 0.9835 - val_accuracy: 0.5897\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8521 - accuracy: 0.6667 - val_loss: 0.9987 - val_accuracy: 0.6239\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9568 - accuracy: 0.6481 - val_loss: 0.8798 - val_accuracy: 0.6239\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8130 - accuracy: 0.6630 - val_loss: 0.9016 - val_accuracy: 0.6068\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8192 - accuracy: 0.6704 - val_loss: 0.9013 - val_accuracy: 0.5983\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8123 - accuracy: 0.6704 - val_loss: 0.9039 - val_accuracy: 0.6154\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7944 - accuracy: 0.6852 - val_loss: 0.9597 - val_accuracy: 0.5983\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8727 - accuracy: 0.6556 - val_loss: 0.9075 - val_accuracy: 0.6154\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8363 - accuracy: 0.6630 - val_loss: 0.9215 - val_accuracy: 0.6068\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7954 - accuracy: 0.6630 - val_loss: 0.8721 - val_accuracy: 0.6068\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8108 - accuracy: 0.6519 - val_loss: 0.8719 - val_accuracy: 0.6068\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7891 - accuracy: 0.6593 - val_loss: 0.8870 - val_accuracy: 0.5897\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8028 - accuracy: 0.6630 - val_loss: 0.8788 - val_accuracy: 0.5726\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8820 - accuracy: 0.6519 - val_loss: 1.0070 - val_accuracy: 0.5897\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0958 - accuracy: 0.6704 - val_loss: 0.9926 - val_accuracy: 0.5812\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9215 - accuracy: 0.6370 - val_loss: 1.0407 - val_accuracy: 0.5214\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9830 - accuracy: 0.6444 - val_loss: 0.9669 - val_accuracy: 0.5812\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8414 - accuracy: 0.6593 - val_loss: 0.9085 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8210 - accuracy: 0.6667 - val_loss: 0.8956 - val_accuracy: 0.5983\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8007 - accuracy: 0.6519 - val_loss: 0.8789 - val_accuracy: 0.6239\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8537 - accuracy: 0.6593 - val_loss: 0.8844 - val_accuracy: 0.6325\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8397 - accuracy: 0.6481 - val_loss: 0.8707 - val_accuracy: 0.6068\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8083 - accuracy: 0.6704 - val_loss: 0.9190 - val_accuracy: 0.6154\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8223 - accuracy: 0.6852 - val_loss: 1.0540 - val_accuracy: 0.5812\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9175 - accuracy: 0.6667 - val_loss: 1.0185 - val_accuracy: 0.5897\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.9216 - accuracy: 0.6593 - val_loss: 0.9850 - val_accuracy: 0.5812\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8024 - accuracy: 0.6630 - val_loss: 0.8720 - val_accuracy: 0.6154\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8138 - accuracy: 0.6852 - val_loss: 0.9454 - val_accuracy: 0.5726\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8085 - accuracy: 0.6630 - val_loss: 0.9291 - val_accuracy: 0.6154\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8429 - accuracy: 0.6667 - val_loss: 1.0587 - val_accuracy: 0.5812\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8502 - accuracy: 0.6815 - val_loss: 0.9750 - val_accuracy: 0.5983\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8811 - accuracy: 0.6556 - val_loss: 1.1311 - val_accuracy: 0.5812\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0081 - accuracy: 0.6481 - val_loss: 0.8751 - val_accuracy: 0.6068\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8032 - accuracy: 0.6704 - val_loss: 0.8920 - val_accuracy: 0.6154\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8367 - accuracy: 0.6741 - val_loss: 0.9509 - val_accuracy: 0.5726\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8222 - accuracy: 0.6778 - val_loss: 0.9273 - val_accuracy: 0.5983\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7987 - accuracy: 0.6741 - val_loss: 0.9370 - val_accuracy: 0.5726\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7987 - accuracy: 0.6815 - val_loss: 0.8662 - val_accuracy: 0.6239\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7794 - accuracy: 0.6704 - val_loss: 0.9276 - val_accuracy: 0.5812\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8346 - accuracy: 0.6593 - val_loss: 0.8848 - val_accuracy: 0.6154\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8303 - accuracy: 0.6667 - val_loss: 0.8803 - val_accuracy: 0.6154\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8068 - accuracy: 0.6593 - val_loss: 0.8799 - val_accuracy: 0.5983\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7862 - accuracy: 0.6741 - val_loss: 0.8759 - val_accuracy: 0.5983\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7867 - accuracy: 0.6519 - val_loss: 0.8757 - val_accuracy: 0.5983\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7861 - accuracy: 0.6852 - val_loss: 0.8825 - val_accuracy: 0.5812\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7913 - accuracy: 0.6704 - val_loss: 0.8672 - val_accuracy: 0.6154\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8038 - accuracy: 0.6778 - val_loss: 0.9364 - val_accuracy: 0.5726\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7812 - accuracy: 0.6667 - val_loss: 0.8683 - val_accuracy: 0.6325\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.7986 - accuracy: 0.6741 - val_loss: 0.8789 - val_accuracy: 0.6239\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8200 - accuracy: 0.6630 - val_loss: 0.8693 - val_accuracy: 0.5983\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7917 - accuracy: 0.6815 - val_loss: 0.8676 - val_accuracy: 0.6068\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7969 - accuracy: 0.6815 - val_loss: 0.8693 - val_accuracy: 0.5983\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7744 - accuracy: 0.6852 - val_loss: 0.8709 - val_accuracy: 0.5897\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7741 - accuracy: 0.6667 - val_loss: 0.8832 - val_accuracy: 0.5983\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7755 - accuracy: 0.6630 - val_loss: 0.8653 - val_accuracy: 0.5983\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.7872 - accuracy: 0.6778 - val_loss: 0.8784 - val_accuracy: 0.5983\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7914 - accuracy: 0.6741 - val_loss: 0.8733 - val_accuracy: 0.6068\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7918 - accuracy: 0.6704 - val_loss: 0.8625 - val_accuracy: 0.5983\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7785 - accuracy: 0.6815 - val_loss: 0.8622 - val_accuracy: 0.6154\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7771 - accuracy: 0.6741 - val_loss: 0.8750 - val_accuracy: 0.6068\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7774 - accuracy: 0.6481 - val_loss: 0.8747 - val_accuracy: 0.5983\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.7822 - accuracy: 0.6815 - val_loss: 0.8841 - val_accuracy: 0.5897\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7775 - accuracy: 0.6630 - val_loss: 0.8870 - val_accuracy: 0.6239\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8041 - accuracy: 0.6815 - val_loss: 0.8944 - val_accuracy: 0.5812\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7775 - accuracy: 0.6630 - val_loss: 0.8756 - val_accuracy: 0.6154\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7764 - accuracy: 0.6815 - val_loss: 0.8738 - val_accuracy: 0.5812\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7805 - accuracy: 0.6704 - val_loss: 0.8809 - val_accuracy: 0.5983\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8508 - accuracy: 0.6667 - val_loss: 0.8833 - val_accuracy: 0.6154\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7861 - accuracy: 0.6741 - val_loss: 1.0091 - val_accuracy: 0.5726\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8163 - accuracy: 0.6778 - val_loss: 1.0497 - val_accuracy: 0.5726\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9724 - accuracy: 0.6407 - val_loss: 0.8796 - val_accuracy: 0.5897\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7954 - accuracy: 0.6815 - val_loss: 0.8834 - val_accuracy: 0.6239\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7974 - accuracy: 0.6667 - val_loss: 0.9083 - val_accuracy: 0.5812\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7721 - accuracy: 0.6815 - val_loss: 0.8646 - val_accuracy: 0.6410\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7755 - accuracy: 0.6815 - val_loss: 0.8688 - val_accuracy: 0.5983\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7795 - accuracy: 0.6593 - val_loss: 0.8728 - val_accuracy: 0.6325\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7841 - accuracy: 0.6815 - val_loss: 0.8940 - val_accuracy: 0.5983\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7666 - accuracy: 0.6630 - val_loss: 0.8646 - val_accuracy: 0.5983\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7954 - accuracy: 0.6741 - val_loss: 0.8605 - val_accuracy: 0.6325\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7780 - accuracy: 0.7000 - val_loss: 0.9058 - val_accuracy: 0.5812\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8274 - accuracy: 0.6370 - val_loss: 0.8981 - val_accuracy: 0.6154\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8985 - accuracy: 0.6741 - val_loss: 1.0760 - val_accuracy: 0.5897\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9567 - accuracy: 0.6704 - val_loss: 0.9333 - val_accuracy: 0.5812\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 357us/step - loss: 0.8274 - accuracy: 0.6667 - val_loss: 0.8872 - val_accuracy: 0.6239\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.7903 - accuracy: 0.6889 - val_loss: 0.8801 - val_accuracy: 0.6325\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 330us/step - loss: 0.8497 - accuracy: 0.6481 - val_loss: 0.9053 - val_accuracy: 0.6154\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8438 - accuracy: 0.6630 - val_loss: 0.8731 - val_accuracy: 0.6410\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.7736 - accuracy: 0.6852 - val_loss: 0.8709 - val_accuracy: 0.6154\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.7650 - accuracy: 0.6852 - val_loss: 0.8628 - val_accuracy: 0.6154\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.7697 - accuracy: 0.6667 - val_loss: 0.8798 - val_accuracy: 0.6239\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7714 - accuracy: 0.6852 - val_loss: 0.9125 - val_accuracy: 0.5812\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8076 - accuracy: 0.6778 - val_loss: 0.8683 - val_accuracy: 0.6325\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9327 - accuracy: 0.6593 - val_loss: 0.9084 - val_accuracy: 0.5726\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.9908 - accuracy: 0.6593 - val_loss: 0.9023 - val_accuracy: 0.5726\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.9188 - accuracy: 0.6519 - val_loss: 1.0422 - val_accuracy: 0.5812\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8638 - accuracy: 0.6593 - val_loss: 0.8714 - val_accuracy: 0.5983\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8242 - accuracy: 0.6593 - val_loss: 0.9392 - val_accuracy: 0.5726\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7954 - accuracy: 0.6667 - val_loss: 0.8607 - val_accuracy: 0.6410\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7702 - accuracy: 0.6852 - val_loss: 0.8645 - val_accuracy: 0.6154\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7710 - accuracy: 0.6630 - val_loss: 0.8624 - val_accuracy: 0.6239\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8319 - accuracy: 0.6630 - val_loss: 1.1536 - val_accuracy: 0.5812\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8483 - accuracy: 0.6889 - val_loss: 0.8617 - val_accuracy: 0.6068\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 121us/step - loss: 0.8246 - accuracy: 0.6667 - val_loss: 0.9006 - val_accuracy: 0.6154\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8235 - accuracy: 0.6815 - val_loss: 0.9336 - val_accuracy: 0.5726\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7766 - accuracy: 0.6852 - val_loss: 0.9227 - val_accuracy: 0.6239\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7835 - accuracy: 0.6815 - val_loss: 1.0378 - val_accuracy: 0.5812\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8093 - accuracy: 0.6630 - val_loss: 0.8614 - val_accuracy: 0.6154\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7594 - accuracy: 0.6963 - val_loss: 0.8630 - val_accuracy: 0.6410\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7673 - accuracy: 0.6815 - val_loss: 0.8800 - val_accuracy: 0.6068\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7686 - accuracy: 0.6778 - val_loss: 0.8666 - val_accuracy: 0.6325\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7752 - accuracy: 0.6889 - val_loss: 0.8777 - val_accuracy: 0.6068\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7735 - accuracy: 0.6704 - val_loss: 0.8954 - val_accuracy: 0.6154\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7709 - accuracy: 0.6815 - val_loss: 0.8667 - val_accuracy: 0.6154\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7101 - accuracy: 0.71 - 0s 135us/step - loss: 0.7768 - accuracy: 0.6852 - val_loss: 0.9167 - val_accuracy: 0.5983\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.7680 - accuracy: 0.6963 - val_loss: 0.8833 - val_accuracy: 0.6154\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8172 - accuracy: 0.6741 - val_loss: 0.9126 - val_accuracy: 0.6325\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9081 - accuracy: 0.6741 - val_loss: 0.8868 - val_accuracy: 0.5983\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8988 - accuracy: 0.6630 - val_loss: 1.1508 - val_accuracy: 0.5726\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.1091 - accuracy: 0.6630 - val_loss: 1.0263 - val_accuracy: 0.5641\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.1080 - accuracy: 0.6148 - val_loss: 0.9003 - val_accuracy: 0.6068\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9053 - accuracy: 0.6704 - val_loss: 1.0139 - val_accuracy: 0.5983\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8595 - accuracy: 0.6593 - val_loss: 0.8697 - val_accuracy: 0.6239\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7881 - accuracy: 0.6852 - val_loss: 0.9068 - val_accuracy: 0.5812\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7744 - accuracy: 0.6667 - val_loss: 0.8814 - val_accuracy: 0.6325\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7741 - accuracy: 0.6889 - val_loss: 1.0558 - val_accuracy: 0.5812\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8412 - accuracy: 0.6741 - val_loss: 0.8579 - val_accuracy: 0.6496\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7707 - accuracy: 0.6815 - val_loss: 0.8581 - val_accuracy: 0.6154\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8765 - accuracy: 0.6667 - val_loss: 0.9246 - val_accuracy: 0.5983\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8306 - accuracy: 0.6593 - val_loss: 0.8581 - val_accuracy: 0.6325\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7788 - accuracy: 0.7000 - val_loss: 0.9667 - val_accuracy: 0.6239\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9103 - accuracy: 0.6704 - val_loss: 1.0012 - val_accuracy: 0.5812\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8876 - accuracy: 0.6704 - val_loss: 0.8607 - val_accuracy: 0.6239\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7698 - accuracy: 0.6778 - val_loss: 0.8818 - val_accuracy: 0.6239\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8571 - accuracy: 0.6926 - val_loss: 0.9727 - val_accuracy: 0.5726\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7878 - accuracy: 0.6704 - val_loss: 0.8545 - val_accuracy: 0.6410\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7511 - accuracy: 0.6963 - val_loss: 0.8708 - val_accuracy: 0.5983\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.7678 - accuracy: 0.6667 - val_loss: 0.9441 - val_accuracy: 0.5726\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8081 - accuracy: 0.6704 - val_loss: 0.8579 - val_accuracy: 0.6410\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7778 - accuracy: 0.6815 - val_loss: 0.9196 - val_accuracy: 0.5983\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7989 - accuracy: 0.6444 - val_loss: 0.8622 - val_accuracy: 0.6068\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7668 - accuracy: 0.6741 - val_loss: 0.9857 - val_accuracy: 0.5812\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9057 - accuracy: 0.6778 - val_loss: 0.9803 - val_accuracy: 0.6068\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8106 - accuracy: 0.6593 - val_loss: 0.9359 - val_accuracy: 0.5983\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8434 - accuracy: 0.6667 - val_loss: 0.9018 - val_accuracy: 0.5812\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7885 - accuracy: 0.6667 - val_loss: 0.8611 - val_accuracy: 0.6154\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7684 - accuracy: 0.6630 - val_loss: 0.8685 - val_accuracy: 0.6239\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7682 - accuracy: 0.6741 - val_loss: 0.8618 - val_accuracy: 0.6239\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7533 - accuracy: 0.6889 - val_loss: 0.8685 - val_accuracy: 0.6325\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7613 - accuracy: 0.6889 - val_loss: 0.8780 - val_accuracy: 0.5983\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7805 - accuracy: 0.6852 - val_loss: 0.8821 - val_accuracy: 0.6239\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7589 - accuracy: 0.6889 - val_loss: 0.8786 - val_accuracy: 0.6068\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7873 - accuracy: 0.6778 - val_loss: 0.8647 - val_accuracy: 0.6154\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7743 - accuracy: 0.6741 - val_loss: 0.9009 - val_accuracy: 0.6068\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8076 - accuracy: 0.6778 - val_loss: 0.9868 - val_accuracy: 0.6239\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8333 - accuracy: 0.6852 - val_loss: 0.9960 - val_accuracy: 0.5812\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7900 - accuracy: 0.7000 - val_loss: 0.8694 - val_accuracy: 0.6239\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7840 - accuracy: 0.6704 - val_loss: 0.8735 - val_accuracy: 0.6325\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8278 - accuracy: 0.6778 - val_loss: 0.9170 - val_accuracy: 0.5897\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8736 - accuracy: 0.6852 - val_loss: 0.9979 - val_accuracy: 0.6325\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.9314 - accuracy: 0.6778 - val_loss: 0.8862 - val_accuracy: 0.5726\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7728 - accuracy: 0.6815 - val_loss: 0.8552 - val_accuracy: 0.6239\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7687 - accuracy: 0.6519 - val_loss: 0.8584 - val_accuracy: 0.6154\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7477 - accuracy: 0.6889 - val_loss: 0.8569 - val_accuracy: 0.6239\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7554 - accuracy: 0.6852 - val_loss: 0.8601 - val_accuracy: 0.6239\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7547 - accuracy: 0.7037 - val_loss: 0.8683 - val_accuracy: 0.6325\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7707 - accuracy: 0.6741 - val_loss: 0.8880 - val_accuracy: 0.5983\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7571 - accuracy: 0.6778 - val_loss: 0.8718 - val_accuracy: 0.6154\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7584 - accuracy: 0.6852 - val_loss: 0.8648 - val_accuracy: 0.6154\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7663 - accuracy: 0.6778 - val_loss: 0.8598 - val_accuracy: 0.6325\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7408 - accuracy: 0.6889 - val_loss: 0.8845 - val_accuracy: 0.6068\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7505 - accuracy: 0.6815 - val_loss: 0.8544 - val_accuracy: 0.6239\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7487 - accuracy: 0.6889 - val_loss: 0.8745 - val_accuracy: 0.5983\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7438 - accuracy: 0.6852 - val_loss: 0.8592 - val_accuracy: 0.6068\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7465 - accuracy: 0.6889 - val_loss: 0.8740 - val_accuracy: 0.6154\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7711 - accuracy: 0.6778 - val_loss: 0.9239 - val_accuracy: 0.5812\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8390 - accuracy: 0.6444 - val_loss: 0.8723 - val_accuracy: 0.6239\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7645 - accuracy: 0.6889 - val_loss: 0.8587 - val_accuracy: 0.6410\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7557 - accuracy: 0.6889 - val_loss: 0.8547 - val_accuracy: 0.6325\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7501 - accuracy: 0.6963 - val_loss: 0.8894 - val_accuracy: 0.6068\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7994 - accuracy: 0.6481 - val_loss: 0.8580 - val_accuracy: 0.6154\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7604 - accuracy: 0.6704 - val_loss: 0.8794 - val_accuracy: 0.6239\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7505 - accuracy: 0.6852 - val_loss: 0.8564 - val_accuracy: 0.6154\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7618 - accuracy: 0.6741 - val_loss: 0.8816 - val_accuracy: 0.6068\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7496 - accuracy: 0.6815 - val_loss: 0.8640 - val_accuracy: 0.5983\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7460 - accuracy: 0.6889 - val_loss: 0.8824 - val_accuracy: 0.6325\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7596 - accuracy: 0.6852 - val_loss: 0.8990 - val_accuracy: 0.6068\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7924 - accuracy: 0.6815 - val_loss: 0.8647 - val_accuracy: 0.5897\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8145 - accuracy: 0.6556 - val_loss: 0.8703 - val_accuracy: 0.6325\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7501 - accuracy: 0.6852 - val_loss: 0.8978 - val_accuracy: 0.6239\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7453 - accuracy: 0.6926 - val_loss: 0.8618 - val_accuracy: 0.6239\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7583 - accuracy: 0.6630 - val_loss: 0.8649 - val_accuracy: 0.6154\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7967 - accuracy: 0.6741 - val_loss: 0.8834 - val_accuracy: 0.6068\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7823 - accuracy: 0.6889 - val_loss: 0.8705 - val_accuracy: 0.6068\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8447 - accuracy: 0.6778 - val_loss: 1.1208 - val_accuracy: 0.6068\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0639 - accuracy: 0.6778 - val_loss: 0.9163 - val_accuracy: 0.5812\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7750 - accuracy: 0.6667 - val_loss: 0.9082 - val_accuracy: 0.6068\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7818 - accuracy: 0.6704 - val_loss: 0.9256 - val_accuracy: 0.5897\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7605 - accuracy: 0.6815 - val_loss: 0.9335 - val_accuracy: 0.5983\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8175 - accuracy: 0.6630 - val_loss: 1.0539 - val_accuracy: 0.5812\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8395 - accuracy: 0.6556 - val_loss: 1.0710 - val_accuracy: 0.5726\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8121 - accuracy: 0.6704 - val_loss: 0.9245 - val_accuracy: 0.5641\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8664 - accuracy: 0.6630 - val_loss: 0.8976 - val_accuracy: 0.6325\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9516 - accuracy: 0.6630 - val_loss: 0.9318 - val_accuracy: 0.6239\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8419 - accuracy: 0.6667 - val_loss: 0.9029 - val_accuracy: 0.5983\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7659 - accuracy: 0.6852 - val_loss: 0.8582 - val_accuracy: 0.6239\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7474 - accuracy: 0.6778 - val_loss: 0.8544 - val_accuracy: 0.6325\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7442 - accuracy: 0.6815 - val_loss: 0.8588 - val_accuracy: 0.6154\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7422 - accuracy: 0.6889 - val_loss: 0.9014 - val_accuracy: 0.6068\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8734 - accuracy: 0.6852 - val_loss: 0.9603 - val_accuracy: 0.6239\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8717 - accuracy: 0.6778 - val_loss: 1.0357 - val_accuracy: 0.5812\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8963 - accuracy: 0.6778 - val_loss: 0.9543 - val_accuracy: 0.6154\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8357 - accuracy: 0.6778 - val_loss: 0.9217 - val_accuracy: 0.6239\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9254 - accuracy: 0.6852 - val_loss: 0.8683 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7539 - accuracy: 0.6926 - val_loss: 0.8912 - val_accuracy: 0.5983\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7446 - accuracy: 0.6926 - val_loss: 0.8667 - val_accuracy: 0.6154\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7400 - accuracy: 0.7074 - val_loss: 0.9358 - val_accuracy: 0.5983\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7657 - accuracy: 0.6852 - val_loss: 0.8703 - val_accuracy: 0.6068\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7663 - accuracy: 0.6852 - val_loss: 0.8976 - val_accuracy: 0.6239\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7952 - accuracy: 0.6593 - val_loss: 1.0296 - val_accuracy: 0.5812\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8392 - accuracy: 0.6815 - val_loss: 1.1472 - val_accuracy: 0.5897\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0255 - accuracy: 0.6704 - val_loss: 0.9029 - val_accuracy: 0.5641\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7721 - accuracy: 0.6667 - val_loss: 0.8684 - val_accuracy: 0.6410\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7413 - accuracy: 0.6963 - val_loss: 0.8845 - val_accuracy: 0.5897\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7480 - accuracy: 0.6741 - val_loss: 0.8652 - val_accuracy: 0.6325\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7389 - accuracy: 0.6889 - val_loss: 0.9505 - val_accuracy: 0.5812\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8506 - accuracy: 0.6704 - val_loss: 0.9982 - val_accuracy: 0.6239\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8216 - accuracy: 0.6852 - val_loss: 0.9886 - val_accuracy: 0.5897\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9357 - accuracy: 0.6593 - val_loss: 0.9483 - val_accuracy: 0.6154\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9172 - accuracy: 0.6852 - val_loss: 0.8651 - val_accuracy: 0.6239\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7968 - accuracy: 0.6815 - val_loss: 0.9407 - val_accuracy: 0.6325\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8844 - accuracy: 0.6519 - val_loss: 0.8787 - val_accuracy: 0.5897\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8058 - accuracy: 0.6556 - val_loss: 0.9464 - val_accuracy: 0.5897\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7594 - accuracy: 0.6667 - val_loss: 0.8926 - val_accuracy: 0.5812\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7389 - accuracy: 0.6852 - val_loss: 0.8767 - val_accuracy: 0.6239\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7413 - accuracy: 0.6889 - val_loss: 0.8728 - val_accuracy: 0.6068\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7423 - accuracy: 0.6852 - val_loss: 0.9376 - val_accuracy: 0.6154\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8665 - accuracy: 0.6667 - val_loss: 0.9808 - val_accuracy: 0.6325\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8539 - accuracy: 0.6667 - val_loss: 0.9307 - val_accuracy: 0.5897\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8442 - accuracy: 0.6519 - val_loss: 0.8744 - val_accuracy: 0.6239\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7405 - accuracy: 0.6704 - val_loss: 0.9334 - val_accuracy: 0.5897\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7571 - accuracy: 0.6926 - val_loss: 0.8899 - val_accuracy: 0.6239\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7823 - accuracy: 0.6704 - val_loss: 0.8678 - val_accuracy: 0.6239\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7588 - accuracy: 0.6815 - val_loss: 0.9321 - val_accuracy: 0.5897\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7796 - accuracy: 0.6815 - val_loss: 0.8670 - val_accuracy: 0.6239\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8107 - accuracy: 0.6926 - val_loss: 0.9625 - val_accuracy: 0.6239\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8934 - accuracy: 0.6852 - val_loss: 0.9279 - val_accuracy: 0.5726\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9314 - accuracy: 0.6481 - val_loss: 1.1373 - val_accuracy: 0.5641\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0113 - accuracy: 0.6630 - val_loss: 0.9671 - val_accuracy: 0.5641\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8396 - accuracy: 0.6630 - val_loss: 0.8986 - val_accuracy: 0.6068\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7299 - accuracy: 0.6815 - val_loss: 0.9043 - val_accuracy: 0.5897\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7422 - accuracy: 0.6889 - val_loss: 0.8707 - val_accuracy: 0.6239\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7330 - accuracy: 0.6963 - val_loss: 0.8577 - val_accuracy: 0.6410\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7435 - accuracy: 0.6704 - val_loss: 0.8618 - val_accuracy: 0.6410\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7450 - accuracy: 0.6926 - val_loss: 0.8592 - val_accuracy: 0.6068\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7414 - accuracy: 0.6889 - val_loss: 0.9094 - val_accuracy: 0.5983\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9108 - accuracy: 0.6741 - val_loss: 0.9942 - val_accuracy: 0.6239\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8828 - accuracy: 0.6778 - val_loss: 0.9171 - val_accuracy: 0.5812\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8751 - accuracy: 0.6519 - val_loss: 0.8737 - val_accuracy: 0.6410\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8398 - accuracy: 0.6704 - val_loss: 0.9130 - val_accuracy: 0.5983\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8664 - accuracy: 0.6704 - val_loss: 0.9925 - val_accuracy: 0.6154\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8987 - accuracy: 0.6667 - val_loss: 1.0355 - val_accuracy: 0.5897\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8551 - accuracy: 0.6815 - val_loss: 0.9807 - val_accuracy: 0.6154\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.0869 - accuracy: 0.6741 - val_loss: 0.9849 - val_accuracy: 0.6068\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8637 - accuracy: 0.6778 - val_loss: 0.8833 - val_accuracy: 0.6410\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7795 - accuracy: 0.6963 - val_loss: 0.8701 - val_accuracy: 0.6239\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7301 - accuracy: 0.6926 - val_loss: 0.8738 - val_accuracy: 0.6239\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7503 - accuracy: 0.6852 - val_loss: 0.8688 - val_accuracy: 0.6068\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7574 - accuracy: 0.6852 - val_loss: 0.8735 - val_accuracy: 0.6410\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7621 - accuracy: 0.6852 - val_loss: 0.9009 - val_accuracy: 0.6068\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7513 - accuracy: 0.6741 - val_loss: 0.8963 - val_accuracy: 0.6239\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7540 - accuracy: 0.6963 - val_loss: 0.8854 - val_accuracy: 0.5983\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7669 - accuracy: 0.6778 - val_loss: 0.8759 - val_accuracy: 0.6410\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7762 - accuracy: 0.6667 - val_loss: 0.9710 - val_accuracy: 0.6154\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9602 - accuracy: 0.6778 - val_loss: 0.8999 - val_accuracy: 0.5983\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8788 - accuracy: 0.6778 - val_loss: 0.8767 - val_accuracy: 0.6068\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0015 - accuracy: 0.7000 - val_loss: 1.0780 - val_accuracy: 0.5983\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8513 - accuracy: 0.6630 - val_loss: 1.5267 - val_accuracy: 0.5385\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1259 - accuracy: 0.6704 - val_loss: 1.0239 - val_accuracy: 0.6068\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8188 - accuracy: 0.6704 - val_loss: 1.0163 - val_accuracy: 0.5726\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7870 - accuracy: 0.6889 - val_loss: 0.8583 - val_accuracy: 0.6239\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7718 - accuracy: 0.6741 - val_loss: 0.8758 - val_accuracy: 0.6496\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7689 - accuracy: 0.6889 - val_loss: 0.8588 - val_accuracy: 0.6410\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7522 - accuracy: 0.6815 - val_loss: 0.8724 - val_accuracy: 0.6068\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7443 - accuracy: 0.6852 - val_loss: 0.8605 - val_accuracy: 0.6410\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7400 - accuracy: 0.6852 - val_loss: 0.8681 - val_accuracy: 0.6068\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7311 - accuracy: 0.6926 - val_loss: 0.8558 - val_accuracy: 0.6239\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7437 - accuracy: 0.6815 - val_loss: 0.8723 - val_accuracy: 0.5983\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 0.8621 - val_accuracy: 0.6325\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7288 - accuracy: 0.6852 - val_loss: 0.8584 - val_accuracy: 0.6325\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7430 - accuracy: 0.6778 - val_loss: 0.8604 - val_accuracy: 0.6239\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7474 - accuracy: 0.6963 - val_loss: 0.8687 - val_accuracy: 0.6239\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7402 - accuracy: 0.6778 - val_loss: 0.8698 - val_accuracy: 0.6239\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7620 - accuracy: 0.6778 - val_loss: 0.9272 - val_accuracy: 0.5983\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7573 - accuracy: 0.6889 - val_loss: 0.8767 - val_accuracy: 0.6325\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7790 - accuracy: 0.6815 - val_loss: 0.9722 - val_accuracy: 0.5812\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7722 - accuracy: 0.6889 - val_loss: 0.8617 - val_accuracy: 0.6325\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7268 - accuracy: 0.6963 - val_loss: 0.8595 - val_accuracy: 0.6325\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7420 - accuracy: 0.6815 - val_loss: 0.9315 - val_accuracy: 0.5897\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7539 - accuracy: 0.6963 - val_loss: 0.9126 - val_accuracy: 0.6239\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8030 - accuracy: 0.6667 - val_loss: 0.8678 - val_accuracy: 0.6239\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8595 - accuracy: 0.6815 - val_loss: 0.8613 - val_accuracy: 0.6325\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7566 - accuracy: 0.6926 - val_loss: 0.8697 - val_accuracy: 0.6325\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7469 - accuracy: 0.6815 - val_loss: 0.8721 - val_accuracy: 0.6325\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7541 - accuracy: 0.6815 - val_loss: 0.9080 - val_accuracy: 0.5983\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7894 - accuracy: 0.6926 - val_loss: 0.9804 - val_accuracy: 0.6239\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8173 - accuracy: 0.6704 - val_loss: 0.9683 - val_accuracy: 0.5897\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7779 - accuracy: 0.6889 - val_loss: 0.8627 - val_accuracy: 0.6154\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7457 - accuracy: 0.6963 - val_loss: 0.8601 - val_accuracy: 0.6239\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7501 - accuracy: 0.6963 - val_loss: 0.9157 - val_accuracy: 0.6068\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7537 - accuracy: 0.6852 - val_loss: 0.8600 - val_accuracy: 0.6325\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7627 - accuracy: 0.6889 - val_loss: 0.8876 - val_accuracy: 0.6239\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8260 - accuracy: 0.6852 - val_loss: 0.8827 - val_accuracy: 0.6154\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7981 - accuracy: 0.6778 - val_loss: 0.9180 - val_accuracy: 0.6239\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7875 - accuracy: 0.6815 - val_loss: 1.2191 - val_accuracy: 0.5726\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8856 - accuracy: 0.6481 - val_loss: 0.9563 - val_accuracy: 0.5812\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8128 - accuracy: 0.6704 - val_loss: 0.8883 - val_accuracy: 0.6068\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7379 - accuracy: 0.6889 - val_loss: 0.8546 - val_accuracy: 0.6325\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7318 - accuracy: 0.7000 - val_loss: 0.8699 - val_accuracy: 0.5983\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7428 - accuracy: 0.6741 - val_loss: 0.8579 - val_accuracy: 0.6325\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7584 - accuracy: 0.6778 - val_loss: 0.8592 - val_accuracy: 0.6325\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7608 - accuracy: 0.6778 - val_loss: 0.8639 - val_accuracy: 0.6325\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8090 - accuracy: 0.6889 - val_loss: 0.9518 - val_accuracy: 0.6239\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9510 - accuracy: 0.6815 - val_loss: 0.8791 - val_accuracy: 0.6239\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7563 - accuracy: 0.6889 - val_loss: 0.9382 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7745 - accuracy: 0.6852 - val_loss: 0.8829 - val_accuracy: 0.5983\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7782 - accuracy: 0.6889 - val_loss: 0.8888 - val_accuracy: 0.6068\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7897 - accuracy: 0.6778 - val_loss: 0.8573 - val_accuracy: 0.6239\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7259 - accuracy: 0.6963 - val_loss: 0.8653 - val_accuracy: 0.6154\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7214 - accuracy: 0.6963 - val_loss: 0.8780 - val_accuracy: 0.6239\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7281 - accuracy: 0.6778 - val_loss: 0.8700 - val_accuracy: 0.6068\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7289 - accuracy: 0.6852 - val_loss: 0.8571 - val_accuracy: 0.6410\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7287 - accuracy: 0.7000 - val_loss: 0.8987 - val_accuracy: 0.5897\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7448 - accuracy: 0.6926 - val_loss: 0.8643 - val_accuracy: 0.6068\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7284 - accuracy: 0.6963 - val_loss: 0.9008 - val_accuracy: 0.6068\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.7346 - accuracy: 0.6926 - val_loss: 0.8562 - val_accuracy: 0.6325\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7294 - accuracy: 0.6926 - val_loss: 0.8882 - val_accuracy: 0.6068\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7176 - accuracy: 0.6963 - val_loss: 0.8611 - val_accuracy: 0.6239\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7459 - accuracy: 0.6889 - val_loss: 0.8907 - val_accuracy: 0.6239\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7861 - accuracy: 0.6630 - val_loss: 0.8553 - val_accuracy: 0.6325\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7516 - accuracy: 0.6852 - val_loss: 0.8629 - val_accuracy: 0.6239\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7396 - accuracy: 0.6926 - val_loss: 0.8649 - val_accuracy: 0.6239\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7341 - accuracy: 0.6926 - val_loss: 0.8720 - val_accuracy: 0.6068\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7337 - accuracy: 0.6963 - val_loss: 0.8628 - val_accuracy: 0.6325\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7739 - accuracy: 0.6593 - val_loss: 1.2474 - val_accuracy: 0.5726\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9864 - accuracy: 0.6296 - val_loss: 0.9565 - val_accuracy: 0.5897\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7827 - accuracy: 0.6556 - val_loss: 0.8825 - val_accuracy: 0.6068\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7588 - accuracy: 0.6815 - val_loss: 0.9064 - val_accuracy: 0.6239\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7265 - accuracy: 0.6852 - val_loss: 0.8628 - val_accuracy: 0.6496\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7320 - accuracy: 0.6889 - val_loss: 0.9668 - val_accuracy: 0.5983\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7612 - accuracy: 0.6926 - val_loss: 0.8774 - val_accuracy: 0.5983\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7270 - accuracy: 0.7000 - val_loss: 0.9596 - val_accuracy: 0.5897\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7585 - accuracy: 0.6852 - val_loss: 0.8799 - val_accuracy: 0.5983\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7279 - accuracy: 0.6926 - val_loss: 0.8688 - val_accuracy: 0.6068\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7306 - accuracy: 0.6926 - val_loss: 0.8569 - val_accuracy: 0.6239\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7394 - accuracy: 0.6889 - val_loss: 0.8646 - val_accuracy: 0.6068\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7158 - accuracy: 0.7000 - val_loss: 0.8583 - val_accuracy: 0.6325\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7529 - accuracy: 0.6926 - val_loss: 0.8651 - val_accuracy: 0.6239\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7723 - accuracy: 0.6778 - val_loss: 0.8717 - val_accuracy: 0.5983\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7289 - accuracy: 0.6926 - val_loss: 0.8651 - val_accuracy: 0.6325\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7244 - accuracy: 0.6926 - val_loss: 0.8584 - val_accuracy: 0.6154\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7199 - accuracy: 0.6926 - val_loss: 0.8898 - val_accuracy: 0.6239\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7587 - accuracy: 0.6852 - val_loss: 0.8710 - val_accuracy: 0.6068\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7725 - accuracy: 0.6815 - val_loss: 1.1978 - val_accuracy: 0.5726\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0133 - accuracy: 0.6778 - val_loss: 0.8916 - val_accuracy: 0.6068\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8506 - accuracy: 0.6481 - val_loss: 0.8909 - val_accuracy: 0.6325\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0715 - accuracy: 0.6889 - val_loss: 1.0237 - val_accuracy: 0.6068\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8962 - accuracy: 0.6630 - val_loss: 1.1814 - val_accuracy: 0.5812\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9755 - accuracy: 0.6556 - val_loss: 0.9483 - val_accuracy: 0.5556\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8299 - accuracy: 0.6593 - val_loss: 1.1598 - val_accuracy: 0.5641\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0709 - accuracy: 0.6704 - val_loss: 0.9362 - val_accuracy: 0.5556\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8245 - accuracy: 0.6593 - val_loss: 0.8815 - val_accuracy: 0.6154\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7767 - accuracy: 0.7000 - val_loss: 0.8852 - val_accuracy: 0.5983\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7530 - accuracy: 0.6741 - val_loss: 0.8571 - val_accuracy: 0.6410\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7219 - accuracy: 0.7074 - val_loss: 0.8873 - val_accuracy: 0.6068\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7358 - accuracy: 0.7037 - val_loss: 0.8593 - val_accuracy: 0.6410\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7365 - accuracy: 0.7037 - val_loss: 0.8876 - val_accuracy: 0.6154\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7511 - accuracy: 0.6889 - val_loss: 0.8665 - val_accuracy: 0.6410\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7783 - accuracy: 0.6926 - val_loss: 0.8818 - val_accuracy: 0.6325\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7268 - accuracy: 0.6926 - val_loss: 0.8546 - val_accuracy: 0.6325\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7279 - accuracy: 0.6963 - val_loss: 0.8726 - val_accuracy: 0.6410\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7441 - accuracy: 0.6815 - val_loss: 0.8679 - val_accuracy: 0.6154\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7287 - accuracy: 0.6815 - val_loss: 0.8592 - val_accuracy: 0.6325\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7546 - accuracy: 0.6778 - val_loss: 1.0396 - val_accuracy: 0.5983\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8913 - accuracy: 0.6667 - val_loss: 1.0511 - val_accuracy: 0.6154\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8457 - accuracy: 0.6889 - val_loss: 1.1545 - val_accuracy: 0.5897\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9949 - accuracy: 0.6667 - val_loss: 1.2129 - val_accuracy: 0.6239\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.2618 - accuracy: 0.6778 - val_loss: 1.0980 - val_accuracy: 0.5726\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7980 - accuracy: 0.6704 - val_loss: 1.0399 - val_accuracy: 0.5641\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7724 - accuracy: 0.7074 - val_loss: 0.8765 - val_accuracy: 0.6325\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7339 - accuracy: 0.6963 - val_loss: 0.8712 - val_accuracy: 0.6325\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7415 - accuracy: 0.6778 - val_loss: 0.8840 - val_accuracy: 0.6239\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7184 - accuracy: 0.7074 - val_loss: 0.8652 - val_accuracy: 0.6325\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7326 - accuracy: 0.7000 - val_loss: 0.8645 - val_accuracy: 0.6239\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7273 - accuracy: 0.6889 - val_loss: 0.8929 - val_accuracy: 0.6068\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7268 - accuracy: 0.6963 - val_loss: 0.8594 - val_accuracy: 0.6410\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7147 - accuracy: 0.7000 - val_loss: 0.8612 - val_accuracy: 0.6239\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7344 - accuracy: 0.6926 - val_loss: 0.8871 - val_accuracy: 0.5983\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7324 - accuracy: 0.6778 - val_loss: 0.8596 - val_accuracy: 0.6325\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7175 - accuracy: 0.7000 - val_loss: 0.8708 - val_accuracy: 0.6068\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7194 - accuracy: 0.6963 - val_loss: 0.8719 - val_accuracy: 0.6154\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7175 - accuracy: 0.6963 - val_loss: 0.8549 - val_accuracy: 0.6239\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7329 - accuracy: 0.6815 - val_loss: 0.8593 - val_accuracy: 0.6325\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8246 - accuracy: 0.6815 - val_loss: 0.9773 - val_accuracy: 0.5897\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7909 - accuracy: 0.6889 - val_loss: 0.8810 - val_accuracy: 0.6496\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7785 - accuracy: 0.6778 - val_loss: 0.9152 - val_accuracy: 0.5983\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7695 - accuracy: 0.6704 - val_loss: 0.8597 - val_accuracy: 0.6325\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7524 - accuracy: 0.6519 - val_loss: 0.8816 - val_accuracy: 0.6154\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7555 - accuracy: 0.6889 - val_loss: 0.8955 - val_accuracy: 0.6325\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7330 - accuracy: 0.6963 - val_loss: 0.8621 - val_accuracy: 0.6325\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7288 - accuracy: 0.6852 - val_loss: 0.8698 - val_accuracy: 0.6325\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7201 - accuracy: 0.6963 - val_loss: 0.8630 - val_accuracy: 0.6325\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7176 - accuracy: 0.6926 - val_loss: 0.8621 - val_accuracy: 0.6239\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7405 - accuracy: 0.6667 - val_loss: 0.8887 - val_accuracy: 0.5983\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7237 - accuracy: 0.6926 - val_loss: 0.8767 - val_accuracy: 0.5983\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7293 - accuracy: 0.6889 - val_loss: 0.8617 - val_accuracy: 0.6325\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7220 - accuracy: 0.6815 - val_loss: 0.8649 - val_accuracy: 0.6239\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7293 - accuracy: 0.6815 - val_loss: 0.8641 - val_accuracy: 0.6325\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7861 - accuracy: 0.6852 - val_loss: 1.0487 - val_accuracy: 0.5897\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9821 - accuracy: 0.7000 - val_loss: 1.3039 - val_accuracy: 0.5812\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.1759 - accuracy: 0.6593 - val_loss: 0.9315 - val_accuracy: 0.5812\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0497 - accuracy: 0.6667 - val_loss: 0.8644 - val_accuracy: 0.6410\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.1489 - accuracy: 0.6704 - val_loss: 1.2450 - val_accuracy: 0.5983\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9896 - accuracy: 0.6889 - val_loss: 0.9382 - val_accuracy: 0.5812\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7672 - accuracy: 0.7037 - val_loss: 0.8576 - val_accuracy: 0.6410\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7278 - accuracy: 0.6963 - val_loss: 0.8711 - val_accuracy: 0.6068\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7225 - accuracy: 0.6889 - val_loss: 0.8775 - val_accuracy: 0.6154\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7388 - accuracy: 0.6889 - val_loss: 0.8662 - val_accuracy: 0.6410\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7263 - accuracy: 0.6963 - val_loss: 0.9045 - val_accuracy: 0.6068\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7306 - accuracy: 0.6889 - val_loss: 0.8611 - val_accuracy: 0.6325\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7307 - accuracy: 0.6741 - val_loss: 0.8620 - val_accuracy: 0.6325\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7401 - accuracy: 0.6926 - val_loss: 0.9103 - val_accuracy: 0.6239\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7899 - accuracy: 0.6926 - val_loss: 1.0182 - val_accuracy: 0.6154\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8812 - accuracy: 0.6815 - val_loss: 1.1086 - val_accuracy: 0.5983\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9068 - accuracy: 0.6704 - val_loss: 0.9496 - val_accuracy: 0.6154\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8287 - accuracy: 0.6741 - val_loss: 0.9625 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7217 - accuracy: 0.6963 - val_loss: 0.8720 - val_accuracy: 0.6325\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7464 - accuracy: 0.6815 - val_loss: 1.0445 - val_accuracy: 0.5983\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8922 - accuracy: 0.6704 - val_loss: 1.0560 - val_accuracy: 0.6154\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8812 - accuracy: 0.6889 - val_loss: 1.2352 - val_accuracy: 0.5641\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0173 - accuracy: 0.6667 - val_loss: 1.1526 - val_accuracy: 0.6154\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9203 - accuracy: 0.6741 - val_loss: 0.9839 - val_accuracy: 0.5983\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7777 - accuracy: 0.6852 - val_loss: 0.8631 - val_accuracy: 0.6410\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7140 - accuracy: 0.7037 - val_loss: 0.9174 - val_accuracy: 0.6068\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7547 - accuracy: 0.6889 - val_loss: 0.8891 - val_accuracy: 0.6239\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7408 - accuracy: 0.7074 - val_loss: 0.8823 - val_accuracy: 0.6325\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7239 - accuracy: 0.7000 - val_loss: 0.8758 - val_accuracy: 0.6068\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7313 - accuracy: 0.6963 - val_loss: 0.8662 - val_accuracy: 0.6239\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7183 - accuracy: 0.7000 - val_loss: 0.8613 - val_accuracy: 0.6410\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7240 - accuracy: 0.7000 - val_loss: 0.9065 - val_accuracy: 0.6239\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7385 - accuracy: 0.6741 - val_loss: 0.8847 - val_accuracy: 0.6325\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7523 - accuracy: 0.6741 - val_loss: 0.8778 - val_accuracy: 0.6325\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7743 - accuracy: 0.6593 - val_loss: 0.8808 - val_accuracy: 0.6496\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.7590 - accuracy: 0.6852 - val_loss: 0.8911 - val_accuracy: 0.6239\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7402 - accuracy: 0.6926 - val_loss: 0.8672 - val_accuracy: 0.6239\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7210 - accuracy: 0.6852 - val_loss: 0.8652 - val_accuracy: 0.6325\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7156 - accuracy: 0.7074 - val_loss: 0.8934 - val_accuracy: 0.5983\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7217 - accuracy: 0.7037 - val_loss: 0.8633 - val_accuracy: 0.6154\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7461 - accuracy: 0.7074 - val_loss: 0.9202 - val_accuracy: 0.6068\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8077 - accuracy: 0.6815 - val_loss: 1.0302 - val_accuracy: 0.6154\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9004 - accuracy: 0.6852 - val_loss: 0.9066 - val_accuracy: 0.6154\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7349 - accuracy: 0.7000 - val_loss: 0.8659 - val_accuracy: 0.6410\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7149 - accuracy: 0.7000 - val_loss: 0.9076 - val_accuracy: 0.6068\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7437 - accuracy: 0.6741 - val_loss: 0.8666 - val_accuracy: 0.6325\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7295 - accuracy: 0.6926 - val_loss: 0.8716 - val_accuracy: 0.6325\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.7278 - accuracy: 0.6963 - val_loss: 0.8998 - val_accuracy: 0.6068\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7302 - accuracy: 0.6852 - val_loss: 0.8717 - val_accuracy: 0.6410\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7962 - accuracy: 0.6889 - val_loss: 0.9982 - val_accuracy: 0.6239\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0704 - accuracy: 0.6593 - val_loss: 0.9386 - val_accuracy: 0.6068\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8098 - accuracy: 0.6704 - val_loss: 1.0118 - val_accuracy: 0.6325\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 1.0265 - accuracy: 0.6704 - val_loss: 0.8835 - val_accuracy: 0.6068\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7593 - accuracy: 0.7037 - val_loss: 0.8867 - val_accuracy: 0.6410\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8766 - accuracy: 0.6852 - val_loss: 0.8606 - val_accuracy: 0.6581\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7361 - accuracy: 0.7074 - val_loss: 0.8584 - val_accuracy: 0.6410\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7202 - accuracy: 0.7000 - val_loss: 0.8731 - val_accuracy: 0.6410\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7237 - accuracy: 0.6926 - val_loss: 0.8604 - val_accuracy: 0.6410\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7204 - accuracy: 0.7000 - val_loss: 0.8840 - val_accuracy: 0.6325\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7270 - accuracy: 0.6926 - val_loss: 0.8856 - val_accuracy: 0.6068\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7380 - accuracy: 0.6704 - val_loss: 0.8807 - val_accuracy: 0.6325\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7387 - accuracy: 0.6741 - val_loss: 0.8754 - val_accuracy: 0.6068\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7317 - accuracy: 0.7037 - val_loss: 0.9701 - val_accuracy: 0.5983\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8315 - accuracy: 0.6963 - val_loss: 0.9772 - val_accuracy: 0.6239\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7917 - accuracy: 0.6963 - val_loss: 0.8615 - val_accuracy: 0.6496\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7525 - accuracy: 0.6926 - val_loss: 0.8607 - val_accuracy: 0.6239\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7601 - accuracy: 0.6852 - val_loss: 0.8935 - val_accuracy: 0.6068\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7450 - accuracy: 0.6852 - val_loss: 0.8602 - val_accuracy: 0.6154\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7097 - accuracy: 0.6963 - val_loss: 0.8707 - val_accuracy: 0.6068\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7210 - accuracy: 0.6926 - val_loss: 0.8629 - val_accuracy: 0.6325\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7276 - accuracy: 0.6963 - val_loss: 0.9070 - val_accuracy: 0.6154\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7117 - accuracy: 0.7074 - val_loss: 0.8568 - val_accuracy: 0.6239\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7740 - accuracy: 0.6741 - val_loss: 1.0633 - val_accuracy: 0.5983\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7620 - accuracy: 0.7074 - val_loss: 0.8604 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7471 - accuracy: 0.7074 - val_loss: 0.9238 - val_accuracy: 0.6239\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9166 - accuracy: 0.6741 - val_loss: 0.8756 - val_accuracy: 0.6325\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9307 - accuracy: 0.6704 - val_loss: 1.0452 - val_accuracy: 0.6239\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8560 - accuracy: 0.6630 - val_loss: 0.9725 - val_accuracy: 0.5897\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7806 - accuracy: 0.6852 - val_loss: 0.9751 - val_accuracy: 0.6239\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8372 - accuracy: 0.6741 - val_loss: 1.0158 - val_accuracy: 0.5897\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9120 - accuracy: 0.6704 - val_loss: 1.0011 - val_accuracy: 0.6239\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7683 - accuracy: 0.6778 - val_loss: 1.0256 - val_accuracy: 0.5812\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7752 - accuracy: 0.7037 - val_loss: 0.9474 - val_accuracy: 0.6068\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8068 - accuracy: 0.6926 - val_loss: 0.9556 - val_accuracy: 0.5983\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7660 - accuracy: 0.6778 - val_loss: 0.8910 - val_accuracy: 0.6325\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7449 - accuracy: 0.6889 - val_loss: 1.0716 - val_accuracy: 0.5983\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7620 - accuracy: 0.6852 - val_loss: 0.9014 - val_accuracy: 0.6239\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7458 - accuracy: 0.7000 - val_loss: 0.9790 - val_accuracy: 0.5983\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7608 - accuracy: 0.6889 - val_loss: 0.8680 - val_accuracy: 0.6154\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7238 - accuracy: 0.6926 - val_loss: 0.8687 - val_accuracy: 0.6154\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7297 - accuracy: 0.6926 - val_loss: 0.8745 - val_accuracy: 0.6325\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7185 - accuracy: 0.7000 - val_loss: 0.8617 - val_accuracy: 0.6325\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7182 - accuracy: 0.6926 - val_loss: 0.8638 - val_accuracy: 0.6325\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7427 - accuracy: 0.6889 - val_loss: 0.8719 - val_accuracy: 0.6410\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7394 - accuracy: 0.6963 - val_loss: 0.8704 - val_accuracy: 0.6239\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7101 - accuracy: 0.6889 - val_loss: 0.8582 - val_accuracy: 0.6325\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7218 - accuracy: 0.6852 - val_loss: 0.8595 - val_accuracy: 0.6325\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7260 - accuracy: 0.6815 - val_loss: 0.9264 - val_accuracy: 0.5983\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7620 - accuracy: 0.6889 - val_loss: 0.8691 - val_accuracy: 0.6325\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7294 - accuracy: 0.6963 - val_loss: 0.9244 - val_accuracy: 0.6068\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7403 - accuracy: 0.6815 - val_loss: 0.8617 - val_accuracy: 0.6239\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7264 - accuracy: 0.7111 - val_loss: 0.8612 - val_accuracy: 0.6325\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7231 - accuracy: 0.7000 - val_loss: 0.8699 - val_accuracy: 0.6068\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7155 - accuracy: 0.6889 - val_loss: 0.8658 - val_accuracy: 0.6239\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7211 - accuracy: 0.6926 - val_loss: 0.8599 - val_accuracy: 0.6325\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7378 - accuracy: 0.6778 - val_loss: 0.8902 - val_accuracy: 0.5983\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7275 - accuracy: 0.6815 - val_loss: 0.8626 - val_accuracy: 0.6325\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7135 - accuracy: 0.6963 - val_loss: 0.8806 - val_accuracy: 0.6068\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7274 - accuracy: 0.6778 - val_loss: 0.8765 - val_accuracy: 0.6239\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7119 - accuracy: 0.6889 - val_loss: 0.8609 - val_accuracy: 0.6325\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7142 - accuracy: 0.7000 - val_loss: 0.8597 - val_accuracy: 0.6325\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7452 - accuracy: 0.6778 - val_loss: 0.8891 - val_accuracy: 0.5897\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7325 - accuracy: 0.6778 - val_loss: 0.8622 - val_accuracy: 0.6325\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7087 - accuracy: 0.7000 - val_loss: 0.8624 - val_accuracy: 0.6325\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7125 - accuracy: 0.6926 - val_loss: 0.8763 - val_accuracy: 0.6154\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7208 - accuracy: 0.7074 - val_loss: 0.8857 - val_accuracy: 0.6239\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7382 - accuracy: 0.6889 - val_loss: 0.9139 - val_accuracy: 0.5983\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7355 - accuracy: 0.7000 - val_loss: 0.8615 - val_accuracy: 0.6410\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7101 - accuracy: 0.7111 - val_loss: 0.9647 - val_accuracy: 0.5812\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7841 - accuracy: 0.6704 - val_loss: 0.9353 - val_accuracy: 0.6154\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7566 - accuracy: 0.6778 - val_loss: 0.9005 - val_accuracy: 0.6068\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7221 - accuracy: 0.6889 - val_loss: 0.8704 - val_accuracy: 0.6239\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7284 - accuracy: 0.6778 - val_loss: 0.8749 - val_accuracy: 0.6410\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7244 - accuracy: 0.6852 - val_loss: 0.8616 - val_accuracy: 0.6325\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7153 - accuracy: 0.6926 - val_loss: 0.8632 - val_accuracy: 0.6325\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7127 - accuracy: 0.6889 - val_loss: 0.8873 - val_accuracy: 0.5983\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7607 - accuracy: 0.6593 - val_loss: 0.8631 - val_accuracy: 0.6325\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7604 - accuracy: 0.6778 - val_loss: 0.8702 - val_accuracy: 0.6239\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7537 - accuracy: 0.6778 - val_loss: 0.8615 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7131 - accuracy: 0.6926 - val_loss: 0.8604 - val_accuracy: 0.6325\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7129 - accuracy: 0.6852 - val_loss: 0.9056 - val_accuracy: 0.5983\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7123 - accuracy: 0.7037 - val_loss: 0.8826 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7473 - accuracy: 0.6741 - val_loss: 0.8595 - val_accuracy: 0.6325\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7222 - accuracy: 0.6963 - val_loss: 0.8672 - val_accuracy: 0.6325\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7309 - accuracy: 0.7000 - val_loss: 0.8737 - val_accuracy: 0.6410\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7129 - accuracy: 0.6963 - val_loss: 0.8732 - val_accuracy: 0.6068\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7030 - accuracy: 0.6963 - val_loss: 0.8914 - val_accuracy: 0.6239\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7357 - accuracy: 0.6815 - val_loss: 0.8658 - val_accuracy: 0.6239\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7078 - accuracy: 0.7148 - val_loss: 0.9104 - val_accuracy: 0.5897\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7219 - accuracy: 0.6926 - val_loss: 0.8694 - val_accuracy: 0.6068\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7228 - accuracy: 0.6926 - val_loss: 0.8713 - val_accuracy: 0.6239\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7275 - accuracy: 0.6889 - val_loss: 0.8734 - val_accuracy: 0.6068\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7165 - accuracy: 0.6963 - val_loss: 0.8799 - val_accuracy: 0.6154\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7060 - accuracy: 0.7037 - val_loss: 0.8625 - val_accuracy: 0.6325\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7112 - accuracy: 0.6963 - val_loss: 0.8894 - val_accuracy: 0.6154\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7246 - accuracy: 0.6815 - val_loss: 0.8790 - val_accuracy: 0.6068\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7124 - accuracy: 0.6889 - val_loss: 0.8942 - val_accuracy: 0.6239\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7408 - accuracy: 0.6889 - val_loss: 0.8898 - val_accuracy: 0.6154\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7181 - accuracy: 0.6963 - val_loss: 0.8801 - val_accuracy: 0.6325\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7338 - accuracy: 0.6778 - val_loss: 0.9390 - val_accuracy: 0.5897\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7349 - accuracy: 0.6889 - val_loss: 0.8705 - val_accuracy: 0.6239\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8322 - accuracy: 0.6667 - val_loss: 0.9438 - val_accuracy: 0.6239\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7578 - accuracy: 0.6852 - val_loss: 0.8886 - val_accuracy: 0.6154\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8427 - accuracy: 0.6778 - val_loss: 0.8761 - val_accuracy: 0.6239\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.2110 - accuracy: 0.6370 - val_loss: 1.0581 - val_accuracy: 0.6239\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0432 - accuracy: 0.6593 - val_loss: 0.8882 - val_accuracy: 0.6068\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8387 - accuracy: 0.6481 - val_loss: 0.9230 - val_accuracy: 0.6068\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8483 - accuracy: 0.6889 - val_loss: 0.8950 - val_accuracy: 0.6068\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9476 - accuracy: 0.6815 - val_loss: 0.9755 - val_accuracy: 0.6154\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8185 - accuracy: 0.6815 - val_loss: 0.8845 - val_accuracy: 0.6068\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7988 - accuracy: 0.6926 - val_loss: 0.8768 - val_accuracy: 0.6154\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7508 - accuracy: 0.6963 - val_loss: 0.8676 - val_accuracy: 0.6496\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7571 - accuracy: 0.6852 - val_loss: 0.8873 - val_accuracy: 0.6496\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7226 - accuracy: 0.7074 - val_loss: 0.8739 - val_accuracy: 0.6154\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7277 - accuracy: 0.6852 - val_loss: 0.8659 - val_accuracy: 0.6325\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7439 - accuracy: 0.6704 - val_loss: 0.8677 - val_accuracy: 0.6410\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7173 - accuracy: 0.6926 - val_loss: 0.9206 - val_accuracy: 0.6068\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7199 - accuracy: 0.7111 - val_loss: 0.8903 - val_accuracy: 0.6154\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7444 - accuracy: 0.6852 - val_loss: 0.9279 - val_accuracy: 0.6068\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7256 - accuracy: 0.7074 - val_loss: 0.8614 - val_accuracy: 0.6410\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7792 - accuracy: 0.6630 - val_loss: 0.8895 - val_accuracy: 0.6325\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7966 - accuracy: 0.6741 - val_loss: 0.9560 - val_accuracy: 0.6068\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7154 - accuracy: 0.7000 - val_loss: 0.8612 - val_accuracy: 0.6239\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7076 - accuracy: 0.6963 - val_loss: 0.8660 - val_accuracy: 0.6239\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7090 - accuracy: 0.6963 - val_loss: 0.8926 - val_accuracy: 0.6239\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.7232 - accuracy: 0.6852 - val_loss: 0.8700 - val_accuracy: 0.6068\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7379 - accuracy: 0.6778 - val_loss: 0.8814 - val_accuracy: 0.6239\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7280 - accuracy: 0.6926 - val_loss: 0.8970 - val_accuracy: 0.5897\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7250 - accuracy: 0.6852 - val_loss: 0.9373 - val_accuracy: 0.5983\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7438 - accuracy: 0.6926 - val_loss: 0.9694 - val_accuracy: 0.5897\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7808 - accuracy: 0.6741 - val_loss: 0.9508 - val_accuracy: 0.6068\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7768 - accuracy: 0.6481 - val_loss: 0.8985 - val_accuracy: 0.6068\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7439 - accuracy: 0.6963 - val_loss: 0.8693 - val_accuracy: 0.6410\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7294 - accuracy: 0.6815 - val_loss: 0.8804 - val_accuracy: 0.6325\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7489 - accuracy: 0.6815 - val_loss: 0.8641 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7441 - accuracy: 0.6593 - val_loss: 0.8661 - val_accuracy: 0.6325\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7416 - accuracy: 0.6815 - val_loss: 0.9036 - val_accuracy: 0.6239\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9376 - accuracy: 0.6741 - val_loss: 1.0143 - val_accuracy: 0.6239\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7782 - accuracy: 0.7074 - val_loss: 0.9837 - val_accuracy: 0.6068\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7154 - accuracy: 0.7148 - val_loss: 0.8941 - val_accuracy: 0.6239\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7261 - accuracy: 0.6963 - val_loss: 0.9688 - val_accuracy: 0.5812\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7702 - accuracy: 0.6815 - val_loss: 1.1938 - val_accuracy: 0.5812\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0533 - accuracy: 0.6778 - val_loss: 0.9187 - val_accuracy: 0.5726\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7603 - accuracy: 0.6889 - val_loss: 0.8786 - val_accuracy: 0.6239\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7460 - accuracy: 0.6963 - val_loss: 0.8805 - val_accuracy: 0.5897\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7110 - accuracy: 0.6778 - val_loss: 0.8599 - val_accuracy: 0.6154\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7112 - accuracy: 0.7000 - val_loss: 0.8973 - val_accuracy: 0.6239\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7347 - accuracy: 0.7037 - val_loss: 0.8777 - val_accuracy: 0.6068\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7148 - accuracy: 0.7037 - val_loss: 0.8687 - val_accuracy: 0.6410\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7044 - accuracy: 0.6852 - val_loss: 0.8753 - val_accuracy: 0.6068\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7273 - accuracy: 0.6815 - val_loss: 0.9380 - val_accuracy: 0.5897\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.7541 - accuracy: 0.6630 - val_loss: 0.9176 - val_accuracy: 0.5641\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7312 - accuracy: 0.6889 - val_loss: 0.8929 - val_accuracy: 0.6410\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7110 - accuracy: 0.6815 - val_loss: 0.8966 - val_accuracy: 0.5812\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7234 - accuracy: 0.7037 - val_loss: 0.9250 - val_accuracy: 0.6154\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7388 - accuracy: 0.6741 - val_loss: 0.9112 - val_accuracy: 0.5897\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7194 - accuracy: 0.7000 - val_loss: 0.8808 - val_accuracy: 0.6410\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7356 - accuracy: 0.7074 - val_loss: 0.8828 - val_accuracy: 0.6239\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7181 - accuracy: 0.6852 - val_loss: 0.8649 - val_accuracy: 0.6325\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7225 - accuracy: 0.6889 - val_loss: 0.8629 - val_accuracy: 0.6154\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7031 - accuracy: 0.6963 - val_loss: 0.8834 - val_accuracy: 0.6154\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7120 - accuracy: 0.7000 - val_loss: 0.8629 - val_accuracy: 0.6154\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7067 - accuracy: 0.7074 - val_loss: 0.8748 - val_accuracy: 0.6154\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7234 - accuracy: 0.6926 - val_loss: 0.8893 - val_accuracy: 0.6325\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7293 - accuracy: 0.6889 - val_loss: 0.8628 - val_accuracy: 0.6239\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7642 - accuracy: 0.6741 - val_loss: 0.9058 - val_accuracy: 0.6239\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7461 - accuracy: 0.6815 - val_loss: 0.8861 - val_accuracy: 0.5983\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7352 - accuracy: 0.6852 - val_loss: 0.8634 - val_accuracy: 0.6325\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7063 - accuracy: 0.6778 - val_loss: 0.8652 - val_accuracy: 0.6239\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7079 - accuracy: 0.6963 - val_loss: 0.8797 - val_accuracy: 0.5983\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7180 - accuracy: 0.6852 - val_loss: 0.8668 - val_accuracy: 0.6154\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7410 - accuracy: 0.6704 - val_loss: 0.8739 - val_accuracy: 0.6154\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7002 - accuracy: 0.6926 - val_loss: 0.8777 - val_accuracy: 0.6239\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7113 - accuracy: 0.7037 - val_loss: 0.8711 - val_accuracy: 0.6154\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7048 - accuracy: 0.6926 - val_loss: 0.8683 - val_accuracy: 0.6325\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7298 - accuracy: 0.6963 - val_loss: 0.9077 - val_accuracy: 0.5897\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7101 - accuracy: 0.6926 - val_loss: 0.8747 - val_accuracy: 0.6154\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7417 - accuracy: 0.6815 - val_loss: 0.9159 - val_accuracy: 0.5812\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7431 - accuracy: 0.6741 - val_loss: 0.9395 - val_accuracy: 0.5983\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7621 - accuracy: 0.6815 - val_loss: 0.9100 - val_accuracy: 0.6239\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7407 - accuracy: 0.6963 - val_loss: 0.8822 - val_accuracy: 0.5983\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7107 - accuracy: 0.6889 - val_loss: 0.9178 - val_accuracy: 0.6068\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7378 - accuracy: 0.6889 - val_loss: 0.8661 - val_accuracy: 0.6239\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7162 - accuracy: 0.7000 - val_loss: 0.8726 - val_accuracy: 0.6154\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.7307 - accuracy: 0.6852 - val_loss: 0.9186 - val_accuracy: 0.5897\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6915 - accuracy: 0.7148 - val_loss: 0.8948 - val_accuracy: 0.6239\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.7314 - accuracy: 0.7000 - val_loss: 0.9543 - val_accuracy: 0.5983\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7816 - accuracy: 0.6667 - val_loss: 0.9445 - val_accuracy: 0.6068\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8158 - accuracy: 0.6667 - val_loss: 0.9045 - val_accuracy: 0.6410\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8077 - accuracy: 0.6481 - val_loss: 0.8705 - val_accuracy: 0.6154\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.7932 - accuracy: 0.6704 - val_loss: 1.0974 - val_accuracy: 0.5983\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9296 - accuracy: 0.6815 - val_loss: 1.2274 - val_accuracy: 0.6239\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 1.2506 - accuracy: 0.6778 - val_loss: 1.0588 - val_accuracy: 0.5983\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9957 - accuracy: 0.6481 - val_loss: 0.9143 - val_accuracy: 0.5983\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8156 - accuracy: 0.6815 - val_loss: 0.8831 - val_accuracy: 0.5983\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8200 - accuracy: 0.6926 - val_loss: 0.9502 - val_accuracy: 0.6154\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9179 - accuracy: 0.6852 - val_loss: 0.8769 - val_accuracy: 0.6068\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7714 - accuracy: 0.7000 - val_loss: 0.9077 - val_accuracy: 0.6239\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7516 - accuracy: 0.6815 - val_loss: 1.0692 - val_accuracy: 0.5983\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8173 - accuracy: 0.6889 - val_loss: 0.9897 - val_accuracy: 0.6154\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7498 - accuracy: 0.6926 - val_loss: 0.9712 - val_accuracy: 0.6068\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7502 - accuracy: 0.7037 - val_loss: 0.8758 - val_accuracy: 0.6239\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7497 - accuracy: 0.6963 - val_loss: 0.9564 - val_accuracy: 0.6154\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8108 - accuracy: 0.6926 - val_loss: 0.9367 - val_accuracy: 0.6068\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7482 - accuracy: 0.6926 - val_loss: 0.8692 - val_accuracy: 0.6239\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7615 - accuracy: 0.6852 - val_loss: 0.8645 - val_accuracy: 0.6410\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7416 - accuracy: 0.7000 - val_loss: 0.9849 - val_accuracy: 0.5983\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7472 - accuracy: 0.6926 - val_loss: 0.8682 - val_accuracy: 0.6154\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7160 - accuracy: 0.6852 - val_loss: 0.8823 - val_accuracy: 0.6068\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7199 - accuracy: 0.7000 - val_loss: 0.8813 - val_accuracy: 0.6239\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7592 - accuracy: 0.6889 - val_loss: 0.8749 - val_accuracy: 0.6068\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.7135 - accuracy: 0.7000 - val_loss: 0.8616 - val_accuracy: 0.6325\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.7074 - accuracy: 0.6963 - val_loss: 0.8798 - val_accuracy: 0.5983\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7213 - accuracy: 0.6926 - val_loss: 0.8821 - val_accuracy: 0.5983\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7115 - accuracy: 0.7000 - val_loss: 0.8678 - val_accuracy: 0.6239\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7104 - accuracy: 0.6926 - val_loss: 0.8662 - val_accuracy: 0.6325\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7076 - accuracy: 0.7000 - val_loss: 0.8743 - val_accuracy: 0.6154\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7060 - accuracy: 0.6963 - val_loss: 0.8805 - val_accuracy: 0.5983\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7057 - accuracy: 0.7000 - val_loss: 0.8706 - val_accuracy: 0.6410\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7196 - accuracy: 0.7000 - val_loss: 0.8830 - val_accuracy: 0.5983\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7055 - accuracy: 0.7111 - val_loss: 0.8794 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7775 - accuracy: 0.6889 - val_loss: 1.0376 - val_accuracy: 0.6154\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9419 - accuracy: 0.6704 - val_loss: 1.1346 - val_accuracy: 0.5897\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8099 - accuracy: 0.6889 - val_loss: 0.8606 - val_accuracy: 0.6239\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7309 - accuracy: 0.7074 - val_loss: 0.8656 - val_accuracy: 0.6325\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7124 - accuracy: 0.6963 - val_loss: 0.8803 - val_accuracy: 0.6154\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7186 - accuracy: 0.7000 - val_loss: 0.8709 - val_accuracy: 0.6239\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7019 - accuracy: 0.7000 - val_loss: 0.8648 - val_accuracy: 0.6239\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7065 - accuracy: 0.7074 - val_loss: 0.8635 - val_accuracy: 0.6325\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7103 - accuracy: 0.7000 - val_loss: 0.8664 - val_accuracy: 0.6154\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7064 - accuracy: 0.6926 - val_loss: 0.8860 - val_accuracy: 0.6239\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7325 - accuracy: 0.6852 - val_loss: 0.9772 - val_accuracy: 0.5897\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7484 - accuracy: 0.6778 - val_loss: 0.8650 - val_accuracy: 0.6239\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7273 - accuracy: 0.7148 - val_loss: 0.8672 - val_accuracy: 0.6325\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7184 - accuracy: 0.6889 - val_loss: 0.9450 - val_accuracy: 0.5812\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7315 - accuracy: 0.7000 - val_loss: 0.8770 - val_accuracy: 0.6068\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7089 - accuracy: 0.6778 - val_loss: 0.8842 - val_accuracy: 0.6154\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7084 - accuracy: 0.6963 - val_loss: 0.8831 - val_accuracy: 0.6239\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7143 - accuracy: 0.6963 - val_loss: 0.8693 - val_accuracy: 0.6154\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7087 - accuracy: 0.6889 - val_loss: 0.8616 - val_accuracy: 0.6410\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7055 - accuracy: 0.7037 - val_loss: 0.8812 - val_accuracy: 0.6068\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7048 - accuracy: 0.6963 - val_loss: 0.8612 - val_accuracy: 0.6239\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7000 - accuracy: 0.7037 - val_loss: 0.8972 - val_accuracy: 0.5897\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7140 - accuracy: 0.6926 - val_loss: 0.8687 - val_accuracy: 0.6239\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7131 - accuracy: 0.7000 - val_loss: 0.9269 - val_accuracy: 0.6068\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7280 - accuracy: 0.7000 - val_loss: 0.9385 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7386 - accuracy: 0.7074 - val_loss: 0.8945 - val_accuracy: 0.6154\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7520 - accuracy: 0.6704 - val_loss: 0.8892 - val_accuracy: 0.6325\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7172 - accuracy: 0.6852 - val_loss: 0.8883 - val_accuracy: 0.6154\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.7202 - accuracy: 0.6963 - val_loss: 0.9011 - val_accuracy: 0.6239\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.7131 - accuracy: 0.7037 - val_loss: 0.8887 - val_accuracy: 0.6325\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.7158 - accuracy: 0.6963 - val_loss: 0.9839 - val_accuracy: 0.5897\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7365 - accuracy: 0.6852 - val_loss: 0.8719 - val_accuracy: 0.6325\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7292 - accuracy: 0.6815 - val_loss: 0.8685 - val_accuracy: 0.6325\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7069 - accuracy: 0.7111 - val_loss: 0.8922 - val_accuracy: 0.6239\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7516 - accuracy: 0.6741 - val_loss: 0.9058 - val_accuracy: 0.6154\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7371 - accuracy: 0.6963 - val_loss: 0.9102 - val_accuracy: 0.5897\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7137 - accuracy: 0.6778 - val_loss: 0.8640 - val_accuracy: 0.6239\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7294 - accuracy: 0.6926 - val_loss: 0.8715 - val_accuracy: 0.6410\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7177 - accuracy: 0.6926 - val_loss: 0.8725 - val_accuracy: 0.6154\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7015 - accuracy: 0.7000 - val_loss: 0.8658 - val_accuracy: 0.6154\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7063 - accuracy: 0.7037 - val_loss: 0.9146 - val_accuracy: 0.5897\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7138 - accuracy: 0.6778 - val_loss: 0.8648 - val_accuracy: 0.6239\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7144 - accuracy: 0.6889 - val_loss: 0.8727 - val_accuracy: 0.6239\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7098 - accuracy: 0.6926 - val_loss: 0.8671 - val_accuracy: 0.6239\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7240 - accuracy: 0.6852 - val_loss: 0.9530 - val_accuracy: 0.6068\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7429 - accuracy: 0.6889 - val_loss: 0.9058 - val_accuracy: 0.6325\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7323 - accuracy: 0.6889 - val_loss: 0.8902 - val_accuracy: 0.6154\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7020 - accuracy: 0.6963 - val_loss: 0.8693 - val_accuracy: 0.6410\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7178 - accuracy: 0.6926 - val_loss: 0.9089 - val_accuracy: 0.5897\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7202 - accuracy: 0.6889 - val_loss: 0.8852 - val_accuracy: 0.6154\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7287 - accuracy: 0.6815 - val_loss: 0.9543 - val_accuracy: 0.5897\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7434 - accuracy: 0.6926 - val_loss: 0.9263 - val_accuracy: 0.6154\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7417 - accuracy: 0.6889 - val_loss: 0.8918 - val_accuracy: 0.5983\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7211 - accuracy: 0.6815 - val_loss: 1.0085 - val_accuracy: 0.5897\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8557 - accuracy: 0.6926 - val_loss: 1.1606 - val_accuracy: 0.6154\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8599 - accuracy: 0.6926 - val_loss: 1.1046 - val_accuracy: 0.5812\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9182 - accuracy: 0.6704 - val_loss: 1.0749 - val_accuracy: 0.6239\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9312 - accuracy: 0.6778 - val_loss: 1.3382 - val_accuracy: 0.6068\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0599 - accuracy: 0.6704 - val_loss: 0.9888 - val_accuracy: 0.6154\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8371 - accuracy: 0.6963 - val_loss: 0.9417 - val_accuracy: 0.5897\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7088 - accuracy: 0.7037 - val_loss: 0.8620 - val_accuracy: 0.6325\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7017 - accuracy: 0.7148 - val_loss: 0.8795 - val_accuracy: 0.6154\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7019 - accuracy: 0.6926 - val_loss: 0.9015 - val_accuracy: 0.6154\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7354 - accuracy: 0.6889 - val_loss: 0.8780 - val_accuracy: 0.6239\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6991 - accuracy: 0.7111 - val_loss: 0.8654 - val_accuracy: 0.6496\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7116 - accuracy: 0.6963 - val_loss: 0.8660 - val_accuracy: 0.6325\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6994 - accuracy: 0.6963 - val_loss: 0.8857 - val_accuracy: 0.6068\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7184 - accuracy: 0.6889 - val_loss: 0.8722 - val_accuracy: 0.6154\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7166 - accuracy: 0.7000 - val_loss: 0.8664 - val_accuracy: 0.6154\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7605 - accuracy: 0.6852 - val_loss: 0.9732 - val_accuracy: 0.5983\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7909 - accuracy: 0.7000 - val_loss: 0.8716 - val_accuracy: 0.6410\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7131 - accuracy: 0.7037 - val_loss: 0.9438 - val_accuracy: 0.6068\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7252 - accuracy: 0.6815 - val_loss: 0.8784 - val_accuracy: 0.6154\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7173 - accuracy: 0.7111 - val_loss: 0.8730 - val_accuracy: 0.6154\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7012 - accuracy: 0.6963 - val_loss: 0.8808 - val_accuracy: 0.6068\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7170 - accuracy: 0.6889 - val_loss: 0.8799 - val_accuracy: 0.6325\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7163 - accuracy: 0.6815 - val_loss: 0.8892 - val_accuracy: 0.6068\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7203 - accuracy: 0.7000 - val_loss: 0.9483 - val_accuracy: 0.6068\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7303 - accuracy: 0.6963 - val_loss: 0.8608 - val_accuracy: 0.6239\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7053 - accuracy: 0.6852 - val_loss: 0.8772 - val_accuracy: 0.6325\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7261 - accuracy: 0.7148 - val_loss: 0.9144 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7563 - accuracy: 0.6778 - val_loss: 1.1338 - val_accuracy: 0.5983\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8348 - accuracy: 0.6926 - val_loss: 1.2089 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.2247 - accuracy: 0.6852 - val_loss: 0.9734 - val_accuracy: 0.5983\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7848 - accuracy: 0.7000 - val_loss: 0.8997 - val_accuracy: 0.6325\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7662 - accuracy: 0.6963 - val_loss: 0.9325 - val_accuracy: 0.5812\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7277 - accuracy: 0.6926 - val_loss: 0.8882 - val_accuracy: 0.6239\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7229 - accuracy: 0.6741 - val_loss: 0.8848 - val_accuracy: 0.6154\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7298 - accuracy: 0.6852 - val_loss: 0.8963 - val_accuracy: 0.6325\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7585 - accuracy: 0.6741 - val_loss: 0.8905 - val_accuracy: 0.6325\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8088 - accuracy: 0.6704 - val_loss: 1.1043 - val_accuracy: 0.5726\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9263 - accuracy: 0.6556 - val_loss: 1.1659 - val_accuracy: 0.5812\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9052 - accuracy: 0.6778 - val_loss: 1.0277 - val_accuracy: 0.5897\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7634 - accuracy: 0.6889 - val_loss: 0.8745 - val_accuracy: 0.6325\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7013 - accuracy: 0.6963 - val_loss: 0.8850 - val_accuracy: 0.6154\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7297 - accuracy: 0.6963 - val_loss: 0.8713 - val_accuracy: 0.6154\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7322 - accuracy: 0.6963 - val_loss: 0.8908 - val_accuracy: 0.6154\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7610 - accuracy: 0.6963 - val_loss: 0.9488 - val_accuracy: 0.5897\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7252 - accuracy: 0.7111 - val_loss: 0.8774 - val_accuracy: 0.6410\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7380 - accuracy: 0.6963 - val_loss: 0.9161 - val_accuracy: 0.5897\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7239 - accuracy: 0.7000 - val_loss: 0.9225 - val_accuracy: 0.6068\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7228 - accuracy: 0.6963 - val_loss: 0.8705 - val_accuracy: 0.6410\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7113 - accuracy: 0.7000 - val_loss: 0.9439 - val_accuracy: 0.6068\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7053 - accuracy: 0.7000 - val_loss: 0.8869 - val_accuracy: 0.6239\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7136 - accuracy: 0.6852 - val_loss: 0.8787 - val_accuracy: 0.5983\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7074 - accuracy: 0.6815 - val_loss: 0.8641 - val_accuracy: 0.6154\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7149 - accuracy: 0.7000 - val_loss: 0.8656 - val_accuracy: 0.6239\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7018 - accuracy: 0.6815 - val_loss: 0.8666 - val_accuracy: 0.6154\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6950 - accuracy: 0.7074 - val_loss: 0.8708 - val_accuracy: 0.6325\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6976 - accuracy: 0.7074 - val_loss: 0.8629 - val_accuracy: 0.6239\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7070 - accuracy: 0.6852 - val_loss: 0.8648 - val_accuracy: 0.6410\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7073 - accuracy: 0.7000 - val_loss: 0.8915 - val_accuracy: 0.6239\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7106 - accuracy: 0.6889 - val_loss: 0.8987 - val_accuracy: 0.6068\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7311 - accuracy: 0.7000 - val_loss: 0.9072 - val_accuracy: 0.6068\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7513 - accuracy: 0.6815 - val_loss: 0.9309 - val_accuracy: 0.5812\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7315 - accuracy: 0.6815 - val_loss: 0.8790 - val_accuracy: 0.6410\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7145 - accuracy: 0.6815 - val_loss: 1.1573 - val_accuracy: 0.5812\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8572 - accuracy: 0.6815 - val_loss: 0.9872 - val_accuracy: 0.6068\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9153 - accuracy: 0.6926 - val_loss: 0.9053 - val_accuracy: 0.5726\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7817 - accuracy: 0.6963 - val_loss: 0.9583 - val_accuracy: 0.6068\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7304 - accuracy: 0.7037 - val_loss: 0.8760 - val_accuracy: 0.5983\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7017 - accuracy: 0.6926 - val_loss: 0.8673 - val_accuracy: 0.6239\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6982 - accuracy: 0.6889 - val_loss: 0.8710 - val_accuracy: 0.6239\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6979 - accuracy: 0.6926 - val_loss: 0.9014 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7298 - accuracy: 0.6926 - val_loss: 0.8960 - val_accuracy: 0.6154\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7122 - accuracy: 0.7037 - val_loss: 1.0818 - val_accuracy: 0.5812\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7741 - accuracy: 0.6852 - val_loss: 0.9053 - val_accuracy: 0.6239\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7208 - accuracy: 0.7074 - val_loss: 1.2607 - val_accuracy: 0.5812\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 1.0251 - accuracy: 0.7000 - val_loss: 1.2445 - val_accuracy: 0.6154\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 1.1490 - accuracy: 0.6481 - val_loss: 1.0627 - val_accuracy: 0.5726\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8695 - accuracy: 0.6407 - val_loss: 0.9227 - val_accuracy: 0.6239\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7838 - accuracy: 0.6852 - val_loss: 0.8807 - val_accuracy: 0.6325\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7663 - accuracy: 0.6889 - val_loss: 0.8949 - val_accuracy: 0.6154\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7694 - accuracy: 0.6963 - val_loss: 0.8732 - val_accuracy: 0.6154\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7332 - accuracy: 0.6889 - val_loss: 0.8781 - val_accuracy: 0.6239\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7784 - accuracy: 0.6926 - val_loss: 0.9476 - val_accuracy: 0.6239\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8197 - accuracy: 0.7000 - val_loss: 0.9499 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7394 - accuracy: 0.7000 - val_loss: 0.9679 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d927e10>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 87us/step\n",
      "over-sampling test accuracy: 67.52%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 0, 2, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0,\n",
       "       0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0,\n",
       "       1, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 2, 2, 1, 2, 0, 2, 1,\n",
       "       2, 0, 0, 2, 1, 1, 2, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 1,\n",
       "       2, 1, 2, 0, 2, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1, 0, 0, 2, 2, 0, 2, 0,\n",
       "       0, 1, 2, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS210     0     0\n",
       "1         NRS205     2     2\n",
       "2            312     2     2\n",
       "3           GA15     2     0\n",
       "4         SR4035     0     0\n",
       "..           ...   ...   ...\n",
       "112       NRS265     2     2\n",
       "113  CFBREBSa108     1     0\n",
       "114        NY224     1     1\n",
       "115       NRS386     2     2\n",
       "116       NRS168     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767829</td>\n",
       "      <td>0.230110</td>\n",
       "      <td>0.002061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069677</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.930126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.962377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580774</td>\n",
       "      <td>0.222390</td>\n",
       "      <td>0.196836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628776</td>\n",
       "      <td>0.370517</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.294361</td>\n",
       "      <td>0.066527</td>\n",
       "      <td>0.639111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.968010</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>0.015745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.244494</td>\n",
       "      <td>0.710529</td>\n",
       "      <td>0.044977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.087958</td>\n",
       "      <td>0.190353</td>\n",
       "      <td>0.721689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.193376</td>\n",
       "      <td>0.806256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.767829  0.230110  0.002061\n",
       "1    0.069677  0.000197  0.930126\n",
       "2    0.021005  0.016618  0.962377\n",
       "3    0.580774  0.222390  0.196836\n",
       "4    0.628776  0.370517  0.000707\n",
       "..        ...       ...       ...\n",
       "112  0.294361  0.066527  0.639111\n",
       "113  0.968010  0.016245  0.015745\n",
       "114  0.244494  0.710529  0.044977\n",
       "115  0.087958  0.190353  0.721689\n",
       "116  0.000368  0.193376  0.806256\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6618 - accuracy: 0.7111 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6797 - accuracy: 0.7148 - val_loss: 0.8956 - val_accuracy: 0.6496\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.7890 - accuracy: 0.6778 - val_loss: 0.9446 - val_accuracy: 0.6239\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7020 - accuracy: 0.7148 - val_loss: 0.9373 - val_accuracy: 0.5983\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6856 - accuracy: 0.6963 - val_loss: 0.8586 - val_accuracy: 0.6581\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7312 - accuracy: 0.6963 - val_loss: 0.8686 - val_accuracy: 0.6410\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7204 - accuracy: 0.7074 - val_loss: 0.8778 - val_accuracy: 0.6667\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7566 - accuracy: 0.7037 - val_loss: 0.9702 - val_accuracy: 0.6239\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8112 - accuracy: 0.7000 - val_loss: 0.9158 - val_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7312 - accuracy: 0.7185 - val_loss: 0.9407 - val_accuracy: 0.6068\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7162 - accuracy: 0.7037 - val_loss: 0.8348 - val_accuracy: 0.6496\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6968 - accuracy: 0.7037 - val_loss: 0.8223 - val_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7286 - accuracy: 0.7037 - val_loss: 0.8745 - val_accuracy: 0.6581\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6816 - accuracy: 0.7148 - val_loss: 0.8252 - val_accuracy: 0.6581\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6853 - accuracy: 0.7074 - val_loss: 0.8863 - val_accuracy: 0.6496\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7040 - accuracy: 0.7185 - val_loss: 0.8878 - val_accuracy: 0.6581\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8733 - accuracy: 0.7111 - val_loss: 0.8840 - val_accuracy: 0.6410\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7632 - accuracy: 0.6963 - val_loss: 0.9606 - val_accuracy: 0.6239\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8480 - accuracy: 0.7000 - val_loss: 0.8450 - val_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7295 - accuracy: 0.7037 - val_loss: 0.8452 - val_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7236 - accuracy: 0.7074 - val_loss: 0.8311 - val_accuracy: 0.6752\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6887 - accuracy: 0.6963 - val_loss: 0.9003 - val_accuracy: 0.6496\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7182 - accuracy: 0.7037 - val_loss: 0.8605 - val_accuracy: 0.6496\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6824 - accuracy: 0.7037 - val_loss: 0.8228 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6853 - accuracy: 0.7111 - val_loss: 0.8358 - val_accuracy: 0.6581\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6814 - accuracy: 0.7037 - val_loss: 0.8552 - val_accuracy: 0.6496\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6647 - accuracy: 0.7037 - val_loss: 0.8350 - val_accuracy: 0.6496\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6898 - accuracy: 0.7074 - val_loss: 0.8474 - val_accuracy: 0.6581\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6686 - accuracy: 0.7000 - val_loss: 0.8312 - val_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6678 - accuracy: 0.7259 - val_loss: 0.8343 - val_accuracy: 0.6581\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6561 - accuracy: 0.7111 - val_loss: 0.8226 - val_accuracy: 0.6752\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6637 - accuracy: 0.7148 - val_loss: 0.8409 - val_accuracy: 0.6496\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6738 - accuracy: 0.7111 - val_loss: 0.8257 - val_accuracy: 0.6581\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6928 - accuracy: 0.6963 - val_loss: 0.8297 - val_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6813 - accuracy: 0.7111 - val_loss: 0.8343 - val_accuracy: 0.6581\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6799 - accuracy: 0.6889 - val_loss: 0.8258 - val_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6720 - accuracy: 0.7259 - val_loss: 0.8172 - val_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6700 - accuracy: 0.7000 - val_loss: 0.8282 - val_accuracy: 0.6752\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7135 - accuracy: 0.7074 - val_loss: 0.8631 - val_accuracy: 0.6496\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6936 - accuracy: 0.6852 - val_loss: 0.9135 - val_accuracy: 0.6239\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7090 - accuracy: 0.6963 - val_loss: 0.8425 - val_accuracy: 0.6496\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6930 - accuracy: 0.7037 - val_loss: 0.8266 - val_accuracy: 0.6410\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6982 - accuracy: 0.7037 - val_loss: 0.8712 - val_accuracy: 0.6410\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6727 - accuracy: 0.7074 - val_loss: 0.8294 - val_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6644 - accuracy: 0.7148 - val_loss: 0.8201 - val_accuracy: 0.6667\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6585 - accuracy: 0.7296 - val_loss: 0.8352 - val_accuracy: 0.6496\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.68 - 0s 110us/step - loss: 0.6605 - accuracy: 0.7148 - val_loss: 0.8278 - val_accuracy: 0.6581\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6578 - accuracy: 0.7148 - val_loss: 0.8235 - val_accuracy: 0.6581\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6569 - accuracy: 0.7074 - val_loss: 0.8306 - val_accuracy: 0.6496\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7050 - accuracy: 0.7222 - val_loss: 0.8237 - val_accuracy: 0.6581\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6841 - accuracy: 0.6963 - val_loss: 0.8567 - val_accuracy: 0.6581\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6638 - accuracy: 0.7111 - val_loss: 0.8181 - val_accuracy: 0.6838\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6597 - accuracy: 0.7185 - val_loss: 0.8386 - val_accuracy: 0.6752\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6798 - accuracy: 0.7148 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6553 - accuracy: 0.7148 - val_loss: 0.8184 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6517 - accuracy: 0.7259 - val_loss: 0.8392 - val_accuracy: 0.6496\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6724 - accuracy: 0.7074 - val_loss: 0.8372 - val_accuracy: 0.6496\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6830 - accuracy: 0.6963 - val_loss: 0.8172 - val_accuracy: 0.6581\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6686 - accuracy: 0.7148 - val_loss: 0.8288 - val_accuracy: 0.6667\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6629 - accuracy: 0.7148 - val_loss: 0.8222 - val_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6606 - accuracy: 0.7185 - val_loss: 0.8198 - val_accuracy: 0.6752\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6515 - accuracy: 0.7185 - val_loss: 0.8223 - val_accuracy: 0.6752\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6588 - accuracy: 0.7222 - val_loss: 0.8175 - val_accuracy: 0.6581\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6645 - accuracy: 0.7111 - val_loss: 0.8315 - val_accuracy: 0.6581\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6551 - accuracy: 0.7222 - val_loss: 0.8156 - val_accuracy: 0.6838\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6643 - accuracy: 0.7148 - val_loss: 0.8530 - val_accuracy: 0.6496\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6552 - accuracy: 0.7259 - val_loss: 0.8281 - val_accuracy: 0.6752\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6587 - accuracy: 0.7111 - val_loss: 0.8358 - val_accuracy: 0.6581\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6720 - accuracy: 0.7037 - val_loss: 0.8339 - val_accuracy: 0.6667\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7173 - accuracy: 0.7148 - val_loss: 0.8831 - val_accuracy: 0.6410\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6639 - accuracy: 0.7111 - val_loss: 0.8211 - val_accuracy: 0.6838\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6589 - accuracy: 0.7296 - val_loss: 0.8312 - val_accuracy: 0.6581\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6581 - accuracy: 0.7185 - val_loss: 0.8144 - val_accuracy: 0.6667\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6525 - accuracy: 0.7111 - val_loss: 0.8177 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6578 - accuracy: 0.7037 - val_loss: 0.8286 - val_accuracy: 0.6496\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6570 - accuracy: 0.7111 - val_loss: 0.8162 - val_accuracy: 0.6667\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6728 - accuracy: 0.7037 - val_loss: 0.8684 - val_accuracy: 0.6581\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 317us/step - loss: 0.6601 - accuracy: 0.7111 - val_loss: 0.8455 - val_accuracy: 0.6496\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.6629 - accuracy: 0.7111 - val_loss: 0.8576 - val_accuracy: 0.6410\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 362us/step - loss: 0.6604 - accuracy: 0.7111 - val_loss: 0.8320 - val_accuracy: 0.6667\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6784 - accuracy: 0.7259 - val_loss: 0.8270 - val_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6589 - accuracy: 0.7222 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6741 - accuracy: 0.7037 - val_loss: 0.8361 - val_accuracy: 0.6667\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.6533 - accuracy: 0.7148 - val_loss: 0.8252 - val_accuracy: 0.6752\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.6823 - accuracy: 0.7111 - val_loss: 0.8802 - val_accuracy: 0.6581\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 450us/step - loss: 0.6942 - accuracy: 0.6926 - val_loss: 0.8208 - val_accuracy: 0.6923\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 705us/step - loss: 0.6686 - accuracy: 0.7185 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6875 - accuracy: 0.7111 - val_loss: 0.8427 - val_accuracy: 0.6581\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6754 - accuracy: 0.7000 - val_loss: 0.8636 - val_accuracy: 0.6752\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7017 - accuracy: 0.7000 - val_loss: 0.8364 - val_accuracy: 0.6752\n",
      "Epoch 91/1000\n",
      " 32/270 [==>...........................] - ETA: 0s - loss: 0.6336 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.124900). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 238us/step - loss: 0.6632 - accuracy: 0.7111 - val_loss: 0.8408 - val_accuracy: 0.6496\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 316us/step - loss: 0.6609 - accuracy: 0.6963 - val_loss: 0.8271 - val_accuracy: 0.6496\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6531 - accuracy: 0.7111 - val_loss: 0.8266 - val_accuracy: 0.6581\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7020 - accuracy: 0.7111 - val_loss: 0.8641 - val_accuracy: 0.6581\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6818 - accuracy: 0.7148 - val_loss: 0.8371 - val_accuracy: 0.6752\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.6784 - accuracy: 0.7148 - val_loss: 0.8403 - val_accuracy: 0.6496\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6958 - accuracy: 0.6926 - val_loss: 0.8277 - val_accuracy: 0.6496\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6733 - accuracy: 0.7037 - val_loss: 0.8595 - val_accuracy: 0.6496\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6670 - accuracy: 0.7185 - val_loss: 0.8209 - val_accuracy: 0.6667\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6604 - accuracy: 0.7074 - val_loss: 0.8173 - val_accuracy: 0.6752\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6779 - accuracy: 0.7148 - val_loss: 0.8464 - val_accuracy: 0.6581\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7047 - accuracy: 0.7074 - val_loss: 0.8335 - val_accuracy: 0.6581\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6564 - accuracy: 0.7111 - val_loss: 0.8236 - val_accuracy: 0.6581\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6477 - accuracy: 0.7296 - val_loss: 0.8270 - val_accuracy: 0.6496\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.6519 - accuracy: 0.7185 - val_loss: 0.8259 - val_accuracy: 0.6581\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6456 - accuracy: 0.7259 - val_loss: 0.8202 - val_accuracy: 0.6838\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6483 - accuracy: 0.7222 - val_loss: 0.8291 - val_accuracy: 0.6838\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6535 - accuracy: 0.7074 - val_loss: 0.8252 - val_accuracy: 0.6667\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6776 - accuracy: 0.7111 - val_loss: 0.9101 - val_accuracy: 0.6410\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7375 - accuracy: 0.7111 - val_loss: 0.9949 - val_accuracy: 0.6496\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9336 - accuracy: 0.7037 - val_loss: 0.8507 - val_accuracy: 0.6496\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7610 - accuracy: 0.7074 - val_loss: 0.8546 - val_accuracy: 0.6581\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.7794 - accuracy: 0.6926 - val_loss: 0.8588 - val_accuracy: 0.6581\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.7397 - accuracy: 0.6815 - val_loss: 0.9697 - val_accuracy: 0.6239\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.7160 - accuracy: 0.7074 - val_loss: 0.8270 - val_accuracy: 0.6581\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.6688 - accuracy: 0.7074 - val_loss: 0.8368 - val_accuracy: 0.6667\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.6673 - accuracy: 0.7111 - val_loss: 0.8197 - val_accuracy: 0.6838\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.6759 - accuracy: 0.7148 - val_loss: 0.8502 - val_accuracy: 0.6581\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.6767 - accuracy: 0.7037 - val_loss: 0.9222 - val_accuracy: 0.6667\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7214 - accuracy: 0.7148 - val_loss: 0.8516 - val_accuracy: 0.6581\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6691 - accuracy: 0.7037 - val_loss: 0.8329 - val_accuracy: 0.6752\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6736 - accuracy: 0.7148 - val_loss: 0.9435 - val_accuracy: 0.6239\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7316 - accuracy: 0.7111 - val_loss: 0.8508 - val_accuracy: 0.6496\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6752 - accuracy: 0.7074 - val_loss: 0.9160 - val_accuracy: 0.6496\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6899 - accuracy: 0.7074 - val_loss: 0.8175 - val_accuracy: 0.6667\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 430us/step - loss: 0.6536 - accuracy: 0.7296 - val_loss: 0.8245 - val_accuracy: 0.6667\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6584 - accuracy: 0.7222 - val_loss: 0.8266 - val_accuracy: 0.6581\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6626 - accuracy: 0.7074 - val_loss: 0.8357 - val_accuracy: 0.6496\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6546 - accuracy: 0.7185 - val_loss: 0.8300 - val_accuracy: 0.6410\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6970 - accuracy: 0.7000 - val_loss: 0.9307 - val_accuracy: 0.6410\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6927 - accuracy: 0.7000 - val_loss: 0.8326 - val_accuracy: 0.6667\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6652 - accuracy: 0.7185 - val_loss: 0.8242 - val_accuracy: 0.6923\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7572 - accuracy: 0.7074 - val_loss: 0.8268 - val_accuracy: 0.6496\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 316us/step - loss: 0.6754 - accuracy: 0.7111 - val_loss: 0.8174 - val_accuracy: 0.6496\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6592 - accuracy: 0.7000 - val_loss: 0.8319 - val_accuracy: 0.6752\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6633 - accuracy: 0.7185 - val_loss: 0.8269 - val_accuracy: 0.6581\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6634 - accuracy: 0.7074 - val_loss: 0.8323 - val_accuracy: 0.6496\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6638 - accuracy: 0.7111 - val_loss: 0.8326 - val_accuracy: 0.6496\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6575 - accuracy: 0.7185 - val_loss: 0.8147 - val_accuracy: 0.6838\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6541 - accuracy: 0.7000 - val_loss: 0.8396 - val_accuracy: 0.6496\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6580 - accuracy: 0.7185 - val_loss: 0.8187 - val_accuracy: 0.6667\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6734 - accuracy: 0.6963 - val_loss: 0.8444 - val_accuracy: 0.6496\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6699 - accuracy: 0.7074 - val_loss: 0.8213 - val_accuracy: 0.6838\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 531us/step - loss: 0.6628 - accuracy: 0.7111 - val_loss: 0.8332 - val_accuracy: 0.6752\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6996 - accuracy: 0.7074 - val_loss: 0.8547 - val_accuracy: 0.6410\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.6835 - accuracy: 0.7185 - val_loss: 0.8458 - val_accuracy: 0.6581\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 324us/step - loss: 0.6854 - accuracy: 0.7185 - val_loss: 0.8659 - val_accuracy: 0.6581\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 617us/step - loss: 0.6569 - accuracy: 0.7111 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 273us/step - loss: 0.6510 - accuracy: 0.7222 - val_loss: 0.8452 - val_accuracy: 0.6410\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.6568 - accuracy: 0.7148 - val_loss: 0.8247 - val_accuracy: 0.6667\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.6798 - accuracy: 0.7074 - val_loss: 0.8762 - val_accuracy: 0.6410\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.6629 - accuracy: 0.7111 - val_loss: 0.8394 - val_accuracy: 0.6752\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6934 - accuracy: 0.7037 - val_loss: 0.8446 - val_accuracy: 0.6496\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6779 - accuracy: 0.7000 - val_loss: 0.9084 - val_accuracy: 0.6154\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7845 - accuracy: 0.6852 - val_loss: 0.8167 - val_accuracy: 0.6667\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 355us/step - loss: 0.7396 - accuracy: 0.6963 - val_loss: 0.8437 - val_accuracy: 0.6581\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.6693 - accuracy: 0.7296 - val_loss: 0.8385 - val_accuracy: 0.6496\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.6559 - accuracy: 0.7148 - val_loss: 0.8101 - val_accuracy: 0.6752\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6474 - accuracy: 0.7222 - val_loss: 0.8334 - val_accuracy: 0.6581\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6517 - accuracy: 0.7259 - val_loss: 0.8090 - val_accuracy: 0.7009\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6477 - accuracy: 0.7074 - val_loss: 0.8142 - val_accuracy: 0.6667\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6757 - accuracy: 0.7037 - val_loss: 0.8596 - val_accuracy: 0.6496\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6652 - accuracy: 0.7037 - val_loss: 0.8330 - val_accuracy: 0.6667\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.6705 - accuracy: 0.7185 - val_loss: 0.8347 - val_accuracy: 0.6496\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6609 - accuracy: 0.7074 - val_loss: 0.8128 - val_accuracy: 0.6667\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6493 - accuracy: 0.7222 - val_loss: 0.8244 - val_accuracy: 0.6581\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6799 - accuracy: 0.7037 - val_loss: 0.8137 - val_accuracy: 0.6581\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6858 - accuracy: 0.7037 - val_loss: 0.8189 - val_accuracy: 0.6496\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6765 - accuracy: 0.6963 - val_loss: 0.8241 - val_accuracy: 0.6496\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.6511 - accuracy: 0.7111 - val_loss: 0.8171 - val_accuracy: 0.6496\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.6542 - accuracy: 0.7111 - val_loss: 0.8196 - val_accuracy: 0.6496\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6697 - accuracy: 0.7074 - val_loss: 0.8284 - val_accuracy: 0.6496\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6572 - accuracy: 0.7148 - val_loss: 0.8168 - val_accuracy: 0.7009\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.6595 - accuracy: 0.7222 - val_loss: 0.8752 - val_accuracy: 0.6581\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.6511 - accuracy: 0.7222 - val_loss: 0.8302 - val_accuracy: 0.6667\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6485 - accuracy: 0.7185 - val_loss: 0.8352 - val_accuracy: 0.6410\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6431 - accuracy: 0.7259 - val_loss: 0.8298 - val_accuracy: 0.6923\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6527 - accuracy: 0.7222 - val_loss: 0.8208 - val_accuracy: 0.6581\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6853 - accuracy: 0.7148 - val_loss: 0.8729 - val_accuracy: 0.6410\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7150 - accuracy: 0.7148 - val_loss: 0.9328 - val_accuracy: 0.6496\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7392 - accuracy: 0.7074 - val_loss: 0.8314 - val_accuracy: 0.6496\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8176 - accuracy: 0.6926 - val_loss: 0.9669 - val_accuracy: 0.6496\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8121 - accuracy: 0.6963 - val_loss: 0.8474 - val_accuracy: 0.6239\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7013 - accuracy: 0.7185 - val_loss: 0.8722 - val_accuracy: 0.6496\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7617 - accuracy: 0.7074 - val_loss: 0.8227 - val_accuracy: 0.6667\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 306us/step - loss: 0.6694 - accuracy: 0.7074 - val_loss: 0.8288 - val_accuracy: 0.6667\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6610 - accuracy: 0.7222 - val_loss: 0.8269 - val_accuracy: 0.6752\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.6713 - accuracy: 0.6926 - val_loss: 0.8482 - val_accuracy: 0.6667\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6568 - accuracy: 0.7222 - val_loss: 0.8425 - val_accuracy: 0.6752\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6541 - accuracy: 0.7185 - val_loss: 0.8229 - val_accuracy: 0.6752\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6516 - accuracy: 0.7259 - val_loss: 0.8268 - val_accuracy: 0.6496\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6526 - accuracy: 0.6963 - val_loss: 0.8302 - val_accuracy: 0.6410\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6474 - accuracy: 0.7111 - val_loss: 0.8146 - val_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6439 - accuracy: 0.7148 - val_loss: 0.8187 - val_accuracy: 0.6752\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6526 - accuracy: 0.7148 - val_loss: 0.8164 - val_accuracy: 0.6667\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6489 - accuracy: 0.7333 - val_loss: 0.8479 - val_accuracy: 0.6496\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6604 - accuracy: 0.7222 - val_loss: 0.8207 - val_accuracy: 0.6667\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6488 - accuracy: 0.7111 - val_loss: 0.8183 - val_accuracy: 0.6581\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.6455 - accuracy: 0.7111 - val_loss: 0.8411 - val_accuracy: 0.6667\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.6364 - accuracy: 0.7407 - val_loss: 0.8246 - val_accuracy: 0.6581\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 312us/step - loss: 0.6515 - accuracy: 0.7148 - val_loss: 0.8455 - val_accuracy: 0.6667\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7062 - accuracy: 0.7074 - val_loss: 0.9525 - val_accuracy: 0.6581\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.7330 - accuracy: 0.7185 - val_loss: 0.8698 - val_accuracy: 0.6154\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.7234 - accuracy: 0.6963 - val_loss: 0.8397 - val_accuracy: 0.6752\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6769 - accuracy: 0.7148 - val_loss: 0.8752 - val_accuracy: 0.6325\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6817 - accuracy: 0.7148 - val_loss: 0.8258 - val_accuracy: 0.6581\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6620 - accuracy: 0.7074 - val_loss: 0.8578 - val_accuracy: 0.6410\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6546 - accuracy: 0.7148 - val_loss: 0.8485 - val_accuracy: 0.6410\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 308us/step - loss: 0.6677 - accuracy: 0.7148 - val_loss: 0.8249 - val_accuracy: 0.6667\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6520 - accuracy: 0.7148 - val_loss: 0.8408 - val_accuracy: 0.6581\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6503 - accuracy: 0.7222 - val_loss: 0.8123 - val_accuracy: 0.6667\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.6558 - accuracy: 0.7222 - val_loss: 0.8438 - val_accuracy: 0.6581\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.6496 - accuracy: 0.7185 - val_loss: 0.8335 - val_accuracy: 0.6752\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.6521 - accuracy: 0.7222 - val_loss: 0.8257 - val_accuracy: 0.6581\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.6437 - accuracy: 0.7185 - val_loss: 0.8308 - val_accuracy: 0.6410\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6546 - accuracy: 0.7333 - val_loss: 0.8168 - val_accuracy: 0.6496\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6833 - accuracy: 0.7037 - val_loss: 0.8764 - val_accuracy: 0.6496\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6339 - accuracy: 0.7185 - val_loss: 0.8347 - val_accuracy: 0.6581\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6606 - accuracy: 0.7148 - val_loss: 0.8250 - val_accuracy: 0.6581\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6432 - accuracy: 0.7185 - val_loss: 0.8233 - val_accuracy: 0.6581\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 635us/step - loss: 0.6684 - accuracy: 0.7111 - val_loss: 0.8144 - val_accuracy: 0.6838\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6778 - accuracy: 0.7222 - val_loss: 0.8273 - val_accuracy: 0.6581\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6741 - accuracy: 0.7074 - val_loss: 0.8260 - val_accuracy: 0.6496\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 282us/step - loss: 0.6645 - accuracy: 0.7111 - val_loss: 0.8544 - val_accuracy: 0.6410\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 312us/step - loss: 0.6783 - accuracy: 0.7111 - val_loss: 0.8153 - val_accuracy: 0.6838\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6411 - accuracy: 0.7370 - val_loss: 0.8246 - val_accuracy: 0.6581\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6478 - accuracy: 0.7148 - val_loss: 0.8242 - val_accuracy: 0.6752\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6480 - accuracy: 0.7259 - val_loss: 0.8257 - val_accuracy: 0.6496\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6652 - accuracy: 0.7111 - val_loss: 0.8428 - val_accuracy: 0.6410\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6779 - accuracy: 0.7074 - val_loss: 0.9639 - val_accuracy: 0.6154\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7346 - accuracy: 0.6889 - val_loss: 0.8323 - val_accuracy: 0.6667\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6916 - accuracy: 0.6778 - val_loss: 0.9092 - val_accuracy: 0.6154\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7421 - accuracy: 0.7000 - val_loss: 0.8575 - val_accuracy: 0.6496\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6622 - accuracy: 0.7148 - val_loss: 0.8864 - val_accuracy: 0.6325\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.6489 - accuracy: 0.7148 - val_loss: 0.8504 - val_accuracy: 0.6496\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.6571 - accuracy: 0.7148 - val_loss: 0.8273 - val_accuracy: 0.6752\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.6563 - accuracy: 0.7222 - val_loss: 0.8162 - val_accuracy: 0.6752\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6335 - accuracy: 0.7259 - val_loss: 0.8418 - val_accuracy: 0.6752\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6418 - accuracy: 0.7222 - val_loss: 0.8433 - val_accuracy: 0.6581\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7305 - accuracy: 0.6852 - val_loss: 0.8168 - val_accuracy: 0.6838\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7428 - accuracy: 0.7111 - val_loss: 0.8306 - val_accuracy: 0.6581\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.7588 - accuracy: 0.7037 - val_loss: 0.9035 - val_accuracy: 0.6410\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.7862 - accuracy: 0.6963 - val_loss: 0.8481 - val_accuracy: 0.6410\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.6675 - accuracy: 0.7222 - val_loss: 0.8296 - val_accuracy: 0.6581\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6425 - accuracy: 0.7222 - val_loss: 0.8205 - val_accuracy: 0.6752\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6411 - accuracy: 0.7259 - val_loss: 0.8496 - val_accuracy: 0.6496\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6584 - accuracy: 0.7148 - val_loss: 0.8202 - val_accuracy: 0.6838\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6562 - accuracy: 0.7259 - val_loss: 0.8402 - val_accuracy: 0.6581\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6725 - accuracy: 0.7074 - val_loss: 0.8508 - val_accuracy: 0.6581\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6528 - accuracy: 0.7111 - val_loss: 0.8176 - val_accuracy: 0.6667\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6736 - accuracy: 0.7074 - val_loss: 0.8938 - val_accuracy: 0.6496\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6716 - accuracy: 0.7037 - val_loss: 0.8145 - val_accuracy: 0.6581\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6530 - accuracy: 0.7185 - val_loss: 0.8197 - val_accuracy: 0.6410\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 287us/step - loss: 0.6430 - accuracy: 0.7222 - val_loss: 0.8302 - val_accuracy: 0.6667\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 360us/step - loss: 0.6535 - accuracy: 0.7370 - val_loss: 0.8155 - val_accuracy: 0.6667\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6916 - accuracy: 0.7000 - val_loss: 0.8456 - val_accuracy: 0.6581\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6684 - accuracy: 0.7074 - val_loss: 0.8207 - val_accuracy: 0.6752\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6500 - accuracy: 0.7185 - val_loss: 0.9091 - val_accuracy: 0.6154\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6835 - accuracy: 0.7111 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6523 - accuracy: 0.7037 - val_loss: 0.8309 - val_accuracy: 0.6581\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6393 - accuracy: 0.7370 - val_loss: 0.8160 - val_accuracy: 0.6752\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6362 - accuracy: 0.7222 - val_loss: 0.8136 - val_accuracy: 0.6752\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6457 - accuracy: 0.7333 - val_loss: 0.8457 - val_accuracy: 0.6581\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6816 - accuracy: 0.7148 - val_loss: 0.8203 - val_accuracy: 0.6496\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.6464 - accuracy: 0.7148 - val_loss: 0.8295 - val_accuracy: 0.6410\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6535 - accuracy: 0.7074 - val_loss: 0.8183 - val_accuracy: 0.6496\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6727 - accuracy: 0.6963 - val_loss: 0.8503 - val_accuracy: 0.6667\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6870 - accuracy: 0.7185 - val_loss: 0.8526 - val_accuracy: 0.6496\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.6480 - accuracy: 0.7185 - val_loss: 0.8191 - val_accuracy: 0.6581\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6498 - accuracy: 0.7185 - val_loss: 0.8724 - val_accuracy: 0.6410\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6898 - accuracy: 0.7000 - val_loss: 0.8216 - val_accuracy: 0.6667\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 313us/step - loss: 0.6530 - accuracy: 0.7074 - val_loss: 0.8579 - val_accuracy: 0.6410\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6478 - accuracy: 0.7185 - val_loss: 0.8097 - val_accuracy: 0.6752\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6501 - accuracy: 0.7259 - val_loss: 0.9167 - val_accuracy: 0.6154\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6815 - accuracy: 0.7111 - val_loss: 0.8213 - val_accuracy: 0.6496\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6927 - accuracy: 0.6926 - val_loss: 0.8714 - val_accuracy: 0.6325\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.7590 - accuracy: 0.7000 - val_loss: 0.8942 - val_accuracy: 0.6325\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8136 - accuracy: 0.7111 - val_loss: 0.8550 - val_accuracy: 0.6581\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6677 - accuracy: 0.7074 - val_loss: 0.8403 - val_accuracy: 0.6581\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6502 - accuracy: 0.7222 - val_loss: 0.8130 - val_accuracy: 0.6752\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6514 - accuracy: 0.7074 - val_loss: 0.8726 - val_accuracy: 0.6581\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.7495 - accuracy: 0.6963 - val_loss: 0.9516 - val_accuracy: 0.6581\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7214 - accuracy: 0.7185 - val_loss: 0.8909 - val_accuracy: 0.5983\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.7040 - accuracy: 0.7000 - val_loss: 0.8199 - val_accuracy: 0.6752\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6623 - accuracy: 0.7148 - val_loss: 0.8130 - val_accuracy: 0.7009\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6573 - accuracy: 0.7222 - val_loss: 0.8568 - val_accuracy: 0.6581\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6646 - accuracy: 0.7111 - val_loss: 0.8485 - val_accuracy: 0.6496\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.6553 - accuracy: 0.7148 - val_loss: 0.8303 - val_accuracy: 0.6410\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6395 - accuracy: 0.7296 - val_loss: 0.8098 - val_accuracy: 0.6752\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6488 - accuracy: 0.7074 - val_loss: 0.8106 - val_accuracy: 0.6752\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6470 - accuracy: 0.7185 - val_loss: 0.8250 - val_accuracy: 0.6581\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6427 - accuracy: 0.7222 - val_loss: 0.8150 - val_accuracy: 0.6667\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6468 - accuracy: 0.7222 - val_loss: 0.8430 - val_accuracy: 0.6581\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6494 - accuracy: 0.7185 - val_loss: 0.8296 - val_accuracy: 0.6923\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6589 - accuracy: 0.7185 - val_loss: 0.8611 - val_accuracy: 0.6325\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6457 - accuracy: 0.7222 - val_loss: 0.8186 - val_accuracy: 0.6496\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6522 - accuracy: 0.7148 - val_loss: 0.8530 - val_accuracy: 0.6410\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6385 - accuracy: 0.7148 - val_loss: 0.8175 - val_accuracy: 0.6581\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6401 - accuracy: 0.7222 - val_loss: 0.8253 - val_accuracy: 0.6496\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.6417 - accuracy: 0.7296 - val_loss: 0.8152 - val_accuracy: 0.6923\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.6389 - accuracy: 0.7333 - val_loss: 0.8202 - val_accuracy: 0.6496\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.6411 - accuracy: 0.7222 - val_loss: 0.8205 - val_accuracy: 0.6667\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.6421 - accuracy: 0.7259 - val_loss: 0.8102 - val_accuracy: 0.6752\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 375us/step - loss: 0.6303 - accuracy: 0.7370 - val_loss: 0.8151 - val_accuracy: 0.6923\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.6388 - accuracy: 0.7407 - val_loss: 0.8340 - val_accuracy: 0.6581\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6487 - accuracy: 0.7259 - val_loss: 0.8309 - val_accuracy: 0.6667\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6442 - accuracy: 0.7222 - val_loss: 0.8488 - val_accuracy: 0.6496\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6556 - accuracy: 0.7111 - val_loss: 0.8215 - val_accuracy: 0.6667\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6557 - accuracy: 0.7111 - val_loss: 0.8335 - val_accuracy: 0.6496\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6394 - accuracy: 0.7148 - val_loss: 0.8098 - val_accuracy: 0.6923\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 325us/step - loss: 0.6364 - accuracy: 0.7296 - val_loss: 0.8367 - val_accuracy: 0.6496\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6459 - accuracy: 0.7296 - val_loss: 0.8127 - val_accuracy: 0.6752\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 455us/step - loss: 0.6393 - accuracy: 0.7222 - val_loss: 0.8443 - val_accuracy: 0.6410\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6373 - accuracy: 0.7222 - val_loss: 0.8144 - val_accuracy: 0.6838\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6448 - accuracy: 0.7259 - val_loss: 0.8289 - val_accuracy: 0.6581\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6330 - accuracy: 0.7370 - val_loss: 0.8123 - val_accuracy: 0.6923\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 509us/step - loss: 0.6337 - accuracy: 0.7407 - val_loss: 0.8125 - val_accuracy: 0.6667\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6427 - accuracy: 0.7074 - val_loss: 0.8256 - val_accuracy: 0.6496\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6373 - accuracy: 0.7185 - val_loss: 0.8109 - val_accuracy: 0.6667\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6384 - accuracy: 0.7185 - val_loss: 0.8367 - val_accuracy: 0.6838\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6342 - accuracy: 0.7333 - val_loss: 0.8110 - val_accuracy: 0.6838\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6385 - accuracy: 0.7333 - val_loss: 0.8095 - val_accuracy: 0.6838\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6330 - accuracy: 0.7185 - val_loss: 0.8277 - val_accuracy: 0.6496\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6363 - accuracy: 0.7185 - val_loss: 0.8160 - val_accuracy: 0.6752\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.6376 - accuracy: 0.7148 - val_loss: 0.8335 - val_accuracy: 0.6496\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.6360 - accuracy: 0.7222 - val_loss: 0.8176 - val_accuracy: 0.6667\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6331 - accuracy: 0.7259 - val_loss: 0.8222 - val_accuracy: 0.6838\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6323 - accuracy: 0.7222 - val_loss: 0.8172 - val_accuracy: 0.6752\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6334 - accuracy: 0.7222 - val_loss: 0.8173 - val_accuracy: 0.6752\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 349us/step - loss: 0.6352 - accuracy: 0.7259 - val_loss: 0.8163 - val_accuracy: 0.6752\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 439us/step - loss: 0.6424 - accuracy: 0.7148 - val_loss: 0.8164 - val_accuracy: 0.6838\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6525 - accuracy: 0.7259 - val_loss: 0.8291 - val_accuracy: 0.6752\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6226 - accuracy: 0.7407 - val_loss: 0.8230 - val_accuracy: 0.6581\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6398 - accuracy: 0.7111 - val_loss: 0.8617 - val_accuracy: 0.6752\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6451 - accuracy: 0.7222 - val_loss: 0.8413 - val_accuracy: 0.6410\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6543 - accuracy: 0.7111 - val_loss: 0.8256 - val_accuracy: 0.6667\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 333us/step - loss: 0.6384 - accuracy: 0.7296 - val_loss: 0.8243 - val_accuracy: 0.6752\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6546 - accuracy: 0.7148 - val_loss: 0.8073 - val_accuracy: 0.6752\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6391 - accuracy: 0.7370 - val_loss: 0.8261 - val_accuracy: 0.6496\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6404 - accuracy: 0.7222 - val_loss: 0.8322 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6397 - accuracy: 0.7296 - val_loss: 0.8177 - val_accuracy: 0.6752\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6500 - accuracy: 0.7259 - val_loss: 0.8857 - val_accuracy: 0.6496\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7117 - accuracy: 0.7222 - val_loss: 0.9318 - val_accuracy: 0.6496\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.7444 - accuracy: 0.7185 - val_loss: 0.8775 - val_accuracy: 0.6239\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 304us/step - loss: 0.6339 - accuracy: 0.7370 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6869 - accuracy: 0.7111 - val_loss: 0.9412 - val_accuracy: 0.6325\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7222 - accuracy: 0.7037 - val_loss: 0.8786 - val_accuracy: 0.6496\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8002 - accuracy: 0.7037 - val_loss: 0.8468 - val_accuracy: 0.6667\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8677 - accuracy: 0.7074 - val_loss: 0.8995 - val_accuracy: 0.6496\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7773 - accuracy: 0.7037 - val_loss: 0.8247 - val_accuracy: 0.6752\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6476 - accuracy: 0.7222 - val_loss: 0.8219 - val_accuracy: 0.6667\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6515 - accuracy: 0.7074 - val_loss: 0.8839 - val_accuracy: 0.6410\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7016 - accuracy: 0.7222 - val_loss: 0.8381 - val_accuracy: 0.6581\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.6887 - accuracy: 0.7000 - val_loss: 0.8601 - val_accuracy: 0.6581\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.6593 - accuracy: 0.7148 - val_loss: 0.8101 - val_accuracy: 0.7009\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6407 - accuracy: 0.7222 - val_loss: 0.8164 - val_accuracy: 0.6667\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6316 - accuracy: 0.7296 - val_loss: 0.8183 - val_accuracy: 0.6752\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6302 - accuracy: 0.7407 - val_loss: 0.8107 - val_accuracy: 0.6581\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6304 - accuracy: 0.7185 - val_loss: 0.8332 - val_accuracy: 0.6410\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6378 - accuracy: 0.7222 - val_loss: 0.8219 - val_accuracy: 0.6667\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6480 - accuracy: 0.7259 - val_loss: 0.8257 - val_accuracy: 0.6410\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.6385 - accuracy: 0.7148 - val_loss: 0.8134 - val_accuracy: 0.6752\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6337 - accuracy: 0.7296 - val_loss: 0.8048 - val_accuracy: 0.6923\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6378 - accuracy: 0.7333 - val_loss: 0.8272 - val_accuracy: 0.6496\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6320 - accuracy: 0.7370 - val_loss: 0.8102 - val_accuracy: 0.6838\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6301 - accuracy: 0.7222 - val_loss: 0.8096 - val_accuracy: 0.6752\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.6320 - accuracy: 0.7111 - val_loss: 0.8274 - val_accuracy: 0.6496\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6320 - accuracy: 0.7259 - val_loss: 0.8065 - val_accuracy: 0.6838\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6287 - accuracy: 0.7222 - val_loss: 0.8132 - val_accuracy: 0.6752\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6301 - accuracy: 0.7370 - val_loss: 0.8165 - val_accuracy: 0.6410\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6289 - accuracy: 0.7296 - val_loss: 0.8256 - val_accuracy: 0.6667\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6385 - accuracy: 0.7185 - val_loss: 0.8227 - val_accuracy: 0.6496\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.6263 - accuracy: 0.7370 - val_loss: 0.8095 - val_accuracy: 0.6752\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 350us/step - loss: 0.6361 - accuracy: 0.7185 - val_loss: 0.8135 - val_accuracy: 0.6667\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.6326 - accuracy: 0.7296 - val_loss: 0.8149 - val_accuracy: 0.6838\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6361 - accuracy: 0.7185 - val_loss: 0.8217 - val_accuracy: 0.6496\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6352 - accuracy: 0.7222 - val_loss: 0.8157 - val_accuracy: 0.6581\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6344 - accuracy: 0.7074 - val_loss: 0.8211 - val_accuracy: 0.6752\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6569 - accuracy: 0.7259 - val_loss: 0.9810 - val_accuracy: 0.6667\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8251 - accuracy: 0.7148 - val_loss: 0.8230 - val_accuracy: 0.6667\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8766 - accuracy: 0.7037 - val_loss: 0.8536 - val_accuracy: 0.6667\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9843 - accuracy: 0.6963 - val_loss: 0.9890 - val_accuracy: 0.6667\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9164 - accuracy: 0.6963 - val_loss: 1.2724 - val_accuracy: 0.6325\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.7950 - accuracy: 0.7259 - val_loss: 0.9957 - val_accuracy: 0.6496\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8229 - accuracy: 0.6889 - val_loss: 0.8889 - val_accuracy: 0.6410\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7206 - accuracy: 0.7296 - val_loss: 0.8346 - val_accuracy: 0.6410\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6816 - accuracy: 0.7111 - val_loss: 0.8520 - val_accuracy: 0.6410\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6380 - accuracy: 0.7185 - val_loss: 0.8528 - val_accuracy: 0.6410\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6647 - accuracy: 0.7222 - val_loss: 0.8992 - val_accuracy: 0.6239\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.6347 - accuracy: 0.7222 - val_loss: 0.8144 - val_accuracy: 0.6667\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6371 - accuracy: 0.7370 - val_loss: 0.8209 - val_accuracy: 0.6667\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.6279 - accuracy: 0.7370 - val_loss: 0.8137 - val_accuracy: 0.6667\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6368 - accuracy: 0.7222 - val_loss: 0.8275 - val_accuracy: 0.6410\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6280 - accuracy: 0.7296 - val_loss: 0.8107 - val_accuracy: 0.6667\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6374 - accuracy: 0.7222 - val_loss: 0.8189 - val_accuracy: 0.6752\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6213 - accuracy: 0.7407 - val_loss: 0.8094 - val_accuracy: 0.6752\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6311 - accuracy: 0.7222 - val_loss: 0.8285 - val_accuracy: 0.6752\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6312 - accuracy: 0.7370 - val_loss: 0.8195 - val_accuracy: 0.6496\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6396 - accuracy: 0.6963 - val_loss: 0.8160 - val_accuracy: 0.6838\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6305 - accuracy: 0.7333 - val_loss: 0.8224 - val_accuracy: 0.6410\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6348 - accuracy: 0.7222 - val_loss: 0.8147 - val_accuracy: 0.6752\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.6440 - accuracy: 0.7370 - val_loss: 0.8134 - val_accuracy: 0.6752\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 658us/step - loss: 0.6466 - accuracy: 0.7370 - val_loss: 0.8488 - val_accuracy: 0.6496\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 310us/step - loss: 0.6433 - accuracy: 0.7222 - val_loss: 0.8094 - val_accuracy: 0.6838\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.6271 - accuracy: 0.7259 - val_loss: 0.8209 - val_accuracy: 0.6410\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6376 - accuracy: 0.7074 - val_loss: 0.8174 - val_accuracy: 0.6752\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6325 - accuracy: 0.7407 - val_loss: 0.8146 - val_accuracy: 0.6752\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6240 - accuracy: 0.7296 - val_loss: 0.8230 - val_accuracy: 0.6752\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.6210 - accuracy: 0.7444 - val_loss: 0.8056 - val_accuracy: 0.6838\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.6277 - accuracy: 0.7370 - val_loss: 0.8071 - val_accuracy: 0.6838\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6255 - accuracy: 0.7333 - val_loss: 0.8121 - val_accuracy: 0.6838\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6230 - accuracy: 0.7444 - val_loss: 0.8116 - val_accuracy: 0.6838\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 0.6238 - accuracy: 0.7259 - val_loss: 0.8088 - val_accuracy: 0.6752\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.6195 - accuracy: 0.7444 - val_loss: 0.8051 - val_accuracy: 0.6838\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6256 - accuracy: 0.7333 - val_loss: 0.8064 - val_accuracy: 0.6752\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6270 - accuracy: 0.7370 - val_loss: 0.8092 - val_accuracy: 0.6752\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.6225 - accuracy: 0.7333 - val_loss: 0.8217 - val_accuracy: 0.6410\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6324 - accuracy: 0.7000 - val_loss: 0.8134 - val_accuracy: 0.6838\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6285 - accuracy: 0.7222 - val_loss: 0.8142 - val_accuracy: 0.6752\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6855 - accuracy: 0.7259 - val_loss: 0.8281 - val_accuracy: 0.6581\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 144us/step - loss: 0.6826 - accuracy: 0.7148 - val_loss: 0.8617 - val_accuracy: 0.6410\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6764 - accuracy: 0.7074 - val_loss: 0.8193 - val_accuracy: 0.6752\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6632 - accuracy: 0.7148 - val_loss: 0.8084 - val_accuracy: 0.7094\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6243 - accuracy: 0.7333 - val_loss: 0.8092 - val_accuracy: 0.6923\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6213 - accuracy: 0.7444 - val_loss: 0.8128 - val_accuracy: 0.6838\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6327 - accuracy: 0.7370 - val_loss: 0.8138 - val_accuracy: 0.6496\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6295 - accuracy: 0.7259 - val_loss: 0.8140 - val_accuracy: 0.6838\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6357 - accuracy: 0.7296 - val_loss: 0.8216 - val_accuracy: 0.6410\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6321 - accuracy: 0.7148 - val_loss: 0.8138 - val_accuracy: 0.6838\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.6316 - accuracy: 0.7296 - val_loss: 0.8150 - val_accuracy: 0.6667\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6500 - accuracy: 0.7037 - val_loss: 0.8392 - val_accuracy: 0.6752\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.6338 - accuracy: 0.7370 - val_loss: 0.8081 - val_accuracy: 0.6752\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6680 - accuracy: 0.7185 - val_loss: 0.8047 - val_accuracy: 0.7009\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6365 - accuracy: 0.7222 - val_loss: 0.8241 - val_accuracy: 0.6581\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6491 - accuracy: 0.7259 - val_loss: 0.8365 - val_accuracy: 0.6325\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.7143 - accuracy: 0.7074 - val_loss: 0.8267 - val_accuracy: 0.6496\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.6824 - accuracy: 0.7296 - val_loss: 0.8466 - val_accuracy: 0.6496\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.7259 - accuracy: 0.7000 - val_loss: 0.8412 - val_accuracy: 0.6496\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.6474 - accuracy: 0.7222 - val_loss: 0.8157 - val_accuracy: 0.6923\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6444 - accuracy: 0.7185 - val_loss: 0.8219 - val_accuracy: 0.6581\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6328 - accuracy: 0.7370 - val_loss: 0.8228 - val_accuracy: 0.6496\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6569 - accuracy: 0.7074 - val_loss: 0.8916 - val_accuracy: 0.6239\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6308 - accuracy: 0.7333 - val_loss: 0.8190 - val_accuracy: 0.6667\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6537 - accuracy: 0.7074 - val_loss: 0.8075 - val_accuracy: 0.6838\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6248 - accuracy: 0.7333 - val_loss: 0.8282 - val_accuracy: 0.6667\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6267 - accuracy: 0.7259 - val_loss: 0.8138 - val_accuracy: 0.6752\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.6469 - accuracy: 0.7111 - val_loss: 0.8337 - val_accuracy: 0.6410\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6456 - accuracy: 0.7185 - val_loss: 0.8378 - val_accuracy: 0.6410\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6875 - accuracy: 0.7000 - val_loss: 0.8851 - val_accuracy: 0.6325\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6625 - accuracy: 0.7148 - val_loss: 0.8123 - val_accuracy: 0.6752\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6434 - accuracy: 0.7222 - val_loss: 0.8172 - val_accuracy: 0.6752\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6223 - accuracy: 0.7370 - val_loss: 0.8083 - val_accuracy: 0.6838\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.6200 - accuracy: 0.7370 - val_loss: 0.8196 - val_accuracy: 0.6581\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 364us/step - loss: 0.6263 - accuracy: 0.7296 - val_loss: 0.8132 - val_accuracy: 0.6752\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.6261 - accuracy: 0.7185 - val_loss: 0.8115 - val_accuracy: 0.6752\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6270 - accuracy: 0.7407 - val_loss: 0.8052 - val_accuracy: 0.6838\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6166 - accuracy: 0.7481 - val_loss: 0.8102 - val_accuracy: 0.7009\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6261 - accuracy: 0.7370 - val_loss: 0.8025 - val_accuracy: 0.6923\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6188 - accuracy: 0.7519 - val_loss: 0.8137 - val_accuracy: 0.6752\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6258 - accuracy: 0.7370 - val_loss: 0.8239 - val_accuracy: 0.6496\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.6289 - accuracy: 0.7148 - val_loss: 0.8071 - val_accuracy: 0.6838\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 336us/step - loss: 0.6395 - accuracy: 0.7407 - val_loss: 0.8425 - val_accuracy: 0.6581\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 333us/step - loss: 0.6988 - accuracy: 0.7111 - val_loss: 0.8223 - val_accuracy: 0.6838\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.7204 - accuracy: 0.7333 - val_loss: 0.8303 - val_accuracy: 0.6667\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.7984 - accuracy: 0.7148 - val_loss: 0.8703 - val_accuracy: 0.6581\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.6636 - accuracy: 0.7185 - val_loss: 0.8911 - val_accuracy: 0.6325\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6512 - accuracy: 0.7222 - val_loss: 0.8442 - val_accuracy: 0.6410\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6618 - accuracy: 0.7111 - val_loss: 0.8503 - val_accuracy: 0.6752\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6258 - accuracy: 0.7222 - val_loss: 0.8161 - val_accuracy: 0.6581\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6288 - accuracy: 0.7222 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.6261 - accuracy: 0.7370 - val_loss: 0.8126 - val_accuracy: 0.6838\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6297 - accuracy: 0.7259 - val_loss: 0.8486 - val_accuracy: 0.6667\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6429 - accuracy: 0.7185 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6703 - accuracy: 0.7259 - val_loss: 0.8114 - val_accuracy: 0.6838\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6279 - accuracy: 0.7370 - val_loss: 0.8041 - val_accuracy: 0.6752\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 504us/step - loss: 0.6161 - accuracy: 0.7407 - val_loss: 0.8205 - val_accuracy: 0.6667\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 421us/step - loss: 0.6399 - accuracy: 0.7148 - val_loss: 0.8322 - val_accuracy: 0.6496\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6336 - accuracy: 0.7185 - val_loss: 0.8238 - val_accuracy: 0.6581\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6823 - accuracy: 0.7185 - val_loss: 0.8457 - val_accuracy: 0.6239\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6689 - accuracy: 0.7074 - val_loss: 0.8582 - val_accuracy: 0.6410\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6647 - accuracy: 0.7074 - val_loss: 0.8299 - val_accuracy: 0.6667\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6787 - accuracy: 0.7185 - val_loss: 0.9878 - val_accuracy: 0.6154\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8086 - accuracy: 0.7074 - val_loss: 0.8438 - val_accuracy: 0.6581\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 453us/step - loss: 0.6838 - accuracy: 0.7148 - val_loss: 0.8398 - val_accuracy: 0.6410\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.7025 - accuracy: 0.7111 - val_loss: 0.8639 - val_accuracy: 0.6496\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 394us/step - loss: 0.6306 - accuracy: 0.7259 - val_loss: 0.8156 - val_accuracy: 0.6923\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6222 - accuracy: 0.7296 - val_loss: 0.8121 - val_accuracy: 0.6838\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6256 - accuracy: 0.7407 - val_loss: 0.8194 - val_accuracy: 0.6496\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.6555 - accuracy: 0.7222 - val_loss: 0.8348 - val_accuracy: 0.6410\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 313us/step - loss: 0.6467 - accuracy: 0.7185 - val_loss: 0.8340 - val_accuracy: 0.6752\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.6441 - accuracy: 0.7370 - val_loss: 0.8065 - val_accuracy: 0.6752\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6139 - accuracy: 0.7407 - val_loss: 0.8580 - val_accuracy: 0.6325\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.6354 - accuracy: 0.7222 - val_loss: 0.8149 - val_accuracy: 0.6752\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.6214 - accuracy: 0.7370 - val_loss: 0.8149 - val_accuracy: 0.6752\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6169 - accuracy: 0.7407 - val_loss: 0.8043 - val_accuracy: 0.6838\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.6166 - accuracy: 0.7407 - val_loss: 0.8139 - val_accuracy: 0.6838\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6180 - accuracy: 0.7407 - val_loss: 0.8089 - val_accuracy: 0.6838\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6192 - accuracy: 0.7370 - val_loss: 0.8170 - val_accuracy: 0.6838\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6336 - accuracy: 0.7333 - val_loss: 0.8088 - val_accuracy: 0.6752\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6231 - accuracy: 0.7185 - val_loss: 0.8130 - val_accuracy: 0.6838\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.6160 - accuracy: 0.7481 - val_loss: 0.8048 - val_accuracy: 0.6838\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6155 - accuracy: 0.7444 - val_loss: 0.8080 - val_accuracy: 0.6752\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6137 - accuracy: 0.7519 - val_loss: 0.8071 - val_accuracy: 0.6838\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6220 - accuracy: 0.7370 - val_loss: 0.8248 - val_accuracy: 0.6496\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.6476 - accuracy: 0.7000 - val_loss: 0.8575 - val_accuracy: 0.6667\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6374 - accuracy: 0.7333 - val_loss: 0.8081 - val_accuracy: 0.6838\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.6268 - accuracy: 0.7296 - val_loss: 0.8188 - val_accuracy: 0.6923\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.6350 - accuracy: 0.7148 - val_loss: 0.8165 - val_accuracy: 0.6667\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6184 - accuracy: 0.7333 - val_loss: 0.8111 - val_accuracy: 0.6838\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6162 - accuracy: 0.7519 - val_loss: 0.8094 - val_accuracy: 0.6752\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6223 - accuracy: 0.7296 - val_loss: 0.8368 - val_accuracy: 0.6752\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6258 - accuracy: 0.7259 - val_loss: 0.8063 - val_accuracy: 0.6752\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6186 - accuracy: 0.7481 - val_loss: 0.8068 - val_accuracy: 0.6752\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6122 - accuracy: 0.7481 - val_loss: 0.8112 - val_accuracy: 0.6752\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6273 - accuracy: 0.7333 - val_loss: 0.8079 - val_accuracy: 0.6838\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6269 - accuracy: 0.7185 - val_loss: 0.8349 - val_accuracy: 0.6410\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6263 - accuracy: 0.7407 - val_loss: 0.8048 - val_accuracy: 0.6752\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 303us/step - loss: 0.6308 - accuracy: 0.7074 - val_loss: 0.8082 - val_accuracy: 0.6838\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.6265 - accuracy: 0.7259 - val_loss: 0.8614 - val_accuracy: 0.6410\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6372 - accuracy: 0.7185 - val_loss: 0.8020 - val_accuracy: 0.6838\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6280 - accuracy: 0.7444 - val_loss: 0.8136 - val_accuracy: 0.6752\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6209 - accuracy: 0.7444 - val_loss: 0.8147 - val_accuracy: 0.6923\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6201 - accuracy: 0.7333 - val_loss: 0.8172 - val_accuracy: 0.6667\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6198 - accuracy: 0.7481 - val_loss: 0.8174 - val_accuracy: 0.6667\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6186 - accuracy: 0.7407 - val_loss: 0.8096 - val_accuracy: 0.6838\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6264 - accuracy: 0.7333 - val_loss: 0.8373 - val_accuracy: 0.6667\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6409 - accuracy: 0.7259 - val_loss: 0.8058 - val_accuracy: 0.6838\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6163 - accuracy: 0.7407 - val_loss: 0.8240 - val_accuracy: 0.6667\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.6181 - accuracy: 0.7370 - val_loss: 0.8196 - val_accuracy: 0.6581\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6270 - accuracy: 0.7185 - val_loss: 0.8430 - val_accuracy: 0.6752\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 204us/step - loss: 0.6205 - accuracy: 0.7444 - val_loss: 0.8292 - val_accuracy: 0.6667\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6386 - accuracy: 0.7148 - val_loss: 0.8350 - val_accuracy: 0.6838\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6310 - accuracy: 0.7296 - val_loss: 0.8089 - val_accuracy: 0.6923\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.6309 - accuracy: 0.7259 - val_loss: 0.8108 - val_accuracy: 0.6838\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.6368 - accuracy: 0.7185 - val_loss: 0.8083 - val_accuracy: 0.6667\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6209 - accuracy: 0.7444 - val_loss: 0.8072 - val_accuracy: 0.6838\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6148 - accuracy: 0.7444 - val_loss: 0.8073 - val_accuracy: 0.6752\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6128 - accuracy: 0.7444 - val_loss: 0.8285 - val_accuracy: 0.6667\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.6386 - accuracy: 0.7222 - val_loss: 0.8189 - val_accuracy: 0.6752\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.6198 - accuracy: 0.7444 - val_loss: 0.8365 - val_accuracy: 0.6752\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.6404 - accuracy: 0.7407 - val_loss: 0.8329 - val_accuracy: 0.6667\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.6306 - accuracy: 0.7370 - val_loss: 0.8273 - val_accuracy: 0.6581\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6847 - accuracy: 0.7185 - val_loss: 0.8509 - val_accuracy: 0.6667\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6292 - accuracy: 0.7444 - val_loss: 0.8064 - val_accuracy: 0.6752\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6153 - accuracy: 0.7407 - val_loss: 0.8098 - val_accuracy: 0.6752\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 348us/step - loss: 0.6148 - accuracy: 0.7407 - val_loss: 0.8044 - val_accuracy: 0.6752\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6105 - accuracy: 0.7481 - val_loss: 0.8249 - val_accuracy: 0.6667\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.6147 - accuracy: 0.7407 - val_loss: 0.8071 - val_accuracy: 0.6752\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6143 - accuracy: 0.7296 - val_loss: 0.8440 - val_accuracy: 0.6325\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.6254 - accuracy: 0.7185 - val_loss: 0.8184 - val_accuracy: 0.6581\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6584 - accuracy: 0.7185 - val_loss: 0.8345 - val_accuracy: 0.6410\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.6867 - accuracy: 0.7333 - val_loss: 0.8168 - val_accuracy: 0.6496\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.6590 - accuracy: 0.7222 - val_loss: 0.8063 - val_accuracy: 0.6838\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6235 - accuracy: 0.7296 - val_loss: 0.8435 - val_accuracy: 0.6667\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6153 - accuracy: 0.7407 - val_loss: 0.8060 - val_accuracy: 0.6752\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6178 - accuracy: 0.7333 - val_loss: 0.8176 - val_accuracy: 0.6752\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6114 - accuracy: 0.7407 - val_loss: 0.8331 - val_accuracy: 0.6496\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6434 - accuracy: 0.7185 - val_loss: 0.8064 - val_accuracy: 0.6838\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6204 - accuracy: 0.7333 - val_loss: 0.8121 - val_accuracy: 0.6752\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.6208 - accuracy: 0.7333 - val_loss: 0.8205 - val_accuracy: 0.6838\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6222 - accuracy: 0.7296 - val_loss: 0.8271 - val_accuracy: 0.6667\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6672 - accuracy: 0.7259 - val_loss: 0.8125 - val_accuracy: 0.6496\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6388 - accuracy: 0.7259 - val_loss: 0.8116 - val_accuracy: 0.6667\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6314 - accuracy: 0.7222 - val_loss: 0.8306 - val_accuracy: 0.6410\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6243 - accuracy: 0.7222 - val_loss: 0.8122 - val_accuracy: 0.6752\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6323 - accuracy: 0.7370 - val_loss: 0.8214 - val_accuracy: 0.6667\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6380 - accuracy: 0.7222 - val_loss: 0.8171 - val_accuracy: 0.6838\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 395us/step - loss: 0.6166 - accuracy: 0.7444 - val_loss: 0.8043 - val_accuracy: 0.7009\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6183 - accuracy: 0.7370 - val_loss: 0.8121 - val_accuracy: 0.6752\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6266 - accuracy: 0.7333 - val_loss: 0.8176 - val_accuracy: 0.6752\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6237 - accuracy: 0.7296 - val_loss: 0.8244 - val_accuracy: 0.6496\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6520 - accuracy: 0.7148 - val_loss: 0.8582 - val_accuracy: 0.6496\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.75 - 0s 123us/step - loss: 0.6417 - accuracy: 0.7370 - val_loss: 0.8538 - val_accuracy: 0.6325\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 385us/step - loss: 0.6467 - accuracy: 0.7185 - val_loss: 0.8231 - val_accuracy: 0.6838\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.6884 - accuracy: 0.7185 - val_loss: 0.8976 - val_accuracy: 0.6325\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6641 - accuracy: 0.7111 - val_loss: 0.8133 - val_accuracy: 0.6667\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.6345 - accuracy: 0.7333 - val_loss: 0.8701 - val_accuracy: 0.6496\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6578 - accuracy: 0.7148 - val_loss: 0.8177 - val_accuracy: 0.6838\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6359 - accuracy: 0.7407 - val_loss: 0.8260 - val_accuracy: 0.6410\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6306 - accuracy: 0.7185 - val_loss: 0.8075 - val_accuracy: 0.6838\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6231 - accuracy: 0.7370 - val_loss: 0.8212 - val_accuracy: 0.6496\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6244 - accuracy: 0.7148 - val_loss: 0.8074 - val_accuracy: 0.6923\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6219 - accuracy: 0.7370 - val_loss: 0.8377 - val_accuracy: 0.6325\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6293 - accuracy: 0.7259 - val_loss: 0.8039 - val_accuracy: 0.6923\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7099 - accuracy: 0.7000 - val_loss: 0.9117 - val_accuracy: 0.6325\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6466 - accuracy: 0.7296 - val_loss: 0.8811 - val_accuracy: 0.6581\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6760 - accuracy: 0.7185 - val_loss: 0.8742 - val_accuracy: 0.6496\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6471 - accuracy: 0.7259 - val_loss: 0.8179 - val_accuracy: 0.6838\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6294 - accuracy: 0.7296 - val_loss: 0.8226 - val_accuracy: 0.6581\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6314 - accuracy: 0.7259 - val_loss: 0.8078 - val_accuracy: 0.6667\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6224 - accuracy: 0.7333 - val_loss: 0.8088 - val_accuracy: 0.6752\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6269 - accuracy: 0.7259 - val_loss: 0.8087 - val_accuracy: 0.6667\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.6225 - accuracy: 0.7296 - val_loss: 0.8526 - val_accuracy: 0.6325\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6169 - accuracy: 0.7370 - val_loss: 0.8066 - val_accuracy: 0.6752\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6239 - accuracy: 0.7333 - val_loss: 0.8245 - val_accuracy: 0.6838\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6213 - accuracy: 0.7296 - val_loss: 0.8086 - val_accuracy: 0.6752\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 265us/step - loss: 0.6269 - accuracy: 0.7370 - val_loss: 0.8141 - val_accuracy: 0.6752\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6472 - accuracy: 0.7370 - val_loss: 0.8437 - val_accuracy: 0.6752\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6407 - accuracy: 0.7222 - val_loss: 0.8030 - val_accuracy: 0.6752\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6393 - accuracy: 0.7259 - val_loss: 0.8182 - val_accuracy: 0.6667\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6470 - accuracy: 0.7333 - val_loss: 0.8051 - val_accuracy: 0.6838\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6386 - accuracy: 0.7259 - val_loss: 0.8092 - val_accuracy: 0.6752\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6080 - accuracy: 0.7444 - val_loss: 0.8218 - val_accuracy: 0.6496\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6120 - accuracy: 0.7333 - val_loss: 0.8126 - val_accuracy: 0.6752\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 299us/step - loss: 0.6154 - accuracy: 0.7370 - val_loss: 0.8038 - val_accuracy: 0.6923\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6130 - accuracy: 0.7444 - val_loss: 0.8230 - val_accuracy: 0.6410\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6433 - accuracy: 0.7296 - val_loss: 0.8045 - val_accuracy: 0.6752\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6150 - accuracy: 0.7370 - val_loss: 0.8311 - val_accuracy: 0.6496\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6213 - accuracy: 0.7222 - val_loss: 0.8092 - val_accuracy: 0.6752\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6336 - accuracy: 0.7185 - val_loss: 0.8505 - val_accuracy: 0.6325\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6327 - accuracy: 0.7148 - val_loss: 0.8239 - val_accuracy: 0.6752\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6148 - accuracy: 0.7481 - val_loss: 0.8166 - val_accuracy: 0.6496\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.6138 - accuracy: 0.7185 - val_loss: 0.8259 - val_accuracy: 0.6752\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6110 - accuracy: 0.7333 - val_loss: 0.8136 - val_accuracy: 0.6752\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6080 - accuracy: 0.7407 - val_loss: 0.8117 - val_accuracy: 0.6752\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6047 - accuracy: 0.7519 - val_loss: 0.8250 - val_accuracy: 0.6496\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6206 - accuracy: 0.7370 - val_loss: 0.8156 - val_accuracy: 0.6581\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6332 - accuracy: 0.7407 - val_loss: 0.8338 - val_accuracy: 0.6667\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6165 - accuracy: 0.7333 - val_loss: 0.8109 - val_accuracy: 0.6752\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6082 - accuracy: 0.7444 - val_loss: 0.8100 - val_accuracy: 0.6752\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.6096 - accuracy: 0.7407 - val_loss: 0.8091 - val_accuracy: 0.6838\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6129 - accuracy: 0.7407 - val_loss: 0.8111 - val_accuracy: 0.6752\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6158 - accuracy: 0.7407 - val_loss: 0.8239 - val_accuracy: 0.6667\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6241 - accuracy: 0.7370 - val_loss: 0.8354 - val_accuracy: 0.6325\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6138 - accuracy: 0.7296 - val_loss: 0.8130 - val_accuracy: 0.6752\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6302 - accuracy: 0.7370 - val_loss: 0.8178 - val_accuracy: 0.6667\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6326 - accuracy: 0.7259 - val_loss: 0.8891 - val_accuracy: 0.6581\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6495 - accuracy: 0.7333 - val_loss: 0.8179 - val_accuracy: 0.6667\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6152 - accuracy: 0.7370 - val_loss: 0.8750 - val_accuracy: 0.6325\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6290 - accuracy: 0.7259 - val_loss: 0.8112 - val_accuracy: 0.6752\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6151 - accuracy: 0.7407 - val_loss: 0.8086 - val_accuracy: 0.6752\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6079 - accuracy: 0.7444 - val_loss: 0.8065 - val_accuracy: 0.6667\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6088 - accuracy: 0.7481 - val_loss: 0.8137 - val_accuracy: 0.6838\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 468us/step - loss: 0.6204 - accuracy: 0.7148 - val_loss: 0.8220 - val_accuracy: 0.6667\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 329us/step - loss: 0.6099 - accuracy: 0.7481 - val_loss: 0.8085 - val_accuracy: 0.6752\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6122 - accuracy: 0.7407 - val_loss: 0.8199 - val_accuracy: 0.6923\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6859 - accuracy: 0.7222 - val_loss: 0.8150 - val_accuracy: 0.6581\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6859 - accuracy: 0.7370 - val_loss: 0.8526 - val_accuracy: 0.6496\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7445 - accuracy: 0.7259 - val_loss: 0.8274 - val_accuracy: 0.6752\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6399 - accuracy: 0.7444 - val_loss: 0.8127 - val_accuracy: 0.6752\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 159us/step - loss: 0.6572 - accuracy: 0.7370 - val_loss: 0.8582 - val_accuracy: 0.6581\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.6164 - accuracy: 0.7333 - val_loss: 0.8079 - val_accuracy: 0.6667\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6076 - accuracy: 0.7333 - val_loss: 0.8350 - val_accuracy: 0.6410\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6206 - accuracy: 0.7259 - val_loss: 0.8066 - val_accuracy: 0.6752\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6047 - accuracy: 0.7519 - val_loss: 0.8070 - val_accuracy: 0.6923\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6025 - accuracy: 0.7519 - val_loss: 0.8044 - val_accuracy: 0.6838\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6234 - accuracy: 0.7370 - val_loss: 0.8462 - val_accuracy: 0.6581\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6717 - accuracy: 0.7222 - val_loss: 0.9285 - val_accuracy: 0.6496\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6938 - accuracy: 0.7296 - val_loss: 0.8461 - val_accuracy: 0.6581\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.7327 - accuracy: 0.7148 - val_loss: 0.9412 - val_accuracy: 0.6581\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8767 - accuracy: 0.7259 - val_loss: 0.8275 - val_accuracy: 0.6838\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.6576 - accuracy: 0.7259 - val_loss: 0.8141 - val_accuracy: 0.6667\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.6305 - accuracy: 0.7444 - val_loss: 0.8090 - val_accuracy: 0.6838\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6104 - accuracy: 0.7481 - val_loss: 0.8107 - val_accuracy: 0.6667\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6218 - accuracy: 0.7407 - val_loss: 0.8370 - val_accuracy: 0.6410\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6160 - accuracy: 0.7259 - val_loss: 0.8039 - val_accuracy: 0.6752\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6275 - accuracy: 0.7370 - val_loss: 0.8080 - val_accuracy: 0.6667\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6206 - accuracy: 0.7259 - val_loss: 0.8091 - val_accuracy: 0.6838\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6064 - accuracy: 0.7407 - val_loss: 0.8049 - val_accuracy: 0.6752\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6114 - accuracy: 0.7370 - val_loss: 0.8319 - val_accuracy: 0.6496\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6307 - accuracy: 0.7185 - val_loss: 0.8008 - val_accuracy: 0.6838\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6271 - accuracy: 0.7407 - val_loss: 0.8026 - val_accuracy: 0.6838\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6217 - accuracy: 0.7370 - val_loss: 0.8429 - val_accuracy: 0.6496\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.6186 - accuracy: 0.7222 - val_loss: 0.8147 - val_accuracy: 0.6752\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6080 - accuracy: 0.7407 - val_loss: 0.8302 - val_accuracy: 0.6667\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.6177 - accuracy: 0.7407 - val_loss: 0.8276 - val_accuracy: 0.6325\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6470 - accuracy: 0.7296 - val_loss: 0.8067 - val_accuracy: 0.6752\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6249 - accuracy: 0.7222 - val_loss: 0.8248 - val_accuracy: 0.6752\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6252 - accuracy: 0.7222 - val_loss: 0.8106 - val_accuracy: 0.6667\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.6162 - accuracy: 0.7370 - val_loss: 0.8614 - val_accuracy: 0.6410\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.6454 - accuracy: 0.7037 - val_loss: 0.8243 - val_accuracy: 0.6752\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6158 - accuracy: 0.7370 - val_loss: 0.8042 - val_accuracy: 0.6752\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6220 - accuracy: 0.7333 - val_loss: 0.8403 - val_accuracy: 0.6667\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6059 - accuracy: 0.7444 - val_loss: 0.8223 - val_accuracy: 0.6667\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6465 - accuracy: 0.7370 - val_loss: 0.8605 - val_accuracy: 0.6667\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6436 - accuracy: 0.7148 - val_loss: 0.8263 - val_accuracy: 0.6581\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6103 - accuracy: 0.7370 - val_loss: 0.8232 - val_accuracy: 0.6667\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6314 - accuracy: 0.7333 - val_loss: 0.9108 - val_accuracy: 0.6325\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.6393 - accuracy: 0.7296 - val_loss: 0.8315 - val_accuracy: 0.6752\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.6162 - accuracy: 0.7407 - val_loss: 0.8488 - val_accuracy: 0.6496\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6417 - accuracy: 0.7296 - val_loss: 0.8134 - val_accuracy: 0.6752\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6362 - accuracy: 0.7259 - val_loss: 0.8877 - val_accuracy: 0.6496\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6498 - accuracy: 0.7185 - val_loss: 0.8126 - val_accuracy: 0.6752\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6166 - accuracy: 0.7370 - val_loss: 0.8121 - val_accuracy: 0.6581\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6198 - accuracy: 0.7259 - val_loss: 0.8069 - val_accuracy: 0.6667\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6199 - accuracy: 0.7370 - val_loss: 0.8245 - val_accuracy: 0.6581\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6596 - accuracy: 0.7037 - val_loss: 0.9731 - val_accuracy: 0.6410\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8164 - accuracy: 0.7222 - val_loss: 0.8191 - val_accuracy: 0.6752\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.6817 - accuracy: 0.7185 - val_loss: 0.8295 - val_accuracy: 0.6410\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.6838 - accuracy: 0.7259 - val_loss: 0.8539 - val_accuracy: 0.6496\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 484us/step - loss: 0.6576 - accuracy: 0.7444 - val_loss: 0.9082 - val_accuracy: 0.6496\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7707 - accuracy: 0.7185 - val_loss: 0.8529 - val_accuracy: 0.6496\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6264 - accuracy: 0.7481 - val_loss: 0.8140 - val_accuracy: 0.6838\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6143 - accuracy: 0.7333 - val_loss: 0.8093 - val_accuracy: 0.6838\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6300 - accuracy: 0.7222 - val_loss: 0.8983 - val_accuracy: 0.6410\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.7096 - accuracy: 0.7185 - val_loss: 0.8449 - val_accuracy: 0.6496\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6578 - accuracy: 0.7111 - val_loss: 0.8892 - val_accuracy: 0.6410\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6628 - accuracy: 0.7111 - val_loss: 0.8146 - val_accuracy: 0.6752\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.6180 - accuracy: 0.7333 - val_loss: 0.8423 - val_accuracy: 0.6667\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6181 - accuracy: 0.7407 - val_loss: 0.8118 - val_accuracy: 0.6752\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6077 - accuracy: 0.7481 - val_loss: 0.8251 - val_accuracy: 0.6667\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6133 - accuracy: 0.7333 - val_loss: 0.8130 - val_accuracy: 0.6752\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6193 - accuracy: 0.7222 - val_loss: 0.8192 - val_accuracy: 0.6667\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.5996 - accuracy: 0.7444 - val_loss: 0.8096 - val_accuracy: 0.6838\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 263us/step - loss: 0.6082 - accuracy: 0.7481 - val_loss: 0.8195 - val_accuracy: 0.6667\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6081 - accuracy: 0.7296 - val_loss: 0.8095 - val_accuracy: 0.6752\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6096 - accuracy: 0.7370 - val_loss: 0.8118 - val_accuracy: 0.6667\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.6087 - accuracy: 0.7370 - val_loss: 0.8152 - val_accuracy: 0.6667\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6115 - accuracy: 0.7407 - val_loss: 0.8098 - val_accuracy: 0.6752\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6481 - accuracy: 0.7037 - val_loss: 0.9400 - val_accuracy: 0.6239\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6804 - accuracy: 0.7111 - val_loss: 0.8220 - val_accuracy: 0.6752\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.6400 - accuracy: 0.7259 - val_loss: 0.9200 - val_accuracy: 0.6239\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.8314 - accuracy: 0.7185 - val_loss: 1.0601 - val_accuracy: 0.6410\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 256us/step - loss: 0.7742 - accuracy: 0.7259 - val_loss: 0.9510 - val_accuracy: 0.6154\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6912 - accuracy: 0.7222 - val_loss: 0.8426 - val_accuracy: 0.6838\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.6613 - accuracy: 0.7407 - val_loss: 0.8111 - val_accuracy: 0.6838\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6268 - accuracy: 0.7222 - val_loss: 0.8083 - val_accuracy: 0.6752\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6706 - accuracy: 0.7407 - val_loss: 0.8568 - val_accuracy: 0.6667\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6680 - accuracy: 0.7370 - val_loss: 0.8596 - val_accuracy: 0.6496\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6729 - accuracy: 0.7370 - val_loss: 0.8568 - val_accuracy: 0.6667\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6100 - accuracy: 0.7370 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6124 - accuracy: 0.7370 - val_loss: 0.9053 - val_accuracy: 0.6581\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.6292 - accuracy: 0.7185 - val_loss: 0.8918 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6881 - accuracy: 0.7074 - val_loss: 0.8551 - val_accuracy: 0.6410\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6497 - accuracy: 0.7222 - val_loss: 1.0506 - val_accuracy: 0.5897\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7410 - accuracy: 0.7074 - val_loss: 0.8355 - val_accuracy: 0.6496\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6270 - accuracy: 0.7370 - val_loss: 0.8471 - val_accuracy: 0.6325\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.6667 - accuracy: 0.7111 - val_loss: 0.9508 - val_accuracy: 0.6239\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6579 - accuracy: 0.7259 - val_loss: 0.8388 - val_accuracy: 0.6667\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.6389 - accuracy: 0.7333 - val_loss: 0.8439 - val_accuracy: 0.6667\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6079 - accuracy: 0.7444 - val_loss: 0.8202 - val_accuracy: 0.6752\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6050 - accuracy: 0.7296 - val_loss: 0.8325 - val_accuracy: 0.6667\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6086 - accuracy: 0.7519 - val_loss: 0.8096 - val_accuracy: 0.6752\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6157 - accuracy: 0.7481 - val_loss: 0.8157 - val_accuracy: 0.6838\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.6094 - accuracy: 0.7444 - val_loss: 0.8057 - val_accuracy: 0.6667\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6041 - accuracy: 0.7519 - val_loss: 0.8094 - val_accuracy: 0.6838\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6032 - accuracy: 0.7444 - val_loss: 0.8157 - val_accuracy: 0.6752\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6108 - accuracy: 0.7444 - val_loss: 0.8170 - val_accuracy: 0.6838\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6072 - accuracy: 0.7481 - val_loss: 0.8111 - val_accuracy: 0.6752\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6069 - accuracy: 0.7407 - val_loss: 0.8159 - val_accuracy: 0.6667\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6191 - accuracy: 0.7370 - val_loss: 0.8183 - val_accuracy: 0.6752\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6531 - accuracy: 0.7259 - val_loss: 0.8164 - val_accuracy: 0.6838\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6172 - accuracy: 0.7407 - val_loss: 0.8045 - val_accuracy: 0.6838\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6064 - accuracy: 0.7481 - val_loss: 0.8180 - val_accuracy: 0.6752\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6073 - accuracy: 0.7481 - val_loss: 0.8158 - val_accuracy: 0.6667\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6120 - accuracy: 0.7296 - val_loss: 0.8695 - val_accuracy: 0.6410\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6345 - accuracy: 0.7185 - val_loss: 0.8444 - val_accuracy: 0.6667\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6591 - accuracy: 0.7222 - val_loss: 0.8383 - val_accuracy: 0.6752\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 306us/step - loss: 0.6062 - accuracy: 0.7519 - val_loss: 0.8194 - val_accuracy: 0.6752\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6388 - accuracy: 0.7296 - val_loss: 0.8083 - val_accuracy: 0.6752\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 64us/step - loss: 0.6082 - accuracy: 0.7407 - val_loss: 0.8079 - val_accuracy: 0.6838\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 393us/step - loss: 0.6012 - accuracy: 0.7444 - val_loss: 0.8103 - val_accuracy: 0.6752\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.6042 - accuracy: 0.7444 - val_loss: 0.8120 - val_accuracy: 0.6752\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.6105 - accuracy: 0.7370 - val_loss: 0.8177 - val_accuracy: 0.6752\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 321us/step - loss: 0.6177 - accuracy: 0.7444 - val_loss: 0.8102 - val_accuracy: 0.6752\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 337us/step - loss: 0.6086 - accuracy: 0.7407 - val_loss: 0.8083 - val_accuracy: 0.6752\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6019 - accuracy: 0.7407 - val_loss: 0.8142 - val_accuracy: 0.6838\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6057 - accuracy: 0.7370 - val_loss: 0.8130 - val_accuracy: 0.6752\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5985 - accuracy: 0.7481 - val_loss: 0.8089 - val_accuracy: 0.6752\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 475us/step - loss: 0.6201 - accuracy: 0.7296 - val_loss: 0.8203 - val_accuracy: 0.6752\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.6053 - accuracy: 0.7370 - val_loss: 0.8165 - val_accuracy: 0.6752\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6107 - accuracy: 0.7407 - val_loss: 0.8129 - val_accuracy: 0.6752\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6286 - accuracy: 0.7370 - val_loss: 0.8567 - val_accuracy: 0.6667\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6812 - accuracy: 0.7259 - val_loss: 0.8414 - val_accuracy: 0.6581\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6688 - accuracy: 0.7296 - val_loss: 0.8908 - val_accuracy: 0.6496\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6282 - accuracy: 0.7481 - val_loss: 0.8221 - val_accuracy: 0.6667\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6267 - accuracy: 0.7222 - val_loss: 0.8359 - val_accuracy: 0.6667\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6219 - accuracy: 0.7185 - val_loss: 0.8761 - val_accuracy: 0.6496\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6810 - accuracy: 0.7222 - val_loss: 0.8850 - val_accuracy: 0.6325\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6245 - accuracy: 0.7407 - val_loss: 0.8280 - val_accuracy: 0.6581\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6107 - accuracy: 0.7296 - val_loss: 0.8253 - val_accuracy: 0.6667\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6209 - accuracy: 0.7296 - val_loss: 0.8111 - val_accuracy: 0.6752\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6114 - accuracy: 0.7370 - val_loss: 0.8179 - val_accuracy: 0.6752\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6096 - accuracy: 0.7296 - val_loss: 0.8091 - val_accuracy: 0.6838\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6070 - accuracy: 0.7407 - val_loss: 0.8196 - val_accuracy: 0.6667\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6082 - accuracy: 0.7444 - val_loss: 0.8275 - val_accuracy: 0.6581\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6246 - accuracy: 0.7185 - val_loss: 0.8412 - val_accuracy: 0.6667\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6124 - accuracy: 0.7333 - val_loss: 0.8068 - val_accuracy: 0.6752\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6228 - accuracy: 0.7407 - val_loss: 0.8085 - val_accuracy: 0.6838\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6239 - accuracy: 0.7333 - val_loss: 0.8259 - val_accuracy: 0.6667\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6109 - accuracy: 0.7259 - val_loss: 0.8148 - val_accuracy: 0.6752\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6123 - accuracy: 0.7444 - val_loss: 0.8145 - val_accuracy: 0.6752\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6312 - accuracy: 0.7185 - val_loss: 0.8489 - val_accuracy: 0.6496\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6279 - accuracy: 0.7222 - val_loss: 0.8163 - val_accuracy: 0.6752\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6183 - accuracy: 0.7333 - val_loss: 0.8263 - val_accuracy: 0.6667\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6176 - accuracy: 0.7296 - val_loss: 0.8414 - val_accuracy: 0.6667\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6355 - accuracy: 0.7333 - val_loss: 0.8261 - val_accuracy: 0.6496\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6379 - accuracy: 0.7259 - val_loss: 0.8236 - val_accuracy: 0.6752\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6040 - accuracy: 0.7370 - val_loss: 0.8073 - val_accuracy: 0.6752\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.5960 - accuracy: 0.7444 - val_loss: 0.8360 - val_accuracy: 0.6667\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.6123 - accuracy: 0.7370 - val_loss: 0.8084 - val_accuracy: 0.6752\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5952 - accuracy: 0.7444 - val_loss: 0.8119 - val_accuracy: 0.6838\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5946 - accuracy: 0.7519 - val_loss: 0.8079 - val_accuracy: 0.6752\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.5987 - accuracy: 0.7370 - val_loss: 0.8152 - val_accuracy: 0.6752\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6027 - accuracy: 0.7407 - val_loss: 0.8200 - val_accuracy: 0.6752\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.6146 - accuracy: 0.7370 - val_loss: 0.8313 - val_accuracy: 0.6752\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6168 - accuracy: 0.7259 - val_loss: 0.8225 - val_accuracy: 0.6838\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6022 - accuracy: 0.7481 - val_loss: 0.8101 - val_accuracy: 0.6838\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.5961 - accuracy: 0.7519 - val_loss: 0.8110 - val_accuracy: 0.6752\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5957 - accuracy: 0.7407 - val_loss: 0.8099 - val_accuracy: 0.6752\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5934 - accuracy: 0.7444 - val_loss: 0.8101 - val_accuracy: 0.6838\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5952 - accuracy: 0.7519 - val_loss: 0.8116 - val_accuracy: 0.6752\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5984 - accuracy: 0.7444 - val_loss: 0.8104 - val_accuracy: 0.6667\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6025 - accuracy: 0.7370 - val_loss: 0.8218 - val_accuracy: 0.6667\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6010 - accuracy: 0.7407 - val_loss: 0.8081 - val_accuracy: 0.6838\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6021 - accuracy: 0.7407 - val_loss: 0.8090 - val_accuracy: 0.6752\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6146 - accuracy: 0.7407 - val_loss: 0.8152 - val_accuracy: 0.6923\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6019 - accuracy: 0.7481 - val_loss: 0.8177 - val_accuracy: 0.6752\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6018 - accuracy: 0.7519 - val_loss: 0.8113 - val_accuracy: 0.6752\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6030 - accuracy: 0.7444 - val_loss: 0.8253 - val_accuracy: 0.6752\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6331 - accuracy: 0.7185 - val_loss: 0.8209 - val_accuracy: 0.6752\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6286 - accuracy: 0.7296 - val_loss: 0.8423 - val_accuracy: 0.6410\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6264 - accuracy: 0.7296 - val_loss: 0.8151 - val_accuracy: 0.6838\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6160 - accuracy: 0.7370 - val_loss: 0.8213 - val_accuracy: 0.6752\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5988 - accuracy: 0.7444 - val_loss: 0.8172 - val_accuracy: 0.6752\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6010 - accuracy: 0.7481 - val_loss: 0.8161 - val_accuracy: 0.6667\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6066 - accuracy: 0.7333 - val_loss: 0.8411 - val_accuracy: 0.6667\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6079 - accuracy: 0.7370 - val_loss: 0.8109 - val_accuracy: 0.6752\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6093 - accuracy: 0.7370 - val_loss: 0.8268 - val_accuracy: 0.6581\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6246 - accuracy: 0.7333 - val_loss: 0.8184 - val_accuracy: 0.6838\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6169 - accuracy: 0.7296 - val_loss: 0.8136 - val_accuracy: 0.6838\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6070 - accuracy: 0.7407 - val_loss: 0.8789 - val_accuracy: 0.6496\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6564 - accuracy: 0.7148 - val_loss: 0.8205 - val_accuracy: 0.6752\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6126 - accuracy: 0.7444 - val_loss: 0.8135 - val_accuracy: 0.6752\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6074 - accuracy: 0.7407 - val_loss: 0.8351 - val_accuracy: 0.6667\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6437 - accuracy: 0.7259 - val_loss: 0.8268 - val_accuracy: 0.6667\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6089 - accuracy: 0.7296 - val_loss: 0.8231 - val_accuracy: 0.6752\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6045 - accuracy: 0.7444 - val_loss: 0.8079 - val_accuracy: 0.6838\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5980 - accuracy: 0.7481 - val_loss: 0.8079 - val_accuracy: 0.6923\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6036 - accuracy: 0.7481 - val_loss: 0.8151 - val_accuracy: 0.6752\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5992 - accuracy: 0.7481 - val_loss: 0.8098 - val_accuracy: 0.6923\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5974 - accuracy: 0.7481 - val_loss: 0.8087 - val_accuracy: 0.6838\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6183 - accuracy: 0.7407 - val_loss: 0.8121 - val_accuracy: 0.6838\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6174 - accuracy: 0.7222 - val_loss: 0.8251 - val_accuracy: 0.6667\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.6105 - accuracy: 0.7370 - val_loss: 0.8247 - val_accuracy: 0.6752\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6098 - accuracy: 0.7370 - val_loss: 0.8220 - val_accuracy: 0.6752\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6323 - accuracy: 0.7259 - val_loss: 0.8204 - val_accuracy: 0.6752\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5940 - accuracy: 0.7481 - val_loss: 0.8374 - val_accuracy: 0.6752\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6037 - accuracy: 0.7370 - val_loss: 0.8138 - val_accuracy: 0.6752\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6004 - accuracy: 0.7370 - val_loss: 0.8303 - val_accuracy: 0.6667\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.81 - 0s 120us/step - loss: 0.6275 - accuracy: 0.7296 - val_loss: 0.8041 - val_accuracy: 0.6838\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6007 - accuracy: 0.7481 - val_loss: 0.8106 - val_accuracy: 0.6752\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6103 - accuracy: 0.7185 - val_loss: 0.8271 - val_accuracy: 0.6667\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6000 - accuracy: 0.7370 - val_loss: 0.8442 - val_accuracy: 0.6581\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6371 - accuracy: 0.7222 - val_loss: 0.8391 - val_accuracy: 0.6667\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5979 - accuracy: 0.7481 - val_loss: 0.8297 - val_accuracy: 0.6667\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6331 - accuracy: 0.7333 - val_loss: 0.8477 - val_accuracy: 0.6667\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6144 - accuracy: 0.7444 - val_loss: 0.8179 - val_accuracy: 0.6752\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6234 - accuracy: 0.7333 - val_loss: 0.8369 - val_accuracy: 0.6667\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6345 - accuracy: 0.7259 - val_loss: 0.8487 - val_accuracy: 0.6410\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7029 - accuracy: 0.6926 - val_loss: 0.8286 - val_accuracy: 0.6496\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6532 - accuracy: 0.7296 - val_loss: 0.8177 - val_accuracy: 0.6838\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7095 - accuracy: 0.7074 - val_loss: 0.8556 - val_accuracy: 0.6410\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6421 - accuracy: 0.7296 - val_loss: 0.8783 - val_accuracy: 0.6496\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6610 - accuracy: 0.7259 - val_loss: 0.8440 - val_accuracy: 0.6496\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6453 - accuracy: 0.7296 - val_loss: 0.8697 - val_accuracy: 0.6325\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6593 - accuracy: 0.7111 - val_loss: 0.8728 - val_accuracy: 0.6410\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6275 - accuracy: 0.7222 - val_loss: 0.8222 - val_accuracy: 0.6752\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6033 - accuracy: 0.7333 - val_loss: 0.8287 - val_accuracy: 0.6667\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6116 - accuracy: 0.7444 - val_loss: 0.8225 - val_accuracy: 0.6752\n",
      "Epoch 861/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 108us/step - loss: 0.6040 - accuracy: 0.7333 - val_loss: 0.8270 - val_accuracy: 0.6667\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6016 - accuracy: 0.7444 - val_loss: 0.8222 - val_accuracy: 0.6752\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5986 - accuracy: 0.7444 - val_loss: 0.8171 - val_accuracy: 0.6667\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5993 - accuracy: 0.7370 - val_loss: 0.8259 - val_accuracy: 0.6667\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5921 - accuracy: 0.7444 - val_loss: 0.8201 - val_accuracy: 0.6667\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6037 - accuracy: 0.7444 - val_loss: 0.8219 - val_accuracy: 0.6752\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6059 - accuracy: 0.7296 - val_loss: 0.8243 - val_accuracy: 0.6838\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6596 - accuracy: 0.7185 - val_loss: 0.9003 - val_accuracy: 0.6581\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6170 - accuracy: 0.7556 - val_loss: 1.0298 - val_accuracy: 0.6239\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7161 - accuracy: 0.7148 - val_loss: 0.8324 - val_accuracy: 0.6667\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6064 - accuracy: 0.7407 - val_loss: 0.8290 - val_accuracy: 0.6667\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5992 - accuracy: 0.7407 - val_loss: 0.8205 - val_accuracy: 0.6838\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5943 - accuracy: 0.7444 - val_loss: 0.8232 - val_accuracy: 0.6667\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5972 - accuracy: 0.7407 - val_loss: 0.8157 - val_accuracy: 0.6752\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6018 - accuracy: 0.7259 - val_loss: 0.8236 - val_accuracy: 0.6838\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5982 - accuracy: 0.7444 - val_loss: 0.8129 - val_accuracy: 0.6752\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5949 - accuracy: 0.7481 - val_loss: 0.8209 - val_accuracy: 0.6752\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5997 - accuracy: 0.7481 - val_loss: 0.8166 - val_accuracy: 0.6667\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6020 - accuracy: 0.7333 - val_loss: 0.8259 - val_accuracy: 0.6752\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5965 - accuracy: 0.7481 - val_loss: 0.8155 - val_accuracy: 0.6752\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6039 - accuracy: 0.7481 - val_loss: 0.8135 - val_accuracy: 0.6923\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.5927 - accuracy: 0.7444 - val_loss: 0.8175 - val_accuracy: 0.6838\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5949 - accuracy: 0.7444 - val_loss: 0.8246 - val_accuracy: 0.6752\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7246 - accuracy: 0.7222 - val_loss: 1.0113 - val_accuracy: 0.6581\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7843 - accuracy: 0.7296 - val_loss: 0.8254 - val_accuracy: 0.6838\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6306 - accuracy: 0.7407 - val_loss: 0.8175 - val_accuracy: 0.6838\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6126 - accuracy: 0.7407 - val_loss: 0.8203 - val_accuracy: 0.7009\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6041 - accuracy: 0.7444 - val_loss: 0.8258 - val_accuracy: 0.6752\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6049 - accuracy: 0.7370 - val_loss: 0.8201 - val_accuracy: 0.6752\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6005 - accuracy: 0.7407 - val_loss: 0.8260 - val_accuracy: 0.6752\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5952 - accuracy: 0.7481 - val_loss: 0.8130 - val_accuracy: 0.6838\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.5990 - accuracy: 0.7370 - val_loss: 0.8212 - val_accuracy: 0.6752\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6118 - accuracy: 0.7444 - val_loss: 0.8280 - val_accuracy: 0.6581\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6130 - accuracy: 0.7333 - val_loss: 0.8529 - val_accuracy: 0.6667\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6017 - accuracy: 0.7407 - val_loss: 0.8251 - val_accuracy: 0.6667\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.6058 - accuracy: 0.7333 - val_loss: 0.8411 - val_accuracy: 0.6667\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6054 - accuracy: 0.7444 - val_loss: 0.8162 - val_accuracy: 0.6752\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6080 - accuracy: 0.7259 - val_loss: 0.8496 - val_accuracy: 0.6667\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6003 - accuracy: 0.7444 - val_loss: 0.8254 - val_accuracy: 0.6667\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6134 - accuracy: 0.7370 - val_loss: 0.8408 - val_accuracy: 0.6667\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6009 - accuracy: 0.7333 - val_loss: 0.8164 - val_accuracy: 0.6838\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5916 - accuracy: 0.7481 - val_loss: 0.8264 - val_accuracy: 0.6752\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6070 - accuracy: 0.7333 - val_loss: 0.8123 - val_accuracy: 0.6838\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5972 - accuracy: 0.7481 - val_loss: 0.8124 - val_accuracy: 0.6838\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5926 - accuracy: 0.7407 - val_loss: 0.8208 - val_accuracy: 0.6838\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.5947 - accuracy: 0.7481 - val_loss: 0.8158 - val_accuracy: 0.6838\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6012 - accuracy: 0.7444 - val_loss: 0.8204 - val_accuracy: 0.6752\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5978 - accuracy: 0.7481 - val_loss: 0.8244 - val_accuracy: 0.6667\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5991 - accuracy: 0.7407 - val_loss: 0.8283 - val_accuracy: 0.6667\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6036 - accuracy: 0.7444 - val_loss: 0.8125 - val_accuracy: 0.6752\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6022 - accuracy: 0.7333 - val_loss: 0.8193 - val_accuracy: 0.6752\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5965 - accuracy: 0.7407 - val_loss: 0.8105 - val_accuracy: 0.6838\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6094 - accuracy: 0.7370 - val_loss: 0.8237 - val_accuracy: 0.6752\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5924 - accuracy: 0.7370 - val_loss: 0.8133 - val_accuracy: 0.6838\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5941 - accuracy: 0.7519 - val_loss: 0.8119 - val_accuracy: 0.6838\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5902 - accuracy: 0.7556 - val_loss: 0.8132 - val_accuracy: 0.6838\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5909 - accuracy: 0.7407 - val_loss: 0.8136 - val_accuracy: 0.6752\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5904 - accuracy: 0.7481 - val_loss: 0.8183 - val_accuracy: 0.6752\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5920 - accuracy: 0.7444 - val_loss: 0.8067 - val_accuracy: 0.6838\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5939 - accuracy: 0.7444 - val_loss: 0.8273 - val_accuracy: 0.6752\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6005 - accuracy: 0.7370 - val_loss: 0.8097 - val_accuracy: 0.6838\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.5942 - accuracy: 0.7519 - val_loss: 0.8152 - val_accuracy: 0.6752\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5942 - accuracy: 0.7407 - val_loss: 0.8121 - val_accuracy: 0.6838\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.5919 - accuracy: 0.7481 - val_loss: 0.8148 - val_accuracy: 0.6752\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5994 - accuracy: 0.7333 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5917 - accuracy: 0.7481 - val_loss: 0.8155 - val_accuracy: 0.6838\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5987 - accuracy: 0.7481 - val_loss: 0.8154 - val_accuracy: 0.6752\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5996 - accuracy: 0.7407 - val_loss: 0.8083 - val_accuracy: 0.6752\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5892 - accuracy: 0.7481 - val_loss: 0.8107 - val_accuracy: 0.6923\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5892 - accuracy: 0.7519 - val_loss: 0.8134 - val_accuracy: 0.6752\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5942 - accuracy: 0.7519 - val_loss: 0.8115 - val_accuracy: 0.6838\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5908 - accuracy: 0.7444 - val_loss: 0.8160 - val_accuracy: 0.6838\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5946 - accuracy: 0.7481 - val_loss: 0.8104 - val_accuracy: 0.6752\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5874 - accuracy: 0.7481 - val_loss: 0.8240 - val_accuracy: 0.6838\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6022 - accuracy: 0.7481 - val_loss: 0.8105 - val_accuracy: 0.6752\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5873 - accuracy: 0.7519 - val_loss: 0.8314 - val_accuracy: 0.6667\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5951 - accuracy: 0.7444 - val_loss: 0.8102 - val_accuracy: 0.6752\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5935 - accuracy: 0.7407 - val_loss: 0.8499 - val_accuracy: 0.6667\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6065 - accuracy: 0.7407 - val_loss: 0.8527 - val_accuracy: 0.6667\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6264 - accuracy: 0.7333 - val_loss: 0.8869 - val_accuracy: 0.6410\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7448 - accuracy: 0.7259 - val_loss: 0.9634 - val_accuracy: 0.6496\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7540 - accuracy: 0.7259 - val_loss: 0.8834 - val_accuracy: 0.6410\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6940 - accuracy: 0.7296 - val_loss: 0.9111 - val_accuracy: 0.6581\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6625 - accuracy: 0.7370 - val_loss: 0.9287 - val_accuracy: 0.6068\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7148 - accuracy: 0.7222 - val_loss: 0.8606 - val_accuracy: 0.6667\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7445 - accuracy: 0.7111 - val_loss: 0.8123 - val_accuracy: 0.6838\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6237 - accuracy: 0.7333 - val_loss: 0.8225 - val_accuracy: 0.6752\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6038 - accuracy: 0.7296 - val_loss: 0.8546 - val_accuracy: 0.6581\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6217 - accuracy: 0.7407 - val_loss: 0.8264 - val_accuracy: 0.6581\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6056 - accuracy: 0.7259 - val_loss: 0.8428 - val_accuracy: 0.6667\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6088 - accuracy: 0.7333 - val_loss: 0.8188 - val_accuracy: 0.6752\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6035 - accuracy: 0.7370 - val_loss: 0.8351 - val_accuracy: 0.6667\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5936 - accuracy: 0.7481 - val_loss: 0.8106 - val_accuracy: 0.6838\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5928 - accuracy: 0.7481 - val_loss: 0.8227 - val_accuracy: 0.6752\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6163 - accuracy: 0.7296 - val_loss: 0.8185 - val_accuracy: 0.6923\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6132 - accuracy: 0.7407 - val_loss: 0.8201 - val_accuracy: 0.6667\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6458 - accuracy: 0.7222 - val_loss: 0.8639 - val_accuracy: 0.6410\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6145 - accuracy: 0.7222 - val_loss: 0.8278 - val_accuracy: 0.6838\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6067 - accuracy: 0.7370 - val_loss: 0.8214 - val_accuracy: 0.6838\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6060 - accuracy: 0.7481 - val_loss: 0.8212 - val_accuracy: 0.6752\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6051 - accuracy: 0.7222 - val_loss: 0.8258 - val_accuracy: 0.6752\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5985 - accuracy: 0.7444 - val_loss: 0.8129 - val_accuracy: 0.6838\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6211 - accuracy: 0.7296 - val_loss: 0.9408 - val_accuracy: 0.6325\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6349 - accuracy: 0.7259 - val_loss: 0.9357 - val_accuracy: 0.6410\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6692 - accuracy: 0.7148 - val_loss: 0.9584 - val_accuracy: 0.6325\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6250 - accuracy: 0.7259 - val_loss: 0.8352 - val_accuracy: 0.6752\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6086 - accuracy: 0.7259 - val_loss: 0.8832 - val_accuracy: 0.6410\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6128 - accuracy: 0.7333 - val_loss: 0.8242 - val_accuracy: 0.6752\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6170 - accuracy: 0.7296 - val_loss: 0.8565 - val_accuracy: 0.6581\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8116 - accuracy: 0.7148 - val_loss: 0.9324 - val_accuracy: 0.6581\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 106us/step - loss: 0.6275 - accuracy: 0.7444 - val_loss: 1.0817 - val_accuracy: 0.6325\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7105 - accuracy: 0.7259 - val_loss: 0.8871 - val_accuracy: 0.6581\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6660 - accuracy: 0.7296 - val_loss: 0.8671 - val_accuracy: 0.6581\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5992 - accuracy: 0.7481 - val_loss: 0.8168 - val_accuracy: 0.6838\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6355 - accuracy: 0.7222 - val_loss: 0.8418 - val_accuracy: 0.6667\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6393 - accuracy: 0.7333 - val_loss: 0.8526 - val_accuracy: 0.6667\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6294 - accuracy: 0.7296 - val_loss: 0.8428 - val_accuracy: 0.6667\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6018 - accuracy: 0.7333 - val_loss: 0.8094 - val_accuracy: 0.6838\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5944 - accuracy: 0.7444 - val_loss: 0.8095 - val_accuracy: 0.6923\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5878 - accuracy: 0.7519 - val_loss: 0.8092 - val_accuracy: 0.6752\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5876 - accuracy: 0.7481 - val_loss: 0.8152 - val_accuracy: 0.6838\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.75 - 0s 128us/step - loss: 0.5902 - accuracy: 0.7444 - val_loss: 0.8141 - val_accuracy: 0.6923\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.5878 - accuracy: 0.7444 - val_loss: 0.8123 - val_accuracy: 0.6838\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5959 - accuracy: 0.7481 - val_loss: 0.8115 - val_accuracy: 0.6838\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5934 - accuracy: 0.7333 - val_loss: 0.8181 - val_accuracy: 0.6752\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5934 - accuracy: 0.7444 - val_loss: 0.8182 - val_accuracy: 0.6752\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5922 - accuracy: 0.7481 - val_loss: 0.8212 - val_accuracy: 0.6752\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5896 - accuracy: 0.7481 - val_loss: 0.8106 - val_accuracy: 0.6838\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5949 - accuracy: 0.7407 - val_loss: 0.8365 - val_accuracy: 0.6667\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5913 - accuracy: 0.7481 - val_loss: 0.8102 - val_accuracy: 0.6923\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5885 - accuracy: 0.7407 - val_loss: 0.8166 - val_accuracy: 0.6752\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5857 - accuracy: 0.7444 - val_loss: 0.8141 - val_accuracy: 0.6752\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5883 - accuracy: 0.7519 - val_loss: 0.8169 - val_accuracy: 0.6838\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5943 - accuracy: 0.7481 - val_loss: 0.8117 - val_accuracy: 0.6838\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6260 - accuracy: 0.7259 - val_loss: 0.9791 - val_accuracy: 0.6154\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7006 - accuracy: 0.7111 - val_loss: 0.8309 - val_accuracy: 0.6752\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6889 - accuracy: 0.7259 - val_loss: 0.8906 - val_accuracy: 0.6410\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7915 - accuracy: 0.7148 - val_loss: 0.9152 - val_accuracy: 0.6581\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6395 - accuracy: 0.7222 - val_loss: 1.0501 - val_accuracy: 0.5897\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7865 - accuracy: 0.6963 - val_loss: 0.8972 - val_accuracy: 0.6581\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 72.55%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.67828900e-01, 2.30110440e-01, 2.06067500e-03],\n",
       "       [6.96772800e-02, 1.96709080e-04, 9.30126100e-01],\n",
       "       [2.10048200e-02, 1.66178460e-02, 9.62377300e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [6.28776250e-01, 3.70516660e-01, 7.07122300e-04],\n",
       "       [4.51863560e-02, 2.77519600e-02, 9.27061740e-01],\n",
       "       [3.35063100e-01, 6.64909500e-01, 2.73770000e-05],\n",
       "       [2.70308000e-01, 3.80303600e-01, 3.49388450e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [9.72553300e-01, 2.74464530e-02, 1.92193720e-07],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [8.85721100e-01, 1.06108680e-01, 8.17020000e-03],\n",
       "       [1.66191280e-01, 6.49790940e-01, 1.84017780e-01],\n",
       "       [7.99674030e-01, 7.64478600e-02, 1.23878084e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [3.14755740e-04, 1.22953540e-01, 8.76731750e-01],\n",
       "       [6.97452900e-01, 1.02297670e-01, 2.00249400e-01],\n",
       "       [8.16299600e-02, 2.94111500e-02, 8.88958900e-01],\n",
       "       [2.22664110e-05, 2.66066780e-04, 9.99711700e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [9.99999900e-01, 1.24945790e-07, 5.70944340e-17],\n",
       "       [7.46729850e-01, 2.16855320e-01, 3.64147700e-02],\n",
       "       [1.21455970e-01, 5.79219300e-02, 8.20622150e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [9.48550640e-01, 1.28517830e-02, 3.85976400e-02],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [3.90681950e-01, 5.38318500e-01, 7.09995500e-02],\n",
       "       [6.98788940e-01, 1.28604010e-01, 1.72607120e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [1.48981510e-01, 2.12582500e-01, 6.38436000e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [3.90681950e-01, 5.38318500e-01, 7.09995500e-02],\n",
       "       [2.10048200e-02, 1.66178460e-02, 9.62377300e-01],\n",
       "       [7.45247800e-01, 6.23066000e-02, 1.92445700e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [1.48981510e-01, 2.12582500e-01, 6.38436000e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [6.28776250e-01, 3.70516660e-01, 7.07122300e-04],\n",
       "       [3.40704620e-01, 2.69746330e-01, 3.89549100e-01],\n",
       "       [2.10048200e-02, 1.66178460e-02, 9.62377300e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [6.85455260e-01, 1.05378530e-01, 2.09166120e-01],\n",
       "       [6.83105050e-01, 3.11027620e-01, 5.86737550e-03],\n",
       "       [9.99867440e-01, 1.25658320e-04, 6.91627800e-06],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [2.70308000e-01, 3.80303600e-01, 3.49388450e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [8.44260630e-01, 6.49436400e-02, 9.07957400e-02],\n",
       "       [4.06137700e-01, 3.54480060e-01, 2.39382240e-01],\n",
       "       [8.58356800e-03, 8.65237900e-02, 9.04892600e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [7.64453600e-04, 2.52365340e-03, 9.96711850e-01],\n",
       "       [8.16299600e-02, 2.94111500e-02, 8.88958900e-01],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [5.09563270e-02, 3.16116500e-01, 6.32927100e-01],\n",
       "       [1.00000000e+00, 1.90209520e-22, 0.00000000e+00],\n",
       "       [3.14755740e-04, 1.22953540e-01, 8.76731750e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [3.67889560e-04, 1.93375870e-01, 8.06256300e-01],\n",
       "       [9.68010200e-01, 1.62451510e-02, 1.57446210e-02],\n",
       "       [6.84578660e-01, 1.09310200e-01, 2.06111160e-01],\n",
       "       [8.79584900e-02, 1.90352870e-01, 7.21688570e-01],\n",
       "       [3.90681950e-01, 5.38318500e-01, 7.09995500e-02],\n",
       "       [2.77097300e-01, 3.78357230e-01, 3.44545480e-01],\n",
       "       [3.06795690e-02, 1.13897404e-04, 9.69206600e-01],\n",
       "       [6.84578660e-01, 1.09310200e-01, 2.06111160e-01],\n",
       "       [8.58356800e-03, 8.65237900e-02, 9.04892600e-01],\n",
       "       [3.22596400e-04, 9.99602140e-01, 7.52552900e-05],\n",
       "       [6.28776250e-01, 3.70516660e-01, 7.07122300e-04],\n",
       "       [4.06137700e-01, 3.54480060e-01, 2.39382240e-01],\n",
       "       [5.55200840e-02, 1.24049490e-02, 9.32075000e-01],\n",
       "       [6.96772800e-02, 1.96709080e-04, 9.30126100e-01],\n",
       "       [1.15007020e-01, 3.61150770e-01, 5.23842160e-01],\n",
       "       [5.94176000e-01, 3.65545360e-01, 4.02786770e-02],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [5.94176000e-01, 3.65545360e-01, 4.02786770e-02],\n",
       "       [6.28776250e-01, 3.70516660e-01, 7.07122300e-04],\n",
       "       [6.84578660e-01, 1.09310200e-01, 2.06111160e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [1.15007020e-01, 3.61150770e-01, 5.23842160e-01],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [3.07119200e-03, 2.73053270e-04, 9.96655700e-01],\n",
       "       [6.39046430e-01, 2.33384430e-01, 1.27569150e-01],\n",
       "       [3.92290470e-01, 1.97031540e-01, 4.10678000e-01],\n",
       "       [1.74188970e-01, 2.37098830e-01, 5.88712300e-01],\n",
       "       [9.99677060e-01, 3.22989700e-04, 3.31067550e-08],\n",
       "       [3.06795690e-02, 1.13897404e-04, 9.69206600e-01],\n",
       "       [4.50076430e-01, 5.49914840e-01, 8.62760700e-06],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [7.80556400e-01, 1.01563980e-01, 1.17879670e-01],\n",
       "       [2.10048200e-02, 1.66178460e-02, 9.62377300e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [2.46529220e-01, 6.02341650e-01, 1.51129140e-01],\n",
       "       [5.80773600e-01, 2.22390470e-01, 1.96835900e-01],\n",
       "       [6.84578660e-01, 1.09310200e-01, 2.06111160e-01],\n",
       "       [8.16299600e-02, 2.94111500e-02, 8.88958900e-01],\n",
       "       [2.16958510e-01, 6.36463000e-02, 7.19395160e-01],\n",
       "       [4.06137700e-01, 3.54480060e-01, 2.39382240e-01],\n",
       "       [3.67889560e-04, 1.93375870e-01, 8.06256300e-01],\n",
       "       [4.06137700e-01, 3.54480060e-01, 2.39382240e-01],\n",
       "       [9.53081300e-01, 3.34013200e-02, 1.35174060e-02],\n",
       "       [7.95808100e-02, 9.17573030e-01, 2.84617720e-03],\n",
       "       [2.94361400e-01, 6.65271700e-02, 6.39111400e-01],\n",
       "       [9.68010200e-01, 1.62451510e-02, 1.57446210e-02],\n",
       "       [2.44494050e-01, 7.10529000e-01, 4.49769420e-02],\n",
       "       [8.79584900e-02, 1.90352870e-01, 7.21688570e-01],\n",
       "       [3.67889560e-04, 1.93375870e-01, 8.06256300e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888450580758274"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888450580758274"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS236     1\n",
       "1      NRS113     2\n",
       "2    CFBRSa23     0\n",
       "3      NRS249     2\n",
       "4         107     1\n",
       "..        ...   ...\n",
       "112     NY439     2\n",
       "113    NRS106     0\n",
       "114       221     0\n",
       "115    NRS386     2\n",
       "116  CFBRSa03     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 603us/step - loss: 14.5086 - accuracy: 0.3852 - val_loss: 11.2833 - val_accuracy: 0.4786\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 8.4163 - accuracy: 0.4667 - val_loss: 4.9167 - val_accuracy: 0.4444\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 3.3838 - accuracy: 0.4333 - val_loss: 2.7282 - val_accuracy: 0.3675\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 2.8056 - accuracy: 0.3630 - val_loss: 2.7566 - val_accuracy: 0.3761\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 2.6665 - accuracy: 0.3519 - val_loss: 2.6052 - val_accuracy: 0.3590\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 2.5098 - accuracy: 0.3593 - val_loss: 1.9119 - val_accuracy: 0.4017\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 1.9948 - accuracy: 0.4593 - val_loss: 2.0306 - val_accuracy: 0.3932\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 1.8701 - accuracy: 0.4556 - val_loss: 1.5679 - val_accuracy: 0.3846\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 1.4570 - accuracy: 0.4593 - val_loss: 1.5730 - val_accuracy: 0.4274\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.3774 - accuracy: 0.4444 - val_loss: 1.2950 - val_accuracy: 0.3846\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.2371 - accuracy: 0.4519 - val_loss: 1.1607 - val_accuracy: 0.3761\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.1194 - accuracy: 0.4704 - val_loss: 1.1821 - val_accuracy: 0.4188\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.2094 - accuracy: 0.4519 - val_loss: 1.2258 - val_accuracy: 0.4359\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 1.2277 - accuracy: 0.4370 - val_loss: 1.1198 - val_accuracy: 0.4274\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.1334 - accuracy: 0.4333 - val_loss: 1.1267 - val_accuracy: 0.4359\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.1295 - accuracy: 0.4370 - val_loss: 1.1208 - val_accuracy: 0.4103\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.1126 - accuracy: 0.4519 - val_loss: 1.1239 - val_accuracy: 0.4615\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.1226 - accuracy: 0.4815 - val_loss: 1.1199 - val_accuracy: 0.4188\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0791 - accuracy: 0.4667 - val_loss: 1.0790 - val_accuracy: 0.4188\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0575 - accuracy: 0.4667 - val_loss: 1.1091 - val_accuracy: 0.4444\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 1.0795 - accuracy: 0.4889 - val_loss: 1.1581 - val_accuracy: 0.4615\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0998 - accuracy: 0.4556 - val_loss: 1.1183 - val_accuracy: 0.4615\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0985 - accuracy: 0.4519 - val_loss: 1.0941 - val_accuracy: 0.4359\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0718 - accuracy: 0.5037 - val_loss: 1.1678 - val_accuracy: 0.4701\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0882 - accuracy: 0.4815 - val_loss: 1.0784 - val_accuracy: 0.4274\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0598 - accuracy: 0.4815 - val_loss: 1.1043 - val_accuracy: 0.3932\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.0705 - accuracy: 0.4741 - val_loss: 1.2419 - val_accuracy: 0.4615\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1737 - accuracy: 0.5074 - val_loss: 1.1438 - val_accuracy: 0.4701\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 1.0404 - accuracy: 0.4963 - val_loss: 1.1496 - val_accuracy: 0.4530\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.0976 - accuracy: 0.4630 - val_loss: 1.1053 - val_accuracy: 0.4615\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1238 - accuracy: 0.5148 - val_loss: 1.1744 - val_accuracy: 0.5128\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.1189 - accuracy: 0.5148 - val_loss: 1.0391 - val_accuracy: 0.4701\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.0580 - accuracy: 0.4889 - val_loss: 1.0505 - val_accuracy: 0.5470\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 1.1409 - accuracy: 0.5407 - val_loss: 1.3847 - val_accuracy: 0.5385\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 1.2942 - accuracy: 0.5481 - val_loss: 1.3326 - val_accuracy: 0.5470\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 1.1791 - accuracy: 0.5593 - val_loss: 1.0632 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 1.1035 - accuracy: 0.4889 - val_loss: 1.3136 - val_accuracy: 0.4359\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1214 - accuracy: 0.5185 - val_loss: 1.1100 - val_accuracy: 0.5470\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.1474 - accuracy: 0.5444 - val_loss: 1.2395 - val_accuracy: 0.5641\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1545 - accuracy: 0.5481 - val_loss: 1.1283 - val_accuracy: 0.5043\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0410 - accuracy: 0.5444 - val_loss: 1.0408 - val_accuracy: 0.4530\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 1.0343 - accuracy: 0.5259 - val_loss: 1.0292 - val_accuracy: 0.4444\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0057 - accuracy: 0.5593 - val_loss: 1.0402 - val_accuracy: 0.4872\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9929 - accuracy: 0.5407 - val_loss: 1.0350 - val_accuracy: 0.4444\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9876 - accuracy: 0.5444 - val_loss: 1.0721 - val_accuracy: 0.4957\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0345 - accuracy: 0.5444 - val_loss: 1.0231 - val_accuracy: 0.4957\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.0075 - accuracy: 0.5111 - val_loss: 1.0496 - val_accuracy: 0.4530\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 1.0128 - accuracy: 0.5333 - val_loss: 1.0014 - val_accuracy: 0.4872\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9791 - accuracy: 0.5370 - val_loss: 1.0031 - val_accuracy: 0.4615\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0618 - accuracy: 0.4926 - val_loss: 0.9920 - val_accuracy: 0.5128\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9555 - accuracy: 0.5630 - val_loss: 1.0743 - val_accuracy: 0.4872\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.0110 - accuracy: 0.5481 - val_loss: 1.0203 - val_accuracy: 0.4957\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9556 - accuracy: 0.5667 - val_loss: 1.0176 - val_accuracy: 0.4444\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0077 - accuracy: 0.5222 - val_loss: 0.9980 - val_accuracy: 0.5043\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0083 - accuracy: 0.5407 - val_loss: 0.9958 - val_accuracy: 0.4701\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9924 - accuracy: 0.5444 - val_loss: 1.0048 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0729 - accuracy: 0.5333 - val_loss: 0.9908 - val_accuracy: 0.4957\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9849 - accuracy: 0.5296 - val_loss: 1.0150 - val_accuracy: 0.4615\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9701 - accuracy: 0.5333 - val_loss: 1.0035 - val_accuracy: 0.4957\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0692 - accuracy: 0.5333 - val_loss: 1.1864 - val_accuracy: 0.4530\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.1125 - accuracy: 0.5407 - val_loss: 1.0122 - val_accuracy: 0.5043\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 1.0253 - accuracy: 0.5444 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 1.0509 - accuracy: 0.5370 - val_loss: 1.1468 - val_accuracy: 0.4530\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1852 - accuracy: 0.4815 - val_loss: 0.9635 - val_accuracy: 0.5214\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9905 - accuracy: 0.5370 - val_loss: 1.0957 - val_accuracy: 0.5128\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0373 - accuracy: 0.5741 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0381 - accuracy: 0.5222 - val_loss: 0.9614 - val_accuracy: 0.5556\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9435 - accuracy: 0.5704 - val_loss: 1.0599 - val_accuracy: 0.5556\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9870 - accuracy: 0.5593 - val_loss: 0.9625 - val_accuracy: 0.5556\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9448 - accuracy: 0.5481 - val_loss: 1.0101 - val_accuracy: 0.5641\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0030 - accuracy: 0.5778 - val_loss: 0.9528 - val_accuracy: 0.5556\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.9923 - accuracy: 0.5519 - val_loss: 0.9943 - val_accuracy: 0.5470\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9458 - accuracy: 0.5444 - val_loss: 0.9864 - val_accuracy: 0.5470\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9526 - accuracy: 0.5370 - val_loss: 0.9589 - val_accuracy: 0.5556\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9167 - accuracy: 0.5667 - val_loss: 0.9962 - val_accuracy: 0.5470\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9453 - accuracy: 0.5519 - val_loss: 0.9871 - val_accuracy: 0.5470\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9276 - accuracy: 0.5519 - val_loss: 1.0071 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9504 - accuracy: 0.5630 - val_loss: 0.9512 - val_accuracy: 0.5556\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9300 - accuracy: 0.5519 - val_loss: 0.9648 - val_accuracy: 0.5128\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9376 - accuracy: 0.5593 - val_loss: 0.9754 - val_accuracy: 0.5128\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9202 - accuracy: 0.5519 - val_loss: 0.9737 - val_accuracy: 0.5385\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.9655 - accuracy: 0.5556 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9623 - accuracy: 0.5185 - val_loss: 1.0103 - val_accuracy: 0.5556\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 1.0004 - accuracy: 0.5778 - val_loss: 1.0240 - val_accuracy: 0.5556\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9520 - accuracy: 0.5667 - val_loss: 1.0543 - val_accuracy: 0.5385\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.2681 - accuracy: 0.5630 - val_loss: 1.6064 - val_accuracy: 0.4872\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 1.7046 - accuracy: 0.5259 - val_loss: 1.6203 - val_accuracy: 0.5128\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.5534 - accuracy: 0.5370 - val_loss: 1.3168 - val_accuracy: 0.5128\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 1.0805 - accuracy: 0.5741 - val_loss: 1.2142 - val_accuracy: 0.5214\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0595 - accuracy: 0.5333 - val_loss: 1.0694 - val_accuracy: 0.5812\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0680 - accuracy: 0.5667 - val_loss: 1.1146 - val_accuracy: 0.5385\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.0128 - accuracy: 0.5556 - val_loss: 0.9510 - val_accuracy: 0.5385\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9053 - accuracy: 0.5444 - val_loss: 0.9789 - val_accuracy: 0.5726\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9239 - accuracy: 0.5704 - val_loss: 0.9484 - val_accuracy: 0.5470\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8975 - accuracy: 0.5815 - val_loss: 0.9687 - val_accuracy: 0.5641\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8958 - accuracy: 0.5778 - val_loss: 0.9781 - val_accuracy: 0.5812\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8947 - accuracy: 0.5889 - val_loss: 0.9457 - val_accuracy: 0.5726\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8956 - accuracy: 0.5852 - val_loss: 0.9729 - val_accuracy: 0.5812\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8888 - accuracy: 0.5778 - val_loss: 0.9524 - val_accuracy: 0.5385\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8933 - accuracy: 0.5444 - val_loss: 0.9453 - val_accuracy: 0.5470\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8764 - accuracy: 0.5741 - val_loss: 0.9344 - val_accuracy: 0.5641\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8884 - accuracy: 0.6037 - val_loss: 0.9416 - val_accuracy: 0.5726\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8840 - accuracy: 0.5889 - val_loss: 0.9967 - val_accuracy: 0.5726\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9369 - accuracy: 0.5852 - val_loss: 1.0127 - val_accuracy: 0.5556\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9054 - accuracy: 0.5815 - val_loss: 0.9479 - val_accuracy: 0.5556\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8901 - accuracy: 0.5630 - val_loss: 0.9667 - val_accuracy: 0.5641\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8966 - accuracy: 0.5889 - val_loss: 0.9641 - val_accuracy: 0.5641\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8675 - accuracy: 0.53 - 0s 94us/step - loss: 0.8711 - accuracy: 0.5889 - val_loss: 0.9915 - val_accuracy: 0.5299\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9253 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.5470\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9279 - accuracy: 0.6148 - val_loss: 0.9912 - val_accuracy: 0.5812\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8951 - accuracy: 0.5963 - val_loss: 1.0104 - val_accuracy: 0.5983\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9354 - accuracy: 0.6111 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8859 - accuracy: 0.5593 - val_loss: 0.9634 - val_accuracy: 0.5641\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8704 - accuracy: 0.5963 - val_loss: 0.9552 - val_accuracy: 0.5556\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8812 - accuracy: 0.5630 - val_loss: 0.9914 - val_accuracy: 0.5726\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9293 - accuracy: 0.5815 - val_loss: 0.9907 - val_accuracy: 0.5726\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8786 - accuracy: 0.5852 - val_loss: 0.9598 - val_accuracy: 0.5641\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8730 - accuracy: 0.5593 - val_loss: 0.9769 - val_accuracy: 0.5556\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8748 - accuracy: 0.5852 - val_loss: 0.9435 - val_accuracy: 0.5641\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8623 - accuracy: 0.5778 - val_loss: 0.9604 - val_accuracy: 0.5641\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8906 - accuracy: 0.5593 - val_loss: 0.9763 - val_accuracy: 0.5897\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8913 - accuracy: 0.5889 - val_loss: 0.9680 - val_accuracy: 0.5726\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8746 - accuracy: 0.5815 - val_loss: 0.9632 - val_accuracy: 0.5641\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8791 - accuracy: 0.5667 - val_loss: 0.9380 - val_accuracy: 0.5470\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8750 - accuracy: 0.5741 - val_loss: 0.9954 - val_accuracy: 0.5470\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.9536 - accuracy: 0.5963 - val_loss: 0.9964 - val_accuracy: 0.5470\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8543 - accuracy: 0.5815 - val_loss: 0.9878 - val_accuracy: 0.5470\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8682 - accuracy: 0.5556 - val_loss: 0.9945 - val_accuracy: 0.5641\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8739 - accuracy: 0.6037 - val_loss: 0.9267 - val_accuracy: 0.6068\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8447 - accuracy: 0.6222 - val_loss: 0.9600 - val_accuracy: 0.5983\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8629 - accuracy: 0.6000 - val_loss: 0.9394 - val_accuracy: 0.5470\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8562 - accuracy: 0.6000 - val_loss: 0.9323 - val_accuracy: 0.6068\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8627 - accuracy: 0.6296 - val_loss: 0.9395 - val_accuracy: 0.5897\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8461 - accuracy: 0.5963 - val_loss: 0.9516 - val_accuracy: 0.5812\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8580 - accuracy: 0.6000 - val_loss: 0.9397 - val_accuracy: 0.5812\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8798 - accuracy: 0.6148 - val_loss: 0.9460 - val_accuracy: 0.5897\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8544 - accuracy: 0.6370 - val_loss: 0.9365 - val_accuracy: 0.5726\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8727 - accuracy: 0.6074 - val_loss: 0.9321 - val_accuracy: 0.5726\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8874 - accuracy: 0.6148 - val_loss: 0.9912 - val_accuracy: 0.6154\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8561 - accuracy: 0.6296 - val_loss: 1.0717 - val_accuracy: 0.5726\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9074 - accuracy: 0.6000 - val_loss: 1.0316 - val_accuracy: 0.5983\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9259 - accuracy: 0.6370 - val_loss: 0.9297 - val_accuracy: 0.5812\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9141 - accuracy: 0.6000 - val_loss: 0.9972 - val_accuracy: 0.5983\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8805 - accuracy: 0.6185 - val_loss: 0.9711 - val_accuracy: 0.5983\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8638 - accuracy: 0.6111 - val_loss: 0.9635 - val_accuracy: 0.6239\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8502 - accuracy: 0.6333 - val_loss: 0.9417 - val_accuracy: 0.5641\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8538 - accuracy: 0.6222 - val_loss: 0.9294 - val_accuracy: 0.5812\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8525 - accuracy: 0.6111 - val_loss: 0.9569 - val_accuracy: 0.5897\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8479 - accuracy: 0.6407 - val_loss: 0.9648 - val_accuracy: 0.5983\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8525 - accuracy: 0.6111 - val_loss: 0.9514 - val_accuracy: 0.6239\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8543 - accuracy: 0.6333 - val_loss: 0.9694 - val_accuracy: 0.6154\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8516 - accuracy: 0.5926 - val_loss: 1.0057 - val_accuracy: 0.5641\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8761 - accuracy: 0.5630 - val_loss: 0.9882 - val_accuracy: 0.6068\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8608 - accuracy: 0.6296 - val_loss: 0.9856 - val_accuracy: 0.5726\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8428 - accuracy: 0.6074 - val_loss: 0.9948 - val_accuracy: 0.6068\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8644 - accuracy: 0.6259 - val_loss: 0.9320 - val_accuracy: 0.5641\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8241 - accuracy: 0.6185 - val_loss: 0.9304 - val_accuracy: 0.5726\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8284 - accuracy: 0.6444 - val_loss: 0.9449 - val_accuracy: 0.5812\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8417 - accuracy: 0.6148 - val_loss: 0.9366 - val_accuracy: 0.5897\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8249 - accuracy: 0.6407 - val_loss: 0.9591 - val_accuracy: 0.5897\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8414 - accuracy: 0.6111 - val_loss: 1.0204 - val_accuracy: 0.5983\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9048 - accuracy: 0.6407 - val_loss: 1.0086 - val_accuracy: 0.5983\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8918 - accuracy: 0.6037 - val_loss: 0.9368 - val_accuracy: 0.6154\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8283 - accuracy: 0.6296 - val_loss: 0.9236 - val_accuracy: 0.5897\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8430 - accuracy: 0.6148 - val_loss: 0.9691 - val_accuracy: 0.6239\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8340 - accuracy: 0.6481 - val_loss: 0.9388 - val_accuracy: 0.5983\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8409 - accuracy: 0.6222 - val_loss: 0.9584 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8225 - accuracy: 0.6259 - val_loss: 0.9367 - val_accuracy: 0.6068\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8279 - accuracy: 0.6481 - val_loss: 0.9401 - val_accuracy: 0.5812\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8088 - accuracy: 0.6259 - val_loss: 0.9798 - val_accuracy: 0.5983\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8830 - accuracy: 0.6074 - val_loss: 0.9518 - val_accuracy: 0.5812\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8479 - accuracy: 0.6111 - val_loss: 0.9880 - val_accuracy: 0.6325\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8917 - accuracy: 0.6185 - val_loss: 1.0703 - val_accuracy: 0.5812\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8769 - accuracy: 0.5815 - val_loss: 1.0043 - val_accuracy: 0.6239\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9064 - accuracy: 0.6593 - val_loss: 0.9876 - val_accuracy: 0.5983\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8272 - accuracy: 0.6259 - val_loss: 1.0883 - val_accuracy: 0.5983\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8866 - accuracy: 0.6333 - val_loss: 1.1125 - val_accuracy: 0.6154\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9364 - accuracy: 0.6556 - val_loss: 1.0269 - val_accuracy: 0.5812\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8333 - accuracy: 0.6111 - val_loss: 1.0730 - val_accuracy: 0.5983\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9327 - accuracy: 0.6000 - val_loss: 1.0075 - val_accuracy: 0.6068\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8853 - accuracy: 0.6370 - val_loss: 1.2033 - val_accuracy: 0.6068\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 1.4553 - accuracy: 0.6074 - val_loss: 2.0062 - val_accuracy: 0.5470\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.8859 - accuracy: 0.5704 - val_loss: 2.0244 - val_accuracy: 0.5214\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 1.6674 - accuracy: 0.5556 - val_loss: 1.3715 - val_accuracy: 0.5385\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0660 - accuracy: 0.6037 - val_loss: 1.7444 - val_accuracy: 0.5556\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 1.3824 - accuracy: 0.5519 - val_loss: 1.1234 - val_accuracy: 0.5897\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9603 - accuracy: 0.6444 - val_loss: 1.0966 - val_accuracy: 0.5556\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8844 - accuracy: 0.6074 - val_loss: 1.0460 - val_accuracy: 0.5897\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9455 - accuracy: 0.6222 - val_loss: 1.0581 - val_accuracy: 0.5812\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8778 - accuracy: 0.6111 - val_loss: 0.9791 - val_accuracy: 0.5812\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8783 - accuracy: 0.5963 - val_loss: 1.0553 - val_accuracy: 0.5983\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8605 - accuracy: 0.6296 - val_loss: 0.9342 - val_accuracy: 0.6154\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8274 - accuracy: 0.6000 - val_loss: 0.9685 - val_accuracy: 0.5983\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8356 - accuracy: 0.6296 - val_loss: 0.9542 - val_accuracy: 0.5897\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8316 - accuracy: 0.6185 - val_loss: 0.9299 - val_accuracy: 0.5812\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8600 - accuracy: 0.6333 - val_loss: 1.0108 - val_accuracy: 0.5983\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8168 - accuracy: 0.6444 - val_loss: 0.9391 - val_accuracy: 0.5812\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8536 - accuracy: 0.6185 - val_loss: 0.9691 - val_accuracy: 0.5897\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8365 - accuracy: 0.6333 - val_loss: 0.9440 - val_accuracy: 0.6068\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8025 - accuracy: 0.6333 - val_loss: 0.9421 - val_accuracy: 0.5812\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8056 - accuracy: 0.6259 - val_loss: 0.9385 - val_accuracy: 0.5897\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7975 - accuracy: 0.6333 - val_loss: 0.9217 - val_accuracy: 0.5897\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8259 - accuracy: 0.6444 - val_loss: 0.9603 - val_accuracy: 0.5897\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7927 - accuracy: 0.6296 - val_loss: 0.9455 - val_accuracy: 0.5726\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8121 - accuracy: 0.6259 - val_loss: 0.9264 - val_accuracy: 0.5812\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8298 - accuracy: 0.6222 - val_loss: 0.9697 - val_accuracy: 0.5897\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8101 - accuracy: 0.6444 - val_loss: 1.0667 - val_accuracy: 0.5983\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.1934 - accuracy: 0.5963 - val_loss: 1.1708 - val_accuracy: 0.5812\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8610 - accuracy: 0.6111 - val_loss: 1.1199 - val_accuracy: 0.4701\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9741 - accuracy: 0.6000 - val_loss: 0.9878 - val_accuracy: 0.4615\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8435 - accuracy: 0.5889 - val_loss: 0.9593 - val_accuracy: 0.6239\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8206 - accuracy: 0.6259 - val_loss: 0.9513 - val_accuracy: 0.6154\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8115 - accuracy: 0.6333 - val_loss: 0.9231 - val_accuracy: 0.6154\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7981 - accuracy: 0.6148 - val_loss: 0.9529 - val_accuracy: 0.6239\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7993 - accuracy: 0.6370 - val_loss: 0.9321 - val_accuracy: 0.5897\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8141 - accuracy: 0.6370 - val_loss: 0.9641 - val_accuracy: 0.5983\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7986 - accuracy: 0.6630 - val_loss: 0.9466 - val_accuracy: 0.6154\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7966 - accuracy: 0.6333 - val_loss: 0.9571 - val_accuracy: 0.6239\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8588 - accuracy: 0.6296 - val_loss: 0.9671 - val_accuracy: 0.6239\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7903 - accuracy: 0.6333 - val_loss: 1.0243 - val_accuracy: 0.5983\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8288 - accuracy: 0.6222 - val_loss: 0.9647 - val_accuracy: 0.5726\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8257 - accuracy: 0.6519 - val_loss: 0.9378 - val_accuracy: 0.5641\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8064 - accuracy: 0.6185 - val_loss: 0.9336 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7822 - accuracy: 0.6444 - val_loss: 0.9851 - val_accuracy: 0.5897\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8208 - accuracy: 0.6519 - val_loss: 0.9216 - val_accuracy: 0.5641\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7910 - accuracy: 0.6296 - val_loss: 0.9270 - val_accuracy: 0.5812\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7965 - accuracy: 0.6593 - val_loss: 0.9269 - val_accuracy: 0.6068\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7997 - accuracy: 0.6333 - val_loss: 0.9214 - val_accuracy: 0.4444\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7877 - accuracy: 0.6148 - val_loss: 0.9444 - val_accuracy: 0.5812\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7892 - accuracy: 0.6519 - val_loss: 0.9652 - val_accuracy: 0.5983\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7945 - accuracy: 0.6296 - val_loss: 0.9227 - val_accuracy: 0.5983\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7835 - accuracy: 0.6296 - val_loss: 0.9295 - val_accuracy: 0.5812\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7946 - accuracy: 0.6370 - val_loss: 0.9180 - val_accuracy: 0.5812\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7851 - accuracy: 0.6185 - val_loss: 0.9520 - val_accuracy: 0.6068\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8184 - accuracy: 0.6593 - val_loss: 0.9303 - val_accuracy: 0.5556\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8632 - accuracy: 0.6185 - val_loss: 0.9400 - val_accuracy: 0.5897\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7812 - accuracy: 0.6593 - val_loss: 0.9315 - val_accuracy: 0.6068\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7780 - accuracy: 0.6407 - val_loss: 0.9184 - val_accuracy: 0.5983\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7782 - accuracy: 0.6185 - val_loss: 0.9331 - val_accuracy: 0.6239\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7844 - accuracy: 0.6667 - val_loss: 0.9344 - val_accuracy: 0.6154\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7872 - accuracy: 0.6481 - val_loss: 0.9401 - val_accuracy: 0.6068\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7914 - accuracy: 0.6444 - val_loss: 0.9410 - val_accuracy: 0.6068\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7827 - accuracy: 0.6370 - val_loss: 0.9214 - val_accuracy: 0.5812\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7815 - accuracy: 0.6407 - val_loss: 0.9476 - val_accuracy: 0.5983\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7839 - accuracy: 0.6704 - val_loss: 0.9307 - val_accuracy: 0.6239\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7834 - accuracy: 0.6370 - val_loss: 0.9318 - val_accuracy: 0.5983\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7908 - accuracy: 0.6519 - val_loss: 0.9956 - val_accuracy: 0.6068\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8097 - accuracy: 0.6593 - val_loss: 0.9210 - val_accuracy: 0.6068\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7874 - accuracy: 0.6519 - val_loss: 1.0548 - val_accuracy: 0.6154\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9838 - accuracy: 0.6444 - val_loss: 1.3395 - val_accuracy: 0.5983\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0932 - accuracy: 0.6111 - val_loss: 1.1712 - val_accuracy: 0.5897\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9105 - accuracy: 0.6556 - val_loss: 0.9894 - val_accuracy: 0.5897\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8665 - accuracy: 0.5963 - val_loss: 0.9379 - val_accuracy: 0.5897\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8385 - accuracy: 0.6074 - val_loss: 0.9363 - val_accuracy: 0.6154\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8012 - accuracy: 0.6370 - val_loss: 0.9576 - val_accuracy: 0.6239\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7810 - accuracy: 0.6481 - val_loss: 0.9428 - val_accuracy: 0.5897\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8060 - accuracy: 0.6444 - val_loss: 0.9176 - val_accuracy: 0.5897\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7880 - accuracy: 0.6407 - val_loss: 0.9727 - val_accuracy: 0.6068\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8255 - accuracy: 0.6630 - val_loss: 0.9424 - val_accuracy: 0.6068\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7728 - accuracy: 0.6407 - val_loss: 0.9626 - val_accuracy: 0.5897\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8114 - accuracy: 0.6296 - val_loss: 1.0356 - val_accuracy: 0.6154\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8917 - accuracy: 0.6704 - val_loss: 0.9654 - val_accuracy: 0.6239\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7768 - accuracy: 0.6222 - val_loss: 1.0486 - val_accuracy: 0.6068\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8161 - accuracy: 0.6519 - val_loss: 0.9804 - val_accuracy: 0.6068\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8190 - accuracy: 0.6630 - val_loss: 0.9140 - val_accuracy: 0.5983\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8908 - accuracy: 0.6370 - val_loss: 0.9646 - val_accuracy: 0.5897\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8766 - accuracy: 0.6519 - val_loss: 1.1618 - val_accuracy: 0.5983\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9166 - accuracy: 0.6481 - val_loss: 0.9828 - val_accuracy: 0.5812\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8402 - accuracy: 0.6111 - val_loss: 0.9709 - val_accuracy: 0.5983\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8143 - accuracy: 0.6519 - val_loss: 0.9813 - val_accuracy: 0.5897\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8042 - accuracy: 0.6296 - val_loss: 0.9334 - val_accuracy: 0.5983\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7814 - accuracy: 0.6444 - val_loss: 0.9589 - val_accuracy: 0.6325\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7774 - accuracy: 0.6667 - val_loss: 0.9167 - val_accuracy: 0.5897\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7796 - accuracy: 0.6370 - val_loss: 0.9380 - val_accuracy: 0.6325\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7706 - accuracy: 0.6630 - val_loss: 0.9190 - val_accuracy: 0.6068\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7727 - accuracy: 0.6296 - val_loss: 0.9167 - val_accuracy: 0.5897\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.7714 - accuracy: 0.6481 - val_loss: 0.9325 - val_accuracy: 0.6239\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8226 - accuracy: 0.6519 - val_loss: 1.1104 - val_accuracy: 0.6154\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9909 - accuracy: 0.6630 - val_loss: 1.1580 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8979 - accuracy: 0.6333 - val_loss: 0.9182 - val_accuracy: 0.5897\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8306 - accuracy: 0.6444 - val_loss: 1.0346 - val_accuracy: 0.6068\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9098 - accuracy: 0.6519 - val_loss: 1.0345 - val_accuracy: 0.5897\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8483 - accuracy: 0.6074 - val_loss: 0.9714 - val_accuracy: 0.5897\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9499 - accuracy: 0.6519 - val_loss: 1.2666 - val_accuracy: 0.5983\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9556 - accuracy: 0.6556 - val_loss: 1.0429 - val_accuracy: 0.5641\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8941 - accuracy: 0.5815 - val_loss: 1.0962 - val_accuracy: 0.5983\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9256 - accuracy: 0.6148 - val_loss: 0.9841 - val_accuracy: 0.5812\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7944 - accuracy: 0.6259 - val_loss: 0.9835 - val_accuracy: 0.5726\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7886 - accuracy: 0.6481 - val_loss: 1.0892 - val_accuracy: 0.6068\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8695 - accuracy: 0.6185 - val_loss: 0.9889 - val_accuracy: 0.6068\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7870 - accuracy: 0.6370 - val_loss: 0.9973 - val_accuracy: 0.6239\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8457 - accuracy: 0.6556 - val_loss: 0.9937 - val_accuracy: 0.6239\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8060 - accuracy: 0.6296 - val_loss: 0.9766 - val_accuracy: 0.6154\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7766 - accuracy: 0.6519 - val_loss: 0.9834 - val_accuracy: 0.6239\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8210 - accuracy: 0.6296 - val_loss: 0.9312 - val_accuracy: 0.5556\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 1.0821 - accuracy: 0.6185 - val_loss: 1.1384 - val_accuracy: 0.5812\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8593 - accuracy: 0.6444 - val_loss: 1.2141 - val_accuracy: 0.5983\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9707 - accuracy: 0.6556 - val_loss: 1.0777 - val_accuracy: 0.6068\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8578 - accuracy: 0.6296 - val_loss: 0.9296 - val_accuracy: 0.6239\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7826 - accuracy: 0.6519 - val_loss: 0.9580 - val_accuracy: 0.6239\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7731 - accuracy: 0.6630 - val_loss: 0.9080 - val_accuracy: 0.6068\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7700 - accuracy: 0.6407 - val_loss: 0.9182 - val_accuracy: 0.6068\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7686 - accuracy: 0.6519 - val_loss: 0.9232 - val_accuracy: 0.5897\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7673 - accuracy: 0.6556 - val_loss: 0.9249 - val_accuracy: 0.6154\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7647 - accuracy: 0.6630 - val_loss: 0.9244 - val_accuracy: 0.6154\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7740 - accuracy: 0.6556 - val_loss: 0.9344 - val_accuracy: 0.6068\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7578 - accuracy: 0.6519 - val_loss: 0.9264 - val_accuracy: 0.6154\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7736 - accuracy: 0.6333 - val_loss: 0.9295 - val_accuracy: 0.6239\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.7669 - accuracy: 0.6481 - val_loss: 1.0047 - val_accuracy: 0.6068\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8377 - accuracy: 0.6667 - val_loss: 0.9712 - val_accuracy: 0.6239\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7767 - accuracy: 0.6296 - val_loss: 0.9508 - val_accuracy: 0.6239\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7886 - accuracy: 0.6481 - val_loss: 1.0152 - val_accuracy: 0.5983\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7998 - accuracy: 0.6630 - val_loss: 0.9173 - val_accuracy: 0.5812\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8568 - accuracy: 0.6222 - val_loss: 0.9523 - val_accuracy: 0.6068\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9730 - accuracy: 0.6481 - val_loss: 1.3428 - val_accuracy: 0.6154\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0198 - accuracy: 0.6593 - val_loss: 1.0646 - val_accuracy: 0.6068\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9308 - accuracy: 0.5926 - val_loss: 1.1056 - val_accuracy: 0.5726\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9248 - accuracy: 0.6296 - val_loss: 1.0709 - val_accuracy: 0.5983\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9577 - accuracy: 0.6185 - val_loss: 1.0615 - val_accuracy: 0.6068\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9054 - accuracy: 0.6481 - val_loss: 1.0067 - val_accuracy: 0.6154\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9164 - accuracy: 0.6074 - val_loss: 0.9470 - val_accuracy: 0.6239\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.1056 - accuracy: 0.6333 - val_loss: 1.4856 - val_accuracy: 0.5470\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0685 - accuracy: 0.5926 - val_loss: 0.9563 - val_accuracy: 0.6068\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7804 - accuracy: 0.6259 - val_loss: 1.0200 - val_accuracy: 0.5812\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8242 - accuracy: 0.6259 - val_loss: 0.9839 - val_accuracy: 0.6239\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7857 - accuracy: 0.6407 - val_loss: 1.0069 - val_accuracy: 0.6068\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 359us/step - loss: 0.7874 - accuracy: 0.6333 - val_loss: 0.9474 - val_accuracy: 0.5812\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7759 - accuracy: 0.6444 - val_loss: 0.9478 - val_accuracy: 0.5897\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7620 - accuracy: 0.6593 - val_loss: 0.9706 - val_accuracy: 0.5983\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7651 - accuracy: 0.6593 - val_loss: 0.9340 - val_accuracy: 0.6068\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7612 - accuracy: 0.6407 - val_loss: 0.9234 - val_accuracy: 0.5983\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7777 - accuracy: 0.6296 - val_loss: 0.9697 - val_accuracy: 0.6068\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8184 - accuracy: 0.6667 - val_loss: 1.0290 - val_accuracy: 0.6239\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7949 - accuracy: 0.6778 - val_loss: 0.9475 - val_accuracy: 0.5812\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7597 - accuracy: 0.6519 - val_loss: 0.9692 - val_accuracy: 0.6154\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7770 - accuracy: 0.6556 - val_loss: 0.9294 - val_accuracy: 0.6154\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7438 - accuracy: 0.6593 - val_loss: 0.9380 - val_accuracy: 0.6154\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7609 - accuracy: 0.6741 - val_loss: 0.9118 - val_accuracy: 0.6154\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8023 - accuracy: 0.6481 - val_loss: 0.9769 - val_accuracy: 0.6154\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7802 - accuracy: 0.6852 - val_loss: 0.9125 - val_accuracy: 0.6154\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7962 - accuracy: 0.6519 - val_loss: 0.9613 - val_accuracy: 0.6154\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7929 - accuracy: 0.6815 - val_loss: 0.9425 - val_accuracy: 0.6154\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7530 - accuracy: 0.6704 - val_loss: 0.9408 - val_accuracy: 0.5897\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7563 - accuracy: 0.6630 - val_loss: 0.9775 - val_accuracy: 0.6068\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7628 - accuracy: 0.6778 - val_loss: 0.9235 - val_accuracy: 0.6239\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7479 - accuracy: 0.6704 - val_loss: 0.9576 - val_accuracy: 0.6239\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7535 - accuracy: 0.6778 - val_loss: 0.9263 - val_accuracy: 0.5983\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.7434 - accuracy: 0.6741 - val_loss: 0.9523 - val_accuracy: 0.5983\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7614 - accuracy: 0.6741 - val_loss: 0.9114 - val_accuracy: 0.6325\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7421 - accuracy: 0.6741 - val_loss: 0.9334 - val_accuracy: 0.6410\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7522 - accuracy: 0.6704 - val_loss: 0.9540 - val_accuracy: 0.6068\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7531 - accuracy: 0.6815 - val_loss: 0.9134 - val_accuracy: 0.6068\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7483 - accuracy: 0.6704 - val_loss: 0.9238 - val_accuracy: 0.6239\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7466 - accuracy: 0.6778 - val_loss: 0.9309 - val_accuracy: 0.6068\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7474 - accuracy: 0.6704 - val_loss: 0.9402 - val_accuracy: 0.6068\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7509 - accuracy: 0.6741 - val_loss: 0.9332 - val_accuracy: 0.6154\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7592 - accuracy: 0.6815 - val_loss: 0.9239 - val_accuracy: 0.6239\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7377 - accuracy: 0.6926 - val_loss: 0.9225 - val_accuracy: 0.6239\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7573 - accuracy: 0.6704 - val_loss: 0.9618 - val_accuracy: 0.5983\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7672 - accuracy: 0.6741 - val_loss: 0.9315 - val_accuracy: 0.6325\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7515 - accuracy: 0.6815 - val_loss: 0.9567 - val_accuracy: 0.6325\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7533 - accuracy: 0.6667 - val_loss: 0.9436 - val_accuracy: 0.6068\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7640 - accuracy: 0.6778 - val_loss: 0.9142 - val_accuracy: 0.6325\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7493 - accuracy: 0.6593 - val_loss: 0.9784 - val_accuracy: 0.6410\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7938 - accuracy: 0.6222 - val_loss: 0.9418 - val_accuracy: 0.6325\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7551 - accuracy: 0.6667 - val_loss: 0.9370 - val_accuracy: 0.6154\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7647 - accuracy: 0.6889 - val_loss: 1.0164 - val_accuracy: 0.6239\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7870 - accuracy: 0.6481 - val_loss: 0.9158 - val_accuracy: 0.6239\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7670 - accuracy: 0.6481 - val_loss: 0.9446 - val_accuracy: 0.6496\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7666 - accuracy: 0.6704 - val_loss: 0.9309 - val_accuracy: 0.6581\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7423 - accuracy: 0.6963 - val_loss: 0.9259 - val_accuracy: 0.6154\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7456 - accuracy: 0.6852 - val_loss: 0.9146 - val_accuracy: 0.5983\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7430 - accuracy: 0.6778 - val_loss: 0.9308 - val_accuracy: 0.6154\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7492 - accuracy: 0.6741 - val_loss: 0.9346 - val_accuracy: 0.6325\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7377 - accuracy: 0.6741 - val_loss: 0.9175 - val_accuracy: 0.6154\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7537 - accuracy: 0.6667 - val_loss: 0.9195 - val_accuracy: 0.6325\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7572 - accuracy: 0.6519 - val_loss: 0.9753 - val_accuracy: 0.6154\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7746 - accuracy: 0.6778 - val_loss: 0.9433 - val_accuracy: 0.6325\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7609 - accuracy: 0.6778 - val_loss: 0.9197 - val_accuracy: 0.6154\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7644 - accuracy: 0.6667 - val_loss: 0.9991 - val_accuracy: 0.6325\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7942 - accuracy: 0.6926 - val_loss: 0.9289 - val_accuracy: 0.6239\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7713 - accuracy: 0.6519 - val_loss: 0.9631 - val_accuracy: 0.6239\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9642 - accuracy: 0.6444 - val_loss: 1.2681 - val_accuracy: 0.6410\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9207 - accuracy: 0.6741 - val_loss: 1.0251 - val_accuracy: 0.5726\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7844 - accuracy: 0.6407 - val_loss: 1.0992 - val_accuracy: 0.6154\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8877 - accuracy: 0.6185 - val_loss: 0.9769 - val_accuracy: 0.6068\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7898 - accuracy: 0.6519 - val_loss: 0.9561 - val_accuracy: 0.6239\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7943 - accuracy: 0.6815 - val_loss: 0.9473 - val_accuracy: 0.6410\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8054 - accuracy: 0.6556 - val_loss: 1.0300 - val_accuracy: 0.6325\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 1.0673 - accuracy: 0.6148 - val_loss: 1.5117 - val_accuracy: 0.5897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0706 - accuracy: 0.6519 - val_loss: 0.9672 - val_accuracy: 0.5726\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9017 - accuracy: 0.6111 - val_loss: 1.0889 - val_accuracy: 0.5897\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9611 - accuracy: 0.6111 - val_loss: 1.1591 - val_accuracy: 0.5983\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8263 - accuracy: 0.6481 - val_loss: 1.0688 - val_accuracy: 0.5641\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8100 - accuracy: 0.6370 - val_loss: 0.9751 - val_accuracy: 0.6154\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7963 - accuracy: 0.6556 - val_loss: 1.0041 - val_accuracy: 0.6068\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8656 - accuracy: 0.6444 - val_loss: 0.9283 - val_accuracy: 0.5897\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7723 - accuracy: 0.6704 - val_loss: 1.2269 - val_accuracy: 0.6239\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9363 - accuracy: 0.6704 - val_loss: 1.0362 - val_accuracy: 0.6154\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8196 - accuracy: 0.6296 - val_loss: 1.0245 - val_accuracy: 0.6068\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8489 - accuracy: 0.6222 - val_loss: 0.9897 - val_accuracy: 0.6068\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8155 - accuracy: 0.6296 - val_loss: 1.0001 - val_accuracy: 0.6410\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9128 - accuracy: 0.6407 - val_loss: 1.0538 - val_accuracy: 0.6154\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7885 - accuracy: 0.6444 - val_loss: 1.0150 - val_accuracy: 0.6068\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7989 - accuracy: 0.6296 - val_loss: 0.9223 - val_accuracy: 0.6325\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7763 - accuracy: 0.6593 - val_loss: 1.0130 - val_accuracy: 0.6325\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7635 - accuracy: 0.6741 - val_loss: 0.9352 - val_accuracy: 0.6581\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7491 - accuracy: 0.6481 - val_loss: 0.9481 - val_accuracy: 0.6239\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7684 - accuracy: 0.6963 - val_loss: 1.0199 - val_accuracy: 0.6325\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7735 - accuracy: 0.6926 - val_loss: 0.9805 - val_accuracy: 0.5983\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7608 - accuracy: 0.6926 - val_loss: 1.1067 - val_accuracy: 0.6325\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8473 - accuracy: 0.6815 - val_loss: 0.9672 - val_accuracy: 0.6068\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7480 - accuracy: 0.6519 - val_loss: 0.9588 - val_accuracy: 0.5983\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7721 - accuracy: 0.6481 - val_loss: 0.9706 - val_accuracy: 0.6154\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.71 - 0s 57us/step - loss: 0.7478 - accuracy: 0.6778 - val_loss: 0.9129 - val_accuracy: 0.6154\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7415 - accuracy: 0.6704 - val_loss: 0.9510 - val_accuracy: 0.6410\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7534 - accuracy: 0.6815 - val_loss: 0.9499 - val_accuracy: 0.6239\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7751 - accuracy: 0.6593 - val_loss: 0.9483 - val_accuracy: 0.6239\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7662 - accuracy: 0.6556 - val_loss: 0.9065 - val_accuracy: 0.6325\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7373 - accuracy: 0.6852 - val_loss: 0.9391 - val_accuracy: 0.6410\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8241 - accuracy: 0.6593 - val_loss: 0.9687 - val_accuracy: 0.6068\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7724 - accuracy: 0.6889 - val_loss: 1.0074 - val_accuracy: 0.6068\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7567 - accuracy: 0.6889 - val_loss: 0.9770 - val_accuracy: 0.5726\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8987 - accuracy: 0.6556 - val_loss: 0.9309 - val_accuracy: 0.6410\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7968 - accuracy: 0.6630 - val_loss: 1.0139 - val_accuracy: 0.6239\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7650 - accuracy: 0.6704 - val_loss: 1.0095 - val_accuracy: 0.6154\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7948 - accuracy: 0.6593 - val_loss: 0.9627 - val_accuracy: 0.6325\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7553 - accuracy: 0.6926 - val_loss: 0.9137 - val_accuracy: 0.6325\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7447 - accuracy: 0.6704 - val_loss: 0.9422 - val_accuracy: 0.6068\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7453 - accuracy: 0.6778 - val_loss: 0.9865 - val_accuracy: 0.6068\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7419 - accuracy: 0.6630 - val_loss: 0.9427 - val_accuracy: 0.6154\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7385 - accuracy: 0.6667 - val_loss: 0.9317 - val_accuracy: 0.6239\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7400 - accuracy: 0.6704 - val_loss: 0.9666 - val_accuracy: 0.6325\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7463 - accuracy: 0.6630 - val_loss: 0.9243 - val_accuracy: 0.6239\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7774 - accuracy: 0.6630 - val_loss: 0.9893 - val_accuracy: 0.6239\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8383 - accuracy: 0.6889 - val_loss: 1.0950 - val_accuracy: 0.6325\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8132 - accuracy: 0.6852 - val_loss: 0.9164 - val_accuracy: 0.6239\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7344 - accuracy: 0.6704 - val_loss: 0.9462 - val_accuracy: 0.6325\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7366 - accuracy: 0.6704 - val_loss: 0.9551 - val_accuracy: 0.6154\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7366 - accuracy: 0.6815 - val_loss: 0.9240 - val_accuracy: 0.6325\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7339 - accuracy: 0.6741 - val_loss: 0.9528 - val_accuracy: 0.6410\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7291 - accuracy: 0.6704 - val_loss: 0.9070 - val_accuracy: 0.6410\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7342 - accuracy: 0.6704 - val_loss: 0.9113 - val_accuracy: 0.6325\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7504 - accuracy: 0.6593 - val_loss: 0.9471 - val_accuracy: 0.5983\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7687 - accuracy: 0.6556 - val_loss: 0.9271 - val_accuracy: 0.6068\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7454 - accuracy: 0.6630 - val_loss: 0.9489 - val_accuracy: 0.6239\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7495 - accuracy: 0.6778 - val_loss: 0.9244 - val_accuracy: 0.6325\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7285 - accuracy: 0.6889 - val_loss: 0.9186 - val_accuracy: 0.6410\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7399 - accuracy: 0.6926 - val_loss: 0.9274 - val_accuracy: 0.6068\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7367 - accuracy: 0.6704 - val_loss: 0.9299 - val_accuracy: 0.6239\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7247 - accuracy: 0.6963 - val_loss: 0.9368 - val_accuracy: 0.6068\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7258 - accuracy: 0.7000 - val_loss: 0.9227 - val_accuracy: 0.6325\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7332 - accuracy: 0.6741 - val_loss: 0.9362 - val_accuracy: 0.6239\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7317 - accuracy: 0.6852 - val_loss: 0.9438 - val_accuracy: 0.6581\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7282 - accuracy: 0.6963 - val_loss: 0.9405 - val_accuracy: 0.6325\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7302 - accuracy: 0.6926 - val_loss: 0.9149 - val_accuracy: 0.6496\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7240 - accuracy: 0.6889 - val_loss: 0.9674 - val_accuracy: 0.6239\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7480 - accuracy: 0.6815 - val_loss: 0.9208 - val_accuracy: 0.6410\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.7324 - accuracy: 0.6815 - val_loss: 0.9779 - val_accuracy: 0.6154\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8442 - accuracy: 0.6778 - val_loss: 1.1139 - val_accuracy: 0.6325\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8097 - accuracy: 0.6778 - val_loss: 0.9432 - val_accuracy: 0.6068\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8393 - accuracy: 0.6407 - val_loss: 1.0705 - val_accuracy: 0.6154\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9795 - accuracy: 0.6407 - val_loss: 1.3320 - val_accuracy: 0.6325\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 1.0817 - accuracy: 0.6630 - val_loss: 1.2544 - val_accuracy: 0.6325\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9384 - accuracy: 0.6741 - val_loss: 1.0513 - val_accuracy: 0.6325\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7925 - accuracy: 0.6444 - val_loss: 1.2367 - val_accuracy: 0.5983\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8570 - accuracy: 0.6481 - val_loss: 1.0883 - val_accuracy: 0.6154\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8980 - accuracy: 0.6889 - val_loss: 1.1161 - val_accuracy: 0.6154\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8545 - accuracy: 0.6852 - val_loss: 0.9281 - val_accuracy: 0.5897\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7957 - accuracy: 0.6407 - val_loss: 0.9830 - val_accuracy: 0.6325\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7770 - accuracy: 0.6704 - val_loss: 0.9745 - val_accuracy: 0.6239\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7449 - accuracy: 0.6704 - val_loss: 0.9175 - val_accuracy: 0.6325\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7393 - accuracy: 0.6593 - val_loss: 0.9528 - val_accuracy: 0.6325\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7341 - accuracy: 0.6741 - val_loss: 0.9163 - val_accuracy: 0.6325\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7548 - accuracy: 0.6407 - val_loss: 0.9534 - val_accuracy: 0.6325\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7568 - accuracy: 0.6556 - val_loss: 1.0197 - val_accuracy: 0.6154\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7700 - accuracy: 0.6593 - val_loss: 0.9715 - val_accuracy: 0.6325\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8006 - accuracy: 0.6815 - val_loss: 1.0407 - val_accuracy: 0.6496\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7756 - accuracy: 0.6926 - val_loss: 1.0316 - val_accuracy: 0.6154\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8152 - accuracy: 0.6074 - val_loss: 0.9850 - val_accuracy: 0.6410\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7474 - accuracy: 0.6667 - val_loss: 0.9484 - val_accuracy: 0.6325\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7622 - accuracy: 0.6407 - val_loss: 0.9798 - val_accuracy: 0.6496\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7391 - accuracy: 0.6741 - val_loss: 0.9191 - val_accuracy: 0.6239\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7288 - accuracy: 0.6963 - val_loss: 0.9354 - val_accuracy: 0.6325\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7302 - accuracy: 0.6630 - val_loss: 0.9789 - val_accuracy: 0.6410\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7591 - accuracy: 0.6926 - val_loss: 0.9528 - val_accuracy: 0.6239\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7273 - accuracy: 0.6963 - val_loss: 0.9455 - val_accuracy: 0.6239\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7885 - accuracy: 0.6556 - val_loss: 1.0184 - val_accuracy: 0.6410\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7449 - accuracy: 0.6963 - val_loss: 0.9086 - val_accuracy: 0.6410\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7272 - accuracy: 0.6815 - val_loss: 0.9468 - val_accuracy: 0.6410\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7240 - accuracy: 0.6889 - val_loss: 0.9365 - val_accuracy: 0.6154\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7258 - accuracy: 0.6778 - val_loss: 0.9574 - val_accuracy: 0.6154\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7406 - accuracy: 0.6889 - val_loss: 0.9282 - val_accuracy: 0.6239\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7296 - accuracy: 0.6704 - val_loss: 0.9250 - val_accuracy: 0.6410\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.7233 - accuracy: 0.6815 - val_loss: 0.9186 - val_accuracy: 0.6496\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7199 - accuracy: 0.6963 - val_loss: 0.9043 - val_accuracy: 0.6410\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.7225 - accuracy: 0.7000 - val_loss: 0.9581 - val_accuracy: 0.6325\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7315 - accuracy: 0.6889 - val_loss: 0.9134 - val_accuracy: 0.6410\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.7315 - accuracy: 0.6889 - val_loss: 0.9549 - val_accuracy: 0.6325\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7401 - accuracy: 0.6926 - val_loss: 0.9111 - val_accuracy: 0.6496\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7235 - accuracy: 0.7037 - val_loss: 0.9313 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7170 - accuracy: 0.6963 - val_loss: 0.9416 - val_accuracy: 0.6325\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.7272 - accuracy: 0.6926 - val_loss: 0.9226 - val_accuracy: 0.6496\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7322 - accuracy: 0.6778 - val_loss: 0.9617 - val_accuracy: 0.6325\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.7904 - accuracy: 0.6963 - val_loss: 1.0723 - val_accuracy: 0.6325\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7814 - accuracy: 0.6741 - val_loss: 0.9652 - val_accuracy: 0.6325\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8019 - accuracy: 0.6889 - val_loss: 1.1602 - val_accuracy: 0.6410\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8398 - accuracy: 0.6889 - val_loss: 0.9420 - val_accuracy: 0.6325\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7885 - accuracy: 0.6333 - val_loss: 1.0533 - val_accuracy: 0.6410\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 1.0379 - accuracy: 0.6259 - val_loss: 1.3431 - val_accuracy: 0.6325\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9284 - accuracy: 0.6519 - val_loss: 1.6574 - val_accuracy: 0.5983\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 1.1691 - accuracy: 0.6370 - val_loss: 1.2822 - val_accuracy: 0.5556\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 1.1550 - accuracy: 0.5926 - val_loss: 1.4431 - val_accuracy: 0.5214\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 1.0662 - accuracy: 0.5963 - val_loss: 0.9841 - val_accuracy: 0.6410\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 1.0437 - accuracy: 0.6259 - val_loss: 1.0007 - val_accuracy: 0.6325\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8873 - accuracy: 0.6481 - val_loss: 1.3024 - val_accuracy: 0.5641\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 1.1025 - accuracy: 0.5889 - val_loss: 1.1531 - val_accuracy: 0.6239\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8253 - accuracy: 0.6556 - val_loss: 1.1056 - val_accuracy: 0.5983\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.8612 - accuracy: 0.6519 - val_loss: 1.1464 - val_accuracy: 0.6239\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8162 - accuracy: 0.6370 - val_loss: 1.0225 - val_accuracy: 0.6239\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7696 - accuracy: 0.6407 - val_loss: 0.9923 - val_accuracy: 0.6667\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7698 - accuracy: 0.6704 - val_loss: 0.9425 - val_accuracy: 0.6325\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7230 - accuracy: 0.6852 - val_loss: 0.9274 - val_accuracy: 0.6325\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7251 - accuracy: 0.6926 - val_loss: 0.9434 - val_accuracy: 0.6239\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7160 - accuracy: 0.6815 - val_loss: 0.9476 - val_accuracy: 0.6068\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7266 - accuracy: 0.6667 - val_loss: 0.9699 - val_accuracy: 0.6154\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7338 - accuracy: 0.6889 - val_loss: 0.9373 - val_accuracy: 0.6325\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7320 - accuracy: 0.6519 - val_loss: 0.9819 - val_accuracy: 0.6239\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7807 - accuracy: 0.6889 - val_loss: 1.0064 - val_accuracy: 0.6239\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7492 - accuracy: 0.6815 - val_loss: 0.9865 - val_accuracy: 0.6154\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7492 - accuracy: 0.6704 - val_loss: 1.0298 - val_accuracy: 0.6325\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.7791 - accuracy: 0.6852 - val_loss: 0.9823 - val_accuracy: 0.6154\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7318 - accuracy: 0.6741 - val_loss: 0.9802 - val_accuracy: 0.6154\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7363 - accuracy: 0.6667 - val_loss: 0.9943 - val_accuracy: 0.6496\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7556 - accuracy: 0.6556 - val_loss: 0.9479 - val_accuracy: 0.6667\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7502 - accuracy: 0.6704 - val_loss: 0.9352 - val_accuracy: 0.6068\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7289 - accuracy: 0.6889 - val_loss: 0.9556 - val_accuracy: 0.6154\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7206 - accuracy: 0.6852 - val_loss: 0.9375 - val_accuracy: 0.6154\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7213 - accuracy: 0.6778 - val_loss: 0.9525 - val_accuracy: 0.6068\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7285 - accuracy: 0.6889 - val_loss: 0.9197 - val_accuracy: 0.6239\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7213 - accuracy: 0.6667 - val_loss: 0.9460 - val_accuracy: 0.6410\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7161 - accuracy: 0.6963 - val_loss: 0.9096 - val_accuracy: 0.6410\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7236 - accuracy: 0.7000 - val_loss: 0.9429 - val_accuracy: 0.6325\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7257 - accuracy: 0.6889 - val_loss: 0.9497 - val_accuracy: 0.6496\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7202 - accuracy: 0.6778 - val_loss: 0.9410 - val_accuracy: 0.6239\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7220 - accuracy: 0.6741 - val_loss: 0.9481 - val_accuracy: 0.6239\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7191 - accuracy: 0.6889 - val_loss: 0.9499 - val_accuracy: 0.6239\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7224 - accuracy: 0.7000 - val_loss: 0.9390 - val_accuracy: 0.6325\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7130 - accuracy: 0.7000 - val_loss: 0.9319 - val_accuracy: 0.6239\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7139 - accuracy: 0.6926 - val_loss: 0.9440 - val_accuracy: 0.6154\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7173 - accuracy: 0.6889 - val_loss: 0.9464 - val_accuracy: 0.6325\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7081 - accuracy: 0.7037 - val_loss: 0.9437 - val_accuracy: 0.6154\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7160 - accuracy: 0.6778 - val_loss: 0.9373 - val_accuracy: 0.6325\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7229 - accuracy: 0.6852 - val_loss: 0.9408 - val_accuracy: 0.6410\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7107 - accuracy: 0.6889 - val_loss: 0.9479 - val_accuracy: 0.6496\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7144 - accuracy: 0.6815 - val_loss: 0.9427 - val_accuracy: 0.6325\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7189 - accuracy: 0.6889 - val_loss: 0.9283 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7082 - accuracy: 0.6963 - val_loss: 0.9418 - val_accuracy: 0.6239\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7140 - accuracy: 0.6889 - val_loss: 0.9334 - val_accuracy: 0.6325\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.7171 - accuracy: 0.7000 - val_loss: 0.9563 - val_accuracy: 0.6496\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7156 - accuracy: 0.7037 - val_loss: 0.9320 - val_accuracy: 0.6581\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7077 - accuracy: 0.7000 - val_loss: 0.9199 - val_accuracy: 0.6325\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7160 - accuracy: 0.6815 - val_loss: 0.9414 - val_accuracy: 0.6410\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7320 - accuracy: 0.6593 - val_loss: 0.9952 - val_accuracy: 0.6154\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7252 - accuracy: 0.6889 - val_loss: 0.9198 - val_accuracy: 0.6239\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7117 - accuracy: 0.6852 - val_loss: 0.9330 - val_accuracy: 0.6239\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7280 - accuracy: 0.6889 - val_loss: 0.9129 - val_accuracy: 0.6581\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7846 - accuracy: 0.6815 - val_loss: 0.9412 - val_accuracy: 0.6325\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7495 - accuracy: 0.6778 - val_loss: 0.9970 - val_accuracy: 0.6154\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7940 - accuracy: 0.6593 - val_loss: 0.9272 - val_accuracy: 0.6496\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7149 - accuracy: 0.6963 - val_loss: 0.9624 - val_accuracy: 0.6239\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7461 - accuracy: 0.6852 - val_loss: 0.9169 - val_accuracy: 0.6496\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8104 - accuracy: 0.6593 - val_loss: 1.0368 - val_accuracy: 0.6410\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0100 - accuracy: 0.6704 - val_loss: 1.4725 - val_accuracy: 0.6496\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.0485 - accuracy: 0.6704 - val_loss: 1.3622 - val_accuracy: 0.6239\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9177 - accuracy: 0.6630 - val_loss: 1.1055 - val_accuracy: 0.6239\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9736 - accuracy: 0.6000 - val_loss: 1.0606 - val_accuracy: 0.5812\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7576 - accuracy: 0.6815 - val_loss: 1.0412 - val_accuracy: 0.6410\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8251 - accuracy: 0.6815 - val_loss: 1.0224 - val_accuracy: 0.6325\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7584 - accuracy: 0.6889 - val_loss: 0.9674 - val_accuracy: 0.6154\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7420 - accuracy: 0.6556 - val_loss: 0.9875 - val_accuracy: 0.6325\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7458 - accuracy: 0.6889 - val_loss: 0.9187 - val_accuracy: 0.6496\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7101 - accuracy: 0.6926 - val_loss: 0.9375 - val_accuracy: 0.6581\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7088 - accuracy: 0.6963 - val_loss: 0.9346 - val_accuracy: 0.6581\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7082 - accuracy: 0.6926 - val_loss: 0.9446 - val_accuracy: 0.6410\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7466 - accuracy: 0.6630 - val_loss: 0.9665 - val_accuracy: 0.6410\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7622 - accuracy: 0.6778 - val_loss: 0.9595 - val_accuracy: 0.6410\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7154 - accuracy: 0.6926 - val_loss: 0.9644 - val_accuracy: 0.6325\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7131 - accuracy: 0.6778 - val_loss: 0.9794 - val_accuracy: 0.6410\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7293 - accuracy: 0.6963 - val_loss: 0.9431 - val_accuracy: 0.6410\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7055 - accuracy: 0.6852 - val_loss: 0.9199 - val_accuracy: 0.6410\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7213 - accuracy: 0.6815 - val_loss: 0.9442 - val_accuracy: 0.6239\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7100 - accuracy: 0.6815 - val_loss: 0.9564 - val_accuracy: 0.5983\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7219 - accuracy: 0.6778 - val_loss: 1.0022 - val_accuracy: 0.6154\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7613 - accuracy: 0.6963 - val_loss: 0.9811 - val_accuracy: 0.6154\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7100 - accuracy: 0.6926 - val_loss: 0.9337 - val_accuracy: 0.6410\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7144 - accuracy: 0.6815 - val_loss: 0.9386 - val_accuracy: 0.6325\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7271 - accuracy: 0.6963 - val_loss: 0.9329 - val_accuracy: 0.6325\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7315 - accuracy: 0.6926 - val_loss: 0.9170 - val_accuracy: 0.6496\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7870 - accuracy: 0.6778 - val_loss: 0.9327 - val_accuracy: 0.6325\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9134 - accuracy: 0.6852 - val_loss: 1.3753 - val_accuracy: 0.6410\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0303 - accuracy: 0.6815 - val_loss: 1.1992 - val_accuracy: 0.6325\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8631 - accuracy: 0.6741 - val_loss: 1.0027 - val_accuracy: 0.6068\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7803 - accuracy: 0.6481 - val_loss: 1.1277 - val_accuracy: 0.6068\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8181 - accuracy: 0.6370 - val_loss: 0.9707 - val_accuracy: 0.6325\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7447 - accuracy: 0.6815 - val_loss: 0.9802 - val_accuracy: 0.6410\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7234 - accuracy: 0.6704 - val_loss: 0.9904 - val_accuracy: 0.6239\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7711 - accuracy: 0.6519 - val_loss: 0.9996 - val_accuracy: 0.6325\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8518 - accuracy: 0.6963 - val_loss: 1.2210 - val_accuracy: 0.6325\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9060 - accuracy: 0.6815 - val_loss: 1.0244 - val_accuracy: 0.6581\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7559 - accuracy: 0.6778 - val_loss: 1.0229 - val_accuracy: 0.5983\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7591 - accuracy: 0.6481 - val_loss: 1.0189 - val_accuracy: 0.6239\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7264 - accuracy: 0.6704 - val_loss: 0.9696 - val_accuracy: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7670 - accuracy: 0.6556 - val_loss: 1.0096 - val_accuracy: 0.6239\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7539 - accuracy: 0.6556 - val_loss: 1.0511 - val_accuracy: 0.6154\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.65 - 0s 58us/step - loss: 0.9021 - accuracy: 0.6667 - val_loss: 1.2775 - val_accuracy: 0.6410\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9662 - accuracy: 0.6704 - val_loss: 1.0682 - val_accuracy: 0.6667\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7649 - accuracy: 0.6815 - val_loss: 1.1259 - val_accuracy: 0.5983\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8646 - accuracy: 0.6111 - val_loss: 1.0161 - val_accuracy: 0.6154\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7413 - accuracy: 0.6444 - val_loss: 0.9276 - val_accuracy: 0.6325\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7282 - accuracy: 0.6889 - val_loss: 0.9834 - val_accuracy: 0.6496\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7147 - accuracy: 0.6815 - val_loss: 0.9444 - val_accuracy: 0.6325\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7191 - accuracy: 0.6704 - val_loss: 0.9783 - val_accuracy: 0.6239\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7755 - accuracy: 0.6963 - val_loss: 1.0046 - val_accuracy: 0.6325\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7323 - accuracy: 0.6889 - val_loss: 1.1920 - val_accuracy: 0.6154\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9308 - accuracy: 0.6556 - val_loss: 0.9935 - val_accuracy: 0.6325\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7937 - accuracy: 0.6926 - val_loss: 1.0454 - val_accuracy: 0.6410\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7169 - accuracy: 0.6963 - val_loss: 0.9821 - val_accuracy: 0.6239\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8634 - accuracy: 0.6630 - val_loss: 0.9571 - val_accuracy: 0.6325\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.7522 - accuracy: 0.6852 - val_loss: 1.0647 - val_accuracy: 0.6325\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.7738 - accuracy: 0.6926 - val_loss: 0.9276 - val_accuracy: 0.6239\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 325us/step - loss: 0.7171 - accuracy: 0.6815 - val_loss: 0.9366 - val_accuracy: 0.6496\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7149 - accuracy: 0.6963 - val_loss: 0.9655 - val_accuracy: 0.6325\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7088 - accuracy: 0.7000 - val_loss: 0.9276 - val_accuracy: 0.6325\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7045 - accuracy: 0.6889 - val_loss: 0.9502 - val_accuracy: 0.6068\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7166 - accuracy: 0.6889 - val_loss: 0.9496 - val_accuracy: 0.6325\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7802 - accuracy: 0.6667 - val_loss: 0.9613 - val_accuracy: 0.6154\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7351 - accuracy: 0.6889 - val_loss: 1.0090 - val_accuracy: 0.6325\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7172 - accuracy: 0.6963 - val_loss: 0.9473 - val_accuracy: 0.6325\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7212 - accuracy: 0.6815 - val_loss: 0.9693 - val_accuracy: 0.6410\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7218 - accuracy: 0.6963 - val_loss: 0.9242 - val_accuracy: 0.6496\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7252 - accuracy: 0.6704 - val_loss: 1.0137 - val_accuracy: 0.6068\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8824 - accuracy: 0.6926 - val_loss: 1.3841 - val_accuracy: 0.6154\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0432 - accuracy: 0.6889 - val_loss: 1.2790 - val_accuracy: 0.6154\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9201 - accuracy: 0.6815 - val_loss: 1.0048 - val_accuracy: 0.6068\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7213 - accuracy: 0.6852 - val_loss: 1.1823 - val_accuracy: 0.5897\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8334 - accuracy: 0.6333 - val_loss: 1.0825 - val_accuracy: 0.6410\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8519 - accuracy: 0.6963 - val_loss: 1.1879 - val_accuracy: 0.6325\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8928 - accuracy: 0.6741 - val_loss: 1.2051 - val_accuracy: 0.6410\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 1.2217 - accuracy: 0.6333 - val_loss: 1.7737 - val_accuracy: 0.5470\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.3797 - accuracy: 0.6000 - val_loss: 1.2489 - val_accuracy: 0.5641\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8580 - accuracy: 0.6519 - val_loss: 1.1576 - val_accuracy: 0.6496\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0045 - accuracy: 0.6370 - val_loss: 1.2593 - val_accuracy: 0.6325\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9164 - accuracy: 0.6926 - val_loss: 1.0556 - val_accuracy: 0.6325\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7617 - accuracy: 0.6889 - val_loss: 1.0203 - val_accuracy: 0.6239\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7035 - accuracy: 0.6963 - val_loss: 1.0348 - val_accuracy: 0.6239\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7945 - accuracy: 0.7000 - val_loss: 1.0155 - val_accuracy: 0.6325\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7319 - accuracy: 0.6778 - val_loss: 1.0663 - val_accuracy: 0.6239\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7508 - accuracy: 0.6778 - val_loss: 1.0543 - val_accuracy: 0.6410\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7990 - accuracy: 0.6926 - val_loss: 1.0743 - val_accuracy: 0.6325\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7598 - accuracy: 0.6815 - val_loss: 0.9404 - val_accuracy: 0.6154\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8339 - accuracy: 0.6593 - val_loss: 0.9894 - val_accuracy: 0.6325\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7613 - accuracy: 0.6889 - val_loss: 1.4384 - val_accuracy: 0.6410\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0389 - accuracy: 0.6852 - val_loss: 1.2228 - val_accuracy: 0.6325\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8845 - accuracy: 0.6667 - val_loss: 1.0015 - val_accuracy: 0.6154\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7297 - accuracy: 0.6963 - val_loss: 1.1068 - val_accuracy: 0.5983\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7880 - accuracy: 0.6407 - val_loss: 1.0362 - val_accuracy: 0.6239\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7765 - accuracy: 0.6741 - val_loss: 1.0043 - val_accuracy: 0.6325\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7555 - accuracy: 0.6815 - val_loss: 1.1264 - val_accuracy: 0.6154\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7952 - accuracy: 0.6407 - val_loss: 1.0525 - val_accuracy: 0.6325\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7930 - accuracy: 0.6852 - val_loss: 1.0828 - val_accuracy: 0.6325\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8226 - accuracy: 0.6630 - val_loss: 0.9735 - val_accuracy: 0.6239\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7898 - accuracy: 0.6667 - val_loss: 1.2588 - val_accuracy: 0.5983\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8291 - accuracy: 0.6111 - val_loss: 1.1221 - val_accuracy: 0.6239\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8292 - accuracy: 0.6889 - val_loss: 1.0537 - val_accuracy: 0.6325\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7939 - accuracy: 0.6630 - val_loss: 0.9407 - val_accuracy: 0.6325\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7184 - accuracy: 0.6741 - val_loss: 1.0095 - val_accuracy: 0.6325\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7224 - accuracy: 0.6667 - val_loss: 0.9987 - val_accuracy: 0.6410\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7230 - accuracy: 0.6741 - val_loss: 0.9532 - val_accuracy: 0.6239\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7098 - accuracy: 0.6778 - val_loss: 0.9371 - val_accuracy: 0.6496\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7172 - accuracy: 0.6815 - val_loss: 0.9991 - val_accuracy: 0.6410\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7371 - accuracy: 0.6926 - val_loss: 0.9767 - val_accuracy: 0.6496\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7321 - accuracy: 0.6667 - val_loss: 0.9472 - val_accuracy: 0.6410\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7105 - accuracy: 0.6889 - val_loss: 0.9563 - val_accuracy: 0.6410\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7015 - accuracy: 0.6852 - val_loss: 0.9450 - val_accuracy: 0.6325\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7075 - accuracy: 0.6815 - val_loss: 0.9684 - val_accuracy: 0.6325\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7073 - accuracy: 0.6741 - val_loss: 0.9686 - val_accuracy: 0.6581\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7043 - accuracy: 0.6926 - val_loss: 0.9613 - val_accuracy: 0.6581\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6988 - accuracy: 0.6926 - val_loss: 0.9633 - val_accuracy: 0.6410\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7026 - accuracy: 0.6926 - val_loss: 0.9415 - val_accuracy: 0.6410\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6986 - accuracy: 0.6889 - val_loss: 0.9469 - val_accuracy: 0.6239\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6942 - accuracy: 0.7037 - val_loss: 0.9775 - val_accuracy: 0.6325\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7084 - accuracy: 0.6963 - val_loss: 0.9475 - val_accuracy: 0.6410\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6942 - accuracy: 0.7037 - val_loss: 0.9352 - val_accuracy: 0.6581\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6968 - accuracy: 0.7000 - val_loss: 0.9401 - val_accuracy: 0.6667\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6969 - accuracy: 0.7074 - val_loss: 0.9427 - val_accuracy: 0.6496\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7008 - accuracy: 0.6889 - val_loss: 0.9484 - val_accuracy: 0.6154\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7011 - accuracy: 0.6926 - val_loss: 0.9617 - val_accuracy: 0.6325\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7473 - accuracy: 0.6667 - val_loss: 0.9960 - val_accuracy: 0.6239\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7500 - accuracy: 0.6778 - val_loss: 0.9636 - val_accuracy: 0.6410\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7421 - accuracy: 0.6630 - val_loss: 0.9427 - val_accuracy: 0.6239\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7242 - accuracy: 0.6963 - val_loss: 0.9913 - val_accuracy: 0.6325\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7447 - accuracy: 0.6704 - val_loss: 0.9682 - val_accuracy: 0.6496\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8289 - accuracy: 0.6815 - val_loss: 1.2863 - val_accuracy: 0.6496\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9226 - accuracy: 0.6815 - val_loss: 1.3024 - val_accuracy: 0.6154\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8187 - accuracy: 0.6630 - val_loss: 1.0453 - val_accuracy: 0.6410\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7643 - accuracy: 0.6444 - val_loss: 1.0591 - val_accuracy: 0.6325\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7320 - accuracy: 0.6593 - val_loss: 0.9358 - val_accuracy: 0.6496\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7362 - accuracy: 0.6741 - val_loss: 0.9835 - val_accuracy: 0.6496\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7135 - accuracy: 0.6630 - val_loss: 0.9880 - val_accuracy: 0.6581\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7115 - accuracy: 0.6667 - val_loss: 0.9522 - val_accuracy: 0.6581\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7093 - accuracy: 0.6926 - val_loss: 0.9476 - val_accuracy: 0.6239\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7178 - accuracy: 0.6704 - val_loss: 0.9478 - val_accuracy: 0.6496\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7027 - accuracy: 0.6889 - val_loss: 0.9708 - val_accuracy: 0.6752\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7023 - accuracy: 0.6889 - val_loss: 0.9441 - val_accuracy: 0.6496\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7079 - accuracy: 0.6852 - val_loss: 0.9712 - val_accuracy: 0.6239\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7145 - accuracy: 0.6889 - val_loss: 0.9731 - val_accuracy: 0.6496\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7011 - accuracy: 0.6963 - val_loss: 0.9656 - val_accuracy: 0.6410\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7045 - accuracy: 0.6926 - val_loss: 0.9817 - val_accuracy: 0.6325\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7220 - accuracy: 0.6852 - val_loss: 0.9417 - val_accuracy: 0.6239\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7045 - accuracy: 0.6741 - val_loss: 0.9609 - val_accuracy: 0.6239\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7220 - accuracy: 0.6630 - val_loss: 0.9514 - val_accuracy: 0.6239\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7166 - accuracy: 0.6852 - val_loss: 0.9309 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7171 - accuracy: 0.6741 - val_loss: 0.9672 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7063 - accuracy: 0.6926 - val_loss: 0.9769 - val_accuracy: 0.6239\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6968 - accuracy: 0.6889 - val_loss: 0.9526 - val_accuracy: 0.6325\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7040 - accuracy: 0.6778 - val_loss: 0.9813 - val_accuracy: 0.6239\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7287 - accuracy: 0.6889 - val_loss: 0.9864 - val_accuracy: 0.6325\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7046 - accuracy: 0.6926 - val_loss: 1.0329 - val_accuracy: 0.6239\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7329 - accuracy: 0.6704 - val_loss: 1.0052 - val_accuracy: 0.6410\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7317 - accuracy: 0.6963 - val_loss: 0.9611 - val_accuracy: 0.6325\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7026 - accuracy: 0.6852 - val_loss: 0.9392 - val_accuracy: 0.6496\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7102 - accuracy: 0.6889 - val_loss: 0.9883 - val_accuracy: 0.6325\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7129 - accuracy: 0.6926 - val_loss: 0.9370 - val_accuracy: 0.6410\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6949 - accuracy: 0.7000 - val_loss: 0.9652 - val_accuracy: 0.6325\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7064 - accuracy: 0.6926 - val_loss: 0.9462 - val_accuracy: 0.6325\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6936 - accuracy: 0.7000 - val_loss: 0.9519 - val_accuracy: 0.6325\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6942 - accuracy: 0.6926 - val_loss: 0.9394 - val_accuracy: 0.6325\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6954 - accuracy: 0.7000 - val_loss: 0.9491 - val_accuracy: 0.6154\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7045 - accuracy: 0.7000 - val_loss: 0.9309 - val_accuracy: 0.6496\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6943 - accuracy: 0.7000 - val_loss: 0.9441 - val_accuracy: 0.6496\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6934 - accuracy: 0.6926 - val_loss: 0.9690 - val_accuracy: 0.6239\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7313 - accuracy: 0.6667 - val_loss: 0.9792 - val_accuracy: 0.6410\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7180 - accuracy: 0.6926 - val_loss: 1.0011 - val_accuracy: 0.6325\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7075 - accuracy: 0.6963 - val_loss: 0.9479 - val_accuracy: 0.6325\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7177 - accuracy: 0.6889 - val_loss: 1.0705 - val_accuracy: 0.6154\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7743 - accuracy: 0.6926 - val_loss: 1.0293 - val_accuracy: 0.6154\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7092 - accuracy: 0.6963 - val_loss: 1.0378 - val_accuracy: 0.6068\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7294 - accuracy: 0.6889 - val_loss: 1.0205 - val_accuracy: 0.6325\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7334 - accuracy: 0.6926 - val_loss: 0.9730 - val_accuracy: 0.6410\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6900 - accuracy: 0.7037 - val_loss: 0.9721 - val_accuracy: 0.6325\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.7266 - accuracy: 0.6778 - val_loss: 1.0508 - val_accuracy: 0.6325\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7741 - accuracy: 0.6926 - val_loss: 0.9885 - val_accuracy: 0.6325\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7096 - accuracy: 0.6926 - val_loss: 0.9702 - val_accuracy: 0.6325\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7004 - accuracy: 0.6963 - val_loss: 1.0058 - val_accuracy: 0.6410\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7227 - accuracy: 0.6963 - val_loss: 0.9519 - val_accuracy: 0.6410\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6908 - accuracy: 0.6926 - val_loss: 0.9632 - val_accuracy: 0.6239\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7031 - accuracy: 0.6741 - val_loss: 0.9662 - val_accuracy: 0.6325\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6963 - accuracy: 0.6926 - val_loss: 0.9444 - val_accuracy: 0.6325\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7105 - accuracy: 0.6667 - val_loss: 0.9566 - val_accuracy: 0.6068\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7426 - accuracy: 0.6889 - val_loss: 0.9863 - val_accuracy: 0.6325\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.7187 - accuracy: 0.6889 - val_loss: 0.9508 - val_accuracy: 0.6325\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.7363 - accuracy: 0.6519 - val_loss: 1.0622 - val_accuracy: 0.6496\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7922 - accuracy: 0.6963 - val_loss: 1.0440 - val_accuracy: 0.6154\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7461 - accuracy: 0.6815 - val_loss: 0.9706 - val_accuracy: 0.6325\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7423 - accuracy: 0.6778 - val_loss: 1.0971 - val_accuracy: 0.6154\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7550 - accuracy: 0.6704 - val_loss: 0.9597 - val_accuracy: 0.6496\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8125 - accuracy: 0.6593 - val_loss: 0.9424 - val_accuracy: 0.6239\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7084 - accuracy: 0.6889 - val_loss: 1.0225 - val_accuracy: 0.6325\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7103 - accuracy: 0.6926 - val_loss: 0.9751 - val_accuracy: 0.6154\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7390 - accuracy: 0.6481 - val_loss: 1.0068 - val_accuracy: 0.6325\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7541 - accuracy: 0.6963 - val_loss: 1.0750 - val_accuracy: 0.6325\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7278 - accuracy: 0.6926 - val_loss: 0.9654 - val_accuracy: 0.6325\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8288 - accuracy: 0.6704 - val_loss: 0.9679 - val_accuracy: 0.6410\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7493 - accuracy: 0.6926 - val_loss: 1.0791 - val_accuracy: 0.6239\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7401 - accuracy: 0.6963 - val_loss: 0.9517 - val_accuracy: 0.5983\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7829 - accuracy: 0.6741 - val_loss: 1.0081 - val_accuracy: 0.6154\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7619 - accuracy: 0.6889 - val_loss: 1.1293 - val_accuracy: 0.6239\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7769 - accuracy: 0.6963 - val_loss: 0.9490 - val_accuracy: 0.6154\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7218 - accuracy: 0.6667 - val_loss: 0.9609 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7240 - accuracy: 0.6889 - val_loss: 0.9743 - val_accuracy: 0.6325\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7062 - accuracy: 0.6889 - val_loss: 0.9363 - val_accuracy: 0.6410\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6930 - accuracy: 0.6926 - val_loss: 0.9733 - val_accuracy: 0.6325\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7023 - accuracy: 0.6926 - val_loss: 0.9504 - val_accuracy: 0.6410\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7849 - accuracy: 0.6630 - val_loss: 1.0354 - val_accuracy: 0.6325\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8517 - accuracy: 0.6741 - val_loss: 1.4609 - val_accuracy: 0.6325\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.0151 - accuracy: 0.6815 - val_loss: 1.2637 - val_accuracy: 0.6239\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9352 - accuracy: 0.6481 - val_loss: 1.2551 - val_accuracy: 0.5983\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9456 - accuracy: 0.6222 - val_loss: 1.3553 - val_accuracy: 0.5897\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9508 - accuracy: 0.5926 - val_loss: 1.0158 - val_accuracy: 0.6410\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7832 - accuracy: 0.6815 - val_loss: 1.1836 - val_accuracy: 0.6410\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8698 - accuracy: 0.7037 - val_loss: 1.0975 - val_accuracy: 0.6239\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7733 - accuracy: 0.6815 - val_loss: 1.0274 - val_accuracy: 0.5897\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7632 - accuracy: 0.6741 - val_loss: 1.0212 - val_accuracy: 0.6410\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7236 - accuracy: 0.6889 - val_loss: 1.0026 - val_accuracy: 0.6239\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7045 - accuracy: 0.6815 - val_loss: 0.9635 - val_accuracy: 0.6325\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7124 - accuracy: 0.6963 - val_loss: 0.9809 - val_accuracy: 0.6325\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7079 - accuracy: 0.6778 - val_loss: 0.9664 - val_accuracy: 0.6154\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7000 - accuracy: 0.6630 - val_loss: 0.9619 - val_accuracy: 0.6325\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6925 - accuracy: 0.6852 - val_loss: 0.9535 - val_accuracy: 0.6410\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6906 - accuracy: 0.6963 - val_loss: 0.9582 - val_accuracy: 0.6325\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6976 - accuracy: 0.6852 - val_loss: 0.9937 - val_accuracy: 0.6325\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7064 - accuracy: 0.6667 - val_loss: 0.9793 - val_accuracy: 0.6239\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7016 - accuracy: 0.7000 - val_loss: 0.9603 - val_accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7376 - accuracy: 0.6370 - val_loss: 1.0129 - val_accuracy: 0.5726\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7127 - accuracy: 0.6852 - val_loss: 1.1950 - val_accuracy: 0.5983\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8236 - accuracy: 0.6926 - val_loss: 1.0162 - val_accuracy: 0.6154\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7363 - accuracy: 0.6778 - val_loss: 1.0710 - val_accuracy: 0.5983\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7149 - accuracy: 0.6963 - val_loss: 1.0283 - val_accuracy: 0.6410\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7599 - accuracy: 0.6926 - val_loss: 1.0444 - val_accuracy: 0.6325\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7110 - accuracy: 0.7000 - val_loss: 1.0136 - val_accuracy: 0.5983\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7342 - accuracy: 0.6778 - val_loss: 1.0899 - val_accuracy: 0.6239\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7916 - accuracy: 0.6963 - val_loss: 1.0578 - val_accuracy: 0.6154\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7710 - accuracy: 0.6556 - val_loss: 1.1929 - val_accuracy: 0.6068\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7996 - accuracy: 0.6667 - val_loss: 1.1347 - val_accuracy: 0.6154\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7960 - accuracy: 0.6667 - val_loss: 1.0717 - val_accuracy: 0.6325\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7210 - accuracy: 0.6926 - val_loss: 1.0339 - val_accuracy: 0.6068\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8008 - accuracy: 0.6444 - val_loss: 1.1913 - val_accuracy: 0.6154\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8351 - accuracy: 0.6296 - val_loss: 1.0016 - val_accuracy: 0.6325\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7294 - accuracy: 0.6704 - val_loss: 0.9935 - val_accuracy: 0.6325\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7622 - accuracy: 0.6778 - val_loss: 1.0471 - val_accuracy: 0.6325\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7072 - accuracy: 0.6889 - val_loss: 1.1150 - val_accuracy: 0.6239\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7625 - accuracy: 0.6704 - val_loss: 1.0502 - val_accuracy: 0.6410\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7376 - accuracy: 0.6704 - val_loss: 1.0239 - val_accuracy: 0.6581\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7046 - accuracy: 0.7037 - val_loss: 0.9700 - val_accuracy: 0.6239\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7370 - accuracy: 0.6889 - val_loss: 1.0222 - val_accuracy: 0.6068\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7219 - accuracy: 0.6889 - val_loss: 0.9667 - val_accuracy: 0.6068\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8093 - accuracy: 0.6704 - val_loss: 0.9690 - val_accuracy: 0.6325\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7034 - accuracy: 0.6963 - val_loss: 0.9736 - val_accuracy: 0.6068\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7196 - accuracy: 0.6926 - val_loss: 0.9558 - val_accuracy: 0.6325\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7880 - accuracy: 0.6630 - val_loss: 1.0369 - val_accuracy: 0.6496\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7583 - accuracy: 0.7000 - val_loss: 1.0695 - val_accuracy: 0.6325\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7288 - accuracy: 0.6963 - val_loss: 0.9490 - val_accuracy: 0.6239\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7026 - accuracy: 0.6852 - val_loss: 0.9563 - val_accuracy: 0.6410\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6894 - accuracy: 0.7000 - val_loss: 0.9412 - val_accuracy: 0.6239\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6910 - accuracy: 0.6926 - val_loss: 0.9706 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7153 - accuracy: 0.6889 - val_loss: 0.9909 - val_accuracy: 0.6496\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7102 - accuracy: 0.6963 - val_loss: 1.0013 - val_accuracy: 0.6239\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7280 - accuracy: 0.6889 - val_loss: 0.9742 - val_accuracy: 0.6239\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7268 - accuracy: 0.6778 - val_loss: 1.0288 - val_accuracy: 0.6410\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7020 - accuracy: 0.6963 - val_loss: 0.9837 - val_accuracy: 0.6325\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7088 - accuracy: 0.6889 - val_loss: 0.9638 - val_accuracy: 0.6325\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7015 - accuracy: 0.6889 - val_loss: 0.9525 - val_accuracy: 0.6496\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7214 - accuracy: 0.6852 - val_loss: 1.0069 - val_accuracy: 0.6410\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7452 - accuracy: 0.6926 - val_loss: 0.9889 - val_accuracy: 0.6154\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7139 - accuracy: 0.6852 - val_loss: 1.1251 - val_accuracy: 0.6068\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7452 - accuracy: 0.6704 - val_loss: 1.0209 - val_accuracy: 0.6239\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7652 - accuracy: 0.6963 - val_loss: 1.0429 - val_accuracy: 0.6154\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7311 - accuracy: 0.6778 - val_loss: 1.0665 - val_accuracy: 0.5983\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8062 - accuracy: 0.6852 - val_loss: 1.0869 - val_accuracy: 0.6325\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7665 - accuracy: 0.6963 - val_loss: 1.0437 - val_accuracy: 0.6325\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7062 - accuracy: 0.6926 - val_loss: 1.0120 - val_accuracy: 0.6325\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7191 - accuracy: 0.6852 - val_loss: 1.0350 - val_accuracy: 0.6410\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7318 - accuracy: 0.6963 - val_loss: 0.9715 - val_accuracy: 0.6410\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7256 - accuracy: 0.6741 - val_loss: 0.9807 - val_accuracy: 0.6154\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7172 - accuracy: 0.6963 - val_loss: 1.0403 - val_accuracy: 0.6068\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7358 - accuracy: 0.6889 - val_loss: 0.9742 - val_accuracy: 0.6154\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6916 - accuracy: 0.6963 - val_loss: 1.0139 - val_accuracy: 0.6068\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7128 - accuracy: 0.6704 - val_loss: 1.0114 - val_accuracy: 0.6325\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7118 - accuracy: 0.6963 - val_loss: 0.9580 - val_accuracy: 0.6496\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6876 - accuracy: 0.7074 - val_loss: 0.9583 - val_accuracy: 0.6496\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6820 - accuracy: 0.6963 - val_loss: 0.9430 - val_accuracy: 0.6325\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.6985 - accuracy: 0.6852 - val_loss: 0.9927 - val_accuracy: 0.6496\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7187 - accuracy: 0.6667 - val_loss: 1.0347 - val_accuracy: 0.6239\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7052 - accuracy: 0.6704 - val_loss: 0.9873 - val_accuracy: 0.6325\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6967 - accuracy: 0.6926 - val_loss: 0.9681 - val_accuracy: 0.6154\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7248 - accuracy: 0.6704 - val_loss: 1.1169 - val_accuracy: 0.6154\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8612 - accuracy: 0.6370 - val_loss: 1.1624 - val_accuracy: 0.6068\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7514 - accuracy: 0.6630 - val_loss: 0.9560 - val_accuracy: 0.6239\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7870 - accuracy: 0.6481 - val_loss: 1.0586 - val_accuracy: 0.6410\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7807 - accuracy: 0.6481 - val_loss: 1.0752 - val_accuracy: 0.6496\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7098 - accuracy: 0.6963 - val_loss: 1.0119 - val_accuracy: 0.5983\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7068 - accuracy: 0.6778 - val_loss: 1.0310 - val_accuracy: 0.6154\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7249 - accuracy: 0.6667 - val_loss: 1.0178 - val_accuracy: 0.6410\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6931 - accuracy: 0.6889 - val_loss: 0.9518 - val_accuracy: 0.6068\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6966 - accuracy: 0.6852 - val_loss: 0.9811 - val_accuracy: 0.6239\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6864 - accuracy: 0.6926 - val_loss: 1.0005 - val_accuracy: 0.6496\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6910 - accuracy: 0.7000 - val_loss: 0.9824 - val_accuracy: 0.6239\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6840 - accuracy: 0.6963 - val_loss: 0.9638 - val_accuracy: 0.6239\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7008 - accuracy: 0.6815 - val_loss: 0.9916 - val_accuracy: 0.6154\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6952 - accuracy: 0.6926 - val_loss: 0.9568 - val_accuracy: 0.6325\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7284 - accuracy: 0.6852 - val_loss: 0.9554 - val_accuracy: 0.6496\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6922 - accuracy: 0.6963 - val_loss: 0.9783 - val_accuracy: 0.6410\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6890 - accuracy: 0.7000 - val_loss: 0.9520 - val_accuracy: 0.6496\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6900 - accuracy: 0.6926 - val_loss: 0.9580 - val_accuracy: 0.6325\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6916 - accuracy: 0.6889 - val_loss: 0.9442 - val_accuracy: 0.6325\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6960 - accuracy: 0.6778 - val_loss: 1.0086 - val_accuracy: 0.6410\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8018 - accuracy: 0.7000 - val_loss: 1.2500 - val_accuracy: 0.6496\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8690 - accuracy: 0.6926 - val_loss: 1.0611 - val_accuracy: 0.6752\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7299 - accuracy: 0.7000 - val_loss: 1.1335 - val_accuracy: 0.6068\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8122 - accuracy: 0.6444 - val_loss: 1.0346 - val_accuracy: 0.6239\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7179 - accuracy: 0.6852 - val_loss: 1.0289 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7159 - accuracy: 0.6852 - val_loss: 0.9483 - val_accuracy: 0.6496\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7148 - accuracy: 0.6741 - val_loss: 1.0606 - val_accuracy: 0.6154\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7079 - accuracy: 0.6593 - val_loss: 1.0373 - val_accuracy: 0.6325\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7098 - accuracy: 0.6926 - val_loss: 0.9483 - val_accuracy: 0.6239\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7181 - accuracy: 0.6852 - val_loss: 0.9851 - val_accuracy: 0.6154\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7178 - accuracy: 0.6926 - val_loss: 1.0078 - val_accuracy: 0.6239\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7093 - accuracy: 0.6741 - val_loss: 0.9900 - val_accuracy: 0.6154\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7089 - accuracy: 0.6963 - val_loss: 0.9972 - val_accuracy: 0.6068\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7047 - accuracy: 0.6926 - val_loss: 1.0447 - val_accuracy: 0.6239\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9175 - accuracy: 0.6333 - val_loss: 1.4837 - val_accuracy: 0.5556\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9585 - accuracy: 0.6111 - val_loss: 1.0361 - val_accuracy: 0.6154\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 1.1972 - accuracy: 0.5963 - val_loss: 1.2460 - val_accuracy: 0.5983\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9682 - accuracy: 0.6222 - val_loss: 1.4606 - val_accuracy: 0.6068\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0070 - accuracy: 0.6444 - val_loss: 1.0868 - val_accuracy: 0.6325\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8051 - accuracy: 0.6667 - val_loss: 0.9877 - val_accuracy: 0.6410\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7407 - accuracy: 0.6741 - val_loss: 1.1996 - val_accuracy: 0.6496\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8410 - accuracy: 0.6481 - val_loss: 1.0149 - val_accuracy: 0.6581\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6964 - accuracy: 0.6815 - val_loss: 1.0340 - val_accuracy: 0.6154\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7653 - accuracy: 0.6667 - val_loss: 1.1581 - val_accuracy: 0.6325\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7960 - accuracy: 0.6556 - val_loss: 1.0387 - val_accuracy: 0.6410\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7172 - accuracy: 0.6852 - val_loss: 1.1673 - val_accuracy: 0.6410\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8752 - accuracy: 0.6630 - val_loss: 1.1210 - val_accuracy: 0.6667\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8174 - accuracy: 0.6926 - val_loss: 1.0939 - val_accuracy: 0.6325\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7394 - accuracy: 0.6852 - val_loss: 1.1586 - val_accuracy: 0.6154\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7757 - accuracy: 0.6593 - val_loss: 1.0580 - val_accuracy: 0.6239\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7964 - accuracy: 0.6926 - val_loss: 1.0655 - val_accuracy: 0.6667\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7650 - accuracy: 0.6852 - val_loss: 1.1079 - val_accuracy: 0.6239\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7934 - accuracy: 0.6296 - val_loss: 1.1352 - val_accuracy: 0.6325\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7990 - accuracy: 0.6815 - val_loss: 1.0687 - val_accuracy: 0.6239\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7664 - accuracy: 0.6593 - val_loss: 1.0370 - val_accuracy: 0.6068\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7182 - accuracy: 0.6741 - val_loss: 1.0468 - val_accuracy: 0.6410\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7249 - accuracy: 0.6926 - val_loss: 1.0542 - val_accuracy: 0.6410\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7037 - accuracy: 0.6963 - val_loss: 0.9650 - val_accuracy: 0.6581\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6861 - accuracy: 0.6889 - val_loss: 0.9602 - val_accuracy: 0.6154\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6942 - accuracy: 0.6667 - val_loss: 0.9998 - val_accuracy: 0.6154\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7471 - accuracy: 0.7000 - val_loss: 1.1126 - val_accuracy: 0.6410\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7376 - accuracy: 0.6963 - val_loss: 0.9795 - val_accuracy: 0.6581\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7077 - accuracy: 0.6667 - val_loss: 0.9700 - val_accuracy: 0.6325\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7101 - accuracy: 0.6926 - val_loss: 1.0378 - val_accuracy: 0.6239\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7213 - accuracy: 0.6889 - val_loss: 0.9744 - val_accuracy: 0.6239\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6887 - accuracy: 0.6704 - val_loss: 1.0360 - val_accuracy: 0.6239\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7169 - accuracy: 0.6889 - val_loss: 1.0169 - val_accuracy: 0.6410\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6965 - accuracy: 0.6926 - val_loss: 0.9559 - val_accuracy: 0.6325\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6801 - accuracy: 0.6926 - val_loss: 0.9547 - val_accuracy: 0.6496\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6869 - accuracy: 0.7000 - val_loss: 1.0323 - val_accuracy: 0.6410\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7427 - accuracy: 0.7000 - val_loss: 1.0787 - val_accuracy: 0.6154\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.7073 - accuracy: 0.6926 - val_loss: 0.9732 - val_accuracy: 0.6239\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7085 - accuracy: 0.6741 - val_loss: 0.9705 - val_accuracy: 0.6496\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6812 - accuracy: 0.7037 - val_loss: 1.0088 - val_accuracy: 0.6325\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6892 - accuracy: 0.6963 - val_loss: 0.9810 - val_accuracy: 0.6325\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6793 - accuracy: 0.7000 - val_loss: 0.9786 - val_accuracy: 0.6239\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6863 - accuracy: 0.6963 - val_loss: 0.9782 - val_accuracy: 0.6239\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7031 - accuracy: 0.6926 - val_loss: 0.9946 - val_accuracy: 0.6154\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7086 - accuracy: 0.6741 - val_loss: 1.0545 - val_accuracy: 0.6154\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6921 - accuracy: 0.6852 - val_loss: 0.9655 - val_accuracy: 0.6239\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6950 - accuracy: 0.6852 - val_loss: 0.9695 - val_accuracy: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6817 - accuracy: 0.6815 - val_loss: 0.9704 - val_accuracy: 0.6667\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6804 - accuracy: 0.6963 - val_loss: 0.9986 - val_accuracy: 0.6068\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6936 - accuracy: 0.6815 - val_loss: 0.9766 - val_accuracy: 0.6581\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6783 - accuracy: 0.7000 - val_loss: 1.0092 - val_accuracy: 0.6239\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7187 - accuracy: 0.6963 - val_loss: 1.0501 - val_accuracy: 0.6410\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7472 - accuracy: 0.6963 - val_loss: 1.0519 - val_accuracy: 0.6410\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6982 - accuracy: 0.6926 - val_loss: 1.0346 - val_accuracy: 0.5983\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7242 - accuracy: 0.6815 - val_loss: 0.9756 - val_accuracy: 0.6239\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6891 - accuracy: 0.6963 - val_loss: 0.9837 - val_accuracy: 0.6496\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6790 - accuracy: 0.7037 - val_loss: 0.9833 - val_accuracy: 0.6239\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6893 - accuracy: 0.6778 - val_loss: 0.9781 - val_accuracy: 0.6068\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7266 - accuracy: 0.6889 - val_loss: 0.9921 - val_accuracy: 0.6068\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7180 - accuracy: 0.6815 - val_loss: 0.9977 - val_accuracy: 0.6154\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6915 - accuracy: 0.6778 - val_loss: 1.0321 - val_accuracy: 0.6154\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.7197 - accuracy: 0.6963 - val_loss: 0.9789 - val_accuracy: 0.6154\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6887 - accuracy: 0.6815 - val_loss: 0.9922 - val_accuracy: 0.6154\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7611 - accuracy: 0.7037 - val_loss: 1.2121 - val_accuracy: 0.6154\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8524 - accuracy: 0.6963 - val_loss: 1.0811 - val_accuracy: 0.6154\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7107 - accuracy: 0.6926 - val_loss: 1.1401 - val_accuracy: 0.6325\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7678 - accuracy: 0.6704 - val_loss: 1.0053 - val_accuracy: 0.6325\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6932 - accuracy: 0.6926 - val_loss: 1.0009 - val_accuracy: 0.6410\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6905 - accuracy: 0.6889 - val_loss: 0.9456 - val_accuracy: 0.6410\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6798 - accuracy: 0.6889 - val_loss: 0.9512 - val_accuracy: 0.6496\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6765 - accuracy: 0.6963 - val_loss: 0.9539 - val_accuracy: 0.6325\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6784 - accuracy: 0.6963 - val_loss: 0.9751 - val_accuracy: 0.6325\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6779 - accuracy: 0.6963 - val_loss: 0.9950 - val_accuracy: 0.6068\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6837 - accuracy: 0.6963 - val_loss: 0.9758 - val_accuracy: 0.6325\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6762 - accuracy: 0.7037 - val_loss: 0.9618 - val_accuracy: 0.6239\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6919 - accuracy: 0.6926 - val_loss: 0.9693 - val_accuracy: 0.6325\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6852 - accuracy: 0.6815 - val_loss: 0.9703 - val_accuracy: 0.6496\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6816 - accuracy: 0.6926 - val_loss: 0.9799 - val_accuracy: 0.6410\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6846 - accuracy: 0.7000 - val_loss: 0.9605 - val_accuracy: 0.6581\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6800 - accuracy: 0.6926 - val_loss: 0.9759 - val_accuracy: 0.6325\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6938 - accuracy: 0.6926 - val_loss: 1.0443 - val_accuracy: 0.6496\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6943 - accuracy: 0.6778 - val_loss: 1.0101 - val_accuracy: 0.6068\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7402 - accuracy: 0.6704 - val_loss: 0.9811 - val_accuracy: 0.6154\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6977 - accuracy: 0.6926 - val_loss: 0.9520 - val_accuracy: 0.6154\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7105 - accuracy: 0.6815 - val_loss: 0.9731 - val_accuracy: 0.6239\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6880 - accuracy: 0.6963 - val_loss: 0.9987 - val_accuracy: 0.6239\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6833 - accuracy: 0.6963 - val_loss: 0.9495 - val_accuracy: 0.6410\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7079 - accuracy: 0.6852 - val_loss: 1.0066 - val_accuracy: 0.6410\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7061 - accuracy: 0.6778 - val_loss: 1.0402 - val_accuracy: 0.6496\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6824 - accuracy: 0.6963 - val_loss: 0.9804 - val_accuracy: 0.6410\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6996 - accuracy: 0.6889 - val_loss: 1.0317 - val_accuracy: 0.6325\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7348 - accuracy: 0.6778 - val_loss: 1.1109 - val_accuracy: 0.6325\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7187 - accuracy: 0.6704 - val_loss: 0.9817 - val_accuracy: 0.6496\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6886 - accuracy: 0.7037 - val_loss: 0.9598 - val_accuracy: 0.6239\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6918 - accuracy: 0.6926 - val_loss: 0.9767 - val_accuracy: 0.6239\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6824 - accuracy: 0.6926 - val_loss: 0.9441 - val_accuracy: 0.6496\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6869 - accuracy: 0.6926 - val_loss: 0.9672 - val_accuracy: 0.6496\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6724 - accuracy: 0.7000 - val_loss: 0.9538 - val_accuracy: 0.6325\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6743 - accuracy: 0.6926 - val_loss: 0.9586 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3dd6fa90>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 84us/step\n",
      "over-sampling test accuracy: 64.10%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 2, 1, 0, 2, 2, 0, 1, 1, 0, 2, 0, 1, 1, 2, 2, 2,\n",
       "       2, 2, 0, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2,\n",
       "       2, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1,\n",
       "       1, 0, 1, 1, 0, 0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1,\n",
       "       1, 1, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS236     1     2\n",
       "1      NRS113     2     2\n",
       "2    CFBRSa23     0     0\n",
       "3      NRS249     2     2\n",
       "4         107     1     1\n",
       "..        ...   ...   ...\n",
       "112     NY439     2     2\n",
       "113    NRS106     0     0\n",
       "114       221     0     1\n",
       "115    NRS386     2     2\n",
       "116  CFBRSa03     1     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.055683</td>\n",
       "      <td>0.937519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112860</td>\n",
       "      <td>0.056992</td>\n",
       "      <td>0.830148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480284</td>\n",
       "      <td>0.383319</td>\n",
       "      <td>0.136397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.212836</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.783843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.314489</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>0.178483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>0.980786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.593088</td>\n",
       "      <td>0.224250</td>\n",
       "      <td>0.182662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.314489</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>0.178483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.056708</td>\n",
       "      <td>0.293001</td>\n",
       "      <td>0.650292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.314489</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>0.178483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.006798  0.055683  0.937519\n",
       "1    0.112860  0.056992  0.830148\n",
       "2    0.480284  0.383319  0.136397\n",
       "3    0.212836  0.003320  0.783843\n",
       "4    0.314489  0.507028  0.178483\n",
       "..        ...       ...       ...\n",
       "112  0.002477  0.016737  0.980786\n",
       "113  0.593088  0.224250  0.182662\n",
       "114  0.314489  0.507028  0.178483\n",
       "115  0.056708  0.293001  0.650292\n",
       "116  0.314489  0.507028  0.178483\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p006ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6900 - accuracy: 0.6889 - val_loss: 1.0304 - val_accuracy: 0.6325\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6966 - accuracy: 0.7000 - val_loss: 1.1327 - val_accuracy: 0.6154\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7060 - accuracy: 0.7037 - val_loss: 1.0305 - val_accuracy: 0.6154\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6902 - accuracy: 0.6741 - val_loss: 1.0337 - val_accuracy: 0.6068\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7010 - accuracy: 0.7000 - val_loss: 0.9978 - val_accuracy: 0.5983\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6762 - accuracy: 0.6963 - val_loss: 0.9932 - val_accuracy: 0.6239\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6653 - accuracy: 0.7000 - val_loss: 1.0066 - val_accuracy: 0.6496\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6741 - accuracy: 0.6852 - val_loss: 1.0070 - val_accuracy: 0.6239\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6649 - accuracy: 0.6889 - val_loss: 0.9838 - val_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6687 - accuracy: 0.6741 - val_loss: 0.9876 - val_accuracy: 0.6154\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6585 - accuracy: 0.7037 - val_loss: 0.9978 - val_accuracy: 0.6068\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6670 - accuracy: 0.7037 - val_loss: 1.0783 - val_accuracy: 0.6410\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7467 - accuracy: 0.7037 - val_loss: 1.0116 - val_accuracy: 0.5983\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7265 - accuracy: 0.6778 - val_loss: 0.9969 - val_accuracy: 0.5983\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6934 - accuracy: 0.7074 - val_loss: 1.0018 - val_accuracy: 0.6068\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6581 - accuracy: 0.7000 - val_loss: 0.9724 - val_accuracy: 0.6325\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6695 - accuracy: 0.6963 - val_loss: 0.9944 - val_accuracy: 0.6239\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6783 - accuracy: 0.7000 - val_loss: 1.0839 - val_accuracy: 0.6325\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7513 - accuracy: 0.6889 - val_loss: 1.0712 - val_accuracy: 0.6154\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6733 - accuracy: 0.7037 - val_loss: 1.1911 - val_accuracy: 0.5983\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8018 - accuracy: 0.6889 - val_loss: 1.1588 - val_accuracy: 0.6239\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7473 - accuracy: 0.6889 - val_loss: 1.1019 - val_accuracy: 0.5812\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7242 - accuracy: 0.6852 - val_loss: 1.0465 - val_accuracy: 0.6239\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6913 - accuracy: 0.6963 - val_loss: 0.9718 - val_accuracy: 0.6325\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6702 - accuracy: 0.6963 - val_loss: 1.0333 - val_accuracy: 0.6239\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6841 - accuracy: 0.7000 - val_loss: 1.0290 - val_accuracy: 0.6154\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6620 - accuracy: 0.6963 - val_loss: 1.0057 - val_accuracy: 0.6154\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6725 - accuracy: 0.6815 - val_loss: 1.0286 - val_accuracy: 0.6325\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6815 - accuracy: 0.7037 - val_loss: 0.9806 - val_accuracy: 0.6239\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6663 - accuracy: 0.7000 - val_loss: 1.0537 - val_accuracy: 0.5897\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7324 - accuracy: 0.6889 - val_loss: 1.1135 - val_accuracy: 0.6154\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8721 - accuracy: 0.7000 - val_loss: 1.5434 - val_accuracy: 0.6239\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 1.0438 - accuracy: 0.6963 - val_loss: 1.1856 - val_accuracy: 0.6410\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7730 - accuracy: 0.7037 - val_loss: 1.0684 - val_accuracy: 0.5983\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7458 - accuracy: 0.6481 - val_loss: 1.1736 - val_accuracy: 0.5812\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7418 - accuracy: 0.6667 - val_loss: 1.0730 - val_accuracy: 0.5983\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6746 - accuracy: 0.7037 - val_loss: 1.0367 - val_accuracy: 0.5983\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6948 - accuracy: 0.6963 - val_loss: 1.0388 - val_accuracy: 0.5983\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6923 - accuracy: 0.6926 - val_loss: 1.0735 - val_accuracy: 0.6325\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7107 - accuracy: 0.7000 - val_loss: 1.0651 - val_accuracy: 0.6325\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6874 - accuracy: 0.6889 - val_loss: 0.9940 - val_accuracy: 0.6068\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6931 - accuracy: 0.7000 - val_loss: 1.0139 - val_accuracy: 0.6154\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6628 - accuracy: 0.7074 - val_loss: 1.0163 - val_accuracy: 0.6154\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6850 - accuracy: 0.6815 - val_loss: 0.9714 - val_accuracy: 0.6239\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6717 - accuracy: 0.6815 - val_loss: 1.0083 - val_accuracy: 0.6239\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6895 - accuracy: 0.6963 - val_loss: 1.0067 - val_accuracy: 0.5897\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6591 - accuracy: 0.7000 - val_loss: 0.9846 - val_accuracy: 0.6154\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6555 - accuracy: 0.7037 - val_loss: 0.9989 - val_accuracy: 0.6068\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6566 - accuracy: 0.7037 - val_loss: 1.0030 - val_accuracy: 0.6325\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.7378 - accuracy: 0.6889 - val_loss: 1.1396 - val_accuracy: 0.6410\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7735 - accuracy: 0.7000 - val_loss: 1.0933 - val_accuracy: 0.6496\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6929 - accuracy: 0.7000 - val_loss: 1.1003 - val_accuracy: 0.6239\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7437 - accuracy: 0.6926 - val_loss: 1.1086 - val_accuracy: 0.6496\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8064 - accuracy: 0.7037 - val_loss: 1.2319 - val_accuracy: 0.6239\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7905 - accuracy: 0.7037 - val_loss: 0.9841 - val_accuracy: 0.5556\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6836 - accuracy: 0.6778 - val_loss: 1.0644 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6880 - accuracy: 0.6963 - val_loss: 1.0701 - val_accuracy: 0.5812\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6780 - accuracy: 0.6926 - val_loss: 1.0312 - val_accuracy: 0.5812\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6641 - accuracy: 0.7074 - val_loss: 0.9837 - val_accuracy: 0.6154\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6692 - accuracy: 0.7000 - val_loss: 1.0162 - val_accuracy: 0.6239\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6858 - accuracy: 0.6926 - val_loss: 1.0632 - val_accuracy: 0.6239\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7418 - accuracy: 0.6926 - val_loss: 1.0517 - val_accuracy: 0.6496\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6978 - accuracy: 0.6852 - val_loss: 1.0196 - val_accuracy: 0.6410\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6817 - accuracy: 0.6963 - val_loss: 1.0958 - val_accuracy: 0.6068\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6891 - accuracy: 0.6963 - val_loss: 1.0343 - val_accuracy: 0.6325\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6557 - accuracy: 0.6926 - val_loss: 0.9887 - val_accuracy: 0.6325\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6721 - accuracy: 0.6963 - val_loss: 0.9847 - val_accuracy: 0.6410\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6560 - accuracy: 0.7000 - val_loss: 1.0024 - val_accuracy: 0.6325\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6630 - accuracy: 0.6889 - val_loss: 1.0053 - val_accuracy: 0.6239\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6605 - accuracy: 0.6889 - val_loss: 0.9966 - val_accuracy: 0.6325\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6745 - accuracy: 0.7037 - val_loss: 0.9730 - val_accuracy: 0.6325\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6991 - accuracy: 0.6852 - val_loss: 1.0203 - val_accuracy: 0.6154\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6828 - accuracy: 0.6963 - val_loss: 1.0095 - val_accuracy: 0.6154\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6751 - accuracy: 0.7074 - val_loss: 0.9980 - val_accuracy: 0.6239\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6519 - accuracy: 0.7111 - val_loss: 0.9865 - val_accuracy: 0.5983\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6732 - accuracy: 0.6778 - val_loss: 1.0537 - val_accuracy: 0.6239\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.7716 - accuracy: 0.6926 - val_loss: 1.0271 - val_accuracy: 0.6239\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6710 - accuracy: 0.6926 - val_loss: 1.0404 - val_accuracy: 0.5983\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6808 - accuracy: 0.6963 - val_loss: 1.0555 - val_accuracy: 0.5897\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6832 - accuracy: 0.7037 - val_loss: 1.0491 - val_accuracy: 0.6068\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6734 - accuracy: 0.7000 - val_loss: 1.0213 - val_accuracy: 0.6154\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6603 - accuracy: 0.6889 - val_loss: 0.9881 - val_accuracy: 0.6239\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6664 - accuracy: 0.6889 - val_loss: 1.0047 - val_accuracy: 0.6154\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6627 - accuracy: 0.6926 - val_loss: 1.0750 - val_accuracy: 0.6154\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7502 - accuracy: 0.6963 - val_loss: 1.0985 - val_accuracy: 0.6154\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7905 - accuracy: 0.7037 - val_loss: 1.1001 - val_accuracy: 0.6154\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7266 - accuracy: 0.6889 - val_loss: 1.1320 - val_accuracy: 0.5897\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7265 - accuracy: 0.6926 - val_loss: 1.1939 - val_accuracy: 0.6496\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7531 - accuracy: 0.6963 - val_loss: 1.0452 - val_accuracy: 0.6410\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6984 - accuracy: 0.6778 - val_loss: 1.0506 - val_accuracy: 0.6410\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7000 - accuracy: 0.7000 - val_loss: 1.0130 - val_accuracy: 0.6068\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6690 - accuracy: 0.7037 - val_loss: 1.0323 - val_accuracy: 0.6496\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6639 - accuracy: 0.7074 - val_loss: 1.0398 - val_accuracy: 0.6239\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6718 - accuracy: 0.7074 - val_loss: 1.0585 - val_accuracy: 0.6496\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7188 - accuracy: 0.6963 - val_loss: 1.0243 - val_accuracy: 0.6410\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7039 - accuracy: 0.6667 - val_loss: 1.0717 - val_accuracy: 0.6410\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7064 - accuracy: 0.7074 - val_loss: 1.1025 - val_accuracy: 0.6154\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6929 - accuracy: 0.7000 - val_loss: 1.0233 - val_accuracy: 0.6239\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6519 - accuracy: 0.7074 - val_loss: 0.9927 - val_accuracy: 0.5983\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6911 - accuracy: 0.7000 - val_loss: 0.9977 - val_accuracy: 0.5726\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6847 - accuracy: 0.6778 - val_loss: 1.0015 - val_accuracy: 0.5983\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6613 - accuracy: 0.7148 - val_loss: 0.9995 - val_accuracy: 0.6068\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7013 - accuracy: 0.6889 - val_loss: 1.0737 - val_accuracy: 0.6068\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7213 - accuracy: 0.6963 - val_loss: 1.0802 - val_accuracy: 0.6154\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6846 - accuracy: 0.7037 - val_loss: 1.0400 - val_accuracy: 0.5641\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6805 - accuracy: 0.6741 - val_loss: 1.0012 - val_accuracy: 0.5812\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6637 - accuracy: 0.6778 - val_loss: 1.0098 - val_accuracy: 0.5897\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6619 - accuracy: 0.7074 - val_loss: 1.0543 - val_accuracy: 0.5983\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.71 - 0s 58us/step - loss: 0.6728 - accuracy: 0.7074 - val_loss: 1.0312 - val_accuracy: 0.6239\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6583 - accuracy: 0.7111 - val_loss: 1.0149 - val_accuracy: 0.6239\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6808 - accuracy: 0.6963 - val_loss: 0.9855 - val_accuracy: 0.6068\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6616 - accuracy: 0.6926 - val_loss: 1.0100 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6814 - accuracy: 0.7000 - val_loss: 1.0110 - val_accuracy: 0.6068\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6752 - accuracy: 0.6889 - val_loss: 1.0007 - val_accuracy: 0.5897\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6677 - accuracy: 0.6926 - val_loss: 1.1392 - val_accuracy: 0.6325\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0138 - accuracy: 0.7000 - val_loss: 1.6902 - val_accuracy: 0.6239\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.1225 - accuracy: 0.7037 - val_loss: 1.2624 - val_accuracy: 0.6154\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.7504 - accuracy: 0.6926 - val_loss: 1.1774 - val_accuracy: 0.5726\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8676 - accuracy: 0.6333 - val_loss: 1.2196 - val_accuracy: 0.6154\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9119 - accuracy: 0.6741 - val_loss: 1.2019 - val_accuracy: 0.6325\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6929 - accuracy: 0.7074 - val_loss: 1.2476 - val_accuracy: 0.6154\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8207 - accuracy: 0.6889 - val_loss: 1.2170 - val_accuracy: 0.6410\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.8836 - accuracy: 0.7037 - val_loss: 1.3770 - val_accuracy: 0.6325\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.8796 - accuracy: 0.7037 - val_loss: 1.0224 - val_accuracy: 0.6239\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7254 - accuracy: 0.6815 - val_loss: 1.0311 - val_accuracy: 0.6325\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9618 - accuracy: 0.7000 - val_loss: 1.7434 - val_accuracy: 0.6325\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 1.2402 - accuracy: 0.7000 - val_loss: 1.4953 - val_accuracy: 0.6325\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0344 - accuracy: 0.6741 - val_loss: 1.1555 - val_accuracy: 0.6325\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7480 - accuracy: 0.6926 - val_loss: 1.3261 - val_accuracy: 0.5897\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9370 - accuracy: 0.6333 - val_loss: 1.2649 - val_accuracy: 0.6325\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8661 - accuracy: 0.7037 - val_loss: 1.1357 - val_accuracy: 0.6325\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8123 - accuracy: 0.6778 - val_loss: 1.0359 - val_accuracy: 0.6154\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6962 - accuracy: 0.6926 - val_loss: 1.1162 - val_accuracy: 0.5983\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.7016 - accuracy: 0.6852 - val_loss: 1.0398 - val_accuracy: 0.6154\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 514us/step - loss: 0.6667 - accuracy: 0.6963 - val_loss: 0.9909 - val_accuracy: 0.6068\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6921 - accuracy: 0.6926 - val_loss: 1.0019 - val_accuracy: 0.5897\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7078 - accuracy: 0.6889 - val_loss: 1.0598 - val_accuracy: 0.5983\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6875 - accuracy: 0.7074 - val_loss: 1.0705 - val_accuracy: 0.6154\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6663 - accuracy: 0.7074 - val_loss: 1.1137 - val_accuracy: 0.6068\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7025 - accuracy: 0.7000 - val_loss: 1.0523 - val_accuracy: 0.6154\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6985 - accuracy: 0.6926 - val_loss: 0.9967 - val_accuracy: 0.6239\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6629 - accuracy: 0.7000 - val_loss: 1.0246 - val_accuracy: 0.6154\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6765 - accuracy: 0.6889 - val_loss: 1.0100 - val_accuracy: 0.6154\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.6625 - accuracy: 0.7037 - val_loss: 0.9905 - val_accuracy: 0.6068\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6628 - accuracy: 0.6889 - val_loss: 0.9746 - val_accuracy: 0.6068\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6528 - accuracy: 0.7037 - val_loss: 0.9842 - val_accuracy: 0.6154\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6588 - accuracy: 0.6963 - val_loss: 1.0332 - val_accuracy: 0.6239\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6851 - accuracy: 0.6852 - val_loss: 0.9907 - val_accuracy: 0.6154\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6839 - accuracy: 0.6889 - val_loss: 1.0156 - val_accuracy: 0.6239\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6766 - accuracy: 0.6963 - val_loss: 0.9877 - val_accuracy: 0.6068\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6655 - accuracy: 0.7037 - val_loss: 1.0381 - val_accuracy: 0.6154\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6899 - accuracy: 0.7000 - val_loss: 1.0444 - val_accuracy: 0.6068\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6660 - accuracy: 0.6926 - val_loss: 0.9895 - val_accuracy: 0.6239\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6593 - accuracy: 0.6889 - val_loss: 0.9867 - val_accuracy: 0.6239\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6571 - accuracy: 0.7037 - val_loss: 0.9840 - val_accuracy: 0.6410\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6596 - accuracy: 0.6926 - val_loss: 1.0297 - val_accuracy: 0.6410\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6931 - accuracy: 0.7037 - val_loss: 1.0213 - val_accuracy: 0.6325\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6711 - accuracy: 0.6815 - val_loss: 0.9869 - val_accuracy: 0.6154\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6654 - accuracy: 0.7037 - val_loss: 0.9930 - val_accuracy: 0.6154\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7870 - accuracy: 0.6889 - val_loss: 0.9840 - val_accuracy: 0.5983\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7674 - accuracy: 0.6963 - val_loss: 1.2361 - val_accuracy: 0.6239\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8031 - accuracy: 0.7037 - val_loss: 1.0067 - val_accuracy: 0.5812\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6993 - accuracy: 0.6815 - val_loss: 1.0531 - val_accuracy: 0.6068\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6829 - accuracy: 0.7037 - val_loss: 1.0337 - val_accuracy: 0.6325\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7233 - accuracy: 0.6852 - val_loss: 0.9887 - val_accuracy: 0.6496\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7140 - accuracy: 0.6852 - val_loss: 1.0130 - val_accuracy: 0.6325\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7380 - accuracy: 0.7000 - val_loss: 1.0117 - val_accuracy: 0.6410\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7029 - accuracy: 0.6963 - val_loss: 1.0294 - val_accuracy: 0.6154\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6952 - accuracy: 0.7074 - val_loss: 1.0737 - val_accuracy: 0.6325\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6728 - accuracy: 0.7222 - val_loss: 1.0424 - val_accuracy: 0.6239\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6970 - accuracy: 0.6778 - val_loss: 1.0441 - val_accuracy: 0.6154\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6983 - accuracy: 0.7000 - val_loss: 1.0268 - val_accuracy: 0.5812\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.6609 - accuracy: 0.7000 - val_loss: 1.0328 - val_accuracy: 0.6068\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6689 - accuracy: 0.7037 - val_loss: 0.9977 - val_accuracy: 0.6068\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.70 - 0s 100us/step - loss: 0.6502 - accuracy: 0.7074 - val_loss: 0.9947 - val_accuracy: 0.5897\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6581 - accuracy: 0.6926 - val_loss: 0.9870 - val_accuracy: 0.6154\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6434 - accuracy: 0.6963 - val_loss: 1.0514 - val_accuracy: 0.5983\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7553 - accuracy: 0.6815 - val_loss: 1.1220 - val_accuracy: 0.6325\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7836 - accuracy: 0.7000 - val_loss: 1.1358 - val_accuracy: 0.6325\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7292 - accuracy: 0.6926 - val_loss: 1.0939 - val_accuracy: 0.6068\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7583 - accuracy: 0.6852 - val_loss: 1.0479 - val_accuracy: 0.6325\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7306 - accuracy: 0.7000 - val_loss: 1.1031 - val_accuracy: 0.6410\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6979 - accuracy: 0.6963 - val_loss: 1.0609 - val_accuracy: 0.6154\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6851 - accuracy: 0.6926 - val_loss: 1.0113 - val_accuracy: 0.6239\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6581 - accuracy: 0.6963 - val_loss: 1.0671 - val_accuracy: 0.6154\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6760 - accuracy: 0.7074 - val_loss: 1.1242 - val_accuracy: 0.6496\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8254 - accuracy: 0.7000 - val_loss: 1.0981 - val_accuracy: 0.6410\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.7593 - accuracy: 0.7000 - val_loss: 1.1718 - val_accuracy: 0.5897\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.7541 - accuracy: 0.6889 - val_loss: 1.1560 - val_accuracy: 0.6325\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7581 - accuracy: 0.7037 - val_loss: 1.1623 - val_accuracy: 0.5726\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7241 - accuracy: 0.6815 - val_loss: 1.1859 - val_accuracy: 0.5897\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7695 - accuracy: 0.6556 - val_loss: 1.1325 - val_accuracy: 0.5983\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6756 - accuracy: 0.6889 - val_loss: 1.1377 - val_accuracy: 0.5983\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7177 - accuracy: 0.6889 - val_loss: 1.0988 - val_accuracy: 0.6154\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7194 - accuracy: 0.6778 - val_loss: 1.0886 - val_accuracy: 0.6154\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6837 - accuracy: 0.7111 - val_loss: 1.0161 - val_accuracy: 0.5897\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7170 - accuracy: 0.6778 - val_loss: 1.0578 - val_accuracy: 0.6154\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7385 - accuracy: 0.7037 - val_loss: 1.1213 - val_accuracy: 0.6154\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7156 - accuracy: 0.6963 - val_loss: 1.0090 - val_accuracy: 0.5897\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6718 - accuracy: 0.7037 - val_loss: 1.0238 - val_accuracy: 0.5897\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6693 - accuracy: 0.7000 - val_loss: 0.9695 - val_accuracy: 0.6410\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6550 - accuracy: 0.7000 - val_loss: 0.9791 - val_accuracy: 0.6154\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6588 - accuracy: 0.6926 - val_loss: 1.0385 - val_accuracy: 0.6410\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7515 - accuracy: 0.6926 - val_loss: 1.0467 - val_accuracy: 0.6154\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6762 - accuracy: 0.6889 - val_loss: 1.0722 - val_accuracy: 0.5897\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6604 - accuracy: 0.7037 - val_loss: 1.0490 - val_accuracy: 0.6410\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6872 - accuracy: 0.6926 - val_loss: 0.9854 - val_accuracy: 0.5897\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6728 - accuracy: 0.6852 - val_loss: 1.0952 - val_accuracy: 0.6410\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7154 - accuracy: 0.6963 - val_loss: 1.0412 - val_accuracy: 0.6325\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6693 - accuracy: 0.6963 - val_loss: 1.0737 - val_accuracy: 0.6410\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7783 - accuracy: 0.7000 - val_loss: 1.1587 - val_accuracy: 0.6410\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7308 - accuracy: 0.6926 - val_loss: 1.0027 - val_accuracy: 0.6154\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8132 - accuracy: 0.6889 - val_loss: 1.1185 - val_accuracy: 0.6325\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7599 - accuracy: 0.7037 - val_loss: 1.1308 - val_accuracy: 0.6325\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6856 - accuracy: 0.6963 - val_loss: 1.3069 - val_accuracy: 0.6154\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8340 - accuracy: 0.6815 - val_loss: 1.0986 - val_accuracy: 0.6325\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7135 - accuracy: 0.7074 - val_loss: 1.1015 - val_accuracy: 0.6239\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7320 - accuracy: 0.6889 - val_loss: 1.1251 - val_accuracy: 0.6325\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.7989 - accuracy: 0.7037 - val_loss: 1.1515 - val_accuracy: 0.6325\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6887 - accuracy: 0.7111 - val_loss: 1.0428 - val_accuracy: 0.6068\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7495 - accuracy: 0.6741 - val_loss: 1.0618 - val_accuracy: 0.6325\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6698 - accuracy: 0.7037 - val_loss: 1.0801 - val_accuracy: 0.6239\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 62us/step - loss: 0.7034 - accuracy: 0.6963 - val_loss: 1.0409 - val_accuracy: 0.6410\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6817 - accuracy: 0.7111 - val_loss: 1.0274 - val_accuracy: 0.6068\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6691 - accuracy: 0.6815 - val_loss: 0.9995 - val_accuracy: 0.5983\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6793 - accuracy: 0.6852 - val_loss: 1.0278 - val_accuracy: 0.6154\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6715 - accuracy: 0.7000 - val_loss: 1.0074 - val_accuracy: 0.5897\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6726 - accuracy: 0.6889 - val_loss: 1.0229 - val_accuracy: 0.5983\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6771 - accuracy: 0.7037 - val_loss: 1.0391 - val_accuracy: 0.5812\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6644 - accuracy: 0.6852 - val_loss: 1.0164 - val_accuracy: 0.6068\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6787 - accuracy: 0.6852 - val_loss: 1.0355 - val_accuracy: 0.6325\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.71 - 0s 81us/step - loss: 0.6838 - accuracy: 0.7000 - val_loss: 0.9927 - val_accuracy: 0.6068\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6585 - accuracy: 0.7000 - val_loss: 1.0239 - val_accuracy: 0.6410\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6636 - accuracy: 0.7111 - val_loss: 1.0318 - val_accuracy: 0.5812\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6655 - accuracy: 0.7037 - val_loss: 1.0145 - val_accuracy: 0.5726\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6550 - accuracy: 0.7000 - val_loss: 1.0031 - val_accuracy: 0.5983\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6525 - accuracy: 0.6963 - val_loss: 1.0334 - val_accuracy: 0.5812\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6584 - accuracy: 0.7000 - val_loss: 1.0105 - val_accuracy: 0.6325\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6693 - accuracy: 0.6741 - val_loss: 1.0866 - val_accuracy: 0.6410\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7266 - accuracy: 0.7074 - val_loss: 1.1895 - val_accuracy: 0.6239\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.7284 - accuracy: 0.6852 - val_loss: 1.0850 - val_accuracy: 0.6410\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6900 - accuracy: 0.6815 - val_loss: 1.0303 - val_accuracy: 0.6325\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6743 - accuracy: 0.6889 - val_loss: 1.0445 - val_accuracy: 0.6068\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6883 - accuracy: 0.6852 - val_loss: 1.1028 - val_accuracy: 0.6410\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6868 - accuracy: 0.6815 - val_loss: 1.0499 - val_accuracy: 0.6154\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6676 - accuracy: 0.6963 - val_loss: 0.9770 - val_accuracy: 0.6581\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7186 - accuracy: 0.6852 - val_loss: 1.0027 - val_accuracy: 0.6239\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6818 - accuracy: 0.7037 - val_loss: 1.1550 - val_accuracy: 0.6325\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7395 - accuracy: 0.6815 - val_loss: 1.1867 - val_accuracy: 0.6410\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.0418 - accuracy: 0.7037 - val_loss: 1.6839 - val_accuracy: 0.6239\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 1.1272 - accuracy: 0.6963 - val_loss: 1.4065 - val_accuracy: 0.6410\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9877 - accuracy: 0.6519 - val_loss: 1.4207 - val_accuracy: 0.5299\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0616 - accuracy: 0.5852 - val_loss: 1.4058 - val_accuracy: 0.5556\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8846 - accuracy: 0.6519 - val_loss: 1.1528 - val_accuracy: 0.6239\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8635 - accuracy: 0.6889 - val_loss: 1.0962 - val_accuracy: 0.6068\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7126 - accuracy: 0.7111 - val_loss: 1.2323 - val_accuracy: 0.5641\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7941 - accuracy: 0.6556 - val_loss: 1.1300 - val_accuracy: 0.5983\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6734 - accuracy: 0.7000 - val_loss: 1.0822 - val_accuracy: 0.5726\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7591 - accuracy: 0.6889 - val_loss: 1.0899 - val_accuracy: 0.6068\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7199 - accuracy: 0.6852 - val_loss: 1.1552 - val_accuracy: 0.6239\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7614 - accuracy: 0.6778 - val_loss: 1.0930 - val_accuracy: 0.6410\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6693 - accuracy: 0.7000 - val_loss: 1.0201 - val_accuracy: 0.6154\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6946 - accuracy: 0.6926 - val_loss: 0.9944 - val_accuracy: 0.6068\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6489 - accuracy: 0.6926 - val_loss: 1.0151 - val_accuracy: 0.6068\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6556 - accuracy: 0.6963 - val_loss: 1.0602 - val_accuracy: 0.6325\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6705 - accuracy: 0.7000 - val_loss: 0.9934 - val_accuracy: 0.6410\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6505 - accuracy: 0.6963 - val_loss: 1.0090 - val_accuracy: 0.6068\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6592 - accuracy: 0.6963 - val_loss: 1.0043 - val_accuracy: 0.6068\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6521 - accuracy: 0.6963 - val_loss: 1.0385 - val_accuracy: 0.6239\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6519 - accuracy: 0.6963 - val_loss: 1.1225 - val_accuracy: 0.6325\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7181 - accuracy: 0.6963 - val_loss: 1.0276 - val_accuracy: 0.5983\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6667 - accuracy: 0.6852 - val_loss: 0.9854 - val_accuracy: 0.6068\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6415 - accuracy: 0.6926 - val_loss: 0.9989 - val_accuracy: 0.5897\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6463 - accuracy: 0.6926 - val_loss: 0.9806 - val_accuracy: 0.5897\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6476 - accuracy: 0.7037 - val_loss: 1.0230 - val_accuracy: 0.5983\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6608 - accuracy: 0.6963 - val_loss: 1.0038 - val_accuracy: 0.6325\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6469 - accuracy: 0.7074 - val_loss: 1.0275 - val_accuracy: 0.5983\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.7195 - accuracy: 0.7000 - val_loss: 1.0687 - val_accuracy: 0.6154\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6896 - accuracy: 0.6852 - val_loss: 0.9946 - val_accuracy: 0.6325\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6762 - accuracy: 0.6926 - val_loss: 1.1240 - val_accuracy: 0.6410\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7304 - accuracy: 0.7037 - val_loss: 0.9884 - val_accuracy: 0.6068\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7962 - accuracy: 0.6852 - val_loss: 1.0297 - val_accuracy: 0.6325\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6965 - accuracy: 0.7000 - val_loss: 1.0749 - val_accuracy: 0.6239\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6718 - accuracy: 0.7037 - val_loss: 1.1127 - val_accuracy: 0.5726\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7356 - accuracy: 0.6778 - val_loss: 1.0636 - val_accuracy: 0.6068\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7189 - accuracy: 0.6889 - val_loss: 1.0214 - val_accuracy: 0.6325\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7177 - accuracy: 0.7000 - val_loss: 1.0336 - val_accuracy: 0.6325\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6664 - accuracy: 0.7000 - val_loss: 1.0684 - val_accuracy: 0.5983\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6555 - accuracy: 0.7000 - val_loss: 1.0882 - val_accuracy: 0.6239\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6937 - accuracy: 0.7037 - val_loss: 1.0000 - val_accuracy: 0.6154\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6475 - accuracy: 0.7074 - val_loss: 0.9988 - val_accuracy: 0.6325\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6543 - accuracy: 0.6852 - val_loss: 1.0139 - val_accuracy: 0.6154\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6675 - accuracy: 0.7111 - val_loss: 1.0139 - val_accuracy: 0.6154\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6761 - accuracy: 0.6926 - val_loss: 1.0041 - val_accuracy: 0.6410\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7421 - accuracy: 0.7000 - val_loss: 1.0660 - val_accuracy: 0.6410\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7186 - accuracy: 0.6926 - val_loss: 1.0920 - val_accuracy: 0.6410\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6926 - accuracy: 0.6963 - val_loss: 1.0768 - val_accuracy: 0.6154\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7381 - accuracy: 0.6926 - val_loss: 1.0768 - val_accuracy: 0.6410\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7178 - accuracy: 0.7000 - val_loss: 1.1283 - val_accuracy: 0.6410\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6842 - accuracy: 0.6963 - val_loss: 1.0279 - val_accuracy: 0.5983\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6772 - accuracy: 0.6852 - val_loss: 1.0233 - val_accuracy: 0.5897\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6386 - accuracy: 0.7037 - val_loss: 1.0306 - val_accuracy: 0.5812\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6708 - accuracy: 0.7000 - val_loss: 1.0213 - val_accuracy: 0.6068\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6880 - accuracy: 0.6741 - val_loss: 1.0640 - val_accuracy: 0.6325\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6949 - accuracy: 0.7000 - val_loss: 1.0211 - val_accuracy: 0.6410\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7006 - accuracy: 0.6889 - val_loss: 1.0691 - val_accuracy: 0.6325\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6953 - accuracy: 0.7000 - val_loss: 1.1563 - val_accuracy: 0.6325\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.7233 - accuracy: 0.6741 - val_loss: 1.0575 - val_accuracy: 0.6154\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6733 - accuracy: 0.7074 - val_loss: 1.0186 - val_accuracy: 0.6325\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6619 - accuracy: 0.6889 - val_loss: 1.0209 - val_accuracy: 0.6325\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6795 - accuracy: 0.6963 - val_loss: 1.1376 - val_accuracy: 0.6410\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.7286 - accuracy: 0.7037 - val_loss: 1.0566 - val_accuracy: 0.6325\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6521 - accuracy: 0.6963 - val_loss: 0.9832 - val_accuracy: 0.6325\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6456 - accuracy: 0.7037 - val_loss: 1.0100 - val_accuracy: 0.6239\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6561 - accuracy: 0.7000 - val_loss: 0.9918 - val_accuracy: 0.6239\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6513 - accuracy: 0.7037 - val_loss: 1.0002 - val_accuracy: 0.6154\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6479 - accuracy: 0.7074 - val_loss: 1.0007 - val_accuracy: 0.5897\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6460 - accuracy: 0.7000 - val_loss: 1.0034 - val_accuracy: 0.6068\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6657 - accuracy: 0.7000 - val_loss: 1.0013 - val_accuracy: 0.6239\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6437 - accuracy: 0.7074 - val_loss: 1.0194 - val_accuracy: 0.6410\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6546 - accuracy: 0.7037 - val_loss: 1.0070 - val_accuracy: 0.6325\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6476 - accuracy: 0.7000 - val_loss: 0.9849 - val_accuracy: 0.6325\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6510 - accuracy: 0.7000 - val_loss: 1.0165 - val_accuracy: 0.6154\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6965 - accuracy: 0.7000 - val_loss: 1.0368 - val_accuracy: 0.6154\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6702 - accuracy: 0.6963 - val_loss: 1.0028 - val_accuracy: 0.6068\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6718 - accuracy: 0.6889 - val_loss: 1.0081 - val_accuracy: 0.6239\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6988 - accuracy: 0.6704 - val_loss: 1.0229 - val_accuracy: 0.6325\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6499 - accuracy: 0.7037 - val_loss: 1.0682 - val_accuracy: 0.6154\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6780 - accuracy: 0.7037 - val_loss: 1.0674 - val_accuracy: 0.6325\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6827 - accuracy: 0.7000 - val_loss: 1.0195 - val_accuracy: 0.6325\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6477 - accuracy: 0.7037 - val_loss: 0.9955 - val_accuracy: 0.6239\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6488 - accuracy: 0.7000 - val_loss: 0.9796 - val_accuracy: 0.6239\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6404 - accuracy: 0.6963 - val_loss: 1.0070 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6533 - accuracy: 0.7037 - val_loss: 1.0001 - val_accuracy: 0.6581\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6419 - accuracy: 0.7074 - val_loss: 1.0127 - val_accuracy: 0.6239\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6377 - accuracy: 0.7074 - val_loss: 0.9864 - val_accuracy: 0.6154\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6452 - accuracy: 0.6926 - val_loss: 1.0261 - val_accuracy: 0.6325\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6818 - accuracy: 0.6963 - val_loss: 1.0240 - val_accuracy: 0.6068\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6650 - accuracy: 0.6852 - val_loss: 1.0018 - val_accuracy: 0.5897\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6414 - accuracy: 0.6926 - val_loss: 1.0072 - val_accuracy: 0.6068\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6566 - accuracy: 0.6963 - val_loss: 1.0086 - val_accuracy: 0.5983\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6705 - accuracy: 0.6926 - val_loss: 1.1315 - val_accuracy: 0.6325\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8243 - accuracy: 0.7000 - val_loss: 1.5377 - val_accuracy: 0.6154\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 1.0539 - accuracy: 0.7000 - val_loss: 1.2861 - val_accuracy: 0.5983\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8339 - accuracy: 0.7000 - val_loss: 1.0647 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6933 - accuracy: 0.6889 - val_loss: 1.2130 - val_accuracy: 0.5897\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7731 - accuracy: 0.6704 - val_loss: 1.2092 - val_accuracy: 0.6410\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7438 - accuracy: 0.7037 - val_loss: 1.0275 - val_accuracy: 0.5897\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9314 - accuracy: 0.6852 - val_loss: 1.0044 - val_accuracy: 0.5897\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7839 - accuracy: 0.6852 - val_loss: 1.3207 - val_accuracy: 0.6239\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8042 - accuracy: 0.7074 - val_loss: 1.0245 - val_accuracy: 0.5812\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7604 - accuracy: 0.6889 - val_loss: 1.0247 - val_accuracy: 0.5641\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6835 - accuracy: 0.6963 - val_loss: 1.0847 - val_accuracy: 0.6325\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6819 - accuracy: 0.6963 - val_loss: 1.0892 - val_accuracy: 0.6410\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8832 - accuracy: 0.6556 - val_loss: 1.6293 - val_accuracy: 0.5812\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.1931 - accuracy: 0.6259 - val_loss: 1.4733 - val_accuracy: 0.5556\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9026 - accuracy: 0.6519 - val_loss: 1.1505 - val_accuracy: 0.6239\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7507 - accuracy: 0.6926 - val_loss: 1.0390 - val_accuracy: 0.5726\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6945 - accuracy: 0.6778 - val_loss: 1.2091 - val_accuracy: 0.6154\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8342 - accuracy: 0.6593 - val_loss: 1.1753 - val_accuracy: 0.6239\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7199 - accuracy: 0.6778 - val_loss: 1.0018 - val_accuracy: 0.6410\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6869 - accuracy: 0.6926 - val_loss: 1.0611 - val_accuracy: 0.6410\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7026 - accuracy: 0.7000 - val_loss: 1.0398 - val_accuracy: 0.6154\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6870 - accuracy: 0.6889 - val_loss: 1.1131 - val_accuracy: 0.6325\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7309 - accuracy: 0.7000 - val_loss: 1.1413 - val_accuracy: 0.6410\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6919 - accuracy: 0.6963 - val_loss: 1.0784 - val_accuracy: 0.6154\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7086 - accuracy: 0.6815 - val_loss: 1.0708 - val_accuracy: 0.6410\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7261 - accuracy: 0.7074 - val_loss: 1.0645 - val_accuracy: 0.6325\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6575 - accuracy: 0.7074 - val_loss: 1.0143 - val_accuracy: 0.6325\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6765 - accuracy: 0.7000 - val_loss: 1.0305 - val_accuracy: 0.5812\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6746 - accuracy: 0.6704 - val_loss: 0.9933 - val_accuracy: 0.6325\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6520 - accuracy: 0.7000 - val_loss: 1.0079 - val_accuracy: 0.5983\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7163 - accuracy: 0.6815 - val_loss: 1.1028 - val_accuracy: 0.6068\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7185 - accuracy: 0.7037 - val_loss: 1.0486 - val_accuracy: 0.6068\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6522 - accuracy: 0.6963 - val_loss: 0.9982 - val_accuracy: 0.5983\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6452 - accuracy: 0.7037 - val_loss: 1.0293 - val_accuracy: 0.6325\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6572 - accuracy: 0.6963 - val_loss: 1.0445 - val_accuracy: 0.6239\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6685 - accuracy: 0.7000 - val_loss: 1.0031 - val_accuracy: 0.6496\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6598 - accuracy: 0.6926 - val_loss: 1.0208 - val_accuracy: 0.6068\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6438 - accuracy: 0.6963 - val_loss: 1.0193 - val_accuracy: 0.6068\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6473 - accuracy: 0.6963 - val_loss: 0.9963 - val_accuracy: 0.6154\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6450 - accuracy: 0.7037 - val_loss: 1.0233 - val_accuracy: 0.5983\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6521 - accuracy: 0.6963 - val_loss: 1.0585 - val_accuracy: 0.6154\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6585 - accuracy: 0.7074 - val_loss: 1.0463 - val_accuracy: 0.6410\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6495 - accuracy: 0.7111 - val_loss: 1.0475 - val_accuracy: 0.6325\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6924 - accuracy: 0.6926 - val_loss: 1.0501 - val_accuracy: 0.6325\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6833 - accuracy: 0.6889 - val_loss: 0.9956 - val_accuracy: 0.6239\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6454 - accuracy: 0.7000 - val_loss: 1.0149 - val_accuracy: 0.6239\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6509 - accuracy: 0.7037 - val_loss: 0.9926 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6761 - accuracy: 0.6926 - val_loss: 1.0262 - val_accuracy: 0.6239\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6509 - accuracy: 0.6889 - val_loss: 1.0141 - val_accuracy: 0.5983\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6543 - accuracy: 0.7000 - val_loss: 1.0294 - val_accuracy: 0.5983\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6496 - accuracy: 0.7000 - val_loss: 1.0004 - val_accuracy: 0.6068\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6584 - accuracy: 0.6889 - val_loss: 1.0322 - val_accuracy: 0.6239\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6448 - accuracy: 0.7037 - val_loss: 1.0099 - val_accuracy: 0.6239\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.6602 - accuracy: 0.6963 - val_loss: 1.0735 - val_accuracy: 0.6410\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 303us/step - loss: 0.6961 - accuracy: 0.6963 - val_loss: 1.0305 - val_accuracy: 0.6410\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6432 - accuracy: 0.7111 - val_loss: 1.0158 - val_accuracy: 0.6068\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6546 - accuracy: 0.6963 - val_loss: 1.0833 - val_accuracy: 0.6325\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6776 - accuracy: 0.7037 - val_loss: 1.0052 - val_accuracy: 0.6239\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6534 - accuracy: 0.6926 - val_loss: 1.0356 - val_accuracy: 0.6410\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6495 - accuracy: 0.7037 - val_loss: 1.0260 - val_accuracy: 0.6154\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6746 - accuracy: 0.6852 - val_loss: 1.0598 - val_accuracy: 0.6154\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6576 - accuracy: 0.6889 - val_loss: 1.0722 - val_accuracy: 0.5983\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6507 - accuracy: 0.7037 - val_loss: 1.0212 - val_accuracy: 0.6068\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6441 - accuracy: 0.6963 - val_loss: 1.0231 - val_accuracy: 0.6154\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6847 - accuracy: 0.6963 - val_loss: 1.0154 - val_accuracy: 0.6068\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7225 - accuracy: 0.6704 - val_loss: 1.0479 - val_accuracy: 0.6239\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.7540 - accuracy: 0.7074 - val_loss: 1.1230 - val_accuracy: 0.6410\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6968 - accuracy: 0.7000 - val_loss: 1.0323 - val_accuracy: 0.6068\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6716 - accuracy: 0.6889 - val_loss: 1.0769 - val_accuracy: 0.6325\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7497 - accuracy: 0.7000 - val_loss: 1.0639 - val_accuracy: 0.6410\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 294us/step - loss: 0.7226 - accuracy: 0.7000 - val_loss: 1.3484 - val_accuracy: 0.6239\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7812 - accuracy: 0.6926 - val_loss: 1.1955 - val_accuracy: 0.6325\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8346 - accuracy: 0.7000 - val_loss: 1.5021 - val_accuracy: 0.6325\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0129 - accuracy: 0.7000 - val_loss: 1.2254 - val_accuracy: 0.6325\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.7795 - accuracy: 0.6889 - val_loss: 1.0929 - val_accuracy: 0.5983\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7266 - accuracy: 0.6556 - val_loss: 1.3030 - val_accuracy: 0.5726\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8555 - accuracy: 0.6407 - val_loss: 1.1369 - val_accuracy: 0.5812\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6528 - accuracy: 0.7000 - val_loss: 1.1441 - val_accuracy: 0.5726\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.6917 - accuracy: 0.6852 - val_loss: 1.0621 - val_accuracy: 0.6068\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.6801 - accuracy: 0.6889 - val_loss: 1.1576 - val_accuracy: 0.6068\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6908 - accuracy: 0.6963 - val_loss: 1.1144 - val_accuracy: 0.6239\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6859 - accuracy: 0.7000 - val_loss: 0.9881 - val_accuracy: 0.6068\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6760 - accuracy: 0.6815 - val_loss: 0.9922 - val_accuracy: 0.6154\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6379 - accuracy: 0.7037 - val_loss: 1.0111 - val_accuracy: 0.6068\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6498 - accuracy: 0.6963 - val_loss: 1.0059 - val_accuracy: 0.6068\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6529 - accuracy: 0.6926 - val_loss: 0.9970 - val_accuracy: 0.6325\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6552 - accuracy: 0.6889 - val_loss: 0.9847 - val_accuracy: 0.6154\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6543 - accuracy: 0.6889 - val_loss: 0.9955 - val_accuracy: 0.6154\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6439 - accuracy: 0.6926 - val_loss: 0.9955 - val_accuracy: 0.5897\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6403 - accuracy: 0.7000 - val_loss: 1.0044 - val_accuracy: 0.6154\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6363 - accuracy: 0.7000 - val_loss: 1.0080 - val_accuracy: 0.6325\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6504 - accuracy: 0.7000 - val_loss: 0.9776 - val_accuracy: 0.6496\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6402 - accuracy: 0.6889 - val_loss: 0.9863 - val_accuracy: 0.6154\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6427 - accuracy: 0.7037 - val_loss: 1.0256 - val_accuracy: 0.5983\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6389 - accuracy: 0.7074 - val_loss: 1.0005 - val_accuracy: 0.6154\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6537 - accuracy: 0.7000 - val_loss: 1.0035 - val_accuracy: 0.5897\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6537 - accuracy: 0.6963 - val_loss: 1.0341 - val_accuracy: 0.5983\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6618 - accuracy: 0.7000 - val_loss: 1.0849 - val_accuracy: 0.6068\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6672 - accuracy: 0.7037 - val_loss: 1.0269 - val_accuracy: 0.5726\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6945 - accuracy: 0.6741 - val_loss: 1.0625 - val_accuracy: 0.6068\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6893 - accuracy: 0.7000 - val_loss: 1.0796 - val_accuracy: 0.6154\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6619 - accuracy: 0.6852 - val_loss: 1.0577 - val_accuracy: 0.6068\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6747 - accuracy: 0.6926 - val_loss: 1.0419 - val_accuracy: 0.6239\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6480 - accuracy: 0.6963 - val_loss: 1.0446 - val_accuracy: 0.6154\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6488 - accuracy: 0.6963 - val_loss: 1.0294 - val_accuracy: 0.6325\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6663 - accuracy: 0.7000 - val_loss: 1.0001 - val_accuracy: 0.6068\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6540 - accuracy: 0.6926 - val_loss: 1.0247 - val_accuracy: 0.5983\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6587 - accuracy: 0.7074 - val_loss: 1.0428 - val_accuracy: 0.6325\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6448 - accuracy: 0.7111 - val_loss: 1.0230 - val_accuracy: 0.6154\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6522 - accuracy: 0.7000 - val_loss: 1.0799 - val_accuracy: 0.6325\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6796 - accuracy: 0.6963 - val_loss: 1.0101 - val_accuracy: 0.5983\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6700 - accuracy: 0.6889 - val_loss: 1.0296 - val_accuracy: 0.5897\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6495 - accuracy: 0.7000 - val_loss: 1.0113 - val_accuracy: 0.5897\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6803 - accuracy: 0.6963 - val_loss: 0.9884 - val_accuracy: 0.5983\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7329 - accuracy: 0.6889 - val_loss: 1.0385 - val_accuracy: 0.6325\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7238 - accuracy: 0.7000 - val_loss: 1.0298 - val_accuracy: 0.6325\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6976 - accuracy: 0.6852 - val_loss: 1.1220 - val_accuracy: 0.6154\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7080 - accuracy: 0.6815 - val_loss: 1.1663 - val_accuracy: 0.6154\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6806 - accuracy: 0.6926 - val_loss: 1.0668 - val_accuracy: 0.6154\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6588 - accuracy: 0.7000 - val_loss: 0.9854 - val_accuracy: 0.6239\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6597 - accuracy: 0.6926 - val_loss: 1.0250 - val_accuracy: 0.6239\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6761 - accuracy: 0.7000 - val_loss: 1.1015 - val_accuracy: 0.6154\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6779 - accuracy: 0.7000 - val_loss: 1.0688 - val_accuracy: 0.6325\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6550 - accuracy: 0.7074 - val_loss: 1.0083 - val_accuracy: 0.6239\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6539 - accuracy: 0.7000 - val_loss: 1.0658 - val_accuracy: 0.6154\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7326 - accuracy: 0.6889 - val_loss: 1.0777 - val_accuracy: 0.6410\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7165 - accuracy: 0.6963 - val_loss: 1.0778 - val_accuracy: 0.6325\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7300 - accuracy: 0.6889 - val_loss: 0.9925 - val_accuracy: 0.6154\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7957 - accuracy: 0.7037 - val_loss: 1.3585 - val_accuracy: 0.6239\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8318 - accuracy: 0.7037 - val_loss: 1.0716 - val_accuracy: 0.5641\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8086 - accuracy: 0.6815 - val_loss: 1.0386 - val_accuracy: 0.5897\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.6485 - accuracy: 0.7111 - val_loss: 1.1241 - val_accuracy: 0.6325\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6847 - accuracy: 0.7074 - val_loss: 1.0792 - val_accuracy: 0.6154\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6839 - accuracy: 0.6926 - val_loss: 1.0336 - val_accuracy: 0.6410\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6477 - accuracy: 0.7037 - val_loss: 0.9954 - val_accuracy: 0.6068\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6388 - accuracy: 0.7074 - val_loss: 1.0027 - val_accuracy: 0.5983\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.6362 - accuracy: 0.6963 - val_loss: 1.0431 - val_accuracy: 0.6154\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6612 - accuracy: 0.6852 - val_loss: 1.0559 - val_accuracy: 0.6325\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 531us/step - loss: 0.6916 - accuracy: 0.6926 - val_loss: 1.0301 - val_accuracy: 0.6154\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7101 - accuracy: 0.7000 - val_loss: 1.1141 - val_accuracy: 0.6068\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 306us/step - loss: 0.6593 - accuracy: 0.7037 - val_loss: 1.0660 - val_accuracy: 0.5897\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 273us/step - loss: 0.6737 - accuracy: 0.6926 - val_loss: 1.0954 - val_accuracy: 0.6068\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6736 - accuracy: 0.7074 - val_loss: 1.0953 - val_accuracy: 0.5897\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6593 - accuracy: 0.7148 - val_loss: 1.0406 - val_accuracy: 0.5897\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6508 - accuracy: 0.7000 - val_loss: 1.0358 - val_accuracy: 0.5897\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6692 - accuracy: 0.6926 - val_loss: 1.1272 - val_accuracy: 0.6154\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7339 - accuracy: 0.7000 - val_loss: 1.1034 - val_accuracy: 0.6154\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6893 - accuracy: 0.6815 - val_loss: 1.0720 - val_accuracy: 0.6154\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6569 - accuracy: 0.7037 - val_loss: 1.0168 - val_accuracy: 0.6410\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6599 - accuracy: 0.6926 - val_loss: 0.9994 - val_accuracy: 0.6154\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6410 - accuracy: 0.7074 - val_loss: 1.0403 - val_accuracy: 0.6154\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6394 - accuracy: 0.7111 - val_loss: 1.0277 - val_accuracy: 0.6154\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6403 - accuracy: 0.6963 - val_loss: 1.0143 - val_accuracy: 0.5812\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6465 - accuracy: 0.7074 - val_loss: 0.9874 - val_accuracy: 0.6068\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6577 - accuracy: 0.6926 - val_loss: 1.0966 - val_accuracy: 0.6154\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6993 - accuracy: 0.7000 - val_loss: 1.0571 - val_accuracy: 0.6154\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6706 - accuracy: 0.7000 - val_loss: 1.0734 - val_accuracy: 0.6068\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8735 - accuracy: 0.6963 - val_loss: 1.4785 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9586 - accuracy: 0.7000 - val_loss: 1.3509 - val_accuracy: 0.6154\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8412 - accuracy: 0.6778 - val_loss: 1.1459 - val_accuracy: 0.5726\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8085 - accuracy: 0.6593 - val_loss: 1.2211 - val_accuracy: 0.5897\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7359 - accuracy: 0.6778 - val_loss: 1.1254 - val_accuracy: 0.6325\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6628 - accuracy: 0.6963 - val_loss: 1.0653 - val_accuracy: 0.6239\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7186 - accuracy: 0.6852 - val_loss: 1.0844 - val_accuracy: 0.6410\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6712 - accuracy: 0.7037 - val_loss: 1.0585 - val_accuracy: 0.6239\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6456 - accuracy: 0.7000 - val_loss: 1.0029 - val_accuracy: 0.6239\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6369 - accuracy: 0.7074 - val_loss: 1.0098 - val_accuracy: 0.6068\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6797 - accuracy: 0.6926 - val_loss: 1.0542 - val_accuracy: 0.5983\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6568 - accuracy: 0.7037 - val_loss: 1.1469 - val_accuracy: 0.6239\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6767 - accuracy: 0.7000 - val_loss: 1.0700 - val_accuracy: 0.6325\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6517 - accuracy: 0.7074 - val_loss: 1.0054 - val_accuracy: 0.6239\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6375 - accuracy: 0.6963 - val_loss: 1.0068 - val_accuracy: 0.6068\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6448 - accuracy: 0.6963 - val_loss: 1.0053 - val_accuracy: 0.6068\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6386 - accuracy: 0.7074 - val_loss: 1.0377 - val_accuracy: 0.6068\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6455 - accuracy: 0.6963 - val_loss: 1.0197 - val_accuracy: 0.6068\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6422 - accuracy: 0.7037 - val_loss: 1.0098 - val_accuracy: 0.6154\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6384 - accuracy: 0.7037 - val_loss: 0.9915 - val_accuracy: 0.6325\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6376 - accuracy: 0.7000 - val_loss: 1.0155 - val_accuracy: 0.6154\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6576 - accuracy: 0.6963 - val_loss: 1.0202 - val_accuracy: 0.6154\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6494 - accuracy: 0.7037 - val_loss: 1.0294 - val_accuracy: 0.6410\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6349 - accuracy: 0.7000 - val_loss: 1.0204 - val_accuracy: 0.6325\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.6295 - accuracy: 0.7074 - val_loss: 0.9833 - val_accuracy: 0.6496\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 0.6425 - accuracy: 0.6963 - val_loss: 1.0026 - val_accuracy: 0.6154\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.6400 - accuracy: 0.7074 - val_loss: 0.9851 - val_accuracy: 0.6239\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.6406 - accuracy: 0.7000 - val_loss: 1.0171 - val_accuracy: 0.5812\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6368 - accuracy: 0.7074 - val_loss: 1.0009 - val_accuracy: 0.5983\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6315 - accuracy: 0.7074 - val_loss: 1.0421 - val_accuracy: 0.6068\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6356 - accuracy: 0.7037 - val_loss: 1.0283 - val_accuracy: 0.5726\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6388 - accuracy: 0.7000 - val_loss: 1.0411 - val_accuracy: 0.5641\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6398 - accuracy: 0.6963 - val_loss: 1.0129 - val_accuracy: 0.5897\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6344 - accuracy: 0.7074 - val_loss: 1.0108 - val_accuracy: 0.6154\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6309 - accuracy: 0.7037 - val_loss: 1.0181 - val_accuracy: 0.6068\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6437 - accuracy: 0.7000 - val_loss: 1.0097 - val_accuracy: 0.5726\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6451 - accuracy: 0.7000 - val_loss: 0.9995 - val_accuracy: 0.5812\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6637 - accuracy: 0.6815 - val_loss: 1.1640 - val_accuracy: 0.5897\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7694 - accuracy: 0.6407 - val_loss: 1.2404 - val_accuracy: 0.6239\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7103 - accuracy: 0.6852 - val_loss: 1.0218 - val_accuracy: 0.6068\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6616 - accuracy: 0.7074 - val_loss: 1.1003 - val_accuracy: 0.6410\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.6803 - accuracy: 0.6889 - val_loss: 1.0332 - val_accuracy: 0.6068\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6481 - accuracy: 0.6889 - val_loss: 1.0347 - val_accuracy: 0.6325\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6467 - accuracy: 0.7000 - val_loss: 1.0410 - val_accuracy: 0.6068\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7070 - accuracy: 0.6815 - val_loss: 1.1384 - val_accuracy: 0.6154\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9334 - accuracy: 0.6704 - val_loss: 1.6800 - val_accuracy: 0.5812\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0462 - accuracy: 0.6519 - val_loss: 1.1214 - val_accuracy: 0.5897\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7390 - accuracy: 0.70 - 0s 57us/step - loss: 0.8015 - accuracy: 0.6852 - val_loss: 1.1053 - val_accuracy: 0.6239\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.9928 - accuracy: 0.6852 - val_loss: 1.8593 - val_accuracy: 0.6068\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 1.3022 - accuracy: 0.6444 - val_loss: 1.3748 - val_accuracy: 0.6154\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8107 - accuracy: 0.6556 - val_loss: 1.1209 - val_accuracy: 0.6239\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8224 - accuracy: 0.6593 - val_loss: 1.2837 - val_accuracy: 0.6325\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 1.0290 - accuracy: 0.6519 - val_loss: 1.2972 - val_accuracy: 0.6239\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9325 - accuracy: 0.6593 - val_loss: 1.5342 - val_accuracy: 0.5812\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0136 - accuracy: 0.6481 - val_loss: 1.1934 - val_accuracy: 0.6496\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8601 - accuracy: 0.6630 - val_loss: 1.3996 - val_accuracy: 0.6239\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8706 - accuracy: 0.6519 - val_loss: 1.2840 - val_accuracy: 0.5983\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6938 - accuracy: 0.6815 - val_loss: 1.0620 - val_accuracy: 0.6154\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6905 - accuracy: 0.6963 - val_loss: 1.0672 - val_accuracy: 0.6410\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 284us/step - loss: 0.6709 - accuracy: 0.7037 - val_loss: 1.0375 - val_accuracy: 0.6325\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7039 - accuracy: 0.6741 - val_loss: 1.0613 - val_accuracy: 0.6154\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6685 - accuracy: 0.6704 - val_loss: 1.0292 - val_accuracy: 0.6068\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6457 - accuracy: 0.6963 - val_loss: 1.0175 - val_accuracy: 0.6068\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6533 - accuracy: 0.6926 - val_loss: 1.0285 - val_accuracy: 0.5812\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6789 - accuracy: 0.7000 - val_loss: 1.0235 - val_accuracy: 0.5897\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6624 - accuracy: 0.7037 - val_loss: 1.0201 - val_accuracy: 0.6154\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6560 - accuracy: 0.7074 - val_loss: 1.0766 - val_accuracy: 0.6410\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6651 - accuracy: 0.7000 - val_loss: 1.0135 - val_accuracy: 0.6325\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.6604 - accuracy: 0.6889 - val_loss: 1.0530 - val_accuracy: 0.6410\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 411us/step - loss: 0.6808 - accuracy: 0.7000 - val_loss: 1.0586 - val_accuracy: 0.6410\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6378 - accuracy: 0.7074 - val_loss: 1.0497 - val_accuracy: 0.6154\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7546 - accuracy: 0.6852 - val_loss: 1.0428 - val_accuracy: 0.6325\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7043 - accuracy: 0.7037 - val_loss: 1.1562 - val_accuracy: 0.6410\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.7119 - accuracy: 0.7000 - val_loss: 1.0121 - val_accuracy: 0.5983\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8216 - accuracy: 0.6889 - val_loss: 1.2235 - val_accuracy: 0.5983\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7404 - accuracy: 0.7037 - val_loss: 1.1435 - val_accuracy: 0.6325\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6805 - accuracy: 0.6963 - val_loss: 1.0780 - val_accuracy: 0.6154\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6620 - accuracy: 0.6889 - val_loss: 1.0660 - val_accuracy: 0.6325\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6751 - accuracy: 0.6963 - val_loss: 1.0401 - val_accuracy: 0.6325\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.6569 - accuracy: 0.6889 - val_loss: 1.0477 - val_accuracy: 0.6325\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.7959 - accuracy: 0.7000 - val_loss: 1.2634 - val_accuracy: 0.6325\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8247 - accuracy: 0.6963 - val_loss: 1.0710 - val_accuracy: 0.6410\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.6838 - accuracy: 0.6963 - val_loss: 1.3350 - val_accuracy: 0.5983\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 356us/step - loss: 0.7735 - accuracy: 0.6852 - val_loss: 1.1483 - val_accuracy: 0.6410\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 371us/step - loss: 0.7270 - accuracy: 0.7037 - val_loss: 1.0772 - val_accuracy: 0.6239\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6728 - accuracy: 0.7111 - val_loss: 1.0291 - val_accuracy: 0.6239\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7264 - accuracy: 0.7037 - val_loss: 1.3510 - val_accuracy: 0.6154\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8939 - accuracy: 0.7000 - val_loss: 1.2248 - val_accuracy: 0.6239\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.7536 - accuracy: 0.7037 - val_loss: 1.0469 - val_accuracy: 0.5897\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.6686 - accuracy: 0.6963 - val_loss: 1.0950 - val_accuracy: 0.6154\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.6721 - accuracy: 0.6926 - val_loss: 1.0887 - val_accuracy: 0.5726\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6479 - accuracy: 0.7074 - val_loss: 1.0549 - val_accuracy: 0.6239\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.6468 - accuracy: 0.7037 - val_loss: 1.0267 - val_accuracy: 0.6154\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6568 - accuracy: 0.6926 - val_loss: 1.0251 - val_accuracy: 0.6154\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6857 - accuracy: 0.6963 - val_loss: 1.1049 - val_accuracy: 0.6239\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6735 - accuracy: 0.7037 - val_loss: 0.9963 - val_accuracy: 0.6239\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6765 - accuracy: 0.6926 - val_loss: 1.0527 - val_accuracy: 0.6239\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6966 - accuracy: 0.7037 - val_loss: 1.1035 - val_accuracy: 0.6325\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6820 - accuracy: 0.7037 - val_loss: 0.9891 - val_accuracy: 0.6325\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6712 - accuracy: 0.6889 - val_loss: 0.9995 - val_accuracy: 0.6325\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6481 - accuracy: 0.6926 - val_loss: 1.0469 - val_accuracy: 0.5983\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6718 - accuracy: 0.7037 - val_loss: 1.0323 - val_accuracy: 0.5983\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6802 - accuracy: 0.6963 - val_loss: 1.0196 - val_accuracy: 0.5983\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6448 - accuracy: 0.7074 - val_loss: 1.0181 - val_accuracy: 0.6068\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6522 - accuracy: 0.6963 - val_loss: 1.0576 - val_accuracy: 0.6239\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8055 - accuracy: 0.7000 - val_loss: 1.3409 - val_accuracy: 0.6325\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8205 - accuracy: 0.7037 - val_loss: 1.0884 - val_accuracy: 0.6154\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8070 - accuracy: 0.6741 - val_loss: 1.2783 - val_accuracy: 0.6068\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7309 - accuracy: 0.6815 - val_loss: 1.1488 - val_accuracy: 0.6410\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7637 - accuracy: 0.7037 - val_loss: 1.1350 - val_accuracy: 0.6239\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6538 - accuracy: 0.7074 - val_loss: 1.0950 - val_accuracy: 0.6068\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 57us/step - loss: 0.6923 - accuracy: 0.6963 - val_loss: 1.0207 - val_accuracy: 0.5897\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6843 - accuracy: 0.6963 - val_loss: 1.0129 - val_accuracy: 0.6068\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6499 - accuracy: 0.7000 - val_loss: 1.0148 - val_accuracy: 0.6410\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6601 - accuracy: 0.7000 - val_loss: 1.0445 - val_accuracy: 0.6325\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6364 - accuracy: 0.7111 - val_loss: 1.1002 - val_accuracy: 0.6068\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6965 - accuracy: 0.6741 - val_loss: 1.0526 - val_accuracy: 0.6239\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6624 - accuracy: 0.7000 - val_loss: 1.0001 - val_accuracy: 0.6154\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6417 - accuracy: 0.7074 - val_loss: 1.0536 - val_accuracy: 0.6068\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6915 - accuracy: 0.7000 - val_loss: 1.0412 - val_accuracy: 0.6068\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6854 - accuracy: 0.6963 - val_loss: 1.0338 - val_accuracy: 0.6239\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6490 - accuracy: 0.7111 - val_loss: 1.0977 - val_accuracy: 0.6154\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6548 - accuracy: 0.7000 - val_loss: 1.0429 - val_accuracy: 0.6410\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6390 - accuracy: 0.7000 - val_loss: 1.0341 - val_accuracy: 0.5812\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6448 - accuracy: 0.7037 - val_loss: 1.0264 - val_accuracy: 0.5897\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6507 - accuracy: 0.7037 - val_loss: 1.0589 - val_accuracy: 0.5812\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6846 - accuracy: 0.7037 - val_loss: 1.1510 - val_accuracy: 0.5812\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6830 - accuracy: 0.6963 - val_loss: 1.1114 - val_accuracy: 0.6068\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6445 - accuracy: 0.7111 - val_loss: 1.0377 - val_accuracy: 0.6325\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.6692 - accuracy: 0.6963 - val_loss: 1.0364 - val_accuracy: 0.6325\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6364 - accuracy: 0.7000 - val_loss: 1.0503 - val_accuracy: 0.6325\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6550 - accuracy: 0.7037 - val_loss: 1.0613 - val_accuracy: 0.6068\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 263us/step - loss: 0.6285 - accuracy: 0.6852 - val_loss: 1.0579 - val_accuracy: 0.5812\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6782 - accuracy: 0.6963 - val_loss: 1.1499 - val_accuracy: 0.6239\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.7382 - accuracy: 0.6778 - val_loss: 1.2720 - val_accuracy: 0.5983\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.6846 - accuracy: 0.6889 - val_loss: 1.1537 - val_accuracy: 0.6325\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.7154 - accuracy: 0.7000 - val_loss: 1.2120 - val_accuracy: 0.6325\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6978 - accuracy: 0.6926 - val_loss: 1.1210 - val_accuracy: 0.5983\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6744 - accuracy: 0.7037 - val_loss: 1.2113 - val_accuracy: 0.5983\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7328 - accuracy: 0.6778 - val_loss: 1.2032 - val_accuracy: 0.6496\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7785 - accuracy: 0.7037 - val_loss: 1.1883 - val_accuracy: 0.6410\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.7430 - accuracy: 0.6926 - val_loss: 1.0668 - val_accuracy: 0.5641\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.6785 - accuracy: 0.6852 - val_loss: 1.1142 - val_accuracy: 0.6154\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.6629 - accuracy: 0.7185 - val_loss: 1.0787 - val_accuracy: 0.6410\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6393 - accuracy: 0.7074 - val_loss: 1.0231 - val_accuracy: 0.6581\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6443 - accuracy: 0.6926 - val_loss: 1.0934 - val_accuracy: 0.6410\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.7764 - accuracy: 0.6852 - val_loss: 1.3553 - val_accuracy: 0.6068\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.7591 - accuracy: 0.6667 - val_loss: 1.2065 - val_accuracy: 0.6154\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.7284 - accuracy: 0.6889 - val_loss: 1.1893 - val_accuracy: 0.6154\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.7894 - accuracy: 0.6926 - val_loss: 1.1823 - val_accuracy: 0.6239\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.7647 - accuracy: 0.7037 - val_loss: 1.1245 - val_accuracy: 0.5897\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.6915 - accuracy: 0.6926 - val_loss: 1.1140 - val_accuracy: 0.6068\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6695 - accuracy: 0.6889 - val_loss: 1.0766 - val_accuracy: 0.5812\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6424 - accuracy: 0.7037 - val_loss: 1.0501 - val_accuracy: 0.6239\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.6537 - accuracy: 0.6889 - val_loss: 1.0619 - val_accuracy: 0.6410\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6789 - accuracy: 0.6963 - val_loss: 1.0990 - val_accuracy: 0.6410\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6619 - accuracy: 0.6926 - val_loss: 1.0502 - val_accuracy: 0.6325\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6390 - accuracy: 0.7074 - val_loss: 1.0256 - val_accuracy: 0.6154\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.6376 - accuracy: 0.6926 - val_loss: 1.0115 - val_accuracy: 0.6325\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.6341 - accuracy: 0.6963 - val_loss: 1.0228 - val_accuracy: 0.6154\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6338 - accuracy: 0.7037 - val_loss: 1.0165 - val_accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6295 - accuracy: 0.6889 - val_loss: 1.0167 - val_accuracy: 0.6325\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6309 - accuracy: 0.7000 - val_loss: 1.0260 - val_accuracy: 0.6068\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6294 - accuracy: 0.7037 - val_loss: 1.0429 - val_accuracy: 0.6239\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6409 - accuracy: 0.7037 - val_loss: 1.0126 - val_accuracy: 0.6325\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6327 - accuracy: 0.6963 - val_loss: 1.0043 - val_accuracy: 0.6325\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.6431 - accuracy: 0.7037 - val_loss: 1.0855 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.6445 - accuracy: 0.7074 - val_loss: 1.0007 - val_accuracy: 0.6325\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.6510 - accuracy: 0.6963 - val_loss: 1.0078 - val_accuracy: 0.6154\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6398 - accuracy: 0.7000 - val_loss: 1.0445 - val_accuracy: 0.6239\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.6340 - accuracy: 0.7111 - val_loss: 1.0767 - val_accuracy: 0.5983\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6774 - accuracy: 0.6889 - val_loss: 1.0571 - val_accuracy: 0.6068\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6448 - accuracy: 0.7000 - val_loss: 1.0102 - val_accuracy: 0.6068\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6412 - accuracy: 0.6926 - val_loss: 1.0284 - val_accuracy: 0.6239\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6397 - accuracy: 0.7000 - val_loss: 1.0135 - val_accuracy: 0.5897\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.6966 - accuracy: 0.6852 - val_loss: 1.0877 - val_accuracy: 0.6239\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.6851 - accuracy: 0.6889 - val_loss: 1.0505 - val_accuracy: 0.6154\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.9122 - accuracy: 0.7037 - val_loss: 1.4862 - val_accuracy: 0.6154\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9828 - accuracy: 0.7037 - val_loss: 1.2581 - val_accuracy: 0.6410\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7452 - accuracy: 0.6889 - val_loss: 1.0869 - val_accuracy: 0.5983\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.8504 - accuracy: 0.6667 - val_loss: 1.1657 - val_accuracy: 0.6068\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.7832 - accuracy: 0.7000 - val_loss: 1.2899 - val_accuracy: 0.6410\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 385us/step - loss: 0.7340 - accuracy: 0.7037 - val_loss: 1.0482 - val_accuracy: 0.6496\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 528us/step - loss: 0.6892 - accuracy: 0.6852 - val_loss: 1.0320 - val_accuracy: 0.6239\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6662 - accuracy: 0.6963 - val_loss: 1.0748 - val_accuracy: 0.6410\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6379 - accuracy: 0.7074 - val_loss: 1.0468 - val_accuracy: 0.6154\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6525 - accuracy: 0.6889 - val_loss: 1.0551 - val_accuracy: 0.6068\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6775 - accuracy: 0.7000 - val_loss: 1.0454 - val_accuracy: 0.6325\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6408 - accuracy: 0.7037 - val_loss: 1.0046 - val_accuracy: 0.5897\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6438 - accuracy: 0.7037 - val_loss: 1.0660 - val_accuracy: 0.6239\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.6415 - accuracy: 0.7037 - val_loss: 1.0228 - val_accuracy: 0.6068\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 519us/step - loss: 0.6401 - accuracy: 0.7000 - val_loss: 1.0454 - val_accuracy: 0.5897\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.6456 - accuracy: 0.7074 - val_loss: 1.0178 - val_accuracy: 0.5812\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6307 - accuracy: 0.7000 - val_loss: 1.0042 - val_accuracy: 0.6154\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6347 - accuracy: 0.7037 - val_loss: 1.0236 - val_accuracy: 0.5983\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6410 - accuracy: 0.6926 - val_loss: 1.0093 - val_accuracy: 0.6154\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6379 - accuracy: 0.7000 - val_loss: 1.0204 - val_accuracy: 0.5897\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6283 - accuracy: 0.7037 - val_loss: 1.0154 - val_accuracy: 0.5983\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6831 - accuracy: 0.6778 - val_loss: 1.0187 - val_accuracy: 0.5897\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6679 - accuracy: 0.7000 - val_loss: 1.0139 - val_accuracy: 0.6410\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6295 - accuracy: 0.7000 - val_loss: 1.0399 - val_accuracy: 0.6325\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6382 - accuracy: 0.6889 - val_loss: 1.0032 - val_accuracy: 0.6410\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6287 - accuracy: 0.7074 - val_loss: 1.0258 - val_accuracy: 0.6239\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6385 - accuracy: 0.6963 - val_loss: 1.0396 - val_accuracy: 0.5897\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6728 - accuracy: 0.6963 - val_loss: 1.1765 - val_accuracy: 0.6068\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7048 - accuracy: 0.7000 - val_loss: 1.1710 - val_accuracy: 0.6154\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6665 - accuracy: 0.7000 - val_loss: 1.0815 - val_accuracy: 0.6154\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6580 - accuracy: 0.7037 - val_loss: 1.1189 - val_accuracy: 0.6068\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6549 - accuracy: 0.6926 - val_loss: 1.0613 - val_accuracy: 0.6410\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6616 - accuracy: 0.6963 - val_loss: 1.0889 - val_accuracy: 0.6154\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6525 - accuracy: 0.7074 - val_loss: 1.0176 - val_accuracy: 0.6325\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6617 - accuracy: 0.6889 - val_loss: 1.0689 - val_accuracy: 0.6068\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7028 - accuracy: 0.7037 - val_loss: 1.1338 - val_accuracy: 0.6154\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6698 - accuracy: 0.7000 - val_loss: 1.0276 - val_accuracy: 0.6068\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6772 - accuracy: 0.6852 - val_loss: 1.0746 - val_accuracy: 0.6325\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.6707 - accuracy: 0.7074 - val_loss: 1.0706 - val_accuracy: 0.6325\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6450 - accuracy: 0.7037 - val_loss: 1.0100 - val_accuracy: 0.6154\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6295 - accuracy: 0.7000 - val_loss: 1.0344 - val_accuracy: 0.6410\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6687 - accuracy: 0.7000 - val_loss: 1.0629 - val_accuracy: 0.6410\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6449 - accuracy: 0.6963 - val_loss: 1.0790 - val_accuracy: 0.6068\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6689 - accuracy: 0.6852 - val_loss: 1.0763 - val_accuracy: 0.5983\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6992 - accuracy: 0.6889 - val_loss: 1.0443 - val_accuracy: 0.6154\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6281 - accuracy: 0.7148 - val_loss: 1.0845 - val_accuracy: 0.5812\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6541 - accuracy: 0.6889 - val_loss: 1.0462 - val_accuracy: 0.6325\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.6627 - accuracy: 0.7000 - val_loss: 1.0440 - val_accuracy: 0.6325\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6422 - accuracy: 0.6926 - val_loss: 1.0448 - val_accuracy: 0.6068\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6447 - accuracy: 0.6926 - val_loss: 1.0598 - val_accuracy: 0.6325\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6603 - accuracy: 0.7037 - val_loss: 1.0240 - val_accuracy: 0.6154\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6756 - accuracy: 0.6926 - val_loss: 1.0738 - val_accuracy: 0.6325\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6575 - accuracy: 0.7037 - val_loss: 1.1322 - val_accuracy: 0.6410\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6638 - accuracy: 0.7037 - val_loss: 1.0350 - val_accuracy: 0.6325\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6428 - accuracy: 0.6926 - val_loss: 1.0441 - val_accuracy: 0.6410\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6442 - accuracy: 0.7037 - val_loss: 1.0257 - val_accuracy: 0.6068\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6245 - accuracy: 0.6963 - val_loss: 1.0194 - val_accuracy: 0.6068\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6414 - accuracy: 0.7074 - val_loss: 1.0381 - val_accuracy: 0.5897\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6578 - accuracy: 0.6815 - val_loss: 1.0417 - val_accuracy: 0.6154\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6754 - accuracy: 0.7000 - val_loss: 1.0424 - val_accuracy: 0.6410\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6381 - accuracy: 0.7074 - val_loss: 1.1385 - val_accuracy: 0.6239\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6860 - accuracy: 0.6889 - val_loss: 1.1458 - val_accuracy: 0.6325\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 316us/step - loss: 0.6814 - accuracy: 0.6889 - val_loss: 1.0986 - val_accuracy: 0.6325\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6561 - accuracy: 0.6926 - val_loss: 1.0438 - val_accuracy: 0.6068\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8379 - accuracy: 0.6741 - val_loss: 1.1078 - val_accuracy: 0.5983\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6848 - accuracy: 0.7000 - val_loss: 1.2502 - val_accuracy: 0.6239\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7244 - accuracy: 0.6963 - val_loss: 1.1397 - val_accuracy: 0.6068\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6840 - accuracy: 0.6852 - val_loss: 1.0635 - val_accuracy: 0.6239\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6421 - accuracy: 0.7037 - val_loss: 1.0544 - val_accuracy: 0.5897\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6508 - accuracy: 0.6926 - val_loss: 1.0675 - val_accuracy: 0.6154\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6630 - accuracy: 0.7111 - val_loss: 1.0917 - val_accuracy: 0.6239\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6574 - accuracy: 0.6926 - val_loss: 1.0627 - val_accuracy: 0.6325\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.6365 - accuracy: 0.7111 - val_loss: 1.0358 - val_accuracy: 0.6325\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6430 - accuracy: 0.7000 - val_loss: 1.0219 - val_accuracy: 0.6325\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6285 - accuracy: 0.7037 - val_loss: 1.0737 - val_accuracy: 0.6154\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.6396 - accuracy: 0.7074 - val_loss: 1.0639 - val_accuracy: 0.6410\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6397 - accuracy: 0.6926 - val_loss: 1.0344 - val_accuracy: 0.6410\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.73 - 0s 94us/step - loss: 0.6658 - accuracy: 0.6926 - val_loss: 1.0266 - val_accuracy: 0.6410\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6363 - accuracy: 0.7000 - val_loss: 1.0689 - val_accuracy: 0.5983\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6712 - accuracy: 0.6926 - val_loss: 1.0400 - val_accuracy: 0.6239\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6527 - accuracy: 0.6963 - val_loss: 1.0391 - val_accuracy: 0.6154\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6346 - accuracy: 0.7037 - val_loss: 1.0280 - val_accuracy: 0.6068\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6453 - accuracy: 0.6630 - val_loss: 1.0621 - val_accuracy: 0.6154\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6423 - accuracy: 0.7111 - val_loss: 1.0389 - val_accuracy: 0.6154\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6415 - accuracy: 0.7037 - val_loss: 1.0575 - val_accuracy: 0.6154\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6782 - accuracy: 0.6963 - val_loss: 1.1233 - val_accuracy: 0.6325\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6584 - accuracy: 0.7037 - val_loss: 1.0269 - val_accuracy: 0.5983\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6434 - accuracy: 0.6926 - val_loss: 1.0526 - val_accuracy: 0.6239\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6387 - accuracy: 0.7185 - val_loss: 1.0392 - val_accuracy: 0.6496\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6271 - accuracy: 0.7074 - val_loss: 1.0245 - val_accuracy: 0.6496\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6533 - accuracy: 0.6926 - val_loss: 1.0801 - val_accuracy: 0.6410\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7104 - accuracy: 0.7037 - val_loss: 1.1516 - val_accuracy: 0.6410\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.6750 - accuracy: 0.7000 - val_loss: 1.0057 - val_accuracy: 0.5983\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6521 - accuracy: 0.6963 - val_loss: 1.0260 - val_accuracy: 0.5726\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6357 - accuracy: 0.7000 - val_loss: 1.0236 - val_accuracy: 0.5983\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6356 - accuracy: 0.7000 - val_loss: 1.0162 - val_accuracy: 0.5983\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6285 - accuracy: 0.6926 - val_loss: 1.0394 - val_accuracy: 0.6154\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6326 - accuracy: 0.7074 - val_loss: 1.0186 - val_accuracy: 0.6325\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6352 - accuracy: 0.6889 - val_loss: 1.0533 - val_accuracy: 0.6239\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6547 - accuracy: 0.7037 - val_loss: 1.0451 - val_accuracy: 0.6410\n",
      "Epoch 777/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 106us/step - loss: 0.6280 - accuracy: 0.7148 - val_loss: 1.0542 - val_accuracy: 0.6154\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6511 - accuracy: 0.6852 - val_loss: 1.0851 - val_accuracy: 0.6154\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6586 - accuracy: 0.6926 - val_loss: 1.0625 - val_accuracy: 0.6410\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6426 - accuracy: 0.6963 - val_loss: 1.0194 - val_accuracy: 0.6325\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6274 - accuracy: 0.7111 - val_loss: 1.0053 - val_accuracy: 0.6496\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6274 - accuracy: 0.7074 - val_loss: 1.0410 - val_accuracy: 0.6239\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6230 - accuracy: 0.7074 - val_loss: 1.0284 - val_accuracy: 0.6154\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.6231 - accuracy: 0.7037 - val_loss: 1.0171 - val_accuracy: 0.5983\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.6199 - accuracy: 0.7037 - val_loss: 1.0341 - val_accuracy: 0.5983\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6213 - accuracy: 0.7000 - val_loss: 1.0469 - val_accuracy: 0.6325\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6250 - accuracy: 0.7000 - val_loss: 1.0307 - val_accuracy: 0.6068\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6235 - accuracy: 0.7000 - val_loss: 1.0227 - val_accuracy: 0.6068\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6224 - accuracy: 0.7074 - val_loss: 1.0199 - val_accuracy: 0.6068\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.6302 - accuracy: 0.7000 - val_loss: 1.0252 - val_accuracy: 0.5726\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.6439 - accuracy: 0.6852 - val_loss: 1.0743 - val_accuracy: 0.6154\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6826 - accuracy: 0.7037 - val_loss: 1.1000 - val_accuracy: 0.6410\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6700 - accuracy: 0.6926 - val_loss: 1.0304 - val_accuracy: 0.5983\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6269 - accuracy: 0.6963 - val_loss: 1.0875 - val_accuracy: 0.6325\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6468 - accuracy: 0.7037 - val_loss: 1.0488 - val_accuracy: 0.6325\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6514 - accuracy: 0.6815 - val_loss: 1.0872 - val_accuracy: 0.6410\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7705 - accuracy: 0.6926 - val_loss: 1.2526 - val_accuracy: 0.6239\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.7938 - accuracy: 0.7037 - val_loss: 1.0774 - val_accuracy: 0.6154\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6504 - accuracy: 0.7000 - val_loss: 1.2101 - val_accuracy: 0.5897\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7047 - accuracy: 0.6963 - val_loss: 1.1883 - val_accuracy: 0.6325\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.7247 - accuracy: 0.7111 - val_loss: 1.0933 - val_accuracy: 0.6496\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6677 - accuracy: 0.6926 - val_loss: 1.0733 - val_accuracy: 0.5897\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6459 - accuracy: 0.7000 - val_loss: 1.1286 - val_accuracy: 0.6325\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 264us/step - loss: 0.6861 - accuracy: 0.7000 - val_loss: 1.0776 - val_accuracy: 0.6154\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.6462 - accuracy: 0.6852 - val_loss: 1.0262 - val_accuracy: 0.6239\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6301 - accuracy: 0.7000 - val_loss: 1.0378 - val_accuracy: 0.6325\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.6393 - accuracy: 0.6926 - val_loss: 1.0064 - val_accuracy: 0.5897\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6253 - accuracy: 0.6926 - val_loss: 1.0497 - val_accuracy: 0.6154\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6739 - accuracy: 0.7000 - val_loss: 1.1227 - val_accuracy: 0.6154\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6495 - accuracy: 0.7037 - val_loss: 1.1218 - val_accuracy: 0.5897\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6490 - accuracy: 0.7000 - val_loss: 1.0644 - val_accuracy: 0.6239\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.6476 - accuracy: 0.7037 - val_loss: 1.1278 - val_accuracy: 0.6325\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.9086 - accuracy: 0.6815 - val_loss: 1.6242 - val_accuracy: 0.6154\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 1.0075 - accuracy: 0.6630 - val_loss: 1.3855 - val_accuracy: 0.6154\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7684 - accuracy: 0.6741 - val_loss: 1.3647 - val_accuracy: 0.6496\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 256us/step - loss: 1.0095 - accuracy: 0.6926 - val_loss: 1.4979 - val_accuracy: 0.6325\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.7893 - accuracy: 0.6963 - val_loss: 1.3238 - val_accuracy: 0.5641\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.0118 - accuracy: 0.6519 - val_loss: 1.0852 - val_accuracy: 0.6239\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6630 - accuracy: 0.6926 - val_loss: 1.1481 - val_accuracy: 0.6410\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6983 - accuracy: 0.6963 - val_loss: 1.0622 - val_accuracy: 0.5983\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6676 - accuracy: 0.6926 - val_loss: 1.0832 - val_accuracy: 0.6154\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6456 - accuracy: 0.7037 - val_loss: 1.1134 - val_accuracy: 0.6154\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6520 - accuracy: 0.6963 - val_loss: 1.0681 - val_accuracy: 0.6410\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6380 - accuracy: 0.7000 - val_loss: 1.0304 - val_accuracy: 0.6581\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.6537 - accuracy: 0.6852 - val_loss: 1.0645 - val_accuracy: 0.6410\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6811 - accuracy: 0.7000 - val_loss: 1.0536 - val_accuracy: 0.6410\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6555 - accuracy: 0.7000 - val_loss: 1.0357 - val_accuracy: 0.6239\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.6529 - accuracy: 0.6963 - val_loss: 1.1410 - val_accuracy: 0.6496\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6973 - accuracy: 0.6963 - val_loss: 1.0721 - val_accuracy: 0.6239\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6552 - accuracy: 0.7074 - val_loss: 1.0925 - val_accuracy: 0.5897\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6744 - accuracy: 0.6889 - val_loss: 1.1670 - val_accuracy: 0.6239\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7208 - accuracy: 0.6926 - val_loss: 1.0667 - val_accuracy: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6304 - accuracy: 0.6963 - val_loss: 1.0313 - val_accuracy: 0.6239\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6327 - accuracy: 0.6963 - val_loss: 1.0360 - val_accuracy: 0.6239\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.6346 - accuracy: 0.6852 - val_loss: 1.0259 - val_accuracy: 0.6581\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6329 - accuracy: 0.6963 - val_loss: 1.0102 - val_accuracy: 0.6325\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6305 - accuracy: 0.6963 - val_loss: 1.0048 - val_accuracy: 0.6581\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6466 - accuracy: 0.6889 - val_loss: 1.0445 - val_accuracy: 0.6325\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6370 - accuracy: 0.7148 - val_loss: 1.0244 - val_accuracy: 0.6410\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6230 - accuracy: 0.7037 - val_loss: 1.0553 - val_accuracy: 0.6239\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6779 - accuracy: 0.7111 - val_loss: 1.1850 - val_accuracy: 0.6154\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6712 - accuracy: 0.7074 - val_loss: 1.1792 - val_accuracy: 0.6068\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.6616 - accuracy: 0.7037 - val_loss: 1.0872 - val_accuracy: 0.6239\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.6773 - accuracy: 0.6926 - val_loss: 1.0352 - val_accuracy: 0.6239\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6448 - accuracy: 0.6926 - val_loss: 1.1215 - val_accuracy: 0.6325\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6797 - accuracy: 0.7000 - val_loss: 1.1497 - val_accuracy: 0.6239\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6688 - accuracy: 0.6778 - val_loss: 1.1021 - val_accuracy: 0.6496\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.6871 - accuracy: 0.7000 - val_loss: 1.1517 - val_accuracy: 0.6325\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.6999 - accuracy: 0.6963 - val_loss: 1.0519 - val_accuracy: 0.5897\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.6655 - accuracy: 0.6704 - val_loss: 1.1003 - val_accuracy: 0.6154\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6891 - accuracy: 0.7074 - val_loss: 1.1514 - val_accuracy: 0.6068\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6853 - accuracy: 0.7037 - val_loss: 1.1118 - val_accuracy: 0.6068\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6388 - accuracy: 0.6963 - val_loss: 1.0311 - val_accuracy: 0.6410\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6516 - accuracy: 0.7000 - val_loss: 1.0327 - val_accuracy: 0.6154\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6299 - accuracy: 0.6963 - val_loss: 1.0441 - val_accuracy: 0.6239\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.6516 - accuracy: 0.6815 - val_loss: 1.0632 - val_accuracy: 0.6410\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6305 - accuracy: 0.7037 - val_loss: 1.0226 - val_accuracy: 0.6410\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6247 - accuracy: 0.7000 - val_loss: 1.0283 - val_accuracy: 0.6154\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6233 - accuracy: 0.6926 - val_loss: 1.0501 - val_accuracy: 0.5983\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6465 - accuracy: 0.7037 - val_loss: 1.0342 - val_accuracy: 0.5812\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6237 - accuracy: 0.7000 - val_loss: 1.0219 - val_accuracy: 0.6068\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.70 - 0s 326us/step - loss: 0.6269 - accuracy: 0.7111 - val_loss: 1.0587 - val_accuracy: 0.6154\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6273 - accuracy: 0.7037 - val_loss: 1.0265 - val_accuracy: 0.6239\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6197 - accuracy: 0.7148 - val_loss: 1.0497 - val_accuracy: 0.6154\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6215 - accuracy: 0.7000 - val_loss: 1.0315 - val_accuracy: 0.6410\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6207 - accuracy: 0.7111 - val_loss: 1.0364 - val_accuracy: 0.6154\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6330 - accuracy: 0.7074 - val_loss: 1.0301 - val_accuracy: 0.6154\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6218 - accuracy: 0.7111 - val_loss: 1.0192 - val_accuracy: 0.6239\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6395 - accuracy: 0.7000 - val_loss: 1.0849 - val_accuracy: 0.6068\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6469 - accuracy: 0.7037 - val_loss: 1.0300 - val_accuracy: 0.6154\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6391 - accuracy: 0.6926 - val_loss: 1.0152 - val_accuracy: 0.6068\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.6263 - accuracy: 0.6926 - val_loss: 1.0280 - val_accuracy: 0.6325\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6265 - accuracy: 0.7037 - val_loss: 1.0470 - val_accuracy: 0.6239\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6253 - accuracy: 0.7037 - val_loss: 1.0461 - val_accuracy: 0.6410\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.6254 - accuracy: 0.7148 - val_loss: 1.0471 - val_accuracy: 0.5641\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.6278 - accuracy: 0.7037 - val_loss: 1.0253 - val_accuracy: 0.6068\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6191 - accuracy: 0.6963 - val_loss: 1.0114 - val_accuracy: 0.6410\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6201 - accuracy: 0.7000 - val_loss: 1.0294 - val_accuracy: 0.6325\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6237 - accuracy: 0.7037 - val_loss: 1.0104 - val_accuracy: 0.6239\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6202 - accuracy: 0.7148 - val_loss: 1.0087 - val_accuracy: 0.5812\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6210 - accuracy: 0.7148 - val_loss: 1.0181 - val_accuracy: 0.5897\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6234 - accuracy: 0.7000 - val_loss: 1.0441 - val_accuracy: 0.6154\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6321 - accuracy: 0.7111 - val_loss: 1.0217 - val_accuracy: 0.6154\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6435 - accuracy: 0.6889 - val_loss: 1.1126 - val_accuracy: 0.6410\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7147 - accuracy: 0.7000 - val_loss: 1.1839 - val_accuracy: 0.6496\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6979 - accuracy: 0.6963 - val_loss: 1.0247 - val_accuracy: 0.5983\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6786 - accuracy: 0.6926 - val_loss: 1.0716 - val_accuracy: 0.5983\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.6457 - accuracy: 0.7074 - val_loss: 1.0958 - val_accuracy: 0.6068\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6448 - accuracy: 0.6963 - val_loss: 1.0572 - val_accuracy: 0.5983\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6291 - accuracy: 0.7037 - val_loss: 1.0398 - val_accuracy: 0.6068\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6506 - accuracy: 0.7000 - val_loss: 1.0558 - val_accuracy: 0.6154\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6236 - accuracy: 0.7148 - val_loss: 1.0234 - val_accuracy: 0.6154\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.6205 - accuracy: 0.7037 - val_loss: 1.0540 - val_accuracy: 0.6239\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.70 - 0s 193us/step - loss: 0.6376 - accuracy: 0.7074 - val_loss: 1.0226 - val_accuracy: 0.6154\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6181 - accuracy: 0.6963 - val_loss: 1.0267 - val_accuracy: 0.6325\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6333 - accuracy: 0.7074 - val_loss: 1.0345 - val_accuracy: 0.6410\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.6143 - accuracy: 0.6963 - val_loss: 1.0350 - val_accuracy: 0.6068\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.6193 - accuracy: 0.7037 - val_loss: 1.0622 - val_accuracy: 0.6068\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.65 - 0s 96us/step - loss: 0.6258 - accuracy: 0.7000 - val_loss: 1.0386 - val_accuracy: 0.5812\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.6205 - accuracy: 0.6963 - val_loss: 1.0185 - val_accuracy: 0.5983\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6261 - accuracy: 0.6963 - val_loss: 1.0148 - val_accuracy: 0.5983\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6144 - accuracy: 0.7037 - val_loss: 1.0372 - val_accuracy: 0.6154\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6251 - accuracy: 0.7000 - val_loss: 1.0777 - val_accuracy: 0.6410\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6459 - accuracy: 0.7000 - val_loss: 1.0207 - val_accuracy: 0.5983\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.7350 - accuracy: 0.6852 - val_loss: 1.0336 - val_accuracy: 0.6239\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7997 - accuracy: 0.7074 - val_loss: 1.4233 - val_accuracy: 0.6410\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9262 - accuracy: 0.7111 - val_loss: 1.3056 - val_accuracy: 0.6410\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8214 - accuracy: 0.6963 - val_loss: 1.1301 - val_accuracy: 0.5641\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7279 - accuracy: 0.6963 - val_loss: 1.0864 - val_accuracy: 0.5812\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6232 - accuracy: 0.7259 - val_loss: 1.0402 - val_accuracy: 0.6154\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6361 - accuracy: 0.6963 - val_loss: 1.0303 - val_accuracy: 0.6068\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.6368 - accuracy: 0.6963 - val_loss: 1.0357 - val_accuracy: 0.6410\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.79 - 0s 124us/step - loss: 0.6337 - accuracy: 0.7074 - val_loss: 1.0323 - val_accuracy: 0.6496\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7562 - accuracy: 0.6852 - val_loss: 1.0749 - val_accuracy: 0.6325\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6819 - accuracy: 0.7037 - val_loss: 1.1172 - val_accuracy: 0.6410\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6841 - accuracy: 0.7000 - val_loss: 1.0257 - val_accuracy: 0.5983\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6423 - accuracy: 0.6926 - val_loss: 1.0418 - val_accuracy: 0.5897\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6296 - accuracy: 0.7000 - val_loss: 1.0493 - val_accuracy: 0.5983\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6314 - accuracy: 0.7000 - val_loss: 1.0549 - val_accuracy: 0.6239\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6293 - accuracy: 0.7000 - val_loss: 1.0550 - val_accuracy: 0.6239\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.6329 - accuracy: 0.6926 - val_loss: 1.0602 - val_accuracy: 0.6154\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.6341 - accuracy: 0.7074 - val_loss: 1.1116 - val_accuracy: 0.5897\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6387 - accuracy: 0.7074 - val_loss: 1.0703 - val_accuracy: 0.6154\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6190 - accuracy: 0.7111 - val_loss: 1.0429 - val_accuracy: 0.6325\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6495 - accuracy: 0.6926 - val_loss: 1.1113 - val_accuracy: 0.6239\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6587 - accuracy: 0.7037 - val_loss: 1.1534 - val_accuracy: 0.5897\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6563 - accuracy: 0.6926 - val_loss: 1.1278 - val_accuracy: 0.6239\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6358 - accuracy: 0.6926 - val_loss: 1.0438 - val_accuracy: 0.6410\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.6284 - accuracy: 0.6926 - val_loss: 1.0331 - val_accuracy: 0.6325\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6256 - accuracy: 0.6963 - val_loss: 1.0494 - val_accuracy: 0.6325\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6212 - accuracy: 0.7185 - val_loss: 1.0623 - val_accuracy: 0.5983\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6465 - accuracy: 0.7037 - val_loss: 1.0500 - val_accuracy: 0.6239\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6311 - accuracy: 0.6926 - val_loss: 1.0491 - val_accuracy: 0.6239\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.6207 - accuracy: 0.7000 - val_loss: 1.0945 - val_accuracy: 0.5983\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.6296 - accuracy: 0.6963 - val_loss: 1.0966 - val_accuracy: 0.5897\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6287 - accuracy: 0.7000 - val_loss: 1.0667 - val_accuracy: 0.5897\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6265 - accuracy: 0.6926 - val_loss: 1.0323 - val_accuracy: 0.5897\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6439 - accuracy: 0.6889 - val_loss: 1.0993 - val_accuracy: 0.6239\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6968 - accuracy: 0.6926 - val_loss: 1.1380 - val_accuracy: 0.6239\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6479 - accuracy: 0.7037 - val_loss: 1.0945 - val_accuracy: 0.6239\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6613 - accuracy: 0.6889 - val_loss: 1.0669 - val_accuracy: 0.6325\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6403 - accuracy: 0.7111 - val_loss: 1.0482 - val_accuracy: 0.5812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6321 - accuracy: 0.6963 - val_loss: 1.0373 - val_accuracy: 0.6239\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6291 - accuracy: 0.7037 - val_loss: 1.0500 - val_accuracy: 0.5983\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.6256 - accuracy: 0.6926 - val_loss: 1.0536 - val_accuracy: 0.6068\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6164 - accuracy: 0.7074 - val_loss: 1.0468 - val_accuracy: 0.6068\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6282 - accuracy: 0.6926 - val_loss: 1.0328 - val_accuracy: 0.5726\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.6411 - accuracy: 0.6889 - val_loss: 1.0473 - val_accuracy: 0.6239\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.6215 - accuracy: 0.7000 - val_loss: 1.0663 - val_accuracy: 0.5897\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6328 - accuracy: 0.6963 - val_loss: 1.1060 - val_accuracy: 0.5983\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6326 - accuracy: 0.6963 - val_loss: 1.0684 - val_accuracy: 0.6154\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.6224 - accuracy: 0.6926 - val_loss: 1.0891 - val_accuracy: 0.6068\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6268 - accuracy: 0.7074 - val_loss: 1.0584 - val_accuracy: 0.5897\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6224 - accuracy: 0.6926 - val_loss: 1.0710 - val_accuracy: 0.5983\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6308 - accuracy: 0.6963 - val_loss: 1.0528 - val_accuracy: 0.6068\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6854 - accuracy: 0.6889 - val_loss: 1.1864 - val_accuracy: 0.6325\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.0611 - accuracy: 0.7037 - val_loss: 1.8979 - val_accuracy: 0.6410\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.2471 - accuracy: 0.7000 - val_loss: 1.6676 - val_accuracy: 0.6325\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.0695 - accuracy: 0.6926 - val_loss: 1.2838 - val_accuracy: 0.6325\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7484 - accuracy: 0.7037 - val_loss: 1.1246 - val_accuracy: 0.5897\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.7926 - accuracy: 0.6556 - val_loss: 1.1454 - val_accuracy: 0.6068\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7744 - accuracy: 0.7185 - val_loss: 1.4436 - val_accuracy: 0.6325\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9151 - accuracy: 0.7037 - val_loss: 1.2899 - val_accuracy: 0.6239\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7857 - accuracy: 0.7037 - val_loss: 1.0668 - val_accuracy: 0.6068\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6448 - accuracy: 0.6926 - val_loss: 1.1573 - val_accuracy: 0.6154\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.6641 - accuracy: 0.7000 - val_loss: 1.1417 - val_accuracy: 0.6154\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.6462 - accuracy: 0.7111 - val_loss: 1.0590 - val_accuracy: 0.6325\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6315 - accuracy: 0.7037 - val_loss: 1.0666 - val_accuracy: 0.6154\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.6280 - accuracy: 0.7000 - val_loss: 1.0899 - val_accuracy: 0.6154\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.6249 - accuracy: 0.7185 - val_loss: 1.0900 - val_accuracy: 0.6239\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6401 - accuracy: 0.6963 - val_loss: 1.0726 - val_accuracy: 0.6239\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6239 - accuracy: 0.6963 - val_loss: 1.0287 - val_accuracy: 0.6154\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6116 - accuracy: 0.7185 - val_loss: 1.0631 - val_accuracy: 0.5983\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6394 - accuracy: 0.6963 - val_loss: 1.0293 - val_accuracy: 0.5983\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6195 - accuracy: 0.7148 - val_loss: 1.0227 - val_accuracy: 0.6325\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.6253 - accuracy: 0.7037 - val_loss: 1.0736 - val_accuracy: 0.6325\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6186 - accuracy: 0.7185 - val_loss: 1.0848 - val_accuracy: 0.6239\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6899 - accuracy: 0.6778 - val_loss: 1.0869 - val_accuracy: 0.6410\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6577 - accuracy: 0.6963 - val_loss: 1.0532 - val_accuracy: 0.6154\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.6224 - accuracy: 0.6963 - val_loss: 1.0947 - val_accuracy: 0.5641\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6391 - accuracy: 0.6926 - val_loss: 1.0968 - val_accuracy: 0.6068\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.6593 - accuracy: 0.7111 - val_loss: 1.0730 - val_accuracy: 0.6239\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7063 - accuracy: 0.6741 - val_loss: 1.1624 - val_accuracy: 0.6239\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7149 - accuracy: 0.7000 - val_loss: 1.5843 - val_accuracy: 0.6068\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9472 - accuracy: 0.6815 - val_loss: 1.2800 - val_accuracy: 0.6410\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.7149 - accuracy: 0.6963 - val_loss: 1.0935 - val_accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6738 - accuracy: 0.6963 - val_loss: 1.1817 - val_accuracy: 0.6068\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.7032 - accuracy: 0.6963 - val_loss: 1.1690 - val_accuracy: 0.6325\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6894 - accuracy: 0.6889 - val_loss: 1.0608 - val_accuracy: 0.6325\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.6280 - accuracy: 0.6963 - val_loss: 1.0349 - val_accuracy: 0.6325\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.6408 - accuracy: 0.6963 - val_loss: 1.0180 - val_accuracy: 0.5812\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.6309 - accuracy: 0.7000 - val_loss: 1.0360 - val_accuracy: 0.5983\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6419 - accuracy: 0.7037 - val_loss: 1.0503 - val_accuracy: 0.6239\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6310 - accuracy: 0.7000 - val_loss: 1.0024 - val_accuracy: 0.6410\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6244 - accuracy: 0.7000 - val_loss: 1.0504 - val_accuracy: 0.5983\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6279 - accuracy: 0.7148 - val_loss: 1.0595 - val_accuracy: 0.5983\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6130 - accuracy: 0.7074 - val_loss: 1.0859 - val_accuracy: 0.5812\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.6403 - accuracy: 0.7000 - val_loss: 1.0940 - val_accuracy: 0.6239\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.6603 - accuracy: 0.7037 - val_loss: 1.0497 - val_accuracy: 0.6239\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6282 - accuracy: 0.6963 - val_loss: 1.0277 - val_accuracy: 0.6154\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 69.56%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.79776700e-03, 5.56828380e-02, 9.37519430e-01],\n",
       "       [1.12860054e-01, 5.69916070e-02, 8.30148340e-01],\n",
       "       [4.80284450e-01, 3.83318600e-01, 1.36396960e-01],\n",
       "       [2.12836350e-01, 3.32044410e-03, 7.83843160e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.49065770e-02, 2.23908190e-01, 7.21185200e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [6.49095650e-01, 3.41353980e-01, 9.55032300e-03],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.35238000e-01, 3.76735000e-01, 8.80270150e-02],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [2.57582960e-01, 1.81236270e-01, 5.61180700e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.81124570e-02, 3.08436660e-01, 6.33450900e-01],\n",
       "       [6.86385630e-01, 3.08748930e-01, 4.86536930e-03],\n",
       "       [6.34144400e-05, 2.58747780e-04, 9.99677900e-01],\n",
       "       [1.04569540e-01, 3.83047200e-01, 5.12383200e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [7.37449760e-03, 8.37352050e-02, 9.08890250e-01],\n",
       "       [2.47680300e-03, 1.67371500e-02, 9.80786000e-01],\n",
       "       [2.41321340e-01, 3.84746280e-01, 3.73932300e-01],\n",
       "       [7.03169600e-01, 1.70271500e-01, 1.26558930e-01],\n",
       "       [5.22940640e-01, 3.47549020e-01, 1.29510300e-01],\n",
       "       [5.93088400e-01, 2.24249850e-01, 1.82661770e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [4.14239700e-03, 7.17460800e-01, 2.78396820e-01],\n",
       "       [5.06299260e-01, 4.01726400e-01, 9.19742900e-02],\n",
       "       [1.29254250e-01, 3.91656400e-02, 8.31580160e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [7.59704300e-01, 2.37685780e-01, 2.60984760e-03],\n",
       "       [2.12836350e-01, 3.32044410e-03, 7.83843160e-01],\n",
       "       [6.62307160e-03, 2.34782290e-02, 9.69898640e-01],\n",
       "       [4.53124100e-01, 3.78752400e-01, 1.68123470e-01],\n",
       "       [3.34193920e-01, 5.88530060e-01, 7.72760140e-02],\n",
       "       [1.93741640e-02, 7.88475000e-01, 1.92150940e-01],\n",
       "       [4.53124100e-01, 3.78752400e-01, 1.68123470e-01],\n",
       "       [4.79264680e-04, 2.40503220e-01, 7.59017470e-01],\n",
       "       [9.55182800e-01, 4.48107500e-02, 6.54609100e-06],\n",
       "       [1.83563020e-01, 6.54370900e-01, 1.62066120e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [2.57582960e-01, 1.81236270e-01, 5.61180700e-01],\n",
       "       [2.12836350e-01, 3.32044410e-03, 7.83843160e-01],\n",
       "       [5.81759960e-03, 5.52735400e-05, 9.94127150e-01],\n",
       "       [6.79776700e-03, 5.56828380e-02, 9.37519430e-01],\n",
       "       [3.58623300e-02, 1.69900420e-01, 7.94237300e-01],\n",
       "       [5.93088400e-01, 2.24249850e-01, 1.82661770e-01],\n",
       "       [4.33336800e-01, 8.97972900e-02, 4.76865830e-01],\n",
       "       [4.53124100e-01, 3.78752400e-01, 1.68123470e-01],\n",
       "       [2.26806160e-01, 6.19395500e-01, 1.53798340e-01],\n",
       "       [7.37449760e-03, 8.37352050e-02, 9.08890250e-01],\n",
       "       [7.15367170e-03, 2.86113020e-02, 9.64235070e-01],\n",
       "       [2.38993660e-01, 7.47501200e-01, 1.35050810e-02],\n",
       "       [1.83563020e-01, 6.54370900e-01, 1.62066120e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [1.67614070e-01, 6.98241650e-01, 1.34144370e-01],\n",
       "       [3.04658560e-01, 6.90066750e-01, 5.27477300e-03],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [6.78034370e-01, 3.14213200e-01, 7.75248320e-03],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [4.85988860e-01, 5.04729450e-01, 9.28167700e-03],\n",
       "       [2.09660740e-01, 5.18313700e-01, 2.72025500e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [7.37911200e-01, 2.60195850e-01, 1.89290000e-03],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [2.57582960e-01, 1.81236270e-01, 5.61180700e-01],\n",
       "       [2.55541320e-01, 1.61220480e-01, 5.83238200e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [2.38993660e-01, 7.47501200e-01, 1.35050810e-02],\n",
       "       [2.12836350e-01, 3.32044410e-03, 7.83843160e-01],\n",
       "       [5.93088400e-01, 2.24249850e-01, 1.82661770e-01],\n",
       "       [4.45987020e-02, 8.39708400e-01, 1.15692880e-01],\n",
       "       [9.85023100e-02, 9.30686800e-02, 8.08429000e-01],\n",
       "       [1.05636135e-01, 5.68114100e-01, 3.26249800e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [6.78034370e-01, 3.14213200e-01, 7.75248320e-03],\n",
       "       [2.57582960e-01, 1.81236270e-01, 5.61180700e-01],\n",
       "       [2.57582960e-01, 1.81236270e-01, 5.61180700e-01],\n",
       "       [1.83563020e-01, 6.54370900e-01, 1.62066120e-01],\n",
       "       [7.24365700e-01, 2.67654570e-01, 7.97966900e-03],\n",
       "       [7.24365700e-01, 2.67654570e-01, 7.97966900e-03],\n",
       "       [5.81759960e-03, 5.52735400e-05, 9.94127150e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [6.19791750e-01, 3.27760070e-01, 5.24482130e-02],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.00822600e-01, 2.43476350e-01, 2.55701100e-01],\n",
       "       [1.04569540e-01, 3.83047200e-01, 5.12383200e-01],\n",
       "       [5.39134550e-02, 7.69593830e-01, 1.76492700e-01],\n",
       "       [4.78501380e-01, 5.21187250e-01, 3.11409270e-04],\n",
       "       [7.24365700e-01, 2.67654570e-01, 7.97966900e-03],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [4.80284450e-01, 3.83318600e-01, 1.36396960e-01],\n",
       "       [6.86394200e-01, 3.03505930e-01, 1.00999200e-02],\n",
       "       [2.37973100e-01, 3.21946650e-01, 4.40080200e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [4.53124100e-01, 3.78752400e-01, 1.68123470e-01],\n",
       "       [2.47680300e-03, 1.67371500e-02, 9.80786000e-01],\n",
       "       [4.78501380e-01, 5.21187250e-01, 3.11409270e-04],\n",
       "       [5.13861650e-03, 3.09920400e-02, 9.63869330e-01],\n",
       "       [1.67614070e-01, 6.98241650e-01, 1.34144370e-01],\n",
       "       [4.79264680e-04, 2.40503220e-01, 7.59017470e-01],\n",
       "       [8.63844250e-03, 9.91351600e-01, 9.95758800e-06],\n",
       "       [1.83563020e-01, 6.54370900e-01, 1.62066120e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.93088400e-01, 2.24249850e-01, 1.82661770e-01],\n",
       "       [8.36228900e-03, 9.18525900e-02, 8.99785160e-01],\n",
       "       [3.34740220e-01, 1.79435860e-01, 4.85823930e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [1.67614070e-01, 6.98241650e-01, 1.34144370e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [2.47680300e-03, 1.67371500e-02, 9.80786000e-01],\n",
       "       [5.93088400e-01, 2.24249850e-01, 1.82661770e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01],\n",
       "       [5.67075870e-02, 2.93000700e-01, 6.50291700e-01],\n",
       "       [3.14489450e-01, 5.07027570e-01, 1.78483000e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0006kpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7501643655489808"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7501643655489808"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519449923296077"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022618617985551374"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519449923296077"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022618617985551374"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 62.39%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.03676207159959011\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 71.13%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.010667921\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
