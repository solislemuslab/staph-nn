{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0017presabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7159)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0017presabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    0\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_4749</th>\n",
       "      <th>group_6727</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9205</th>\n",
       "      <th>group_9474</th>\n",
       "      <th>group_9475</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_4749  group_6727  group_8892  group_9205  group_9474  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_9475  group_9858  ST  CC  pheno  \n",
       "0           0           0   5   5      2  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      2  \n",
       "3           0           0   5   5      2  \n",
       "4           0           0   5   5      2  \n",
       "\n",
       "[5 rows x 7159 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7158)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_4749</th>\n",
       "      <th>group_6727</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9205</th>\n",
       "      <th>group_9474</th>\n",
       "      <th>group_9475</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_4749  group_6727  group_8892  group_9205  group_9474  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_9475  group_9858  ST  CC  pheno  \n",
       "0           0           0   5   5      2  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      2  \n",
       "3           0           0   5   5      2  \n",
       "4           0           0   5   5      2  \n",
       "\n",
       "[5 rows x 7158 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 7158) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "112       NRS027     1\n",
       "207       NRS246     1\n",
       "186       NRS218     2\n",
       "88      CFBRSa70     2\n",
       "156       NRS177     1\n",
       "..           ...   ...\n",
       "244       SR3585     0\n",
       "99       GA50819     2\n",
       "147       NRS161     2\n",
       "49   CFBREBSa114     1\n",
       "140       NRS114     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 950us/step - loss: 1.3886 - accuracy: 0.4181 - val_loss: 1.6842 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 1.6026 - accuracy: 0.4972 - val_loss: 1.5356 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 1.3812 - accuracy: 0.5141 - val_loss: 1.0383 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 1.2332 - accuracy: 0.5763 - val_loss: 1.2765 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 1.1373 - accuracy: 0.6215 - val_loss: 1.0610 - val_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 464us/step - loss: 0.8628 - accuracy: 0.6328 - val_loss: 1.2545 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.8375 - accuracy: 0.6667 - val_loss: 0.9811 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.7929 - accuracy: 0.6723 - val_loss: 1.6433 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 720us/step - loss: 0.7504 - accuracy: 0.6836 - val_loss: 1.7384 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.8067 - accuracy: 0.6836 - val_loss: 1.5085 - val_accuracy: 0.5526\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.8836 - accuracy: 0.7232 - val_loss: 1.6033 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.7275 - accuracy: 0.7006 - val_loss: 2.0730 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.9978 - accuracy: 0.7175 - val_loss: 2.0534 - val_accuracy: 0.4211\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.7937 - accuracy: 0.7288 - val_loss: 1.4720 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.6713 - accuracy: 0.7627 - val_loss: 1.6436 - val_accuracy: 0.4211\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.7203 - accuracy: 0.7175 - val_loss: 1.4752 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.6238 - accuracy: 0.7684 - val_loss: 1.6332 - val_accuracy: 0.5526\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.5388 - accuracy: 0.7684 - val_loss: 1.6639 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 407us/step - loss: 0.5117 - accuracy: 0.8418 - val_loss: 1.7666 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.5359 - accuracy: 0.8136 - val_loss: 1.6578 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.4751 - accuracy: 0.8475 - val_loss: 1.7723 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.4946 - accuracy: 0.8588 - val_loss: 1.8912 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.5569 - accuracy: 0.8192 - val_loss: 1.7276 - val_accuracy: 0.5395\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.7298 - accuracy: 0.8644 - val_loss: 1.9084 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.6026 - accuracy: 0.8192 - val_loss: 2.0054 - val_accuracy: 0.4605\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 407us/step - loss: 0.6693 - accuracy: 0.8531 - val_loss: 1.6956 - val_accuracy: 0.4868\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 806us/step - loss: 0.5818 - accuracy: 0.8418 - val_loss: 1.7986 - val_accuracy: 0.5395\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.5406 - accuracy: 0.8644 - val_loss: 1.6264 - val_accuracy: 0.4868\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8983 - val_loss: 1.8883 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 758us/step - loss: 0.5204 - accuracy: 0.8644 - val_loss: 1.7977 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 808us/step - loss: 0.4160 - accuracy: 0.8644 - val_loss: 1.6976 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.4045 - accuracy: 0.9040 - val_loss: 1.6117 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 543us/step - loss: 0.3550 - accuracy: 0.8927 - val_loss: 1.7249 - val_accuracy: 0.5395\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.3491 - accuracy: 0.8983 - val_loss: 1.7998 - val_accuracy: 0.4868\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8870 - val_loss: 1.7716 - val_accuracy: 0.5263\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 509us/step - loss: 0.4478 - accuracy: 0.9096 - val_loss: 1.9194 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.4684 - accuracy: 0.8588 - val_loss: 1.8550 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 712us/step - loss: 0.3830 - accuracy: 0.8927 - val_loss: 1.7445 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.3194 - accuracy: 0.9266 - val_loss: 1.8488 - val_accuracy: 0.5132\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.3136 - accuracy: 0.9266 - val_loss: 1.7169 - val_accuracy: 0.5132\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.3007 - accuracy: 0.9322 - val_loss: 1.8172 - val_accuracy: 0.5658\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.3223 - accuracy: 0.9153 - val_loss: 1.7881 - val_accuracy: 0.5395\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3289 - accuracy: 0.9209 - val_loss: 1.8398 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 975us/step - loss: 0.4127 - accuracy: 0.9322 - val_loss: 2.0119 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.4106 - accuracy: 0.8983 - val_loss: 1.7553 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "128/177 [====================>.........] - ETA: 0s - loss: 0.4717 - accuracy: 0.8906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.103770). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 959us/step - loss: 0.4124 - accuracy: 0.9096 - val_loss: 1.9522 - val_accuracy: 0.4342\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.4175 - accuracy: 0.9266 - val_loss: 2.1623 - val_accuracy: 0.5132\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 904us/step - loss: 0.3777 - accuracy: 0.8531 - val_loss: 1.8624 - val_accuracy: 0.4868\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 695us/step - loss: 0.3646 - accuracy: 0.8983 - val_loss: 1.9232 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.2664 - accuracy: 0.9492 - val_loss: 1.9088 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.2606 - accuracy: 0.9492 - val_loss: 1.8684 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.2305 - accuracy: 0.9548 - val_loss: 1.9589 - val_accuracy: 0.5132\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.2558 - accuracy: 0.9379 - val_loss: 1.9770 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 612us/step - loss: 0.2414 - accuracy: 0.9266 - val_loss: 1.9046 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 790us/step - loss: 0.3121 - accuracy: 0.9209 - val_loss: 1.9369 - val_accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 497us/step - loss: 0.2892 - accuracy: 0.9492 - val_loss: 1.8975 - val_accuracy: 0.4868\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 683us/step - loss: 0.2842 - accuracy: 0.9040 - val_loss: 1.9573 - val_accuracy: 0.4868\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.2403 - accuracy: 0.9153 - val_loss: 2.0653 - val_accuracy: 0.4737\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.2614 - accuracy: 0.9322 - val_loss: 1.9503 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.2777 - accuracy: 0.9266 - val_loss: 2.0668 - val_accuracy: 0.5132\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.2758 - accuracy: 0.9322 - val_loss: 2.0252 - val_accuracy: 0.4737\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 776us/step - loss: 0.2260 - accuracy: 0.9774 - val_loss: 1.8921 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.2749 - accuracy: 0.9435 - val_loss: 1.8406 - val_accuracy: 0.4868\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.2665 - accuracy: 0.9435 - val_loss: 2.0189 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.2232 - accuracy: 0.9379 - val_loss: 2.0796 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 683us/step - loss: 0.2571 - accuracy: 0.9322 - val_loss: 2.1645 - val_accuracy: 0.4868\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.2397 - accuracy: 0.9492 - val_loss: 2.2647 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.3735 - accuracy: 0.9492 - val_loss: 2.2475 - val_accuracy: 0.4868\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.2206 - accuracy: 0.9322 - val_loss: 2.0698 - val_accuracy: 0.4737\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 713us/step - loss: 0.2188 - accuracy: 0.9435 - val_loss: 2.1389 - val_accuracy: 0.5263\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.1684 - accuracy: 0.9435 - val_loss: 2.1561 - val_accuracy: 0.5132\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.1859 - accuracy: 0.9548 - val_loss: 2.0896 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 626us/step - loss: 0.2017 - accuracy: 0.9548 - val_loss: 2.1082 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.2220 - accuracy: 0.9548 - val_loss: 2.2456 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.2226 - accuracy: 0.9605 - val_loss: 2.0462 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.3132 - accuracy: 0.9492 - val_loss: 2.1351 - val_accuracy: 0.5132\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1801 - accuracy: 0.9718 - val_loss: 2.2647 - val_accuracy: 0.4868\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.1783 - accuracy: 0.9492 - val_loss: 2.1820 - val_accuracy: 0.4868\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.1956 - accuracy: 0.9492 - val_loss: 2.1661 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.2042 - accuracy: 0.9605 - val_loss: 2.2226 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.2418 - accuracy: 0.9605 - val_loss: 2.2275 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.1679 - accuracy: 0.9831 - val_loss: 2.3618 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.1915 - accuracy: 0.9548 - val_loss: 2.1140 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.1650 - accuracy: 0.9605 - val_loss: 2.1651 - val_accuracy: 0.4737\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.1592 - accuracy: 0.9548 - val_loss: 2.1128 - val_accuracy: 0.5132\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 584us/step - loss: 0.1360 - accuracy: 0.9661 - val_loss: 2.1154 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 557us/step - loss: 0.1381 - accuracy: 0.9718 - val_loss: 2.1276 - val_accuracy: 0.5263\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 429us/step - loss: 0.1481 - accuracy: 0.9774 - val_loss: 2.1806 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.1277 - accuracy: 0.9774 - val_loss: 2.3669 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 536us/step - loss: 0.1687 - accuracy: 0.9548 - val_loss: 2.1249 - val_accuracy: 0.5132\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.1404 - accuracy: 0.9774 - val_loss: 2.1625 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.1769 - accuracy: 0.9661 - val_loss: 2.1831 - val_accuracy: 0.4868\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1881 - accuracy: 0.9718 - val_loss: 2.3067 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.1701 - accuracy: 0.9718 - val_loss: 2.3788 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.2073 - accuracy: 0.9774 - val_loss: 2.1491 - val_accuracy: 0.4474\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.2053 - accuracy: 0.9774 - val_loss: 2.2579 - val_accuracy: 0.4868\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 691us/step - loss: 0.1399 - accuracy: 0.9435 - val_loss: 2.3242 - val_accuracy: 0.4868\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 604us/step - loss: 0.1550 - accuracy: 0.9322 - val_loss: 2.3406 - val_accuracy: 0.4868\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 602us/step - loss: 0.1882 - accuracy: 0.9831 - val_loss: 2.2134 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1487 - accuracy: 0.9774 - val_loss: 2.3197 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63cdf30b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 167us/step\n",
      "test accuracy: 48.68%\n"
     ]
    }
   ],
   "source": [
    "acc_test1 = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 1, 2, 2, 0, 0, 1, 2, 1, 2, 1, 0,\n",
       "       2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0,\n",
       "       2, 2, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1,\n",
       "       0, 2, 1, 1, 0, 0, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "112       NRS027     1     0\n",
       "207       NRS246     1     0\n",
       "186       NRS218     2     1\n",
       "88      CFBRSa70     2     0\n",
       "156       NRS177     1     1\n",
       "..           ...   ...   ...\n",
       "244       SR3585     0     0\n",
       "99       GA50819     2     0\n",
       "147       NRS161     2     0\n",
       "49   CFBREBSa114     1     0\n",
       "140       NRS114     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1.predict_proba(X_test)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748608</td>\n",
       "      <td>0.091089</td>\n",
       "      <td>0.160304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689107</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.018205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029113</td>\n",
       "      <td>0.924627</td>\n",
       "      <td>0.046260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.933857</td>\n",
       "      <td>0.033455</td>\n",
       "      <td>0.032688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032013</td>\n",
       "      <td>0.939939</td>\n",
       "      <td>0.028048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.926324</td>\n",
       "      <td>0.052714</td>\n",
       "      <td>0.020962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.949648</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.035839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.755204</td>\n",
       "      <td>0.244795</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.989175</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.009465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.101348</td>\n",
       "      <td>0.305778</td>\n",
       "      <td>0.592874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.748608  0.091089  0.160304\n",
       "1   0.689107  0.292688  0.018205\n",
       "2   0.029113  0.924627  0.046260\n",
       "3   0.933857  0.033455  0.032688\n",
       "4   0.032013  0.939939  0.028048\n",
       "..       ...       ...       ...\n",
       "71  0.926324  0.052714  0.020962\n",
       "72  0.949648  0.014513  0.035839\n",
       "73  0.755204  0.244795  0.000001\n",
       "74  0.989175  0.001360  0.009465\n",
       "75  0.101348  0.305778  0.592874\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.1171 - accuracy: 0.9548 - val_loss: 2.2946 - val_accuracy: 0.4737\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1351 - accuracy: 0.9605 - val_loss: 2.2022 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.1407 - accuracy: 0.9661 - val_loss: 2.3433 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1321 - accuracy: 0.9718 - val_loss: 2.4889 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.1166 - accuracy: 0.9944 - val_loss: 2.2457 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.1167 - accuracy: 0.9774 - val_loss: 2.2751 - val_accuracy: 0.5132\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.1096 - accuracy: 0.9774 - val_loss: 2.3353 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.1066 - accuracy: 0.9944 - val_loss: 2.3325 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.1095 - accuracy: 0.9887 - val_loss: 2.2711 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1065 - accuracy: 0.9605 - val_loss: 2.3727 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.0977 - accuracy: 0.9718 - val_loss: 2.3681 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.1153 - accuracy: 0.9831 - val_loss: 2.3452 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.0864 - accuracy: 0.9887 - val_loss: 2.6093 - val_accuracy: 0.4342\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.1354 - accuracy: 0.9887 - val_loss: 2.3785 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 451us/step - loss: 0.1126 - accuracy: 0.9774 - val_loss: 2.3809 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.0932 - accuracy: 0.9774 - val_loss: 2.5253 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1199 - accuracy: 0.9661 - val_loss: 2.3794 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.0910 - accuracy: 0.9831 - val_loss: 2.3323 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.0940 - accuracy: 0.9887 - val_loss: 2.3462 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 590us/step - loss: 0.0942 - accuracy: 0.9661 - val_loss: 2.3900 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 699us/step - loss: 0.0849 - accuracy: 0.9774 - val_loss: 2.3884 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 666us/step - loss: 0.0909 - accuracy: 0.9831 - val_loss: 2.5046 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.0976 - accuracy: 0.9718 - val_loss: 2.4360 - val_accuracy: 0.4868\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.1273 - accuracy: 0.9831 - val_loss: 2.4213 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.1129 - accuracy: 0.9605 - val_loss: 2.5237 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.1014 - accuracy: 0.9661 - val_loss: 2.5193 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.0901 - accuracy: 0.9774 - val_loss: 2.4596 - val_accuracy: 0.4868\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.1050 - accuracy: 0.9718 - val_loss: 2.4631 - val_accuracy: 0.4868\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.0787 - accuracy: 0.9831 - val_loss: 2.5102 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.0858 - accuracy: 0.9831 - val_loss: 2.4989 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 594us/step - loss: 0.0864 - accuracy: 0.9774 - val_loss: 2.4703 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.0911 - accuracy: 0.9774 - val_loss: 2.4928 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 587us/step - loss: 0.0832 - accuracy: 0.9831 - val_loss: 2.5815 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 2.5010 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.0905 - accuracy: 0.9774 - val_loss: 2.5632 - val_accuracy: 0.4868\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.0838 - accuracy: 0.9831 - val_loss: 2.5596 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.0983 - accuracy: 0.9831 - val_loss: 2.5417 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.0889 - accuracy: 0.9887 - val_loss: 2.6510 - val_accuracy: 0.4605\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.0832 - accuracy: 0.9887 - val_loss: 2.6160 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 696us/step - loss: 0.0886 - accuracy: 0.9831 - val_loss: 2.5176 - val_accuracy: 0.5132\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 686us/step - loss: 0.1093 - accuracy: 0.9718 - val_loss: 2.6036 - val_accuracy: 0.4605\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 624us/step - loss: 0.0835 - accuracy: 0.9887 - val_loss: 2.7133 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.0769 - accuracy: 0.9887 - val_loss: 2.5844 - val_accuracy: 0.4868\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.1013 - accuracy: 0.9887 - val_loss: 2.6039 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.1022 - accuracy: 0.9831 - val_loss: 2.7740 - val_accuracy: 0.4342\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1005 - accuracy: 0.9718 - val_loss: 2.7972 - val_accuracy: 0.4342\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.0772 - accuracy: 0.9774 - val_loss: 2.6624 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.0985 - accuracy: 0.9831 - val_loss: 2.6567 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 680us/step - loss: 0.1137 - accuracy: 0.9435 - val_loss: 2.6597 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.0871 - accuracy: 0.9831 - val_loss: 2.5887 - val_accuracy: 0.4868\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.0770 - accuracy: 0.9831 - val_loss: 2.6390 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 728us/step - loss: 0.0719 - accuracy: 0.9887 - val_loss: 2.6707 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 623us/step - loss: 0.0805 - accuracy: 0.9831 - val_loss: 2.6437 - val_accuracy: 0.4868\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.0827 - accuracy: 0.9887 - val_loss: 2.6923 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 858us/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 2.7339 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 558us/step - loss: 0.0953 - accuracy: 0.9887 - val_loss: 2.6199 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 607us/step - loss: 0.0742 - accuracy: 0.9831 - val_loss: 2.8205 - val_accuracy: 0.4079\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9831 - val_loss: 2.7541 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 850us/step - loss: 0.0764 - accuracy: 0.9774 - val_loss: 2.7426 - val_accuracy: 0.4868\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.1015 - accuracy: 0.9887 - val_loss: 2.6501 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 582us/step - loss: 0.1170 - accuracy: 0.9831 - val_loss: 2.6542 - val_accuracy: 0.4737\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1002 - accuracy: 0.9887 - val_loss: 2.8594 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0949 - accuracy: 0.9718 - val_loss: 2.7059 - val_accuracy: 0.4868\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.0777 - accuracy: 0.9774 - val_loss: 2.7832 - val_accuracy: 0.4474\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1172 - accuracy: 0.9661 - val_loss: 2.8973 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.1010 - accuracy: 0.9774 - val_loss: 2.9745 - val_accuracy: 0.4868\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.1822 - accuracy: 0.9435 - val_loss: 3.1059 - val_accuracy: 0.4342\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 704us/step - loss: 0.1651 - accuracy: 0.9548 - val_loss: 2.7030 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.1384 - accuracy: 0.9548 - val_loss: 2.7832 - val_accuracy: 0.4868\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9718 - val_loss: 2.5753 - val_accuracy: 0.4737\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 736us/step - loss: 0.0864 - accuracy: 0.9605 - val_loss: 3.1715 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.1050 - accuracy: 0.9774 - val_loss: 2.8088 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 623us/step - loss: 0.0712 - accuracy: 0.9718 - val_loss: 2.7630 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 473us/step - loss: 0.0764 - accuracy: 0.9831 - val_loss: 2.6386 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.0603 - accuracy: 0.9831 - val_loss: 2.6966 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.0823 - accuracy: 0.9774 - val_loss: 2.7633 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 466us/step - loss: 0.0647 - accuracy: 0.9887 - val_loss: 2.7206 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.0713 - accuracy: 0.9887 - val_loss: 2.8698 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.0610 - accuracy: 0.9887 - val_loss: 2.7651 - val_accuracy: 0.4868\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.0730 - accuracy: 0.9887 - val_loss: 2.7064 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.0591 - accuracy: 0.9887 - val_loss: 2.7926 - val_accuracy: 0.4474\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.0729 - accuracy: 0.9831 - val_loss: 2.8431 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.0491 - accuracy: 0.9944 - val_loss: 2.8058 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.0861 - accuracy: 0.9887 - val_loss: 2.7313 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.0653 - accuracy: 0.9718 - val_loss: 2.7889 - val_accuracy: 0.4342\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.0678 - accuracy: 0.9831 - val_loss: 2.8182 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.0562 - accuracy: 0.9831 - val_loss: 2.9286 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 386us/step - loss: 0.0702 - accuracy: 0.9774 - val_loss: 2.8482 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.0683 - accuracy: 0.9887 - val_loss: 2.7850 - val_accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.0606 - accuracy: 0.9887 - val_loss: 2.8372 - val_accuracy: 0.4474\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.0586 - accuracy: 0.9887 - val_loss: 2.8203 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.0766 - accuracy: 0.9831 - val_loss: 2.8256 - val_accuracy: 0.4868\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.0595 - accuracy: 0.9887 - val_loss: 2.8399 - val_accuracy: 0.4737\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9831 - val_loss: 2.8945 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0439 - accuracy: 0.9944 - val_loss: 2.8945 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.0712 - accuracy: 0.9887 - val_loss: 2.8123 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 753us/step - loss: 0.0539 - accuracy: 0.9887 - val_loss: 2.8561 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 776us/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 2.9881 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.0698 - accuracy: 0.9831 - val_loss: 2.8753 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.1133 - accuracy: 0.9831 - val_loss: 2.7888 - val_accuracy: 0.4868\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.94%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist1.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947819</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.042591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.184744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS027          1           0  0.759813   \n",
       "1       p0017kpresabs_qual    NRS246          1           0  0.947819   \n",
       "2       p0017kpresabs_qual    NRS218          2           1  0.008693   \n",
       "3       p0017kpresabs_qual  CFBRSa70          2           0  0.813774   \n",
       "4       p0017kpresabs_qual    NRS177          1           1  0.000916   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS187          1           1  0.216843   \n",
       "604  p0040presabsSTCC_qual    SR1287          0           1  0.418802   \n",
       "605  p0040presabsSTCC_qual  CFBRSa50          0           0  0.948100   \n",
       "606  p0040presabsSTCC_qual    NRS196          2           2  0.000964   \n",
       "607  p0040presabsSTCC_qual    NRS072          0           0  0.795570   \n",
       "\n",
       "            1         2  \n",
       "0    0.001304  0.238883  \n",
       "1    0.009591  0.042591  \n",
       "2    0.989390  0.001916  \n",
       "3    0.001482  0.184744  \n",
       "4    0.998926  0.000157  \n",
       "..        ...       ...  \n",
       "603  0.568123  0.215034  \n",
       "604  0.553160  0.028038  \n",
       "605  0.035031  0.016869  \n",
       "606  0.039095  0.959940  \n",
       "607  0.187358  0.017072  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.48607600e-01, 9.10885860e-02, 1.60303830e-01],\n",
       "       [6.89107400e-01, 2.92687540e-01, 1.82050450e-02],\n",
       "       [2.91128890e-02, 9.24627300e-01, 4.62598430e-02],\n",
       "       [9.33857260e-01, 3.34546680e-02, 3.26880330e-02],\n",
       "       [3.20128540e-02, 9.39938800e-01, 2.80482900e-02],\n",
       "       [9.89545300e-01, 5.98503600e-03, 4.46960140e-03],\n",
       "       [9.70200400e-01, 1.17197650e-02, 1.80798840e-02],\n",
       "       [9.94562570e-01, 1.24398170e-05, 5.42505700e-03],\n",
       "       [8.66072000e-01, 1.16183780e-01, 1.77441820e-02],\n",
       "       [3.48143570e-04, 8.43306200e-02, 9.15321230e-01],\n",
       "       [5.55978700e-02, 9.33403800e-01, 1.09983780e-02],\n",
       "       [7.74316200e-03, 9.84019640e-01, 8.23720100e-03],\n",
       "       [2.75979980e-03, 6.48523100e-02, 9.32387900e-01],\n",
       "       [2.96608490e-02, 9.57406600e-02, 8.74598440e-01],\n",
       "       [5.28993070e-01, 2.02217500e-01, 2.68789470e-01],\n",
       "       [9.57669260e-01, 4.22977170e-02, 3.30163400e-05],\n",
       "       [1.23803560e-02, 9.67566500e-01, 2.00532040e-02],\n",
       "       [1.28446060e-07, 5.16763930e-03, 9.94832160e-01],\n",
       "       [3.63889930e-01, 3.91779750e-01, 2.44330270e-01],\n",
       "       [8.40977400e-02, 3.53365900e-01, 5.62536300e-01],\n",
       "       [3.34060100e-01, 3.34510300e-01, 3.31429570e-01],\n",
       "       [3.97194060e-01, 2.89215560e-01, 3.13590380e-01],\n",
       "       [9.03676900e-05, 3.70170800e-01, 6.29738800e-01],\n",
       "       [5.34958540e-02, 5.69767900e-01, 3.76736280e-01],\n",
       "       [7.29512100e-02, 1.75836160e-01, 7.51212600e-01],\n",
       "       [7.99919370e-01, 1.86876740e-01, 1.32039260e-02],\n",
       "       [2.90234700e-01, 7.04025700e-01, 5.73962970e-03],\n",
       "       [5.17903300e-02, 9.04051200e-01, 4.41584330e-02],\n",
       "       [9.60025700e-03, 9.73965400e-01, 1.64344760e-02],\n",
       "       [8.52157600e-01, 9.55616600e-02, 5.22806420e-02],\n",
       "       [3.18723250e-02, 8.81406660e-01, 8.67211000e-02],\n",
       "       [1.22969540e-03, 3.27217580e-02, 9.66048540e-01],\n",
       "       [3.37242200e-02, 1.44535170e-01, 8.21740570e-01],\n",
       "       [3.25044130e-01, 5.72164200e-01, 1.02791680e-01],\n",
       "       [3.79988200e-04, 7.17529560e-03, 9.92444700e-01],\n",
       "       [7.68352450e-02, 1.26928570e-01, 7.96236200e-01],\n",
       "       [9.89175260e-01, 1.35983700e-03, 9.46485700e-03],\n",
       "       [4.64206330e-03, 8.23943200e-02, 9.12963570e-01],\n",
       "       [6.66852240e-01, 3.32855670e-01, 2.92057060e-04],\n",
       "       [9.20530000e-01, 1.74346420e-02, 6.20353560e-02],\n",
       "       [4.36312780e-02, 6.81598900e-01, 2.74769870e-01],\n",
       "       [9.28872760e-01, 1.33978340e-02, 5.77294300e-02],\n",
       "       [3.19346370e-01, 2.34859510e-01, 4.45794140e-01],\n",
       "       [4.79221370e-01, 3.86811380e-01, 1.33967330e-01],\n",
       "       [3.81934730e-01, 1.43381850e-01, 4.74683400e-01],\n",
       "       [4.54401150e-06, 1.34465430e-04, 9.99861000e-01],\n",
       "       [4.90391900e-03, 9.94071300e-01, 1.02486670e-03],\n",
       "       [9.73887700e-01, 1.49747925e-02, 1.11375100e-02],\n",
       "       [1.06192550e-01, 4.38716530e-01, 4.55090850e-01],\n",
       "       [3.27698800e-03, 5.62509700e-02, 9.40472000e-01],\n",
       "       [5.52750770e-06, 9.32378240e-05, 9.99901200e-01],\n",
       "       [3.37925100e-01, 6.52095900e-01, 9.97901700e-03],\n",
       "       [3.36011200e-01, 2.60273460e-01, 4.03715340e-01],\n",
       "       [2.25318380e-04, 1.03825120e-01, 8.95949540e-01],\n",
       "       [4.10766540e-01, 3.89462770e-01, 1.99770670e-01],\n",
       "       [4.10198500e-02, 1.00960250e-01, 8.58019900e-01],\n",
       "       [6.39491860e-01, 3.60503200e-01, 4.96841950e-06],\n",
       "       [9.99906060e-01, 2.12046500e-05, 7.27202200e-05],\n",
       "       [4.89038230e-01, 5.09399800e-01, 1.56202280e-03],\n",
       "       [6.09341740e-01, 3.77289030e-01, 1.33692715e-02],\n",
       "       [5.50413700e-01, 3.91061570e-01, 5.85246700e-02],\n",
       "       [9.45096700e-01, 5.31823000e-02, 1.72106840e-03],\n",
       "       [9.94408250e-01, 1.72937670e-04, 5.41878630e-03],\n",
       "       [1.39700705e-05, 5.94654800e-03, 9.94039540e-01],\n",
       "       [1.15431900e-04, 9.99755800e-01, 1.28669130e-04],\n",
       "       [1.09401500e-04, 6.06671450e-01, 3.93219140e-01],\n",
       "       [6.86793900e-01, 7.20042400e-02, 2.41201820e-01],\n",
       "       [2.74196840e-02, 3.71073720e-01, 6.01506530e-01],\n",
       "       [3.44275900e-18, 1.00000000e+00, 1.51736010e-17],\n",
       "       [2.15724810e-01, 6.50443700e-01, 1.33831600e-01],\n",
       "       [6.04873400e-01, 4.65010370e-02, 3.48625480e-01],\n",
       "       [9.26323830e-01, 5.27140870e-02, 2.09621140e-02],\n",
       "       [9.49648260e-01, 1.45127560e-02, 3.58389000e-02],\n",
       "       [7.55203840e-01, 2.44795040e-01, 1.04405520e-06],\n",
       "       [9.89175260e-01, 1.35983700e-03, 9.46485700e-03],\n",
       "       [1.01347720e-01, 3.05777880e-01, 5.92874400e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6532530520625758"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6532530520625758"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat2['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "178     NRS210     2\n",
       "104     Grady1     0\n",
       "79    CFBRSa29     2\n",
       "66    CFBRSa03     0\n",
       "9          217     1\n",
       "..         ...   ...\n",
       "25   BCH-SA-10     1\n",
       "94        GA15     2\n",
       "244     SR3585     0\n",
       "227     NRS387     2\n",
       "185     NRS217     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.9756 - accuracy: 0.3672 - val_loss: 1.1070 - val_accuracy: 0.4737\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 803us/step - loss: 1.1481 - accuracy: 0.4237 - val_loss: 0.9961 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 720us/step - loss: 1.0713 - accuracy: 0.5537 - val_loss: 0.9700 - val_accuracy: 0.5395\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 762us/step - loss: 1.0669 - accuracy: 0.5537 - val_loss: 1.4252 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 812us/step - loss: 0.9918 - accuracy: 0.5932 - val_loss: 0.9314 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 629us/step - loss: 0.9061 - accuracy: 0.6328 - val_loss: 1.1522 - val_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.8754 - accuracy: 0.6102 - val_loss: 1.0920 - val_accuracy: 0.4474\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 739us/step - loss: 0.7927 - accuracy: 0.6780 - val_loss: 1.1576 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 659us/step - loss: 0.8486 - accuracy: 0.6667 - val_loss: 1.1831 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 907us/step - loss: 0.7902 - accuracy: 0.6610 - val_loss: 1.1324 - val_accuracy: 0.4211\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 832us/step - loss: 0.7514 - accuracy: 0.6610 - val_loss: 1.0718 - val_accuracy: 0.5395\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.8315 - accuracy: 0.6949 - val_loss: 1.1298 - val_accuracy: 0.5263\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 476us/step - loss: 0.8334 - accuracy: 0.6836 - val_loss: 1.0556 - val_accuracy: 0.5395\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 820us/step - loss: 0.9398 - accuracy: 0.6441 - val_loss: 1.1123 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 776us/step - loss: 0.8396 - accuracy: 0.7062 - val_loss: 1.2233 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 917us/step - loss: 0.8212 - accuracy: 0.6893 - val_loss: 1.1220 - val_accuracy: 0.4737\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.6531 - accuracy: 0.7345 - val_loss: 1.1353 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.7401 - val_loss: 1.1602 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 623us/step - loss: 0.7278 - accuracy: 0.6949 - val_loss: 1.2233 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 736us/step - loss: 0.7210 - accuracy: 0.7514 - val_loss: 1.2368 - val_accuracy: 0.4737\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 723us/step - loss: 0.6803 - accuracy: 0.7684 - val_loss: 1.2330 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 755us/step - loss: 0.6195 - accuracy: 0.7401 - val_loss: 1.2067 - val_accuracy: 0.4868\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 889us/step - loss: 0.6924 - accuracy: 0.7345 - val_loss: 1.3117 - val_accuracy: 0.4211\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.6140 - accuracy: 0.7458 - val_loss: 1.3014 - val_accuracy: 0.4605\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 840us/step - loss: 0.5763 - accuracy: 0.8136 - val_loss: 1.3092 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.5867 - accuracy: 0.8023 - val_loss: 1.3529 - val_accuracy: 0.4868\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.4787 - accuracy: 0.8136 - val_loss: 1.3705 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.4740 - accuracy: 0.8136 - val_loss: 1.3950 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.4620 - accuracy: 0.8362 - val_loss: 1.4205 - val_accuracy: 0.4605\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 474us/step - loss: 0.4255 - accuracy: 0.8475 - val_loss: 1.4399 - val_accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 881us/step - loss: 0.4572 - accuracy: 0.8418 - val_loss: 1.4685 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8079 - val_loss: 1.4781 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7797 - val_loss: 1.4675 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.4919 - accuracy: 0.8136 - val_loss: 1.5232 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 451us/step - loss: 0.4155 - accuracy: 0.8588 - val_loss: 1.5155 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.4022 - accuracy: 0.8418 - val_loss: 1.5480 - val_accuracy: 0.4868\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.4248 - accuracy: 0.8757 - val_loss: 1.5231 - val_accuracy: 0.4342\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.3901 - accuracy: 0.8588 - val_loss: 1.5262 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.3718 - accuracy: 0.8814 - val_loss: 1.6041 - val_accuracy: 0.4079\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 608us/step - loss: 0.3572 - accuracy: 0.8644 - val_loss: 1.5799 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 751us/step - loss: 0.3356 - accuracy: 0.8701 - val_loss: 1.6959 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 701us/step - loss: 0.3573 - accuracy: 0.8870 - val_loss: 1.6097 - val_accuracy: 0.4868\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.5215 - accuracy: 0.7910 - val_loss: 1.7181 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 630us/step - loss: 0.6991 - accuracy: 0.7571 - val_loss: 1.5627 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.5006 - accuracy: 0.8305 - val_loss: 1.4963 - val_accuracy: 0.4868\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.4540 - accuracy: 0.8249 - val_loss: 1.6882 - val_accuracy: 0.4211\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 497us/step - loss: 0.4638 - accuracy: 0.8079 - val_loss: 1.5913 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.4426 - accuracy: 0.8475 - val_loss: 1.5498 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 449us/step - loss: 0.3310 - accuracy: 0.8701 - val_loss: 1.6518 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.3417 - accuracy: 0.8588 - val_loss: 1.5853 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 460us/step - loss: 0.3916 - accuracy: 0.8644 - val_loss: 1.6839 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 588us/step - loss: 0.3512 - accuracy: 0.8757 - val_loss: 1.6888 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.3291 - accuracy: 0.8701 - val_loss: 1.6897 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 480us/step - loss: 0.3063 - accuracy: 0.8983 - val_loss: 1.7340 - val_accuracy: 0.3947\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 605us/step - loss: 0.2831 - accuracy: 0.8870 - val_loss: 1.7104 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.3142 - accuracy: 0.8644 - val_loss: 1.7664 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 466us/step - loss: 0.3237 - accuracy: 0.8814 - val_loss: 1.8147 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.2528 - accuracy: 0.9153 - val_loss: 1.7715 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.2654 - accuracy: 0.8870 - val_loss: 1.7424 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 469us/step - loss: 0.2468 - accuracy: 0.8983 - val_loss: 1.7738 - val_accuracy: 0.4737\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.2319 - accuracy: 0.9209 - val_loss: 1.8342 - val_accuracy: 0.4474\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 597us/step - loss: 0.2296 - accuracy: 0.9322 - val_loss: 1.8496 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.2362 - accuracy: 0.9266 - val_loss: 1.7988 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.2634 - accuracy: 0.9266 - val_loss: 1.8697 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 814us/step - loss: 0.2503 - accuracy: 0.9096 - val_loss: 1.8722 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 599us/step - loss: 0.2673 - accuracy: 0.9266 - val_loss: 1.8825 - val_accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.2041 - accuracy: 0.9266 - val_loss: 1.9496 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 577us/step - loss: 0.3138 - accuracy: 0.8814 - val_loss: 1.9426 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 560us/step - loss: 0.2396 - accuracy: 0.9096 - val_loss: 1.9102 - val_accuracy: 0.4079\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.2124 - accuracy: 0.9096 - val_loss: 1.8855 - val_accuracy: 0.4737\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 699us/step - loss: 0.2128 - accuracy: 0.9040 - val_loss: 1.9601 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.1962 - accuracy: 0.9435 - val_loss: 1.9555 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.2039 - accuracy: 0.9266 - val_loss: 2.0215 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 812us/step - loss: 0.2175 - accuracy: 0.9209 - val_loss: 1.9949 - val_accuracy: 0.4474\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 705us/step - loss: 0.1960 - accuracy: 0.9096 - val_loss: 2.0967 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 712us/step - loss: 0.2116 - accuracy: 0.9153 - val_loss: 2.0901 - val_accuracy: 0.4342\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 757us/step - loss: 0.3282 - accuracy: 0.8870 - val_loss: 2.1343 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 724us/step - loss: 0.2615 - accuracy: 0.8983 - val_loss: 2.0412 - val_accuracy: 0.4868\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 547us/step - loss: 0.1941 - accuracy: 0.9153 - val_loss: 2.0221 - val_accuracy: 0.4868\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 625us/step - loss: 0.1807 - accuracy: 0.9322 - val_loss: 2.0509 - val_accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9209 - val_loss: 2.1195 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.6002 - accuracy: 0.9040 - val_loss: 2.2073 - val_accuracy: 0.4342\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.4028 - accuracy: 0.8927 - val_loss: 2.1899 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.4292 - accuracy: 0.8870 - val_loss: 2.2943 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 672us/step - loss: 0.2856 - accuracy: 0.8927 - val_loss: 2.2277 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.3222 - accuracy: 0.9040 - val_loss: 2.1621 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.2375 - accuracy: 0.9153 - val_loss: 2.0708 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.1849 - accuracy: 0.9266 - val_loss: 2.1322 - val_accuracy: 0.3947\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.1827 - accuracy: 0.9379 - val_loss: 2.1672 - val_accuracy: 0.4474\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 585us/step - loss: 0.2035 - accuracy: 0.9096 - val_loss: 2.1189 - val_accuracy: 0.4474\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.1703 - accuracy: 0.9435 - val_loss: 2.0744 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 513us/step - loss: 0.1812 - accuracy: 0.9435 - val_loss: 2.1014 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.1624 - accuracy: 0.9492 - val_loss: 2.1144 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.1609 - accuracy: 0.9322 - val_loss: 2.1380 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 540us/step - loss: 0.1604 - accuracy: 0.9379 - val_loss: 2.1933 - val_accuracy: 0.4474\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 602us/step - loss: 0.1715 - accuracy: 0.9379 - val_loss: 2.1781 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 529us/step - loss: 0.1551 - accuracy: 0.9435 - val_loss: 2.2063 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.1998 - accuracy: 0.9379 - val_loss: 2.1378 - val_accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.1750 - accuracy: 0.9322 - val_loss: 2.2970 - val_accuracy: 0.4342\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.3407 - accuracy: 0.8927 - val_loss: 2.3215 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63c3a92e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 212us/step\n",
      "test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2, 0, 1, 0, 1, 0, 2, 1, 2, 0,\n",
       "       0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0,\n",
       "       2, 1, 2, 2, 0, 1, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict_classes(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "178     NRS210     2     1\n",
       "104     Grady1     0     2\n",
       "79    CFBRSa29     2     0\n",
       "66    CFBRSa03     0     1\n",
       "9          217     1     1\n",
       "..         ...   ...   ...\n",
       "25   BCH-SA-10     1     1\n",
       "94        GA15     2     2\n",
       "244     SR3585     0     0\n",
       "227     NRS387     2     2\n",
       "185     NRS217     0     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model2.predict_proba(X_test)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081527</td>\n",
       "      <td>0.918088</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.304125</td>\n",
       "      <td>0.366356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632590</td>\n",
       "      <td>0.260623</td>\n",
       "      <td>0.106787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.975836</td>\n",
       "      <td>0.012352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.363130</td>\n",
       "      <td>0.447296</td>\n",
       "      <td>0.189574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.640052</td>\n",
       "      <td>0.341197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.355005</td>\n",
       "      <td>0.229513</td>\n",
       "      <td>0.415482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.748998</td>\n",
       "      <td>0.142183</td>\n",
       "      <td>0.108819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.058424</td>\n",
       "      <td>0.101928</td>\n",
       "      <td>0.839647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.940404</td>\n",
       "      <td>0.058923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.081527  0.918088  0.000385\n",
       "1   0.329519  0.304125  0.366356\n",
       "2   0.632590  0.260623  0.106787\n",
       "3   0.011812  0.975836  0.012352\n",
       "4   0.363130  0.447296  0.189574\n",
       "..       ...       ...       ...\n",
       "71  0.018751  0.640052  0.341197\n",
       "72  0.355005  0.229513  0.415482\n",
       "73  0.748998  0.142183  0.108819\n",
       "74  0.058424  0.101928  0.839647\n",
       "75  0.000673  0.940404  0.058923\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.1932 - accuracy: 0.9266 - val_loss: 2.2315 - val_accuracy: 0.4605\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.2160 - accuracy: 0.9266 - val_loss: 2.2207 - val_accuracy: 0.5526\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.1843 - accuracy: 0.9266 - val_loss: 2.2431 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 498us/step - loss: 0.2308 - accuracy: 0.9322 - val_loss: 2.2242 - val_accuracy: 0.5526\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 531us/step - loss: 0.2139 - accuracy: 0.9322 - val_loss: 2.2155 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.1950 - accuracy: 0.9209 - val_loss: 2.2539 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 593us/step - loss: 0.1861 - accuracy: 0.9209 - val_loss: 2.2041 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 701us/step - loss: 0.1858 - accuracy: 0.9266 - val_loss: 2.2186 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 676us/step - loss: 0.1634 - accuracy: 0.9435 - val_loss: 2.2255 - val_accuracy: 0.5132\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 590us/step - loss: 0.1640 - accuracy: 0.9379 - val_loss: 2.2318 - val_accuracy: 0.4868\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 527us/step - loss: 0.1920 - accuracy: 0.9266 - val_loss: 2.2720 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 556us/step - loss: 0.1960 - accuracy: 0.9266 - val_loss: 2.3459 - val_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.2122 - accuracy: 0.9266 - val_loss: 2.4069 - val_accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 583us/step - loss: 0.2504 - accuracy: 0.9322 - val_loss: 2.5301 - val_accuracy: 0.4474\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 659us/step - loss: 0.2266 - accuracy: 0.9266 - val_loss: 2.4442 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.1563 - accuracy: 0.9492 - val_loss: 2.4418 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1886 - accuracy: 0.9435 - val_loss: 2.4740 - val_accuracy: 0.4868\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 536us/step - loss: 0.1609 - accuracy: 0.9379 - val_loss: 2.4305 - val_accuracy: 0.5395\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.1699 - accuracy: 0.9492 - val_loss: 2.4884 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.1424 - accuracy: 0.9548 - val_loss: 2.4627 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.1847 - accuracy: 0.9435 - val_loss: 2.4986 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.3209 - accuracy: 0.9322 - val_loss: 2.5336 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.2735 - accuracy: 0.9266 - val_loss: 2.4659 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.2180 - accuracy: 0.9435 - val_loss: 2.4329 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.2075 - accuracy: 0.9492 - val_loss: 2.5028 - val_accuracy: 0.5263\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 2.4831 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 557us/step - loss: 0.1343 - accuracy: 0.9605 - val_loss: 2.5071 - val_accuracy: 0.4868\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 527us/step - loss: 0.1454 - accuracy: 0.9605 - val_loss: 2.5029 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 566us/step - loss: 0.1924 - accuracy: 0.9548 - val_loss: 2.4988 - val_accuracy: 0.4868\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 567us/step - loss: 0.2455 - accuracy: 0.9492 - val_loss: 2.5042 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 541us/step - loss: 0.2234 - accuracy: 0.9266 - val_loss: 2.5718 - val_accuracy: 0.4868\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 580us/step - loss: 0.4013 - accuracy: 0.9266 - val_loss: 2.7015 - val_accuracy: 0.4868\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.3719 - accuracy: 0.9266 - val_loss: 2.6552 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 579us/step - loss: 0.3566 - accuracy: 0.9435 - val_loss: 2.5154 - val_accuracy: 0.4211\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.2574 - accuracy: 0.9209 - val_loss: 2.4402 - val_accuracy: 0.5526\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.1696 - accuracy: 0.9379 - val_loss: 2.4614 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.1452 - accuracy: 0.9548 - val_loss: 2.4385 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.1528 - accuracy: 0.9492 - val_loss: 2.5015 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.1455 - accuracy: 0.9492 - val_loss: 2.5234 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.1503 - accuracy: 0.9435 - val_loss: 2.5528 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.1403 - accuracy: 0.9548 - val_loss: 2.5449 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 480us/step - loss: 0.1421 - accuracy: 0.9322 - val_loss: 2.5605 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 502us/step - loss: 0.1416 - accuracy: 0.9492 - val_loss: 2.6063 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.1326 - accuracy: 0.9605 - val_loss: 2.6707 - val_accuracy: 0.5263\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.2549 - accuracy: 0.8927 - val_loss: 2.7890 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.1574 - accuracy: 0.9322 - val_loss: 2.5598 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 496us/step - loss: 0.1557 - accuracy: 0.9492 - val_loss: 2.5697 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 492us/step - loss: 0.1455 - accuracy: 0.9435 - val_loss: 2.6036 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.1378 - accuracy: 0.9548 - val_loss: 2.6695 - val_accuracy: 0.4868\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.1321 - accuracy: 0.9492 - val_loss: 2.6673 - val_accuracy: 0.5263\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.1255 - accuracy: 0.9605 - val_loss: 2.6556 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.1395 - accuracy: 0.9435 - val_loss: 2.7271 - val_accuracy: 0.4474\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.1599 - accuracy: 0.9266 - val_loss: 2.7186 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 490us/step - loss: 0.1751 - accuracy: 0.9322 - val_loss: 2.7128 - val_accuracy: 0.4474\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1699 - accuracy: 0.9266 - val_loss: 2.6821 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 498us/step - loss: 0.1573 - accuracy: 0.9322 - val_loss: 2.6711 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 521us/step - loss: 0.1497 - accuracy: 0.9548 - val_loss: 2.7127 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.1414 - accuracy: 0.9548 - val_loss: 2.7385 - val_accuracy: 0.4737\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.1594 - accuracy: 0.9435 - val_loss: 2.7252 - val_accuracy: 0.4868\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.2485 - accuracy: 0.9379 - val_loss: 2.7385 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.1486 - accuracy: 0.9379 - val_loss: 2.7181 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.3784 - accuracy: 0.9040 - val_loss: 2.7622 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 487us/step - loss: 0.5062 - accuracy: 0.8192 - val_loss: 2.7539 - val_accuracy: 0.4211\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.4596 - accuracy: 0.8475 - val_loss: 2.5403 - val_accuracy: 0.5132\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 466us/step - loss: 0.3669 - accuracy: 0.8927 - val_loss: 2.5161 - val_accuracy: 0.5263\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.2767 - accuracy: 0.9153 - val_loss: 2.5974 - val_accuracy: 0.4868\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.2703 - accuracy: 0.9209 - val_loss: 2.6151 - val_accuracy: 0.4605\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 471us/step - loss: 0.2062 - accuracy: 0.9266 - val_loss: 2.6284 - val_accuracy: 0.5263\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1899 - accuracy: 0.9548 - val_loss: 2.6680 - val_accuracy: 0.4868\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 492us/step - loss: 0.2866 - accuracy: 0.9266 - val_loss: 2.6376 - val_accuracy: 0.5132\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 473us/step - loss: 0.1943 - accuracy: 0.9322 - val_loss: 2.6734 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.3937 - accuracy: 0.8757 - val_loss: 2.6289 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.3546 - accuracy: 0.8757 - val_loss: 2.4938 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.2903 - accuracy: 0.9096 - val_loss: 2.4311 - val_accuracy: 0.5132\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 496us/step - loss: 0.2441 - accuracy: 0.9322 - val_loss: 2.4989 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.2273 - accuracy: 0.9379 - val_loss: 2.5220 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 485us/step - loss: 0.1680 - accuracy: 0.9435 - val_loss: 2.5913 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.2229 - accuracy: 0.9435 - val_loss: 2.6635 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.1939 - accuracy: 0.9492 - val_loss: 2.6667 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.3500 - accuracy: 0.8927 - val_loss: 2.7239 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.1996 - accuracy: 0.9266 - val_loss: 2.9228 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 487us/step - loss: 0.1823 - accuracy: 0.9379 - val_loss: 2.9689 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.2022 - accuracy: 0.9492 - val_loss: 2.9670 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.1263 - accuracy: 0.9548 - val_loss: 2.9682 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 486us/step - loss: 0.1508 - accuracy: 0.9548 - val_loss: 2.9644 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.1827 - accuracy: 0.9548 - val_loss: 3.0261 - val_accuracy: 0.4868\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.2185 - accuracy: 0.9096 - val_loss: 3.1349 - val_accuracy: 0.4737\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.1780 - accuracy: 0.9435 - val_loss: 2.9377 - val_accuracy: 0.5395\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 506us/step - loss: 0.1605 - accuracy: 0.9379 - val_loss: 2.9776 - val_accuracy: 0.4737\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.1229 - accuracy: 0.9492 - val_loss: 3.0190 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.1512 - accuracy: 0.9548 - val_loss: 2.9866 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 485us/step - loss: 0.1033 - accuracy: 0.9605 - val_loss: 2.9909 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.1058 - accuracy: 0.9492 - val_loss: 3.0198 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 509us/step - loss: 0.1486 - accuracy: 0.9548 - val_loss: 3.0458 - val_accuracy: 0.5132\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.1213 - accuracy: 0.9435 - val_loss: 3.1519 - val_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.1087 - accuracy: 0.9492 - val_loss: 3.0834 - val_accuracy: 0.4868\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.0925 - accuracy: 0.9605 - val_loss: 3.1032 - val_accuracy: 0.5132\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.1036 - accuracy: 0.9661 - val_loss: 3.0933 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 495us/step - loss: 0.0964 - accuracy: 0.9548 - val_loss: 3.0773 - val_accuracy: 0.4868\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.0986 - accuracy: 0.9548 - val_loss: 3.1134 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 93.55%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.851192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625329</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.889404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>6.335156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>2.086646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>4.754707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>2.864372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>5.715521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>9.284494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>9.653131e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>3.775318e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS210          2           0  0.999887   \n",
       "1       p0017kpresabs_qual    Grady1          0           0  0.625329   \n",
       "2       p0017kpresabs_qual  CFBRSa29          2           0  0.999098   \n",
       "3       p0017kpresabs_qual  CFBRSa03          0           0  0.647338   \n",
       "4       p0017kpresabs_qual       217          1           0  0.613342   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS265          1           1  0.025601   \n",
       "604  p0040presabsSTCC_qual     NY439          2           2  0.161947   \n",
       "605  p0040presabsSTCC_qual  CFBRSa05          0           0  0.652983   \n",
       "606  p0040presabsSTCC_qual    NRS205          2           2  0.000927   \n",
       "607  p0040presabsSTCC_qual     CA105          1           0  0.736115   \n",
       "\n",
       "            1             2  \n",
       "0    0.000112  8.851192e-07  \n",
       "1    0.369782  4.889404e-03  \n",
       "2    0.000269  6.335156e-04  \n",
       "3    0.331796  2.086646e-02  \n",
       "4    0.381903  4.754707e-03  \n",
       "..        ...           ...  \n",
       "603  0.687962  2.864372e-01  \n",
       "604  0.266501  5.715521e-01  \n",
       "605  0.254172  9.284494e-02  \n",
       "606  0.033760  9.653131e-01  \n",
       "607  0.260109  3.775318e-03  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.15265400e-02, 9.18088140e-01, 3.85301160e-04],\n",
       "       [3.29518850e-01, 3.04124650e-01, 3.66356500e-01],\n",
       "       [6.32589700e-01, 2.60622950e-01, 1.06787370e-01],\n",
       "       [1.18123260e-02, 9.75835740e-01, 1.23519290e-02],\n",
       "       [3.63130150e-01, 4.47296000e-01, 1.89573880e-01],\n",
       "       [5.49466400e-03, 3.60497200e-01, 6.34008100e-01],\n",
       "       [9.59864900e-01, 1.86675860e-02, 2.14674580e-02],\n",
       "       [1.40141710e-01, 6.41925700e-01, 2.17932600e-01],\n",
       "       [3.00830860e-08, 2.22404250e-04, 9.99777600e-01],\n",
       "       [9.02642500e-01, 5.99486500e-02, 3.74088180e-02],\n",
       "       [3.25059700e-01, 5.53053440e-01, 1.21886870e-01],\n",
       "       [2.72419040e-05, 4.67871000e-02, 9.53185700e-01],\n",
       "       [7.96510200e-01, 2.01096580e-01, 2.39321820e-03],\n",
       "       [7.56294800e-02, 9.19433100e-01, 4.93738900e-03],\n",
       "       [7.91458900e-02, 8.85281700e-01, 3.55723460e-02],\n",
       "       [3.38485420e-01, 6.34423730e-01, 2.70908180e-02],\n",
       "       [1.09793840e-04, 9.99885560e-01, 4.66086300e-06],\n",
       "       [2.17132370e-01, 7.80801100e-01, 2.06639870e-03],\n",
       "       [1.50165410e-05, 3.43962270e-03, 9.96545400e-01],\n",
       "       [9.88710100e-01, 1.03975290e-02, 8.92340850e-04],\n",
       "       [5.23186300e-04, 9.12525900e-01, 8.69508000e-02],\n",
       "       [3.61042600e-01, 3.14822550e-01, 3.24134830e-01],\n",
       "       [9.93055900e-01, 4.87122500e-03, 2.07285750e-03],\n",
       "       [2.19471220e-03, 9.19996700e-01, 7.78085440e-02],\n",
       "       [1.64001940e-03, 7.99665600e-01, 1.98694420e-01],\n",
       "       [9.71911700e-01, 2.03565470e-02, 7.73179950e-03],\n",
       "       [7.93407200e-01, 6.96508960e-02, 1.36941940e-01],\n",
       "       [9.60766730e-01, 3.33727800e-02, 5.86051070e-03],\n",
       "       [2.51634750e-01, 5.68186460e-01, 1.80178850e-01],\n",
       "       [9.00916600e-03, 2.41856170e-02, 9.66805160e-01],\n",
       "       [1.57608710e-04, 9.99685170e-01, 1.57212560e-04],\n",
       "       [1.33749690e-06, 1.10936450e-02, 9.88904950e-01],\n",
       "       [3.25337200e-02, 5.97395820e-02, 9.07726650e-01],\n",
       "       [9.83308730e-01, 5.72308670e-05, 1.66340540e-02],\n",
       "       [1.10008880e-01, 1.23102196e-01, 7.66888900e-01],\n",
       "       [7.01542000e-01, 6.50378000e-02, 2.33420210e-01],\n",
       "       [2.36938340e-01, 5.07019040e-01, 2.56042660e-01],\n",
       "       [9.95638800e-01, 6.72180800e-04, 3.68915130e-03],\n",
       "       [7.77333460e-03, 9.70128500e-01, 2.20982260e-02],\n",
       "       [9.85264200e-01, 1.30840910e-02, 1.65168740e-03],\n",
       "       [2.06419730e-02, 4.05709950e-01, 5.73648100e-01],\n",
       "       [2.90870130e-01, 5.66622140e-01, 1.42507730e-01],\n",
       "       [6.72721500e-04, 6.27850200e-05, 9.99264540e-01],\n",
       "       [3.98672340e-01, 2.69479700e-01, 3.31848000e-01],\n",
       "       [6.27405000e-01, 1.96371880e-01, 1.76223100e-01],\n",
       "       [2.37387300e-02, 9.09201560e-01, 6.70597260e-02],\n",
       "       [4.10565020e-01, 3.54672520e-01, 2.34762420e-01],\n",
       "       [7.41511700e-03, 9.56508460e-01, 3.60763520e-02],\n",
       "       [3.08363320e-01, 6.35061000e-01, 5.65756970e-02],\n",
       "       [1.77622780e-03, 8.49218130e-01, 1.49005650e-01],\n",
       "       [1.50419030e-01, 2.68421300e-04, 8.49312540e-01],\n",
       "       [6.64480550e-04, 9.99323600e-01, 1.18912710e-05],\n",
       "       [6.34170800e-01, 2.09953640e-01, 1.55875530e-01],\n",
       "       [3.92776200e-02, 7.55520400e-01, 2.05202000e-01],\n",
       "       [7.17237500e-01, 2.82181080e-01, 5.81389350e-04],\n",
       "       [5.95633450e-01, 3.86928020e-01, 1.74384620e-02],\n",
       "       [3.98965750e-01, 5.48992700e-01, 5.20416160e-02],\n",
       "       [9.69242200e-01, 6.89203660e-03, 2.38657520e-02],\n",
       "       [6.59986600e-01, 3.36794800e-02, 3.06333960e-01],\n",
       "       [6.56200050e-01, 1.65904920e-01, 1.77895100e-01],\n",
       "       [1.42317400e-01, 1.93246660e-01, 6.64435860e-01],\n",
       "       [1.78996160e-08, 7.71280100e-05, 9.99922900e-01],\n",
       "       [8.44205800e-03, 2.09028360e-01, 7.82529530e-01],\n",
       "       [5.46959820e-02, 9.66910800e-02, 8.48612900e-01],\n",
       "       [8.76536900e-02, 1.47667440e-02, 8.97579550e-01],\n",
       "       [9.74769700e-01, 2.51398850e-02, 9.04439800e-05],\n",
       "       [3.24086300e-01, 2.84791000e-02, 6.47434600e-01],\n",
       "       [4.89943330e-03, 9.60774100e-01, 3.43264900e-02],\n",
       "       [3.82441500e-01, 1.86480400e-01, 4.31078080e-01],\n",
       "       [2.39342950e-02, 3.93600850e-01, 5.82464900e-01],\n",
       "       [9.99982360e-01, 2.49312370e-06, 1.50995040e-05],\n",
       "       [1.87505970e-02, 6.40052100e-01, 3.41197400e-01],\n",
       "       [3.55004580e-01, 2.29513360e-01, 4.15482040e-01],\n",
       "       [7.48998200e-01, 1.42182540e-01, 1.08819170e-01],\n",
       "       [5.84242570e-02, 1.01928460e-01, 8.39647300e-01],\n",
       "       [6.73386150e-04, 9.40404060e-01, 5.89225740e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909205433014956"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909205433014956"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat3['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "231      NY360     2\n",
       "92       EUH25     2\n",
       "91       EUH15     2\n",
       "203     NRS241     0\n",
       "242     SR2852     2\n",
       "..         ...   ...\n",
       "26   BCH-SA-11     0\n",
       "111     NRS022     1\n",
       "96        GA27     2\n",
       "129     NRS102     1\n",
       "166     NRS192     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.3503 - val_loss: 1.3662 - val_accuracy: 0.3684\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 683us/step - loss: 1.1352 - accuracy: 0.5537 - val_loss: 1.6999 - val_accuracy: 0.3026\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 713us/step - loss: 1.0572 - accuracy: 0.5593 - val_loss: 1.4395 - val_accuracy: 0.3684\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 883us/step - loss: 0.8711 - accuracy: 0.6102 - val_loss: 1.3950 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.7997 - accuracy: 0.6497 - val_loss: 1.4311 - val_accuracy: 0.4342\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.8549 - accuracy: 0.6384 - val_loss: 1.4501 - val_accuracy: 0.4211\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.9850 - accuracy: 0.6215 - val_loss: 1.5058 - val_accuracy: 0.3816\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 557us/step - loss: 0.8926 - accuracy: 0.6780 - val_loss: 1.4340 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.9312 - accuracy: 0.6610 - val_loss: 1.5419 - val_accuracy: 0.4211\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 726us/step - loss: 0.8283 - accuracy: 0.6723 - val_loss: 1.4824 - val_accuracy: 0.3684\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.7178 - accuracy: 0.6780 - val_loss: 1.3962 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 692us/step - loss: 0.7349 - accuracy: 0.7006 - val_loss: 1.5225 - val_accuracy: 0.3684\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 770us/step - loss: 0.7222 - accuracy: 0.7232 - val_loss: 1.5722 - val_accuracy: 0.4079\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 916us/step - loss: 0.6702 - accuracy: 0.7627 - val_loss: 1.5164 - val_accuracy: 0.4079\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 732us/step - loss: 0.6631 - accuracy: 0.7571 - val_loss: 1.5603 - val_accuracy: 0.4342\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.7698 - accuracy: 0.7006 - val_loss: 1.6392 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.6468 - accuracy: 0.7345 - val_loss: 1.4942 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.5658 - accuracy: 0.7684 - val_loss: 1.5157 - val_accuracy: 0.3947\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7627 - val_loss: 1.6245 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 996us/step - loss: 0.5155 - accuracy: 0.7797 - val_loss: 1.6779 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 881us/step - loss: 0.5065 - accuracy: 0.7910 - val_loss: 1.5952 - val_accuracy: 0.4211\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7740 - val_loss: 1.6940 - val_accuracy: 0.3947\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7910 - val_loss: 1.8063 - val_accuracy: 0.4079\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8023 - val_loss: 1.7046 - val_accuracy: 0.4474\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8023 - val_loss: 1.7069 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 852us/step - loss: 0.4300 - accuracy: 0.8588 - val_loss: 1.7070 - val_accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 733us/step - loss: 0.4575 - accuracy: 0.8136 - val_loss: 1.8014 - val_accuracy: 0.4211\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 717us/step - loss: 0.4403 - accuracy: 0.8192 - val_loss: 1.8741 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 860us/step - loss: 0.3673 - accuracy: 0.8531 - val_loss: 1.7656 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.3749 - accuracy: 0.8588 - val_loss: 1.9570 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 486us/step - loss: 0.4473 - accuracy: 0.8475 - val_loss: 1.9894 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.3754 - accuracy: 0.8475 - val_loss: 1.9137 - val_accuracy: 0.4605\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.3623 - accuracy: 0.8701 - val_loss: 1.9470 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.3486 - accuracy: 0.8701 - val_loss: 1.9260 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 562us/step - loss: 0.3288 - accuracy: 0.8757 - val_loss: 1.9928 - val_accuracy: 0.4474\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 564us/step - loss: 0.3385 - accuracy: 0.8588 - val_loss: 1.9608 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 578us/step - loss: 0.3217 - accuracy: 0.8814 - val_loss: 2.0655 - val_accuracy: 0.4342\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.3060 - accuracy: 0.8814 - val_loss: 1.9008 - val_accuracy: 0.4605\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 917us/step - loss: 0.2985 - accuracy: 0.8701 - val_loss: 2.0954 - val_accuracy: 0.4474\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.8701 - val_loss: 1.9759 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.3250 - accuracy: 0.8644 - val_loss: 2.0846 - val_accuracy: 0.4211\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.3261 - accuracy: 0.8588 - val_loss: 1.8527 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 487us/step - loss: 0.3012 - accuracy: 0.8644 - val_loss: 2.2463 - val_accuracy: 0.4079\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 480us/step - loss: 0.2839 - accuracy: 0.8757 - val_loss: 2.0973 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 741us/step - loss: 0.3171 - accuracy: 0.8588 - val_loss: 1.9188 - val_accuracy: 0.4342\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 806us/step - loss: 0.3582 - accuracy: 0.8475 - val_loss: 2.0770 - val_accuracy: 0.4211\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 668us/step - loss: 0.3014 - accuracy: 0.8927 - val_loss: 2.0325 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 545us/step - loss: 0.2582 - accuracy: 0.9096 - val_loss: 2.1017 - val_accuracy: 0.3947\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.2817 - accuracy: 0.9040 - val_loss: 2.1943 - val_accuracy: 0.3816\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.5139 - accuracy: 0.7966 - val_loss: 2.1224 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 576us/step - loss: 0.4742 - accuracy: 0.8249 - val_loss: 2.0455 - val_accuracy: 0.4079\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 999us/step - loss: 0.3202 - accuracy: 0.8814 - val_loss: 2.1272 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 584us/step - loss: 0.3370 - accuracy: 0.8701 - val_loss: 2.2050 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.2822 - accuracy: 0.8814 - val_loss: 2.2840 - val_accuracy: 0.4211\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.2485 - accuracy: 0.9435 - val_loss: 2.3093 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 672us/step - loss: 0.2447 - accuracy: 0.9266 - val_loss: 2.2073 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.2208 - accuracy: 0.9379 - val_loss: 2.2204 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 697us/step - loss: 0.2013 - accuracy: 0.9322 - val_loss: 2.2654 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 738us/step - loss: 0.2190 - accuracy: 0.9322 - val_loss: 2.2747 - val_accuracy: 0.4342\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.2126 - accuracy: 0.9322 - val_loss: 2.2106 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.2412 - accuracy: 0.9209 - val_loss: 2.4299 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.2358 - accuracy: 0.9096 - val_loss: 2.3668 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 471us/step - loss: 0.1971 - accuracy: 0.9266 - val_loss: 2.3116 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.5004 - accuracy: 0.8588 - val_loss: 3.1190 - val_accuracy: 0.4079\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 490us/step - loss: 1.0579 - accuracy: 0.8983 - val_loss: 2.8634 - val_accuracy: 0.4474\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.3597 - accuracy: 0.8870 - val_loss: 2.6724 - val_accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.5086 - accuracy: 0.9040 - val_loss: 2.2038 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.3962 - accuracy: 0.9209 - val_loss: 2.6781 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 608us/step - loss: 0.4050 - accuracy: 0.9266 - val_loss: 2.4807 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.3075 - accuracy: 0.9040 - val_loss: 2.5233 - val_accuracy: 0.4737\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.2675 - accuracy: 0.9209 - val_loss: 2.3600 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.2019 - accuracy: 0.9435 - val_loss: 2.4545 - val_accuracy: 0.4605\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 578us/step - loss: 0.1984 - accuracy: 0.9153 - val_loss: 2.4896 - val_accuracy: 0.4605\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.1898 - accuracy: 0.9548 - val_loss: 2.5110 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.1568 - accuracy: 0.9605 - val_loss: 2.4372 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 487us/step - loss: 0.1476 - accuracy: 0.9492 - val_loss: 2.4977 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.1626 - accuracy: 0.9548 - val_loss: 2.5295 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.1473 - accuracy: 0.9605 - val_loss: 2.6205 - val_accuracy: 0.4868\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 624us/step - loss: 0.1876 - accuracy: 0.9266 - val_loss: 2.5017 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.1724 - accuracy: 0.9322 - val_loss: 2.6453 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 729us/step - loss: 0.1719 - accuracy: 0.9153 - val_loss: 2.5803 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 531us/step - loss: 0.1998 - accuracy: 0.9096 - val_loss: 2.8089 - val_accuracy: 0.4474\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 520us/step - loss: 0.2322 - accuracy: 0.9266 - val_loss: 2.7362 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 528us/step - loss: 0.1611 - accuracy: 0.9379 - val_loss: 2.6618 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.1572 - accuracy: 0.9435 - val_loss: 2.7203 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.1619 - accuracy: 0.9322 - val_loss: 2.5782 - val_accuracy: 0.4868\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 598us/step - loss: 0.1494 - accuracy: 0.9435 - val_loss: 2.6303 - val_accuracy: 0.4211\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.5313 - accuracy: 0.9209 - val_loss: 2.6245 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 498us/step - loss: 0.3566 - accuracy: 0.9379 - val_loss: 3.3063 - val_accuracy: 0.4079\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 685us/step - loss: 0.2344 - accuracy: 0.9209 - val_loss: 3.2151 - val_accuracy: 0.3553\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 677us/step - loss: 0.3017 - accuracy: 0.9266 - val_loss: 3.0297 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.3846 - accuracy: 0.8927 - val_loss: 2.7840 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 720us/step - loss: 0.7152 - accuracy: 0.8023 - val_loss: 3.2981 - val_accuracy: 0.4079\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 777us/step - loss: 0.5031 - accuracy: 0.8362 - val_loss: 2.5233 - val_accuracy: 0.5132\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 574us/step - loss: 0.4862 - accuracy: 0.8701 - val_loss: 3.7293 - val_accuracy: 0.4342\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 495us/step - loss: 0.4530 - accuracy: 0.8362 - val_loss: 2.7394 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9153 - val_loss: 2.5459 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 775us/step - loss: 0.1864 - accuracy: 0.9379 - val_loss: 2.5837 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 585us/step - loss: 0.1760 - accuracy: 0.9548 - val_loss: 2.6369 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.1579 - accuracy: 0.9492 - val_loss: 2.5714 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a42276240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 226us/step\n",
      "test accuracy: 44.74%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 2,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 1, 1, 1, 0, 2,\n",
       "       0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 2,\n",
       "       2, 0, 2, 2, 1, 0, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict_classes(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "231      NY360     2     1\n",
       "92       EUH25     2     2\n",
       "91       EUH15     2     2\n",
       "203     NRS241     0     1\n",
       "242     SR2852     2     2\n",
       "..         ...   ...   ...\n",
       "26   BCH-SA-11     0     0\n",
       "111     NRS022     1     2\n",
       "96        GA27     2     2\n",
       "129     NRS102     1     0\n",
       "166     NRS192     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model3.predict_proba(X_test)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126397</td>\n",
       "      <td>0.865422</td>\n",
       "      <td>0.008181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.410383</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.588977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>0.952332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202512</td>\n",
       "      <td>0.744713</td>\n",
       "      <td>0.052775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.052598</td>\n",
       "      <td>0.947125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.909264</td>\n",
       "      <td>0.084855</td>\n",
       "      <td>0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.993794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.043086</td>\n",
       "      <td>0.956747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.903737</td>\n",
       "      <td>0.092407</td>\n",
       "      <td>0.003856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.859798</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.118167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.126397  0.865422  0.008181\n",
       "1   0.410383  0.000640  0.588977\n",
       "2   0.029125  0.018543  0.952332\n",
       "3   0.202512  0.744713  0.052775\n",
       "4   0.000277  0.052598  0.947125\n",
       "..       ...       ...       ...\n",
       "71  0.909264  0.084855  0.005880\n",
       "72  0.005166  0.001040  0.993794\n",
       "73  0.000167  0.043086  0.956747\n",
       "74  0.903737  0.092407  0.003856\n",
       "75  0.859798  0.022035  0.118167\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.1394 - accuracy: 0.9718 - val_loss: 2.9921 - val_accuracy: 0.4737\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.1135 - accuracy: 0.9605 - val_loss: 3.0083 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 547us/step - loss: 0.1480 - accuracy: 0.9605 - val_loss: 2.9106 - val_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 558us/step - loss: 0.1608 - accuracy: 0.9548 - val_loss: 2.9860 - val_accuracy: 0.4342\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.1937 - accuracy: 0.9661 - val_loss: 3.0510 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 522us/step - loss: 0.1874 - accuracy: 0.9605 - val_loss: 2.9599 - val_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 634us/step - loss: 0.1350 - accuracy: 0.9605 - val_loss: 3.0593 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 558us/step - loss: 0.1250 - accuracy: 0.9605 - val_loss: 3.0730 - val_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.1191 - accuracy: 0.9718 - val_loss: 3.0951 - val_accuracy: 0.4605\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 701us/step - loss: 0.1228 - accuracy: 0.9661 - val_loss: 3.0719 - val_accuracy: 0.4737\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 610us/step - loss: 0.1157 - accuracy: 0.9718 - val_loss: 3.0708 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.1023 - accuracy: 0.9774 - val_loss: 3.0746 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.1251 - accuracy: 0.9774 - val_loss: 3.1163 - val_accuracy: 0.4737\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 552us/step - loss: 0.1035 - accuracy: 0.9718 - val_loss: 3.1524 - val_accuracy: 0.4605\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 548us/step - loss: 0.0997 - accuracy: 0.9831 - val_loss: 3.1460 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9774 - val_loss: 3.0586 - val_accuracy: 0.4737\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 528us/step - loss: 1.0385 - accuracy: 0.9153 - val_loss: 3.6358 - val_accuracy: 0.4079\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 676us/step - loss: 1.1650 - accuracy: 0.9096 - val_loss: 3.3491 - val_accuracy: 0.4474\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.5586 - accuracy: 0.9266 - val_loss: 3.3423 - val_accuracy: 0.4474\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.8008 - accuracy: 0.8644 - val_loss: 4.8459 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.7479 - accuracy: 0.8644 - val_loss: 4.3023 - val_accuracy: 0.4342\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.9153 - val_loss: 3.8671 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      " 16/177 [=>............................] - ETA: 0s - loss: 0.2560 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.118353). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.9096 - val_loss: 3.6821 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.2334 - accuracy: 0.9379 - val_loss: 3.4956 - val_accuracy: 0.4474\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 819us/step - loss: 0.1734 - accuracy: 0.9605 - val_loss: 3.1044 - val_accuracy: 0.4868\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.1086 - accuracy: 0.9605 - val_loss: 3.0833 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 595us/step - loss: 0.1593 - accuracy: 0.9718 - val_loss: 3.0936 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 581us/step - loss: 0.1078 - accuracy: 0.9718 - val_loss: 3.1142 - val_accuracy: 0.4868\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 578us/step - loss: 0.1787 - accuracy: 0.9774 - val_loss: 3.2596 - val_accuracy: 0.4474\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.2424 - accuracy: 0.9209 - val_loss: 3.2099 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.1965 - accuracy: 0.9379 - val_loss: 3.1271 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 748us/step - loss: 0.1343 - accuracy: 0.9661 - val_loss: 3.1036 - val_accuracy: 0.4342\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 890us/step - loss: 0.5428 - accuracy: 0.9379 - val_loss: 3.4750 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9266 - val_loss: 3.1081 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 932us/step - loss: 0.2016 - accuracy: 0.9379 - val_loss: 2.9007 - val_accuracy: 0.4605\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 693us/step - loss: 0.1638 - accuracy: 0.9266 - val_loss: 3.0608 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 671us/step - loss: 0.1428 - accuracy: 0.9492 - val_loss: 2.9241 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 685us/step - loss: 0.1221 - accuracy: 0.9661 - val_loss: 2.9865 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 583us/step - loss: 0.1198 - accuracy: 0.9548 - val_loss: 3.0467 - val_accuracy: 0.4342\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 560us/step - loss: 0.1238 - accuracy: 0.9435 - val_loss: 3.0650 - val_accuracy: 0.4474\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 557us/step - loss: 0.1208 - accuracy: 0.9492 - val_loss: 3.0350 - val_accuracy: 0.4605\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 594us/step - loss: 0.1091 - accuracy: 0.9492 - val_loss: 3.0689 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 763us/step - loss: 0.1049 - accuracy: 0.9661 - val_loss: 3.0797 - val_accuracy: 0.4474\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 689us/step - loss: 0.1280 - accuracy: 0.9605 - val_loss: 3.0828 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 785us/step - loss: 0.1177 - accuracy: 0.9605 - val_loss: 3.1596 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 718us/step - loss: 0.1080 - accuracy: 0.9661 - val_loss: 3.1276 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 786us/step - loss: 0.1091 - accuracy: 0.9605 - val_loss: 3.0945 - val_accuracy: 0.4605\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 594us/step - loss: 0.1005 - accuracy: 0.9661 - val_loss: 3.0958 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.1203 - accuracy: 0.9492 - val_loss: 3.1649 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 590us/step - loss: 0.1064 - accuracy: 0.9605 - val_loss: 3.1640 - val_accuracy: 0.4605\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 618us/step - loss: 0.1001 - accuracy: 0.9661 - val_loss: 3.1514 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 597us/step - loss: 0.1039 - accuracy: 0.9661 - val_loss: 3.1589 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 760us/step - loss: 0.0923 - accuracy: 0.9661 - val_loss: 3.2071 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 917us/step - loss: 0.1066 - accuracy: 0.9492 - val_loss: 3.1096 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 922us/step - loss: 0.1277 - accuracy: 0.9492 - val_loss: 3.1354 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 728us/step - loss: 0.1303 - accuracy: 0.9661 - val_loss: 3.1074 - val_accuracy: 0.4605\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.1179 - accuracy: 0.9605 - val_loss: 3.1817 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 703us/step - loss: 0.0949 - accuracy: 0.9661 - val_loss: 3.1868 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 700us/step - loss: 0.0994 - accuracy: 0.9661 - val_loss: 3.2280 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.0999 - accuracy: 0.9605 - val_loss: 3.2133 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 781us/step - loss: 0.1083 - accuracy: 0.9718 - val_loss: 3.2406 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 727us/step - loss: 0.0799 - accuracy: 0.9718 - val_loss: 3.2946 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.1025 - accuracy: 0.9718 - val_loss: 3.3002 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.0913 - accuracy: 0.9774 - val_loss: 3.2760 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.1716 - accuracy: 0.9266 - val_loss: 3.4357 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 560us/step - loss: 0.1526 - accuracy: 0.9266 - val_loss: 3.3477 - val_accuracy: 0.4868\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.2153 - accuracy: 0.9096 - val_loss: 3.7094 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 626us/step - loss: 0.1396 - accuracy: 0.9435 - val_loss: 3.3165 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.1324 - accuracy: 0.9548 - val_loss: 3.6263 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 743us/step - loss: 0.0996 - accuracy: 0.9661 - val_loss: 3.3296 - val_accuracy: 0.4868\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 731us/step - loss: 0.1145 - accuracy: 0.9718 - val_loss: 3.3059 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 736us/step - loss: 0.0938 - accuracy: 0.9774 - val_loss: 3.5012 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 732us/step - loss: 0.0913 - accuracy: 0.9831 - val_loss: 3.2880 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 773us/step - loss: 0.1049 - accuracy: 0.9718 - val_loss: 3.4743 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 618us/step - loss: 0.0957 - accuracy: 0.9718 - val_loss: 3.3719 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.0928 - accuracy: 0.9774 - val_loss: 3.3970 - val_accuracy: 0.4737\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 740us/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 3.4779 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 718us/step - loss: 0.0859 - accuracy: 0.9774 - val_loss: 3.4076 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 862us/step - loss: 0.0883 - accuracy: 0.9718 - val_loss: 3.4379 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.1162 - accuracy: 0.9718 - val_loss: 3.4741 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 622us/step - loss: 0.0825 - accuracy: 0.9718 - val_loss: 3.4977 - val_accuracy: 0.4605\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.0895 - accuracy: 0.9718 - val_loss: 3.4585 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 622us/step - loss: 0.0724 - accuracy: 0.9774 - val_loss: 3.5060 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.0748 - accuracy: 0.9661 - val_loss: 3.5221 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.0848 - accuracy: 0.9774 - val_loss: 3.4935 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 784us/step - loss: 0.0798 - accuracy: 0.9774 - val_loss: 3.5059 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 918us/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 3.5338 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.0694 - accuracy: 0.9718 - val_loss: 3.5246 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 632us/step - loss: 0.0745 - accuracy: 0.9718 - val_loss: 3.5083 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 612us/step - loss: 0.0852 - accuracy: 0.9718 - val_loss: 3.5791 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.0716 - accuracy: 0.9831 - val_loss: 3.5358 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9774 - val_loss: 3.5290 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.1091 - accuracy: 0.9661 - val_loss: 3.5141 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9548 - val_loss: 3.6517 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 739us/step - loss: 0.1028 - accuracy: 0.9492 - val_loss: 3.5421 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 789us/step - loss: 0.0756 - accuracy: 0.9718 - val_loss: 3.5968 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 3.6573 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 696us/step - loss: 0.0678 - accuracy: 0.9718 - val_loss: 3.6396 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.0647 - accuracy: 0.9774 - val_loss: 3.6534 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 839us/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 3.6413 - val_accuracy: 0.4605\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.86%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.165526e-02</td>\n",
       "      <td>4.848140e-01</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.986388e-01</td>\n",
       "      <td>1.245148e-03</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.227520e-04</td>\n",
       "      <td>1.424882e-02</td>\n",
       "      <td>0.984828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.374333e-01</td>\n",
       "      <td>1.614128e-01</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.976981e-09</td>\n",
       "      <td>5.145955e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305407e-01</td>\n",
       "      <td>6.356251e-02</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.476389e-02</td>\n",
       "      <td>8.577548e-01</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779456e-01</td>\n",
       "      <td>5.384378e-01</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.210180e-01</td>\n",
       "      <td>3.559393e-01</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.484084e-03</td>\n",
       "      <td>9.944786e-01</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage     strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual      NY360          2           2  2.165526e-02   \n",
       "1       p0017kpresabs_qual      EUH25          2           0  9.986388e-01   \n",
       "2       p0017kpresabs_qual      EUH15          2           2  9.227520e-04   \n",
       "3       p0017kpresabs_qual     NRS241          0           0  8.374333e-01   \n",
       "4       p0017kpresabs_qual     SR2852          2           2  3.976981e-09   \n",
       "..                     ...        ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  BCH-SA-01          0           0  9.305407e-01   \n",
       "604  p0040presabsSTCC_qual        504          0           1  4.476389e-02   \n",
       "605  p0040presabsSTCC_qual       GA27          2           1  2.779456e-01   \n",
       "606  p0040presabsSTCC_qual     NRS209          1           0  4.210180e-01   \n",
       "607  p0040presabsSTCC_qual  BCH-SA-13          1           1  5.484084e-03   \n",
       "\n",
       "                1         2  \n",
       "0    4.848140e-01  0.493531  \n",
       "1    1.245148e-03  0.000116  \n",
       "2    1.424882e-02  0.984828  \n",
       "3    1.614128e-01  0.001154  \n",
       "4    5.145955e-10  1.000000  \n",
       "..            ...       ...  \n",
       "603  6.356251e-02  0.005897  \n",
       "604  8.577548e-01  0.097481  \n",
       "605  5.384378e-01  0.183617  \n",
       "606  3.559393e-01  0.223043  \n",
       "607  9.944786e-01  0.000037  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26396850e-01, 8.65422000e-01, 8.18115400e-03],\n",
       "       [4.10383200e-01, 6.39689600e-04, 5.88977100e-01],\n",
       "       [2.91246050e-02, 1.85434220e-02, 9.52332000e-01],\n",
       "       [2.02512030e-01, 7.44713300e-01, 5.27747000e-02],\n",
       "       [2.76904800e-04, 5.25984650e-02, 9.47124600e-01],\n",
       "       [1.39941680e-02, 8.16045600e-20, 9.86005800e-01],\n",
       "       [1.74624660e-02, 7.56512170e-01, 2.26025400e-01],\n",
       "       [3.03647340e-04, 3.86978000e-02, 9.60998540e-01],\n",
       "       [6.12981700e-01, 1.89618380e-01, 1.97399960e-01],\n",
       "       [9.35696200e-01, 7.54482900e-03, 5.67589800e-02],\n",
       "       [6.10852200e-01, 3.21490470e-01, 6.76573200e-02],\n",
       "       [9.96480500e-01, 3.93556180e-07, 3.51915560e-03],\n",
       "       [9.48791800e-01, 3.63506450e-02, 1.48575800e-02],\n",
       "       [8.99686500e-01, 9.82338560e-02, 2.07962860e-03],\n",
       "       [6.33348100e-01, 1.14917280e-02, 3.55160150e-01],\n",
       "       [4.71423100e-01, 4.46810130e-01, 8.17668140e-02],\n",
       "       [1.48697750e-01, 4.80408220e-01, 3.70894070e-01],\n",
       "       [2.03739540e-01, 2.02078310e-01, 5.94182200e-01],\n",
       "       [8.24122500e-05, 9.93260900e-01, 6.65671470e-03],\n",
       "       [9.89480850e-01, 8.41953030e-04, 9.67716100e-03],\n",
       "       [9.78355770e-01, 2.13907440e-02, 2.53574050e-04],\n",
       "       [5.88970030e-03, 1.72069900e-04, 9.93938200e-01],\n",
       "       [9.69830700e-01, 1.82444750e-02, 1.19248150e-02],\n",
       "       [3.78771900e-02, 1.08539610e-18, 9.62122800e-01],\n",
       "       [3.52282700e-01, 6.40746500e-01, 6.97082500e-03],\n",
       "       [5.79859400e-02, 2.00240540e-01, 7.41773500e-01],\n",
       "       [3.37905680e-01, 4.81349020e-01, 1.80745230e-01],\n",
       "       [1.36282470e-01, 8.63019800e-01, 6.97776850e-04],\n",
       "       [8.58463900e-01, 1.23474160e-02, 1.29188660e-01],\n",
       "       [3.58230230e-01, 4.73561560e-01, 1.68208230e-01],\n",
       "       [1.02608770e-01, 1.51816280e-01, 7.45574900e-01],\n",
       "       [8.25879800e-01, 1.62041620e-01, 1.20785050e-02],\n",
       "       [1.15514030e-01, 8.21807200e-01, 6.26787500e-02],\n",
       "       [7.77700640e-03, 5.86735600e-05, 9.92164250e-01],\n",
       "       [4.47331030e-02, 4.24396630e-01, 5.30870300e-01],\n",
       "       [1.95682030e-03, 5.91750000e-01, 4.06293120e-01],\n",
       "       [2.32757630e-02, 6.09868360e-02, 9.15737400e-01],\n",
       "       [1.01423040e-03, 2.94455850e-02, 9.69540200e-01],\n",
       "       [8.81883000e-01, 7.53661250e-02, 4.27509060e-02],\n",
       "       [1.28513430e-03, 9.98707900e-01, 7.07495500e-06],\n",
       "       [4.34801730e-03, 9.95650800e-01, 1.18090280e-06],\n",
       "       [4.62026120e-01, 5.18361600e-01, 1.96122880e-02],\n",
       "       [7.35809100e-01, 1.72644870e-02, 2.46926400e-01],\n",
       "       [4.72287300e-06, 1.23913534e-01, 8.76081760e-01],\n",
       "       [6.92286100e-01, 2.49867080e-01, 5.78468030e-02],\n",
       "       [9.42866600e-01, 4.76027700e-02, 9.53060950e-03],\n",
       "       [4.50603750e-01, 1.85832560e-18, 5.49396300e-01],\n",
       "       [1.58711310e-04, 9.99693900e-01, 1.47410900e-04],\n",
       "       [8.85905900e-01, 1.10846065e-01, 3.24799770e-03],\n",
       "       [9.75705900e-01, 2.22257340e-02, 2.06840480e-03],\n",
       "       [9.42866600e-01, 4.76027700e-02, 9.53060950e-03],\n",
       "       [1.93112000e-02, 6.20277700e-01, 3.60411080e-01],\n",
       "       [5.78438460e-01, 4.36564940e-04, 4.21125050e-01],\n",
       "       [2.17022110e-02, 7.57477800e-01, 2.20819980e-01],\n",
       "       [7.69038100e-01, 4.71329040e-05, 2.30914820e-01],\n",
       "       [1.13516960e-04, 9.99146600e-01, 7.39939800e-04],\n",
       "       [1.66090320e-03, 9.96075000e-01, 2.26408940e-03],\n",
       "       [3.96409260e-02, 9.60353600e-01, 5.54002960e-06],\n",
       "       [8.97708830e-01, 6.12686200e-02, 4.10225300e-02],\n",
       "       [9.12194200e-01, 2.86644250e-03, 8.49393300e-02],\n",
       "       [4.95816950e-02, 5.06992200e-01, 4.43426100e-01],\n",
       "       [1.03781260e-01, 6.14455380e-02, 8.34773200e-01],\n",
       "       [4.13375500e-01, 2.82111050e-01, 3.04513480e-01],\n",
       "       [6.68004040e-01, 2.17268050e-01, 1.14727795e-01],\n",
       "       [1.28335820e-03, 9.97150240e-01, 1.56642830e-03],\n",
       "       [3.67650670e-03, 8.89137000e-19, 9.96323470e-01],\n",
       "       [2.00092840e-03, 2.49862900e-01, 7.48136100e-01],\n",
       "       [9.39815700e-01, 3.92061050e-03, 5.62636300e-02],\n",
       "       [8.09893300e-04, 1.21585420e-18, 9.99190150e-01],\n",
       "       [3.94780670e-01, 8.44543200e-03, 5.96773900e-01],\n",
       "       [2.20149350e-01, 7.52953100e-01, 2.68974840e-02],\n",
       "       [9.09264300e-01, 8.48553850e-02, 5.88031700e-03],\n",
       "       [5.16595040e-03, 1.03996170e-03, 9.93794100e-01],\n",
       "       [1.67044550e-04, 4.30855080e-02, 9.56747500e-01],\n",
       "       [9.03736530e-01, 9.24072860e-02, 3.85618280e-03],\n",
       "       [8.59797900e-01, 2.20349300e-02, 1.18167080e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131295952724525"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131295952724525"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat4['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "236     SR1129     2\n",
       "31       CA105     2\n",
       "155     NRS175     1\n",
       "92       EUH25     2\n",
       "122     NRS070     2\n",
       "..         ...   ...\n",
       "235     SR1065     0\n",
       "24   BCH-SA-09     0\n",
       "104     Grady1     0\n",
       "213     NRS254     2\n",
       "87   CFBRSa66B     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.9811 - accuracy: 0.3503 - val_loss: 1.4700 - val_accuracy: 0.3816\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 1.3690 - accuracy: 0.5085 - val_loss: 1.2163 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 1.0598 - accuracy: 0.5932 - val_loss: 1.0984 - val_accuracy: 0.3158\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 464us/step - loss: 0.9442 - accuracy: 0.6610 - val_loss: 1.2153 - val_accuracy: 0.3158\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.8364 - accuracy: 0.6384 - val_loss: 1.2351 - val_accuracy: 0.3158\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 0.7763 - accuracy: 0.6780 - val_loss: 1.3287 - val_accuracy: 0.3158\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.7467 - accuracy: 0.6723 - val_loss: 1.4333 - val_accuracy: 0.3158\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 438us/step - loss: 0.7066 - accuracy: 0.6893 - val_loss: 1.3704 - val_accuracy: 0.3289\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 487us/step - loss: 0.6837 - accuracy: 0.7062 - val_loss: 1.4515 - val_accuracy: 0.3684\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.6413 - accuracy: 0.7175 - val_loss: 1.5493 - val_accuracy: 0.3421\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 496us/step - loss: 0.6392 - accuracy: 0.7345 - val_loss: 1.4810 - val_accuracy: 0.3553\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.6020 - accuracy: 0.7288 - val_loss: 1.5065 - val_accuracy: 0.3816\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.5795 - accuracy: 0.7345 - val_loss: 1.5395 - val_accuracy: 0.3289\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 459us/step - loss: 0.5587 - accuracy: 0.7627 - val_loss: 1.5405 - val_accuracy: 0.3553\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.5433 - accuracy: 0.7740 - val_loss: 1.5777 - val_accuracy: 0.3553\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.5171 - accuracy: 0.8023 - val_loss: 1.6710 - val_accuracy: 0.3684\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.5083 - accuracy: 0.8023 - val_loss: 1.6910 - val_accuracy: 0.3684\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.4902 - accuracy: 0.8305 - val_loss: 1.7078 - val_accuracy: 0.3816\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.4772 - accuracy: 0.8362 - val_loss: 1.7126 - val_accuracy: 0.3816\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 802us/step - loss: 0.4665 - accuracy: 0.8192 - val_loss: 1.8042 - val_accuracy: 0.3684\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 608us/step - loss: 0.4631 - accuracy: 0.8249 - val_loss: 1.8680 - val_accuracy: 0.3816\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 517us/step - loss: 0.4395 - accuracy: 0.8192 - val_loss: 1.8301 - val_accuracy: 0.3947\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 478us/step - loss: 0.4333 - accuracy: 0.8362 - val_loss: 1.8130 - val_accuracy: 0.3553\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.4255 - accuracy: 0.8418 - val_loss: 1.9516 - val_accuracy: 0.3684\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 490us/step - loss: 0.4171 - accuracy: 0.8418 - val_loss: 1.9200 - val_accuracy: 0.3947\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.3991 - accuracy: 0.8531 - val_loss: 1.8716 - val_accuracy: 0.3816\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 711us/step - loss: 0.3962 - accuracy: 0.8531 - val_loss: 1.9604 - val_accuracy: 0.3816\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 786us/step - loss: 0.3822 - accuracy: 0.8475 - val_loss: 2.0151 - val_accuracy: 0.3947\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.3835 - accuracy: 0.8588 - val_loss: 1.9924 - val_accuracy: 0.3816\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.3722 - accuracy: 0.8588 - val_loss: 2.0064 - val_accuracy: 0.3947\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.3609 - accuracy: 0.8701 - val_loss: 1.9932 - val_accuracy: 0.3816\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 616us/step - loss: 0.3538 - accuracy: 0.8701 - val_loss: 2.0941 - val_accuracy: 0.4079\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 693us/step - loss: 0.3426 - accuracy: 0.8701 - val_loss: 2.0676 - val_accuracy: 0.3816\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.3309 - accuracy: 0.8927 - val_loss: 2.1100 - val_accuracy: 0.3947\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.3439 - accuracy: 0.8701 - val_loss: 2.1399 - val_accuracy: 0.3947\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.3342 - accuracy: 0.8757 - val_loss: 2.1483 - val_accuracy: 0.3816\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 545us/step - loss: 0.3414 - accuracy: 0.8870 - val_loss: 2.0883 - val_accuracy: 0.3816\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 628us/step - loss: 0.3438 - accuracy: 0.8870 - val_loss: 2.2779 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.3162 - accuracy: 0.8927 - val_loss: 2.3449 - val_accuracy: 0.4079\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 591us/step - loss: 0.3013 - accuracy: 0.8927 - val_loss: 2.1517 - val_accuracy: 0.3947\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 604us/step - loss: 0.3046 - accuracy: 0.9040 - val_loss: 2.1787 - val_accuracy: 0.3816\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 728us/step - loss: 0.2992 - accuracy: 0.9040 - val_loss: 2.3278 - val_accuracy: 0.3816\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 429us/step - loss: 0.2790 - accuracy: 0.8983 - val_loss: 2.1971 - val_accuracy: 0.4211\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.2895 - accuracy: 0.8927 - val_loss: 2.5115 - val_accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.2993 - accuracy: 0.9040 - val_loss: 2.5475 - val_accuracy: 0.3947\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.2633 - accuracy: 0.9096 - val_loss: 2.3401 - val_accuracy: 0.4211\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.2826 - accuracy: 0.9266 - val_loss: 2.6640 - val_accuracy: 0.3947\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.2725 - accuracy: 0.9096 - val_loss: 2.6742 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.2443 - accuracy: 0.9096 - val_loss: 2.4966 - val_accuracy: 0.4079\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.2410 - accuracy: 0.9379 - val_loss: 2.4929 - val_accuracy: 0.3947\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.2383 - accuracy: 0.9266 - val_loss: 2.5742 - val_accuracy: 0.4079\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 699us/step - loss: 0.2273 - accuracy: 0.9322 - val_loss: 2.6382 - val_accuracy: 0.3947\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 570us/step - loss: 0.2344 - accuracy: 0.9322 - val_loss: 2.7466 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 701us/step - loss: 0.2237 - accuracy: 0.9379 - val_loss: 2.8069 - val_accuracy: 0.4079\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 423us/step - loss: 0.2161 - accuracy: 0.9379 - val_loss: 2.8097 - val_accuracy: 0.3947\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.2224 - accuracy: 0.9379 - val_loss: 2.7879 - val_accuracy: 0.3947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.2093 - accuracy: 0.9435 - val_loss: 2.7664 - val_accuracy: 0.4342\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.2136 - accuracy: 0.9379 - val_loss: 2.7647 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.2024 - accuracy: 0.9435 - val_loss: 2.8130 - val_accuracy: 0.4079\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 495us/step - loss: 0.2052 - accuracy: 0.9492 - val_loss: 2.8254 - val_accuracy: 0.4079\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.2031 - accuracy: 0.9435 - val_loss: 2.8566 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 423us/step - loss: 0.1932 - accuracy: 0.9548 - val_loss: 2.9362 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.1932 - accuracy: 0.9435 - val_loss: 2.9542 - val_accuracy: 0.4211\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1886 - accuracy: 0.9492 - val_loss: 2.9016 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.1852 - accuracy: 0.9435 - val_loss: 2.9798 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.1918 - accuracy: 0.9605 - val_loss: 3.0160 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.1809 - accuracy: 0.9435 - val_loss: 2.9893 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.1781 - accuracy: 0.9605 - val_loss: 3.0310 - val_accuracy: 0.4211\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.1741 - accuracy: 0.9492 - val_loss: 3.0863 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.1694 - accuracy: 0.9548 - val_loss: 3.0429 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.1782 - accuracy: 0.9548 - val_loss: 3.1034 - val_accuracy: 0.4211\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1619 - accuracy: 0.9548 - val_loss: 3.1533 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.1716 - accuracy: 0.9605 - val_loss: 3.1405 - val_accuracy: 0.4342\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.1636 - accuracy: 0.9492 - val_loss: 3.1535 - val_accuracy: 0.4342\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.1583 - accuracy: 0.9605 - val_loss: 3.2283 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.1518 - accuracy: 0.9605 - val_loss: 3.2398 - val_accuracy: 0.4474\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.1531 - accuracy: 0.9605 - val_loss: 3.2126 - val_accuracy: 0.4211\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.1501 - accuracy: 0.9661 - val_loss: 3.2789 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.1559 - accuracy: 0.9605 - val_loss: 3.3301 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.1360 - accuracy: 0.9661 - val_loss: 3.3543 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.1551 - accuracy: 0.9548 - val_loss: 3.3725 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1408 - accuracy: 0.9548 - val_loss: 3.4106 - val_accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1506 - accuracy: 0.9605 - val_loss: 3.4657 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.1492 - accuracy: 0.9661 - val_loss: 3.4548 - val_accuracy: 0.4474\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 476us/step - loss: 0.1366 - accuracy: 0.9661 - val_loss: 3.4337 - val_accuracy: 0.4342\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 473us/step - loss: 0.1475 - accuracy: 0.9661 - val_loss: 3.4960 - val_accuracy: 0.4342\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.1478 - accuracy: 0.9605 - val_loss: 3.5097 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1308 - accuracy: 0.9605 - val_loss: 3.5527 - val_accuracy: 0.4474\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1301 - accuracy: 0.9661 - val_loss: 3.5354 - val_accuracy: 0.4342\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.1185 - accuracy: 0.9718 - val_loss: 3.5990 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.1221 - accuracy: 0.9718 - val_loss: 3.6963 - val_accuracy: 0.4342\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.1318 - accuracy: 0.9492 - val_loss: 3.6332 - val_accuracy: 0.4474\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.1304 - accuracy: 0.9605 - val_loss: 3.6257 - val_accuracy: 0.4211\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.1290 - accuracy: 0.9605 - val_loss: 3.7286 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.1204 - accuracy: 0.9661 - val_loss: 3.7146 - val_accuracy: 0.4211\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.1138 - accuracy: 0.9605 - val_loss: 3.7129 - val_accuracy: 0.4342\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.1050 - accuracy: 0.9718 - val_loss: 3.7699 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.1073 - accuracy: 0.9605 - val_loss: 3.8586 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.1015 - accuracy: 0.9718 - val_loss: 3.8937 - val_accuracy: 0.4342\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 599us/step - loss: 0.1064 - accuracy: 0.9718 - val_loss: 3.8812 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4171c4a8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 154us/step\n",
      "test accuracy: 46.05%\n"
     ]
    }
   ],
   "source": [
    "acc_test4 = model4.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2,\n",
       "       1, 0, 2, 2, 2, 0, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 1, 0,\n",
       "       1, 2, 0, 1, 1, 2, 2, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2,\n",
       "       0, 2, 2, 2, 2, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model4.predict_classes(X_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "236     SR1129     2     2\n",
       "31       CA105     2     2\n",
       "155     NRS175     1     0\n",
       "92       EUH25     2     1\n",
       "122     NRS070     2     2\n",
       "..         ...   ...   ...\n",
       "235     SR1065     0     0\n",
       "24   BCH-SA-09     0     2\n",
       "104     Grady1     0     1\n",
       "213     NRS254     2     2\n",
       "87   CFBRSa66B     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model4.predict_proba(X_test)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068795</td>\n",
       "      <td>1.512715e-02</td>\n",
       "      <td>0.916077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429596</td>\n",
       "      <td>5.621257e-03</td>\n",
       "      <td>0.564782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997065</td>\n",
       "      <td>2.430247e-03</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012187</td>\n",
       "      <td>9.735159e-01</td>\n",
       "      <td>0.014297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>9.668956e-07</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>6.826960e-06</td>\n",
       "      <td>0.117640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003201</td>\n",
       "      <td>7.025987e-02</td>\n",
       "      <td>0.926539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.143587</td>\n",
       "      <td>7.054675e-01</td>\n",
       "      <td>0.150946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.184970</td>\n",
       "      <td>1.351126e-02</td>\n",
       "      <td>0.801519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.788509</td>\n",
       "      <td>9.878184e-02</td>\n",
       "      <td>0.112709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1         2\n",
       "0   0.068795  1.512715e-02  0.916077\n",
       "1   0.429596  5.621257e-03  0.564782\n",
       "2   0.997065  2.430247e-03  0.000505\n",
       "3   0.012187  9.735159e-01  0.014297\n",
       "4   0.000080  9.668956e-07  0.999919\n",
       "..       ...           ...       ...\n",
       "71  0.882353  6.826960e-06  0.117640\n",
       "72  0.003201  7.025987e-02  0.926539\n",
       "73  0.143587  7.054675e-01  0.150946\n",
       "74  0.184970  1.351126e-02  0.801519\n",
       "75  0.788509  9.878184e-02  0.112709\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.1443 - accuracy: 0.9548 - val_loss: 2.9793 - val_accuracy: 0.4605\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.1452 - accuracy: 0.9661 - val_loss: 3.0322 - val_accuracy: 0.4474\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.1292 - accuracy: 0.9605 - val_loss: 3.0450 - val_accuracy: 0.4474\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.1574 - accuracy: 0.9605 - val_loss: 3.0648 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 423us/step - loss: 0.1310 - accuracy: 0.9661 - val_loss: 3.0622 - val_accuracy: 0.4474\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.1431 - accuracy: 0.9661 - val_loss: 3.0673 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.1247 - accuracy: 0.9548 - val_loss: 3.0991 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1527 - accuracy: 0.9605 - val_loss: 3.1088 - val_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 3.1069 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.1643 - accuracy: 0.9605 - val_loss: 3.0942 - val_accuracy: 0.4474\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1969 - accuracy: 0.9492 - val_loss: 3.0808 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1532 - accuracy: 0.9605 - val_loss: 3.0714 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.1519 - accuracy: 0.9492 - val_loss: 3.1801 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1821 - accuracy: 0.9548 - val_loss: 3.2330 - val_accuracy: 0.4605\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.1623 - accuracy: 0.9718 - val_loss: 3.1908 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.1988 - accuracy: 0.9605 - val_loss: 3.1073 - val_accuracy: 0.4474\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.1761 - accuracy: 0.9661 - val_loss: 3.2809 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.1333 - accuracy: 0.9548 - val_loss: 3.3406 - val_accuracy: 0.4474\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.1520 - accuracy: 0.9548 - val_loss: 3.2408 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1444 - accuracy: 0.9661 - val_loss: 3.2808 - val_accuracy: 0.4474\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.1087 - accuracy: 0.9774 - val_loss: 3.1711 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1099 - accuracy: 0.9605 - val_loss: 3.1701 - val_accuracy: 0.4474\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.1219 - accuracy: 0.9661 - val_loss: 3.3489 - val_accuracy: 0.4605\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.0990 - accuracy: 0.9718 - val_loss: 3.4320 - val_accuracy: 0.4605\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1148 - accuracy: 0.9718 - val_loss: 3.4174 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.0993 - accuracy: 0.9661 - val_loss: 3.4080 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.1561 - accuracy: 0.9548 - val_loss: 3.3632 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.1135 - accuracy: 0.9774 - val_loss: 3.3304 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 437us/step - loss: 0.0955 - accuracy: 0.9718 - val_loss: 3.3429 - val_accuracy: 0.4474\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.1362 - accuracy: 0.9718 - val_loss: 3.3543 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1154 - accuracy: 0.9774 - val_loss: 3.4505 - val_accuracy: 0.4868\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.1112 - accuracy: 0.9774 - val_loss: 3.4792 - val_accuracy: 0.4868\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.1055 - accuracy: 0.9718 - val_loss: 3.4611 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.1225 - accuracy: 0.9718 - val_loss: 3.4588 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.1127 - accuracy: 0.9661 - val_loss: 3.4911 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.1398 - accuracy: 0.9661 - val_loss: 3.4615 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.1136 - accuracy: 0.9718 - val_loss: 3.5012 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.0984 - accuracy: 0.9718 - val_loss: 3.4599 - val_accuracy: 0.4737\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0923 - accuracy: 0.9718 - val_loss: 3.4745 - val_accuracy: 0.4737\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1114 - accuracy: 0.9661 - val_loss: 3.4616 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.0892 - accuracy: 0.9718 - val_loss: 3.4486 - val_accuracy: 0.4605\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.0853 - accuracy: 0.9774 - val_loss: 3.5212 - val_accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.0842 - accuracy: 0.9718 - val_loss: 3.6013 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1074 - accuracy: 0.9718 - val_loss: 3.6272 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0937 - accuracy: 0.9774 - val_loss: 3.6654 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.0781 - accuracy: 0.9774 - val_loss: 3.6432 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.1184 - accuracy: 0.9774 - val_loss: 3.6751 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.1040 - accuracy: 0.9774 - val_loss: 3.7276 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.1259 - accuracy: 0.9774 - val_loss: 3.7047 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 615us/step - loss: 0.1100 - accuracy: 0.9774 - val_loss: 3.6642 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 498us/step - loss: 0.1259 - accuracy: 0.9774 - val_loss: 3.6753 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.0896 - accuracy: 0.9831 - val_loss: 3.7097 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0714 - accuracy: 0.9831 - val_loss: 3.6830 - val_accuracy: 0.4605\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.1501 - accuracy: 0.9774 - val_loss: 3.6643 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1127 - accuracy: 0.9831 - val_loss: 3.7120 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.0880 - accuracy: 0.9718 - val_loss: 3.8513 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.1518 - accuracy: 0.9718 - val_loss: 3.7180 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1418 - accuracy: 0.9831 - val_loss: 3.6369 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.1160 - accuracy: 0.9718 - val_loss: 3.6127 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.0866 - accuracy: 0.9831 - val_loss: 3.6564 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.0974 - accuracy: 0.9774 - val_loss: 3.7425 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1017 - accuracy: 0.9774 - val_loss: 3.7597 - val_accuracy: 0.4605\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 3.7988 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1033 - accuracy: 0.9661 - val_loss: 3.8134 - val_accuracy: 0.4737\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.0858 - accuracy: 0.9831 - val_loss: 3.7416 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.0692 - accuracy: 0.9887 - val_loss: 3.7419 - val_accuracy: 0.4737\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.0648 - accuracy: 0.9887 - val_loss: 3.7524 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.0753 - accuracy: 0.9831 - val_loss: 3.7794 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.0683 - accuracy: 0.9831 - val_loss: 3.7859 - val_accuracy: 0.4737\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.0882 - accuracy: 0.9887 - val_loss: 3.7847 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.0866 - accuracy: 0.9774 - val_loss: 3.8224 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 3.8212 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0792 - accuracy: 0.9774 - val_loss: 3.8651 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 617us/step - loss: 0.0602 - accuracy: 0.9887 - val_loss: 3.8372 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.0688 - accuracy: 0.9887 - val_loss: 3.8805 - val_accuracy: 0.4605\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 3.9072 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 603us/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 3.8816 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.0577 - accuracy: 0.9887 - val_loss: 3.8791 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 587us/step - loss: 0.0529 - accuracy: 0.9944 - val_loss: 3.8845 - val_accuracy: 0.4737\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 457us/step - loss: 0.0675 - accuracy: 0.9887 - val_loss: 3.8969 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.0516 - accuracy: 0.9831 - val_loss: 3.9611 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 509us/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 3.9371 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 902us/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 3.9663 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 687us/step - loss: 0.0566 - accuracy: 0.9887 - val_loss: 3.9734 - val_accuracy: 0.4737\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.0636 - accuracy: 0.9887 - val_loss: 3.9968 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.0799 - accuracy: 0.9831 - val_loss: 3.9533 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 628us/step - loss: 0.0621 - accuracy: 0.9831 - val_loss: 4.0078 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0765 - accuracy: 0.9887 - val_loss: 4.0450 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9887 - val_loss: 3.9808 - val_accuracy: 0.4737\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 407us/step - loss: 0.0817 - accuracy: 0.9887 - val_loss: 3.9974 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.0763 - accuracy: 0.9887 - val_loss: 4.0329 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 822us/step - loss: 0.0471 - accuracy: 0.9887 - val_loss: 4.1065 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.0885 - accuracy: 0.9774 - val_loss: 4.1165 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.0520 - accuracy: 0.9887 - val_loss: 4.0465 - val_accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.0901 - accuracy: 0.9887 - val_loss: 4.0113 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.0740 - accuracy: 0.9831 - val_loss: 4.1032 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.0720 - accuracy: 0.9718 - val_loss: 4.1111 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 415us/step - loss: 0.0606 - accuracy: 0.9887 - val_loss: 4.0825 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.0602 - accuracy: 0.9831 - val_loss: 4.1154 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0552 - accuracy: 0.9774 - val_loss: 4.1729 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist4 = model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.821690e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.652370e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>9.972990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198157e-02</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>5.232074e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.388957e-01</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>1.251503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231966e-03</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>1.824512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.957360e-02</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>5.846961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.196635e-03</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>5.517461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.319404e-02</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>9.278219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.902312e-03</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>3.146706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.566210e-04</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>9.439281e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage  strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  SR1129          2           2  4.821690e-07   \n",
       "1       p0017kpresabs_qual   CA105          2           2  2.652370e-03   \n",
       "2       p0017kpresabs_qual  NRS175          1           1  1.198157e-02   \n",
       "3       p0017kpresabs_qual   EUH25          2           1  1.388957e-01   \n",
       "4       p0017kpresabs_qual  NRS070          2           1  7.231966e-03   \n",
       "..                     ...     ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  NRS247          1           2  2.957360e-02   \n",
       "604  p0040presabsSTCC_qual  NRS215          1           2  3.196635e-03   \n",
       "605  p0040presabsSTCC_qual  SR4152          2           2  4.319404e-02   \n",
       "606  p0040presabsSTCC_qual  NRS035          1           1  4.902312e-03   \n",
       "607  p0040presabsSTCC_qual  SR4187          2           2  2.566210e-04   \n",
       "\n",
       "            1             2  \n",
       "0    0.000001  9.999983e-01  \n",
       "1    0.000049  9.972990e-01  \n",
       "2    0.988018  5.232074e-09  \n",
       "3    0.735954  1.251503e-01  \n",
       "4    0.810317  1.824512e-01  \n",
       "..        ...           ...  \n",
       "603  0.385730  5.846961e-01  \n",
       "604  0.445057  5.517461e-01  \n",
       "605  0.028984  9.278219e-01  \n",
       "606  0.680427  3.146706e-01  \n",
       "607  0.055815  9.439281e-01  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.87952700e-02, 1.51271460e-02, 9.16077500e-01],\n",
       "       [4.29596280e-01, 5.62125700e-03, 5.64782400e-01],\n",
       "       [9.97065250e-01, 2.43024700e-03, 5.04550500e-04],\n",
       "       [1.21871010e-02, 9.73515870e-01, 1.42970560e-02],\n",
       "       [8.00028940e-05, 9.66895600e-07, 9.99919060e-01],\n",
       "       [1.72127130e-03, 4.25128080e-02, 9.55765900e-01],\n",
       "       [2.76227180e-02, 6.81554730e-01, 2.90822480e-01],\n",
       "       [9.99314200e-01, 9.53211600e-06, 6.76300300e-04],\n",
       "       [9.56757000e-02, 7.27630560e-01, 1.76693810e-01],\n",
       "       [3.57633980e-05, 9.99866370e-01, 9.79043250e-05],\n",
       "       [8.71361200e-02, 9.07507800e-01, 5.35616230e-03],\n",
       "       [1.07976770e-03, 9.98903400e-01, 1.67966700e-05],\n",
       "       [7.08725440e-03, 9.66506540e-01, 2.64062920e-02],\n",
       "       [5.15638700e-03, 9.92063600e-01, 2.78006560e-03],\n",
       "       [8.25230800e-03, 9.91696060e-01, 5.17170050e-05],\n",
       "       [1.64736140e-01, 7.69136400e-01, 6.61274600e-02],\n",
       "       [1.19596970e-05, 9.99983800e-01, 4.24389800e-06],\n",
       "       [8.05527700e-01, 9.77264800e-05, 1.94374580e-01],\n",
       "       [1.14634890e-01, 3.01287230e-03, 8.82352300e-01],\n",
       "       [2.65393630e-02, 9.72719430e-01, 7.41196700e-04],\n",
       "       [2.70388480e-01, 6.70255000e-01, 5.93564730e-02],\n",
       "       [1.49526660e-04, 1.16407490e-12, 9.99850400e-01],\n",
       "       [7.73059800e-03, 6.22857800e-01, 3.69411560e-01],\n",
       "       [8.34533750e-01, 9.79160740e-02, 6.75501400e-02],\n",
       "       [7.11224100e-05, 9.55759500e-13, 9.99928830e-01],\n",
       "       [8.58406350e-05, 1.70739580e-01, 8.29174640e-01],\n",
       "       [1.91663240e-08, 3.01111420e-15, 1.00000000e+00],\n",
       "       [9.99633900e-01, 1.92233950e-05, 3.46875020e-04],\n",
       "       [5.34068000e-04, 1.14827960e-01, 8.84638000e-01],\n",
       "       [2.05605550e-01, 5.13260630e-02, 7.43068460e-01],\n",
       "       [4.57945100e-01, 5.32005400e-01, 1.00495170e-02],\n",
       "       [5.26446300e-04, 6.70650900e-02, 9.32408400e-01],\n",
       "       [9.87159300e-03, 9.85426300e-01, 4.70204650e-03],\n",
       "       [6.75998100e-01, 3.23163930e-01, 8.37923300e-04],\n",
       "       [1.58983230e-08, 2.86016970e-14, 1.00000000e+00],\n",
       "       [6.65005500e-02, 9.32258550e-01, 1.24090770e-03],\n",
       "       [4.25606970e-03, 9.93460300e-01, 2.28360340e-03],\n",
       "       [1.40766170e-01, 7.90671800e-01, 6.85620300e-02],\n",
       "       [8.09069800e-01, 1.59762600e-01, 3.11675970e-02],\n",
       "       [9.91044760e-01, 3.86581380e-04, 8.56868700e-03],\n",
       "       [7.56157700e-02, 1.60670010e-03, 9.22777530e-01],\n",
       "       [7.59210770e-01, 1.85301540e-01, 5.54876770e-02],\n",
       "       [5.38680350e-04, 7.18147040e-01, 2.81314300e-01],\n",
       "       [9.98462900e-01, 4.62203500e-04, 1.07491520e-03],\n",
       "       [8.59469760e-04, 9.92781700e-01, 6.35883350e-03],\n",
       "       [5.64244900e-05, 5.51584200e-13, 9.99943600e-01],\n",
       "       [9.97057800e-01, 1.61326140e-03, 1.32898110e-03],\n",
       "       [1.03899610e-06, 9.99998450e-01, 4.46417700e-07],\n",
       "       [1.36625610e-02, 9.83878500e-01, 2.45892440e-03],\n",
       "       [8.20687100e-06, 3.74517100e-07, 9.99991400e-01],\n",
       "       [6.16817100e-08, 4.75499400e-13, 9.99999900e-01],\n",
       "       [5.42907900e-04, 3.19657360e-01, 6.79799700e-01],\n",
       "       [6.10663100e-01, 3.58540860e-01, 3.07960720e-02],\n",
       "       [2.21233920e-01, 2.94432760e-01, 4.84333280e-01],\n",
       "       [6.19494860e-01, 3.64053700e-05, 3.80468700e-01],\n",
       "       [3.97273340e-03, 9.96024700e-01, 2.50132030e-06],\n",
       "       [9.99989600e-01, 4.27057570e-08, 1.03430730e-05],\n",
       "       [7.74107100e-06, 1.81036360e-04, 9.99811230e-01],\n",
       "       [1.85595030e-03, 9.90888600e-01, 7.25547130e-03],\n",
       "       [6.11110000e-01, 1.79419410e-01, 2.09470670e-01],\n",
       "       [8.97347300e-01, 5.24350400e-02, 5.02176360e-02],\n",
       "       [3.72474900e-01, 1.91932240e-04, 6.27333100e-01],\n",
       "       [9.34911550e-01, 3.36908800e-05, 6.50548100e-02],\n",
       "       [9.79312200e-01, 5.69685600e-06, 2.06820370e-02],\n",
       "       [1.05407585e-10, 1.09102820e-14, 1.00000000e+00],\n",
       "       [1.00808640e-04, 3.44888780e-01, 6.55010460e-01],\n",
       "       [5.53463400e-01, 1.67297300e-01, 2.79239300e-01],\n",
       "       [1.71049100e-02, 5.60559400e-05, 9.82839050e-01],\n",
       "       [1.57926640e-05, 3.58951000e-13, 9.99984260e-01],\n",
       "       [5.57072340e-04, 7.50888360e-05, 9.99367900e-01],\n",
       "       [3.30192630e-02, 2.46514130e-04, 9.66734230e-01],\n",
       "       [8.82353250e-01, 6.82696000e-06, 1.17639914e-01],\n",
       "       [3.20118710e-03, 7.02598700e-02, 9.26539000e-01],\n",
       "       [1.43586750e-01, 7.05467460e-01, 1.50945720e-01],\n",
       "       [1.84969900e-01, 1.35112620e-02, 8.01518860e-01],\n",
       "       [7.88509200e-01, 9.87818400e-02, 1.12709010e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5742172289791337"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5742172289791337"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6078801049039144"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029610291404617534"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6078801049039144"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029610291404617534"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test1, acc_test2, acc_test3, acc_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean: 47.37%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation: 0.020804459034607384\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1.history['accuracy']), np.mean(hist2.history['accuracy']), np.mean(hist3.history['accuracy']),\n",
    "             np.mean(hist4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean: 96.21%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation: 0.017170282\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X.loc[:, X.columns != 'id'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X.loc[:, X.columns != 'id']))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 7157\n",
      "selected features: 511\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,   11,   38,   39,   40,   55,   58,   64,  107,  109,  130,\n",
       "         147,  149,  182,  187,  222,  225,  227,  235,  267,  270,  273,\n",
       "         297,  310,  313,  323,  345,  347,  362,  366,  374,  391,  422,\n",
       "         448,  459,  498,  519,  527,  533,  535,  537,  540,  541,  546,\n",
       "         551,  590,  601,  626,  632,  637,  639,  690,  742,  745,  749,\n",
       "         760,  761,  762,  785,  805,  846,  850,  881,  899,  922,  953,\n",
       "         975,  982,  983,  997, 1031, 1047, 1064, 1066, 1088, 1092, 1109,\n",
       "        1135, 1162, 1181, 1184, 1193, 1201, 1202, 1208, 1221, 1253, 1255,\n",
       "        1274, 1278, 1281, 1283, 1287, 1288, 1308, 1321, 1322, 1328, 1400,\n",
       "        1403, 1414, 1427, 1442, 1461, 1481, 1484, 1493, 1501, 1508, 1518,\n",
       "        1519, 1547, 1559, 1572, 1598, 1600, 1618, 1619, 1649, 1653, 1654,\n",
       "        1700, 1734, 1738, 1739, 1746, 1768, 1771, 1801, 1803, 1815, 1830,\n",
       "        1851, 1859, 1885, 1898, 1902, 1906, 1921, 1946, 1995, 2014, 2026,\n",
       "        2059, 2088, 2098, 2130, 2131, 2138, 2163, 2165, 2171, 2193, 2215,\n",
       "        2218, 2244, 2249, 2258, 2278, 2279, 2281, 2286, 2295, 2303, 2311,\n",
       "        2337, 2348, 2350, 2371, 2372, 2378, 2393, 2418, 2451, 2461, 2479,\n",
       "        2480, 2481, 2488, 2492, 2555, 2558, 2563, 2564, 2572, 2579, 2612,\n",
       "        2622, 2625, 2627, 2709, 2732, 2734, 2738, 2740, 2746, 2754, 2758,\n",
       "        2775, 2785, 2794, 2805, 2825, 2851, 2889, 2896, 2898, 2934, 2942,\n",
       "        2948, 2955, 2962, 2968, 2985, 2994, 3004, 3010, 3022, 3041, 3053,\n",
       "        3072, 3083, 3114, 3131, 3150, 3157, 3184, 3185, 3188, 3209, 3217,\n",
       "        3221, 3230, 3237, 3266, 3273, 3311, 3372, 3398, 3401, 3409, 3425,\n",
       "        3426, 3443, 3482, 3513, 3515, 3516, 3573, 3576, 3580, 3582, 3610,\n",
       "        3629, 3650, 3652, 3658, 3685, 3704, 3713, 3725, 3769, 3776, 3828,\n",
       "        3861, 3872, 3881, 3929, 3940, 3946, 3963, 3964, 3971, 3987, 4029,\n",
       "        4031, 4036, 4048, 4049, 4051, 4096, 4099, 4115, 4150, 4151, 4157,\n",
       "        4169, 4194, 4195, 4208, 4218, 4236, 4239, 4290, 4297, 4300, 4307,\n",
       "        4333, 4379, 4390, 4400, 4403, 4438, 4443, 4446, 4481, 4495, 4501,\n",
       "        4543, 4547, 4577, 4580, 4596, 4601, 4610, 4631, 4634, 4681, 4682,\n",
       "        4694, 4701, 4711, 4753, 4754, 4759, 4760, 4763, 4787, 4790, 4842,\n",
       "        4847, 4848, 4859, 4884, 4918, 4930, 4950, 4965, 4978, 4980, 5020,\n",
       "        5024, 5026, 5039, 5061, 5063, 5076, 5078, 5085, 5086, 5088, 5093,\n",
       "        5132, 5157, 5207, 5231, 5233, 5236, 5279, 5290, 5302, 5304, 5320,\n",
       "        5339, 5341, 5343, 5351, 5352, 5356, 5359, 5396, 5397, 5401, 5406,\n",
       "        5421, 5440, 5448, 5459, 5460, 5470, 5493, 5553, 5556, 5579, 5603,\n",
       "        5623, 5625, 5650, 5654, 5655, 5670, 5673, 5682, 5691, 5712, 5742,\n",
       "        5756, 5760, 5782, 5833, 5855, 5859, 5875, 5884, 5897, 5918, 6025,\n",
       "        6035, 6039, 6049, 6050, 6065, 6066, 6078, 6124, 6128, 6134, 6142,\n",
       "        6168, 6201, 6208, 6213, 6214, 6241, 6256, 6275, 6285, 6286, 6313,\n",
       "        6332, 6333, 6360, 6370, 6408, 6410, 6421, 6458, 6487, 6488, 6534,\n",
       "        6536, 6550, 6559, 6591, 6596, 6597, 6655, 6660, 6676, 6686, 6690,\n",
       "        6748, 6751, 6780, 6798, 6803, 6805, 6807, 6808, 6834, 6840, 6852,\n",
       "        6854, 6877, 6900, 6989, 7017, 7022, 7040, 7078, 7079, 7080, 7084,\n",
       "        7085, 7086, 7087, 7088, 7089, 7091, 7092, 7097, 7099, 7100, 7103,\n",
       "        7106, 7108, 7111, 7116, 7117, 7119, 7120, 7122, 7125, 7128, 7129,\n",
       "        7130, 7131, 7132, 7133, 7134, 7135, 7136, 7137, 7138, 7139, 7140,\n",
       "        7142, 7143, 7144, 7155, 7156]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA',\n",
       "       'TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT',\n",
       "       'TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG',\n",
       "       'TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA',\n",
       "       'TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA',\n",
       "       'TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC',\n",
       "       'TTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAA',\n",
       "       'TTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTA',\n",
       "       'TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA',\n",
       "       'TTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAAT',\n",
       "       'TTTTGTTGGAGTA',\n",
       "       'TTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTT',\n",
       "       'TTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCT',\n",
       "       'TTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAA',\n",
       "       'TTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATA',\n",
       "       'TTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAAT',\n",
       "       'TTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTA',\n",
       "       'TTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGG',\n",
       "       'TTTTATTGTATAAT',\n",
       "       'TTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGAT',\n",
       "       'TTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATA',\n",
       "       'TTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAG',\n",
       "       'TTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAA',\n",
       "       'TTTTAAACAATTAA',\n",
       "       'TTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAAC',\n",
       "       'TTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACC',\n",
       "       'TTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTT',\n",
       "       'TTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTC',\n",
       "       'TTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGAC',\n",
       "       'TTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATT',\n",
       "       'TTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAAC',\n",
       "       'TTTGATAATTTCATT',\n",
       "       'TTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAA',\n",
       "       'TTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCT',\n",
       "       'TTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAAT',\n",
       "       'TTTCCATTTATTTC',\n",
       "       'TTTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTT',\n",
       "       'TTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATC',\n",
       "       'TTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTAT',\n",
       "       'TTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCAT',\n",
       "       'TTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGA',\n",
       "       'TTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTA',\n",
       "       'TTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTG',\n",
       "       'TTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGA',\n",
       "       'TTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCA',\n",
       "       'TTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATG',\n",
       "       'TTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGG',\n",
       "       'TTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATG',\n",
       "       'TTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAA',\n",
       "       'TTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGT',\n",
       "       'TTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCG',\n",
       "       'TTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAAT',\n",
       "       'TTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATT',\n",
       "       'TTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCA',\n",
       "       'TTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAATGTT',\n",
       "       'TTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAG',\n",
       "       'TTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCA',\n",
       "       'TTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACA',\n",
       "       'TTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCT',\n",
       "       'TTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAGCA',\n",
       "       'TTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTC',\n",
       "       'TTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCG',\n",
       "       'TTGGAGTAATT',\n",
       "       'TTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGACA',\n",
       "       'TTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACA',\n",
       "       'TTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAG',\n",
       "       'TTGATAGTAAAGG', 'TTGATAACGCTGC', 'TTGATAACGCTGCA',\n",
       "       'TTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATG',\n",
       "       'TTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGT',\n",
       "       'TTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAAC',\n",
       "       'TTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTT',\n",
       "       'TTCTTGATTTTTAA',\n",
       "       'TTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATG',\n",
       "       'TTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTG',\n",
       "       'TTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATT',\n",
       "       'TTCGGGCTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'TTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATA',\n",
       "       'TTCCATTTATTTC',\n",
       "       'TTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTC',\n",
       "       'TTCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATG',\n",
       "       'TTCATTTTACTATT',\n",
       "       'TTCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCAT',\n",
       "       'TTCATTGATGTAT',\n",
       "       'TTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTT',\n",
       "       'TTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCA',\n",
       "       'TTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCA',\n",
       "       'TTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATT',\n",
       "       'TTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGA',\n",
       "       'TTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCATA',\n",
       "       'TTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGAT',\n",
       "       'TTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAG',\n",
       "       'TTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGA',\n",
       "       'TTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAG',\n",
       "       'TTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCAT',\n",
       "       'TTATTTTATTACTA', 'TTATTTGCGACT',\n",
       "       'TTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGC',\n",
       "       'TTATCGAGTAATT', 'TTATCAATAGGT',\n",
       "       'TTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGA',\n",
       "       'TTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTC',\n",
       "       'TTATAAGGTGCT', 'TTAGTTCTGTA',\n",
       "       'TTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGA',\n",
       "       'TTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACA',\n",
       "       'TTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAAC',\n",
       "       'TTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTG',\n",
       "       'TTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGA',\n",
       "       'TTAGCAGTCGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'TTACTTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAAT',\n",
       "       'TTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAAT',\n",
       "       'TTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTT',\n",
       "       'TTACATTCTTCGTC', 'TTACATTATGCA',\n",
       "       'TTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAG',\n",
       "       'TTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAATG',\n",
       "       'TTAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTC',\n",
       "       'TTAATCTCCGC', 'TTAATCTCCGCTT',\n",
       "       'TTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCA',\n",
       "       'TTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTT',\n",
       "       'TTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCAC',\n",
       "       'TTAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACA',\n",
       "       'TTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAAC',\n",
       "       'TTAAACCAATTATG',\n",
       "       'TTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAATGTTG',\n",
       "       'TGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGT',\n",
       "       'TGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACAT',\n",
       "       'TGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTA',\n",
       "       'TGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAG',\n",
       "       'TGTTCCCTCCTC',\n",
       "       'TGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTA',\n",
       "       'TGTTAAAACAAGATGCGAATGATATTGGCTTTGCTAAATTACTACAAAATGAGAATAATCGTATGAGTTATAACGAGTTAATGA',\n",
       "       'TGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACT',\n",
       "       'TGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTT',\n",
       "       'TGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATC',\n",
       "       'TGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCAT',\n",
       "       'TGTATTGCTCCT', 'TGTAATAGACGACC',\n",
       "       'TGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCT',\n",
       "       'TGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGG',\n",
       "       'TGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGT',\n",
       "       'TGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGA',\n",
       "       'TGGATTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCA',\n",
       "       'TGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAG',\n",
       "       'TGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTG',\n",
       "       'TGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGT',\n",
       "       'TGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTAT',\n",
       "       'TGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATA',\n",
       "       'TGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTT',\n",
       "       'TGCCGAGGCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCAC',\n",
       "       'TGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCAC',\n",
       "       'TGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGA',\n",
       "       'TGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCAC',\n",
       "       'TGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGT',\n",
       "       'TGATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACT',\n",
       "       'TGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTAT',\n",
       "       'TGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGT',\n",
       "       'TGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGACAACAT',\n",
       "       'TGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAG',\n",
       "       'TGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGAT',\n",
       "       'TGATAAGTTTAG',\n",
       "       'TGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATT',\n",
       "       'TGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGG',\n",
       "       'TGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACAT',\n",
       "       'TGACCGTGTCT',\n",
       "       'TGAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTA',\n",
       "       'TGAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGA',\n",
       "       'TGAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAG',\n",
       "       'TGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATGAAC',\n",
       "       'TGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTG',\n",
       "       'TGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAGT',\n",
       "       'TCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAACT',\n",
       "       'TCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAG',\n",
       "       'TCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCAT',\n",
       "       'TCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTC',\n",
       "       'TCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAG',\n",
       "       'TCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTT',\n",
       "       'TCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTT',\n",
       "       'TCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGC',\n",
       "       'TCTCCTCTGA',\n",
       "       'TCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGG',\n",
       "       'TCTATTATACAT',\n",
       "       'TCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTG',\n",
       "       'TCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTA',\n",
       "       'TCTAAACGAAAAT', 'TCTAAACATTCT', 'TCTAAAAGAAC', 'TCGAGTTAATGA',\n",
       "       'TCCTGTACTTT', 'TCCTGTACTTTTATTT', 'TCCTGGCAATTG',\n",
       "       'TCCTGCCGAGGCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAG',\n",
       "       'TCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATAT',\n",
       "       'TCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAGCAAAT',\n",
       "       'TCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGAT',\n",
       "       'TCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTC',\n",
       "       'TCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAG',\n",
       "       'TCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGG',\n",
       "       'TCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATT',\n",
       "       'TCATTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTA',\n",
       "       'TCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTC',\n",
       "       'TCAGCAACATTTAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGT',\n",
       "       'TCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCAT',\n",
       "       'TCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCAC',\n",
       "       'TCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTT',\n",
       "       'TCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATTCATAC',\n",
       "       'TCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATT',\n",
       "       'TCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAGT',\n",
       "       'TCAACTTAGTTA',\n",
       "       'TCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTAC',\n",
       "       'TCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGT',\n",
       "       'TCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGG',\n",
       "       'TATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAG',\n",
       "       'TATTTTGTCACT',\n",
       "       'TATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATT',\n",
       "       'TATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTT',\n",
       "       'TATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTA',\n",
       "       'TATTGCTCCTTTT', 'TATTGAACTTGGCG',\n",
       "       'TATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGC',\n",
       "       'TATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCAT',\n",
       "       'TATGTTATAATTAAT',\n",
       "       'TATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATA',\n",
       "       'TATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTT',\n",
       "       'TATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCT',\n",
       "       'TATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGAC',\n",
       "       'TATCTGAGTCTCT',\n",
       "       'TATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATG',\n",
       "       'TATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCT',\n",
       "       'TATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGG',\n",
       "       'TATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACT',\n",
       "       'TATATTAAAGCGCCACATAG',\n",
       "       'TATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAG',\n",
       "       'TATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCG',\n",
       "       'TATAAATATATATC',\n",
       "       'TAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACG',\n",
       "       'TAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGAT',\n",
       "       'TAGTGTTCTTTTA', 'TAGTCTTGTG', 'TAGTCTTGTGATT',\n",
       "       'TAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACAC',\n",
       "       'TAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGC',\n",
       "       'TAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGAT',\n",
       "       'TAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCAT',\n",
       "       'TAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCT',\n",
       "       'TAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGAT',\n",
       "       'TAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACC',\n",
       "       'TACTTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATC',\n",
       "       'TACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCATT',\n",
       "       'TACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATC',\n",
       "       'TACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTG',\n",
       "       'TACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTT',\n",
       "       'TACCTCCTTTTTTT',\n",
       "       'TACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATC',\n",
       "       'TACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTA',\n",
       "       'TACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTG',\n",
       "       'TACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGC',\n",
       "       'TAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAAT',\n",
       "       'TAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCT',\n",
       "       'TAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATG',\n",
       "       'TAATAATTACTC',\n",
       "       'TAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATT',\n",
       "       'TAAGCGGTTTTG',\n",
       "       'TAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCAT',\n",
       "       'TAACATCTTCATT',\n",
       "       'TAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGAGAAGC',\n",
       "       'TAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTT',\n",
       "       'TAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACT',\n",
       "       'TAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACAT',\n",
       "       'TAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATT',\n",
       "       'TAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACG',\n",
       "       'TAAACCAATTATG',\n",
       "       'TAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAATGTTGC',\n",
       "       'TAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTT',\n",
       "       'TAAAATCGGAAATG', 'TAAAATCGAATG',\n",
       "       'TAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATAC',\n",
       "       'GTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTC',\n",
       "       'GTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATT',\n",
       "       'GTTTTATTATCTC',\n",
       "       'GTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGC',\n",
       "       'GTTGTTTAACC',\n",
       "       'GTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAGC',\n",
       "       'GTTGCGCCACT',\n",
       "       'GTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATAT',\n",
       "       'GTTCCCTCTTT', 'GTTATGATTTATTT', 'GTTATAATTAATT', 'GTTAATTTTTTGT',\n",
       "       'GTTAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCT',\n",
       "       'GTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAG',\n",
       "       'GTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATT',\n",
       "       'GTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTG',\n",
       "       'GTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATCC',\n",
       "       'GTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAG',\n",
       "       'GTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAG',\n",
       "       'GTATTTTTTGTG',\n",
       "       'GTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCT',\n",
       "       'GTATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGT',\n",
       "       'GTATATAAATATATAT', 'GTATACTTCTTTT',\n",
       "       'GTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTAT',\n",
       "       'GTACGATTTTAT', 'GTAATTCATAATC',\n",
       "       'GTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAAT',\n",
       "       'GGTTTTTATAAATTGG', 'GGTTTTCGATTG',\n",
       "       'GGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGC',\n",
       "       'GGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATC',\n",
       "       'GGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATC',\n",
       "       'GGTATGAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTG',\n",
       "       'GGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTG',\n",
       "       'GGGTCAAAAAAATCAAAAGCGATCAAAATACTTGGGGAACGGGGAGGGGCTCGACTTCGCGATAATTTTAAAAATCCATGTATAACCCCCC',\n",
       "       'GGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTT',\n",
       "       'GGCATCTATTT',\n",
       "       'GGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGTAGAG',\n",
       "       'GGATTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCG',\n",
       "       'GGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGT',\n",
       "       'GGAGTAATTATT',\n",
       "       'GGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCATTAACT',\n",
       "       'GGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAG',\n",
       "       'GCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGG',\n",
       "       'GCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTGC',\n",
       "       'GCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAG',\n",
       "       'GCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTT',\n",
       "       'GCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'GCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATG',\n",
       "       'GCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAAT',\n",
       "       'GCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATAT',\n",
       "       'GCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTC',\n",
       "       'GCGAAGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTAT',\n",
       "       'GCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTTGG',\n",
       "       'GCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAAT',\n",
       "       'GCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATCCAG',\n",
       "       'GCAGTTAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTT',\n",
       "       'GCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAG',\n",
       "       'GCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTT',\n",
       "       'GATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATT',\n",
       "       'GATTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGG',\n",
       "       'GATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGG',\n",
       "       'GATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTG',\n",
       "       'GATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATT',\n",
       "       'GATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTC',\n",
       "       'GATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAAT',\n",
       "       'GATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAAT',\n",
       "       'GATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATC',\n",
       "       'GATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTC',\n",
       "       'GATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGACAACATT',\n",
       "       'GATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGG',\n",
       "       'GAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTT',\n",
       "       'GAGAATAGATGTT',\n",
       "       'GACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTT',\n",
       "       'GAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGAT',\n",
       "       'GAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATT',\n",
       "       'GAATGGCATAACAATCAATTCTTATGGCGGTGTAGTCGCTTTAACATCTGACTACAATCGAATTATTATCGATTCATATGCTTCAGCTAATATTGAAAGT',\n",
       "       'GAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAAT',\n",
       "       'GAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGT',\n",
       "       'GAACAAGTTTTT', 'GAAATTTTTGTATAAT',\n",
       "       'GAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTG',\n",
       "       'GAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCATTAACTG',\n",
       "       'GAAAATAAAAAATTG',\n",
       "       'GAAAAGCGAAGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGT',\n",
       "       'GAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAGTT',\n",
       "       'CTTTTTTTCTTATT',\n",
       "       'CTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTGCT',\n",
       "       'CTTTTTTAATTGTT',\n",
       "       'CTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGT',\n",
       "       'CTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATT',\n",
       "       'CTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTAT',\n",
       "       'CTTTATAAATTTCGT',\n",
       "       'CTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTT',\n",
       "       'CTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGG',\n",
       "       'CTTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTAT',\n",
       "       'CTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCT',\n",
       "       'CTTCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAAT',\n",
       "       'CTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTG',\n",
       "       'CTTAATCGTTTT',\n",
       "       'CTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTT',\n",
       "       'CTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTT',\n",
       "       'CTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGT',\n",
       "       'CTATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACG',\n",
       "       'CTATAACACTTT',\n",
       "       'CTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'CTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTTATGCCAT',\n",
       "       'CTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATAAAT',\n",
       "       'CTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTT',\n",
       "       'CTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTAT',\n",
       "       'CTAAGAATTAAAAT',\n",
       "       'CTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGT',\n",
       "       'CTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATT',\n",
       "       'CGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTG',\n",
       "       'CGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAAT',\n",
       "       'CGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCG',\n",
       "       'CGCTTCTCTACTTTCAATATTAGCTGAAGCATATGAATCGATAATAATTCGATTGTAGTCAGATGTTAAAGCGACTACACCGCCATAAGAATTGATTGTT',\n",
       "       'CGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATAT',\n",
       "       'CCTTTATATTTTTTT', 'CCTGTACTTTT',\n",
       "       'CCTGGATTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATG',\n",
       "       'CCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTT',\n",
       "       'CCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACT',\n",
       "       'CCGCCAATATAT', 'CCCGGCAAGT',\n",
       "       'CATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCAT',\n",
       "       'CATTAACTCGT', 'CATGTGTTCCCTCCT',\n",
       "       'CATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAATGTTGCTGAT',\n",
       "       'CATCTATTCT',\n",
       "       'CATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCT',\n",
       "       'CATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTT',\n",
       "       'CATAGTTCTGT',\n",
       "       'CAGCAACATTTAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTT',\n",
       "       'CAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCATT',\n",
       "       'CACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTT',\n",
       "       'CACTCGATAAAT', 'CACACTTATTT',\n",
       "       'CAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTT',\n",
       "       'CAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGAT',\n",
       "       'CAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCT',\n",
       "       'CAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCT',\n",
       "       'CAAATCTTCAAAAAT',\n",
       "       'CAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGT',\n",
       "       'ATTTTTGAAGATT', 'ATTTTCGTTTAGAT',\n",
       "       'ATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTT',\n",
       "       'ATTTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACT',\n",
       "       'ATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAAT',\n",
       "       'ATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAATGT',\n",
       "       'ATTGATACCCTT',\n",
       "       'ATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGT',\n",
       "       'ATTATCAATAGGT',\n",
       "       'ATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTT',\n",
       "       'ATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCT',\n",
       "       'ATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTT',\n",
       "       'ATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCAT',\n",
       "       'ATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCT',\n",
       "       'ATCTCCGCTTT',\n",
       "       'ATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCT',\n",
       "       'ATCGAGTAATT',\n",
       "       'ATCATTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGT',\n",
       "       'ATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATAT',\n",
       "       'ATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCT',\n",
       "       'ATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCT',\n",
       "       'ATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTT',\n",
       "       'ATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTT',\n",
       "       'ATAAGCGGTTTT', 'ATAAATTTACCTGTT', 'ATAAATCATAACT', 'AGTATTCATAGT',\n",
       "       'AGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTT',\n",
       "       'AGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCT',\n",
       "       'AGCAGTTAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTT',\n",
       "       'AGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTT',\n",
       "       'AGCAACATTTAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTT',\n",
       "       'AGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGT',\n",
       "       'AGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGT',\n",
       "       'AGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGT',\n",
       "       'AGAATAGATGTT',\n",
       "       'AGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATT',\n",
       "       'AGAAAAGTTGTTT', 'ACTCTTCATTGT',\n",
       "       'ACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTT',\n",
       "       'AATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATTT',\n",
       "       'AATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTT',\n",
       "       'AATAAGCGGTT',\n",
       "       'AAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTT',\n",
       "       'X1_56029_A_G', 'oxyR', 'pckA', 'flr', 'group_4265', 'group_3683',\n",
       "       'group_1177', 'ribD', 'group_1505', 'group_1540', 'group_1454',\n",
       "       'coaBC_2', 'gdmA', 'group_6081', 'group_8506', 'group_8543',\n",
       "       'group_8541', 'group_1176', 'group_6857', 'group_1087',\n",
       "       'group_1405', 'lpl8_2', 'group_7991', 'yezG_6', 'group_6920',\n",
       "       'group_1779', 'lpl2_3', 'group_8664', 'group_6180', 'group_5384',\n",
       "       'group_6934', 'group_8569', 'group_7728', 'group_6924',\n",
       "       'group_2498', 'group_7793', 'group_4054', 'group_276', 'group_178',\n",
       "       'group_64', 'ST', 'CC'], dtype='<U100')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT</th>\n",
       "      <th>TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG</th>\n",
       "      <th>TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA</th>\n",
       "      <th>TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA</th>\n",
       "      <th>TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC</th>\n",
       "      <th>TTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAA</th>\n",
       "      <th>TTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTA</th>\n",
       "      <th>TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA</th>\n",
       "      <th>TTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAAT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_2498</th>\n",
       "      <th>group_7793</th>\n",
       "      <th>group_4054</th>\n",
       "      <th>group_276</th>\n",
       "      <th>group_178</th>\n",
       "      <th>group_64</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCC  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAA  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAAT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     ...  group_2498  group_7793  group_4054  group_276  group_178  group_64  \\\n",
       "0    ...           0           0           0          0          0         0   \n",
       "1    ...           0           0           0          0          0         0   \n",
       "2    ...           0           0           0          0          0         0   \n",
       "3    ...           0           0           0          0          0         0   \n",
       "4    ...           0           0           0          0          0         0   \n",
       "..   ...         ...         ...         ...        ...        ...       ...   \n",
       "248  ...           0           0           0          0          0         0   \n",
       "249  ...           0           0           0          0          0         0   \n",
       "250  ...           0           0           0          0          0         0   \n",
       "251  ...           0           0           0          0          0         0   \n",
       "252  ...           0           0           0          0          0         0   \n",
       "\n",
       "       ST  CC  pheno  strain  \n",
       "0       5   5      2     107  \n",
       "1       8   8      0     109  \n",
       "2       5   5      2     115  \n",
       "3       5   5      2  120335  \n",
       "4       5   5      2  120337  \n",
       "..    ...  ..    ...     ...  \n",
       "248     5   5      2  SR4152  \n",
       "249  3812   5      1  SR4153  \n",
       "250     5   5      0  SR4155  \n",
       "251     5   5      2  SR4156  \n",
       "252  3812   5      2  SR4187  \n",
       "\n",
       "[253 rows x 513 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 512) (253,) (253, 513)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat5['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "231        NY360     2\n",
       "139       NRS113     0\n",
       "4         120337     2\n",
       "59   CFBREBSa127     1\n",
       "96          GA27     2\n",
       "..           ...   ...\n",
       "236       SR1129     2\n",
       "145       NRS152     2\n",
       "86     CFBRSa66A     0\n",
       "28     BCH-SA-13     1\n",
       "249       SR4153     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model_sel = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 889us/step - loss: 2.4314 - accuracy: 0.3220 - val_loss: 1.8199 - val_accuracy: 0.3684\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 1.4595 - accuracy: 0.4294 - val_loss: 1.6622 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 1.5980 - accuracy: 0.4237 - val_loss: 1.5597 - val_accuracy: 0.2895\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 1.3243 - accuracy: 0.4633 - val_loss: 1.2614 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 1.1129 - accuracy: 0.4746 - val_loss: 1.6519 - val_accuracy: 0.3553\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 1.1636 - accuracy: 0.4802 - val_loss: 1.3694 - val_accuracy: 0.4868\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.9847 - accuracy: 0.5198 - val_loss: 1.3081 - val_accuracy: 0.4474\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.9980 - accuracy: 0.5424 - val_loss: 1.2437 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.9380 - accuracy: 0.5593 - val_loss: 1.2882 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.9121 - accuracy: 0.5198 - val_loss: 1.2747 - val_accuracy: 0.4079\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8888 - accuracy: 0.5480 - val_loss: 1.2672 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8701 - accuracy: 0.5650 - val_loss: 1.2783 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.8669 - accuracy: 0.6102 - val_loss: 1.2049 - val_accuracy: 0.4868\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.8503 - accuracy: 0.5989 - val_loss: 1.1776 - val_accuracy: 0.4737\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.8261 - accuracy: 0.6441 - val_loss: 1.2155 - val_accuracy: 0.5395\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8069 - accuracy: 0.6667 - val_loss: 1.3009 - val_accuracy: 0.5526\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.8150 - accuracy: 0.6497 - val_loss: 1.1811 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.7785 - accuracy: 0.6949 - val_loss: 1.1653 - val_accuracy: 0.4605\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7704 - accuracy: 0.6836 - val_loss: 1.1695 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7536 - accuracy: 0.7006 - val_loss: 1.1807 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.7405 - accuracy: 0.7062 - val_loss: 1.1815 - val_accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7287 - accuracy: 0.7006 - val_loss: 1.2095 - val_accuracy: 0.5526\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.7364 - accuracy: 0.7062 - val_loss: 1.1698 - val_accuracy: 0.5658\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.7179 - accuracy: 0.7175 - val_loss: 1.1797 - val_accuracy: 0.5395\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.6990 - accuracy: 0.7006 - val_loss: 1.2370 - val_accuracy: 0.5658\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7038 - accuracy: 0.7175 - val_loss: 1.1880 - val_accuracy: 0.5658\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.7153 - accuracy: 0.7062 - val_loss: 1.1815 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.6756 - accuracy: 0.7514 - val_loss: 1.2471 - val_accuracy: 0.5263\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.6987 - accuracy: 0.7514 - val_loss: 1.2153 - val_accuracy: 0.5395\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.6785 - accuracy: 0.7401 - val_loss: 1.2592 - val_accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.6765 - accuracy: 0.7345 - val_loss: 1.2068 - val_accuracy: 0.5395\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.6551 - accuracy: 0.7627 - val_loss: 1.2333 - val_accuracy: 0.5658\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.6544 - accuracy: 0.7740 - val_loss: 1.2072 - val_accuracy: 0.5658\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.6340 - accuracy: 0.7740 - val_loss: 1.2386 - val_accuracy: 0.5263\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.6427 - accuracy: 0.7401 - val_loss: 1.2641 - val_accuracy: 0.5395\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6246 - accuracy: 0.7514 - val_loss: 1.2545 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.6294 - accuracy: 0.7514 - val_loss: 1.2463 - val_accuracy: 0.5658\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.6145 - accuracy: 0.7571 - val_loss: 1.2433 - val_accuracy: 0.5658\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.5950 - accuracy: 0.7684 - val_loss: 1.2884 - val_accuracy: 0.5526\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.6039 - accuracy: 0.7684 - val_loss: 1.2419 - val_accuracy: 0.5526\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5782 - accuracy: 0.7797 - val_loss: 1.2941 - val_accuracy: 0.5789\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.5745 - accuracy: 0.7684 - val_loss: 1.3027 - val_accuracy: 0.5789\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.5831 - accuracy: 0.7458 - val_loss: 1.2454 - val_accuracy: 0.5526\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.5478 - accuracy: 0.7797 - val_loss: 1.2756 - val_accuracy: 0.5658\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5454 - accuracy: 0.7966 - val_loss: 1.2488 - val_accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.5374 - accuracy: 0.8023 - val_loss: 1.2651 - val_accuracy: 0.5526\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.5288 - accuracy: 0.8079 - val_loss: 1.2804 - val_accuracy: 0.5658\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.5286 - accuracy: 0.7966 - val_loss: 1.2838 - val_accuracy: 0.5789\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5158 - accuracy: 0.7966 - val_loss: 1.3090 - val_accuracy: 0.5526\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.5304 - accuracy: 0.7910 - val_loss: 1.2659 - val_accuracy: 0.5658\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5322 - accuracy: 0.8136 - val_loss: 1.2731 - val_accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.5044 - accuracy: 0.8136 - val_loss: 1.3349 - val_accuracy: 0.5526\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.5139 - accuracy: 0.8079 - val_loss: 1.3043 - val_accuracy: 0.5395\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4988 - accuracy: 0.8079 - val_loss: 1.3564 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.4904 - accuracy: 0.8079 - val_loss: 1.2930 - val_accuracy: 0.5658\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.5089 - accuracy: 0.8249 - val_loss: 1.3220 - val_accuracy: 0.5658\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 89us/step - loss: 0.4980 - accuracy: 0.8249 - val_loss: 1.4310 - val_accuracy: 0.5789\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.4880 - accuracy: 0.8362 - val_loss: 1.3191 - val_accuracy: 0.5395\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.4524 - accuracy: 0.8531 - val_loss: 1.3353 - val_accuracy: 0.5658\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.4630 - accuracy: 0.8418 - val_loss: 1.3438 - val_accuracy: 0.5395\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.4575 - accuracy: 0.8588 - val_loss: 1.4033 - val_accuracy: 0.5789\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4468 - accuracy: 0.8588 - val_loss: 1.3434 - val_accuracy: 0.5789\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.4818 - accuracy: 0.8305 - val_loss: 1.3538 - val_accuracy: 0.5789\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.4163 - accuracy: 0.8588 - val_loss: 1.4228 - val_accuracy: 0.5658\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4841 - accuracy: 0.8418 - val_loss: 1.4123 - val_accuracy: 0.5658\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.4037 - accuracy: 0.8814 - val_loss: 1.3972 - val_accuracy: 0.5789\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4387 - accuracy: 0.8475 - val_loss: 1.3383 - val_accuracy: 0.5658\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4021 - accuracy: 0.8814 - val_loss: 1.3876 - val_accuracy: 0.5789\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4039 - accuracy: 0.8983 - val_loss: 1.4252 - val_accuracy: 0.5789\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.3837 - accuracy: 0.8927 - val_loss: 1.3739 - val_accuracy: 0.5658\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.4106 - accuracy: 0.8701 - val_loss: 1.3658 - val_accuracy: 0.5658\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3729 - accuracy: 0.8814 - val_loss: 1.4402 - val_accuracy: 0.5789\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.3971 - accuracy: 0.8757 - val_loss: 1.3948 - val_accuracy: 0.5789\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.3578 - accuracy: 0.8814 - val_loss: 1.4134 - val_accuracy: 0.6053\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.3677 - accuracy: 0.8870 - val_loss: 1.3978 - val_accuracy: 0.5658\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3632 - accuracy: 0.8983 - val_loss: 1.4158 - val_accuracy: 0.5789\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3474 - accuracy: 0.8927 - val_loss: 1.4058 - val_accuracy: 0.5789\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.3390 - accuracy: 0.9153 - val_loss: 1.4230 - val_accuracy: 0.6053\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.3399 - accuracy: 0.8983 - val_loss: 1.4393 - val_accuracy: 0.5921\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3295 - accuracy: 0.9153 - val_loss: 1.4322 - val_accuracy: 0.5921\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.3254 - accuracy: 0.9096 - val_loss: 1.4325 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3220 - accuracy: 0.9096 - val_loss: 1.4400 - val_accuracy: 0.5789\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.3144 - accuracy: 0.9153 - val_loss: 1.4478 - val_accuracy: 0.5658\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.3131 - accuracy: 0.9209 - val_loss: 1.4720 - val_accuracy: 0.5921\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.3084 - accuracy: 0.9040 - val_loss: 1.4574 - val_accuracy: 0.5921\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3051 - accuracy: 0.9209 - val_loss: 1.4446 - val_accuracy: 0.5789\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2987 - accuracy: 0.9209 - val_loss: 1.4775 - val_accuracy: 0.5789\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2948 - accuracy: 0.9153 - val_loss: 1.4689 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2923 - accuracy: 0.9040 - val_loss: 1.4486 - val_accuracy: 0.5789\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.2862 - accuracy: 0.9322 - val_loss: 1.4531 - val_accuracy: 0.6053\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.2837 - accuracy: 0.9379 - val_loss: 1.4950 - val_accuracy: 0.6053\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2787 - accuracy: 0.9379 - val_loss: 1.4876 - val_accuracy: 0.5921\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2711 - accuracy: 0.9379 - val_loss: 1.4620 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2717 - accuracy: 0.9322 - val_loss: 1.4540 - val_accuracy: 0.6053\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2670 - accuracy: 0.9322 - val_loss: 1.4923 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2632 - accuracy: 0.9266 - val_loss: 1.4984 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2594 - accuracy: 0.9379 - val_loss: 1.4917 - val_accuracy: 0.6053\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2594 - accuracy: 0.9322 - val_loss: 1.4982 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2573 - accuracy: 0.9322 - val_loss: 1.5197 - val_accuracy: 0.6053\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2544 - accuracy: 0.9379 - val_loss: 1.4977 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a45514518>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 77us/step\n",
      "over-sampling test accuracy: 60.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel = model_sel.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 1, 1,\n",
       "       2, 2, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 2,\n",
       "       1, 1, 2, 0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 2, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 2, 0, 0, 0, 2, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model_sel.predict_classes(X_sel_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "231        NY360     2     1\n",
       "139       NRS113     0     0\n",
       "4         120337     2     2\n",
       "59   CFBREBSa127     1     1\n",
       "96          GA27     2     2\n",
       "..           ...   ...   ...\n",
       "236       SR1129     2     2\n",
       "145       NRS152     2     2\n",
       "86     CFBRSa66A     0     0\n",
       "28     BCH-SA-13     1     1\n",
       "249       SR4153     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model_sel.predict_proba(X_sel_test)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.319220</td>\n",
       "      <td>0.671314</td>\n",
       "      <td>0.009466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.956011</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.032526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.989609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048417</td>\n",
       "      <td>0.666007</td>\n",
       "      <td>0.285576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.993417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.083948</td>\n",
       "      <td>0.435341</td>\n",
       "      <td>0.480711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.023044</td>\n",
       "      <td>0.898006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.769431</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>0.064767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.168907</td>\n",
       "      <td>0.430691</td>\n",
       "      <td>0.400402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.998102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.319220  0.671314  0.009466\n",
       "1   0.956011  0.011463  0.032526\n",
       "2   0.002417  0.007974  0.989609\n",
       "3   0.048417  0.666007  0.285576\n",
       "4   0.000127  0.006456  0.993417\n",
       "..       ...       ...       ...\n",
       "71  0.083948  0.435341  0.480711\n",
       "72  0.078950  0.023044  0.898006\n",
       "73  0.769431  0.165802  0.064767\n",
       "74  0.168907  0.430691  0.400402\n",
       "75  0.001700  0.000198  0.998102\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2696 - accuracy: 0.9322 - val_loss: 1.4408 - val_accuracy: 0.5921\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2619 - accuracy: 0.9322 - val_loss: 1.4740 - val_accuracy: 0.5789\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2637 - accuracy: 0.9379 - val_loss: 1.4959 - val_accuracy: 0.5921\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2576 - accuracy: 0.9322 - val_loss: 1.4944 - val_accuracy: 0.5789\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2590 - accuracy: 0.9209 - val_loss: 1.4910 - val_accuracy: 0.5921\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2512 - accuracy: 0.9379 - val_loss: 1.4999 - val_accuracy: 0.5789\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2542 - accuracy: 0.9322 - val_loss: 1.4981 - val_accuracy: 0.5789\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2478 - accuracy: 0.9209 - val_loss: 1.4749 - val_accuracy: 0.5921\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2456 - accuracy: 0.9379 - val_loss: 1.4782 - val_accuracy: 0.6053\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2417 - accuracy: 0.9492 - val_loss: 1.4887 - val_accuracy: 0.5921\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.2363 - accuracy: 0.9435 - val_loss: 1.5041 - val_accuracy: 0.6053\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.2377 - accuracy: 0.9379 - val_loss: 1.4919 - val_accuracy: 0.5921\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2334 - accuracy: 0.9492 - val_loss: 1.4906 - val_accuracy: 0.5921\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2308 - accuracy: 0.9379 - val_loss: 1.5275 - val_accuracy: 0.5921\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2297 - accuracy: 0.9379 - val_loss: 1.5376 - val_accuracy: 0.5921\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2232 - accuracy: 0.9435 - val_loss: 1.5341 - val_accuracy: 0.5921\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.2284 - accuracy: 0.9435 - val_loss: 1.5088 - val_accuracy: 0.5921\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2291 - accuracy: 0.9266 - val_loss: 1.5508 - val_accuracy: 0.5921\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.2216 - accuracy: 0.9322 - val_loss: 1.5197 - val_accuracy: 0.6053\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2165 - accuracy: 0.9435 - val_loss: 1.5515 - val_accuracy: 0.5921\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2176 - accuracy: 0.9322 - val_loss: 1.5620 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2165 - accuracy: 0.9322 - val_loss: 1.6215 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2372 - accuracy: 0.9322 - val_loss: 1.5980 - val_accuracy: 0.5789\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2294 - accuracy: 0.9266 - val_loss: 1.5844 - val_accuracy: 0.5789\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2181 - accuracy: 0.9266 - val_loss: 1.6341 - val_accuracy: 0.5921\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2631 - accuracy: 0.9040 - val_loss: 1.5952 - val_accuracy: 0.5658\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.2371 - accuracy: 0.9096 - val_loss: 1.6085 - val_accuracy: 0.5789\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2034 - accuracy: 0.9492 - val_loss: 1.6501 - val_accuracy: 0.5789\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.2140 - accuracy: 0.9266 - val_loss: 1.6031 - val_accuracy: 0.5921\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2006 - accuracy: 0.9322 - val_loss: 1.6339 - val_accuracy: 0.6053\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2090 - accuracy: 0.9379 - val_loss: 1.6306 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1985 - accuracy: 0.9492 - val_loss: 1.6753 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1973 - accuracy: 0.9266 - val_loss: 1.6902 - val_accuracy: 0.5921\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1962 - accuracy: 0.9435 - val_loss: 1.7028 - val_accuracy: 0.5921\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1968 - accuracy: 0.9266 - val_loss: 1.6411 - val_accuracy: 0.5921\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2227 - accuracy: 0.9209 - val_loss: 1.7102 - val_accuracy: 0.6053\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.2158 - accuracy: 0.9379 - val_loss: 1.7381 - val_accuracy: 0.5921\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1758 - accuracy: 0.9548 - val_loss: 1.6537 - val_accuracy: 0.5789\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2019 - accuracy: 0.9379 - val_loss: 1.6812 - val_accuracy: 0.6053\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1768 - accuracy: 0.9492 - val_loss: 1.7974 - val_accuracy: 0.6053\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1921 - accuracy: 0.9435 - val_loss: 1.6744 - val_accuracy: 0.6053\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1807 - accuracy: 0.9492 - val_loss: 1.6430 - val_accuracy: 0.5921\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1677 - accuracy: 0.9435 - val_loss: 1.7218 - val_accuracy: 0.6053\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1882 - accuracy: 0.9322 - val_loss: 1.7067 - val_accuracy: 0.6053\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1977 - accuracy: 0.9209 - val_loss: 1.6483 - val_accuracy: 0.5658\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1697 - accuracy: 0.9492 - val_loss: 1.7575 - val_accuracy: 0.6053\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1729 - accuracy: 0.9492 - val_loss: 1.6626 - val_accuracy: 0.6053\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1817 - accuracy: 0.9492 - val_loss: 1.6893 - val_accuracy: 0.6053\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1687 - accuracy: 0.9718 - val_loss: 1.6815 - val_accuracy: 0.6184\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1612 - accuracy: 0.9661 - val_loss: 1.6878 - val_accuracy: 0.6316\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1567 - accuracy: 0.9605 - val_loss: 1.6590 - val_accuracy: 0.6053\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1491 - accuracy: 0.9718 - val_loss: 1.7061 - val_accuracy: 0.6053\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1395 - accuracy: 0.9774 - val_loss: 1.7352 - val_accuracy: 0.6316\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1517 - accuracy: 0.9492 - val_loss: 1.6944 - val_accuracy: 0.6184\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1423 - accuracy: 0.9718 - val_loss: 1.6512 - val_accuracy: 0.5789\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.1406 - accuracy: 0.9661 - val_loss: 1.6659 - val_accuracy: 0.6184\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 91us/step - loss: 0.1370 - accuracy: 0.9718 - val_loss: 1.6571 - val_accuracy: 0.6053\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1334 - accuracy: 0.9718 - val_loss: 1.6543 - val_accuracy: 0.6184\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1360 - accuracy: 0.9718 - val_loss: 1.6695 - val_accuracy: 0.6184\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1234 - accuracy: 0.9774 - val_loss: 1.6799 - val_accuracy: 0.6184\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1245 - accuracy: 0.9774 - val_loss: 1.6399 - val_accuracy: 0.6053\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1168 - accuracy: 0.9774 - val_loss: 1.6676 - val_accuracy: 0.6053\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.1184 - accuracy: 0.9718 - val_loss: 1.6857 - val_accuracy: 0.6316\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1105 - accuracy: 0.9774 - val_loss: 1.7033 - val_accuracy: 0.6184\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.1073 - accuracy: 0.9774 - val_loss: 1.7241 - val_accuracy: 0.6053\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1153 - accuracy: 0.9605 - val_loss: 1.7133 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1678 - accuracy: 0.9718 - val_loss: 1.8583 - val_accuracy: 0.6053\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2188 - accuracy: 0.9379 - val_loss: 1.7169 - val_accuracy: 0.6053\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1434 - accuracy: 0.9548 - val_loss: 1.8116 - val_accuracy: 0.6053\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1432 - accuracy: 0.9379 - val_loss: 1.7653 - val_accuracy: 0.5921\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1399 - accuracy: 0.9718 - val_loss: 1.7654 - val_accuracy: 0.6053\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1540 - accuracy: 0.9379 - val_loss: 1.8465 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1406 - accuracy: 0.9718 - val_loss: 1.9036 - val_accuracy: 0.6184\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1183 - accuracy: 0.9605 - val_loss: 1.8638 - val_accuracy: 0.5789\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1135 - accuracy: 0.9718 - val_loss: 1.9601 - val_accuracy: 0.5921\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1274 - accuracy: 0.9605 - val_loss: 1.9245 - val_accuracy: 0.6053\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1081 - accuracy: 0.9774 - val_loss: 1.9321 - val_accuracy: 0.5921\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.1141 - accuracy: 0.9661 - val_loss: 1.9191 - val_accuracy: 0.6053\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.0982 - accuracy: 0.9887 - val_loss: 1.8671 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.1017 - accuracy: 0.9831 - val_loss: 1.8639 - val_accuracy: 0.6184\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0982 - accuracy: 0.9774 - val_loss: 1.8724 - val_accuracy: 0.6053\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.0987 - accuracy: 0.9887 - val_loss: 1.9108 - val_accuracy: 0.5921\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0932 - accuracy: 0.9831 - val_loss: 1.8782 - val_accuracy: 0.5789\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.1005 - accuracy: 0.9831 - val_loss: 1.9021 - val_accuracy: 0.6316\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.0996 - accuracy: 0.9774 - val_loss: 1.9505 - val_accuracy: 0.6053\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.0917 - accuracy: 0.9887 - val_loss: 1.8978 - val_accuracy: 0.5921\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 53us/step - loss: 0.1016 - accuracy: 0.9831 - val_loss: 1.8910 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0843 - accuracy: 0.9887 - val_loss: 1.9739 - val_accuracy: 0.6316\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.0973 - accuracy: 0.9831 - val_loss: 1.9041 - val_accuracy: 0.5921\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.0972 - accuracy: 0.9774 - val_loss: 1.8963 - val_accuracy: 0.5789\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.0879 - accuracy: 0.9774 - val_loss: 1.9368 - val_accuracy: 0.6053\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.0990 - accuracy: 0.9831 - val_loss: 1.9288 - val_accuracy: 0.6316\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0971 - accuracy: 0.9831 - val_loss: 1.8943 - val_accuracy: 0.5921\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0836 - accuracy: 0.9887 - val_loss: 1.9564 - val_accuracy: 0.6053\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0855 - accuracy: 0.9944 - val_loss: 1.9492 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.98 - 0s 163us/step - loss: 0.0835 - accuracy: 0.9944 - val_loss: 1.9182 - val_accuracy: 0.5921\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.0865 - accuracy: 0.9887 - val_loss: 1.9318 - val_accuracy: 0.6053\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0830 - accuracy: 0.9944 - val_loss: 1.9103 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.0758 - accuracy: 0.9944 - val_loss: 1.8638 - val_accuracy: 0.6053\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.0793 - accuracy: 0.9831 - val_loss: 1.8774 - val_accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "hist_sel = model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.59%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848032e-03</td>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.441349e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.155850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466081e-02</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.979626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985392e-01</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.665667e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.617341e-03</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.055758e-03</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.747076e-01</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.593112e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.838999e-01</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual        NY360          2           1  3.848032e-03   \n",
       "1       p0017kpresabs_qual       NRS113          0           0  8.441349e-01   \n",
       "2       p0017kpresabs_qual       120337          2           2  1.466081e-02   \n",
       "3       p0017kpresabs_qual  CFBREBSa127          1           0  9.985392e-01   \n",
       "4       p0017kpresabs_qual         GA27          2           2  1.665667e-08   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa131          2           1  6.617341e-03   \n",
       "604  p0040presabsSTCC_qual       NRS112          2           2  1.055758e-03   \n",
       "605  p0040presabsSTCC_qual    BCH-SA-06          0           0  8.747076e-01   \n",
       "606  p0040presabsSTCC_qual         834N          2           2  2.593112e-06   \n",
       "607  p0040presabsSTCC_qual          CA9          1           2  3.838999e-01   \n",
       "\n",
       "            1         2  \n",
       "0    0.996096  0.000056  \n",
       "1    0.000015  0.155850  \n",
       "2    0.005713  0.979626  \n",
       "3    0.000350  0.001111  \n",
       "4    0.000005  0.999995  \n",
       "..        ...       ...  \n",
       "603  0.565843  0.427540  \n",
       "604  0.045611  0.953333  \n",
       "605  0.071162  0.054130  \n",
       "606  0.000013  0.999985  \n",
       "607  0.142659  0.473441  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.19220040e-01, 6.71313640e-01, 9.46632100e-03],\n",
       "       [9.56010760e-01, 1.14627555e-02, 3.25264900e-02],\n",
       "       [2.41723680e-03, 7.97393450e-03, 9.89608800e-01],\n",
       "       [4.84172200e-02, 6.66006860e-01, 2.85575960e-01],\n",
       "       [1.27318750e-04, 6.45613340e-03, 9.93416550e-01],\n",
       "       [2.18570630e-01, 6.87941300e-01, 9.34880700e-02],\n",
       "       [1.52052500e-02, 8.52544900e-01, 1.32249860e-01],\n",
       "       [2.41774190e-01, 7.52811400e-01, 5.41445240e-03],\n",
       "       [3.78184320e-01, 4.66579080e-07, 6.21815200e-01],\n",
       "       [6.69107740e-01, 3.13014150e-01, 1.78781170e-02],\n",
       "       [5.38035600e-01, 4.14930940e-01, 4.70335400e-02],\n",
       "       [2.69195300e-04, 3.92985400e-07, 9.99730400e-01],\n",
       "       [3.65392630e-01, 5.73541100e-01, 6.10662070e-02],\n",
       "       [8.24086070e-01, 5.34322820e-02, 1.22481660e-01],\n",
       "       [1.50150130e-03, 3.01263350e-02, 9.68372170e-01],\n",
       "       [4.99642450e-02, 8.85122360e-01, 6.49134600e-02],\n",
       "       [3.89094200e-01, 3.38006440e-01, 2.72899420e-01],\n",
       "       [9.93347800e-01, 2.88456200e-06, 6.64925500e-03],\n",
       "       [3.92401250e-01, 2.30327050e-01, 3.77271680e-01],\n",
       "       [8.47621600e-01, 4.47655170e-02, 1.07612850e-01],\n",
       "       [1.67837290e-01, 8.16016440e-01, 1.61463040e-02],\n",
       "       [8.37828900e-02, 4.73377650e-01, 4.42839470e-01],\n",
       "       [1.75630010e-03, 9.57976750e-03, 9.88664000e-01],\n",
       "       [2.61351800e-01, 3.06604200e-01, 4.32043900e-01],\n",
       "       [9.70388650e-01, 3.13373300e-03, 2.64775640e-02],\n",
       "       [1.40178570e-02, 7.39501900e-02, 9.12031950e-01],\n",
       "       [9.66262800e-01, 3.29911260e-02, 7.46093050e-04],\n",
       "       [4.20092430e-01, 4.80428960e-01, 9.94785500e-02],\n",
       "       [6.69107740e-01, 3.13014150e-01, 1.78781170e-02],\n",
       "       [3.05906980e-01, 6.84838100e-01, 9.25492500e-03],\n",
       "       [3.86202630e-02, 9.49717340e-01, 1.16623820e-02],\n",
       "       [7.50579900e-02, 6.22535000e-02, 8.62688540e-01],\n",
       "       [1.06857000e-02, 9.81659500e-01, 7.65479730e-03],\n",
       "       [5.32612300e-01, 3.41630900e-01, 1.25756760e-01],\n",
       "       [6.81354400e-01, 2.53920970e-01, 6.47246200e-02],\n",
       "       [1.73346310e-01, 6.88410940e-01, 1.38242750e-01],\n",
       "       [6.69107740e-01, 3.13014150e-01, 1.78781170e-02],\n",
       "       [1.15533870e-01, 8.17627700e-01, 6.68383700e-02],\n",
       "       [1.91665510e-05, 5.93663680e-08, 9.99980800e-01],\n",
       "       [4.15801470e-01, 3.82004530e-01, 2.02194020e-01],\n",
       "       [5.31706360e-02, 8.62845500e-01, 8.39839200e-02],\n",
       "       [9.14400400e-01, 4.26353550e-02, 4.29642160e-02],\n",
       "       [7.98309000e-01, 1.24470250e-01, 7.72207300e-02],\n",
       "       [9.21494740e-02, 1.36465980e-02, 8.94203960e-01],\n",
       "       [1.63423050e-01, 6.04643500e-01, 2.31933410e-01],\n",
       "       [8.90673000e-02, 7.88112640e-01, 1.22820040e-01],\n",
       "       [1.53066800e-01, 8.05386300e-03, 8.38879350e-01],\n",
       "       [7.71434370e-01, 1.85250850e-01, 4.33147920e-02],\n",
       "       [2.44857980e-03, 3.24595270e-06, 9.97548160e-01],\n",
       "       [1.39348830e-01, 3.25184800e-01, 5.35466300e-01],\n",
       "       [9.35151900e-02, 7.82953900e-02, 8.28189430e-01],\n",
       "       [2.46209610e-02, 4.08379050e-01, 5.67000030e-01],\n",
       "       [9.85812540e-01, 2.15733130e-04, 1.39717115e-02],\n",
       "       [8.42193400e-03, 3.56647100e-02, 9.55913360e-01],\n",
       "       [2.14939790e-01, 7.16557300e-01, 6.85029000e-02],\n",
       "       [9.30291400e-01, 5.56098800e-02, 1.40987510e-02],\n",
       "       [2.61138950e-01, 3.97153880e-01, 3.41707260e-01],\n",
       "       [5.37806630e-01, 6.45107600e-02, 3.97682580e-01],\n",
       "       [1.52689880e-02, 2.08356690e-05, 9.84710160e-01],\n",
       "       [1.44178500e-01, 7.37071900e-01, 1.18749715e-01],\n",
       "       [6.69107740e-01, 3.13014150e-01, 1.78781170e-02],\n",
       "       [8.63083300e-01, 3.54645900e-02, 1.01452050e-01],\n",
       "       [3.51601660e-01, 6.13292600e-01, 3.51057720e-02],\n",
       "       [1.48383120e-02, 9.72732400e-01, 1.24292340e-02],\n",
       "       [7.82404300e-02, 8.73485000e-01, 4.82745840e-02],\n",
       "       [6.83072950e-02, 8.92730500e-01, 3.89621970e-02],\n",
       "       [8.61121650e-01, 1.03176445e-01, 3.57019530e-02],\n",
       "       [1.36016070e-01, 1.13697290e-03, 8.62847000e-01],\n",
       "       [8.86364040e-01, 8.20489900e-02, 3.15869100e-02],\n",
       "       [8.06475940e-01, 5.36691060e-02, 1.39855000e-01],\n",
       "       [5.54345300e-01, 2.06098820e-01, 2.39555880e-01],\n",
       "       [8.39479100e-02, 4.35341060e-01, 4.80710950e-01],\n",
       "       [7.89503600e-02, 2.30437830e-02, 8.98005800e-01],\n",
       "       [7.69430640e-01, 1.65802370e-01, 6.47669600e-02],\n",
       "       [1.68907460e-01, 4.30690970e-01, 4.00401600e-01],\n",
       "       [1.70005470e-03, 1.98475330e-04, 9.98101530e-01]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247446116493735"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247446116493735"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat6['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "44   CFBREBSa104     1\n",
       "170       NRS199     2\n",
       "197       NRS233     1\n",
       "238       SR1746     0\n",
       "172       NRS202     2\n",
       "..           ...   ...\n",
       "92         EUH25     2\n",
       "217       NRS260     0\n",
       "75      CFBRSa25     0\n",
       "156       NRS177     1\n",
       "105        MN055     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 717us/step - loss: 6.7044 - accuracy: 0.3333 - val_loss: 3.2322 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 3.1536 - accuracy: 0.4237 - val_loss: 2.0982 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 1.9138 - accuracy: 0.5028 - val_loss: 1.4340 - val_accuracy: 0.3421\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 1.4327 - accuracy: 0.5311 - val_loss: 1.3462 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 242us/step - loss: 1.0663 - accuracy: 0.5593 - val_loss: 1.2081 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.9725 - accuracy: 0.5989 - val_loss: 1.1119 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.9453 - accuracy: 0.5989 - val_loss: 1.1079 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.9679 - accuracy: 0.6158 - val_loss: 1.0472 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.9646 - accuracy: 0.6497 - val_loss: 1.0578 - val_accuracy: 0.5132\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 1.6098 - accuracy: 0.6610 - val_loss: 1.6021 - val_accuracy: 0.4868\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 1.3828 - accuracy: 0.6328 - val_loss: 1.5773 - val_accuracy: 0.5395\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 1.5704 - accuracy: 0.6384 - val_loss: 1.5158 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 1.3937 - accuracy: 0.6780 - val_loss: 1.3665 - val_accuracy: 0.5132\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 1.2102 - accuracy: 0.6723 - val_loss: 1.1765 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 1.0266 - accuracy: 0.6893 - val_loss: 1.0587 - val_accuracy: 0.5395\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.8003 - accuracy: 0.7232 - val_loss: 1.0522 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 290us/step - loss: 0.7652 - accuracy: 0.7006 - val_loss: 1.0101 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.7427 - accuracy: 0.6836 - val_loss: 1.0208 - val_accuracy: 0.5395\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.7904 - accuracy: 0.6836 - val_loss: 1.0557 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6571 - accuracy: 0.7006 - val_loss: 1.0224 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.7268 - accuracy: 0.7232 - val_loss: 1.0727 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.6979 - accuracy: 0.7401 - val_loss: 1.0687 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.6689 - accuracy: 0.7175 - val_loss: 1.0851 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6643 - accuracy: 0.7232 - val_loss: 1.0463 - val_accuracy: 0.5526\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.6971 - accuracy: 0.6836 - val_loss: 1.0960 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.6135 - accuracy: 0.7458 - val_loss: 1.1418 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.6813 - accuracy: 0.7740 - val_loss: 1.0117 - val_accuracy: 0.5526\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.5916 - accuracy: 0.7740 - val_loss: 1.0549 - val_accuracy: 0.5395\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.6298 - accuracy: 0.7458 - val_loss: 1.0196 - val_accuracy: 0.5263\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.5928 - accuracy: 0.7966 - val_loss: 1.0112 - val_accuracy: 0.5789\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.5484 - accuracy: 0.8192 - val_loss: 1.0134 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.5387 - accuracy: 0.8192 - val_loss: 0.9844 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.5516 - accuracy: 0.8249 - val_loss: 1.0014 - val_accuracy: 0.5921\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.5750 - accuracy: 0.8192 - val_loss: 1.0635 - val_accuracy: 0.5658\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6838 - accuracy: 0.7571 - val_loss: 1.0213 - val_accuracy: 0.5789\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.5825 - accuracy: 0.8192 - val_loss: 1.0344 - val_accuracy: 0.5526\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.5809 - accuracy: 0.8023 - val_loss: 0.9807 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6240 - accuracy: 0.7910 - val_loss: 0.9748 - val_accuracy: 0.5526\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.5497 - accuracy: 0.8192 - val_loss: 1.0135 - val_accuracy: 0.5789\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.5705 - accuracy: 0.8531 - val_loss: 0.9977 - val_accuracy: 0.6184\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5227 - accuracy: 0.8305 - val_loss: 0.9659 - val_accuracy: 0.5789\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.4995 - accuracy: 0.8475 - val_loss: 0.9947 - val_accuracy: 0.5395\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.5014 - accuracy: 0.8305 - val_loss: 1.1977 - val_accuracy: 0.5789\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.6577 - accuracy: 0.8588 - val_loss: 1.0422 - val_accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.5940 - accuracy: 0.7853 - val_loss: 1.0317 - val_accuracy: 0.6053\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 502us/step - loss: 0.4695 - accuracy: 0.8362 - val_loss: 1.0179 - val_accuracy: 0.5921\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.4634 - accuracy: 0.8475 - val_loss: 0.9910 - val_accuracy: 0.5526\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.5446 - accuracy: 0.8136 - val_loss: 1.0463 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.5333 - accuracy: 0.8136 - val_loss: 0.9847 - val_accuracy: 0.5789\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.4663 - accuracy: 0.8192 - val_loss: 1.0371 - val_accuracy: 0.5395\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.4228 - accuracy: 0.8475 - val_loss: 1.0305 - val_accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.4686 - accuracy: 0.8362 - val_loss: 1.0747 - val_accuracy: 0.5789\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.4587 - accuracy: 0.8249 - val_loss: 1.0769 - val_accuracy: 0.6184\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.4533 - accuracy: 0.8701 - val_loss: 1.0245 - val_accuracy: 0.5921\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.4502 - accuracy: 0.8475 - val_loss: 1.0482 - val_accuracy: 0.5921\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.5161 - accuracy: 0.8701 - val_loss: 1.1252 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.5434 - accuracy: 0.8475 - val_loss: 1.0852 - val_accuracy: 0.5658\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.4616 - accuracy: 0.8644 - val_loss: 1.0744 - val_accuracy: 0.5921\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.4416 - accuracy: 0.8927 - val_loss: 1.0354 - val_accuracy: 0.5789\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.4085 - accuracy: 0.8757 - val_loss: 1.0776 - val_accuracy: 0.6053\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4759 - accuracy: 0.8757 - val_loss: 1.0365 - val_accuracy: 0.6053\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.3983 - accuracy: 0.8983 - val_loss: 1.0144 - val_accuracy: 0.6316\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.4215 - accuracy: 0.8927 - val_loss: 1.0193 - val_accuracy: 0.6184\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.3574 - accuracy: 0.9153 - val_loss: 1.0099 - val_accuracy: 0.6053\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.4302 - accuracy: 0.8983 - val_loss: 1.1457 - val_accuracy: 0.6184\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.5172 - accuracy: 0.8983 - val_loss: 1.0572 - val_accuracy: 0.5921\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.4389 - accuracy: 0.8531 - val_loss: 1.1321 - val_accuracy: 0.5921\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.4213 - accuracy: 0.8870 - val_loss: 1.0379 - val_accuracy: 0.5395\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.3411 - accuracy: 0.8757 - val_loss: 1.0429 - val_accuracy: 0.5658\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.3430 - accuracy: 0.8983 - val_loss: 1.0751 - val_accuracy: 0.5658\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.4054 - accuracy: 0.8814 - val_loss: 1.0602 - val_accuracy: 0.5921\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.3206 - accuracy: 0.8927 - val_loss: 1.1886 - val_accuracy: 0.5921\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.4538 - accuracy: 0.8757 - val_loss: 1.0930 - val_accuracy: 0.6316\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.4122 - accuracy: 0.8870 - val_loss: 1.0487 - val_accuracy: 0.5921\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.3200 - accuracy: 0.9040 - val_loss: 1.0772 - val_accuracy: 0.5526\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.4152 - accuracy: 0.8870 - val_loss: 1.0960 - val_accuracy: 0.5395\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.3564 - accuracy: 0.8870 - val_loss: 1.0681 - val_accuracy: 0.6316\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.3009 - accuracy: 0.9096 - val_loss: 1.0431 - val_accuracy: 0.6053\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.3051 - accuracy: 0.9209 - val_loss: 1.0487 - val_accuracy: 0.6053\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3073 - accuracy: 0.8927 - val_loss: 1.0526 - val_accuracy: 0.6053\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2889 - accuracy: 0.9153 - val_loss: 1.0597 - val_accuracy: 0.6184\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3159 - accuracy: 0.9096 - val_loss: 1.1336 - val_accuracy: 0.6316\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3285 - accuracy: 0.9153 - val_loss: 1.0664 - val_accuracy: 0.5658\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3761 - accuracy: 0.8814 - val_loss: 1.1763 - val_accuracy: 0.6184\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.4086 - accuracy: 0.8814 - val_loss: 1.1373 - val_accuracy: 0.6184\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3674 - accuracy: 0.8927 - val_loss: 1.1161 - val_accuracy: 0.6316\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3405 - accuracy: 0.9096 - val_loss: 1.0430 - val_accuracy: 0.5789\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.3220 - accuracy: 0.9153 - val_loss: 1.0224 - val_accuracy: 0.6184\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2763 - accuracy: 0.9435 - val_loss: 1.0236 - val_accuracy: 0.6447\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2945 - accuracy: 0.8927 - val_loss: 0.9921 - val_accuracy: 0.6447\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2737 - accuracy: 0.9209 - val_loss: 1.0942 - val_accuracy: 0.6316\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.3380 - accuracy: 0.9322 - val_loss: 1.0877 - val_accuracy: 0.6447\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2735 - accuracy: 0.9153 - val_loss: 1.1844 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.3209 - accuracy: 0.9040 - val_loss: 1.1207 - val_accuracy: 0.6053\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3122 - accuracy: 0.9266 - val_loss: 1.1613 - val_accuracy: 0.6579\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.3187 - accuracy: 0.9266 - val_loss: 1.0857 - val_accuracy: 0.6053\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2858 - accuracy: 0.9096 - val_loss: 1.1124 - val_accuracy: 0.5526\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4507 - accuracy: 0.8983 - val_loss: 1.2205 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.3031 - accuracy: 0.8814 - val_loss: 1.1679 - val_accuracy: 0.5789\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2855 - accuracy: 0.9040 - val_loss: 1.1399 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a43861550>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 131us/step\n",
      "test accuracy: 59.21%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 2, 0, 2, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 2, 2, 0, 1, 2, 0, 1, 2, 1, 2,\n",
       "       1, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 1, 2, 2, 0, 1,\n",
       "       0, 0, 0, 0, 2, 1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model_sel2.predict_classes(X_sel_test)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "44   CFBREBSa104     1     2\n",
       "170       NRS199     2     2\n",
       "197       NRS233     1     0\n",
       "238       SR1746     0     1\n",
       "172       NRS202     2     2\n",
       "..           ...   ...   ...\n",
       "92         EUH25     2     1\n",
       "217       NRS260     0     0\n",
       "75      CFBRSa25     0     0\n",
       "156       NRS177     1     1\n",
       "105        MN055     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model_sel2.predict_proba(X_sel_test)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187464</td>\n",
       "      <td>0.029691</td>\n",
       "      <td>0.782845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231965</td>\n",
       "      <td>0.376493</td>\n",
       "      <td>0.391541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.663481</td>\n",
       "      <td>0.095792</td>\n",
       "      <td>0.240727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.171868</td>\n",
       "      <td>0.519125</td>\n",
       "      <td>0.309007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.119096</td>\n",
       "      <td>0.846455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.373144</td>\n",
       "      <td>0.625452</td>\n",
       "      <td>0.001403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.976010</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>0.010224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.672251</td>\n",
       "      <td>0.247505</td>\n",
       "      <td>0.080244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.972865</td>\n",
       "      <td>0.010435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.989412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.187464  0.029691  0.782845\n",
       "1   0.231965  0.376493  0.391541\n",
       "2   0.663481  0.095792  0.240727\n",
       "3   0.171868  0.519125  0.309007\n",
       "4   0.034450  0.119096  0.846455\n",
       "..       ...       ...       ...\n",
       "71  0.373144  0.625452  0.001403\n",
       "72  0.976010  0.013766  0.010224\n",
       "73  0.672251  0.247505  0.080244\n",
       "74  0.016700  0.972865  0.010435\n",
       "75  0.008196  0.002393  0.989412\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.4251 - accuracy: 0.8983 - val_loss: 0.9886 - val_accuracy: 0.5921\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.3680 - accuracy: 0.9040 - val_loss: 1.0817 - val_accuracy: 0.6316\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.3978 - accuracy: 0.8870 - val_loss: 0.9710 - val_accuracy: 0.5921\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.3575 - accuracy: 0.9153 - val_loss: 1.0696 - val_accuracy: 0.6053\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.3608 - accuracy: 0.9096 - val_loss: 1.0122 - val_accuracy: 0.6184\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.3479 - accuracy: 0.9153 - val_loss: 1.0307 - val_accuracy: 0.5921\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.4668 - accuracy: 0.8814 - val_loss: 0.9815 - val_accuracy: 0.5789\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.4360 - accuracy: 0.8927 - val_loss: 0.9992 - val_accuracy: 0.6053\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.3719 - accuracy: 0.9096 - val_loss: 0.9962 - val_accuracy: 0.6184\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.3398 - accuracy: 0.8814 - val_loss: 1.1139 - val_accuracy: 0.6053\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.4558 - accuracy: 0.9040 - val_loss: 1.0611 - val_accuracy: 0.6053\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.3567 - accuracy: 0.9209 - val_loss: 1.0499 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.3529 - accuracy: 0.9266 - val_loss: 1.0255 - val_accuracy: 0.6184\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.2648 - accuracy: 0.9266 - val_loss: 1.0082 - val_accuracy: 0.6053\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3296 - accuracy: 0.9379 - val_loss: 1.0169 - val_accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.3866 - accuracy: 0.9040 - val_loss: 0.9571 - val_accuracy: 0.5921\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2999 - accuracy: 0.9153 - val_loss: 0.9887 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.2592 - accuracy: 0.9492 - val_loss: 0.9767 - val_accuracy: 0.5921\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.2859 - accuracy: 0.9153 - val_loss: 1.0121 - val_accuracy: 0.5395\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.2903 - accuracy: 0.9435 - val_loss: 1.0409 - val_accuracy: 0.6053\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4173 - accuracy: 0.8870 - val_loss: 1.0707 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.3499 - accuracy: 0.9209 - val_loss: 1.2326 - val_accuracy: 0.5789\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.4878 - accuracy: 0.8927 - val_loss: 1.1032 - val_accuracy: 0.5921\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.2893 - accuracy: 0.9209 - val_loss: 1.1076 - val_accuracy: 0.5789\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.3276 - accuracy: 0.9209 - val_loss: 1.0490 - val_accuracy: 0.6053\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.2582 - accuracy: 0.9266 - val_loss: 0.9909 - val_accuracy: 0.5921\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2385 - accuracy: 0.9379 - val_loss: 1.0122 - val_accuracy: 0.6184\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2891 - accuracy: 0.9266 - val_loss: 1.0612 - val_accuracy: 0.5921\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.2862 - accuracy: 0.9322 - val_loss: 1.0422 - val_accuracy: 0.6053\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.2627 - accuracy: 0.9379 - val_loss: 1.0572 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3125 - accuracy: 0.9153 - val_loss: 1.0602 - val_accuracy: 0.6316\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.3036 - accuracy: 0.9379 - val_loss: 1.0134 - val_accuracy: 0.6053\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2358 - accuracy: 0.9379 - val_loss: 1.1144 - val_accuracy: 0.6053\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.3466 - accuracy: 0.9096 - val_loss: 1.0707 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.2480 - accuracy: 0.9435 - val_loss: 1.0341 - val_accuracy: 0.5921\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.2553 - accuracy: 0.9492 - val_loss: 1.0235 - val_accuracy: 0.6053\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2565 - accuracy: 0.9548 - val_loss: 1.0225 - val_accuracy: 0.5921\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2734 - accuracy: 0.9492 - val_loss: 1.1062 - val_accuracy: 0.6053\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.3640 - accuracy: 0.9096 - val_loss: 1.1276 - val_accuracy: 0.6447\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.3457 - accuracy: 0.9040 - val_loss: 1.0358 - val_accuracy: 0.6316\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.3701 - accuracy: 0.9153 - val_loss: 1.1274 - val_accuracy: 0.6184\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.3178 - accuracy: 0.9153 - val_loss: 1.2239 - val_accuracy: 0.5921\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3984 - accuracy: 0.8927 - val_loss: 1.2225 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2916 - accuracy: 0.9153 - val_loss: 1.0840 - val_accuracy: 0.6184\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2861 - accuracy: 0.9379 - val_loss: 1.0605 - val_accuracy: 0.6184\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.4088 - accuracy: 0.8870 - val_loss: 1.0779 - val_accuracy: 0.6053\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.3153 - accuracy: 0.9153 - val_loss: 1.0919 - val_accuracy: 0.6579\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.2666 - accuracy: 0.9153 - val_loss: 1.0877 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2017 - accuracy: 0.9492 - val_loss: 1.0596 - val_accuracy: 0.6316\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.2429 - accuracy: 0.9492 - val_loss: 1.0407 - val_accuracy: 0.6184\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 495us/step - loss: 0.1926 - accuracy: 0.9605 - val_loss: 1.0899 - val_accuracy: 0.6184\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.2871 - accuracy: 0.9153 - val_loss: 1.0827 - val_accuracy: 0.5658\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.2830 - accuracy: 0.9435 - val_loss: 1.0479 - val_accuracy: 0.6184\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 748us/step - loss: 0.2752 - accuracy: 0.9379 - val_loss: 0.9945 - val_accuracy: 0.6053\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 579us/step - loss: 0.2440 - accuracy: 0.9096 - val_loss: 0.9640 - val_accuracy: 0.6053\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.2631 - accuracy: 0.9435 - val_loss: 1.0322 - val_accuracy: 0.6053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9322 - val_loss: 1.0951 - val_accuracy: 0.6447\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.2436 - accuracy: 0.9379 - val_loss: 1.0392 - val_accuracy: 0.6316\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 767us/step - loss: 0.2809 - accuracy: 0.9209 - val_loss: 1.0675 - val_accuracy: 0.6053\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.2004 - accuracy: 0.9435 - val_loss: 1.0798 - val_accuracy: 0.5921\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.2279 - accuracy: 0.9548 - val_loss: 1.0785 - val_accuracy: 0.6184\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.2649 - accuracy: 0.9548 - val_loss: 1.0902 - val_accuracy: 0.6053\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.2645 - accuracy: 0.9492 - val_loss: 1.1691 - val_accuracy: 0.6053\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.3368 - accuracy: 0.8870 - val_loss: 1.3464 - val_accuracy: 0.5921\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.5317 - accuracy: 0.9040 - val_loss: 1.3404 - val_accuracy: 0.6447\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.3885 - accuracy: 0.9040 - val_loss: 1.2548 - val_accuracy: 0.5921\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.3409 - accuracy: 0.9096 - val_loss: 1.1767 - val_accuracy: 0.5921\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.2496 - accuracy: 0.8927 - val_loss: 1.1410 - val_accuracy: 0.6447\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.2271 - accuracy: 0.9209 - val_loss: 1.0925 - val_accuracy: 0.6053\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.2415 - accuracy: 0.9492 - val_loss: 1.1890 - val_accuracy: 0.6053\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.1926 - accuracy: 0.9492 - val_loss: 1.1654 - val_accuracy: 0.5921\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.2678 - accuracy: 0.9435 - val_loss: 1.1092 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.1779 - accuracy: 0.9661 - val_loss: 1.1101 - val_accuracy: 0.6053\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.1878 - accuracy: 0.9605 - val_loss: 1.1454 - val_accuracy: 0.5921\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.2864 - accuracy: 0.9379 - val_loss: 1.1278 - val_accuracy: 0.6053\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.3708 - accuracy: 0.9492 - val_loss: 1.1717 - val_accuracy: 0.6053\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2475 - accuracy: 0.9661 - val_loss: 1.1658 - val_accuracy: 0.6053\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1576 - accuracy: 0.9605 - val_loss: 1.1327 - val_accuracy: 0.5789\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1905 - accuracy: 0.9605 - val_loss: 1.1414 - val_accuracy: 0.5789\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.2698 - accuracy: 0.9435 - val_loss: 1.1577 - val_accuracy: 0.5789\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.2666 - accuracy: 0.9040 - val_loss: 1.2572 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.4167 - accuracy: 0.9322 - val_loss: 1.1607 - val_accuracy: 0.6184\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 973us/step - loss: 0.2178 - accuracy: 0.9435 - val_loss: 1.1581 - val_accuracy: 0.6316\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.2055 - accuracy: 0.9548 - val_loss: 1.1975 - val_accuracy: 0.5789\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.4040 - accuracy: 0.9209 - val_loss: 1.2311 - val_accuracy: 0.6316\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.2770 - accuracy: 0.9605 - val_loss: 1.1720 - val_accuracy: 0.5921\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.2373 - accuracy: 0.9322 - val_loss: 1.1965 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.2349 - accuracy: 0.9492 - val_loss: 1.1553 - val_accuracy: 0.5789\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2116 - accuracy: 0.9605 - val_loss: 1.2638 - val_accuracy: 0.6184\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.3800 - accuracy: 0.9435 - val_loss: 1.1349 - val_accuracy: 0.6053\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.1866 - accuracy: 0.9605 - val_loss: 1.1425 - val_accuracy: 0.5789\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1739 - accuracy: 0.9379 - val_loss: 1.1831 - val_accuracy: 0.6184\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.1831 - accuracy: 0.9718 - val_loss: 1.1896 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.2178 - accuracy: 0.9492 - val_loss: 1.1858 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1571 - accuracy: 0.9492 - val_loss: 1.2997 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.3060 - accuracy: 0.9492 - val_loss: 1.1426 - val_accuracy: 0.6053\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2206 - accuracy: 0.9492 - val_loss: 1.1708 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.3069 - accuracy: 0.9435 - val_loss: 1.3028 - val_accuracy: 0.6447\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.4239 - accuracy: 0.9379 - val_loss: 1.2979 - val_accuracy: 0.6053\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.2808 - accuracy: 0.9435 - val_loss: 1.2440 - val_accuracy: 0.5921\n"
     ]
    }
   ],
   "source": [
    "hist_sel2 = model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 92.94%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.290039e-09</td>\n",
       "      <td>1.567630e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.856965e-05</td>\n",
       "      <td>2.843749e-03</td>\n",
       "      <td>9.971277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999446e-01</td>\n",
       "      <td>4.541289e-06</td>\n",
       "      <td>5.090974e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.282367e-02</td>\n",
       "      <td>7.075194e-04</td>\n",
       "      <td>9.364688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.229589e-03</td>\n",
       "      <td>2.163908e-05</td>\n",
       "      <td>9.917488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>9.959286e-01</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>9.996691e-01</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>9.999915e-01</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>1.480882e-02</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>9.994158e-01</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  CFBREBSa104          1           2  1.290039e-09   \n",
       "1       p0017kpresabs_qual       NRS199          2           2  2.856965e-05   \n",
       "2       p0017kpresabs_qual       NRS233          1           0  9.999446e-01   \n",
       "3       p0017kpresabs_qual       SR1746          0           2  6.282367e-02   \n",
       "4       p0017kpresabs_qual       NRS202          2           2  8.229589e-03   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual         GA27          2           1  3.964591e-03   \n",
       "604  p0040presabsSTCC_qual        GA231          2           1  3.309226e-04   \n",
       "605  p0040presabsSTCC_qual       SR1287          0           1  8.445997e-06   \n",
       "606  p0040presabsSTCC_qual          506          2           0  6.516150e-01   \n",
       "607  p0040presabsSTCC_qual       NRS001          1           1  5.841915e-04   \n",
       "\n",
       "                1             2  \n",
       "0    1.567630e-07  9.999999e-01  \n",
       "1    2.843749e-03  9.971277e-01  \n",
       "2    4.541289e-06  5.090974e-05  \n",
       "3    7.075194e-04  9.364688e-01  \n",
       "4    2.163908e-05  9.917488e-01  \n",
       "..            ...           ...  \n",
       "603  9.959286e-01  1.068284e-04  \n",
       "604  9.996691e-01  6.232397e-10  \n",
       "605  9.999915e-01  1.182947e-13  \n",
       "606  1.480882e-02  3.335762e-01  \n",
       "607  9.994158e-01  6.525528e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.87463980e-01, 2.96913940e-02, 7.82844660e-01],\n",
       "       [2.31965440e-01, 3.76493360e-01, 3.91541180e-01],\n",
       "       [6.63481240e-01, 9.57917350e-02, 2.40727070e-01],\n",
       "       [1.71868160e-01, 5.19125100e-01, 3.09006780e-01],\n",
       "       [3.44496400e-02, 1.19095650e-01, 8.46454700e-01],\n",
       "       [5.44801300e-03, 2.19516890e-01, 7.75035100e-01],\n",
       "       [7.66627200e-02, 1.34719670e-01, 7.88617700e-01],\n",
       "       [7.56010800e-01, 1.85391750e-01, 5.85975200e-02],\n",
       "       [4.00522900e-02, 9.21841440e-01, 3.81062900e-02],\n",
       "       [5.85080860e-01, 3.81434230e-01, 3.34849430e-02],\n",
       "       [1.83461640e-01, 6.70618800e-01, 1.45919640e-01],\n",
       "       [2.89404860e-02, 2.51123520e-01, 7.19936000e-01],\n",
       "       [3.13181760e-01, 5.69331470e-01, 1.17486745e-01],\n",
       "       [5.34935160e-03, 8.13380900e-03, 9.86516830e-01],\n",
       "       [8.00847500e-01, 1.30704050e-01, 6.84485200e-02],\n",
       "       [7.59959440e-02, 5.69333140e-02, 8.67070800e-01],\n",
       "       [3.00342100e-01, 5.56674700e-01, 1.42983240e-01],\n",
       "       [7.30021400e-01, 1.14089710e-01, 1.55888940e-01],\n",
       "       [8.47967700e-03, 8.99898770e-01, 9.16215300e-02],\n",
       "       [6.93102700e-01, 9.41594240e-02, 2.12737860e-01],\n",
       "       [2.72178860e-01, 4.46156620e-01, 2.81664500e-01],\n",
       "       [7.72283430e-01, 2.07982570e-01, 1.97340230e-02],\n",
       "       [9.79546960e-01, 1.96984320e-02, 7.54516800e-04],\n",
       "       [8.70076600e-01, 4.88986520e-02, 8.10247600e-02],\n",
       "       [6.99981330e-01, 8.76360400e-02, 2.12382630e-01],\n",
       "       [8.12125440e-01, 1.61311580e-01, 2.65629270e-02],\n",
       "       [9.44252200e-01, 4.83930100e-02, 7.35475100e-03],\n",
       "       [2.30249860e-05, 1.04637290e-02, 9.89513200e-01],\n",
       "       [5.34255340e-03, 1.17521830e-01, 8.77135600e-01],\n",
       "       [9.49269350e-01, 4.19077100e-02, 8.82282600e-03],\n",
       "       [3.95364250e-01, 4.46849580e-01, 1.57786090e-01],\n",
       "       [9.07800400e-03, 1.03214870e-01, 8.87707200e-01],\n",
       "       [9.04166900e-01, 3.80136780e-02, 5.78194800e-02],\n",
       "       [1.67400740e-02, 1.15241340e-01, 8.68018570e-01],\n",
       "       [3.93703320e-02, 2.00431360e-01, 7.60198300e-01],\n",
       "       [7.75038300e-02, 2.76855650e-01, 6.45640500e-01],\n",
       "       [7.03773300e-01, 1.27322060e-01, 1.68904560e-01],\n",
       "       [7.86635060e-02, 6.36562050e-01, 2.84774450e-01],\n",
       "       [2.39724310e-02, 3.17356970e-01, 6.58670660e-01],\n",
       "       [8.89040470e-01, 1.01454824e-01, 9.50469600e-03],\n",
       "       [8.47763700e-02, 8.85335300e-01, 2.98883470e-02],\n",
       "       [3.50022500e-02, 3.79983370e-01, 5.85014400e-01],\n",
       "       [3.27101700e-01, 5.14086660e-01, 1.58811600e-01],\n",
       "       [2.74941980e-09, 1.28106870e-10, 1.00000000e+00],\n",
       "       [1.73479070e-01, 7.46913400e-01, 7.96075700e-02],\n",
       "       [1.07802770e-01, 1.69883100e-01, 7.22314100e-01],\n",
       "       [2.55122000e-02, 3.54572030e-01, 6.19915700e-01],\n",
       "       [1.90910760e-01, 7.10086170e-01, 9.90030300e-02],\n",
       "       [8.27338760e-01, 1.62264630e-01, 1.03966310e-02],\n",
       "       [2.62009830e-01, 3.96256720e-01, 3.41733500e-01],\n",
       "       [1.26079280e-03, 2.50168100e-01, 7.48571100e-01],\n",
       "       [8.60120500e-01, 1.37920140e-01, 1.95929300e-03],\n",
       "       [7.20591200e-01, 2.26835010e-01, 5.25738750e-02],\n",
       "       [3.56399920e-01, 4.62804320e-01, 1.80795730e-01],\n",
       "       [5.06309730e-05, 1.29341640e-04, 9.99820050e-01],\n",
       "       [5.29056850e-01, 4.56786800e-01, 1.41563230e-02],\n",
       "       [6.71011600e-01, 2.88135080e-01, 4.08533330e-02],\n",
       "       [3.16868570e-02, 1.85836850e-01, 7.82476250e-01],\n",
       "       [9.58110500e-01, 3.65353750e-02, 5.35410830e-03],\n",
       "       [8.54402000e-01, 5.03965130e-02, 9.52015100e-02],\n",
       "       [4.24400540e-01, 1.48415150e-01, 4.27184300e-01],\n",
       "       [1.67017620e-03, 9.90069700e-01, 8.26010600e-03],\n",
       "       [4.37042380e-02, 1.87924110e-02, 9.37503300e-01],\n",
       "       [8.75036500e-03, 3.77666970e-03, 9.87473000e-01],\n",
       "       [8.83995650e-01, 8.85637500e-02, 2.74405650e-02],\n",
       "       [3.06857410e-02, 7.77249930e-01, 1.92064390e-01],\n",
       "       [7.38556440e-01, 1.05660416e-01, 1.55783160e-01],\n",
       "       [7.37912900e-01, 2.06859410e-01, 5.52276450e-02],\n",
       "       [9.41443800e-01, 3.59963630e-02, 2.25597700e-02],\n",
       "       [9.99383570e-01, 3.00871500e-06, 6.13475330e-04],\n",
       "       [9.57975800e-09, 2.01079640e-10, 1.00000000e+00],\n",
       "       [3.73144330e-01, 6.25452400e-01, 1.40325740e-03],\n",
       "       [9.76009800e-01, 1.37664240e-02, 1.02236870e-02],\n",
       "       [6.72251200e-01, 2.47504790e-01, 8.02439450e-02],\n",
       "       [1.66999700e-02, 9.72865000e-01, 1.04350080e-02],\n",
       "       [8.19560000e-03, 2.39254370e-03, 9.89411900e-01]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380608809180238"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380608809180238"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat7['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test\n",
       "222    NRS271     1\n",
       "242    SR2852     2\n",
       "34       CA39     2\n",
       "221    NRS266     1\n",
       "230     NY356     2\n",
       "..        ...   ...\n",
       "105     MN055     2\n",
       "67   CFBRSa04     0\n",
       "235    SR1065     0\n",
       "190    NRS224     1\n",
       "178    NRS210     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 822us/step - loss: 8.4130 - accuracy: 0.3503 - val_loss: 7.1595 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 7.0588 - accuracy: 0.4124 - val_loss: 6.2712 - val_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 5.6857 - accuracy: 0.4520 - val_loss: 5.4865 - val_accuracy: 0.3684\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 4.6552 - accuracy: 0.4181 - val_loss: 4.7701 - val_accuracy: 0.4079\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 3.6774 - accuracy: 0.4463 - val_loss: 4.1792 - val_accuracy: 0.3816\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 2.7574 - accuracy: 0.4576 - val_loss: 3.7470 - val_accuracy: 0.3816\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 2.2263 - accuracy: 0.4633 - val_loss: 3.7958 - val_accuracy: 0.3816\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 2.2687 - accuracy: 0.4802 - val_loss: 3.7442 - val_accuracy: 0.3816\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 2.1590 - accuracy: 0.4689 - val_loss: 3.4158 - val_accuracy: 0.3684\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 1.9411 - accuracy: 0.4915 - val_loss: 2.9017 - val_accuracy: 0.3684\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 1.6572 - accuracy: 0.5085 - val_loss: 2.2772 - val_accuracy: 0.3816\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 1.3556 - accuracy: 0.5085 - val_loss: 1.9151 - val_accuracy: 0.4079\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 1.2787 - accuracy: 0.5085 - val_loss: 1.7563 - val_accuracy: 0.4342\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 1.2257 - accuracy: 0.5198 - val_loss: 1.5794 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 1.1011 - accuracy: 0.5537 - val_loss: 1.5070 - val_accuracy: 0.3947\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 1.0281 - accuracy: 0.5480 - val_loss: 1.5127 - val_accuracy: 0.3947\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 1.0157 - accuracy: 0.5480 - val_loss: 1.4329 - val_accuracy: 0.4079\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.9913 - accuracy: 0.5537 - val_loss: 1.3143 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.9740 - accuracy: 0.5650 - val_loss: 1.2538 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.9266 - accuracy: 0.5989 - val_loss: 1.2642 - val_accuracy: 0.4079\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8898 - accuracy: 0.5819 - val_loss: 1.3263 - val_accuracy: 0.4211\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.8756 - accuracy: 0.6102 - val_loss: 1.3389 - val_accuracy: 0.4474\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.8549 - accuracy: 0.6215 - val_loss: 1.2917 - val_accuracy: 0.4868\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8354 - accuracy: 0.6215 - val_loss: 1.2731 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.8138 - accuracy: 0.6158 - val_loss: 1.2373 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.7936 - accuracy: 0.6384 - val_loss: 1.2069 - val_accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.7788 - accuracy: 0.6328 - val_loss: 1.1927 - val_accuracy: 0.4342\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.7594 - accuracy: 0.6497 - val_loss: 1.1889 - val_accuracy: 0.4342\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.7517 - accuracy: 0.6497 - val_loss: 1.1989 - val_accuracy: 0.4474\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.7297 - accuracy: 0.6893 - val_loss: 1.2618 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.7314 - accuracy: 0.6893 - val_loss: 1.2187 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.7031 - accuracy: 0.6667 - val_loss: 1.1589 - val_accuracy: 0.4605\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.7021 - accuracy: 0.6780 - val_loss: 1.1653 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6780 - accuracy: 0.6893 - val_loss: 1.2704 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.6784 - accuracy: 0.7175 - val_loss: 1.3026 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.6677 - accuracy: 0.7401 - val_loss: 1.2059 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.6516 - accuracy: 0.7401 - val_loss: 1.2243 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.6367 - accuracy: 0.7458 - val_loss: 1.2202 - val_accuracy: 0.4868\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6256 - accuracy: 0.7514 - val_loss: 1.1801 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6124 - accuracy: 0.7797 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.6066 - accuracy: 0.7910 - val_loss: 1.2341 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.5990 - accuracy: 0.7514 - val_loss: 1.2657 - val_accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5840 - accuracy: 0.7853 - val_loss: 1.1998 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.5773 - accuracy: 0.8079 - val_loss: 1.2027 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.5652 - accuracy: 0.7853 - val_loss: 1.2903 - val_accuracy: 0.4868\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.5574 - accuracy: 0.7740 - val_loss: 1.2880 - val_accuracy: 0.4737\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5407 - accuracy: 0.8192 - val_loss: 1.1904 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.5396 - accuracy: 0.8249 - val_loss: 1.2049 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5237 - accuracy: 0.8079 - val_loss: 1.3210 - val_accuracy: 0.4868\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.5254 - accuracy: 0.8192 - val_loss: 1.3147 - val_accuracy: 0.4868\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.5093 - accuracy: 0.8079 - val_loss: 1.2366 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.5083 - accuracy: 0.8305 - val_loss: 1.2251 - val_accuracy: 0.5132\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.4820 - accuracy: 0.8588 - val_loss: 1.3655 - val_accuracy: 0.4737\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.4917 - accuracy: 0.8249 - val_loss: 1.3824 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.4795 - accuracy: 0.8305 - val_loss: 1.2930 - val_accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.4584 - accuracy: 0.8588 - val_loss: 1.2264 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4702 - accuracy: 0.8475 - val_loss: 1.2733 - val_accuracy: 0.4737\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4638 - accuracy: 0.8475 - val_loss: 1.4268 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.4563 - accuracy: 0.8475 - val_loss: 1.3689 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.4270 - accuracy: 0.8531 - val_loss: 1.2992 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4189 - accuracy: 0.8701 - val_loss: 1.2954 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4247 - accuracy: 0.8814 - val_loss: 1.3272 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.4092 - accuracy: 0.8701 - val_loss: 1.4068 - val_accuracy: 0.4211\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4023 - accuracy: 0.8588 - val_loss: 1.4112 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3947 - accuracy: 0.8701 - val_loss: 1.3936 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3853 - accuracy: 0.8927 - val_loss: 1.3843 - val_accuracy: 0.4079\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3874 - accuracy: 0.8870 - val_loss: 1.3978 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.3710 - accuracy: 0.8927 - val_loss: 1.3903 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.3776 - accuracy: 0.8814 - val_loss: 1.4390 - val_accuracy: 0.4474\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.3716 - accuracy: 0.8701 - val_loss: 1.4842 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.3644 - accuracy: 0.8814 - val_loss: 1.3956 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3522 - accuracy: 0.9040 - val_loss: 1.3734 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.3546 - accuracy: 0.8757 - val_loss: 1.4736 - val_accuracy: 0.4474\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.3430 - accuracy: 0.8701 - val_loss: 1.4873 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.3373 - accuracy: 0.8701 - val_loss: 1.4139 - val_accuracy: 0.4079\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.3313 - accuracy: 0.9153 - val_loss: 1.4143 - val_accuracy: 0.4474\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.3191 - accuracy: 0.9040 - val_loss: 1.5708 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.3222 - accuracy: 0.8814 - val_loss: 1.5379 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.3121 - accuracy: 0.9040 - val_loss: 1.4321 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.3100 - accuracy: 0.9153 - val_loss: 1.4320 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2997 - accuracy: 0.9266 - val_loss: 1.5042 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2968 - accuracy: 0.8983 - val_loss: 1.5239 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.2933 - accuracy: 0.9096 - val_loss: 1.4863 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2876 - accuracy: 0.9153 - val_loss: 1.4554 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2840 - accuracy: 0.9266 - val_loss: 1.4970 - val_accuracy: 0.4342\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.2785 - accuracy: 0.9096 - val_loss: 1.5696 - val_accuracy: 0.4474\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2729 - accuracy: 0.8983 - val_loss: 1.5310 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2739 - accuracy: 0.9209 - val_loss: 1.5138 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2681 - accuracy: 0.9209 - val_loss: 1.5688 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.2619 - accuracy: 0.9096 - val_loss: 1.5383 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2585 - accuracy: 0.9266 - val_loss: 1.4887 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2645 - accuracy: 0.9322 - val_loss: 1.5739 - val_accuracy: 0.4342\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2542 - accuracy: 0.9096 - val_loss: 1.5932 - val_accuracy: 0.4342\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2419 - accuracy: 0.9322 - val_loss: 1.5459 - val_accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2427 - accuracy: 0.9322 - val_loss: 1.5428 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.2379 - accuracy: 0.9322 - val_loss: 1.5949 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2319 - accuracy: 0.9322 - val_loss: 1.6071 - val_accuracy: 0.4474\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.2317 - accuracy: 0.9266 - val_loss: 1.5860 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.2255 - accuracy: 0.9266 - val_loss: 1.5491 - val_accuracy: 0.4474\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2285 - accuracy: 0.9209 - val_loss: 1.5954 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a43e5d160>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 73us/step\n",
      "test accuracy: 46.05%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel3 = model_sel3.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 0, 0, 1, 2, 2, 1, 2, 1, 2, 0, 1, 1, 2, 1, 1, 2, 2, 1,\n",
       "       0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 1, 2, 0, 1, 0, 2, 2, 2, 1, 0,\n",
       "       2, 0, 1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2,\n",
       "       2, 0, 1, 0, 0, 2, 0, 0, 2, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model_sel3.predict_classes(X_sel_test)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test  pred\n",
       "222    NRS271     1     1\n",
       "242    SR2852     2     2\n",
       "34       CA39     2     1\n",
       "221    NRS266     1     2\n",
       "230     NY356     2     0\n",
       "..        ...   ...   ...\n",
       "105     MN055     2     2\n",
       "67   CFBRSa04     0     0\n",
       "235    SR1065     0     0\n",
       "190    NRS224     1     2\n",
       "178    NRS210     2     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model_sel3.predict_proba(X_sel_test)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120862</td>\n",
       "      <td>0.863844</td>\n",
       "      <td>0.015294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.402346</td>\n",
       "      <td>0.582797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.611152</td>\n",
       "      <td>0.364908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156154</td>\n",
       "      <td>0.340488</td>\n",
       "      <td>0.503358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592273</td>\n",
       "      <td>0.380877</td>\n",
       "      <td>0.026850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.041429</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.932085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.940746</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.003387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.869274</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.094076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.289750</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.710240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.054696</td>\n",
       "      <td>0.596255</td>\n",
       "      <td>0.349050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.120862  0.863844  0.015294\n",
       "1   0.014857  0.402346  0.582797\n",
       "2   0.023940  0.611152  0.364908\n",
       "3   0.156154  0.340488  0.503358\n",
       "4   0.592273  0.380877  0.026850\n",
       "..       ...       ...       ...\n",
       "71  0.041429  0.026486  0.932085\n",
       "72  0.940746  0.055868  0.003387\n",
       "73  0.869274  0.036650  0.094076\n",
       "74  0.289750  0.000010  0.710240\n",
       "75  0.054696  0.596255  0.349050\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2622 - accuracy: 0.9322 - val_loss: 1.4312 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2570 - accuracy: 0.9435 - val_loss: 1.4700 - val_accuracy: 0.4868\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2531 - accuracy: 0.9379 - val_loss: 1.5152 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2454 - accuracy: 0.9435 - val_loss: 1.4860 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2447 - accuracy: 0.9548 - val_loss: 1.4758 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.2385 - accuracy: 0.9435 - val_loss: 1.5136 - val_accuracy: 0.5132\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2363 - accuracy: 0.9492 - val_loss: 1.5478 - val_accuracy: 0.5132\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2321 - accuracy: 0.9492 - val_loss: 1.5341 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.2268 - accuracy: 0.9605 - val_loss: 1.5128 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2244 - accuracy: 0.9605 - val_loss: 1.5239 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2188 - accuracy: 0.9605 - val_loss: 1.5365 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2156 - accuracy: 0.9548 - val_loss: 1.5904 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.2127 - accuracy: 0.9605 - val_loss: 1.5840 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2078 - accuracy: 0.9548 - val_loss: 1.5652 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.2032 - accuracy: 0.9548 - val_loss: 1.5704 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.2005 - accuracy: 0.9548 - val_loss: 1.5914 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2016 - accuracy: 0.9605 - val_loss: 1.5784 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1957 - accuracy: 0.9718 - val_loss: 1.6235 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1960 - accuracy: 0.9605 - val_loss: 1.5836 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1882 - accuracy: 0.9548 - val_loss: 1.6281 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1872 - accuracy: 0.9661 - val_loss: 1.6165 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.1854 - accuracy: 0.9661 - val_loss: 1.6288 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1804 - accuracy: 0.9718 - val_loss: 1.6642 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1758 - accuracy: 0.9661 - val_loss: 1.6047 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1745 - accuracy: 0.9718 - val_loss: 1.7484 - val_accuracy: 0.4868\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1878 - accuracy: 0.9548 - val_loss: 1.6923 - val_accuracy: 0.4868\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1782 - accuracy: 0.9661 - val_loss: 1.5301 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2437 - accuracy: 0.9435 - val_loss: 2.2093 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.2864 - accuracy: 0.8983 - val_loss: 1.9674 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2069 - accuracy: 0.9379 - val_loss: 1.6007 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1998 - accuracy: 0.9548 - val_loss: 1.7492 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1956 - accuracy: 0.9322 - val_loss: 1.8759 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1762 - accuracy: 0.9435 - val_loss: 1.8378 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1767 - accuracy: 0.9435 - val_loss: 1.7630 - val_accuracy: 0.5132\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1655 - accuracy: 0.9718 - val_loss: 1.7318 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1615 - accuracy: 0.9661 - val_loss: 1.7619 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1518 - accuracy: 0.9605 - val_loss: 1.7906 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1532 - accuracy: 0.9605 - val_loss: 1.8838 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.1472 - accuracy: 0.9661 - val_loss: 1.8390 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1447 - accuracy: 0.9718 - val_loss: 1.7603 - val_accuracy: 0.5263\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1465 - accuracy: 0.9605 - val_loss: 1.9510 - val_accuracy: 0.4868\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1425 - accuracy: 0.9661 - val_loss: 1.9323 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1366 - accuracy: 0.9718 - val_loss: 1.7640 - val_accuracy: 0.5132\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1363 - accuracy: 0.9831 - val_loss: 1.8367 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1328 - accuracy: 0.9774 - val_loss: 1.9497 - val_accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1289 - accuracy: 0.9718 - val_loss: 1.8719 - val_accuracy: 0.5263\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1254 - accuracy: 0.9774 - val_loss: 1.8207 - val_accuracy: 0.5132\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.1234 - accuracy: 0.9774 - val_loss: 1.8526 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1258 - accuracy: 0.9718 - val_loss: 1.9061 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1198 - accuracy: 0.9774 - val_loss: 1.8757 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1168 - accuracy: 0.9774 - val_loss: 1.8883 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1146 - accuracy: 0.9831 - val_loss: 1.9336 - val_accuracy: 0.5263\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1153 - accuracy: 0.9831 - val_loss: 1.9332 - val_accuracy: 0.5263\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1128 - accuracy: 0.9774 - val_loss: 1.8825 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1093 - accuracy: 0.9774 - val_loss: 1.9191 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1101 - accuracy: 0.9774 - val_loss: 1.9859 - val_accuracy: 0.5263\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.1079 - accuracy: 0.9774 - val_loss: 1.9692 - val_accuracy: 0.5132\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1099 - accuracy: 0.9831 - val_loss: 1.9001 - val_accuracy: 0.5132\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1058 - accuracy: 0.9774 - val_loss: 1.9419 - val_accuracy: 0.4737\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1035 - accuracy: 0.9831 - val_loss: 1.9736 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.1007 - accuracy: 0.9831 - val_loss: 1.9732 - val_accuracy: 0.5263\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1020 - accuracy: 0.9774 - val_loss: 1.9881 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0984 - accuracy: 0.9831 - val_loss: 1.9591 - val_accuracy: 0.4868\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.0971 - accuracy: 0.9774 - val_loss: 1.9997 - val_accuracy: 0.4868\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.1005 - accuracy: 0.9831 - val_loss: 2.0123 - val_accuracy: 0.4868\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0929 - accuracy: 0.9887 - val_loss: 1.9731 - val_accuracy: 0.5263\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0952 - accuracy: 0.9831 - val_loss: 1.9688 - val_accuracy: 0.5263\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.0974 - accuracy: 0.9831 - val_loss: 2.0051 - val_accuracy: 0.5395\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.0933 - accuracy: 0.9718 - val_loss: 2.0252 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0941 - accuracy: 0.9831 - val_loss: 2.0066 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.0906 - accuracy: 0.9831 - val_loss: 1.9973 - val_accuracy: 0.5132\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.0897 - accuracy: 0.9774 - val_loss: 2.0068 - val_accuracy: 0.5132\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0885 - accuracy: 0.9831 - val_loss: 2.0179 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.0865 - accuracy: 0.9887 - val_loss: 2.0206 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0876 - accuracy: 0.9831 - val_loss: 2.0346 - val_accuracy: 0.5263\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.0868 - accuracy: 0.9774 - val_loss: 2.0343 - val_accuracy: 0.5132\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0873 - accuracy: 0.9774 - val_loss: 2.0166 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.0845 - accuracy: 0.9774 - val_loss: 2.0387 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.0841 - accuracy: 0.9831 - val_loss: 2.0758 - val_accuracy: 0.5132\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.0804 - accuracy: 0.9831 - val_loss: 2.0605 - val_accuracy: 0.5132\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0864 - accuracy: 0.9831 - val_loss: 2.0470 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0805 - accuracy: 0.9887 - val_loss: 2.0709 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.0860 - accuracy: 0.9887 - val_loss: 2.0537 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.0895 - accuracy: 0.9718 - val_loss: 2.0880 - val_accuracy: 0.5395\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.0823 - accuracy: 0.9831 - val_loss: 2.1478 - val_accuracy: 0.5263\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.0814 - accuracy: 0.9774 - val_loss: 2.1389 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.0778 - accuracy: 0.9887 - val_loss: 2.0737 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.0766 - accuracy: 0.9887 - val_loss: 2.0476 - val_accuracy: 0.5526\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.0775 - accuracy: 0.9887 - val_loss: 2.0944 - val_accuracy: 0.5132\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0780 - accuracy: 0.9774 - val_loss: 2.1570 - val_accuracy: 0.5132\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.0746 - accuracy: 0.9831 - val_loss: 2.0988 - val_accuracy: 0.5132\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.0732 - accuracy: 0.9887 - val_loss: 2.0922 - val_accuracy: 0.5395\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.0760 - accuracy: 0.9831 - val_loss: 2.1704 - val_accuracy: 0.5263\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.0726 - accuracy: 0.9831 - val_loss: 2.1973 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.0727 - accuracy: 0.9887 - val_loss: 2.1406 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0727 - accuracy: 0.9831 - val_loss: 2.0798 - val_accuracy: 0.5263\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.0722 - accuracy: 0.9831 - val_loss: 2.1286 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.0729 - accuracy: 0.9887 - val_loss: 2.2107 - val_accuracy: 0.5263\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.0723 - accuracy: 0.9831 - val_loss: 2.2421 - val_accuracy: 0.5263\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 1.00 - 0s 92us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 2.2164 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist_sel3 = model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.02%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.411991</td>\n",
       "      <td>0.578852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual       NRS271          1           0  0.854929   \n",
       "1       p0017kpresabs_qual       SR2852          2           2  0.000001   \n",
       "2       p0017kpresabs_qual         CA39          2           0  0.959992   \n",
       "3       p0017kpresabs_qual       NRS266          1           2  0.000018   \n",
       "4       p0017kpresabs_qual        NY356          2           2  0.009156   \n",
       "..                     ...          ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa110          2           2  0.044135   \n",
       "604  p0040presabsSTCC_qual     CFBRSa05          0           2  0.145032   \n",
       "605  p0040presabsSTCC_qual  CFBREBSa123          0           0  0.994623   \n",
       "606  p0040presabsSTCC_qual        NY360          1           1  0.000795   \n",
       "607  p0040presabsSTCC_qual  CFBREBSa118          2           1  0.000029   \n",
       "\n",
       "            1         2  \n",
       "0    0.144940  0.000130  \n",
       "1    0.000075  0.999923  \n",
       "2    0.013406  0.026602  \n",
       "3    0.000003  0.999980  \n",
       "4    0.411991  0.578852  \n",
       "..        ...       ...  \n",
       "603  0.010244  0.945621  \n",
       "604  0.408530  0.446439  \n",
       "605  0.004152  0.001224  \n",
       "606  0.948566  0.050639  \n",
       "607  0.999037  0.000934  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2086153e-01, 8.6384410e-01, 1.5294372e-02],\n",
       "       [1.4856748e-02, 4.0234596e-01, 5.8279730e-01],\n",
       "       [2.3940066e-02, 6.1115150e-01, 3.6490850e-01],\n",
       "       [1.5615402e-01, 3.4048802e-01, 5.0335795e-01],\n",
       "       [5.9227330e-01, 3.8087663e-01, 2.6850142e-02],\n",
       "       [9.7391200e-01, 5.5985650e-03, 2.0489430e-02],\n",
       "       [1.0621916e-02, 8.7807080e-01, 1.1130733e-01],\n",
       "       [7.9336450e-02, 2.4120276e-01, 6.7946076e-01],\n",
       "       [9.8634504e-02, 4.0473092e-01, 4.9663457e-01],\n",
       "       [6.6578540e-02, 9.3153780e-01, 1.8835821e-03],\n",
       "       [2.5920755e-01, 4.2917213e-04, 7.4036330e-01],\n",
       "       [2.4300893e-01, 4.9691424e-01, 2.6007676e-01],\n",
       "       [4.3629950e-04, 4.4810330e-02, 9.5475334e-01],\n",
       "       [6.8063915e-01, 3.2407406e-03, 3.1612010e-01],\n",
       "       [1.1110698e-01, 8.7137514e-01, 1.7517816e-02],\n",
       "       [2.5254510e-01, 4.3542585e-01, 3.1202910e-01],\n",
       "       [2.4866147e-02, 2.3286150e-02, 9.5184770e-01],\n",
       "       [4.2241812e-01, 4.3617767e-01, 1.4140424e-01],\n",
       "       [2.1103641e-02, 7.7953494e-01, 1.9936149e-01],\n",
       "       [1.6937343e-03, 2.8948510e-02, 9.6935780e-01],\n",
       "       [1.0778592e-02, 5.3471210e-04, 9.8868670e-01],\n",
       "       [4.1716823e-01, 5.7699560e-01, 5.8361110e-03],\n",
       "       [8.0739980e-01, 1.3583852e-01, 5.6761637e-02],\n",
       "       [6.9037360e-01, 2.4956457e-01, 6.0061890e-02],\n",
       "       [4.8509628e-01, 4.7418678e-01, 4.0716887e-02],\n",
       "       [2.4464140e-02, 3.6971986e-05, 9.7549890e-01],\n",
       "       [6.7935824e-01, 3.0700073e-01, 1.3641108e-02],\n",
       "       [9.4987893e-01, 4.5194930e-02, 4.9261916e-03],\n",
       "       [2.9428768e-01, 3.8374728e-01, 3.2196510e-01],\n",
       "       [3.1460002e-01, 1.9084328e-01, 4.9455673e-01],\n",
       "       [8.9987640e-02, 9.0927523e-01, 7.3711860e-04],\n",
       "       [9.3190956e-01, 6.0030260e-02, 8.0601530e-03],\n",
       "       [6.6440780e-01, 2.8458780e-01, 5.1004436e-02],\n",
       "       [1.4944988e-01, 3.2848870e-01, 5.2206147e-01],\n",
       "       [3.0604811e-02, 8.2026035e-01, 1.4913489e-01],\n",
       "       [3.4740686e-02, 2.4646702e-03, 9.6279460e-01],\n",
       "       [7.2234590e-01, 6.6686930e-02, 2.1096715e-01],\n",
       "       [1.5276214e-01, 4.3665750e-01, 4.1058034e-01],\n",
       "       [9.6434800e-01, 3.2938737e-02, 2.7132987e-03],\n",
       "       [2.9059171e-03, 1.0581064e-02, 9.8651296e-01],\n",
       "       [2.7788240e-01, 9.8669510e-06, 7.2210780e-01],\n",
       "       [2.9676008e-05, 1.4376537e-02, 9.8559386e-01],\n",
       "       [1.8078783e-03, 7.7471540e-01, 2.2347666e-01],\n",
       "       [7.7953830e-01, 1.9931903e-01, 2.1142780e-02],\n",
       "       [5.3320322e-02, 2.7633190e-02, 9.1904650e-01],\n",
       "       [9.6467364e-01, 6.4422770e-03, 2.8884096e-02],\n",
       "       [4.3228020e-01, 5.0514190e-01, 6.2577910e-02],\n",
       "       [5.2452934e-01, 4.2091534e-01, 5.4555397e-02],\n",
       "       [9.7878164e-01, 1.7893992e-04, 2.1039406e-02],\n",
       "       [2.6004127e-05, 2.5052802e-07, 9.9997380e-01],\n",
       "       [2.8309283e-01, 6.1289230e-01, 1.0401479e-01],\n",
       "       [6.0750735e-05, 2.1180242e-02, 9.7875905e-01],\n",
       "       [2.9573658e-02, 7.7565745e-02, 8.9286053e-01],\n",
       "       [9.7036920e-01, 2.6108969e-02, 3.5217314e-03],\n",
       "       [6.5433073e-01, 3.4213778e-01, 3.5314756e-03],\n",
       "       [7.1354600e-01, 2.4710068e-01, 3.9353266e-02],\n",
       "       [8.1023747e-01, 3.9264068e-02, 1.5049839e-01],\n",
       "       [1.1627806e-03, 9.9840075e-01, 4.3643130e-04],\n",
       "       [3.9887540e-01, 1.9915620e-01, 4.0196848e-01],\n",
       "       [5.8666322e-02, 3.0963877e-01, 6.3169490e-01],\n",
       "       [8.3435110e-02, 3.0291677e-02, 8.8627320e-01],\n",
       "       [2.6486015e-03, 1.2375203e-01, 8.7359940e-01],\n",
       "       [6.0776080e-01, 3.2511425e-01, 6.7124980e-02],\n",
       "       [4.3410338e-03, 1.4239272e-01, 8.5326624e-01],\n",
       "       [7.7815354e-01, 1.6628465e-01, 5.5561814e-02],\n",
       "       [7.6422250e-02, 5.2842986e-02, 8.7073475e-01],\n",
       "       [2.1467113e-01, 3.8305092e-01, 4.0227795e-01],\n",
       "       [9.9154120e-01, 4.7043525e-03, 3.7543622e-03],\n",
       "       [3.5281240e-01, 6.0757667e-01, 3.9610945e-02],\n",
       "       [6.3780920e-01, 3.0178615e-01, 6.0404617e-02],\n",
       "       [9.3426600e-01, 1.5194512e-03, 6.4214530e-02],\n",
       "       [4.1428670e-02, 2.6486117e-02, 9.3208516e-01],\n",
       "       [9.4074553e-01, 5.5867683e-02, 3.3867676e-03],\n",
       "       [8.6927444e-01, 3.6649555e-02, 9.4075950e-02],\n",
       "       [2.8974968e-01, 1.0381684e-05, 7.1023995e-01],\n",
       "       [5.4695570e-02, 5.9625490e-01, 3.4904950e-01]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571210975972881"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571210975972881"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat8['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "131       NRS104     0\n",
       "123       NRS071     0\n",
       "124       NRS072     1\n",
       "27     BCH-SA-12     0\n",
       "57   CFBREBSa125     2\n",
       "..           ...   ...\n",
       "170       NRS199     2\n",
       "32          CA11     2\n",
       "212       NRS253     1\n",
       "141       NRS119     2\n",
       "126       NRS074     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 754us/step - loss: 2.4099 - accuracy: 0.3785 - val_loss: 1.2550 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 1.4272 - accuracy: 0.3898 - val_loss: 1.3649 - val_accuracy: 0.3684\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 1.1568 - accuracy: 0.4915 - val_loss: 1.1453 - val_accuracy: 0.4605\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 1.0748 - accuracy: 0.4915 - val_loss: 1.0719 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 1.0663 - accuracy: 0.4746 - val_loss: 1.0592 - val_accuracy: 0.4342\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 1.0389 - accuracy: 0.5311 - val_loss: 1.0515 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 1.0041 - accuracy: 0.5763 - val_loss: 1.0355 - val_accuracy: 0.4342\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 1.0238 - accuracy: 0.5876 - val_loss: 1.0141 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.9695 - accuracy: 0.5932 - val_loss: 1.1080 - val_accuracy: 0.5526\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.9806 - accuracy: 0.5876 - val_loss: 1.0119 - val_accuracy: 0.4737\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 1.0201 - accuracy: 0.5819 - val_loss: 1.2415 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.9086 - accuracy: 0.6158 - val_loss: 1.1076 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.9437 - accuracy: 0.6158 - val_loss: 1.0287 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.8261 - accuracy: 0.6667 - val_loss: 1.0358 - val_accuracy: 0.4868\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.8632 - accuracy: 0.6554 - val_loss: 1.0585 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.8312 - accuracy: 0.6384 - val_loss: 1.0202 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.8041 - accuracy: 0.6610 - val_loss: 0.9987 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.7890 - accuracy: 0.6667 - val_loss: 1.1141 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.7676 - accuracy: 0.6667 - val_loss: 0.9964 - val_accuracy: 0.5263\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.7350 - accuracy: 0.6723 - val_loss: 0.9857 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.7719 - accuracy: 0.6780 - val_loss: 1.0414 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.7622 - accuracy: 0.6780 - val_loss: 0.9865 - val_accuracy: 0.5526\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7258 - accuracy: 0.7006 - val_loss: 1.0304 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.6856 - accuracy: 0.7062 - val_loss: 0.9961 - val_accuracy: 0.5658\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.7111 - accuracy: 0.6780 - val_loss: 1.0428 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7029 - accuracy: 0.7062 - val_loss: 1.0021 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.6560 - accuracy: 0.7458 - val_loss: 1.0174 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6803 - accuracy: 0.7288 - val_loss: 1.0092 - val_accuracy: 0.5263\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.6420 - accuracy: 0.7345 - val_loss: 1.0115 - val_accuracy: 0.5263\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.6316 - accuracy: 0.7458 - val_loss: 1.0202 - val_accuracy: 0.5132\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.6148 - accuracy: 0.7514 - val_loss: 0.9951 - val_accuracy: 0.5789\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.6424 - accuracy: 0.7232 - val_loss: 1.0224 - val_accuracy: 0.5395\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6401 - accuracy: 0.7345 - val_loss: 1.1222 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.6395 - accuracy: 0.7627 - val_loss: 1.0254 - val_accuracy: 0.5789\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7111 - accuracy: 0.8079 - val_loss: 1.0713 - val_accuracy: 0.5658\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.6176 - accuracy: 0.7571 - val_loss: 1.1491 - val_accuracy: 0.5526\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.5701 - accuracy: 0.7797 - val_loss: 1.2057 - val_accuracy: 0.4868\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6727 - accuracy: 0.7853 - val_loss: 1.0667 - val_accuracy: 0.5395\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.5559 - accuracy: 0.7966 - val_loss: 1.1947 - val_accuracy: 0.5132\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.6133 - accuracy: 0.8023 - val_loss: 1.1584 - val_accuracy: 0.4868\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.5861 - accuracy: 0.8079 - val_loss: 1.0484 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.5034 - accuracy: 0.8079 - val_loss: 1.1253 - val_accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.5147 - accuracy: 0.8023 - val_loss: 1.0520 - val_accuracy: 0.5395\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.5151 - accuracy: 0.8305 - val_loss: 1.0833 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.4839 - accuracy: 0.8475 - val_loss: 1.0711 - val_accuracy: 0.5395\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.4775 - accuracy: 0.8475 - val_loss: 1.1289 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5225 - accuracy: 0.8079 - val_loss: 1.1640 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.4787 - accuracy: 0.8249 - val_loss: 1.0858 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.4920 - accuracy: 0.8701 - val_loss: 1.0735 - val_accuracy: 0.5395\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.4717 - accuracy: 0.8701 - val_loss: 1.1448 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4394 - accuracy: 0.8701 - val_loss: 1.1451 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.4625 - accuracy: 0.8531 - val_loss: 1.2067 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.4525 - accuracy: 0.8644 - val_loss: 1.1222 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.4853 - accuracy: 0.8475 - val_loss: 1.1305 - val_accuracy: 0.5789\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.4234 - accuracy: 0.8588 - val_loss: 1.3866 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.5727 - accuracy: 0.8531 - val_loss: 1.2880 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.4423 - accuracy: 0.8644 - val_loss: 1.1404 - val_accuracy: 0.5526\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.4103 - accuracy: 0.8644 - val_loss: 1.1842 - val_accuracy: 0.5395\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.3671 - accuracy: 0.8927 - val_loss: 1.1730 - val_accuracy: 0.5526\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.4577 - accuracy: 0.8757 - val_loss: 1.1938 - val_accuracy: 0.5658\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.3544 - accuracy: 0.8870 - val_loss: 1.3491 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.4367 - accuracy: 0.8531 - val_loss: 1.2434 - val_accuracy: 0.5526\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.3645 - accuracy: 0.8870 - val_loss: 1.2038 - val_accuracy: 0.5526\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.4052 - accuracy: 0.8983 - val_loss: 1.2264 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.4017 - accuracy: 0.8814 - val_loss: 1.3791 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3583 - accuracy: 0.8870 - val_loss: 1.1952 - val_accuracy: 0.5921\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3694 - accuracy: 0.8870 - val_loss: 1.2917 - val_accuracy: 0.5263\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.3805 - accuracy: 0.8927 - val_loss: 1.2913 - val_accuracy: 0.5263\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3161 - accuracy: 0.9209 - val_loss: 1.2516 - val_accuracy: 0.5526\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.3219 - accuracy: 0.9209 - val_loss: 1.3022 - val_accuracy: 0.6053\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.3228 - accuracy: 0.9040 - val_loss: 1.3625 - val_accuracy: 0.5132\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.3580 - accuracy: 0.8983 - val_loss: 1.2671 - val_accuracy: 0.5395\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.3396 - accuracy: 0.9266 - val_loss: 1.3399 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.4010 - accuracy: 0.8701 - val_loss: 1.5668 - val_accuracy: 0.5132\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.3736 - accuracy: 0.8757 - val_loss: 1.3000 - val_accuracy: 0.5789\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.4517 - accuracy: 0.8983 - val_loss: 1.3330 - val_accuracy: 0.5789\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.3359 - accuracy: 0.8927 - val_loss: 1.4769 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.3372 - accuracy: 0.9040 - val_loss: 1.3855 - val_accuracy: 0.5658\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.3088 - accuracy: 0.8814 - val_loss: 1.3351 - val_accuracy: 0.5395\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.2971 - accuracy: 0.9209 - val_loss: 1.3521 - val_accuracy: 0.6053\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.3455 - accuracy: 0.8927 - val_loss: 1.3812 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.2824 - accuracy: 0.9209 - val_loss: 1.3557 - val_accuracy: 0.5789\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.2862 - accuracy: 0.9379 - val_loss: 1.3755 - val_accuracy: 0.5658\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3275 - accuracy: 0.9096 - val_loss: 1.5087 - val_accuracy: 0.5789\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.2839 - accuracy: 0.9040 - val_loss: 1.3885 - val_accuracy: 0.5526\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.2506 - accuracy: 0.9322 - val_loss: 1.3475 - val_accuracy: 0.5921\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.2574 - accuracy: 0.9322 - val_loss: 1.4015 - val_accuracy: 0.5263\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.3668 - accuracy: 0.9153 - val_loss: 1.6364 - val_accuracy: 0.5526\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.4307 - accuracy: 0.8983 - val_loss: 1.4281 - val_accuracy: 0.5789\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4583 - accuracy: 0.8927 - val_loss: 1.4757 - val_accuracy: 0.5789\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.3045 - accuracy: 0.9153 - val_loss: 1.6118 - val_accuracy: 0.6184\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.3425 - accuracy: 0.9153 - val_loss: 1.4704 - val_accuracy: 0.5526\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.2787 - accuracy: 0.9322 - val_loss: 1.4534 - val_accuracy: 0.5921\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2965 - accuracy: 0.8870 - val_loss: 1.5783 - val_accuracy: 0.5789\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.2668 - accuracy: 0.9153 - val_loss: 1.5474 - val_accuracy: 0.5395\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.2411 - accuracy: 0.9266 - val_loss: 1.4771 - val_accuracy: 0.5658\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2446 - accuracy: 0.9322 - val_loss: 1.5201 - val_accuracy: 0.5395\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2375 - accuracy: 0.9548 - val_loss: 1.4809 - val_accuracy: 0.5658\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2109 - accuracy: 0.9548 - val_loss: 1.5083 - val_accuracy: 0.5921\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2408 - accuracy: 0.9379 - val_loss: 1.5591 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a444f1898>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 175us/step\n",
      "over-sampling test accuracy: 57.89%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel4 = model_sel4.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.210638e-02</td>\n",
       "      <td>0.917809</td>\n",
       "      <td>8.477923e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015229e-02</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>7.345203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.642946e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.963547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.809318e-03</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>8.980029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875667e-01</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>4.237761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual       NRS104          0           1  8.210638e-02   \n",
       "1       p0017kpresabs_qual       NRS071          0           2  1.015229e-02   \n",
       "2       p0017kpresabs_qual       NRS072          1           2  3.642946e-03   \n",
       "3       p0017kpresabs_qual    BCH-SA-12          0           2  2.809318e-03   \n",
       "4       p0017kpresabs_qual  CFBREBSa125          2           0  4.875667e-01   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual       NRS113          1           2  2.686909e-07   \n",
       "604  p0040presabsSTCC_qual    BCH-SA-09          2           1  5.529492e-07   \n",
       "605  p0040presabsSTCC_qual       NRS106          2           1  1.115902e-03   \n",
       "606  p0040presabsSTCC_qual  CFBREBSa131          2           2  2.708040e-07   \n",
       "607  p0040presabsSTCC_qual      GA51254          0           0  9.993569e-01   \n",
       "\n",
       "            1             2  \n",
       "0    0.917809  8.477923e-05  \n",
       "1    0.255327  7.345203e-01  \n",
       "2    0.000002  9.963547e-01  \n",
       "3    0.099188  8.980029e-01  \n",
       "4    0.088657  4.237761e-01  \n",
       "..        ...           ...  \n",
       "603  0.093121  9.068785e-01  \n",
       "604  0.999990  9.559324e-06  \n",
       "605  0.998816  6.852559e-05  \n",
       "606  0.156768  8.432316e-01  \n",
       "607  0.000643  1.816008e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.01472100e-03, 9.50091660e-01, 4.08937200e-02],\n",
       "       [2.00832220e-03, 9.76960660e-01, 2.10310780e-02],\n",
       "       [4.08984800e-01, 5.22061060e-02, 5.38809060e-01],\n",
       "       [3.60743670e-01, 5.98007700e-01, 4.12486500e-02],\n",
       "       [3.14415150e-03, 5.35487000e-02, 9.43307160e-01],\n",
       "       [9.23743700e-02, 6.57633100e-01, 2.49992500e-01],\n",
       "       [8.99010200e-01, 9.99789400e-02, 1.01097940e-03],\n",
       "       [4.03003100e-02, 5.07762300e-01, 4.51937350e-01],\n",
       "       [1.20078065e-01, 7.91521300e-01, 8.84006400e-02],\n",
       "       [8.97442700e-01, 7.96436100e-02, 2.29135920e-02],\n",
       "       [2.25779010e-01, 6.76036360e-01, 9.81846450e-02],\n",
       "       [2.24848740e-02, 4.25320660e-01, 5.52194500e-01],\n",
       "       [2.53055970e-02, 1.81754810e-01, 7.92939600e-01],\n",
       "       [7.31713530e-01, 8.01618500e-02, 1.88124630e-01],\n",
       "       [9.06770770e-01, 7.96590150e-02, 1.35702130e-02],\n",
       "       [1.36409210e-03, 1.84255170e-02, 9.80210360e-01],\n",
       "       [4.76679360e-04, 9.61809700e-01, 3.77136200e-02],\n",
       "       [2.94208400e-02, 1.91278930e-01, 7.79300200e-01],\n",
       "       [5.76911400e-01, 2.49026600e-01, 1.74062030e-01],\n",
       "       [1.46828870e-03, 9.97581240e-01, 9.50452200e-04],\n",
       "       [8.17125140e-04, 3.94707400e-01, 6.04475560e-01],\n",
       "       [1.32804450e-01, 3.86157240e-01, 4.81038270e-01],\n",
       "       [6.90005660e-01, 8.54531750e-02, 2.24541140e-01],\n",
       "       [6.87709300e-04, 9.85280930e-01, 1.40313830e-02],\n",
       "       [9.98365200e-01, 1.30680860e-03, 3.28062300e-04],\n",
       "       [3.07124830e-03, 1.02140030e-02, 9.86714800e-01],\n",
       "       [6.40109900e-03, 4.28502300e-02, 9.50748700e-01],\n",
       "       [4.75768660e-01, 5.16900800e-01, 7.33061370e-03],\n",
       "       [5.55135140e-04, 1.11198030e-01, 8.88246800e-01],\n",
       "       [1.46436880e-02, 4.64307640e-01, 5.21048670e-01],\n",
       "       [1.52073970e-02, 3.60093860e-01, 6.24698700e-01],\n",
       "       [9.66990000e-01, 3.25346500e-02, 4.75358070e-04],\n",
       "       [4.82867630e-01, 4.10065200e-01, 1.07067120e-01],\n",
       "       [4.55605200e-03, 9.72529900e-01, 2.29140990e-02],\n",
       "       [4.11735030e-02, 5.49355800e-01, 4.09470700e-01],\n",
       "       [3.55105340e-01, 4.44884270e-01, 2.00010360e-01],\n",
       "       [4.11185730e-04, 7.74703100e-01, 2.24885790e-01],\n",
       "       [4.43983640e-03, 6.38975300e-03, 9.89170400e-01],\n",
       "       [8.22622540e-01, 1.75992370e-01, 1.38508040e-03],\n",
       "       [5.66693380e-05, 2.22945240e-03, 9.97713900e-01],\n",
       "       [9.97551860e-01, 2.37370960e-03, 7.44831700e-05],\n",
       "       [2.05532580e-01, 3.39871020e-01, 4.54596370e-01],\n",
       "       [9.29074170e-01, 1.43185770e-02, 5.66073250e-02],\n",
       "       [9.99416800e-04, 5.21411300e-02, 9.46859500e-01],\n",
       "       [4.95169500e-01, 4.54132900e-01, 5.06976360e-02],\n",
       "       [4.78575470e-03, 1.03099450e-01, 8.92114800e-01],\n",
       "       [2.76535200e-03, 9.52789000e-01, 4.44456260e-02],\n",
       "       [9.87397800e-01, 9.23032900e-03, 3.37181540e-03],\n",
       "       [5.10147600e-02, 6.95365600e-01, 2.53619600e-01],\n",
       "       [3.52509600e-05, 1.35267610e-03, 9.98612050e-01],\n",
       "       [1.21639160e-03, 4.59293460e-02, 9.52854300e-01],\n",
       "       [9.98637000e-01, 1.36099410e-03, 2.00781070e-06],\n",
       "       [7.23949300e-02, 2.81674770e-01, 6.45930300e-01],\n",
       "       [1.66264490e-05, 9.45355300e-04, 9.99038100e-01],\n",
       "       [9.89161970e-01, 1.03304440e-02, 5.07461800e-04],\n",
       "       [2.99506900e-02, 3.18126530e-01, 6.51922760e-01],\n",
       "       [6.49875640e-01, 2.70777100e-01, 7.93472500e-02],\n",
       "       [9.75175260e-01, 2.08031130e-02, 4.02156030e-03],\n",
       "       [5.56616160e-07, 2.50554230e-02, 9.74944000e-01],\n",
       "       [4.90752200e-01, 3.46389200e-01, 1.62858600e-01],\n",
       "       [4.05002860e-01, 4.52674240e-01, 1.42322850e-01],\n",
       "       [6.72670400e-01, 9.46946900e-03, 3.17860070e-01],\n",
       "       [3.38049980e-02, 9.28171400e-01, 3.80236000e-02],\n",
       "       [6.49643800e-01, 5.63994160e-02, 2.93956760e-01],\n",
       "       [1.91344660e-01, 3.61411120e-01, 4.47244260e-01],\n",
       "       [2.49982750e-04, 9.97820600e-01, 1.92941190e-03],\n",
       "       [1.20255485e-01, 6.28163900e-01, 2.51580660e-01],\n",
       "       [5.58800100e-01, 2.55649750e-01, 1.85550200e-01],\n",
       "       [6.20510200e-01, 1.53612790e-01, 2.25877050e-01],\n",
       "       [8.08801300e-01, 1.22350365e-01, 6.88483600e-02],\n",
       "       [3.04232860e-03, 9.96758640e-01, 1.99020130e-04],\n",
       "       [3.68220330e-01, 4.81331020e-01, 1.50448650e-01],\n",
       "       [7.66998650e-01, 2.25874260e-01, 7.12710200e-03],\n",
       "       [6.95429150e-02, 7.31683500e-01, 1.98773600e-01],\n",
       "       [7.36089100e-03, 6.61299500e-01, 3.31339630e-01],\n",
       "       [8.04620270e-01, 1.35743740e-01, 5.96360080e-02]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0017presabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055818960580865"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055818960580865"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706377121555693"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03069207381171293"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706377121555693"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03069207381171293"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1, 2, 2, 0, 0, 2, 1, 2, 0, 1, 2, 2,\n",
       "       0, 1, 0, 2, 2, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 0, 2, 0, 2,\n",
       "       0, 2, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model_sel4.predict_classes(X_sel_test)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "131       NRS104     0     1\n",
       "123       NRS071     0     1\n",
       "124       NRS072     1     2\n",
       "27     BCH-SA-12     0     1\n",
       "57   CFBREBSa125     2     2\n",
       "..           ...   ...   ...\n",
       "170       NRS199     2     1\n",
       "32          CA11     2     0\n",
       "212       NRS253     1     1\n",
       "141       NRS119     2     1\n",
       "126       NRS074     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model_sel4.predict_proba(X_sel_test)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.950092</td>\n",
       "      <td>0.040894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.976961</td>\n",
       "      <td>0.021031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408985</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.538809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360744</td>\n",
       "      <td>0.598008</td>\n",
       "      <td>0.041249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.053549</td>\n",
       "      <td>0.943307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.368220</td>\n",
       "      <td>0.481331</td>\n",
       "      <td>0.150449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.766999</td>\n",
       "      <td>0.225874</td>\n",
       "      <td>0.007127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.069543</td>\n",
       "      <td>0.731683</td>\n",
       "      <td>0.198774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.331340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.804620</td>\n",
       "      <td>0.135744</td>\n",
       "      <td>0.059636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.009015  0.950092  0.040894\n",
       "1   0.002008  0.976961  0.021031\n",
       "2   0.408985  0.052206  0.538809\n",
       "3   0.360744  0.598008  0.041249\n",
       "4   0.003144  0.053549  0.943307\n",
       "..       ...       ...       ...\n",
       "71  0.368220  0.481331  0.150449\n",
       "72  0.766999  0.225874  0.007127\n",
       "73  0.069543  0.731683  0.198774\n",
       "74  0.007361  0.661300  0.331340\n",
       "75  0.804620  0.135744  0.059636\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p17pST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.2303 - accuracy: 0.9379 - val_loss: 1.5480 - val_accuracy: 0.5921\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.3055 - accuracy: 0.9153 - val_loss: 1.6071 - val_accuracy: 0.5658\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.3317 - accuracy: 0.9322 - val_loss: 1.7777 - val_accuracy: 0.5658\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.3369 - accuracy: 0.9096 - val_loss: 1.6167 - val_accuracy: 0.5789\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2309 - accuracy: 0.9266 - val_loss: 1.8766 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.3105 - accuracy: 0.9209 - val_loss: 1.7281 - val_accuracy: 0.5526\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1994 - accuracy: 0.9548 - val_loss: 1.5950 - val_accuracy: 0.5921\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2282 - accuracy: 0.9492 - val_loss: 1.7639 - val_accuracy: 0.5395\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.2427 - accuracy: 0.9435 - val_loss: 1.6652 - val_accuracy: 0.5789\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.1905 - accuracy: 0.9605 - val_loss: 1.6548 - val_accuracy: 0.5658\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.1921 - accuracy: 0.9605 - val_loss: 1.6606 - val_accuracy: 0.5526\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2526 - accuracy: 0.9435 - val_loss: 1.6968 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1917 - accuracy: 0.9605 - val_loss: 1.7028 - val_accuracy: 0.5658\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2044 - accuracy: 0.9605 - val_loss: 1.6938 - val_accuracy: 0.5658\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1992 - accuracy: 0.9661 - val_loss: 1.7172 - val_accuracy: 0.5395\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.2055 - accuracy: 0.9548 - val_loss: 1.6822 - val_accuracy: 0.5658\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1959 - accuracy: 0.9605 - val_loss: 1.7181 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1853 - accuracy: 0.9492 - val_loss: 1.7705 - val_accuracy: 0.5395\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.1957 - accuracy: 0.9492 - val_loss: 1.6845 - val_accuracy: 0.5658\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.2000 - accuracy: 0.9492 - val_loss: 1.7098 - val_accuracy: 0.5658\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.1764 - accuracy: 0.9605 - val_loss: 1.7394 - val_accuracy: 0.5658\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2354 - accuracy: 0.9605 - val_loss: 1.6942 - val_accuracy: 0.5921\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.2290 - accuracy: 0.9322 - val_loss: 2.0795 - val_accuracy: 0.5132\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.3185 - accuracy: 0.9209 - val_loss: 1.7901 - val_accuracy: 0.5658\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1950 - accuracy: 0.9435 - val_loss: 1.7456 - val_accuracy: 0.5789\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.2848 - accuracy: 0.8983 - val_loss: 1.8377 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2563 - accuracy: 0.9322 - val_loss: 1.8405 - val_accuracy: 0.5921\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2525 - accuracy: 0.9379 - val_loss: 1.9980 - val_accuracy: 0.5921\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.2202 - accuracy: 0.9605 - val_loss: 1.8153 - val_accuracy: 0.5921\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2147 - accuracy: 0.9492 - val_loss: 1.8585 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1789 - accuracy: 0.9492 - val_loss: 1.8962 - val_accuracy: 0.5132\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.3163 - accuracy: 0.9548 - val_loss: 2.1521 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2541 - accuracy: 0.9435 - val_loss: 1.9086 - val_accuracy: 0.6053\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2745 - accuracy: 0.9492 - val_loss: 1.8126 - val_accuracy: 0.5658\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1627 - accuracy: 0.9831 - val_loss: 1.8842 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1558 - accuracy: 0.9605 - val_loss: 1.9064 - val_accuracy: 0.5526\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1725 - accuracy: 0.9661 - val_loss: 1.8920 - val_accuracy: 0.5132\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.2722 - accuracy: 0.9266 - val_loss: 2.0897 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2362 - accuracy: 0.9492 - val_loss: 1.9423 - val_accuracy: 0.5921\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1815 - accuracy: 0.9548 - val_loss: 1.8955 - val_accuracy: 0.5789\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1530 - accuracy: 0.9605 - val_loss: 2.0327 - val_accuracy: 0.5395\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2315 - accuracy: 0.9266 - val_loss: 2.0064 - val_accuracy: 0.5658\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1635 - accuracy: 0.9605 - val_loss: 1.9265 - val_accuracy: 0.5395\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1909 - accuracy: 0.9661 - val_loss: 1.9359 - val_accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.2665 - accuracy: 0.9492 - val_loss: 2.1448 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.1940 - accuracy: 0.9605 - val_loss: 1.9116 - val_accuracy: 0.5789\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2112 - accuracy: 0.9379 - val_loss: 1.9314 - val_accuracy: 0.5395\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.1355 - accuracy: 0.9661 - val_loss: 1.9696 - val_accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1286 - accuracy: 0.9605 - val_loss: 1.9536 - val_accuracy: 0.5658\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1609 - accuracy: 0.9774 - val_loss: 1.9179 - val_accuracy: 0.5526\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.1851 - accuracy: 0.9605 - val_loss: 1.9752 - val_accuracy: 0.5395\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2265 - accuracy: 0.9718 - val_loss: 1.9724 - val_accuracy: 0.5658\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2203 - accuracy: 0.9718 - val_loss: 2.0377 - val_accuracy: 0.5395\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1321 - accuracy: 0.9774 - val_loss: 1.9594 - val_accuracy: 0.5263\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1285 - accuracy: 0.9661 - val_loss: 2.0033 - val_accuracy: 0.5395\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.1452 - accuracy: 0.9774 - val_loss: 1.9598 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.1321 - accuracy: 0.9774 - val_loss: 1.9415 - val_accuracy: 0.5395\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.1315 - accuracy: 0.9774 - val_loss: 1.9651 - val_accuracy: 0.5395\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1058 - accuracy: 0.9718 - val_loss: 2.0262 - val_accuracy: 0.5395\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1105 - accuracy: 0.9831 - val_loss: 1.9486 - val_accuracy: 0.5526\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1557 - accuracy: 0.9605 - val_loss: 2.0070 - val_accuracy: 0.5526\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.1249 - accuracy: 0.9661 - val_loss: 1.9836 - val_accuracy: 0.5395\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1245 - accuracy: 0.9718 - val_loss: 2.0204 - val_accuracy: 0.5395\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1298 - accuracy: 0.9774 - val_loss: 2.0031 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1018 - accuracy: 0.9774 - val_loss: 2.0550 - val_accuracy: 0.5526\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1395 - accuracy: 0.9548 - val_loss: 2.0450 - val_accuracy: 0.5526\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2186 - accuracy: 0.9492 - val_loss: 2.2176 - val_accuracy: 0.5263\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1916 - accuracy: 0.9548 - val_loss: 2.1816 - val_accuracy: 0.5789\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1127 - accuracy: 0.9661 - val_loss: 2.0891 - val_accuracy: 0.5263\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1174 - accuracy: 0.9831 - val_loss: 2.0135 - val_accuracy: 0.5526\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1657 - accuracy: 0.9605 - val_loss: 2.1490 - val_accuracy: 0.5395\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1191 - accuracy: 0.9718 - val_loss: 1.9965 - val_accuracy: 0.5789\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1031 - accuracy: 0.9718 - val_loss: 2.0176 - val_accuracy: 0.5658\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1976 - accuracy: 0.9492 - val_loss: 2.3066 - val_accuracy: 0.5395\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1845 - accuracy: 0.9718 - val_loss: 2.0724 - val_accuracy: 0.5526\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.1617 - accuracy: 0.9718 - val_loss: 2.3158 - val_accuracy: 0.5395\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.1658 - accuracy: 0.9492 - val_loss: 2.1298 - val_accuracy: 0.5921\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1263 - accuracy: 0.9718 - val_loss: 2.0252 - val_accuracy: 0.5921\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1371 - accuracy: 0.9605 - val_loss: 2.2295 - val_accuracy: 0.4737\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.1490 - accuracy: 0.9605 - val_loss: 2.1124 - val_accuracy: 0.5395\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.1230 - accuracy: 0.9774 - val_loss: 2.1779 - val_accuracy: 0.5395\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1409 - accuracy: 0.9774 - val_loss: 2.0901 - val_accuracy: 0.5526\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.0872 - accuracy: 0.9887 - val_loss: 2.0965 - val_accuracy: 0.5395\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.1164 - accuracy: 0.9718 - val_loss: 2.1487 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1707 - accuracy: 0.9718 - val_loss: 2.1275 - val_accuracy: 0.5132\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1241 - accuracy: 0.9774 - val_loss: 2.1037 - val_accuracy: 0.5263\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1245 - accuracy: 0.9774 - val_loss: 2.1247 - val_accuracy: 0.5526\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.0919 - accuracy: 0.9774 - val_loss: 2.0677 - val_accuracy: 0.5263\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.1052 - accuracy: 0.9774 - val_loss: 2.1896 - val_accuracy: 0.5263\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1343 - accuracy: 0.9831 - val_loss: 2.1338 - val_accuracy: 0.5395\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.1312 - accuracy: 0.9661 - val_loss: 2.0986 - val_accuracy: 0.5789\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.1028 - accuracy: 0.9774 - val_loss: 2.2382 - val_accuracy: 0.5132\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.0851 - accuracy: 0.9887 - val_loss: 2.2140 - val_accuracy: 0.5526\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.1318 - accuracy: 0.9718 - val_loss: 2.2659 - val_accuracy: 0.5395\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1357 - accuracy: 0.9718 - val_loss: 2.1845 - val_accuracy: 0.5395\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.1221 - accuracy: 0.9661 - val_loss: 2.4992 - val_accuracy: 0.5526\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.2062 - accuracy: 0.9548 - val_loss: 2.4408 - val_accuracy: 0.5526\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.3466 - accuracy: 0.9492 - val_loss: 2.4760 - val_accuracy: 0.5921\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.2607 - accuracy: 0.9548 - val_loss: 2.3104 - val_accuracy: 0.5395\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.0889 - accuracy: 0.9774 - val_loss: 3.1401 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist_sel4 = model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 95.89%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l= [acc_test_sel, acc_test_sel2, acc_test_sel3, acc_test_sel4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean after lasso: 55.92%\n"
     ]
    }
   ],
   "source": [
    "mean_l = np.mean(accs_l)\n",
    "print('test accuracy mean after lasso: %.2f%%' % (mean_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation after lasso: 0.05773003194789586\n"
     ]
    }
   ],
   "source": [
    "std_l = np.std(accs_l)\n",
    "print('test accuracy standard deviation after lasso:', std_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l = [np.mean(hist_sel.history['accuracy']), np.mean(hist_sel2.history['accuracy']), np.mean(hist_sel3.history['accuracy']),\n",
    "             np.mean(hist_sel4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean after lasso: 95.36%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l = np.mean(accs_train_l)\n",
    "print('train accuracy mean after lasso: %.2f%%' % (mean_train_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation after lasso: 0.014935704\n"
     ]
    }
   ],
   "source": [
    "std_train_l = np.std(accs_train_l)\n",
    "print('train accuracy standard deviation after lasso:', std_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
