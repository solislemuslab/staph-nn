{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p002ypresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 2035)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p002ypresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  ...  group_8644  group_8645  group_8646  \\\n",
       "0              1                1  ...           0           0           0   \n",
       "1              1                1  ...           0           0           0   \n",
       "2              1                1  ...           0           0           0   \n",
       "3              1                1  ...           0           0           0   \n",
       "4              1                1  ...           0           0           0   \n",
       "\n",
       "   group_8815  group_8892  group_9007  group_9104  ST  CC  pheno  \n",
       "0           0           0           0           0   5   5      0  \n",
       "1           0           0           0           0   8   8      0  \n",
       "2           0           0           0           0   5   5      1  \n",
       "3           0           0           0           0   5   5      0  \n",
       "4           0           0           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 2035 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    220\n",
       "1     30\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 2034)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  \\\n",
       "0              1                1   \n",
       "1              1                1   \n",
       "2              1                1   \n",
       "3              1                1   \n",
       "4              1                1   \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_8644  group_8645  group_8646  group_8815  group_8892  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_9007  group_9104  ST  CC  pheno  \n",
       "0           0           0   5   5      0  \n",
       "1           0           0   8   8      0  \n",
       "2           0           0   5   5      1  \n",
       "3           0           0   5   5      0  \n",
       "4           0           0   5   5      0  \n",
       "\n",
       "[5 rows x 2034 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 2034) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 220), (1, 220), (2, 220)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa26     0\n",
       "1         NRS109     2\n",
       "2         NRS112     0\n",
       "3         NRS216     1\n",
       "4         NRS021     0\n",
       "..           ...   ...\n",
       "193  CFBREBSa133     0\n",
       "194       NRS209     2\n",
       "195       NRS109     2\n",
       "196       NRS209     2\n",
       "197       NRS035     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 481us/step - loss: 1.0873 - accuracy: 0.6385 - val_loss: 0.7128 - val_accuracy: 0.7222\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 0.5253 - accuracy: 0.7879 - val_loss: 0.6271 - val_accuracy: 0.8384\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.4493 - accuracy: 0.8268 - val_loss: 0.3268 - val_accuracy: 0.8636\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.3400 - accuracy: 0.8615 - val_loss: 0.3445 - val_accuracy: 0.8636\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.3445 - accuracy: 0.8615 - val_loss: 0.3043 - val_accuracy: 0.8788\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.3267 - accuracy: 0.8550 - val_loss: 0.2836 - val_accuracy: 0.8434\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.2765 - accuracy: 0.8896 - val_loss: 0.2659 - val_accuracy: 0.8990\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.2463 - accuracy: 0.8918 - val_loss: 0.2236 - val_accuracy: 0.9141\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.2401 - accuracy: 0.9264 - val_loss: 0.2632 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.2665 - accuracy: 0.9177 - val_loss: 0.2005 - val_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.2579 - accuracy: 0.8918 - val_loss: 0.2039 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.2226 - accuracy: 0.9026 - val_loss: 0.1827 - val_accuracy: 0.9697\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.1972 - accuracy: 0.9416 - val_loss: 0.1699 - val_accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1987 - accuracy: 0.9177 - val_loss: 0.1853 - val_accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.1935 - accuracy: 0.9351 - val_loss: 0.2684 - val_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 0.2026 - accuracy: 0.9264 - val_loss: 0.1584 - val_accuracy: 0.9495\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.1496 - accuracy: 0.9545 - val_loss: 0.1563 - val_accuracy: 0.9343\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 429us/step - loss: 0.1562 - accuracy: 0.9481 - val_loss: 0.1623 - val_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 0.1361 - accuracy: 0.9697 - val_loss: 0.1330 - val_accuracy: 0.9646\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1314 - accuracy: 0.9589 - val_loss: 0.1247 - val_accuracy: 0.9697\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.1257 - accuracy: 0.9675 - val_loss: 0.1405 - val_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1167 - accuracy: 0.9762 - val_loss: 0.1276 - val_accuracy: 0.9596\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.1145 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.1061 - accuracy: 0.9805 - val_loss: 0.1096 - val_accuracy: 0.9747\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.1026 - accuracy: 0.9827 - val_loss: 0.1137 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.1098 - accuracy: 0.9697 - val_loss: 0.2220 - val_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 0.1404 - accuracy: 0.9545 - val_loss: 0.1326 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 0.1045 - accuracy: 0.9762 - val_loss: 0.0941 - val_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.1540 - val_accuracy: 0.9293\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 0.0974 - accuracy: 0.9762 - val_loss: 0.0859 - val_accuracy: 0.9848\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 0.0845 - accuracy: 0.9805 - val_loss: 0.0848 - val_accuracy: 0.9848\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0766 - accuracy: 0.9805 - val_loss: 0.0874 - val_accuracy: 0.9848\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 352us/step - loss: 0.0744 - accuracy: 0.9870 - val_loss: 0.0833 - val_accuracy: 0.9848\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 619us/step - loss: 0.0746 - accuracy: 0.9827 - val_loss: 0.0928 - val_accuracy: 0.9747\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 0.0783 - accuracy: 0.9870 - val_loss: 0.0829 - val_accuracy: 0.9949\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 833us/step - loss: 0.0717 - accuracy: 0.9870 - val_loss: 0.0817 - val_accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 850us/step - loss: 0.0763 - accuracy: 0.9827 - val_loss: 0.0801 - val_accuracy: 0.9848\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 696us/step - loss: 0.0747 - accuracy: 0.9848 - val_loss: 0.0758 - val_accuracy: 0.9798\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 642us/step - loss: 0.0684 - accuracy: 0.9870 - val_loss: 0.0750 - val_accuracy: 0.9798\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9870 - val_loss: 0.0757 - val_accuracy: 0.9747\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 846us/step - loss: 0.0590 - accuracy: 0.9913 - val_loss: 0.0661 - val_accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 788us/step - loss: 0.0588 - accuracy: 0.9892 - val_loss: 0.0703 - val_accuracy: 0.9848\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 793us/step - loss: 0.0520 - accuracy: 0.9892 - val_loss: 0.0693 - val_accuracy: 0.9848\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 513us/step - loss: 0.0558 - accuracy: 0.9913 - val_loss: 0.0686 - val_accuracy: 0.9848\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 433us/step - loss: 0.0525 - accuracy: 0.9870 - val_loss: 0.0748 - val_accuracy: 0.9747\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 0.0569 - accuracy: 0.9870 - val_loss: 0.0667 - val_accuracy: 0.9848\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 907us/step - loss: 0.0485 - accuracy: 0.9935 - val_loss: 0.0786 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 430us/step - loss: 0.0498 - accuracy: 0.9913 - val_loss: 0.0683 - val_accuracy: 0.9798\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 0.0465 - accuracy: 0.9913 - val_loss: 0.0640 - val_accuracy: 0.9848\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 0.0446 - accuracy: 0.9892 - val_loss: 0.0630 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 542us/step - loss: 0.0458 - accuracy: 0.9913 - val_loss: 0.0630 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 473us/step - loss: 0.0453 - accuracy: 0.9913 - val_loss: 0.0820 - val_accuracy: 0.9596\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 861us/step - loss: 0.0448 - accuracy: 0.9892 - val_loss: 0.0589 - val_accuracy: 0.9848\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 572us/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.0661 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 719us/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.0610 - val_accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 438us/step - loss: 0.0380 - accuracy: 0.9935 - val_loss: 0.0561 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.0365 - accuracy: 0.9913 - val_loss: 0.0562 - val_accuracy: 0.9949\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 502us/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.0575 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 557us/step - loss: 0.0345 - accuracy: 0.9935 - val_loss: 0.0891 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 0.0364 - accuracy: 0.9935 - val_loss: 0.0470 - val_accuracy: 0.9949\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 0.0372 - accuracy: 0.9913 - val_loss: 0.0575 - val_accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0537 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0319 - accuracy: 0.9935 - val_loss: 0.0492 - val_accuracy: 0.9949\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0528 - val_accuracy: 0.9798\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0296 - accuracy: 0.9957 - val_loss: 0.0482 - val_accuracy: 0.9949\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.0288 - accuracy: 0.9935 - val_loss: 0.0454 - val_accuracy: 0.9949\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0500 - val_accuracy: 0.9747\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.0265 - accuracy: 0.9978 - val_loss: 0.0490 - val_accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.0469 - val_accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9848\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.0575 - val_accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.0227 - accuracy: 0.9978 - val_loss: 0.0530 - val_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 688us/step - loss: 0.0242 - accuracy: 0.9978 - val_loss: 0.0422 - val_accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.0398 - val_accuracy: 0.9949\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 517us/step - loss: 0.0214 - accuracy: 0.9978 - val_loss: 0.0417 - val_accuracy: 0.9949\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 594us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9949\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 496us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9747\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.0735 - val_accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9949\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0196 - accuracy: 0.9978 - val_loss: 0.0404 - val_accuracy: 0.9949\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.0206 - accuracy: 0.9978 - val_loss: 0.0366 - val_accuracy: 0.9949\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0378 - val_accuracy: 0.9949\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0454 - val_accuracy: 0.9747\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 530us/step - loss: 0.0198 - accuracy: 0.9978 - val_loss: 0.0428 - val_accuracy: 0.9747\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 473us/step - loss: 0.0183 - accuracy: 0.9978 - val_loss: 0.0477 - val_accuracy: 0.9747\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.0421 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 626us/step - loss: 0.0175 - accuracy: 0.9978 - val_loss: 0.0528 - val_accuracy: 0.9747\n",
      "Epoch 90/100\n",
      "256/462 [===============>..............] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.129369). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 0s 312us/step - loss: 0.0174 - accuracy: 0.9978 - val_loss: 0.0377 - val_accuracy: 0.9949\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9949\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 0.0398 - val_accuracy: 0.9949\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9949\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 0.0385 - val_accuracy: 0.9949\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9949\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0290 - accuracy: 0.9957 - val_loss: 0.0428 - val_accuracy: 0.9747\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9747\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.0463 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9798\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3707f0b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 147us/step\n",
      "over-sampling test accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 0, 1,\n",
       "       0, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 2, 1, 1, 0,\n",
       "       0, 2, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0,\n",
       "       0, 2, 0, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 2, 2,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 1, 2, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa26     0     0\n",
       "1         NRS109     2     2\n",
       "2         NRS112     0     0\n",
       "3         NRS216     1     1\n",
       "4         NRS021     0     0\n",
       "..           ...   ...   ...\n",
       "193  CFBREBSa133     0     0\n",
       "194       NRS209     2     2\n",
       "195       NRS109     2     2\n",
       "196       NRS209     2     2\n",
       "197       NRS035     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999528e-01</td>\n",
       "      <td>4.725889e-05</td>\n",
       "      <td>3.082832e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.021427e-03</td>\n",
       "      <td>7.837663e-04</td>\n",
       "      <td>9.981949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.970143e-01</td>\n",
       "      <td>2.985639e-03</td>\n",
       "      <td>1.549940e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.931194e-02</td>\n",
       "      <td>9.706042e-01</td>\n",
       "      <td>8.391447e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.988996e-01</td>\n",
       "      <td>1.100384e-03</td>\n",
       "      <td>1.590173e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.373644e-10</td>\n",
       "      <td>7.920553e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.044007e-07</td>\n",
       "      <td>4.704020e-04</td>\n",
       "      <td>9.995294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.021427e-03</td>\n",
       "      <td>7.837656e-04</td>\n",
       "      <td>9.981949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.044007e-07</td>\n",
       "      <td>4.704020e-04</td>\n",
       "      <td>9.995294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>4.167520e-04</td>\n",
       "      <td>9.992151e-01</td>\n",
       "      <td>3.680644e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.999528e-01  4.725889e-05  3.082832e-09\n",
       "1    1.021427e-03  7.837663e-04  9.981949e-01\n",
       "2    9.970143e-01  2.985639e-03  1.549940e-07\n",
       "3    2.931194e-02  9.706042e-01  8.391447e-05\n",
       "4    9.988996e-01  1.100384e-03  1.590173e-10\n",
       "..            ...           ...           ...\n",
       "193  1.000000e+00  7.373644e-10  7.920553e-09\n",
       "194  2.044007e-07  4.704020e-04  9.995294e-01\n",
       "195  1.021427e-03  7.837656e-04  9.981949e-01\n",
       "196  2.044007e-07  4.704020e-04  9.995294e-01\n",
       "197  4.167520e-04  9.992151e-01  3.680644e-04\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9899\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9949\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9747\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9949\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9747\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9949\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9949\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9747\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9949\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9949\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0411 - val_accuracy: 0.9747\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9747\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9949\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9747\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9899\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0323 - val_accuracy: 0.9798\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9798\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9899\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 409us/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0317 - val_accuracy: 0.9949\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9798\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9798\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9949\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9747\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9747\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9747\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9798\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9798\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9747\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9798\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9798\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9949\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9949\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9798\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9747\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9798\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 628us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9747\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9798\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9798\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9747\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9747\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9798\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9747\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9798\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9949\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9747\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9798\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9747\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9798\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9798\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9798\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9798\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9798\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9798\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9798\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9798\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9798\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9798\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9798\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9798\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9798\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9747\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9798\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9798\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9798\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9798\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9798\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9747\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9798\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9798\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9798\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.99%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99952800e-01, 4.72588870e-05, 3.08283150e-09],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [9.97014300e-01, 2.98563930e-03, 1.54993970e-07],\n",
       "       [2.93119440e-02, 9.70604200e-01, 8.39144700e-05],\n",
       "       [9.98899600e-01, 1.10038390e-03, 1.59017260e-10],\n",
       "       [9.99733500e-01, 2.66428570e-04, 8.31315800e-09],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.00000000e+00, 1.90122370e-08, 1.44964470e-12],\n",
       "       [1.53664180e-02, 9.84576900e-01, 5.66871530e-05],\n",
       "       [9.99995230e-01, 4.72467600e-06, 3.18319260e-13],\n",
       "       [8.15281900e-02, 9.18467500e-01, 4.31467700e-06],\n",
       "       [4.21984160e-02, 9.42683340e-01, 1.51182730e-02],\n",
       "       [9.98228250e-01, 1.77174710e-03, 3.35112600e-10],\n",
       "       [1.72360500e-02, 9.82735500e-01, 2.83248120e-05],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.22267720e-03, 9.98767900e-01, 9.42426000e-06],\n",
       "       [7.40570370e-01, 2.59422030e-01, 7.61500770e-06],\n",
       "       [7.33525300e-04, 9.99266450e-01, 3.75847930e-09],\n",
       "       [9.99996400e-01, 3.55300500e-06, 1.77050200e-14],\n",
       "       [9.99997850e-01, 2.82674750e-12, 2.14191070e-06],\n",
       "       [1.86109760e-03, 9.98138550e-01, 4.00562160e-07],\n",
       "       [4.45027920e-01, 5.54967900e-01, 4.21137000e-06],\n",
       "       [8.71085050e-01, 1.28910270e-01, 4.62689900e-06],\n",
       "       [9.99993560e-01, 6.46576200e-06, 3.32363370e-11],\n",
       "       [1.17656920e-04, 9.72742260e-01, 2.71400360e-02],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [5.63790040e-03, 9.94355100e-01, 7.01176080e-06],\n",
       "       [9.29585040e-01, 7.04149100e-02, 7.51627100e-09],\n",
       "       [1.00000000e+00, 5.56830300e-08, 1.57878500e-11],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [7.40570370e-01, 2.59422030e-01, 7.61500770e-06],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [2.02381280e-02, 9.79761600e-01, 1.93956960e-07],\n",
       "       [9.99925400e-01, 7.45673900e-05, 1.36156230e-09],\n",
       "       [1.24881880e-03, 9.97668450e-01, 1.08270310e-03],\n",
       "       [1.82184180e-05, 9.99981760e-01, 2.48989140e-09],\n",
       "       [9.99293570e-01, 7.06366150e-04, 1.36415820e-09],\n",
       "       [9.99860760e-01, 1.39183290e-04, 3.54744570e-11],\n",
       "       [9.99995600e-01, 4.37451630e-06, 4.63857230e-14],\n",
       "       [9.99890700e-01, 1.09272725e-04, 5.37029100e-09],\n",
       "       [9.38456800e-01, 6.15424180e-02, 8.15133800e-07],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.23324170e-02, 9.87667560e-01, 3.72433320e-08],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [6.86069540e-04, 9.99311700e-01, 2.21242500e-06],\n",
       "       [9.99998570e-01, 1.39100550e-06, 1.46841560e-12],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [9.99928830e-01, 7.11586500e-05, 2.79965480e-12],\n",
       "       [9.99999640e-01, 4.00891680e-07, 1.18904990e-11],\n",
       "       [9.87528400e-01, 1.24716520e-02, 4.48513980e-10],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [9.99796330e-01, 2.03687070e-04, 6.93727030e-09],\n",
       "       [9.91951800e-01, 8.04781500e-03, 2.99227500e-07],\n",
       "       [5.44007230e-02, 9.45593540e-01, 5.79687700e-06],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [9.98766540e-01, 1.23351720e-03, 2.87114780e-08],\n",
       "       [8.08169300e-01, 1.91829340e-01, 1.34925190e-06],\n",
       "       [1.72360500e-02, 9.82735500e-01, 2.83248120e-05],\n",
       "       [9.99574600e-01, 4.25348170e-04, 2.66911020e-10],\n",
       "       [4.15028720e-03, 9.95843000e-01, 6.81424800e-06],\n",
       "       [9.99866100e-01, 1.25109670e-04, 8.70948700e-06],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [7.40570370e-01, 2.59422030e-01, 7.61500770e-06],\n",
       "       [9.97804700e-01, 2.19505100e-03, 2.44819550e-07],\n",
       "       [1.17656920e-04, 9.72742260e-01, 2.71400360e-02],\n",
       "       [8.15281900e-02, 9.18467500e-01, 4.31467700e-06],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.82184180e-05, 9.99981760e-01, 2.48989140e-09],\n",
       "       [2.02381280e-02, 9.79761600e-01, 1.93956960e-07],\n",
       "       [7.33525300e-04, 9.99266450e-01, 3.75847930e-09],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [7.40570370e-01, 2.59422030e-01, 7.61500770e-06],\n",
       "       [5.21323640e-02, 9.47860900e-01, 6.65486230e-06],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [9.60361060e-01, 3.96389660e-02, 1.88008360e-08],\n",
       "       [9.98233560e-01, 1.76643600e-03, 1.96969010e-10],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.03371530e-03, 9.98961700e-01, 4.66712900e-06],\n",
       "       [4.15028720e-03, 9.95843000e-01, 6.81424800e-06],\n",
       "       [9.99987960e-01, 1.20730480e-05, 2.66819430e-09],\n",
       "       [9.96073700e-01, 3.92620450e-03, 1.07585480e-07],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [9.99788600e-01, 2.11373220e-04, 1.30211820e-08],\n",
       "       [9.99998570e-01, 7.25111300e-13, 1.41077930e-06],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [9.97139100e-01, 2.86066000e-03, 1.83180000e-07],\n",
       "       [5.21323640e-02, 9.47860900e-01, 6.65486230e-06],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.24881880e-03, 9.97668450e-01, 1.08270310e-03],\n",
       "       [1.24881880e-03, 9.97668450e-01, 1.08270310e-03],\n",
       "       [1.72360500e-02, 9.82735500e-01, 2.83248120e-05],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [9.99861360e-01, 1.38610750e-04, 5.69512160e-10],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [9.99488000e-01, 5.11993540e-04, 3.07701850e-08],\n",
       "       [9.99897840e-01, 1.02143700e-04, 2.84982600e-10],\n",
       "       [9.16373850e-01, 8.36166500e-02, 9.52476800e-06],\n",
       "       [9.99999760e-01, 2.47465550e-07, 1.50315250e-10],\n",
       "       [9.99960400e-01, 3.96187900e-05, 3.15342200e-10],\n",
       "       [5.44007230e-02, 9.45593540e-01, 5.79687700e-06],\n",
       "       [1.24881880e-03, 9.97668450e-01, 1.08270310e-03],\n",
       "       [1.22267720e-03, 9.98767900e-01, 9.42426000e-06],\n",
       "       [9.98513640e-01, 1.48641160e-03, 1.17006100e-10],\n",
       "       [7.97718350e-01, 2.02254180e-01, 2.75255840e-05],\n",
       "       [1.00000000e+00, 1.83193900e-08, 2.82921170e-13],\n",
       "       [2.01528390e-02, 9.78547600e-01, 1.29958310e-03],\n",
       "       [9.99999640e-01, 4.03752040e-07, 1.40366440e-11],\n",
       "       [2.28791960e-03, 9.97675960e-01, 3.61016000e-05],\n",
       "       [9.99998900e-01, 1.09103880e-06, 1.12897730e-11],\n",
       "       [1.72360500e-02, 9.82735500e-01, 2.83248120e-05],\n",
       "       [2.28791960e-03, 9.97675960e-01, 3.61016000e-05],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [2.02381280e-02, 9.79761600e-01, 1.93956960e-07],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.72360500e-02, 9.82735500e-01, 2.83248120e-05],\n",
       "       [1.06481530e-01, 8.93515650e-01, 2.91050080e-06],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [9.96923270e-01, 3.07669470e-03, 4.97449500e-10],\n",
       "       [9.99998330e-01, 1.91430900e-12, 1.66844070e-06],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.23324170e-02, 9.87667560e-01, 3.72433320e-08],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.17656920e-04, 9.72742260e-01, 2.71400360e-02],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [4.16753140e-04, 9.99215100e-01, 3.68064760e-04],\n",
       "       [9.94806000e-01, 5.19405260e-03, 2.19283990e-08],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [5.44007230e-02, 9.45593540e-01, 5.79687700e-06],\n",
       "       [9.38948700e-01, 6.10513500e-02, 1.72204600e-09],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [9.63541300e-01, 3.64587100e-02, 5.06515230e-09],\n",
       "       [9.99988100e-01, 1.19665590e-05, 1.92609090e-11],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [7.77951000e-01, 2.22047760e-01, 1.31596910e-06],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [9.02769700e-01, 9.72290100e-02, 1.25721530e-06],\n",
       "       [9.99991540e-01, 8.50125600e-06, 1.01783130e-12],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [9.95346960e-01, 4.65299330e-03, 9.03711440e-10],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.53664180e-02, 9.84576900e-01, 5.66871530e-05],\n",
       "       [9.99999760e-01, 1.98876040e-07, 1.38732460e-11],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.49095220e-02, 9.74575300e-01, 1.05151640e-02],\n",
       "       [2.93119440e-02, 9.70604200e-01, 8.39144700e-05],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [9.78994370e-01, 2.10057100e-02, 4.44855350e-09],\n",
       "       [2.28791960e-03, 9.97675960e-01, 3.61016000e-05],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [2.01528390e-02, 9.78547600e-01, 1.29958310e-03],\n",
       "       [9.06973600e-01, 9.30242760e-02, 2.14862370e-06],\n",
       "       [2.04400890e-07, 4.70401520e-04, 9.99529360e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [4.21984160e-02, 9.42683340e-01, 1.51182730e-02],\n",
       "       [1.02142730e-03, 7.83766300e-04, 9.98194900e-01],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [3.15670480e-03, 9.96842400e-01, 9.58378600e-07],\n",
       "       [9.97387600e-01, 2.61243270e-03, 2.76689520e-08],\n",
       "       [5.63790040e-03, 9.94355100e-01, 7.01176080e-06],\n",
       "       [1.24881880e-03, 9.97668450e-01, 1.08270310e-03],\n",
       "       [2.02381280e-02, 9.79761600e-01, 1.93956960e-07],\n",
       "       [5.44007230e-02, 9.45593540e-01, 5.79687700e-06],\n",
       "       [1.86109760e-03, 9.98138550e-01, 4.00562160e-07],\n",
       "       [1.86109760e-03, 9.98138550e-01, 4.00562160e-07],\n",
       "       [2.01528390e-02, 9.78547600e-01, 1.29958310e-03],\n",
       "       [1.03371530e-03, 9.98961700e-01, 4.66712900e-06],\n",
       "       [9.99999760e-01, 2.37860960e-07, 1.13927980e-10],\n",
       "       [1.03371530e-03, 9.98961700e-01, 4.66712900e-06],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [7.92732500e-01, 2.07261650e-01, 5.85773900e-06],\n",
       "       [1.63454510e-06, 2.06930840e-03, 9.97929100e-01],\n",
       "       [1.17656920e-04, 9.72742260e-01, 2.71400360e-02],\n",
       "       [1.63454350e-06, 2.06930240e-03, 9.97929100e-01],\n",
       "       [1.00000000e+00, 7.37364450e-10, 7.92055300e-09],\n",
       "       [2.04400690e-07, 4.70401950e-04, 9.99529360e-01],\n",
       "       [1.02142690e-03, 7.83765600e-04, 9.98194900e-01],\n",
       "       [2.04400690e-07, 4.70401950e-04, 9.99529360e-01],\n",
       "       [4.16751950e-04, 9.99215100e-01, 3.68064400e-04]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996939087848178"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996939087848178"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS109     2\n",
       "1     NRS109     2\n",
       "2     NRS222     0\n",
       "3     NRS109     2\n",
       "4    GA50245     0\n",
       "..       ...   ...\n",
       "193   NRS148     2\n",
       "194   NRS266     1\n",
       "195   NRS109     2\n",
       "196   NRS149     0\n",
       "197   NRS109     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 421us/step - loss: 1.3324 - accuracy: 0.6645 - val_loss: 0.6076 - val_accuracy: 0.8131\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.6414 - accuracy: 0.7944 - val_loss: 0.4623 - val_accuracy: 0.8030\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.3956 - accuracy: 0.8377 - val_loss: 0.3848 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 0.3238 - accuracy: 0.8680 - val_loss: 0.3237 - val_accuracy: 0.8586\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.2690 - accuracy: 0.9004 - val_loss: 0.3634 - val_accuracy: 0.8838\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.3056 - accuracy: 0.8918 - val_loss: 0.3179 - val_accuracy: 0.8990\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.2251 - accuracy: 0.9264 - val_loss: 0.2791 - val_accuracy: 0.9040\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.1976 - accuracy: 0.9351 - val_loss: 0.2639 - val_accuracy: 0.8434\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.1888 - accuracy: 0.9264 - val_loss: 0.2599 - val_accuracy: 0.9040\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.1858 - accuracy: 0.9286 - val_loss: 0.2502 - val_accuracy: 0.8737\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1853 - accuracy: 0.9156 - val_loss: 0.2192 - val_accuracy: 0.9141\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.1624 - accuracy: 0.9524 - val_loss: 0.2452 - val_accuracy: 0.8990\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 0.1804 - accuracy: 0.9242 - val_loss: 0.2047 - val_accuracy: 0.8990\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.2101 - accuracy: 0.9069 - val_loss: 0.2442 - val_accuracy: 0.9192\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.1665 - accuracy: 0.9459 - val_loss: 0.3351 - val_accuracy: 0.8788\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1756 - accuracy: 0.9286 - val_loss: 0.1889 - val_accuracy: 0.9293\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 740us/step - loss: 0.1465 - accuracy: 0.9545 - val_loss: 0.1869 - val_accuracy: 0.9141\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 794us/step - loss: 0.1186 - accuracy: 0.9654 - val_loss: 0.2025 - val_accuracy: 0.9192\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 716us/step - loss: 0.1173 - accuracy: 0.9675 - val_loss: 0.1856 - val_accuracy: 0.9293\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 361us/step - loss: 0.1170 - accuracy: 0.9719 - val_loss: 0.1378 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1064 - accuracy: 0.9719 - val_loss: 0.1638 - val_accuracy: 0.9545\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 759us/step - loss: 0.0999 - accuracy: 0.9784 - val_loss: 0.1485 - val_accuracy: 0.9646\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0866 - accuracy: 0.9892 - val_loss: 0.1617 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0886 - accuracy: 0.9805 - val_loss: 0.1270 - val_accuracy: 0.9646\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.0836 - accuracy: 0.9805 - val_loss: 0.1318 - val_accuracy: 0.9596\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.0760 - accuracy: 0.9935 - val_loss: 0.1282 - val_accuracy: 0.9697\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0710 - accuracy: 0.9870 - val_loss: 0.1263 - val_accuracy: 0.9697\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 0.1036 - accuracy: 0.9719 - val_loss: 0.1354 - val_accuracy: 0.9697\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 522us/step - loss: 0.0826 - accuracy: 0.9784 - val_loss: 0.1178 - val_accuracy: 0.9697\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0810 - accuracy: 0.9805 - val_loss: 0.1682 - val_accuracy: 0.9293\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.1105 - accuracy: 0.9589 - val_loss: 0.1136 - val_accuracy: 0.9747\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.1183 - accuracy: 0.9654 - val_loss: 0.0960 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 558us/step - loss: 0.2504 - accuracy: 0.9481 - val_loss: 0.2846 - val_accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0942 - accuracy: 0.9784 - val_loss: 0.1686 - val_accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0773 - accuracy: 0.9827 - val_loss: 0.1227 - val_accuracy: 0.9646\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0591 - accuracy: 0.9870 - val_loss: 0.1243 - val_accuracy: 0.9646\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0541 - accuracy: 0.9892 - val_loss: 0.1119 - val_accuracy: 0.9646\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 538us/step - loss: 0.0538 - accuracy: 0.9870 - val_loss: 0.1215 - val_accuracy: 0.9646\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 0.0519 - accuracy: 0.9935 - val_loss: 0.1125 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.0522 - accuracy: 0.9892 - val_loss: 0.0944 - val_accuracy: 0.9747\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0499 - accuracy: 0.9892 - val_loss: 0.1082 - val_accuracy: 0.9646\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0498 - accuracy: 0.9913 - val_loss: 0.1423 - val_accuracy: 0.9596\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 0.0474 - accuracy: 0.9913 - val_loss: 0.1243 - val_accuracy: 0.9596\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0470 - accuracy: 0.9935 - val_loss: 0.1437 - val_accuracy: 0.9596\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0421 - accuracy: 0.9892 - val_loss: 0.1140 - val_accuracy: 0.9596\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0411 - accuracy: 0.9935 - val_loss: 0.0949 - val_accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0385 - accuracy: 0.9913 - val_loss: 0.1077 - val_accuracy: 0.9596\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.0392 - accuracy: 0.9957 - val_loss: 0.1310 - val_accuracy: 0.9596\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0406 - accuracy: 0.9892 - val_loss: 0.0937 - val_accuracy: 0.9646\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.1049 - val_accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0337 - accuracy: 0.9935 - val_loss: 0.1048 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0400 - accuracy: 0.9935 - val_loss: 0.1134 - val_accuracy: 0.9596\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0397 - accuracy: 0.9935 - val_loss: 0.1457 - val_accuracy: 0.9596\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0371 - accuracy: 0.9913 - val_loss: 0.1045 - val_accuracy: 0.9646\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0428 - accuracy: 0.9913 - val_loss: 0.0966 - val_accuracy: 0.9646\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0380 - accuracy: 0.9935 - val_loss: 0.0790 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.1040 - val_accuracy: 0.9798\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0303 - accuracy: 0.9978 - val_loss: 0.0744 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0263 - accuracy: 0.9957 - val_loss: 0.0880 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0292 - accuracy: 0.9957 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0265 - accuracy: 0.9957 - val_loss: 0.0779 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0239 - accuracy: 0.9978 - val_loss: 0.1004 - val_accuracy: 0.9646\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 0.1055 - val_accuracy: 0.9596\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 0.0956 - val_accuracy: 0.9646\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0235 - accuracy: 0.9978 - val_loss: 0.1116 - val_accuracy: 0.9596\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0231 - accuracy: 0.9978 - val_loss: 0.0866 - val_accuracy: 0.9697\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0245 - accuracy: 0.9957 - val_loss: 0.1117 - val_accuracy: 0.9596\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.0243 - accuracy: 0.9978 - val_loss: 0.0819 - val_accuracy: 0.9798\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0346 - accuracy: 0.9935 - val_loss: 0.0876 - val_accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0476 - accuracy: 0.9870 - val_loss: 0.0898 - val_accuracy: 0.9646\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0314 - accuracy: 0.9935 - val_loss: 0.1081 - val_accuracy: 0.9596\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.1690 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0325 - accuracy: 0.9957 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0227 - accuracy: 0.9978 - val_loss: 0.0764 - val_accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0212 - accuracy: 0.9978 - val_loss: 0.0726 - val_accuracy: 0.9848\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0194 - accuracy: 0.9978 - val_loss: 0.0991 - val_accuracy: 0.9646\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.1439 - val_accuracy: 0.9596\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0293 - accuracy: 0.9892 - val_loss: 0.0709 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.1039 - val_accuracy: 0.9747\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.0728 - val_accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9798\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.0887 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9596\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.0907 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9747\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9596\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9798\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.0661 - val_accuracy: 0.9899\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9747\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9747\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9747\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9747\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9697\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9747\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x631cfc0f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 173us/step\n",
      "over-sampling test accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 0, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1,\n",
       "       2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 1, 2, 0, 2,\n",
       "       1, 1, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 1, 0,\n",
       "       2, 0, 2, 1, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1,\n",
       "       1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 0, 2, 1, 0,\n",
       "       0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "       0, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS109     2     2\n",
       "1     NRS109     2     2\n",
       "2     NRS222     0     0\n",
       "3     NRS109     2     2\n",
       "4    GA50245     0     0\n",
       "..       ...   ...   ...\n",
       "193   NRS148     2     2\n",
       "194   NRS266     1     1\n",
       "195   NRS109     2     2\n",
       "196   NRS149     0     1\n",
       "197   NRS109     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.302851e-04</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>9.942011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.302851e-04</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>9.942011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.947300e-01</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>3.008131e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.302851e-04</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>9.942011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.987645e-01</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>6.272662e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.341323e-09</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>9.984811e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.687704e-04</td>\n",
       "      <td>0.999517</td>\n",
       "      <td>1.455117e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>6.302848e-04</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>9.942011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4.454741e-01</td>\n",
       "      <td>0.554522</td>\n",
       "      <td>3.477236e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.302848e-04</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>9.942011e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    6.302851e-04  0.005169  9.942011e-01\n",
       "1    6.302851e-04  0.005169  9.942011e-01\n",
       "2    9.947300e-01  0.005270  3.008131e-07\n",
       "3    6.302851e-04  0.005169  9.942011e-01\n",
       "4    9.987645e-01  0.001235  6.272662e-07\n",
       "..            ...       ...           ...\n",
       "193  1.341323e-09  0.001519  9.984811e-01\n",
       "194  4.687704e-04  0.999517  1.455117e-05\n",
       "195  6.302848e-04  0.005169  9.942011e-01\n",
       "196  4.454741e-01  0.554522  3.477236e-06\n",
       "197  6.302848e-04  0.005169  9.942011e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 0.0884 - val_accuracy: 0.9747\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.0972 - val_accuracy: 0.9747\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9747\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.1152 - val_accuracy: 0.9747\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9747\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9747\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9798\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9798\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9747\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9747\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9747\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9747\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9747\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9747\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 472us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9747\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9747\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 776us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9747\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9747\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9747\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 838us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9747\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9747\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9747\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9747\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9747\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9747\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9747\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9747\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9747\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9747\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9747\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9747\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9747\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9747\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9747\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9747\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9747\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9747\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9747\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9747\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9747\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 469us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9747\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9747\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9747\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9747\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9747\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9747\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9747\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9747\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9747\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9747\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9747\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9747\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9747\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9747\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 453us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9747\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9747\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 383us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9747\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9747\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9747\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9747\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9747\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9747\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9747\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9747\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9747\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9747\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9747\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.98%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.94730000e-01, 5.26959640e-03, 3.00813100e-07],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.98764500e-01, 1.23492540e-03, 6.27266160e-07],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.97446060e-01, 2.55394980e-03, 4.57869300e-09],\n",
       "       [3.06966760e-03, 9.96923600e-01, 6.64078650e-06],\n",
       "       [9.99999760e-01, 2.14201380e-07, 2.15502250e-11],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99815170e-01, 1.84799180e-04, 1.10494206e-07],\n",
       "       [5.33969300e-04, 9.99464450e-01, 1.60185440e-06],\n",
       "       [9.94723700e-01, 5.27623060e-03, 1.59178510e-07],\n",
       "       [2.66609780e-06, 9.89390300e-01, 1.06069840e-02],\n",
       "       [1.27158970e-03, 9.98695900e-01, 3.25350300e-05],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [4.48031240e-05, 9.99951840e-01, 3.29720610e-06],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [1.16676485e-04, 9.99351800e-01, 5.31565460e-04],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99877800e-01, 1.21045570e-04, 1.12889840e-06],\n",
       "       [1.23993140e-02, 9.87578200e-01, 2.24580160e-05],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [2.66609780e-06, 9.89390300e-01, 1.06069840e-02],\n",
       "       [3.18345220e-03, 9.93672600e-01, 3.14391640e-03],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [5.33969300e-04, 9.99464450e-01, 1.60185440e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [4.51032040e-02, 9.54892200e-01, 4.52429700e-06],\n",
       "       [9.98393600e-01, 1.60628840e-03, 8.59717700e-08],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99969500e-01, 3.05631440e-05, 2.89304180e-09],\n",
       "       [2.31340260e-01, 7.68644300e-01, 1.55277410e-05],\n",
       "       [8.98401340e-05, 9.99713360e-01, 1.96795600e-04],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [4.48031240e-05, 9.99951840e-01, 3.29720610e-06],\n",
       "       [9.99231800e-01, 7.67836000e-04, 3.13621680e-07],\n",
       "       [2.78431880e-02, 9.34034800e-01, 3.81219200e-02],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [6.57120160e-03, 9.93423940e-01, 4.88069050e-06],\n",
       "       [1.00000000e+00, 1.17971730e-09, 1.76912160e-17],\n",
       "       [9.99574960e-01, 4.25052920e-04, 1.14893720e-09],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [1.35511540e-04, 9.99855400e-01, 9.00359800e-06],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99995600e-01, 4.35489440e-06, 1.54543390e-10],\n",
       "       [9.70957500e-01, 2.90408530e-02, 1.65292890e-06],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [2.32662420e-03, 9.97673330e-01, 1.54420310e-09],\n",
       "       [4.68770360e-04, 9.99516700e-01, 1.45511970e-05],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.77790500e-01, 2.22063180e-02, 3.25041700e-06],\n",
       "       [7.78913400e-05, 9.99919650e-01, 2.47828440e-06],\n",
       "       [7.25014660e-02, 9.27498500e-01, 1.01019630e-12],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.98855350e-01, 1.14461290e-03, 2.95797050e-09],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99966860e-01, 3.31835180e-05, 4.93676180e-11],\n",
       "       [9.99999640e-01, 3.04108080e-07, 6.62646160e-15],\n",
       "       [1.23993140e-02, 9.87578200e-01, 2.24580160e-05],\n",
       "       [1.22938230e-02, 9.87703200e-01, 2.96593200e-06],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99815050e-01, 1.84936490e-04, 1.11005120e-08],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [5.04256830e-03, 9.94956900e-01, 5.14319370e-07],\n",
       "       [7.78049140e-03, 9.92209900e-01, 9.53652600e-06],\n",
       "       [9.84804030e-01, 1.51959760e-02, 4.56537650e-11],\n",
       "       [9.99464600e-01, 5.31435900e-04, 4.10386500e-06],\n",
       "       [9.79124000e-05, 9.99902100e-01, 2.37518000e-12],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [4.68770360e-04, 9.99516700e-01, 1.45511970e-05],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99928100e-01, 6.89669100e-05, 2.83783830e-06],\n",
       "       [9.88799040e-01, 1.11997420e-02, 1.35279150e-06],\n",
       "       [9.68436540e-01, 3.15634940e-02, 8.55597000e-11],\n",
       "       [8.20035160e-01, 1.79948990e-01, 1.58768330e-05],\n",
       "       [1.02292850e-02, 9.89454750e-01, 3.15975720e-04],\n",
       "       [8.67911600e-03, 9.58716900e-01, 3.26040050e-02],\n",
       "       [9.99855040e-01, 1.44950400e-04, 1.48174520e-08],\n",
       "       [1.35511540e-04, 9.99855400e-01, 9.00359800e-06],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [9.82808300e-01, 1.71910490e-02, 5.55695600e-07],\n",
       "       [5.04256830e-03, 9.94956900e-01, 5.14319370e-07],\n",
       "       [9.94856000e-01, 5.14371930e-03, 2.89039240e-07],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [1.00000000e+00, 1.48843300e-08, 4.28176050e-16],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [5.33969300e-04, 9.99464450e-01, 1.60185440e-06],\n",
       "       [3.06966760e-03, 9.96923600e-01, 6.64078650e-06],\n",
       "       [6.57120160e-03, 9.93423940e-01, 4.88069050e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.77149320e-05, 9.99982240e-01, 2.76606460e-10],\n",
       "       [9.99758660e-01, 2.41199420e-04, 9.52943700e-08],\n",
       "       [9.99595460e-01, 4.04516580e-04, 4.22326460e-08],\n",
       "       [1.16676485e-04, 9.99351800e-01, 5.31565460e-04],\n",
       "       [1.00000000e+00, 3.99549900e-18, 5.99148400e-10],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [9.97909600e-01, 2.09025830e-03, 6.44672700e-08],\n",
       "       [5.33969300e-04, 9.99464450e-01, 1.60185440e-06],\n",
       "       [7.91294800e-01, 2.08697420e-01, 7.77968400e-06],\n",
       "       [4.51032040e-02, 9.54892200e-01, 4.52429700e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [1.00000000e+00, 3.86131270e-08, 5.45738400e-12],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [1.02292850e-02, 9.89454750e-01, 3.15975720e-04],\n",
       "       [9.96460860e-01, 3.53903070e-03, 8.74604900e-08],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.13083065e-01, 8.86916800e-01, 1.42254080e-07],\n",
       "       [1.23993140e-02, 9.87578200e-01, 2.24580160e-05],\n",
       "       [7.94995350e-02, 9.20458730e-01, 4.16974800e-05],\n",
       "       [8.67911600e-03, 9.58716900e-01, 3.26040050e-02],\n",
       "       [9.94772260e-01, 5.22764800e-03, 1.31855220e-07],\n",
       "       [9.99999760e-01, 2.05115470e-07, 2.17280290e-11],\n",
       "       [9.99993300e-01, 6.68554640e-06, 1.26782630e-11],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.93616700e-01, 6.38140600e-03, 1.85258830e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [1.69383120e-03, 9.98301740e-01, 4.39641640e-06],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [6.79757800e-03, 9.93158160e-01, 4.43360260e-05],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.79124000e-05, 9.99902100e-01, 2.37518000e-12],\n",
       "       [1.00000000e+00, 2.25709600e-08, 3.34923550e-16],\n",
       "       [1.16676485e-04, 9.99351800e-01, 5.31565460e-04],\n",
       "       [6.79757800e-03, 9.93158160e-01, 4.43360260e-05],\n",
       "       [4.51032040e-02, 9.54892200e-01, 4.52429700e-06],\n",
       "       [3.06966760e-03, 9.96923600e-01, 6.64078650e-06],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.80100500e-01, 1.98993350e-02, 8.33655850e-08],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [9.99875800e-01, 1.24142700e-04, 1.52303500e-16],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.99998800e-01, 1.18362810e-06, 2.56017680e-10],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.32223300e-01, 6.77410500e-02, 3.55173180e-05],\n",
       "       [9.99914050e-01, 8.58835340e-05, 2.07758440e-13],\n",
       "       [7.00681400e-04, 9.99298000e-01, 1.27422440e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [9.99368000e-01, 6.32042360e-04, 7.16007800e-10],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [6.79757800e-03, 9.93158160e-01, 4.43360260e-05],\n",
       "       [9.99797050e-01, 2.02986570e-04, 4.18965130e-09],\n",
       "       [9.99946950e-01, 5.30019400e-05, 2.16128260e-13],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [1.77149320e-05, 9.99982240e-01, 2.76606460e-10],\n",
       "       [8.67911600e-03, 9.58716900e-01, 3.26040050e-02],\n",
       "       [9.96408760e-01, 3.59097660e-03, 2.40940780e-07],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [2.66609780e-06, 9.89390300e-01, 1.06069840e-02],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [9.68829600e-01, 3.11699550e-02, 5.05842500e-07],\n",
       "       [9.98597560e-01, 1.40231990e-03, 1.16534120e-07],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [9.99894600e-01, 1.05316016e-04, 4.59950900e-10],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [2.78431880e-02, 9.34034800e-01, 3.81219200e-02],\n",
       "       [6.79757800e-03, 9.93158160e-01, 4.43360260e-05],\n",
       "       [9.79124000e-05, 9.99902100e-01, 2.37518000e-12],\n",
       "       [4.23477170e-10, 4.77588260e-05, 9.99952200e-01],\n",
       "       [2.70309080e-02, 9.72945000e-01, 2.41561400e-05],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [9.99877200e-01, 1.22754970e-04, 4.20752540e-13],\n",
       "       [6.57120160e-03, 9.93423940e-01, 4.88069050e-06],\n",
       "       [3.89214250e-01, 6.10785800e-01, 2.38306960e-08],\n",
       "       [1.02292850e-02, 9.89454750e-01, 3.15975720e-04],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [3.54965570e-01, 6.45030600e-01, 3.76039750e-06],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [7.78049140e-03, 9.92209900e-01, 9.53652600e-06],\n",
       "       [9.77931800e-01, 2.20681970e-02, 6.35620000e-15],\n",
       "       [9.99997260e-01, 2.75000140e-06, 1.33156090e-14],\n",
       "       [1.00000000e+00, 8.69654100e-12, 2.03972980e-24],\n",
       "       [9.99963760e-01, 3.62347640e-05, 7.55433700e-18],\n",
       "       [1.22938230e-02, 9.87703200e-01, 2.96593200e-06],\n",
       "       [1.34133350e-09, 1.51889340e-03, 9.98481100e-01],\n",
       "       [6.30285070e-04, 5.16860600e-03, 9.94201100e-01],\n",
       "       [8.67911600e-03, 9.58716900e-01, 3.26040050e-02],\n",
       "       [1.89058860e-04, 9.99811000e-01, 4.74897300e-14],\n",
       "       [1.34132330e-09, 1.51888980e-03, 9.98481100e-01],\n",
       "       [4.68770360e-04, 9.99516700e-01, 1.45511690e-05],\n",
       "       [6.30284800e-04, 5.16860900e-03, 9.94201100e-01],\n",
       "       [4.45474120e-01, 5.54522340e-01, 3.47723560e-06],\n",
       "       [6.30284800e-04, 5.16860900e-03, 9.94201100e-01]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949877563513927"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949877563513927"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa110     0\n",
       "1    CFBREBSa131     1\n",
       "2         NRS148     2\n",
       "3         NRS169     1\n",
       "4         NRS073     0\n",
       "..           ...   ...\n",
       "193       NRS001     1\n",
       "194       NRS191     0\n",
       "195       NRS207     0\n",
       "196         CA26     0\n",
       "197     CFBRSa48     0\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 423us/step - loss: 1.6758 - accuracy: 0.5952 - val_loss: 0.7575 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.5447 - accuracy: 0.7684 - val_loss: 0.5952 - val_accuracy: 0.7626\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.4132 - accuracy: 0.8398 - val_loss: 0.5061 - val_accuracy: 0.7929\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.3633 - accuracy: 0.8615 - val_loss: 0.4361 - val_accuracy: 0.8283\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 390us/step - loss: 0.3313 - accuracy: 0.8745 - val_loss: 0.3726 - val_accuracy: 0.8586\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.3297 - accuracy: 0.8723 - val_loss: 0.3663 - val_accuracy: 0.8283\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 0.2460 - accuracy: 0.8918 - val_loss: 0.3292 - val_accuracy: 0.8636\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.2438 - accuracy: 0.8983 - val_loss: 0.3012 - val_accuracy: 0.8990\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 0.2230 - accuracy: 0.9113 - val_loss: 0.2789 - val_accuracy: 0.8586\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.1927 - accuracy: 0.9221 - val_loss: 0.2599 - val_accuracy: 0.9192\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.1817 - accuracy: 0.9329 - val_loss: 0.2742 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.2027 - accuracy: 0.9307 - val_loss: 0.2212 - val_accuracy: 0.9293\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.1591 - accuracy: 0.9437 - val_loss: 0.2762 - val_accuracy: 0.8737\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.1517 - accuracy: 0.9545 - val_loss: 0.2321 - val_accuracy: 0.8939\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 0.1466 - accuracy: 0.9502 - val_loss: 0.2604 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 591us/step - loss: 0.1529 - accuracy: 0.9459 - val_loss: 0.2146 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.1283 - accuracy: 0.9610 - val_loss: 0.1864 - val_accuracy: 0.9697\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 361us/step - loss: 0.1171 - accuracy: 0.9719 - val_loss: 0.1858 - val_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 0.1170 - accuracy: 0.9697 - val_loss: 0.1893 - val_accuracy: 0.9192\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.1205 - accuracy: 0.9545 - val_loss: 0.1746 - val_accuracy: 0.9394\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 0.1016 - accuracy: 0.9805 - val_loss: 0.1821 - val_accuracy: 0.9495\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 443us/step - loss: 0.1022 - accuracy: 0.9762 - val_loss: 0.1797 - val_accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.0885 - accuracy: 0.9913 - val_loss: 0.1826 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.1023 - accuracy: 0.9675 - val_loss: 0.1687 - val_accuracy: 0.9444\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0791 - accuracy: 0.9870 - val_loss: 0.1860 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.0937 - accuracy: 0.9762 - val_loss: 0.1740 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.0873 - accuracy: 0.9827 - val_loss: 0.1620 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0760 - accuracy: 0.9870 - val_loss: 0.1605 - val_accuracy: 0.9495\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.0847 - accuracy: 0.9719 - val_loss: 0.1520 - val_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0837 - accuracy: 0.9740 - val_loss: 0.1654 - val_accuracy: 0.9495\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0695 - accuracy: 0.9870 - val_loss: 0.1324 - val_accuracy: 0.9798\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0700 - accuracy: 0.9740 - val_loss: 0.1348 - val_accuracy: 0.9646\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 540us/step - loss: 0.0599 - accuracy: 0.9913 - val_loss: 0.1636 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.0573 - accuracy: 0.9935 - val_loss: 0.1613 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0562 - accuracy: 0.9870 - val_loss: 0.1301 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0502 - accuracy: 0.9892 - val_loss: 0.1226 - val_accuracy: 0.9646\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.0487 - accuracy: 0.9957 - val_loss: 0.1400 - val_accuracy: 0.9495\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0485 - accuracy: 0.9913 - val_loss: 0.1273 - val_accuracy: 0.9646\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0489 - accuracy: 0.9935 - val_loss: 0.1491 - val_accuracy: 0.9495\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0455 - accuracy: 0.9913 - val_loss: 0.1282 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.0448 - accuracy: 0.9935 - val_loss: 0.1121 - val_accuracy: 0.9747\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0481 - accuracy: 0.9913 - val_loss: 0.1107 - val_accuracy: 0.9798\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0660 - accuracy: 0.9805 - val_loss: 0.1112 - val_accuracy: 0.9798\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0512 - accuracy: 0.9870 - val_loss: 0.0998 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0458 - accuracy: 0.9913 - val_loss: 0.1055 - val_accuracy: 0.9747\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.0383 - accuracy: 0.9935 - val_loss: 0.1275 - val_accuracy: 0.9697\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.0343 - accuracy: 0.9913 - val_loss: 0.1136 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0342 - accuracy: 0.9978 - val_loss: 0.1111 - val_accuracy: 0.9646\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0346 - accuracy: 0.9957 - val_loss: 0.1166 - val_accuracy: 0.9747\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.0332 - accuracy: 0.9935 - val_loss: 0.1215 - val_accuracy: 0.9646\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0346 - accuracy: 0.9913 - val_loss: 0.1287 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.0431 - accuracy: 0.9913 - val_loss: 0.1019 - val_accuracy: 0.9747\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0382 - accuracy: 0.9935 - val_loss: 0.0988 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.1129 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0295 - accuracy: 0.9957 - val_loss: 0.1216 - val_accuracy: 0.9697\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0282 - accuracy: 0.9957 - val_loss: 0.1246 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0249 - accuracy: 0.9978 - val_loss: 0.1634 - val_accuracy: 0.9545\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.0275 - accuracy: 0.9978 - val_loss: 0.0946 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0225 - accuracy: 0.9978 - val_loss: 0.0983 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 465us/step - loss: 0.0232 - accuracy: 0.9978 - val_loss: 0.0936 - val_accuracy: 0.9848\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.0285 - accuracy: 0.9957 - val_loss: 0.0971 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0241 - accuracy: 0.9935 - val_loss: 0.0853 - val_accuracy: 0.9848\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.0252 - accuracy: 0.9978 - val_loss: 0.0858 - val_accuracy: 0.9848\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0251 - accuracy: 0.9957 - val_loss: 0.0807 - val_accuracy: 0.9848\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9747\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0211 - accuracy: 0.9957 - val_loss: 0.0942 - val_accuracy: 0.9848\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0243 - accuracy: 0.9978 - val_loss: 0.0967 - val_accuracy: 0.9848\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.1075 - val_accuracy: 0.9747\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0284 - accuracy: 0.9957 - val_loss: 0.0845 - val_accuracy: 0.9848\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0168 - accuracy: 0.9978 - val_loss: 0.1252 - val_accuracy: 0.9646\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 0.0172 - accuracy: 0.9978 - val_loss: 0.1207 - val_accuracy: 0.9646\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 0.0176 - accuracy: 0.9978 - val_loss: 0.1337 - val_accuracy: 0.9646\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.1405 - val_accuracy: 0.9646\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.0170 - accuracy: 0.9978 - val_loss: 0.1311 - val_accuracy: 0.9646\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0193 - accuracy: 0.9978 - val_loss: 0.1474 - val_accuracy: 0.9596\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9646\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 464us/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.1076 - val_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 518us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9646\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9646\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 0.0979 - val_accuracy: 0.9848\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0949 - val_accuracy: 0.9798\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9848\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9848\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9697\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9848\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9596\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9747\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.0817 - val_accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9646\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x632277b00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 187us/step\n",
      "over-sampling test accuracy: 97.47%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 2,\n",
       "       1, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2, 2, 1, 0, 0,\n",
       "       1, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2,\n",
       "       2, 1, 2, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 2, 0, 2, 0, 1,\n",
       "       2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 1, 1, 2,\n",
       "       1, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 1, 0, 2, 0, 1, 2, 0, 1, 0, 1,\n",
       "       1, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa110     0     0\n",
       "1    CFBREBSa131     1     1\n",
       "2         NRS148     2     2\n",
       "3         NRS169     1     1\n",
       "4         NRS073     0     0\n",
       "..           ...   ...   ...\n",
       "193       NRS001     1     1\n",
       "194       NRS191     0     0\n",
       "195       NRS207     0     0\n",
       "196         CA26     0     0\n",
       "197     CFBRSa48     0     0\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999314</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>3.761691e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.963644</td>\n",
       "      <td>1.427160e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>9.971011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.979220</td>\n",
       "      <td>5.497806e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999118</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>1.210949e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.990276</td>\n",
       "      <td>5.089228e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.845824</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>4.374536e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>7.595697e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.380664e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.989620</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>2.075908e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.999314  0.000686  3.761691e-09\n",
       "1    0.036356  0.963644  1.427160e-09\n",
       "2    0.000001  0.002898  9.971011e-01\n",
       "3    0.015282  0.979220  5.497806e-03\n",
       "4    0.999118  0.000882  1.210949e-12\n",
       "..        ...       ...           ...\n",
       "193  0.009724  0.990276  5.089228e-08\n",
       "194  0.845824  0.154172  4.374536e-06\n",
       "195  0.999702  0.000297  7.595697e-08\n",
       "196  0.999991  0.000009  1.380664e-09\n",
       "197  0.989620  0.010380  2.075908e-08\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9798\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9798\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0745 - val_accuracy: 0.9848\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9798\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9848\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9848\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9747\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9848\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9798\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9848\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9798\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9798\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9848\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9697\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9848\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9798\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9848\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9798\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9798\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9848\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9798\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 490us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9798\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 429us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9798\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 817us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 508us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9848\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 576us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9747\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9848\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9848\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9747\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9747\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9697\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9848\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9697\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9848\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9747\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9848\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9848\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9697\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9798\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9848\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9848\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9848\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9848\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 506us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9697\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 525us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9848\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9697\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9848\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9848\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 322us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9848\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 600us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9798\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9848\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 417us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 512us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9848\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9848\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9848\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9798\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9798\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 430us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9848\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9747\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9798\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9848\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9848\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9848\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9848\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9848\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9848\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9798\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9848\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99313830e-01, 6.86202500e-04, 3.76169140e-09],\n",
       "       [3.63563600e-02, 9.63643600e-01, 1.42716030e-09],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.52819770e-02, 9.79220150e-01, 5.49780620e-03],\n",
       "       [9.99117700e-01, 8.82361260e-04, 1.21094910e-12],\n",
       "       [1.54402840e-05, 9.99984500e-01, 8.83860100e-11],\n",
       "       [7.55906150e-05, 9.77803100e-01, 2.21213330e-02],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [5.66168600e-04, 9.99433700e-01, 7.55483640e-08],\n",
       "       [3.30562800e-01, 6.69437200e-01, 1.04187174e-08],\n",
       "       [9.99978540e-01, 2.14273660e-05, 2.31031800e-14],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [2.47907300e-02, 9.75209060e-01, 2.69607230e-07],\n",
       "       [9.72403900e-03, 9.90276000e-01, 5.08922820e-08],\n",
       "       [9.99975900e-01, 2.05343300e-05, 3.57822070e-06],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.99882700e-01, 6.67148600e-05, 5.05345740e-05],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.99981900e-01, 9.20221400e-06, 8.89741100e-06],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.87292300e-01, 1.27077550e-02, 1.38411320e-11],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [7.55906150e-05, 9.77803100e-01, 2.21213330e-02],\n",
       "       [9.99995000e-01, 5.01244950e-06, 1.30656820e-10],\n",
       "       [6.61331000e-03, 9.93203500e-01, 1.83161100e-04],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99892100e-01, 1.07889050e-04, 5.54222600e-10],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [3.32941640e-02, 9.59171950e-01, 7.53392330e-03],\n",
       "       [9.63319700e-03, 9.90355500e-01, 1.12898510e-05],\n",
       "       [9.25477600e-01, 7.45222100e-02, 1.09404190e-07],\n",
       "       [2.65362490e-03, 9.97346400e-01, 2.10258070e-08],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.48566510e-04, 9.99783700e-01, 6.77116100e-05],\n",
       "       [9.99313830e-01, 6.86202500e-04, 3.76169140e-09],\n",
       "       [9.85366200e-01, 1.46337840e-02, 1.05929390e-10],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [5.02728570e-04, 9.99497300e-01, 5.22099270e-08],\n",
       "       [9.99998330e-01, 1.71528700e-06, 1.58044040e-10],\n",
       "       [9.99993560e-01, 6.30740600e-06, 6.18438850e-08],\n",
       "       [9.39248800e-03, 9.90607500e-01, 3.36846280e-09],\n",
       "       [7.79763300e-04, 9.99114100e-01, 1.06085880e-04],\n",
       "       [9.99985800e-01, 1.41416995e-05, 3.04715400e-10],\n",
       "       [1.52819770e-02, 9.79220150e-01, 5.49780620e-03],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [3.32941640e-02, 9.59171950e-01, 7.53392330e-03],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [4.66627350e-03, 9.95332660e-01, 1.04805620e-06],\n",
       "       [9.99996300e-01, 3.13091600e-14, 3.66609300e-06],\n",
       "       [9.99347270e-01, 6.52593740e-04, 6.30179600e-08],\n",
       "       [6.38865500e-05, 9.99935870e-01, 1.98067810e-07],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [3.98786430e-01, 6.01211900e-01, 1.61542820e-06],\n",
       "       [6.38865500e-05, 9.99935870e-01, 1.98067810e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [2.35625300e-03, 9.97643770e-01, 1.23248000e-08],\n",
       "       [9.84501800e-01, 1.54981220e-02, 9.29019400e-08],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [7.40380630e-03, 9.92596200e-01, 2.00203040e-08],\n",
       "       [7.25745600e-01, 2.74254350e-01, 6.56459700e-09],\n",
       "       [1.02623810e-03, 9.98970600e-01, 3.10446080e-06],\n",
       "       [1.14040100e-02, 9.88596000e-01, 2.56626760e-08],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [7.55906150e-05, 9.77803100e-01, 2.21213330e-02],\n",
       "       [2.65362490e-03, 9.97346400e-01, 2.10258070e-08],\n",
       "       [9.99999050e-01, 9.82266100e-07, 7.61676170e-10],\n",
       "       [1.75002510e-03, 9.98249950e-01, 5.95014350e-09],\n",
       "       [8.03100350e-04, 9.99194440e-01, 2.52405040e-06],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.13095940e-02, 9.88689960e-01, 4.49415780e-07],\n",
       "       [7.40380630e-03, 9.92596200e-01, 2.00203040e-08],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.97534400e-01, 2.46556940e-03, 3.44830630e-09],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99313830e-01, 6.86202500e-04, 3.76169140e-09],\n",
       "       [9.94095300e-01, 5.90463300e-03, 1.14273740e-08],\n",
       "       [1.14040100e-02, 9.88596000e-01, 2.56626760e-08],\n",
       "       [9.99997740e-01, 2.01410020e-14, 2.26003110e-06],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [7.55906150e-05, 9.77803100e-01, 2.21213330e-02],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [5.66168600e-04, 9.99433700e-01, 7.55483640e-08],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.80404200e-01, 1.95957930e-02, 2.71188120e-08],\n",
       "       [7.79763300e-04, 9.99114100e-01, 1.06085880e-04],\n",
       "       [9.88985060e-01, 1.10148955e-02, 3.10001340e-08],\n",
       "       [9.98442350e-01, 1.55771640e-03, 1.84167820e-11],\n",
       "       [1.52819770e-02, 9.79220150e-01, 5.49780620e-03],\n",
       "       [5.28250770e-03, 9.94716800e-01, 7.45715600e-07],\n",
       "       [9.97041400e-01, 2.95860880e-03, 5.86087760e-09],\n",
       "       [9.99466240e-01, 5.33726900e-04, 2.07193040e-09],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [2.55400840e-04, 9.99744600e-01, 2.94899420e-09],\n",
       "       [1.12908114e-04, 9.99885200e-01, 1.95479200e-06],\n",
       "       [9.99243260e-01, 7.56730700e-04, 1.00854290e-12],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.99980800e-01, 1.91875840e-05, 1.54897860e-14],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99990460e-01, 9.58263300e-06, 5.45111960e-09],\n",
       "       [1.75002510e-03, 9.98249950e-01, 5.95014350e-09],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.99313830e-01, 6.86202500e-04, 3.76169140e-09],\n",
       "       [2.50141400e-03, 9.97496400e-01, 2.09239870e-06],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [8.03100350e-04, 9.99194440e-01, 2.52405040e-06],\n",
       "       [9.99784770e-01, 2.15287440e-04, 1.14182840e-09],\n",
       "       [3.63563600e-02, 9.63643600e-01, 1.42716030e-09],\n",
       "       [5.70662500e-03, 9.94261260e-01, 3.20794280e-05],\n",
       "       [9.99995950e-01, 4.00258930e-06, 1.94259140e-10],\n",
       "       [1.43760080e-02, 9.85623360e-01, 6.19667330e-07],\n",
       "       [1.52819770e-02, 9.79220150e-01, 5.49780620e-03],\n",
       "       [2.80368330e-03, 9.97195600e-01, 7.18063860e-07],\n",
       "       [9.99041140e-01, 9.58810040e-04, 4.56702870e-13],\n",
       "       [9.99998330e-01, 4.34134330e-15, 1.64336210e-06],\n",
       "       [5.66168600e-04, 9.99433700e-01, 7.55483640e-08],\n",
       "       [9.98872200e-01, 1.12775550e-03, 4.80425430e-09],\n",
       "       [9.99889600e-01, 1.10401270e-04, 1.19118390e-08],\n",
       "       [9.63319700e-03, 9.90355500e-01, 1.12898510e-05],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99975440e-01, 2.45455400e-05, 4.30523670e-10],\n",
       "       [7.55906150e-05, 9.77803100e-01, 2.21213330e-02],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [2.79851880e-01, 7.20146240e-01, 1.88018260e-06],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [3.38729400e-04, 9.99661300e-01, 2.56799560e-11],\n",
       "       [5.02728570e-04, 9.99497300e-01, 5.22099270e-08],\n",
       "       [1.02623810e-03, 9.98970600e-01, 3.10446080e-06],\n",
       "       [6.80583100e-01, 3.19391400e-01, 2.55283870e-05],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [5.70662500e-03, 9.94261260e-01, 3.20794280e-05],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.99986200e-01, 1.37738725e-05, 7.33271550e-10],\n",
       "       [8.46418900e-01, 1.53581020e-01, 9.34273740e-08],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [7.79763300e-04, 9.99114100e-01, 1.06085880e-04],\n",
       "       [8.03100350e-04, 9.99194440e-01, 2.52405040e-06],\n",
       "       [1.43760080e-02, 9.85623360e-01, 6.19667330e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.13095940e-02, 9.88689960e-01, 4.49415780e-07],\n",
       "       [9.99930000e-01, 6.99989540e-05, 9.87006400e-10],\n",
       "       [1.00000000e+00, 4.20966800e-11, 1.36458530e-18],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.99391900e-01, 6.08123200e-04, 4.32181420e-14],\n",
       "       [2.35625300e-03, 9.97643770e-01, 1.23248000e-08],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.63319700e-03, 9.90355500e-01, 1.12898510e-05],\n",
       "       [7.40380630e-03, 9.92596200e-01, 2.00203040e-08],\n",
       "       [9.99802050e-01, 1.97950780e-04, 3.22079340e-09],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [9.99993700e-01, 6.36581850e-06, 1.36284704e-14],\n",
       "       [1.13095940e-02, 9.88689960e-01, 4.49415780e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99886900e-01, 1.13127210e-04, 9.49524360e-15],\n",
       "       [4.85503170e-01, 5.14496740e-01, 3.74341230e-08],\n",
       "       [9.99795850e-01, 2.04155830e-04, 1.16494380e-09],\n",
       "       [9.39248800e-03, 9.90607500e-01, 3.36846280e-09],\n",
       "       [1.12908114e-04, 9.99885200e-01, 1.95479200e-06],\n",
       "       [5.28250770e-03, 9.94716800e-01, 7.45715600e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99556960e-01, 4.42971770e-04, 1.56583340e-09],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [1.49616090e-03, 8.12478650e-04, 9.97691400e-01],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.83317400e-01, 1.66825670e-02, 7.39968700e-11],\n",
       "       [8.97613800e-01, 1.02386095e-01, 7.60813560e-08],\n",
       "       [5.28250770e-03, 9.94716800e-01, 7.45715600e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [1.00000000e+00, 1.07361490e-08, 3.77669000e-11],\n",
       "       [5.28250770e-03, 9.94716800e-01, 7.45715600e-07],\n",
       "       [9.42512030e-07, 1.33821740e-04, 9.99865200e-01],\n",
       "       [9.99957560e-01, 4.24079040e-05, 7.90249700e-14],\n",
       "       [1.31860800e-06, 2.89752900e-03, 9.97101100e-01],\n",
       "       [9.72403500e-03, 9.90276000e-01, 5.08922820e-08],\n",
       "       [9.72403500e-03, 9.90276000e-01, 5.08922820e-08],\n",
       "       [8.45823940e-01, 1.54171680e-01, 4.37453630e-06],\n",
       "       [9.99702400e-01, 2.97413760e-04, 7.59569700e-08],\n",
       "       [9.99990940e-01, 9.04722200e-06, 1.38066440e-09],\n",
       "       [9.89619700e-01, 1.03803070e-02, 2.07590760e-08]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920033670033671"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920033670033671"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS110     1\n",
       "1         NRS216     1\n",
       "2         NRS386     1\n",
       "3       CFBRSa25     0\n",
       "4      BCH-SA-03     1\n",
       "..           ...   ...\n",
       "193       NRS216     1\n",
       "194  CFBREBSa110     0\n",
       "195       NRS148     2\n",
       "196         GA27     0\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.4792 - accuracy: 0.6342 - val_loss: 0.7244 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6459 - accuracy: 0.7511 - val_loss: 0.4009 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 465us/step - loss: 0.4748 - accuracy: 0.7835 - val_loss: 0.4055 - val_accuracy: 0.8434\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.3709 - accuracy: 0.8463 - val_loss: 0.3417 - val_accuracy: 0.8182\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.3220 - accuracy: 0.8680 - val_loss: 0.4860 - val_accuracy: 0.7828\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 0.3392 - accuracy: 0.8485 - val_loss: 0.3325 - val_accuracy: 0.9040\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.2513 - accuracy: 0.9113 - val_loss: 0.2784 - val_accuracy: 0.8939\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.2069 - accuracy: 0.9459 - val_loss: 0.2640 - val_accuracy: 0.9091\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 554us/step - loss: 0.1939 - accuracy: 0.9351 - val_loss: 0.2641 - val_accuracy: 0.9141\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 0.2166 - accuracy: 0.9221 - val_loss: 0.2324 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.2024 - accuracy: 0.9307 - val_loss: 0.2315 - val_accuracy: 0.9343\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 502us/step - loss: 0.1776 - accuracy: 0.9545 - val_loss: 0.2395 - val_accuracy: 0.8990\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.1697 - accuracy: 0.9394 - val_loss: 0.2163 - val_accuracy: 0.9495\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.1469 - accuracy: 0.9632 - val_loss: 0.2274 - val_accuracy: 0.9141\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1396 - accuracy: 0.9610 - val_loss: 0.2055 - val_accuracy: 0.9394\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1318 - accuracy: 0.9632 - val_loss: 0.1997 - val_accuracy: 0.9343\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 545us/step - loss: 0.1260 - accuracy: 0.9740 - val_loss: 0.1793 - val_accuracy: 0.9646\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.1147 - accuracy: 0.9762 - val_loss: 0.1977 - val_accuracy: 0.9141\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.1143 - accuracy: 0.9848 - val_loss: 0.1732 - val_accuracy: 0.9646\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1042 - accuracy: 0.9848 - val_loss: 0.1630 - val_accuracy: 0.9646\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.1029 - accuracy: 0.9805 - val_loss: 0.1690 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 0.0988 - accuracy: 0.9805 - val_loss: 0.1587 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0992 - accuracy: 0.9740 - val_loss: 0.1792 - val_accuracy: 0.9545\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.1520 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0922 - accuracy: 0.9805 - val_loss: 0.1773 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0851 - accuracy: 0.9848 - val_loss: 0.1575 - val_accuracy: 0.9545\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 0.0800 - accuracy: 0.9827 - val_loss: 0.1526 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.0834 - accuracy: 0.9697 - val_loss: 0.2007 - val_accuracy: 0.9394\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0881 - accuracy: 0.9805 - val_loss: 0.1344 - val_accuracy: 0.9596\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0700 - accuracy: 0.9913 - val_loss: 0.1331 - val_accuracy: 0.9596\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0697 - accuracy: 0.9892 - val_loss: 0.1347 - val_accuracy: 0.9596\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0701 - accuracy: 0.9870 - val_loss: 0.1423 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 0.0720 - accuracy: 0.9827 - val_loss: 0.1311 - val_accuracy: 0.9646\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 503us/step - loss: 0.0676 - accuracy: 0.9913 - val_loss: 0.1246 - val_accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.0603 - accuracy: 0.9870 - val_loss: 0.1236 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.0587 - accuracy: 0.9892 - val_loss: 0.1230 - val_accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0603 - accuracy: 0.9892 - val_loss: 0.1188 - val_accuracy: 0.9697\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 0.0539 - accuracy: 0.9913 - val_loss: 0.1273 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0626 - accuracy: 0.9892 - val_loss: 0.1167 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.0554 - accuracy: 0.9892 - val_loss: 0.1247 - val_accuracy: 0.9646\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 0.0508 - accuracy: 0.9913 - val_loss: 0.1185 - val_accuracy: 0.9596\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.0525 - accuracy: 0.9892 - val_loss: 0.1165 - val_accuracy: 0.9646\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 0.0549 - accuracy: 0.9892 - val_loss: 0.1085 - val_accuracy: 0.9646\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.0469 - accuracy: 0.9913 - val_loss: 0.1076 - val_accuracy: 0.9747\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0539 - accuracy: 0.9892 - val_loss: 0.1109 - val_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0973 - val_accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.0426 - accuracy: 0.9913 - val_loss: 0.1075 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0489 - accuracy: 0.9870 - val_loss: 0.1081 - val_accuracy: 0.9798\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0446 - accuracy: 0.9935 - val_loss: 0.1077 - val_accuracy: 0.9798\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0449 - accuracy: 0.9957 - val_loss: 0.0984 - val_accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0526 - accuracy: 0.9892 - val_loss: 0.1124 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0470 - accuracy: 0.9892 - val_loss: 0.0976 - val_accuracy: 0.9747\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0377 - accuracy: 0.9913 - val_loss: 0.0953 - val_accuracy: 0.9646\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0924 - val_accuracy: 0.9697\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0330 - accuracy: 0.9957 - val_loss: 0.0882 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0372 - accuracy: 0.9913 - val_loss: 0.0877 - val_accuracy: 0.9747\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0339 - accuracy: 0.9935 - val_loss: 0.1071 - val_accuracy: 0.9646\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0329 - accuracy: 0.9935 - val_loss: 0.1059 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0277 - accuracy: 0.9978 - val_loss: 0.0986 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.0872 - val_accuracy: 0.9697\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 0.0876 - val_accuracy: 0.9697\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 0.0890 - val_accuracy: 0.9798\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.0836 - val_accuracy: 0.9798\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 0.0979 - val_accuracy: 0.9747\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0258 - accuracy: 0.9957 - val_loss: 0.0807 - val_accuracy: 0.9697\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.1241 - val_accuracy: 0.9596\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0265 - accuracy: 0.9957 - val_loss: 0.0880 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 0.0783 - val_accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.0754 - val_accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 438us/step - loss: 0.0206 - accuracy: 0.9978 - val_loss: 0.0776 - val_accuracy: 0.9747\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 517us/step - loss: 0.0245 - accuracy: 0.9957 - val_loss: 0.0912 - val_accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 505us/step - loss: 0.0255 - accuracy: 0.9957 - val_loss: 0.0733 - val_accuracy: 0.9798\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 755us/step - loss: 0.0260 - accuracy: 0.9935 - val_loss: 0.0791 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 707us/step - loss: 0.0235 - accuracy: 0.9978 - val_loss: 0.1015 - val_accuracy: 0.9646\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 426us/step - loss: 0.0203 - accuracy: 0.9978 - val_loss: 0.0922 - val_accuracy: 0.9646\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.0835 - val_accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0195 - accuracy: 0.9978 - val_loss: 0.0801 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 0.1021 - val_accuracy: 0.9646\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.0963 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0776 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0796 - val_accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 0.0782 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.0858 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 0.1005 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0161 - accuracy: 0.9978 - val_loss: 0.0940 - val_accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.1072 - val_accuracy: 0.9646\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.0885 - val_accuracy: 0.9697\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0872 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9646\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0144 - accuracy: 0.9978 - val_loss: 0.1205 - val_accuracy: 0.9646\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.0170 - accuracy: 0.9978 - val_loss: 0.1498 - val_accuracy: 0.9646\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9697\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.1018 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9646\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.0965 - val_accuracy: 0.9697\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.0752 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0903 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a373eafd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 291us/step\n",
      "over-sampling test accuracy: 96.97%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 2, 2,\n",
       "       0, 0, 1, 2, 2, 0, 0, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 0, 2, 0, 0, 1,\n",
       "       0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 1, 2, 0,\n",
       "       1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 1, 2, 0, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 2,\n",
       "       2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS110     1     1\n",
       "1         NRS216     1     1\n",
       "2         NRS386     1     1\n",
       "3       CFBRSa25     0     0\n",
       "4      BCH-SA-03     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS216     1     1\n",
       "194  CFBREBSa110     0     0\n",
       "195       NRS148     2     2\n",
       "196         GA27     0     0\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>8.019265e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.976704</td>\n",
       "      <td>2.383147e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.961320</td>\n",
       "      <td>1.034880e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>1.617060e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>5.751620e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.976704</td>\n",
       "      <td>2.383147e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>7.801651e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>9.988357e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>2.547308e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>9.988357e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.002259  0.997741  8.019265e-12\n",
       "1    0.023295  0.976704  2.383147e-07\n",
       "2    0.038680  0.961320  1.034880e-09\n",
       "3    0.999643  0.000357  1.617060e-12\n",
       "4    0.010256  0.989744  5.751620e-11\n",
       "..        ...       ...           ...\n",
       "193  0.023295  0.976704  2.383147e-07\n",
       "194  0.999738  0.000262  7.801651e-09\n",
       "195  0.000003  0.001161  9.988357e-01\n",
       "196  0.999186  0.000814  2.547308e-17\n",
       "197  0.000003  0.001161  9.988357e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9697\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9697\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9697\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.1229 - val_accuracy: 0.9747\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1394 - val_accuracy: 0.9697\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9697\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9697\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9697\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9697\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9697\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9697\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9697\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9697\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9697\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9697\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9697\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9697\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9697\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9697\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 443us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9697\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9697\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9697\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 598us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 545us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 485us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9697\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 964us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9646\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9697\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9697\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9697\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9697\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9697\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9697\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9697\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9697\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9646\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9697\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9697\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9697\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9697\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 413us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9646\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 680us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9697\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9697\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 437us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9646\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 486us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9697\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9697\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 642us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9697\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9697\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 0.9646\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9697\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9697\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 353us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9697\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9697\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9697\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9697\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9697\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9697\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9697\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.25869940e-03, 9.97741340e-01, 8.01926500e-12],\n",
       "       [2.32953320e-02, 9.76704500e-01, 2.38314660e-07],\n",
       "       [3.86803600e-02, 9.61319700e-01, 1.03487970e-09],\n",
       "       [9.99643450e-01, 3.56529520e-04, 1.61705980e-12],\n",
       "       [1.02559660e-02, 9.89744000e-01, 5.75162000e-11],\n",
       "       [2.25869940e-03, 9.97741340e-01, 8.01926500e-12],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99736500e-01, 2.48903100e-04, 1.45464730e-05],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.82613500e-01, 1.73864960e-02, 2.57739800e-10],\n",
       "       [9.95524300e-01, 4.47564850e-03, 7.19103850e-08],\n",
       "       [9.71900460e-01, 2.80995740e-02, 2.64107350e-11],\n",
       "       [9.99098660e-01, 9.01342840e-04, 1.45180080e-12],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99938130e-01, 6.18358900e-05, 3.06039480e-09],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [2.25869940e-03, 9.97741340e-01, 8.01926500e-12],\n",
       "       [9.96914400e-01, 3.08558800e-03, 3.19821560e-12],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.15586130e-03, 9.96844200e-01, 1.00453710e-09],\n",
       "       [5.48457000e-03, 9.94515360e-01, 3.37706950e-10],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [6.59397500e-05, 9.99934100e-01, 1.31084040e-12],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [5.43078100e-04, 9.99366700e-01, 9.02021100e-05],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [1.79995630e-02, 9.82000400e-01, 5.67378140e-10],\n",
       "       [3.13958800e-04, 9.99685400e-01, 5.66901460e-07],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.79995630e-02, 9.82000400e-01, 5.67378140e-10],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [1.02559660e-02, 9.89744000e-01, 5.75162000e-11],\n",
       "       [2.12289490e-02, 9.78770900e-01, 1.18824670e-07],\n",
       "       [5.48457000e-03, 9.94515360e-01, 3.37706950e-10],\n",
       "       [9.99660970e-01, 3.39055400e-04, 3.05632600e-17],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.99999900e-01, 1.06502670e-07, 8.92321550e-10],\n",
       "       [9.82454840e-01, 1.75452030e-02, 8.00885750e-12],\n",
       "       [4.07068640e-04, 9.93668000e-01, 5.92496340e-03],\n",
       "       [9.10466900e-03, 9.89481330e-01, 1.41399730e-03],\n",
       "       [2.32953320e-02, 9.76704500e-01, 2.38314660e-07],\n",
       "       [9.65440900e-01, 3.45590970e-02, 6.89599900e-12],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [1.69253810e-02, 9.83074600e-01, 5.34972700e-13],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [9.95023370e-01, 4.97665400e-03, 8.10901300e-15],\n",
       "       [9.99718500e-01, 2.81540000e-04, 1.92498530e-17],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [1.79995630e-02, 9.82000400e-01, 5.67378140e-10],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [7.85195440e-04, 9.99214650e-01, 9.00105500e-08],\n",
       "       [1.05571160e-01, 8.94428800e-01, 2.69265240e-11],\n",
       "       [9.99730170e-01, 2.69773740e-04, 5.80159650e-09],\n",
       "       [9.99919650e-01, 8.03302400e-05, 1.32480920e-12],\n",
       "       [9.96107760e-01, 3.89221470e-03, 9.91608100e-11],\n",
       "       [2.38278230e-03, 9.97617200e-01, 1.06044610e-11],\n",
       "       [6.38183400e-04, 9.99361340e-01, 4.52805470e-07],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [8.80000900e-03, 9.91200030e-01, 1.65730840e-16],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.99830960e-01, 1.68976130e-04, 7.04446160e-13],\n",
       "       [9.71564000e-01, 2.84360330e-02, 3.97520060e-09],\n",
       "       [6.38183400e-04, 9.99361340e-01, 4.52805470e-07],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.99192900e-01, 8.07155900e-04, 2.19427200e-14],\n",
       "       [7.07626500e-01, 2.92373540e-01, 6.43202800e-11],\n",
       "       [3.13958800e-04, 9.99685400e-01, 5.66901460e-07],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99941800e-01, 5.81656060e-05, 7.12778700e-13],\n",
       "       [1.69253810e-02, 9.83074600e-01, 5.34972700e-13],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [5.43078100e-04, 9.99366700e-01, 9.02021100e-05],\n",
       "       [1.96389760e-02, 9.80361000e-01, 3.62083520e-12],\n",
       "       [9.92558500e-01, 7.44145550e-03, 1.11212630e-07],\n",
       "       [2.48223890e-01, 7.51776040e-01, 5.89380780e-08],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [7.77286650e-01, 2.22713320e-01, 2.91776700e-09],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [9.98644400e-01, 1.35554420e-03, 1.52124740e-11],\n",
       "       [9.97666240e-01, 1.06337605e-08, 2.33374330e-03],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [9.99628300e-01, 3.71712200e-04, 2.92582160e-09],\n",
       "       [9.99410750e-01, 5.89294770e-04, 7.03731100e-17],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [2.12289490e-02, 9.78770900e-01, 1.18824670e-07],\n",
       "       [2.12289490e-02, 9.78770900e-01, 1.18824670e-07],\n",
       "       [2.25869940e-03, 9.97741340e-01, 8.01926500e-12],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [9.99503600e-01, 4.96384600e-04, 1.19068850e-18],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99872300e-01, 1.27640200e-04, 9.12093600e-13],\n",
       "       [9.99103700e-01, 8.96289650e-04, 1.55195510e-12],\n",
       "       [2.25869940e-03, 9.97741340e-01, 8.01926500e-12],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.10466900e-03, 9.89481330e-01, 1.41399730e-03],\n",
       "       [1.69253810e-02, 9.83074600e-01, 5.34972700e-13],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.99886750e-01, 1.13206195e-04, 1.20850940e-11],\n",
       "       [6.38183400e-04, 9.99361340e-01, 4.52805470e-07],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [7.66627400e-02, 9.23337300e-01, 4.23258820e-17],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [1.02559660e-02, 9.89744000e-01, 5.75162000e-11],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.02559660e-02, 9.89744000e-01, 5.75162000e-11],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99842500e-01, 1.57416740e-04, 5.69716300e-11],\n",
       "       [9.98860700e-01, 1.13931430e-03, 7.34422900e-14],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [2.36361880e-01, 7.63634100e-01, 4.11383330e-06],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [8.80045400e-01, 1.19954610e-01, 9.27313600e-09],\n",
       "       [4.66436180e-04, 9.99533530e-01, 1.68482970e-11],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99999050e-01, 9.49776000e-07, 1.51492200e-12],\n",
       "       [2.73235680e-02, 9.72676460e-01, 5.22033630e-11],\n",
       "       [9.95279430e-01, 4.72056200e-03, 3.12467980e-12],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [2.12289490e-02, 9.78770900e-01, 1.18824670e-07],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [9.95775500e-01, 4.22448500e-03, 9.75554600e-09],\n",
       "       [9.99738400e-01, 2.61650920e-04, 7.80166600e-09],\n",
       "       [1.96389760e-02, 9.80361000e-01, 3.62083520e-12],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [4.02513600e-02, 9.59748600e-01, 2.58618070e-08],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99987000e-01, 1.30531070e-05, 9.17397000e-11],\n",
       "       [9.91989200e-01, 8.01078800e-03, 2.23220140e-15],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99581040e-01, 4.18969370e-04, 1.18327910e-12],\n",
       "       [2.83444530e-03, 9.97165500e-01, 5.86718200e-15],\n",
       "       [3.86803600e-02, 9.61319700e-01, 1.03487970e-09],\n",
       "       [9.99696970e-01, 3.03088980e-04, 8.64225300e-09],\n",
       "       [9.99959000e-01, 4.10126400e-05, 2.29095580e-11],\n",
       "       [9.83657000e-01, 1.63429640e-02, 9.10105600e-08],\n",
       "       [4.31017300e-03, 9.95668400e-01, 2.13065450e-05],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [6.85571750e-04, 9.99314400e-01, 4.78892870e-10],\n",
       "       [4.07068640e-04, 9.93668000e-01, 5.92496340e-03],\n",
       "       [1.02559660e-02, 9.89744000e-01, 5.75162000e-11],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [1.18672560e-03, 8.07663540e-04, 9.98005570e-01],\n",
       "       [1.13315955e-01, 8.86642700e-01, 4.13365740e-05],\n",
       "       [5.48457000e-03, 9.94515360e-01, 3.37706950e-10],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [3.15586130e-03, 9.96844200e-01, 1.00453710e-09],\n",
       "       [9.99309540e-01, 6.90515800e-04, 1.25309335e-17],\n",
       "       [2.80777180e-02, 9.71922340e-01, 1.88448820e-12],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [9.85138950e-01, 1.48609950e-02, 1.11092070e-10],\n",
       "       [4.31017300e-03, 9.95668400e-01, 2.13065450e-05],\n",
       "       [2.36627370e-04, 9.99763400e-01, 1.00039220e-09],\n",
       "       [7.82478330e-01, 2.17521150e-01, 5.33201400e-07],\n",
       "       [5.43078100e-04, 9.99366700e-01, 9.02021100e-05],\n",
       "       [3.15586130e-03, 9.96844200e-01, 1.00453710e-09],\n",
       "       [1.69253810e-02, 9.83074600e-01, 5.34972700e-13],\n",
       "       [9.99771900e-01, 2.28168600e-04, 9.29369400e-12],\n",
       "       [9.99911200e-01, 8.88215400e-05, 5.22893450e-16],\n",
       "       [9.70678100e-01, 2.93218920e-02, 5.37499000e-08],\n",
       "       [9.99999640e-01, 3.08506150e-07, 2.77731740e-12],\n",
       "       [3.02686100e-06, 1.16119230e-03, 9.98835740e-01],\n",
       "       [2.12289490e-02, 9.78770900e-01, 1.18824670e-07],\n",
       "       [8.80000900e-03, 9.91200030e-01, 1.65730840e-16],\n",
       "       [3.15586130e-03, 9.96844200e-01, 1.00453710e-09],\n",
       "       [9.94291400e-01, 5.70860800e-03, 2.59010160e-08],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99786100e-01, 2.13920180e-04, 1.56802540e-08],\n",
       "       [1.00000000e+00, 1.90046960e-08, 7.85761600e-19],\n",
       "       [9.99971400e-01, 2.85661990e-05, 1.76533100e-08],\n",
       "       [9.97985700e-01, 2.01427600e-03, 7.08518400e-11],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [9.99738400e-01, 2.61650920e-04, 7.80166600e-09],\n",
       "       [3.23752900e-05, 8.90931600e-05, 9.99878500e-01],\n",
       "       [1.18672500e-03, 8.07662000e-04, 9.98005570e-01],\n",
       "       [2.32953410e-02, 9.76704500e-01, 2.38314660e-07],\n",
       "       [9.99738400e-01, 2.61651930e-04, 7.80165100e-09],\n",
       "       [3.02686390e-06, 1.16119440e-03, 9.98835740e-01],\n",
       "       [9.99186340e-01, 8.13659300e-04, 2.54730770e-17],\n",
       "       [3.02686390e-06, 1.16119440e-03, 9.98835740e-01]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964799510254055"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964799510254055"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957912457912458"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002770321025286243"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957912457912458"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002770321025286243"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 97.35%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.002186922149028386\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 99.99%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 5.5162433e-05\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS241     1\n",
       "1      NRS148     2\n",
       "2      NRS255     1\n",
       "3      NRS214     0\n",
       "4      NRS148     2\n",
       "..        ...   ...\n",
       "193  CFBRSa30     0\n",
       "194    NRS266     1\n",
       "195    SR4152     0\n",
       "196    NRS109     2\n",
       "197       115     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 5.5119 - accuracy: 0.4935 - val_loss: 1.5872 - val_accuracy: 0.5707\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 467us/step - loss: 3.5817 - accuracy: 0.5931 - val_loss: 0.9677 - val_accuracy: 0.6818\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 634us/step - loss: 3.1734 - accuracy: 0.6255 - val_loss: 1.1601 - val_accuracy: 0.6869\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 3.1783 - accuracy: 0.6126 - val_loss: 0.9472 - val_accuracy: 0.6970\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 3.0246 - accuracy: 0.6190 - val_loss: 0.9642 - val_accuracy: 0.7323\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 2.8984 - accuracy: 0.6732 - val_loss: 1.2928 - val_accuracy: 0.7677\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 2.8975 - accuracy: 0.6710 - val_loss: 1.1657 - val_accuracy: 0.8030\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 418us/step - loss: 2.5145 - accuracy: 0.7013 - val_loss: 0.9655 - val_accuracy: 0.7828\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 819us/step - loss: 2.7269 - accuracy: 0.6861 - val_loss: 1.0284 - val_accuracy: 0.8030\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 734us/step - loss: 2.8000 - accuracy: 0.6710 - val_loss: 1.1579 - val_accuracy: 0.8081\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 574us/step - loss: 2.3585 - accuracy: 0.6991 - val_loss: 1.0877 - val_accuracy: 0.7879\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 2.6025 - accuracy: 0.7013 - val_loss: 1.1198 - val_accuracy: 0.8131\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 2.2202 - accuracy: 0.7100 - val_loss: 1.1867 - val_accuracy: 0.8485\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 2.2644 - accuracy: 0.7013 - val_loss: 1.0128 - val_accuracy: 0.8384\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 426us/step - loss: 2.6875 - accuracy: 0.6883 - val_loss: 1.0885 - val_accuracy: 0.8485\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 436us/step - loss: 2.0603 - accuracy: 0.7186 - val_loss: 0.9296 - val_accuracy: 0.8535\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 2.2269 - accuracy: 0.6926 - val_loss: 1.2136 - val_accuracy: 0.8586\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 2.0278 - accuracy: 0.7403 - val_loss: 1.1776 - val_accuracy: 0.8384\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 1.8583 - accuracy: 0.7229 - val_loss: 1.0504 - val_accuracy: 0.8687\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 751us/step - loss: 2.3049 - accuracy: 0.7035 - val_loss: 1.7666 - val_accuracy: 0.7929\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.9940 - accuracy: 0.6991 - val_loss: 0.7868 - val_accuracy: 0.8737\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 812us/step - loss: 1.6868 - accuracy: 0.7554 - val_loss: 1.5635 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 823us/step - loss: 1.9371 - accuracy: 0.7208 - val_loss: 1.0875 - val_accuracy: 0.8586\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 675us/step - loss: 1.6267 - accuracy: 0.7338 - val_loss: 0.9096 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 452us/step - loss: 1.8568 - accuracy: 0.7338 - val_loss: 1.0334 - val_accuracy: 0.8485\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 872us/step - loss: 1.5136 - accuracy: 0.7381 - val_loss: 0.7908 - val_accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 984us/step - loss: 1.5070 - accuracy: 0.7792 - val_loss: 1.0946 - val_accuracy: 0.8586\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 536us/step - loss: 1.3096 - accuracy: 0.7684 - val_loss: 0.6962 - val_accuracy: 0.9141\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 1.5641 - accuracy: 0.7424 - val_loss: 1.3281 - val_accuracy: 0.8535\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 884us/step - loss: 1.5206 - accuracy: 0.7359 - val_loss: 0.8280 - val_accuracy: 0.9242\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 626us/step - loss: 1.4854 - accuracy: 0.7424 - val_loss: 1.0702 - val_accuracy: 0.8939\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 690us/step - loss: 1.5019 - accuracy: 0.7251 - val_loss: 1.4123 - val_accuracy: 0.8434\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 577us/step - loss: 1.3199 - accuracy: 0.7338 - val_loss: 0.9277 - val_accuracy: 0.9141\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 734us/step - loss: 1.0831 - accuracy: 0.7922 - val_loss: 0.5705 - val_accuracy: 0.9242\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 555us/step - loss: 1.3796 - accuracy: 0.7468 - val_loss: 0.6392 - val_accuracy: 0.9343\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 558us/step - loss: 1.2396 - accuracy: 0.7641 - val_loss: 0.7587 - val_accuracy: 0.8788\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 831us/step - loss: 1.2459 - accuracy: 0.7446 - val_loss: 0.6049 - val_accuracy: 0.9394\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 588us/step - loss: 1.1781 - accuracy: 0.7489 - val_loss: 0.8095 - val_accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 894us/step - loss: 1.0748 - accuracy: 0.7900 - val_loss: 0.7406 - val_accuracy: 0.9242\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 934us/step - loss: 0.9681 - accuracy: 0.7662 - val_loss: 0.7543 - val_accuracy: 0.9343\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 649us/step - loss: 0.9042 - accuracy: 0.8052 - val_loss: 0.6829 - val_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 468us/step - loss: 0.9705 - accuracy: 0.8009 - val_loss: 0.6328 - val_accuracy: 0.9242\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 609us/step - loss: 1.0030 - accuracy: 0.7446 - val_loss: 0.8770 - val_accuracy: 0.9293\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 707us/step - loss: 0.8778 - accuracy: 0.7532 - val_loss: 0.6611 - val_accuracy: 0.9394\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 890us/step - loss: 0.9325 - accuracy: 0.7727 - val_loss: 0.9317 - val_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.0000 - accuracy: 0.7619 - val_loss: 0.8180 - val_accuracy: 0.9141\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 868us/step - loss: 0.9210 - accuracy: 0.7792 - val_loss: 0.8221 - val_accuracy: 0.9242\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 366us/step - loss: 0.7123 - accuracy: 0.8009 - val_loss: 0.6885 - val_accuracy: 0.9394\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 555us/step - loss: 1.0495 - accuracy: 0.7814 - val_loss: 1.0545 - val_accuracy: 0.9040\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 569us/step - loss: 0.8001 - accuracy: 0.8203 - val_loss: 0.5915 - val_accuracy: 0.9697\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 540us/step - loss: 0.6449 - accuracy: 0.8290 - val_loss: 0.7271 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 459us/step - loss: 0.7075 - accuracy: 0.7879 - val_loss: 0.5557 - val_accuracy: 0.9343\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 569us/step - loss: 0.9493 - accuracy: 0.7922 - val_loss: 0.8492 - val_accuracy: 0.8990\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 0.8862 - accuracy: 0.7749 - val_loss: 0.7390 - val_accuracy: 0.9091\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 497us/step - loss: 0.8560 - accuracy: 0.7814 - val_loss: 0.7584 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 510us/step - loss: 0.8135 - accuracy: 0.7532 - val_loss: 0.6734 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 340us/step - loss: 0.8509 - accuracy: 0.7879 - val_loss: 1.0065 - val_accuracy: 0.9343\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 1.0456 - accuracy: 0.7727 - val_loss: 0.9897 - val_accuracy: 0.9293\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 0.9309 - accuracy: 0.7576 - val_loss: 1.0163 - val_accuracy: 0.9293\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 0.8784 - accuracy: 0.7641 - val_loss: 1.5296 - val_accuracy: 0.8990\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.9912 - accuracy: 0.7814 - val_loss: 0.9218 - val_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.7651 - accuracy: 0.8117 - val_loss: 0.9188 - val_accuracy: 0.9343\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.6801 - accuracy: 0.7879 - val_loss: 0.6656 - val_accuracy: 0.9394\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.7134 - accuracy: 0.7532 - val_loss: 0.5750 - val_accuracy: 0.9596\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.9445 - accuracy: 0.7749 - val_loss: 1.0583 - val_accuracy: 0.8788\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 650us/step - loss: 0.9474 - accuracy: 0.7641 - val_loss: 0.6240 - val_accuracy: 0.9545\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 0.5438 - accuracy: 0.8030 - val_loss: 0.7336 - val_accuracy: 0.9545\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 868us/step - loss: 0.6551 - accuracy: 0.7965 - val_loss: 0.8824 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 0.7318 - accuracy: 0.7684 - val_loss: 0.7380 - val_accuracy: 0.9394\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.6445 - accuracy: 0.8052 - val_loss: 0.8461 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 470us/step - loss: 0.6437 - accuracy: 0.8095 - val_loss: 0.7165 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 577us/step - loss: 0.6966 - accuracy: 0.7922 - val_loss: 0.7508 - val_accuracy: 0.9495\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 588us/step - loss: 0.5007 - accuracy: 0.8009 - val_loss: 0.8076 - val_accuracy: 0.9495\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 520us/step - loss: 0.6633 - accuracy: 0.7857 - val_loss: 0.6045 - val_accuracy: 0.9545\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 513us/step - loss: 0.6791 - accuracy: 0.7900 - val_loss: 0.5928 - val_accuracy: 0.9646\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.5437 - accuracy: 0.8009 - val_loss: 0.9573 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 966us/step - loss: 0.7184 - accuracy: 0.7771 - val_loss: 0.8848 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 527us/step - loss: 0.6367 - accuracy: 0.8095 - val_loss: 0.6540 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.5898 - accuracy: 0.8074 - val_loss: 0.5882 - val_accuracy: 0.9596\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 534us/step - loss: 0.6436 - accuracy: 0.7706 - val_loss: 0.5829 - val_accuracy: 0.9646\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.8030 - val_loss: 0.4098 - val_accuracy: 0.9596\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 512us/step - loss: 0.6245 - accuracy: 0.8160 - val_loss: 0.4436 - val_accuracy: 0.9747\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.5678 - accuracy: 0.8117 - val_loss: 0.6458 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 870us/step - loss: 0.5472 - accuracy: 0.7727 - val_loss: 0.4539 - val_accuracy: 0.9646\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.5423 - accuracy: 0.7879 - val_loss: 0.7043 - val_accuracy: 0.9596\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.4517 - accuracy: 0.7965 - val_loss: 0.5044 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 615us/step - loss: 0.4974 - accuracy: 0.8030 - val_loss: 0.6221 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.5632 - accuracy: 0.7727 - val_loss: 0.8448 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.4311 - accuracy: 0.8095 - val_loss: 0.6321 - val_accuracy: 0.9545\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.5107 - accuracy: 0.7835 - val_loss: 0.5913 - val_accuracy: 0.9646\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 520us/step - loss: 0.5323 - accuracy: 0.8074 - val_loss: 0.9592 - val_accuracy: 0.9394\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.4803 - accuracy: 0.7835 - val_loss: 0.6026 - val_accuracy: 0.9596\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 562us/step - loss: 0.5264 - accuracy: 0.7706 - val_loss: 0.5974 - val_accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 407us/step - loss: 0.3827 - accuracy: 0.8442 - val_loss: 0.4686 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.4745 - accuracy: 0.8117 - val_loss: 0.6254 - val_accuracy: 0.9596\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.4932 - accuracy: 0.7684 - val_loss: 0.7131 - val_accuracy: 0.9596\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 634us/step - loss: 0.5076 - accuracy: 0.7792 - val_loss: 0.8635 - val_accuracy: 0.9394\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.4893 - accuracy: 0.7879 - val_loss: 0.5588 - val_accuracy: 0.9646\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 425us/step - loss: 0.4579 - accuracy: 0.8009 - val_loss: 0.4617 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 413us/step - loss: 0.5482 - accuracy: 0.8052 - val_loss: 0.4968 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38c92748>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 167us/step\n",
      "over-sampling test accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 1,\n",
       "       2, 2, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2,\n",
       "       0, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2, 0, 0,\n",
       "       2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 0, 1, 0, 2, 1,\n",
       "       1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2,\n",
       "       0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 0, 1, 2,\n",
       "       2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS241     1     1\n",
       "1      NRS148     2     2\n",
       "2      NRS255     1     1\n",
       "3      NRS214     0     0\n",
       "4      NRS148     2     2\n",
       "..        ...   ...   ...\n",
       "193  CFBRSa30     0     0\n",
       "194    NRS266     1     1\n",
       "195    SR4152     0     0\n",
       "196    NRS109     2     2\n",
       "197       115     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.010424e-03</td>\n",
       "      <td>9.989893e-01</td>\n",
       "      <td>2.661334e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.171583e-14</td>\n",
       "      <td>1.380678e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.208902e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.522147e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.010950e-12</td>\n",
       "      <td>7.298213e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.171583e-14</td>\n",
       "      <td>1.380678e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.208899e-15</td>\n",
       "      <td>1.537287e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>6.152107e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.621104e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.045865e-11</td>\n",
       "      <td>8.918558e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>4.125410e-12</td>\n",
       "      <td>1.115170e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.107970e-02</td>\n",
       "      <td>9.618005e-01</td>\n",
       "      <td>1.711991e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.010424e-03  9.989893e-01  2.661334e-07\n",
       "1    1.171583e-14  1.380678e-15  1.000000e+00\n",
       "2    6.208902e-13  1.000000e+00  2.522147e-14\n",
       "3    1.000000e+00  1.010950e-12  7.298213e-14\n",
       "4    1.171583e-14  1.380678e-15  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "193  1.000000e+00  3.208899e-15  1.537287e-16\n",
       "194  6.152107e-09  1.000000e+00  1.621104e-10\n",
       "195  1.000000e+00  1.045865e-11  8.918558e-13\n",
       "196  4.125410e-12  1.115170e-12  1.000000e+00\n",
       "197  2.107970e-02  9.618005e-01  1.711991e-02\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.6857 - accuracy: 0.8139 - val_loss: 0.7262 - val_accuracy: 0.9495\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.6256 - accuracy: 0.8030 - val_loss: 0.6635 - val_accuracy: 0.9495\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.5761 - accuracy: 0.8203 - val_loss: 0.5914 - val_accuracy: 0.9545\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.6384 - accuracy: 0.8160 - val_loss: 0.6722 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5305 - accuracy: 0.7987 - val_loss: 0.6152 - val_accuracy: 0.9646\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5755 - accuracy: 0.8074 - val_loss: 0.5865 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5525 - accuracy: 0.8139 - val_loss: 0.6303 - val_accuracy: 0.9596\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6383 - accuracy: 0.7987 - val_loss: 0.6149 - val_accuracy: 0.9596\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.6737 - accuracy: 0.8052 - val_loss: 0.6673 - val_accuracy: 0.9545\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.6406 - accuracy: 0.8052 - val_loss: 0.6285 - val_accuracy: 0.9646\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.6237 - accuracy: 0.8009 - val_loss: 0.7179 - val_accuracy: 0.9545\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6035 - accuracy: 0.7835 - val_loss: 0.5517 - val_accuracy: 0.9697\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.5246 - accuracy: 0.7857 - val_loss: 0.7419 - val_accuracy: 0.9545\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.6658 - accuracy: 0.7922 - val_loss: 0.5707 - val_accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.5903 - accuracy: 0.7900 - val_loss: 0.7434 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.5288 - accuracy: 0.8182 - val_loss: 0.7169 - val_accuracy: 0.9495\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.6362 - accuracy: 0.7900 - val_loss: 0.5240 - val_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.5972 - accuracy: 0.8095 - val_loss: 0.6905 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6005 - accuracy: 0.7749 - val_loss: 0.6534 - val_accuracy: 0.9495\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5195 - accuracy: 0.7792 - val_loss: 0.5067 - val_accuracy: 0.9747\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.5524 - accuracy: 0.8052 - val_loss: 0.6417 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.5974 - accuracy: 0.7944 - val_loss: 0.7559 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.7061 - accuracy: 0.7900 - val_loss: 0.8510 - val_accuracy: 0.9545\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.6004 - accuracy: 0.7944 - val_loss: 0.4374 - val_accuracy: 0.9747\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.4995 - accuracy: 0.8312 - val_loss: 0.8104 - val_accuracy: 0.9394\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5902 - accuracy: 0.7879 - val_loss: 0.5608 - val_accuracy: 0.9697\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.6278 - accuracy: 0.8074 - val_loss: 0.7138 - val_accuracy: 0.9545\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 0.6434 - accuracy: 0.8052 - val_loss: 0.4741 - val_accuracy: 0.9697\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 0.5195 - accuracy: 0.8052 - val_loss: 0.8540 - val_accuracy: 0.9343\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.5325 - accuracy: 0.8225 - val_loss: 0.5018 - val_accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.5426 - accuracy: 0.8030 - val_loss: 0.5202 - val_accuracy: 0.9596\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.5598 - accuracy: 0.8074 - val_loss: 0.7417 - val_accuracy: 0.9495\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 0.5346 - accuracy: 0.8225 - val_loss: 0.6956 - val_accuracy: 0.9545\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.5060 - accuracy: 0.7965 - val_loss: 0.6560 - val_accuracy: 0.9545\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.6282 - accuracy: 0.7532 - val_loss: 0.6303 - val_accuracy: 0.9545\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 0.4865 - accuracy: 0.8139 - val_loss: 0.7810 - val_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.5395 - accuracy: 0.7987 - val_loss: 0.4941 - val_accuracy: 0.9646\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.6196 - accuracy: 0.7706 - val_loss: 0.7396 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.5768 - accuracy: 0.7749 - val_loss: 0.6904 - val_accuracy: 0.9545\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 352us/step - loss: 0.5979 - accuracy: 0.7597 - val_loss: 0.6412 - val_accuracy: 0.9495\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.5259 - accuracy: 0.7944 - val_loss: 0.8011 - val_accuracy: 0.9495\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.6759 - accuracy: 0.8030 - val_loss: 0.5562 - val_accuracy: 0.9697\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.4847 - accuracy: 0.8009 - val_loss: 0.5938 - val_accuracy: 0.9545\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.4849 - accuracy: 0.7987 - val_loss: 0.6451 - val_accuracy: 0.9545\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 552us/step - loss: 0.4634 - accuracy: 0.8095 - val_loss: 0.5060 - val_accuracy: 0.9697\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 424us/step - loss: 0.4610 - accuracy: 0.8139 - val_loss: 0.5664 - val_accuracy: 0.9545\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 363us/step - loss: 0.4644 - accuracy: 0.7965 - val_loss: 0.7147 - val_accuracy: 0.9394\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 437us/step - loss: 0.5233 - accuracy: 0.7792 - val_loss: 0.5762 - val_accuracy: 0.9646\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.5772 - accuracy: 0.7900 - val_loss: 0.4082 - val_accuracy: 0.9747\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.5488 - accuracy: 0.7987 - val_loss: 0.8478 - val_accuracy: 0.9394\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.4930 - accuracy: 0.8074 - val_loss: 0.5844 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.4363 - accuracy: 0.8268 - val_loss: 0.6542 - val_accuracy: 0.9596\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.5177 - accuracy: 0.8182 - val_loss: 0.6778 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.5923 - accuracy: 0.7922 - val_loss: 0.6592 - val_accuracy: 0.9596\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5947 - accuracy: 0.7987 - val_loss: 0.7412 - val_accuracy: 0.9545\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.6303 - accuracy: 0.7749 - val_loss: 0.5908 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.5862 - accuracy: 0.7900 - val_loss: 0.5155 - val_accuracy: 0.9747\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.5286 - accuracy: 0.8333 - val_loss: 0.8280 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.4949 - accuracy: 0.8182 - val_loss: 0.4816 - val_accuracy: 0.9697\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.4919 - accuracy: 0.8030 - val_loss: 0.6138 - val_accuracy: 0.9545\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.5404 - accuracy: 0.7857 - val_loss: 0.8611 - val_accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.6215 - accuracy: 0.7857 - val_loss: 0.6417 - val_accuracy: 0.9596\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.4658 - accuracy: 0.7879 - val_loss: 0.4440 - val_accuracy: 0.9697\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.4604 - accuracy: 0.8009 - val_loss: 0.8355 - val_accuracy: 0.9242\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.5121 - accuracy: 0.7965 - val_loss: 0.6118 - val_accuracy: 0.9646\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.4949 - accuracy: 0.8117 - val_loss: 0.4997 - val_accuracy: 0.9646\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.4883 - accuracy: 0.8052 - val_loss: 0.5766 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.5086 - accuracy: 0.8268 - val_loss: 0.4743 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.9825 - accuracy: 0.7749 - val_loss: 1.1755 - val_accuracy: 0.9242\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.7822 - accuracy: 0.7771 - val_loss: 0.6851 - val_accuracy: 0.9545\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.5074 - accuracy: 0.8182 - val_loss: 0.5795 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.4987 - accuracy: 0.7835 - val_loss: 0.6442 - val_accuracy: 0.9545\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.5751 - accuracy: 0.7684 - val_loss: 1.0193 - val_accuracy: 0.9343\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.5763 - accuracy: 0.7965 - val_loss: 0.5425 - val_accuracy: 0.9646\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.4672 - accuracy: 0.8139 - val_loss: 0.6339 - val_accuracy: 0.9697\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 0.5029 - accuracy: 0.8052 - val_loss: 0.5925 - val_accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.4615 - accuracy: 0.8182 - val_loss: 0.6056 - val_accuracy: 0.9545\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.4689 - accuracy: 0.7857 - val_loss: 0.6980 - val_accuracy: 0.9495\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4983 - accuracy: 0.7900 - val_loss: 0.6633 - val_accuracy: 0.9545\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.4627 - accuracy: 0.7987 - val_loss: 0.7145 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.4905 - accuracy: 0.7987 - val_loss: 0.5259 - val_accuracy: 0.9596\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.5067 - accuracy: 0.7814 - val_loss: 0.8022 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.5376 - accuracy: 0.7446 - val_loss: 0.5235 - val_accuracy: 0.9697\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.4722 - accuracy: 0.7987 - val_loss: 0.6346 - val_accuracy: 0.9596\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.4333 - accuracy: 0.8268 - val_loss: 0.6400 - val_accuracy: 0.9545\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.4846 - accuracy: 0.7944 - val_loss: 0.5169 - val_accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.4920 - accuracy: 0.7944 - val_loss: 0.6424 - val_accuracy: 0.9596\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.4927 - accuracy: 0.8117 - val_loss: 0.5668 - val_accuracy: 0.9646\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.4814 - accuracy: 0.7900 - val_loss: 0.3443 - val_accuracy: 0.9596\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.4020 - accuracy: 0.8442 - val_loss: 0.9424 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.4256 - accuracy: 0.7922 - val_loss: 0.4959 - val_accuracy: 0.9596\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.5962 - accuracy: 0.8009 - val_loss: 0.7522 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.4678 - accuracy: 0.8052 - val_loss: 0.7384 - val_accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.4802 - accuracy: 0.7814 - val_loss: 0.8480 - val_accuracy: 0.9343\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.4457 - accuracy: 0.8030 - val_loss: 0.6174 - val_accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.3806 - accuracy: 0.8290 - val_loss: 0.5226 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.5254 - accuracy: 0.7879 - val_loss: 0.8514 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.4591 - accuracy: 0.8160 - val_loss: 0.5152 - val_accuracy: 0.9646\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.4915 - accuracy: 0.7965 - val_loss: 0.6719 - val_accuracy: 0.9596\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.5472 - accuracy: 0.7944 - val_loss: 1.0363 - val_accuracy: 0.9343\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.92%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01042390e-03, 9.98989300e-01, 2.66133360e-07],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [6.20890200e-13, 1.00000000e+00, 2.52214660e-14],\n",
       "       [1.00000000e+00, 1.01095010e-12, 7.29821300e-14],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [6.59399170e-06, 9.99993440e-01, 1.21551270e-09],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [7.05474650e-08, 9.99999900e-01, 3.39856570e-09],\n",
       "       [3.29710060e-05, 9.99967000e-01, 8.31547100e-11],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [8.64502100e-09, 1.00000000e+00, 2.47795400e-10],\n",
       "       [1.00000000e+00, 6.37299230e-24, 7.31899400e-26],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.98721130e-05, 9.99965300e-01, 4.79001030e-06],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [2.98721130e-05, 9.99965300e-01, 4.79001030e-06],\n",
       "       [6.59399170e-06, 9.99993440e-01, 1.21551270e-09],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.39757160e-07, 9.99999760e-01, 7.78957040e-11],\n",
       "       [3.25238700e-09, 1.00000000e+00, 2.56156680e-10],\n",
       "       [1.00000000e+00, 2.35659780e-09, 1.83622960e-10],\n",
       "       [3.58611740e-06, 9.99995470e-01, 9.55472500e-07],\n",
       "       [1.00000000e+00, 1.45547920e-16, 5.59307600e-18],\n",
       "       [1.00000000e+00, 5.30639960e-25, 5.10455000e-27],\n",
       "       [1.00000000e+00, 9.46558000e-14, 5.77186100e-15],\n",
       "       [1.00000000e+00, 1.53266540e-10, 1.55055970e-11],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.13356090e-12, 5.95446900e-14],\n",
       "       [1.00000000e+00, 7.30416160e-17, 2.67220720e-18],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.76911440e-25, 1.57364930e-27],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.39980150e-15, 6.32093600e-17],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.28336660e-19, 2.98713680e-21],\n",
       "       [1.23750840e-06, 9.99998800e-01, 6.62386060e-09],\n",
       "       [3.58611740e-06, 9.99995470e-01, 9.55472500e-07],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.30416160e-17, 2.67220720e-18],\n",
       "       [1.00000000e+00, 1.51308170e-11, 1.62922880e-13],\n",
       "       [1.23750840e-06, 9.99998800e-01, 6.62386060e-09],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.78170570e-24, 1.86847780e-26],\n",
       "       [1.00000000e+00, 1.64992710e-10, 1.71268640e-11],\n",
       "       [2.10797040e-02, 9.61800460e-01, 1.71199100e-02],\n",
       "       [1.55762270e-08, 1.00000000e+00, 5.16450940e-10],\n",
       "       [1.00000000e+00, 2.12086960e-17, 7.10448060e-19],\n",
       "       [1.87854060e-11, 1.00000000e+00, 3.41953240e-11],\n",
       "       [1.00000000e+00, 1.69402440e-23, 2.08591020e-25],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.66057520e-15, 7.59037600e-17],\n",
       "       [2.39757160e-07, 9.99999760e-01, 7.78957040e-11],\n",
       "       [4.31474870e-13, 1.00000000e+00, 1.71790070e-12],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.50075680e-19, 3.53229700e-21],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.30416160e-17, 2.67220720e-18],\n",
       "       [6.20890200e-13, 1.00000000e+00, 2.52214660e-14],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.20883990e-11, 1.00000000e+00, 6.74549600e-14],\n",
       "       [1.00000000e+00, 5.24706300e-16, 2.20932150e-17],\n",
       "       [1.00000000e+00, 9.90319160e-17, 2.85175310e-18],\n",
       "       [9.99999640e-01, 3.94163380e-07, 5.47508840e-11],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.91326470e-16, 1.17626130e-17],\n",
       "       [4.31474870e-13, 1.00000000e+00, 1.71790070e-12],\n",
       "       [3.45801200e-08, 1.00000000e+00, 1.39654950e-09],\n",
       "       [1.00000000e+00, 2.66022530e-11, 2.42458800e-12],\n",
       "       [1.00000000e+00, 2.09098350e-19, 5.03924800e-21],\n",
       "       [4.75343800e-08, 1.00000000e+00, 2.07688360e-09],\n",
       "       [1.00000000e+00, 1.88697860e-27, 1.21437045e-29],\n",
       "       [1.77763060e-07, 9.99999900e-01, 1.05597250e-08],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.15096300e-14, 2.06716320e-15],\n",
       "       [5.67490340e-01, 4.12896220e-01, 1.96133850e-02],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.01042390e-03, 9.98989300e-01, 2.66133360e-07],\n",
       "       [1.00000000e+00, 7.04775200e-16, 3.03057440e-17],\n",
       "       [2.10797040e-02, 9.61800460e-01, 1.71199100e-02],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.80258160e-21, 6.50171650e-23],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [7.05474650e-08, 9.99999900e-01, 3.39856570e-09],\n",
       "       [9.07516100e-08, 9.99999760e-01, 1.50091440e-07],\n",
       "       [1.00000000e+00, 1.45266320e-21, 2.45666180e-23],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.24011100e-09, 6.48890000e-10],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.35529760e-14, 1.30062400e-15],\n",
       "       [2.10797040e-02, 9.61800460e-01, 1.71199100e-02],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.30375240e-09, 3.51340500e-12],\n",
       "       [4.31401900e-08, 1.00000000e+00, 1.84021350e-09],\n",
       "       [2.48387370e-10, 1.00000000e+00, 1.03177356e-10],\n",
       "       [3.88293170e-06, 9.99995600e-01, 4.19287830e-07],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [1.01042390e-03, 9.98989300e-01, 2.66133360e-07],\n",
       "       [9.90002400e-01, 9.99749200e-03, 7.42632700e-08],\n",
       "       [1.87854060e-11, 1.00000000e+00, 3.41953240e-11],\n",
       "       [5.35083670e-09, 1.00000000e+00, 8.31282100e-09],\n",
       "       [1.00000000e+00, 1.18707130e-31, 8.70736340e-23],\n",
       "       [4.31474870e-13, 1.00000000e+00, 1.71790070e-12],\n",
       "       [9.92166900e-12, 1.00000000e+00, 1.68024260e-11],\n",
       "       [9.07516100e-08, 9.99999760e-01, 1.50091440e-07],\n",
       "       [7.05474650e-08, 9.99999900e-01, 3.39856570e-09],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.31432410e-06, 9.99998700e-01, 1.91474970e-10],\n",
       "       [4.31401900e-08, 1.00000000e+00, 1.84021350e-09],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [6.15211840e-09, 1.00000000e+00, 1.62110990e-10],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.93533290e-13, 1.07926390e-14],\n",
       "       [9.07516100e-08, 9.99999760e-01, 1.50091440e-07],\n",
       "       [1.00000000e+00, 7.18951300e-12, 4.67339760e-13],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [2.10797040e-02, 9.61800460e-01, 1.71199100e-02],\n",
       "       [6.20890200e-13, 1.00000000e+00, 2.52214660e-14],\n",
       "       [6.59399170e-06, 9.99993440e-01, 1.21551270e-09],\n",
       "       [9.92166900e-12, 1.00000000e+00, 1.68024260e-11],\n",
       "       [9.99999760e-01, 1.91334920e-07, 3.28425500e-08],\n",
       "       [5.53962750e-19, 1.00000000e+00, 2.65233250e-18],\n",
       "       [1.00000000e+00, 2.91326470e-16, 1.17626130e-17],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [9.51200540e-01, 4.87980470e-02, 1.45668280e-06],\n",
       "       [1.00000000e+00, 7.39292250e-14, 4.42927300e-15],\n",
       "       [1.23750840e-06, 9.99998800e-01, 6.62386060e-09],\n",
       "       [3.25238700e-09, 1.00000000e+00, 2.56156680e-10],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.20228720e-10, 1.22017670e-11],\n",
       "       [3.29710060e-05, 9.99967000e-01, 8.31547100e-11],\n",
       "       [1.00000000e+00, 7.65999830e-28, 1.74432690e-17],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.87854060e-11, 1.00000000e+00, 3.41953240e-11],\n",
       "       [6.59399170e-06, 9.99993440e-01, 1.21551270e-09],\n",
       "       [1.77763060e-07, 9.99999900e-01, 1.05597250e-08],\n",
       "       [5.53962750e-19, 1.00000000e+00, 2.65233250e-18],\n",
       "       [1.00000000e+00, 2.98120060e-17, 7.88930300e-19],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.31528710e-17, 7.80435300e-19],\n",
       "       [1.64811060e-05, 9.99981160e-01, 2.35507420e-06],\n",
       "       [1.00000000e+00, 4.78670450e-14, 2.78033550e-15],\n",
       "       [1.00000000e+00, 2.61133550e-30, 1.57689400e-20],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [5.75080680e-11, 1.00000000e+00, 9.81023670e-11],\n",
       "       [5.53962750e-19, 1.00000000e+00, 2.65233250e-18],\n",
       "       [1.23750840e-06, 9.99998800e-01, 6.62386060e-09],\n",
       "       [7.05474650e-08, 9.99999900e-01, 3.39856570e-09],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.24376920e-02, 9.87561700e-01, 6.02350600e-07],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.56350030e-17, 1.60499420e-18],\n",
       "       [5.35083670e-09, 1.00000000e+00, 8.31282100e-09],\n",
       "       [1.00000000e+00, 4.77770000e-11, 4.54009800e-12],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [4.31474870e-13, 1.00000000e+00, 1.71790070e-12],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [9.99997400e-01, 2.15154820e-06, 4.37700070e-07],\n",
       "       [6.60461960e-12, 1.00000000e+00, 1.17812850e-11],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [9.84705500e-01, 1.52944930e-02, 4.24980500e-08],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00674950e-12, 3.82049920e-16],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.59336270e-11, 8.89232740e-14],\n",
       "       [2.42376170e-11, 8.64185900e-12, 1.00000000e+00],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [4.12541800e-12, 1.11517380e-12, 1.00000000e+00],\n",
       "       [2.39757160e-07, 9.99999760e-01, 7.78957040e-11],\n",
       "       [2.39757160e-07, 9.99999760e-01, 7.78957040e-11],\n",
       "       [1.00000000e+00, 2.37893880e-13, 1.23668370e-14],\n",
       "       [1.17158345e-14, 1.38067790e-15, 1.00000000e+00],\n",
       "       [5.35083670e-09, 1.00000000e+00, 8.31282100e-09],\n",
       "       [1.00000000e+00, 1.92302460e-13, 1.23337640e-14],\n",
       "       [6.15210700e-09, 1.00000000e+00, 1.62110380e-10],\n",
       "       [1.00000000e+00, 3.20889900e-15, 1.53728660e-16],\n",
       "       [6.15210700e-09, 1.00000000e+00, 1.62110380e-10],\n",
       "       [1.00000000e+00, 1.04586450e-11, 8.91855760e-13],\n",
       "       [4.12540960e-12, 1.11516960e-12, 1.00000000e+00],\n",
       "       [2.10797040e-02, 9.61800460e-01, 1.71199100e-02]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891720232629323"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891720232629323"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS209     2\n",
       "1       NRS386     1\n",
       "2       NRS148     2\n",
       "3       NRS178     0\n",
       "4       NRS237     0\n",
       "..         ...   ...\n",
       "193     NRS209     2\n",
       "194     NRS002     0\n",
       "195     NRS109     2\n",
       "196  BCH-SA-03     1\n",
       "197  BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 6.7380 - accuracy: 0.4113 - val_loss: 1.7001 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 474us/step - loss: 4.3364 - accuracy: 0.5195 - val_loss: 1.1548 - val_accuracy: 0.5505\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 4.1968 - accuracy: 0.5758 - val_loss: 0.9219 - val_accuracy: 0.7020\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 4.0467 - accuracy: 0.5931 - val_loss: 0.8227 - val_accuracy: 0.7727\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 3.4063 - accuracy: 0.6450 - val_loss: 0.7877 - val_accuracy: 0.7576\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 3.5021 - accuracy: 0.6450 - val_loss: 0.7555 - val_accuracy: 0.7626\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 3.8422 - accuracy: 0.6147 - val_loss: 0.7560 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 3.8368 - accuracy: 0.6169 - val_loss: 0.7779 - val_accuracy: 0.7828\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 3.3143 - accuracy: 0.6429 - val_loss: 0.8064 - val_accuracy: 0.7677\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 951us/step - loss: 3.3473 - accuracy: 0.6320 - val_loss: 0.7314 - val_accuracy: 0.7677\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 3.5250 - accuracy: 0.6450 - val_loss: 0.8596 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 3.3672 - accuracy: 0.6364 - val_loss: 0.9564 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 2.8679 - accuracy: 0.6667 - val_loss: 1.0427 - val_accuracy: 0.7727\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 3.2906 - accuracy: 0.6212 - val_loss: 1.0790 - val_accuracy: 0.7677\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 595us/step - loss: 2.6337 - accuracy: 0.6537 - val_loss: 1.0344 - val_accuracy: 0.7626\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 2.7216 - accuracy: 0.6710 - val_loss: 0.9992 - val_accuracy: 0.7424\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 2.6951 - accuracy: 0.6450 - val_loss: 1.0198 - val_accuracy: 0.7525\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 2.5372 - accuracy: 0.6775 - val_loss: 0.9668 - val_accuracy: 0.7626\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 2.7889 - accuracy: 0.6732 - val_loss: 1.0724 - val_accuracy: 0.7525\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 541us/step - loss: 2.8192 - accuracy: 0.6580 - val_loss: 1.1441 - val_accuracy: 0.7475\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 2.4490 - accuracy: 0.6753 - val_loss: 1.0700 - val_accuracy: 0.7525\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 2.4277 - accuracy: 0.6710 - val_loss: 1.1087 - val_accuracy: 0.7576\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 2.3106 - accuracy: 0.6861 - val_loss: 0.9384 - val_accuracy: 0.7576\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 2.1860 - accuracy: 0.7056 - val_loss: 1.0241 - val_accuracy: 0.7677\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 2.3415 - accuracy: 0.7013 - val_loss: 1.0045 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 2.1852 - accuracy: 0.6991 - val_loss: 1.1064 - val_accuracy: 0.7677\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 2.3110 - accuracy: 0.6732 - val_loss: 0.9926 - val_accuracy: 0.7677\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 469us/step - loss: 2.1955 - accuracy: 0.6602 - val_loss: 0.8847 - val_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 2.1074 - accuracy: 0.7143 - val_loss: 0.9440 - val_accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 2.4179 - accuracy: 0.6732 - val_loss: 0.8281 - val_accuracy: 0.7828\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 2.0471 - accuracy: 0.7035 - val_loss: 1.0478 - val_accuracy: 0.7828\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 1.7062 - accuracy: 0.7294 - val_loss: 0.9189 - val_accuracy: 0.8384\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 375us/step - loss: 1.7383 - accuracy: 0.7143 - val_loss: 0.8991 - val_accuracy: 0.8030\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 2.0485 - accuracy: 0.7013 - val_loss: 0.7890 - val_accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 1.7252 - accuracy: 0.7229 - val_loss: 0.7993 - val_accuracy: 0.8030\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.7833 - accuracy: 0.7056 - val_loss: 0.8949 - val_accuracy: 0.8131\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 1.9475 - accuracy: 0.7078 - val_loss: 1.0745 - val_accuracy: 0.8182\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 1.9279 - accuracy: 0.7056 - val_loss: 0.9757 - val_accuracy: 0.7980\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 1.3987 - accuracy: 0.7597 - val_loss: 1.0536 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 1.8243 - accuracy: 0.7316 - val_loss: 0.9121 - val_accuracy: 0.7828\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 1.5755 - accuracy: 0.7381 - val_loss: 0.7558 - val_accuracy: 0.8788\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 1.6186 - accuracy: 0.7554 - val_loss: 0.7764 - val_accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 1.4414 - accuracy: 0.7403 - val_loss: 0.9014 - val_accuracy: 0.8636\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 1.7972 - accuracy: 0.7229 - val_loss: 0.9460 - val_accuracy: 0.8586\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.4090 - accuracy: 0.7511 - val_loss: 0.7940 - val_accuracy: 0.8939\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.3501 - accuracy: 0.7597 - val_loss: 0.9521 - val_accuracy: 0.8838\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 1.4197 - accuracy: 0.7576 - val_loss: 0.7336 - val_accuracy: 0.8939\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 1.2942 - accuracy: 0.7597 - val_loss: 0.9120 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 1.3282 - accuracy: 0.7468 - val_loss: 1.1514 - val_accuracy: 0.8687\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 1.5650 - accuracy: 0.7403 - val_loss: 1.0148 - val_accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 1.4859 - accuracy: 0.7359 - val_loss: 0.7590 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 1.2203 - accuracy: 0.7727 - val_loss: 0.7659 - val_accuracy: 0.9141\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.0477 - accuracy: 0.7792 - val_loss: 0.7370 - val_accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 1.3084 - accuracy: 0.7424 - val_loss: 0.7484 - val_accuracy: 0.9141\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 1.1009 - accuracy: 0.7857 - val_loss: 0.9390 - val_accuracy: 0.8939\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 1.1262 - accuracy: 0.7619 - val_loss: 0.7729 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 1.1678 - accuracy: 0.7489 - val_loss: 0.8501 - val_accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 1.2515 - accuracy: 0.7424 - val_loss: 0.8911 - val_accuracy: 0.9091\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.2916 - accuracy: 0.7316 - val_loss: 0.6882 - val_accuracy: 0.8838\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 1.2354 - accuracy: 0.7597 - val_loss: 0.8152 - val_accuracy: 0.9293\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.1199 - accuracy: 0.7727 - val_loss: 0.7966 - val_accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 1.1686 - accuracy: 0.7706 - val_loss: 0.7746 - val_accuracy: 0.8939\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 1.1383 - accuracy: 0.7662 - val_loss: 0.8289 - val_accuracy: 0.8939\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 1.1840 - accuracy: 0.7446 - val_loss: 0.7667 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 1.1461 - accuracy: 0.7489 - val_loss: 0.6870 - val_accuracy: 0.9242\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.9319 - accuracy: 0.7554 - val_loss: 0.8204 - val_accuracy: 0.9242\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 1.1534 - accuracy: 0.7186 - val_loss: 0.6850 - val_accuracy: 0.9444\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.0116 - accuracy: 0.8009 - val_loss: 0.6751 - val_accuracy: 0.9545\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.9768 - accuracy: 0.7922 - val_loss: 0.7960 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 1.1562 - accuracy: 0.7749 - val_loss: 0.8685 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 1.1095 - accuracy: 0.7424 - val_loss: 0.7716 - val_accuracy: 0.9141\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.3326 - accuracy: 0.7446 - val_loss: 0.8402 - val_accuracy: 0.9293\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 1.0035 - accuracy: 0.7446 - val_loss: 0.9140 - val_accuracy: 0.9293\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 1.0529 - accuracy: 0.7900 - val_loss: 0.6356 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.9223 - accuracy: 0.7641 - val_loss: 0.8644 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.8819 - accuracy: 0.7771 - val_loss: 0.6873 - val_accuracy: 0.9545\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 0.9904 - accuracy: 0.7576 - val_loss: 0.9247 - val_accuracy: 0.9293\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 0.8854 - accuracy: 0.7944 - val_loss: 0.7474 - val_accuracy: 0.9545\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.8688 - accuracy: 0.8117 - val_loss: 0.6476 - val_accuracy: 0.9495\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 1.0602 - accuracy: 0.7532 - val_loss: 0.7167 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 514us/step - loss: 0.8046 - accuracy: 0.7965 - val_loss: 0.7146 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.8477 - accuracy: 0.7900 - val_loss: 0.6856 - val_accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.0064 - accuracy: 0.7706 - val_loss: 0.6318 - val_accuracy: 0.9141\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.6588 - accuracy: 0.8247 - val_loss: 0.7370 - val_accuracy: 0.9495\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.9090 - accuracy: 0.7792 - val_loss: 0.8001 - val_accuracy: 0.9293\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.8050 - accuracy: 0.7641 - val_loss: 0.4904 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.7070 - accuracy: 0.8225 - val_loss: 0.7916 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.7476 - accuracy: 0.8139 - val_loss: 0.7213 - val_accuracy: 0.9495\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.6890 - accuracy: 0.7749 - val_loss: 0.8129 - val_accuracy: 0.9495\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.7443 - accuracy: 0.7792 - val_loss: 0.7213 - val_accuracy: 0.9495\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.7296 - accuracy: 0.7922 - val_loss: 0.7198 - val_accuracy: 0.9545\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.6622 - accuracy: 0.7965 - val_loss: 0.8699 - val_accuracy: 0.9495\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.6433 - accuracy: 0.8095 - val_loss: 0.6315 - val_accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.6605 - accuracy: 0.8160 - val_loss: 0.7695 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.6524 - accuracy: 0.8095 - val_loss: 0.6160 - val_accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.8760 - accuracy: 0.7684 - val_loss: 0.6323 - val_accuracy: 0.9646\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.7134 - accuracy: 0.7944 - val_loss: 0.7768 - val_accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.8235 - accuracy: 0.8030 - val_loss: 0.7024 - val_accuracy: 0.9545\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.7178 - accuracy: 0.7771 - val_loss: 0.5541 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 340us/step - loss: 0.7828 - accuracy: 0.7468 - val_loss: 0.5768 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3950ea90>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 314us/step\n",
      "over-sampling test accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0,\n",
       "       0, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 2,\n",
       "       0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 2, 2, 1, 0, 2, 0, 1, 0, 0,\n",
       "       0, 2, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 0, 1,\n",
       "       2, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0,\n",
       "       1, 1, 2, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2,\n",
       "       1, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1,\n",
       "       0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS209     2     2\n",
       "1       NRS386     1     1\n",
       "2       NRS148     2     2\n",
       "3       NRS178     0     1\n",
       "4       NRS237     0     0\n",
       "..         ...   ...   ...\n",
       "193     NRS209     2     2\n",
       "194     NRS002     0     0\n",
       "195     NRS109     2     2\n",
       "196  BCH-SA-03     1     1\n",
       "197  BCH-SA-03     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.090142e-08</td>\n",
       "      <td>2.289380e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.581215e-04</td>\n",
       "      <td>9.997348e-01</td>\n",
       "      <td>6.993341e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.165129e-09</td>\n",
       "      <td>2.305962e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.373221e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.699599e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.403704e-10</td>\n",
       "      <td>4.481151e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2.090142e-08</td>\n",
       "      <td>2.289380e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8.901500e-01</td>\n",
       "      <td>1.098500e-01</td>\n",
       "      <td>7.356455e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.026436e-08</td>\n",
       "      <td>6.748064e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.584839e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>4.213840e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.584839e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>4.213840e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    2.090142e-08  2.289380e-08  1.000000e+00\n",
       "1    2.581215e-04  9.997348e-01  6.993341e-06\n",
       "2    7.165129e-09  2.305962e-09  1.000000e+00\n",
       "3    4.373221e-12  1.000000e+00  4.699599e-16\n",
       "4    1.000000e+00  2.403704e-10  4.481151e-11\n",
       "..            ...           ...           ...\n",
       "193  2.090142e-08  2.289380e-08  1.000000e+00\n",
       "194  8.901500e-01  1.098500e-01  7.356455e-09\n",
       "195  1.026436e-08  6.748064e-08  9.999999e-01\n",
       "196  2.584839e-07  9.999998e-01  4.213840e-13\n",
       "197  2.584839e-07  9.999998e-01  4.213840e-13\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 0.6731 - accuracy: 0.7900 - val_loss: 0.7538 - val_accuracy: 0.9444\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.0901 - accuracy: 0.7684 - val_loss: 0.7902 - val_accuracy: 0.9545\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.8114 - accuracy: 0.7727 - val_loss: 0.9618 - val_accuracy: 0.9192\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.6523 - accuracy: 0.7835 - val_loss: 0.7545 - val_accuracy: 0.9444\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.5976 - accuracy: 0.7835 - val_loss: 0.8315 - val_accuracy: 0.9495\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.6995 - accuracy: 0.7771 - val_loss: 0.8870 - val_accuracy: 0.9444\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.6536 - accuracy: 0.7922 - val_loss: 1.0356 - val_accuracy: 0.9394\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.6828 - accuracy: 0.8117 - val_loss: 0.8474 - val_accuracy: 0.9495\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.5893 - accuracy: 0.8139 - val_loss: 0.7996 - val_accuracy: 0.9545\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.6256 - accuracy: 0.7706 - val_loss: 0.9289 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.6607 - accuracy: 0.7792 - val_loss: 0.8462 - val_accuracy: 0.9545\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 0.6172 - accuracy: 0.8095 - val_loss: 1.1566 - val_accuracy: 0.9343\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.5656 - accuracy: 0.8203 - val_loss: 1.0925 - val_accuracy: 0.9343\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.6783 - accuracy: 0.7922 - val_loss: 1.1464 - val_accuracy: 0.9343\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.7406 - accuracy: 0.8052 - val_loss: 0.9283 - val_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 0.6119 - accuracy: 0.8117 - val_loss: 0.9098 - val_accuracy: 0.9495\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 438us/step - loss: 0.5408 - accuracy: 0.8160 - val_loss: 0.9002 - val_accuracy: 0.9495\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 0.6888 - accuracy: 0.7727 - val_loss: 0.8916 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.7512 - accuracy: 0.7706 - val_loss: 1.1228 - val_accuracy: 0.9343\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 417us/step - loss: 0.6754 - accuracy: 0.7900 - val_loss: 1.1378 - val_accuracy: 0.9343\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.7125 - accuracy: 0.8117 - val_loss: 1.1387 - val_accuracy: 0.9242\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 0.5816 - accuracy: 0.7900 - val_loss: 1.1597 - val_accuracy: 0.9343\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 429us/step - loss: 0.5873 - accuracy: 0.8203 - val_loss: 1.1432 - val_accuracy: 0.9343\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.6487 - accuracy: 0.7749 - val_loss: 1.1016 - val_accuracy: 0.9343\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 0.6129 - accuracy: 0.7576 - val_loss: 0.8374 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 0.4984 - accuracy: 0.8030 - val_loss: 0.7904 - val_accuracy: 0.9495\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.5523 - accuracy: 0.7922 - val_loss: 0.8426 - val_accuracy: 0.9545\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.5012 - accuracy: 0.7987 - val_loss: 0.8570 - val_accuracy: 0.9545\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.6425 - accuracy: 0.7835 - val_loss: 0.7576 - val_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.5519 - accuracy: 0.7965 - val_loss: 0.7429 - val_accuracy: 0.9545\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.5571 - accuracy: 0.8030 - val_loss: 0.8505 - val_accuracy: 0.9545\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 558us/step - loss: 0.6492 - accuracy: 0.7792 - val_loss: 1.1490 - val_accuracy: 0.9343\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 0.6658 - accuracy: 0.7771 - val_loss: 1.1753 - val_accuracy: 0.9343\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 0.6224 - accuracy: 0.7835 - val_loss: 1.1948 - val_accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 435us/step - loss: 0.6431 - accuracy: 0.7857 - val_loss: 1.1617 - val_accuracy: 0.9343\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.5132 - accuracy: 0.8333 - val_loss: 1.1398 - val_accuracy: 0.9343\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.6328 - accuracy: 0.7900 - val_loss: 1.1635 - val_accuracy: 0.9343\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.5680 - accuracy: 0.7900 - val_loss: 1.1561 - val_accuracy: 0.9343\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.5925 - accuracy: 0.7662 - val_loss: 1.0654 - val_accuracy: 0.9343\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.6203 - accuracy: 0.7749 - val_loss: 1.1522 - val_accuracy: 0.9343\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.5854 - accuracy: 0.7792 - val_loss: 1.0929 - val_accuracy: 0.9343\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.6012 - accuracy: 0.7900 - val_loss: 0.8574 - val_accuracy: 0.9343\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.4799 - accuracy: 0.7922 - val_loss: 0.8212 - val_accuracy: 0.9495\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.4080 - accuracy: 0.8333 - val_loss: 0.8552 - val_accuracy: 0.9495\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4139 - accuracy: 0.8095 - val_loss: 0.8721 - val_accuracy: 0.9495\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.4677 - accuracy: 0.7749 - val_loss: 0.8505 - val_accuracy: 0.9495\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.3763 - accuracy: 0.8485 - val_loss: 0.7886 - val_accuracy: 0.9495\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.4993 - accuracy: 0.7965 - val_loss: 0.9080 - val_accuracy: 0.9495\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.5437 - accuracy: 0.7835 - val_loss: 0.7759 - val_accuracy: 0.9545\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.5260 - accuracy: 0.7706 - val_loss: 0.8957 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.4704 - accuracy: 0.7900 - val_loss: 0.7868 - val_accuracy: 0.9495\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.5893 - accuracy: 0.7749 - val_loss: 0.7777 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.5208 - accuracy: 0.8074 - val_loss: 0.9038 - val_accuracy: 0.9495\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.4395 - accuracy: 0.8052 - val_loss: 0.8414 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.4779 - accuracy: 0.7900 - val_loss: 0.8155 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.5085 - accuracy: 0.7749 - val_loss: 0.8923 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.4255 - accuracy: 0.7900 - val_loss: 0.7940 - val_accuracy: 0.9545\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.4993 - accuracy: 0.8117 - val_loss: 0.7524 - val_accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.4064 - accuracy: 0.7944 - val_loss: 0.8227 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.4458 - accuracy: 0.7965 - val_loss: 0.7324 - val_accuracy: 0.9545\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.4283 - accuracy: 0.8052 - val_loss: 0.8021 - val_accuracy: 0.9495\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.3975 - accuracy: 0.8095 - val_loss: 0.7431 - val_accuracy: 0.9545\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.3631 - accuracy: 0.8333 - val_loss: 0.7710 - val_accuracy: 0.9545\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.4190 - accuracy: 0.7879 - val_loss: 0.7825 - val_accuracy: 0.9545\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.4040 - accuracy: 0.8312 - val_loss: 0.8418 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.4193 - accuracy: 0.8182 - val_loss: 0.7668 - val_accuracy: 0.9545\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.4936 - accuracy: 0.7857 - val_loss: 0.8259 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.3549 - accuracy: 0.8333 - val_loss: 0.8569 - val_accuracy: 0.9495\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.4662 - accuracy: 0.8160 - val_loss: 0.9268 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5190 - accuracy: 0.7987 - val_loss: 1.1120 - val_accuracy: 0.9343\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.5257 - accuracy: 0.8160 - val_loss: 1.0476 - val_accuracy: 0.9394\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5425 - accuracy: 0.7900 - val_loss: 1.1508 - val_accuracy: 0.9343\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.5396 - accuracy: 0.7814 - val_loss: 1.1227 - val_accuracy: 0.9343\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.5795 - accuracy: 0.7900 - val_loss: 1.1628 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.5397 - accuracy: 0.7879 - val_loss: 1.1347 - val_accuracy: 0.9343\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.5469 - accuracy: 0.8052 - val_loss: 1.1640 - val_accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.6519 - accuracy: 0.7576 - val_loss: 1.0976 - val_accuracy: 0.8838\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.5271 - accuracy: 0.8312 - val_loss: 1.3641 - val_accuracy: 0.9141\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.5768 - accuracy: 0.7835 - val_loss: 1.1314 - val_accuracy: 0.9343\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.5551 - accuracy: 0.8117 - val_loss: 1.1831 - val_accuracy: 0.9293\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.5651 - accuracy: 0.7900 - val_loss: 0.8571 - val_accuracy: 0.9495\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.4618 - accuracy: 0.8074 - val_loss: 0.8514 - val_accuracy: 0.9495\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.5728 - accuracy: 0.7792 - val_loss: 0.8340 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.4733 - accuracy: 0.7749 - val_loss: 0.8067 - val_accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.3598 - accuracy: 0.8420 - val_loss: 0.8757 - val_accuracy: 0.9495\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.6077 - accuracy: 0.8074 - val_loss: 1.0925 - val_accuracy: 0.9242\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.5434 - accuracy: 0.7987 - val_loss: 1.3077 - val_accuracy: 0.8990\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.6750 - accuracy: 0.8203 - val_loss: 1.2543 - val_accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.6263 - accuracy: 0.7879 - val_loss: 1.1752 - val_accuracy: 0.9343\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.5165 - accuracy: 0.7879 - val_loss: 1.0916 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.5265 - accuracy: 0.7857 - val_loss: 0.7194 - val_accuracy: 0.9545\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 510us/step - loss: 0.4512 - accuracy: 0.7987 - val_loss: 0.8693 - val_accuracy: 0.9495\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 447us/step - loss: 0.5931 - accuracy: 0.7922 - val_loss: 0.9109 - val_accuracy: 0.9495\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 795us/step - loss: 0.5106 - accuracy: 0.7857 - val_loss: 0.9164 - val_accuracy: 0.9495\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 439us/step - loss: 0.4299 - accuracy: 0.7922 - val_loss: 0.9124 - val_accuracy: 0.9495\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.4795 - accuracy: 0.7879 - val_loss: 0.7683 - val_accuracy: 0.9545\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.4258 - accuracy: 0.8117 - val_loss: 0.7890 - val_accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 0.5112 - accuracy: 0.8074 - val_loss: 1.1218 - val_accuracy: 0.9343\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.5191 - accuracy: 0.8030 - val_loss: 1.1110 - val_accuracy: 0.9343\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.5458 - accuracy: 0.7814 - val_loss: 1.0961 - val_accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.57%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [2.58121460e-04, 9.99734800e-01, 6.99334120e-06],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [4.37322050e-12, 1.00000000e+00, 4.69959900e-16],\n",
       "       [1.00000000e+00, 2.40370420e-10, 4.48115120e-11],\n",
       "       [6.21077400e-05, 9.99937900e-01, 7.19250600e-09],\n",
       "       [2.58483650e-07, 9.99999760e-01, 4.21383980e-13],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [6.21077400e-05, 9.99937900e-01, 7.19250600e-09],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [2.58121460e-04, 9.99734800e-01, 6.99334120e-06],\n",
       "       [8.98108850e-07, 9.99999050e-01, 5.97431840e-09],\n",
       "       [1.75746940e-08, 1.00000000e+00, 3.12505580e-11],\n",
       "       [1.34828690e-02, 9.86517200e-01, 9.37456000e-10],\n",
       "       [1.00000000e+00, 9.04878800e-19, 1.96243880e-20],\n",
       "       [2.58483650e-07, 9.99999760e-01, 4.21383980e-13],\n",
       "       [1.00000000e+00, 1.55860100e-11, 1.04412880e-14],\n",
       "       [1.30124600e-06, 9.99998700e-01, 9.68821500e-09],\n",
       "       [1.00000000e+00, 2.89998000e-17, 3.54994250e-19],\n",
       "       [3.24545900e-09, 1.00000000e+00, 3.25477750e-12],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.33210540e-10, 1.34088695e-11],\n",
       "       [1.00000000e+00, 5.38253460e-14, 8.97875100e-18],\n",
       "       [1.00000000e+00, 9.03189700e-10, 1.51267200e-11],\n",
       "       [5.96803160e-11, 1.00000000e+00, 1.55109550e-14],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [2.57957900e-11, 1.00000000e+00, 3.85746400e-15],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.57296470e-20, 1.74788600e-22],\n",
       "       [1.03798420e-02, 9.89620150e-01, 4.90226670e-08],\n",
       "       [1.00000000e+00, 4.21729840e-13, 1.16558200e-16],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [2.01918910e-04, 9.99798100e-01, 6.79718560e-10],\n",
       "       [1.00000000e+00, 3.57542200e-13, 1.39768650e-14],\n",
       "       [1.00000000e+00, 3.12578550e-17, 4.17147730e-19],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.33410860e-14, 1.55153280e-15],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.30124600e-06, 9.99998700e-01, 9.68821500e-09],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.74415430e-07, 9.99999900e-01, 6.72255640e-10],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.83116800e-08, 2.32480950e-10],\n",
       "       [1.00000000e+00, 3.17792310e-21, 7.28180300e-22],\n",
       "       [1.59464280e-08, 1.00000000e+00, 2.21861830e-11],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.53142600e-21, 6.30204060e-23],\n",
       "       [1.29583030e-07, 9.99999900e-01, 4.51744480e-10],\n",
       "       [7.11702160e-09, 1.00000000e+00, 1.27087740e-12],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.01918910e-04, 9.99798100e-01, 6.79718560e-10],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [7.11702160e-09, 1.00000000e+00, 1.27087740e-12],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [6.75405500e-11, 1.00000000e+00, 1.83033050e-14],\n",
       "       [1.00000000e+00, 1.40510690e-10, 1.82358000e-11],\n",
       "       [4.06767580e-01, 5.93232450e-01, 4.82668100e-09],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.63613250e-17, 3.85997500e-18],\n",
       "       [1.00000000e+00, 2.12001120e-18, 2.03221590e-20],\n",
       "       [1.95287880e-03, 9.97964400e-01, 8.28246200e-05],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.34828690e-02, 9.86517200e-01, 9.37456000e-10],\n",
       "       [1.00000000e+00, 3.71409500e-20, 5.72327650e-22],\n",
       "       [2.58483650e-07, 9.99999760e-01, 4.21383980e-13],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.32668460e-10, 1.50277800e-13],\n",
       "       [1.13656150e-12, 1.00000000e+00, 5.07127030e-17],\n",
       "       [1.00000000e+00, 6.06520700e-11, 7.15364750e-12],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.25260045e-11, 1.00000000e+00, 1.92089280e-15],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.57957900e-11, 1.00000000e+00, 3.85746400e-15],\n",
       "       [1.00000000e+00, 1.77587280e-21, 1.65161110e-22],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.08019800e-09, 4.62820450e-12],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [9.99931800e-01, 6.68422700e-05, 1.28798590e-06],\n",
       "       [1.00000000e+00, 5.70783200e-17, 1.67197020e-17],\n",
       "       [1.00000000e+00, 4.91602770e-11, 4.36510770e-14],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.96750300e-10, 7.77851850e-13],\n",
       "       [1.77308710e-10, 1.00000000e+00, 5.99603900e-16],\n",
       "       [1.00000000e+00, 2.10999100e-14, 2.77368900e-18],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.11970800e-10, 1.43430060e-12],\n",
       "       [1.00000000e+00, 3.13975560e-17, 1.26619170e-18],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.34828690e-02, 9.86517200e-01, 9.37456000e-10],\n",
       "       [2.89052510e-05, 9.99970700e-01, 4.81895900e-07],\n",
       "       [3.24545900e-09, 1.00000000e+00, 3.25477750e-12],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.12001120e-18, 2.03221590e-20],\n",
       "       [1.77308710e-10, 1.00000000e+00, 5.99603900e-16],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.74415430e-07, 9.99999900e-01, 6.72255640e-10],\n",
       "       [1.00000000e+00, 2.10300280e-15, 6.74325100e-16],\n",
       "       [2.04610710e-02, 9.79539000e-01, 6.86436240e-10],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.03798420e-02, 9.89620150e-01, 4.90226670e-08],\n",
       "       [1.00000000e+00, 3.36637940e-09, 8.63985700e-10],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.03798420e-02, 9.89620150e-01, 4.90226670e-08],\n",
       "       [1.74415430e-07, 9.99999900e-01, 6.72255640e-10],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.34828690e-02, 9.86517200e-01, 9.37456000e-10],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [1.75746940e-08, 1.00000000e+00, 3.12505580e-11],\n",
       "       [1.74415430e-07, 9.99999900e-01, 6.72255640e-10],\n",
       "       [1.00000000e+00, 1.99469350e-12, 8.12700470e-14],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [2.01918910e-04, 9.99798100e-01, 6.79718560e-10],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.34612760e-15, 1.66668020e-15],\n",
       "       [4.06767580e-01, 5.93232450e-01, 4.82668100e-09],\n",
       "       [1.00000000e+00, 9.52059550e-20, 5.63385730e-22],\n",
       "       [1.65675340e-05, 9.99983430e-01, 1.61680780e-12],\n",
       "       [1.00000000e+00, 1.56133120e-20, 5.21722870e-22],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [9.45632000e-11, 1.00000000e+00, 2.87128720e-14],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.74930160e-11, 3.11508900e-14],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.27401340e-14, 2.95063310e-15],\n",
       "       [3.24545900e-09, 1.00000000e+00, 3.25477750e-12],\n",
       "       [9.99998800e-01, 1.16351430e-06, 1.14888360e-08],\n",
       "       [5.45265830e-09, 1.00000000e+00, 6.51625370e-12],\n",
       "       [9.45632000e-11, 1.00000000e+00, 2.87128720e-14],\n",
       "       [1.00000000e+00, 1.76736890e-12, 3.12588560e-14],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.43098550e-13, 2.06437850e-14],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [2.01918910e-04, 9.99798100e-01, 6.79718560e-10],\n",
       "       [1.00000000e+00, 5.61305930e-11, 5.14876200e-14],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.79376140e-19, 2.52292800e-20],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [6.75405500e-11, 1.00000000e+00, 1.83033050e-14],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [4.23188500e-04, 9.99564000e-01, 1.27945880e-05],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.59464280e-08, 1.00000000e+00, 2.21861830e-11],\n",
       "       [9.99999640e-01, 2.43863500e-07, 7.24077400e-08],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.56246550e-18, 7.38137460e-20],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.39456840e-13, 3.24402700e-14],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.62916000e-12, 5.46166140e-13],\n",
       "       [1.00000000e+00, 3.12703750e-17, 2.51370820e-18],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.25260045e-11, 1.00000000e+00, 1.92089280e-15],\n",
       "       [1.00000000e+00, 1.60148940e-11, 5.17085900e-13],\n",
       "       [1.00000000e+00, 2.47238400e-13, 2.85318440e-14],\n",
       "       [1.00000000e+00, 4.09912800e-15, 2.98611740e-17],\n",
       "       [2.58121460e-04, 9.99734800e-01, 6.99334120e-06],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.21068430e-03, 9.98789370e-01, 2.89932910e-08],\n",
       "       [1.00000000e+00, 3.43930880e-13, 1.25313690e-13],\n",
       "       [2.58483650e-07, 9.99999760e-01, 4.21383980e-13],\n",
       "       [5.45265830e-09, 1.00000000e+00, 6.51625370e-12],\n",
       "       [1.00000000e+00, 2.10999100e-14, 2.77368900e-18],\n",
       "       [1.00000000e+00, 6.15101160e-14, 1.20815050e-15],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [1.00000000e+00, 6.06395700e-11, 1.82823870e-12],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [1.25260045e-11, 1.00000000e+00, 1.92089280e-15],\n",
       "       [1.25260045e-11, 1.00000000e+00, 1.92089280e-15],\n",
       "       [1.00000000e+00, 1.44878570e-11, 8.56198700e-13],\n",
       "       [7.16512900e-09, 2.30596230e-09, 1.00000000e+00],\n",
       "       [6.21077400e-05, 9.99937900e-01, 7.19250600e-09],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [1.02643165e-08, 6.74805100e-08, 9.99999900e-01],\n",
       "       [1.11004330e-01, 8.67309500e-01, 2.16861300e-02],\n",
       "       [2.09014200e-08, 2.28938020e-08, 1.00000000e+00],\n",
       "       [8.90150000e-01, 1.09849950e-01, 7.35645500e-09],\n",
       "       [1.02643560e-08, 6.74806400e-08, 9.99999900e-01],\n",
       "       [2.58483880e-07, 9.99999760e-01, 4.21383980e-13],\n",
       "       [2.58483880e-07, 9.99999760e-01, 4.21383980e-13]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815388735843281"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815388735843281"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS209     2\n",
       "1      BCH-SA-09     1\n",
       "2         NRS224     0\n",
       "3         NRS209     2\n",
       "4         NRS235     1\n",
       "..           ...   ...\n",
       "193       NRS209     2\n",
       "194  CFBREBSa131     1\n",
       "195  CFBREBSa103     0\n",
       "196       NRS188     1\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 757us/step - loss: 6.8590 - accuracy: 0.4307 - val_loss: 2.7388 - val_accuracy: 0.5960\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 4.3318 - accuracy: 0.6342 - val_loss: 1.8825 - val_accuracy: 0.7475\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 3.7735 - accuracy: 0.6861 - val_loss: 1.3884 - val_accuracy: 0.6970\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 3.4658 - accuracy: 0.6688 - val_loss: 1.4580 - val_accuracy: 0.7576\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 2.9221 - accuracy: 0.7056 - val_loss: 1.1876 - val_accuracy: 0.7020\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 3.7692 - accuracy: 0.6623 - val_loss: 1.2398 - val_accuracy: 0.7374\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 3.5747 - accuracy: 0.6580 - val_loss: 1.2438 - val_accuracy: 0.7525\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 3.2555 - accuracy: 0.7035 - val_loss: 1.1971 - val_accuracy: 0.7828\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 3.2027 - accuracy: 0.6970 - val_loss: 1.2063 - val_accuracy: 0.7576\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 3.7743 - accuracy: 0.6385 - val_loss: 1.3542 - val_accuracy: 0.7626\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 2.5119 - accuracy: 0.7251 - val_loss: 1.4023 - val_accuracy: 0.7828\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 2.7842 - accuracy: 0.7208 - val_loss: 1.7296 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 2.6901 - accuracy: 0.7013 - val_loss: 1.4139 - val_accuracy: 0.7929\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 697us/step - loss: 2.5363 - accuracy: 0.7381 - val_loss: 1.3018 - val_accuracy: 0.8081\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 741us/step - loss: 2.2434 - accuracy: 0.7165 - val_loss: 1.2964 - val_accuracy: 0.7929\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 2.3486 - accuracy: 0.7229 - val_loss: 1.2484 - val_accuracy: 0.8030\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 2.3435 - accuracy: 0.7576 - val_loss: 1.1271 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 512us/step - loss: 2.2716 - accuracy: 0.7316 - val_loss: 1.2589 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 420us/step - loss: 2.4838 - accuracy: 0.7078 - val_loss: 1.2714 - val_accuracy: 0.7677\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 2.3423 - accuracy: 0.6948 - val_loss: 1.5080 - val_accuracy: 0.8283\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 2.4141 - accuracy: 0.6753 - val_loss: 1.5446 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 2.3908 - accuracy: 0.6775 - val_loss: 1.3184 - val_accuracy: 0.7929\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 2.3854 - accuracy: 0.6883 - val_loss: 1.3486 - val_accuracy: 0.8030\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 2.1677 - accuracy: 0.7165 - val_loss: 1.4417 - val_accuracy: 0.8434\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 2.1279 - accuracy: 0.7208 - val_loss: 1.5450 - val_accuracy: 0.7980\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 2.2941 - accuracy: 0.6861 - val_loss: 1.4808 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 1.8529 - accuracy: 0.7338 - val_loss: 1.3742 - val_accuracy: 0.8283\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 2.0032 - accuracy: 0.7489 - val_loss: 1.3977 - val_accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 1.9574 - accuracy: 0.7165 - val_loss: 1.2481 - val_accuracy: 0.8586\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 1.7541 - accuracy: 0.7489 - val_loss: 1.3706 - val_accuracy: 0.8535\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 1.9521 - accuracy: 0.7229 - val_loss: 1.3053 - val_accuracy: 0.8384\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 1.8376 - accuracy: 0.7424 - val_loss: 1.3836 - val_accuracy: 0.8434\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 1.6275 - accuracy: 0.7121 - val_loss: 1.1562 - val_accuracy: 0.8737\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 527us/step - loss: 1.6693 - accuracy: 0.7273 - val_loss: 1.3249 - val_accuracy: 0.8687\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 435us/step - loss: 1.7808 - accuracy: 0.7381 - val_loss: 1.5168 - val_accuracy: 0.8131\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 1.7714 - accuracy: 0.7078 - val_loss: 1.4661 - val_accuracy: 0.8535\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 1.5695 - accuracy: 0.7359 - val_loss: 1.1805 - val_accuracy: 0.9091\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 1.4313 - accuracy: 0.7641 - val_loss: 2.1343 - val_accuracy: 0.8081\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 1.7134 - accuracy: 0.6991 - val_loss: 1.2652 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 1.4952 - accuracy: 0.7814 - val_loss: 1.3946 - val_accuracy: 0.8838\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 1.2840 - accuracy: 0.7576 - val_loss: 1.1061 - val_accuracy: 0.8838\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 1.3856 - accuracy: 0.7641 - val_loss: 1.1949 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 1.2386 - accuracy: 0.7576 - val_loss: 1.6426 - val_accuracy: 0.8232\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 1.4002 - accuracy: 0.7511 - val_loss: 0.9445 - val_accuracy: 0.9040\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 1.3627 - accuracy: 0.7641 - val_loss: 1.5060 - val_accuracy: 0.8687\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.5536 - accuracy: 0.7489 - val_loss: 0.9380 - val_accuracy: 0.8939\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 1.2959 - accuracy: 0.7424 - val_loss: 1.3901 - val_accuracy: 0.8788\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 1.1524 - accuracy: 0.7771 - val_loss: 1.2062 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.1859 - accuracy: 0.7900 - val_loss: 1.1668 - val_accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 1.1169 - accuracy: 0.7619 - val_loss: 0.9287 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 1.0872 - accuracy: 0.7662 - val_loss: 1.1119 - val_accuracy: 0.8939\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 1.1731 - accuracy: 0.7619 - val_loss: 0.8314 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.0569 - accuracy: 0.7489 - val_loss: 1.0664 - val_accuracy: 0.9394\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 1.0410 - accuracy: 0.7771 - val_loss: 1.0373 - val_accuracy: 0.9242\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.1239 - accuracy: 0.7749 - val_loss: 0.9045 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.8844 - accuracy: 0.7814 - val_loss: 1.0790 - val_accuracy: 0.9242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 0.9577 - accuracy: 0.7597 - val_loss: 0.9715 - val_accuracy: 0.9242\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.8968 - accuracy: 0.7749 - val_loss: 0.9845 - val_accuracy: 0.9394\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.9281 - accuracy: 0.8052 - val_loss: 1.1307 - val_accuracy: 0.9141\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.9591 - accuracy: 0.7727 - val_loss: 1.0140 - val_accuracy: 0.9192\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.9073 - accuracy: 0.7662 - val_loss: 1.1590 - val_accuracy: 0.9242\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.8910 - accuracy: 0.7835 - val_loss: 1.0454 - val_accuracy: 0.9293\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.8438 - accuracy: 0.7900 - val_loss: 0.9608 - val_accuracy: 0.9343\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.9855 - accuracy: 0.7727 - val_loss: 0.9679 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6999 - accuracy: 0.8139 - val_loss: 0.8306 - val_accuracy: 0.9242\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.8682 - accuracy: 0.7706 - val_loss: 0.8887 - val_accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.7365 - accuracy: 0.8009 - val_loss: 0.8111 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.7631 - accuracy: 0.7792 - val_loss: 0.9040 - val_accuracy: 0.9495\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 0.7052 - accuracy: 0.8030 - val_loss: 0.9204 - val_accuracy: 0.9343\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.7042 - accuracy: 0.7987 - val_loss: 0.8824 - val_accuracy: 0.9293\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.7233 - accuracy: 0.8009 - val_loss: 0.9967 - val_accuracy: 0.9293\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.8151 - accuracy: 0.7576 - val_loss: 1.0466 - val_accuracy: 0.9242\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 572us/step - loss: 0.7035 - accuracy: 0.8182 - val_loss: 0.8974 - val_accuracy: 0.9242\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.8434 - accuracy: 0.7446 - val_loss: 0.7476 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.6924 - accuracy: 0.7922 - val_loss: 0.8540 - val_accuracy: 0.9394\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.6740 - accuracy: 0.7706 - val_loss: 0.8678 - val_accuracy: 0.9242\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.7648 - accuracy: 0.7879 - val_loss: 0.6044 - val_accuracy: 0.9242\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.7952 - accuracy: 0.7771 - val_loss: 0.8197 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.7908 - accuracy: 0.7879 - val_loss: 0.8735 - val_accuracy: 0.9242\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.8424 - accuracy: 0.7554 - val_loss: 0.9290 - val_accuracy: 0.9394\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.0011 - accuracy: 0.7424 - val_loss: 0.8302 - val_accuracy: 0.9293\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.6202 - accuracy: 0.7879 - val_loss: 0.5639 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6333 - accuracy: 0.7879 - val_loss: 0.8550 - val_accuracy: 0.9394\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.7324 - accuracy: 0.7619 - val_loss: 0.6767 - val_accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.6166 - accuracy: 0.8182 - val_loss: 0.7194 - val_accuracy: 0.9596\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6992 - accuracy: 0.8095 - val_loss: 1.0346 - val_accuracy: 0.9242\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.9340 - accuracy: 0.7900 - val_loss: 1.0027 - val_accuracy: 0.9141\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.7681 - accuracy: 0.7965 - val_loss: 0.6530 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5485 - accuracy: 0.8225 - val_loss: 0.7172 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.6646 - accuracy: 0.7944 - val_loss: 0.8101 - val_accuracy: 0.9545\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.6496 - accuracy: 0.8074 - val_loss: 0.8057 - val_accuracy: 0.9343\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.6582 - accuracy: 0.8052 - val_loss: 0.9468 - val_accuracy: 0.9293\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.6813 - accuracy: 0.7944 - val_loss: 0.8456 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 476us/step - loss: 0.7336 - accuracy: 0.7684 - val_loss: 0.8663 - val_accuracy: 0.9545\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 448us/step - loss: 0.6378 - accuracy: 0.7965 - val_loss: 0.4719 - val_accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.6239 - accuracy: 0.7835 - val_loss: 0.6617 - val_accuracy: 0.9545\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.5901 - accuracy: 0.7771 - val_loss: 0.6287 - val_accuracy: 0.9646\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.5436 - accuracy: 0.7987 - val_loss: 0.6365 - val_accuracy: 0.9596\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.6983 - accuracy: 0.8052 - val_loss: 1.4558 - val_accuracy: 0.8687\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.8045 - accuracy: 0.7511 - val_loss: 0.6295 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a45f390>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 196us/step\n",
      "over-sampling test accuracy: 91.41%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2, 1,\n",
       "       2, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 1, 0,\n",
       "       2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 2, 0, 2, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 1,\n",
       "       1, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0, 0,\n",
       "       2, 2, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2,\n",
       "       0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2,\n",
       "       0, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS209     2     2\n",
       "1      BCH-SA-09     1     1\n",
       "2         NRS224     0     0\n",
       "3         NRS209     2     2\n",
       "4         NRS235     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS209     2     2\n",
       "194  CFBREBSa131     1     1\n",
       "195  CFBREBSa103     0     0\n",
       "196       NRS188     1     1\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.617234e-09</td>\n",
       "      <td>1.121028e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.367589e-05</td>\n",
       "      <td>9.999763e-01</td>\n",
       "      <td>3.152567e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.816863e-14</td>\n",
       "      <td>4.248027e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.617234e-09</td>\n",
       "      <td>1.121028e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.324296e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.054044e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9.617215e-09</td>\n",
       "      <td>1.121026e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.296561e-02</td>\n",
       "      <td>8.494496e-01</td>\n",
       "      <td>7.758473e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.829268e-15</td>\n",
       "      <td>1.843543e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.117732e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.808631e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.540037e-08</td>\n",
       "      <td>1.822901e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.617234e-09  1.121028e-08  1.000000e+00\n",
       "1    2.367589e-05  9.999763e-01  3.152567e-08\n",
       "2    1.000000e+00  1.816863e-14  4.248027e-12\n",
       "3    9.617234e-09  1.121028e-08  1.000000e+00\n",
       "4    8.324296e-08  9.999999e-01  1.054044e-09\n",
       "..            ...           ...           ...\n",
       "193  9.617215e-09  1.121026e-08  1.000000e+00\n",
       "194  7.296561e-02  8.494496e-01  7.758473e-02\n",
       "195  1.000000e+00  7.829268e-15  1.843543e-17\n",
       "196  1.117732e-08  1.000000e+00  4.808631e-10\n",
       "197  1.540037e-08  1.822901e-08  1.000000e+00\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.9109 - accuracy: 0.7749 - val_loss: 1.0429 - val_accuracy: 0.8990\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.8131 - accuracy: 0.7771 - val_loss: 1.0394 - val_accuracy: 0.8939\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.8217 - accuracy: 0.8182 - val_loss: 1.3902 - val_accuracy: 0.8889\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.8305 - accuracy: 0.7684 - val_loss: 0.8899 - val_accuracy: 0.9040\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.8940 - accuracy: 0.7619 - val_loss: 1.0573 - val_accuracy: 0.9091\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.8499 - accuracy: 0.7835 - val_loss: 1.0625 - val_accuracy: 0.9040\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.8009 - accuracy: 0.7771 - val_loss: 1.0314 - val_accuracy: 0.9040\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.7375 - accuracy: 0.7944 - val_loss: 0.8992 - val_accuracy: 0.9141\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.6538 - accuracy: 0.8225 - val_loss: 0.8199 - val_accuracy: 0.9242\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.7251 - accuracy: 0.8160 - val_loss: 1.2338 - val_accuracy: 0.8939\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.8183 - accuracy: 0.7922 - val_loss: 1.0169 - val_accuracy: 0.9091\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.6995 - accuracy: 0.8052 - val_loss: 0.9343 - val_accuracy: 0.9141\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.6873 - accuracy: 0.7771 - val_loss: 0.8273 - val_accuracy: 0.9293\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.8287 - accuracy: 0.8009 - val_loss: 1.2394 - val_accuracy: 0.8990\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.7387 - accuracy: 0.8052 - val_loss: 1.4947 - val_accuracy: 0.8838\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 436us/step - loss: 0.6709 - accuracy: 0.8139 - val_loss: 1.1122 - val_accuracy: 0.9091\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 0.7539 - accuracy: 0.7965 - val_loss: 1.3496 - val_accuracy: 0.8939\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.7584 - accuracy: 0.7922 - val_loss: 0.8689 - val_accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.7264 - accuracy: 0.7879 - val_loss: 1.0709 - val_accuracy: 0.8990\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.6724 - accuracy: 0.8182 - val_loss: 1.2656 - val_accuracy: 0.8889\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.8678 - accuracy: 0.7879 - val_loss: 1.0967 - val_accuracy: 0.9091\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.9090 - accuracy: 0.8117 - val_loss: 0.9584 - val_accuracy: 0.9141\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.6877 - accuracy: 0.8117 - val_loss: 1.3570 - val_accuracy: 0.8990\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.8182 - accuracy: 0.7771 - val_loss: 0.9132 - val_accuracy: 0.9242\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.8367 - accuracy: 0.7706 - val_loss: 1.3454 - val_accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.8404 - accuracy: 0.7792 - val_loss: 1.0214 - val_accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 0.7321 - accuracy: 0.7879 - val_loss: 1.1585 - val_accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 497us/step - loss: 0.7440 - accuracy: 0.7814 - val_loss: 1.1495 - val_accuracy: 0.8990\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.7127 - accuracy: 0.7965 - val_loss: 1.1045 - val_accuracy: 0.9141\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.7101 - accuracy: 0.8009 - val_loss: 1.4828 - val_accuracy: 0.8838\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.7664 - accuracy: 0.7922 - val_loss: 0.9715 - val_accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.7501 - accuracy: 0.7879 - val_loss: 1.2260 - val_accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.8059 - accuracy: 0.7597 - val_loss: 1.1299 - val_accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 473us/step - loss: 0.7336 - accuracy: 0.7900 - val_loss: 0.9107 - val_accuracy: 0.9192\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.7063 - accuracy: 0.7706 - val_loss: 1.1091 - val_accuracy: 0.9091\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.7037 - accuracy: 0.8009 - val_loss: 1.2897 - val_accuracy: 0.9040\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.7738 - accuracy: 0.7987 - val_loss: 1.0737 - val_accuracy: 0.9141\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.8018 - accuracy: 0.7857 - val_loss: 1.1568 - val_accuracy: 0.9141\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.7630 - accuracy: 0.8030 - val_loss: 1.2360 - val_accuracy: 0.9141\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.7303 - accuracy: 0.7792 - val_loss: 1.0915 - val_accuracy: 0.9141\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.7355 - accuracy: 0.7749 - val_loss: 1.2380 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.6372 - accuracy: 0.7987 - val_loss: 1.1865 - val_accuracy: 0.9141\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.7977 - accuracy: 0.7792 - val_loss: 1.0563 - val_accuracy: 0.9192\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.7326 - accuracy: 0.7922 - val_loss: 1.3020 - val_accuracy: 0.9091\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.6920 - accuracy: 0.7922 - val_loss: 1.1157 - val_accuracy: 0.9192\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.6608 - accuracy: 0.8009 - val_loss: 1.2604 - val_accuracy: 0.8990\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.6902 - accuracy: 0.7684 - val_loss: 1.2779 - val_accuracy: 0.9091\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.7244 - accuracy: 0.7857 - val_loss: 1.0952 - val_accuracy: 0.9242\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.6670 - accuracy: 0.7792 - val_loss: 1.1132 - val_accuracy: 0.9141\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6376 - accuracy: 0.7987 - val_loss: 1.0868 - val_accuracy: 0.9242\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5506 - accuracy: 0.8290 - val_loss: 1.4909 - val_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.6612 - accuracy: 0.7857 - val_loss: 1.0400 - val_accuracy: 0.9242\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.6850 - accuracy: 0.8182 - val_loss: 1.3041 - val_accuracy: 0.9040\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.9005 - accuracy: 0.7835 - val_loss: 1.7548 - val_accuracy: 0.8788\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.7544 - accuracy: 0.7727 - val_loss: 1.6359 - val_accuracy: 0.8838\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.7746 - accuracy: 0.7879 - val_loss: 1.2396 - val_accuracy: 0.9242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.8016 - accuracy: 0.7792 - val_loss: 1.7716 - val_accuracy: 0.8788\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.6755 - accuracy: 0.7792 - val_loss: 1.3477 - val_accuracy: 0.8990\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.6580 - accuracy: 0.7922 - val_loss: 1.0636 - val_accuracy: 0.9242\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.6320 - accuracy: 0.7922 - val_loss: 1.3889 - val_accuracy: 0.9040\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.7383 - accuracy: 0.7554 - val_loss: 1.3223 - val_accuracy: 0.9040\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.5548 - accuracy: 0.8095 - val_loss: 1.5507 - val_accuracy: 0.8838\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.6508 - accuracy: 0.7835 - val_loss: 1.1494 - val_accuracy: 0.9192\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.6683 - accuracy: 0.7727 - val_loss: 1.1812 - val_accuracy: 0.9141\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.6772 - accuracy: 0.7511 - val_loss: 1.4566 - val_accuracy: 0.8990\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.6759 - accuracy: 0.7597 - val_loss: 1.3549 - val_accuracy: 0.9040\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.6423 - accuracy: 0.7771 - val_loss: 1.6428 - val_accuracy: 0.8939\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.5921 - accuracy: 0.8030 - val_loss: 1.3414 - val_accuracy: 0.9192\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.7009 - accuracy: 0.7706 - val_loss: 1.3975 - val_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.7241 - accuracy: 0.7944 - val_loss: 1.4231 - val_accuracy: 0.9040\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.7021 - accuracy: 0.7835 - val_loss: 1.3944 - val_accuracy: 0.9141\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.7199 - accuracy: 0.7987 - val_loss: 1.1404 - val_accuracy: 0.9242\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.6383 - accuracy: 0.7965 - val_loss: 1.1934 - val_accuracy: 0.9192\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.6001 - accuracy: 0.8160 - val_loss: 1.3942 - val_accuracy: 0.9091\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5768 - accuracy: 0.7879 - val_loss: 1.7427 - val_accuracy: 0.8788\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.6746 - accuracy: 0.7857 - val_loss: 1.2336 - val_accuracy: 0.9091\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.7854 - accuracy: 0.7727 - val_loss: 1.9411 - val_accuracy: 0.8687\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.7846 - accuracy: 0.7749 - val_loss: 1.5075 - val_accuracy: 0.9040\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.5942 - accuracy: 0.8117 - val_loss: 1.1522 - val_accuracy: 0.9242\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.5705 - accuracy: 0.8160 - val_loss: 1.1574 - val_accuracy: 0.9293\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.6076 - accuracy: 0.7684 - val_loss: 1.7062 - val_accuracy: 0.8838\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.6390 - accuracy: 0.8117 - val_loss: 1.2797 - val_accuracy: 0.9141\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.6503 - accuracy: 0.7922 - val_loss: 1.3829 - val_accuracy: 0.9141\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.5906 - accuracy: 0.7965 - val_loss: 1.2462 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.6186 - accuracy: 0.8095 - val_loss: 1.4290 - val_accuracy: 0.9141\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.7878 - accuracy: 0.7294 - val_loss: 1.3391 - val_accuracy: 0.9091\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5145 - accuracy: 0.8052 - val_loss: 1.5677 - val_accuracy: 0.9040\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5016 - accuracy: 0.8074 - val_loss: 1.8136 - val_accuracy: 0.8788\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.6721 - accuracy: 0.8009 - val_loss: 1.1657 - val_accuracy: 0.9293\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.5268 - accuracy: 0.7900 - val_loss: 1.2367 - val_accuracy: 0.9040\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.5870 - accuracy: 0.7554 - val_loss: 1.0778 - val_accuracy: 0.9242\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.6608 - accuracy: 0.7727 - val_loss: 1.1672 - val_accuracy: 0.9141\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.5684 - accuracy: 0.8052 - val_loss: 1.1813 - val_accuracy: 0.9242\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.6920 - accuracy: 0.7684 - val_loss: 1.8390 - val_accuracy: 0.8838\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.7159 - accuracy: 0.7511 - val_loss: 1.2136 - val_accuracy: 0.9242\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.9344 - accuracy: 0.8030 - val_loss: 1.4331 - val_accuracy: 0.8990\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.7196 - accuracy: 0.7857 - val_loss: 1.6042 - val_accuracy: 0.8990\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.8467 - accuracy: 0.7381 - val_loss: 1.2117 - val_accuracy: 0.9192\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.6974 - accuracy: 0.7771 - val_loss: 1.3615 - val_accuracy: 0.9141\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.8570 - accuracy: 0.7879 - val_loss: 1.6594 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 78.82%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [2.36758900e-05, 9.99976300e-01, 3.15256700e-08],\n",
       "       [1.00000000e+00, 1.81686280e-14, 4.24802700e-12],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [8.32429600e-08, 9.99999900e-01, 1.05404420e-09],\n",
       "       [4.62640420e-05, 9.99953600e-01, 9.47458100e-08],\n",
       "       [7.88794700e-08, 9.99999900e-01, 6.59497940e-11],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [8.32429600e-08, 9.99999900e-01, 1.05404420e-09],\n",
       "       [2.63931080e-08, 1.00000000e+00, 1.31076380e-09],\n",
       "       [1.00000000e+00, 1.02502680e-16, 6.67100450e-14],\n",
       "       [1.00000000e+00, 6.40438040e-17, 7.43121200e-20],\n",
       "       [1.00000000e+00, 5.07298100e-14, 1.57200220e-16],\n",
       "       [7.88794700e-08, 9.99999900e-01, 6.59497940e-11],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.83921230e-14, 4.91007130e-17],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.30732570e-07, 9.99999900e-01, 8.51306500e-10],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.57326680e-28, 1.03917480e-27],\n",
       "       [1.00000000e+00, 3.51087160e-09, 8.51442200e-12],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.36033890e-18, 1.00000000e+00, 3.50713400e-22],\n",
       "       [1.00000000e+00, 3.43336780e-11, 2.77160180e-13],\n",
       "       [2.04295410e-01, 7.95606850e-01, 9.78222960e-05],\n",
       "       [1.00000000e+00, 1.36722420e-22, 6.06346370e-21],\n",
       "       [4.37648140e-09, 1.00000000e+00, 1.17813810e-10],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [4.36756300e-06, 9.99995600e-01, 7.32538000e-09],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.80895300e-12, 1.00000000e+00, 1.81012470e-14],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.00055730e-12, 1.06363440e-14],\n",
       "       [1.00000000e+00, 9.23115600e-14, 3.12349830e-16],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [2.18592960e-12, 1.00000000e+00, 7.06619240e-16],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [9.99999500e-01, 5.20918200e-07, 1.72987500e-08],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.22396460e-05, 9.99987500e-01, 1.82298520e-07],\n",
       "       [2.36758900e-05, 9.99976300e-01, 3.15256700e-08],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.17197650e-04, 9.99882100e-01, 7.12715860e-07],\n",
       "       [9.32750300e-15, 1.00000000e+00, 3.87091800e-17],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [9.99999900e-01, 6.24763250e-08, 8.89346800e-09],\n",
       "       [1.00000000e+00, 3.06706850e-18, 4.36242700e-18],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.28453080e-22, 4.18027130e-26],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.29172820e-16, 1.17107620e-18],\n",
       "       [1.00000000e+00, 4.46873900e-08, 1.38551310e-08],\n",
       "       [9.99999400e-01, 5.88951140e-07, 1.99138520e-08],\n",
       "       [1.00000000e+00, 1.39345080e-15, 2.18655180e-15],\n",
       "       [9.99984150e-01, 1.50835120e-05, 7.23235600e-07],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.37778510e-10, 1.36410010e-12],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.15697500e-14, 2.96706450e-13],\n",
       "       [1.10720755e-07, 9.99999900e-01, 6.98734360e-09],\n",
       "       [1.00000000e+00, 1.00458430e-15, 1.39187300e-15],\n",
       "       [4.37648140e-09, 1.00000000e+00, 1.17813810e-10],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.36033890e-18, 1.00000000e+00, 3.50713400e-22],\n",
       "       [1.00000000e+00, 3.70058450e-15, 8.81111000e-16],\n",
       "       [1.00000000e+00, 1.40996660e-13, 1.21693090e-13],\n",
       "       [4.84332100e-11, 1.00000000e+00, 8.39410900e-13],\n",
       "       [1.34502370e-07, 9.99999900e-01, 1.74456000e-09],\n",
       "       [8.66457400e-11, 1.00000000e+00, 1.65494940e-12],\n",
       "       [1.36033890e-18, 1.00000000e+00, 3.50713400e-22],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.41383465e-08, 1.00000000e+00, 6.32612000e-10],\n",
       "       [2.36758900e-05, 9.99976300e-01, 3.15256700e-08],\n",
       "       [2.05401350e-06, 9.99997740e-01, 2.14475070e-07],\n",
       "       [1.00000000e+00, 8.11419050e-19, 1.21123650e-17],\n",
       "       [1.00000000e+00, 1.02530230e-20, 1.14683080e-20],\n",
       "       [4.62640420e-05, 9.99953600e-01, 9.47458100e-08],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [1.00000000e+00, 1.01307000e-11, 6.83558840e-14],\n",
       "       [1.00000000e+00, 2.00055730e-12, 1.06363440e-14],\n",
       "       [1.00000000e+00, 9.85896000e-13, 1.05886250e-12],\n",
       "       [1.00000000e+00, 2.02078360e-19, 1.16569150e-19],\n",
       "       [1.00000000e+00, 6.42043650e-29, 1.17690946e-29],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [4.84332100e-11, 1.00000000e+00, 8.39410900e-13],\n",
       "       [1.00000000e+00, 6.05093000e-13, 2.69878500e-15],\n",
       "       [8.59516400e-01, 1.29081950e-01, 1.14017480e-02],\n",
       "       [8.32429600e-08, 9.99999900e-01, 1.05404420e-09],\n",
       "       [1.00000000e+00, 1.05827410e-10, 8.39336500e-11],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.52985800e-14, 1.03706990e-16],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [2.18592960e-12, 1.00000000e+00, 7.06619240e-16],\n",
       "       [9.99990100e-01, 9.44084150e-06, 4.30205570e-07],\n",
       "       [8.66457400e-11, 1.00000000e+00, 1.65494940e-12],\n",
       "       [1.41383465e-08, 1.00000000e+00, 6.32612000e-10],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [7.88794700e-08, 9.99999900e-01, 6.59497940e-11],\n",
       "       [2.44345060e-05, 9.99975440e-01, 1.39305430e-07],\n",
       "       [8.59516400e-01, 1.29081950e-01, 1.14017480e-02],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [7.77387300e-10, 1.00000000e+00, 2.14233890e-11],\n",
       "       [4.36756300e-06, 9.99995600e-01, 7.32538000e-09],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [2.63931080e-08, 1.00000000e+00, 1.31076380e-09],\n",
       "       [1.22396460e-05, 9.99987500e-01, 1.82298520e-07],\n",
       "       [4.96623600e-05, 9.99950300e-01, 1.84691620e-08],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.00055730e-12, 1.06363440e-14],\n",
       "       [4.06665760e-02, 9.59333400e-01, 1.16005610e-08],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.93799700e-12, 1.00000000e+00, 1.28224920e-14],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.65352400e-08, 1.08962990e-08],\n",
       "       [9.99997850e-01, 2.13391010e-06, 2.93722000e-10],\n",
       "       [1.00000000e+00, 1.39085820e-09, 8.04302040e-11],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.10720755e-07, 9.99999900e-01, 6.98734360e-09],\n",
       "       [4.37648140e-09, 1.00000000e+00, 1.17813810e-10],\n",
       "       [9.99999900e-01, 1.25989170e-07, 8.87110100e-10],\n",
       "       [1.24701820e-10, 1.00000000e+00, 2.88679500e-14],\n",
       "       [9.99999050e-01, 9.21188530e-07, 7.72018800e-09],\n",
       "       [4.36756300e-06, 9.99995600e-01, 7.32538000e-09],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.70098840e-08, 5.80700150e-10],\n",
       "       [1.00000000e+00, 3.34837540e-11, 1.48019790e-11],\n",
       "       [2.04295410e-01, 7.95606850e-01, 9.78222960e-05],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.07218660e-12, 7.05893600e-11],\n",
       "       [1.89955440e-10, 1.00000000e+00, 1.42626380e-12],\n",
       "       [1.00000000e+00, 5.17013700e-10, 1.53142130e-09],\n",
       "       [1.11773580e-08, 1.00000000e+00, 4.80863960e-10],\n",
       "       [1.00000000e+00, 1.40012190e-15, 3.10288350e-15],\n",
       "       [1.41383465e-08, 1.00000000e+00, 6.32612000e-10],\n",
       "       [9.99999300e-01, 7.53462360e-07, 2.64057270e-08],\n",
       "       [2.18592960e-12, 1.00000000e+00, 7.06619240e-16],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.30799700e-35, 0.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00],\n",
       "       [9.99925260e-01, 7.47686100e-05, 1.20400685e-08],\n",
       "       [1.00000000e+00, 1.64721410e-13, 6.06852360e-16],\n",
       "       [1.24701820e-10, 1.00000000e+00, 2.88679500e-14],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [4.37648140e-09, 1.00000000e+00, 1.17813810e-10],\n",
       "       [1.00000000e+00, 1.72546690e-08, 8.79918400e-09],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.10720755e-07, 9.99999900e-01, 6.98734360e-09],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [4.62640420e-05, 9.99953600e-01, 9.47458100e-08],\n",
       "       [2.18592960e-12, 1.00000000e+00, 7.06619240e-16],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.09521810e-08, 1.00000000e+00, 4.69579650e-10],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [9.99998700e-01, 1.17786260e-06, 1.07923130e-07],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.08546400e-09, 1.45537180e-11],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.10369700e-17, 3.21747580e-17],\n",
       "       [1.00000000e+00, 8.44534450e-19, 1.37830780e-18],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.04684110e-21, 3.28840870e-21],\n",
       "       [1.24701820e-10, 1.00000000e+00, 2.88679500e-14],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.21308120e-33, 2.58523760e-38],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [1.87435510e-09, 5.53344660e-09, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [1.41383465e-08, 1.00000000e+00, 6.32612000e-10],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [9.61723400e-09, 1.12102800e-08, 1.00000000e+00],\n",
       "       [2.36758900e-05, 9.99976300e-01, 3.15256700e-08],\n",
       "       [8.59516400e-01, 1.29081950e-01, 1.14017480e-02],\n",
       "       [2.36758900e-05, 9.99976300e-01, 3.15256100e-08],\n",
       "       [9.61721550e-09, 1.12102585e-08, 1.00000000e+00],\n",
       "       [7.29656140e-02, 8.49449630e-01, 7.75847300e-02],\n",
       "       [1.00000000e+00, 7.82926800e-15, 1.84354340e-17],\n",
       "       [1.11773150e-08, 1.00000000e+00, 4.80863070e-10],\n",
       "       [1.54003670e-08, 1.82290110e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852502295684115"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852502295684115"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa116     0\n",
       "1         NRS214     0\n",
       "2         NRS148     2\n",
       "3         NRS148     2\n",
       "4         NRS148     2\n",
       "..           ...   ...\n",
       "193       NRS148     2\n",
       "194       NRS054     0\n",
       "195       NRS109     2\n",
       "196       NRS216     1\n",
       "197    BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 788us/step - loss: 6.2071 - accuracy: 0.5195 - val_loss: 2.4389 - val_accuracy: 0.7323\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 4.3776 - accuracy: 0.5823 - val_loss: 1.4943 - val_accuracy: 0.6061\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 502us/step - loss: 3.6823 - accuracy: 0.6364 - val_loss: 1.0597 - val_accuracy: 0.7677\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 3.6903 - accuracy: 0.6407 - val_loss: 1.0230 - val_accuracy: 0.7576\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 3.3820 - accuracy: 0.6602 - val_loss: 0.9743 - val_accuracy: 0.7727\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 3.3565 - accuracy: 0.6667 - val_loss: 1.1421 - val_accuracy: 0.7424\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 3.2720 - accuracy: 0.6494 - val_loss: 1.5299 - val_accuracy: 0.7677\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 3.1652 - accuracy: 0.6688 - val_loss: 1.5682 - val_accuracy: 0.7778\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 3.1225 - accuracy: 0.6537 - val_loss: 1.4713 - val_accuracy: 0.7929\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 413us/step - loss: 2.8442 - accuracy: 0.6342 - val_loss: 1.5792 - val_accuracy: 0.7828\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 2.8540 - accuracy: 0.6732 - val_loss: 1.3062 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 2.7534 - accuracy: 0.7208 - val_loss: 1.1387 - val_accuracy: 0.8283\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 719us/step - loss: 2.4869 - accuracy: 0.7165 - val_loss: 1.3667 - val_accuracy: 0.8586\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 576us/step - loss: 2.4560 - accuracy: 0.7165 - val_loss: 1.2769 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 587us/step - loss: 2.5396 - accuracy: 0.7294 - val_loss: 1.5134 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 791us/step - loss: 2.5386 - accuracy: 0.6970 - val_loss: 1.4222 - val_accuracy: 0.7980\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 738us/step - loss: 2.7812 - accuracy: 0.6537 - val_loss: 1.3707 - val_accuracy: 0.7929\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 2.3379 - accuracy: 0.7121 - val_loss: 1.4646 - val_accuracy: 0.8434\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 2.2091 - accuracy: 0.7294 - val_loss: 1.4156 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 474us/step - loss: 2.1194 - accuracy: 0.7251 - val_loss: 1.3100 - val_accuracy: 0.8485\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 546us/step - loss: 2.3026 - accuracy: 0.6991 - val_loss: 1.4053 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 481us/step - loss: 1.9648 - accuracy: 0.7251 - val_loss: 1.4698 - val_accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 2.1049 - accuracy: 0.7468 - val_loss: 1.1092 - val_accuracy: 0.8384\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.9475 - accuracy: 0.7446 - val_loss: 1.4688 - val_accuracy: 0.8636\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 1.8966 - accuracy: 0.7316 - val_loss: 0.9963 - val_accuracy: 0.8384\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 514us/step - loss: 1.6961 - accuracy: 0.7381 - val_loss: 1.3893 - val_accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 1.6552 - accuracy: 0.7684 - val_loss: 1.2256 - val_accuracy: 0.8535\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 1.8923 - accuracy: 0.7446 - val_loss: 1.0501 - val_accuracy: 0.8737\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 1.7526 - accuracy: 0.7381 - val_loss: 1.0003 - val_accuracy: 0.8687\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 1.5726 - accuracy: 0.7489 - val_loss: 1.1896 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.5004 - accuracy: 0.7641 - val_loss: 1.1075 - val_accuracy: 0.8889\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 1.4398 - accuracy: 0.7684 - val_loss: 1.1543 - val_accuracy: 0.8737\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 1.2990 - accuracy: 0.7814 - val_loss: 1.1807 - val_accuracy: 0.8939\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 1.5553 - accuracy: 0.7706 - val_loss: 0.9352 - val_accuracy: 0.8636\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.3977 - accuracy: 0.7576 - val_loss: 1.3073 - val_accuracy: 0.8434\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 1.4433 - accuracy: 0.7619 - val_loss: 1.1550 - val_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 1.1854 - accuracy: 0.7814 - val_loss: 0.8379 - val_accuracy: 0.8788\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 1.2813 - accuracy: 0.7879 - val_loss: 0.9422 - val_accuracy: 0.8586\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.2838 - accuracy: 0.7576 - val_loss: 1.0168 - val_accuracy: 0.8788\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 1.5060 - accuracy: 0.7424 - val_loss: 0.8494 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 1.4130 - accuracy: 0.7381 - val_loss: 0.8695 - val_accuracy: 0.8838\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 1.0788 - accuracy: 0.7792 - val_loss: 1.4918 - val_accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 1.1805 - accuracy: 0.7662 - val_loss: 0.9510 - val_accuracy: 0.9040\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 1.1258 - accuracy: 0.7879 - val_loss: 1.4398 - val_accuracy: 0.8939\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 1.2524 - accuracy: 0.7597 - val_loss: 1.2536 - val_accuracy: 0.9040\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 1.0632 - accuracy: 0.7900 - val_loss: 0.8002 - val_accuracy: 0.8838\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 1.0594 - accuracy: 0.7597 - val_loss: 1.1056 - val_accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 1.1029 - accuracy: 0.7706 - val_loss: 0.9879 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.0905 - accuracy: 0.7641 - val_loss: 1.3428 - val_accuracy: 0.8990\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.8670 - accuracy: 0.8247 - val_loss: 1.2782 - val_accuracy: 0.8990\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.0296 - accuracy: 0.7641 - val_loss: 0.8615 - val_accuracy: 0.9343\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.0000 - accuracy: 0.7965 - val_loss: 0.6588 - val_accuracy: 0.9343\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.9667 - accuracy: 0.7857 - val_loss: 0.6645 - val_accuracy: 0.9141\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 1.0273 - accuracy: 0.7619 - val_loss: 0.7242 - val_accuracy: 0.9394\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.8643 - accuracy: 0.7879 - val_loss: 0.6376 - val_accuracy: 0.9040\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.8820 - accuracy: 0.7922 - val_loss: 0.6007 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.9360 - accuracy: 0.7835 - val_loss: 0.8982 - val_accuracy: 0.8990\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 1.0471 - accuracy: 0.7424 - val_loss: 0.6354 - val_accuracy: 0.9394\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.8424 - accuracy: 0.7987 - val_loss: 1.0164 - val_accuracy: 0.8939\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.8735 - accuracy: 0.7922 - val_loss: 0.6414 - val_accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.9453 - accuracy: 0.7771 - val_loss: 0.7540 - val_accuracy: 0.9293\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.7696 - accuracy: 0.7835 - val_loss: 0.8552 - val_accuracy: 0.8990\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 0.8993 - accuracy: 0.7749 - val_loss: 1.0912 - val_accuracy: 0.9141\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 601us/step - loss: 0.7478 - accuracy: 0.7965 - val_loss: 0.6886 - val_accuracy: 0.9343\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.7708 - accuracy: 0.8117 - val_loss: 0.8618 - val_accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 468us/step - loss: 0.8998 - accuracy: 0.7835 - val_loss: 0.6302 - val_accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.8287 - accuracy: 0.7814 - val_loss: 1.0426 - val_accuracy: 0.9192\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.8147 - accuracy: 0.7749 - val_loss: 0.5668 - val_accuracy: 0.9343\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.7228 - accuracy: 0.7965 - val_loss: 0.6037 - val_accuracy: 0.9495\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.7479 - accuracy: 0.7987 - val_loss: 0.5568 - val_accuracy: 0.9495\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.7528 - accuracy: 0.7727 - val_loss: 0.7552 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.7439 - accuracy: 0.8247 - val_loss: 0.6260 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.7062 - accuracy: 0.8074 - val_loss: 0.6702 - val_accuracy: 0.9394\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.9248 - accuracy: 0.7771 - val_loss: 0.8703 - val_accuracy: 0.9242\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.7206 - accuracy: 0.8030 - val_loss: 0.5448 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.7396 - accuracy: 0.7749 - val_loss: 0.4680 - val_accuracy: 0.9596\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.7765 - accuracy: 0.7900 - val_loss: 0.7921 - val_accuracy: 0.9343\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.8338 - accuracy: 0.7727 - val_loss: 0.5533 - val_accuracy: 0.9545\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.7518 - accuracy: 0.7835 - val_loss: 0.6375 - val_accuracy: 0.9394\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.6877 - accuracy: 0.7987 - val_loss: 0.7058 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.6486 - accuracy: 0.7857 - val_loss: 0.4719 - val_accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.7099 - accuracy: 0.7576 - val_loss: 0.7231 - val_accuracy: 0.9394\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.6691 - accuracy: 0.8074 - val_loss: 0.7263 - val_accuracy: 0.9343\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5937 - accuracy: 0.7965 - val_loss: 0.4455 - val_accuracy: 0.9596\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.7947 - accuracy: 0.7922 - val_loss: 0.6757 - val_accuracy: 0.9394\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.7880 - accuracy: 0.7641 - val_loss: 0.6670 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.7325 - accuracy: 0.7749 - val_loss: 0.7471 - val_accuracy: 0.9293\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.6633 - accuracy: 0.7835 - val_loss: 0.5766 - val_accuracy: 0.9394\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.5276 - accuracy: 0.8117 - val_loss: 0.5341 - val_accuracy: 0.9545\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.6439 - accuracy: 0.7424 - val_loss: 0.5191 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5215 - accuracy: 0.7857 - val_loss: 0.4730 - val_accuracy: 0.9545\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.5630 - accuracy: 0.7965 - val_loss: 0.5549 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.6458 - accuracy: 0.8009 - val_loss: 0.8946 - val_accuracy: 0.9343\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4607 - accuracy: 0.8355 - val_loss: 0.3941 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.6455 - accuracy: 0.8139 - val_loss: 0.5310 - val_accuracy: 0.9495\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.7049 - accuracy: 0.7727 - val_loss: 0.5053 - val_accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.5141 - accuracy: 0.8247 - val_loss: 0.6926 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.7221 - accuracy: 0.7987 - val_loss: 0.4502 - val_accuracy: 0.9596\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.5940 - accuracy: 0.7965 - val_loss: 0.5073 - val_accuracy: 0.9495\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5671 - accuracy: 0.7857 - val_loss: 0.8054 - val_accuracy: 0.9343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3b05c2b0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 177us/step\n",
      "over-sampling test accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 2,\n",
       "       2, 2, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 2, 2,\n",
       "       1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0,\n",
       "       2, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 2, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
       "       2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa116     0     0\n",
       "1         NRS214     0     0\n",
       "2         NRS148     2     2\n",
       "3         NRS148     2     2\n",
       "4         NRS148     2     2\n",
       "..           ...   ...   ...\n",
       "193       NRS148     2     2\n",
       "194       NRS054     0     0\n",
       "195       NRS109     2     2\n",
       "196       NRS216     1     1\n",
       "197    BCH-SA-03     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.989959e-17</td>\n",
       "      <td>2.267019e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.571602e-11</td>\n",
       "      <td>6.163611e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.903322e-11</td>\n",
       "      <td>9.252212e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.903322e-11</td>\n",
       "      <td>9.252212e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.903322e-11</td>\n",
       "      <td>9.252212e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.903325e-11</td>\n",
       "      <td>9.252230e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.999892e-01</td>\n",
       "      <td>7.644894e-06</td>\n",
       "      <td>3.258920e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3.963342e-13</td>\n",
       "      <td>1.159683e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.209495e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.830634e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.036043e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.507119e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.000000e+00  2.989959e-17  2.267019e-16\n",
       "1    1.000000e+00  7.571602e-11  6.163611e-11\n",
       "2    1.903322e-11  9.252212e-12  1.000000e+00\n",
       "3    1.903322e-11  9.252212e-12  1.000000e+00\n",
       "4    1.903322e-11  9.252212e-12  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "193  1.903325e-11  9.252230e-12  1.000000e+00\n",
       "194  9.999892e-01  7.644894e-06  3.258920e-06\n",
       "195  3.963342e-13  1.159683e-13  1.000000e+00\n",
       "196  9.209495e-09  1.000000e+00  1.830634e-10\n",
       "197  6.036043e-11  1.000000e+00  4.507119e-13\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p002ypST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.7292 - accuracy: 0.7965 - val_loss: 0.4938 - val_accuracy: 0.9444\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.6321 - accuracy: 0.7944 - val_loss: 0.4546 - val_accuracy: 0.9394\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.7012 - accuracy: 0.7792 - val_loss: 0.4362 - val_accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.8464 - accuracy: 0.7835 - val_loss: 0.6047 - val_accuracy: 0.9495\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.6445 - accuracy: 0.7879 - val_loss: 0.5600 - val_accuracy: 0.9495\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.7249 - accuracy: 0.7814 - val_loss: 0.7505 - val_accuracy: 0.9394\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.7690 - accuracy: 0.7792 - val_loss: 0.6889 - val_accuracy: 0.9394\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.5913 - accuracy: 0.8160 - val_loss: 0.5173 - val_accuracy: 0.9394\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.5587 - accuracy: 0.7857 - val_loss: 0.5943 - val_accuracy: 0.9495\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.6334 - accuracy: 0.7857 - val_loss: 0.5438 - val_accuracy: 0.9545\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.6836 - accuracy: 0.7857 - val_loss: 0.9105 - val_accuracy: 0.9192\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.7653 - accuracy: 0.7857 - val_loss: 0.8603 - val_accuracy: 0.9192\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.7951 - accuracy: 0.7944 - val_loss: 1.1323 - val_accuracy: 0.9091\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.6801 - accuracy: 0.7944 - val_loss: 0.7200 - val_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.5832 - accuracy: 0.7879 - val_loss: 0.5022 - val_accuracy: 0.9444\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.7068 - accuracy: 0.7489 - val_loss: 0.7214 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5995 - accuracy: 0.7576 - val_loss: 0.5971 - val_accuracy: 0.9495\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5259 - accuracy: 0.8160 - val_loss: 0.7082 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.5980 - accuracy: 0.7771 - val_loss: 0.6324 - val_accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5419 - accuracy: 0.7857 - val_loss: 0.5464 - val_accuracy: 0.9545\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5820 - accuracy: 0.7922 - val_loss: 0.5838 - val_accuracy: 0.9394\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.6491 - accuracy: 0.7900 - val_loss: 0.8395 - val_accuracy: 0.9343\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.5914 - accuracy: 0.7792 - val_loss: 1.1133 - val_accuracy: 0.9242\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5869 - accuracy: 0.7835 - val_loss: 0.6967 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5851 - accuracy: 0.7597 - val_loss: 0.7181 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.6233 - accuracy: 0.8095 - val_loss: 0.6973 - val_accuracy: 0.9394\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.5289 - accuracy: 0.8139 - val_loss: 0.5111 - val_accuracy: 0.9697\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.6306 - accuracy: 0.7835 - val_loss: 1.1369 - val_accuracy: 0.9141\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.6098 - accuracy: 0.7727 - val_loss: 0.8377 - val_accuracy: 0.9343\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.5488 - accuracy: 0.7857 - val_loss: 0.5186 - val_accuracy: 0.9646\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.5274 - accuracy: 0.7857 - val_loss: 0.5236 - val_accuracy: 0.9646\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.5295 - accuracy: 0.7900 - val_loss: 0.5344 - val_accuracy: 0.9343\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 0.5586 - accuracy: 0.7900 - val_loss: 0.7976 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.5245 - accuracy: 0.7900 - val_loss: 0.8928 - val_accuracy: 0.9242\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5433 - accuracy: 0.8095 - val_loss: 0.5284 - val_accuracy: 0.9596\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.5153 - accuracy: 0.7944 - val_loss: 0.9314 - val_accuracy: 0.9343\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.4390 - accuracy: 0.8139 - val_loss: 0.5179 - val_accuracy: 0.9444\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.5002 - accuracy: 0.8160 - val_loss: 0.9624 - val_accuracy: 0.9242\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5302 - accuracy: 0.8030 - val_loss: 1.2674 - val_accuracy: 0.9040\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5342 - accuracy: 0.8182 - val_loss: 1.6140 - val_accuracy: 0.8939\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.5889 - accuracy: 0.8225 - val_loss: 1.2816 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.5520 - accuracy: 0.7835 - val_loss: 1.5179 - val_accuracy: 0.8939\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.5097 - accuracy: 0.8030 - val_loss: 0.7298 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.4932 - accuracy: 0.8203 - val_loss: 1.0704 - val_accuracy: 0.9192\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.5960 - accuracy: 0.7879 - val_loss: 1.2148 - val_accuracy: 0.9192\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.5353 - accuracy: 0.7879 - val_loss: 0.5496 - val_accuracy: 0.9495\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.4755 - accuracy: 0.8009 - val_loss: 0.8406 - val_accuracy: 0.9394\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.4862 - accuracy: 0.8117 - val_loss: 0.4718 - val_accuracy: 0.9495\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.5477 - accuracy: 0.8160 - val_loss: 1.4054 - val_accuracy: 0.8939\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.5455 - accuracy: 0.8009 - val_loss: 0.5084 - val_accuracy: 0.9495\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.4212 - accuracy: 0.8030 - val_loss: 0.6491 - val_accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.4400 - accuracy: 0.8139 - val_loss: 0.5129 - val_accuracy: 0.9394\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.5043 - accuracy: 0.7597 - val_loss: 0.6153 - val_accuracy: 0.9545\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.4482 - accuracy: 0.8182 - val_loss: 0.7241 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.4441 - accuracy: 0.8182 - val_loss: 0.5663 - val_accuracy: 0.9646\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.4241 - accuracy: 0.8009 - val_loss: 0.7768 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.4636 - accuracy: 0.7749 - val_loss: 1.0269 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.4678 - accuracy: 0.8095 - val_loss: 0.5746 - val_accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.3769 - accuracy: 0.8139 - val_loss: 0.8104 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.4163 - accuracy: 0.8117 - val_loss: 0.5625 - val_accuracy: 0.9545\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.4630 - accuracy: 0.8095 - val_loss: 0.6194 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.4549 - accuracy: 0.7814 - val_loss: 0.7325 - val_accuracy: 0.9495\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.4125 - accuracy: 0.8225 - val_loss: 0.4591 - val_accuracy: 0.9545\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.4298 - accuracy: 0.8182 - val_loss: 1.1011 - val_accuracy: 0.9242\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.5283 - accuracy: 0.8052 - val_loss: 0.7254 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 0.4764 - accuracy: 0.7857 - val_loss: 0.5659 - val_accuracy: 0.9596\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 565us/step - loss: 0.3923 - accuracy: 0.8117 - val_loss: 0.6391 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 0.4204 - accuracy: 0.8052 - val_loss: 1.1958 - val_accuracy: 0.8939\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 786us/step - loss: 0.4481 - accuracy: 0.7706 - val_loss: 0.6065 - val_accuracy: 0.9545\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 463us/step - loss: 0.4314 - accuracy: 0.7727 - val_loss: 0.5492 - val_accuracy: 0.9596\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 643us/step - loss: 0.4787 - accuracy: 0.7900 - val_loss: 0.6416 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      " 64/462 [===>..........................] - ETA: 0s - loss: 0.4037 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.161343). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 0s 504us/step - loss: 0.4814 - accuracy: 0.7771 - val_loss: 0.4297 - val_accuracy: 0.9596\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.4096 - accuracy: 0.8052 - val_loss: 0.7078 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.4224 - accuracy: 0.8052 - val_loss: 0.8052 - val_accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.3643 - accuracy: 0.8074 - val_loss: 0.9018 - val_accuracy: 0.9343\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 0.4251 - accuracy: 0.8117 - val_loss: 0.8969 - val_accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.4515 - accuracy: 0.8074 - val_loss: 0.4287 - val_accuracy: 0.9545\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.4130 - accuracy: 0.8074 - val_loss: 0.7615 - val_accuracy: 0.9495\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.4707 - accuracy: 0.8095 - val_loss: 0.5686 - val_accuracy: 0.9545\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.3981 - accuracy: 0.8160 - val_loss: 0.7699 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.3686 - accuracy: 0.8333 - val_loss: 0.6286 - val_accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.5418 - accuracy: 0.7857 - val_loss: 0.7284 - val_accuracy: 0.9495\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.5294 - accuracy: 0.8052 - val_loss: 1.3529 - val_accuracy: 0.9192\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5925 - accuracy: 0.7554 - val_loss: 1.4160 - val_accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.5527 - accuracy: 0.8009 - val_loss: 1.1192 - val_accuracy: 0.9242\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5781 - accuracy: 0.7900 - val_loss: 1.0627 - val_accuracy: 0.9293\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.4536 - accuracy: 0.7987 - val_loss: 0.6439 - val_accuracy: 0.9495\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.4378 - accuracy: 0.7987 - val_loss: 0.8339 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.3530 - accuracy: 0.8333 - val_loss: 0.8490 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.3800 - accuracy: 0.7944 - val_loss: 0.8799 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4546 - accuracy: 0.7879 - val_loss: 0.6645 - val_accuracy: 0.9545\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4823 - accuracy: 0.7424 - val_loss: 0.8690 - val_accuracy: 0.9343\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.3637 - accuracy: 0.8139 - val_loss: 0.4944 - val_accuracy: 0.9646\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.4379 - accuracy: 0.8095 - val_loss: 1.4494 - val_accuracy: 0.9091\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.4956 - accuracy: 0.8247 - val_loss: 1.3230 - val_accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.5536 - accuracy: 0.7944 - val_loss: 1.3870 - val_accuracy: 0.9091\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.6007 - accuracy: 0.7749 - val_loss: 1.2312 - val_accuracy: 0.9192\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.5961 - accuracy: 0.7619 - val_loss: 1.4642 - val_accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5238 - accuracy: 0.7706 - val_loss: 1.1392 - val_accuracy: 0.9242\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4744 - accuracy: 0.7879 - val_loss: 0.9926 - val_accuracy: 0.9343\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.55%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 2.98995880e-17, 2.26701880e-16],\n",
       "       [1.00000000e+00, 7.57160200e-11, 6.16361060e-11],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [9.20947800e-09, 1.00000000e+00, 1.83062750e-10],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.42661080e-14, 1.20149440e-13],\n",
       "       [1.00000000e+00, 2.47253750e-11, 2.14327900e-11],\n",
       "       [5.53588500e-09, 1.00000000e+00, 7.43924440e-11],\n",
       "       [1.00000000e+00, 2.66637300e-14, 2.73315330e-13],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [5.53588500e-09, 1.00000000e+00, 7.43924440e-11],\n",
       "       [1.00000000e+00, 6.36831000e-14, 7.71469950e-14],\n",
       "       [7.14991730e-10, 1.00000000e+00, 3.25342270e-13],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [6.69556700e-06, 9.99992850e-01, 4.65979600e-07],\n",
       "       [1.20202870e-09, 1.00000000e+00, 1.60718100e-11],\n",
       "       [9.95318600e-01, 3.90919070e-03, 7.72191300e-04],\n",
       "       [1.00000000e+00, 4.40589500e-17, 8.03038000e-17],\n",
       "       [1.98377280e-13, 1.00000000e+00, 4.86450970e-16],\n",
       "       [2.33625010e-11, 1.00000000e+00, 1.45005870e-13],\n",
       "       [1.00000000e+00, 5.46838750e-12, 6.80033100e-11],\n",
       "       [3.52189420e-11, 1.00000000e+00, 2.36786580e-13],\n",
       "       [1.00000000e+00, 1.58557140e-23, 1.58267840e-21],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [8.45308960e-13, 1.00000000e+00, 2.74889760e-15],\n",
       "       [1.00000000e+00, 3.12990820e-13, 3.46739460e-13],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.64410490e-06, 9.99998200e-01, 8.97011960e-08],\n",
       "       [1.00000000e+00, 1.05156150e-18, 5.52167900e-17],\n",
       "       [1.67914360e-11, 1.00000000e+00, 9.77287000e-14],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [9.99992250e-01, 7.67221300e-06, 1.69643710e-07],\n",
       "       [1.00000000e+00, 2.50780200e-08, 5.58772500e-10],\n",
       "       [9.99925400e-01, 7.45865900e-05, 5.73442240e-10],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.53398400e-29, 5.89591170e-27],\n",
       "       [7.14991730e-10, 1.00000000e+00, 3.25342270e-13],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.98377280e-13, 1.00000000e+00, 4.86450970e-16],\n",
       "       [3.09668350e-10, 1.00000000e+00, 3.17936240e-12],\n",
       "       [5.53243060e-10, 1.00000000e+00, 6.35969840e-12],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [2.21274180e-13, 1.00000000e+00, 5.54263740e-16],\n",
       "       [1.00000000e+00, 7.18938700e-09, 4.88687400e-09],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [5.02330800e-10, 1.00000000e+00, 5.66691830e-12],\n",
       "       [6.03604300e-11, 1.00000000e+00, 4.50711920e-13],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [3.17257220e-08, 1.00000000e+00, 1.11537860e-11],\n",
       "       [1.00000000e+00, 1.91965800e-08, 8.53004000e-09],\n",
       "       [1.00000000e+00, 5.31691940e-31, 5.85826100e-30],\n",
       "       [3.47382760e-10, 1.00000000e+00, 3.64729200e-12],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.25692075e-14, 1.66788630e-14],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [6.03604300e-11, 1.00000000e+00, 4.50711920e-13],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.98377280e-13, 1.00000000e+00, 4.86450970e-16],\n",
       "       [1.00000000e+00, 4.43934000e-14, 5.48796270e-14],\n",
       "       [1.00000000e+00, 7.13028800e-15, 4.25154060e-14],\n",
       "       [1.26335260e-14, 1.00000000e+00, 1.81202180e-17],\n",
       "       [1.26335260e-14, 1.00000000e+00, 1.81202180e-17],\n",
       "       [8.45308960e-13, 1.00000000e+00, 2.74889760e-15],\n",
       "       [1.00000000e+00, 5.96297000e-14, 7.25038650e-14],\n",
       "       [1.00000000e+00, 3.56234550e-13, 1.40385160e-12],\n",
       "       [5.02330800e-10, 1.00000000e+00, 5.66691830e-12],\n",
       "       [1.00000000e+00, 2.64277620e-12, 3.90215100e-12],\n",
       "       [1.00000000e+00, 1.05388430e-11, 9.58341650e-12],\n",
       "       [6.69556700e-06, 9.99992850e-01, 4.65979600e-07],\n",
       "       [1.62242410e-03, 9.98103000e-01, 2.74446270e-04],\n",
       "       [9.99908570e-01, 6.60232600e-05, 2.53776890e-05],\n",
       "       [6.71303700e-10, 1.00000000e+00, 2.05893830e-12],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [5.02330800e-10, 1.00000000e+00, 5.66691830e-12],\n",
       "       [9.96225600e-01, 3.76507450e-03, 9.38870400e-06],\n",
       "       [3.52189420e-11, 1.00000000e+00, 2.36786580e-13],\n",
       "       [1.36833090e-10, 1.00000000e+00, 1.19827500e-12],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [1.00000000e+00, 5.22183540e-08, 2.94513360e-08],\n",
       "       [1.00000000e+00, 2.70511360e-15, 7.57741240e-14],\n",
       "       [7.14991730e-10, 1.00000000e+00, 3.25342270e-13],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.51469600e-12, 6.96443500e-12],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [9.99887350e-01, 1.12551000e-04, 1.57648320e-07],\n",
       "       [7.59296240e-11, 1.00000000e+00, 5.92879200e-13],\n",
       "       [1.64410490e-06, 9.99998200e-01, 8.97011960e-08],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.62242410e-03, 9.98103000e-01, 2.74446270e-04],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [8.94564260e-10, 1.00000000e+00, 1.12920680e-11],\n",
       "       [1.60101270e-06, 9.99998330e-01, 8.68994500e-08],\n",
       "       [1.98377280e-13, 1.00000000e+00, 4.86450970e-16],\n",
       "       [1.00000000e+00, 2.35436450e-13, 9.19113900e-13],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [5.53588500e-09, 1.00000000e+00, 7.43924440e-11],\n",
       "       [4.38485160e-10, 1.00000000e+00, 4.81742000e-12],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.30513580e-13, 1.03510960e-12],\n",
       "       [5.22881780e-17, 1.00000000e+00, 2.57599780e-20],\n",
       "       [4.37421960e-04, 9.99562560e-01, 4.74327950e-09],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.20202870e-09, 1.00000000e+00, 1.60718100e-11],\n",
       "       [9.99988560e-01, 1.13914175e-05, 3.67442480e-09],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [1.67914360e-11, 1.00000000e+00, 9.77287000e-14],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.38309800e-10, 5.96249300e-10],\n",
       "       [9.99999900e-01, 6.57263700e-08, 3.61615560e-08],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [7.14991730e-10, 1.00000000e+00, 3.25342270e-13],\n",
       "       [1.00000000e+00, 5.17210900e-14, 6.33921300e-14],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [2.21274180e-13, 1.00000000e+00, 5.54263740e-16],\n",
       "       [9.99900100e-01, 9.96667800e-05, 2.97562650e-07],\n",
       "       [1.00000000e+00, 2.65599450e-13, 5.43569300e-12],\n",
       "       [6.53419970e-06, 9.99992970e-01, 4.52994440e-07],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.95875280e-11, 5.54307470e-11],\n",
       "       [1.00000000e+00, 2.76076200e-15, 1.65178800e-14],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [5.53588500e-09, 1.00000000e+00, 7.43924440e-11],\n",
       "       [1.00000000e+00, 2.69633580e-15, 1.48936560e-14],\n",
       "       [1.00000000e+00, 4.50231620e-13, 4.88699470e-13],\n",
       "       [5.06152770e-03, 9.94938500e-01, 3.75260050e-09],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [6.69556700e-06, 9.99992850e-01, 4.65979600e-07],\n",
       "       [5.02330800e-10, 1.00000000e+00, 5.66691830e-12],\n",
       "       [9.20947800e-09, 1.00000000e+00, 1.83062750e-10],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.68808600e-15, 1.30450280e-14],\n",
       "       [1.00000000e+00, 6.60883000e-19, 2.72875150e-17],\n",
       "       [1.26847750e-12, 1.00000000e+00, 1.04394900e-15],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [5.53243060e-10, 1.00000000e+00, 6.35969840e-12],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [3.29536720e-06, 9.99996660e-01, 1.59121400e-11],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [5.96395750e-04, 9.99320500e-01, 8.30986700e-05],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [5.02330800e-10, 1.00000000e+00, 5.66691830e-12],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.08118480e-09, 7.58088300e-10],\n",
       "       [4.70374100e-09, 4.20116160e-09, 1.00000000e+00],\n",
       "       [1.62242410e-03, 9.98103000e-01, 2.74446270e-04],\n",
       "       [1.00000000e+00, 5.02275900e-15, 7.55326800e-15],\n",
       "       [1.00000000e+00, 5.78247800e-13, 6.18897950e-13],\n",
       "       [6.03604300e-11, 1.00000000e+00, 4.50711920e-13],\n",
       "       [1.90332160e-11, 9.25221200e-12, 1.00000000e+00],\n",
       "       [8.38888000e-08, 9.99999900e-01, 2.56401210e-09],\n",
       "       [6.75845500e-02, 9.32415100e-01, 3.01914800e-07],\n",
       "       [1.00000000e+00, 8.51333800e-11, 7.05171000e-11],\n",
       "       [9.61015500e-09, 1.00000000e+00, 1.92618090e-10],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.61207300e-13, 1.51128700e-12],\n",
       "       [7.93568000e-02, 8.78490870e-01, 4.21523230e-02],\n",
       "       [3.96337230e-13, 1.15969180e-13, 1.00000000e+00],\n",
       "       [9.99999500e-01, 4.74634450e-07, 5.67468200e-08],\n",
       "       [1.90332520e-11, 9.25223000e-12, 1.00000000e+00],\n",
       "       [9.99989150e-01, 7.64489400e-06, 3.25892030e-06],\n",
       "       [3.96334220e-13, 1.15968300e-13, 1.00000000e+00],\n",
       "       [9.20949500e-09, 1.00000000e+00, 1.83063440e-10],\n",
       "       [6.03604300e-11, 1.00000000e+00, 4.50711920e-13]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p002ypresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977502295684114"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977502295684114"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833658555249465"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004329597162429823"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833658555249465"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004329597162429823"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 93.69%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.013121584513306875\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 79.46%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.0039923233\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
