{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p002ykpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1738)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p002ykpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>AACCTTAAAATTAACTTCTTTCAATTTCATAATAAAGTCTCTATAAAATAACTTAGTTTAAAAACGATTCGTATCTTTCAGATTCAAATACCATCATTTT</th>\n",
       "      <th>AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT</th>\n",
       "      <th>AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT</th>\n",
       "      <th>AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT</th>\n",
       "      <th>AAATTGCGTATTT</th>\n",
       "      <th>AAATGCAGTAAAATTAATCGAGAGGTGCCATTTTGAAGACAGGTCGAATAGTGAAATCAATTAGTGGGGTATATCAAGTAGACGTTAATGGCGAACGTTT</th>\n",
       "      <th>AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  ...  \\\n",
       "0              1                1  ...   \n",
       "1              1                1  ...   \n",
       "2              1                1  ...   \n",
       "3              1                1  ...   \n",
       "4              1                1  ...   \n",
       "\n",
       "   AACCTTAAAATTAACTTCTTTCAATTTCATAATAAAGTCTCTATAAAATAACTTAGTTTAAAAACGATTCGTATCTTTCAGATTCAAATACCATCATTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTGCGTATTT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   AAATGCAGTAAAATTAATCGAGAGGTGCCATTTTGAAGACAGGTCGAATAGTGAAATCAATTAGTGGGGTATATCAAGTAGACGTTAATGGCGAACGTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      0  \n",
       "1   8   8      0  \n",
       "2   5   5      1  \n",
       "3   5   5      0  \n",
       "4   5   5      0  \n",
       "\n",
       "[5 rows x 1738 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    220\n",
       "1     30\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1737)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>AACCTTAAAATTAACTTCTTTCAATTTCATAATAAAGTCTCTATAAAATAACTTAGTTTAAAAACGATTCGTATCTTTCAGATTCAAATACCATCATTTT</th>\n",
       "      <th>AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT</th>\n",
       "      <th>AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT</th>\n",
       "      <th>AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT</th>\n",
       "      <th>AAATTGCGTATTT</th>\n",
       "      <th>AAATGCAGTAAAATTAATCGAGAGGTGCCATTTTGAAGACAGGTCGAATAGTGAAATCAATTAGTGGGGTATATCAAGTAGACGTTAATGGCGAACGTTT</th>\n",
       "      <th>AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  \\\n",
       "0              1                1   \n",
       "1              1                1   \n",
       "2              1                1   \n",
       "3              1                1   \n",
       "4              1                1   \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AACCTTAAAATTAACTTCTTTCAATTTCATAATAAAGTCTCTATAAAATAACTTAGTTTAAAAACGATTCGTATCTTTCAGATTCAAATACCATCATTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTGCGTATTT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   AAATGCAGTAAAATTAATCGAGAGGTGCCATTTTGAAGACAGGTCGAATAGTGAAATCAATTAGTGGGGTATATCAAGTAGACGTTAATGGCGAACGTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ST  CC  pheno  \n",
       "0   5   5      0  \n",
       "1   8   8      0  \n",
       "2   5   5      1  \n",
       "3   5   5      0  \n",
       "4   5   5      0  \n",
       "\n",
       "[5 rows x 1737 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 1737) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 220), (1, 220), (2, 220)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa26     0\n",
       "1         NRS109     2\n",
       "2         NRS112     0\n",
       "3         NRS216     1\n",
       "4         NRS021     0\n",
       "..           ...   ...\n",
       "193  CFBREBSa133     0\n",
       "194       NRS209     2\n",
       "195       NRS109     2\n",
       "196       NRS209     2\n",
       "197       NRS035     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 1.0039 - accuracy: 0.5996 - val_loss: 0.8888 - val_accuracy: 0.7677\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.5517 - accuracy: 0.7706 - val_loss: 0.5731 - val_accuracy: 0.7727\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.5479 - accuracy: 0.7662 - val_loss: 0.5057 - val_accuracy: 0.7727\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 550us/step - loss: 0.4180 - accuracy: 0.8052 - val_loss: 0.4701 - val_accuracy: 0.7475\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.4223 - accuracy: 0.7987 - val_loss: 0.4691 - val_accuracy: 0.7323\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.4183 - accuracy: 0.8095 - val_loss: 0.5513 - val_accuracy: 0.7626\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.4133 - accuracy: 0.8247 - val_loss: 0.3895 - val_accuracy: 0.8535\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 407us/step - loss: 0.3752 - accuracy: 0.8377 - val_loss: 0.3228 - val_accuracy: 0.8535\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 0.3399 - accuracy: 0.8831 - val_loss: 0.3384 - val_accuracy: 0.8990\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 514us/step - loss: 0.3637 - accuracy: 0.8810 - val_loss: 0.3048 - val_accuracy: 0.8990\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 0.3410 - accuracy: 0.8636 - val_loss: 0.2877 - val_accuracy: 0.8535\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.3083 - accuracy: 0.8680 - val_loss: 0.3360 - val_accuracy: 0.8737\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.3820 - accuracy: 0.8442 - val_loss: 0.2596 - val_accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 514us/step - loss: 0.4315 - accuracy: 0.8160 - val_loss: 0.3199 - val_accuracy: 0.8990\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 959us/step - loss: 0.3780 - accuracy: 0.8550 - val_loss: 0.5956 - val_accuracy: 0.8081\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 558us/step - loss: 0.5428 - accuracy: 0.7879 - val_loss: 0.4942 - val_accuracy: 0.8030\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 0.3565 - accuracy: 0.8398 - val_loss: 0.3805 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.3565 - accuracy: 0.8333 - val_loss: 0.3604 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 509us/step - loss: 0.2927 - accuracy: 0.8853 - val_loss: 0.2471 - val_accuracy: 0.9293\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.2850 - accuracy: 0.8831 - val_loss: 0.2355 - val_accuracy: 0.9040\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.2706 - accuracy: 0.9004 - val_loss: 0.3641 - val_accuracy: 0.7980\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.3202 - accuracy: 0.8247 - val_loss: 0.2094 - val_accuracy: 0.8990\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.2667 - accuracy: 0.8615 - val_loss: 0.2292 - val_accuracy: 0.9040\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.2414 - accuracy: 0.8939 - val_loss: 0.2093 - val_accuracy: 0.9192\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.2261 - accuracy: 0.9048 - val_loss: 0.2381 - val_accuracy: 0.8737\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.2252 - accuracy: 0.9091 - val_loss: 0.2145 - val_accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.2210 - accuracy: 0.9134 - val_loss: 0.2113 - val_accuracy: 0.8990\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.2138 - accuracy: 0.9156 - val_loss: 0.1906 - val_accuracy: 0.9242\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 419us/step - loss: 0.2379 - accuracy: 0.9091 - val_loss: 0.2027 - val_accuracy: 0.9141\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.2493 - accuracy: 0.8896 - val_loss: 0.2201 - val_accuracy: 0.9040\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 527us/step - loss: 0.2290 - accuracy: 0.9113 - val_loss: 0.2211 - val_accuracy: 0.9242\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.2307 - accuracy: 0.9069 - val_loss: 0.1876 - val_accuracy: 0.9242\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.2359 - accuracy: 0.9026 - val_loss: 0.2108 - val_accuracy: 0.9192\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.1938 - accuracy: 0.9416 - val_loss: 0.2063 - val_accuracy: 0.9040\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.1976 - accuracy: 0.9264 - val_loss: 0.1855 - val_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1927 - accuracy: 0.9242 - val_loss: 0.1760 - val_accuracy: 0.9242\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 463us/step - loss: 0.2037 - accuracy: 0.9264 - val_loss: 0.2006 - val_accuracy: 0.9192\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.2409 - accuracy: 0.9177 - val_loss: 0.2424 - val_accuracy: 0.8838\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.2432 - accuracy: 0.8983 - val_loss: 0.1805 - val_accuracy: 0.9242\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1836 - accuracy: 0.9351 - val_loss: 0.1624 - val_accuracy: 0.9242\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.1836 - accuracy: 0.9416 - val_loss: 0.1721 - val_accuracy: 0.9343\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 674us/step - loss: 0.2004 - accuracy: 0.9091 - val_loss: 0.1921 - val_accuracy: 0.9141\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.1813 - accuracy: 0.9307 - val_loss: 0.1720 - val_accuracy: 0.9242\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.1875 - accuracy: 0.9264 - val_loss: 0.2189 - val_accuracy: 0.9192\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.2074 - accuracy: 0.9156 - val_loss: 0.2471 - val_accuracy: 0.9141\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.2034 - accuracy: 0.9242 - val_loss: 0.1570 - val_accuracy: 0.9394\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1821 - accuracy: 0.9307 - val_loss: 0.1988 - val_accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1983 - accuracy: 0.9091 - val_loss: 0.1753 - val_accuracy: 0.9242\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 531us/step - loss: 0.2000 - accuracy: 0.9242 - val_loss: 0.1448 - val_accuracy: 0.9596\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.2141 - accuracy: 0.8983 - val_loss: 0.1422 - val_accuracy: 0.9596\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1788 - accuracy: 0.9394 - val_loss: 0.1445 - val_accuracy: 0.9545\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1939 - accuracy: 0.9199 - val_loss: 0.1451 - val_accuracy: 0.9343\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 168us/step - loss: 0.1813 - accuracy: 0.9351 - val_loss: 0.1420 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 168us/step - loss: 0.1683 - accuracy: 0.9264 - val_loss: 0.1642 - val_accuracy: 0.9293\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.2121 - accuracy: 0.9221 - val_loss: 0.1697 - val_accuracy: 0.9293\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 424us/step - loss: 0.1909 - accuracy: 0.9113 - val_loss: 0.2067 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.1734 - accuracy: 0.9416 - val_loss: 0.1571 - val_accuracy: 0.9394\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.1711 - accuracy: 0.9264 - val_loss: 0.1538 - val_accuracy: 0.9192\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.1710 - accuracy: 0.9242 - val_loss: 0.1758 - val_accuracy: 0.9192\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.2188 - accuracy: 0.9069 - val_loss: 0.1644 - val_accuracy: 0.9192\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1693 - accuracy: 0.9416 - val_loss: 0.1523 - val_accuracy: 0.9293\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1679 - accuracy: 0.9372 - val_loss: 0.1473 - val_accuracy: 0.9192\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1582 - accuracy: 0.9437 - val_loss: 0.1780 - val_accuracy: 0.9293\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1794 - accuracy: 0.9351 - val_loss: 0.1547 - val_accuracy: 0.9192\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.1617 - accuracy: 0.9329 - val_loss: 0.1569 - val_accuracy: 0.9343\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 0.1547 - accuracy: 0.9416 - val_loss: 0.1425 - val_accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 549us/step - loss: 0.1462 - accuracy: 0.9416 - val_loss: 0.1331 - val_accuracy: 0.9242\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 0.1716 - accuracy: 0.9221 - val_loss: 0.1339 - val_accuracy: 0.9545\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.1498 - accuracy: 0.9459 - val_loss: 0.1395 - val_accuracy: 0.9394\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1455 - accuracy: 0.9545 - val_loss: 0.1530 - val_accuracy: 0.9242\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.1520 - accuracy: 0.9459 - val_loss: 0.1581 - val_accuracy: 0.9495\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1546 - accuracy: 0.9481 - val_loss: 0.1416 - val_accuracy: 0.9394\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1404 - accuracy: 0.9524 - val_loss: 0.1542 - val_accuracy: 0.9293\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1570 - accuracy: 0.9307 - val_loss: 0.1707 - val_accuracy: 0.9242\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.1679 - accuracy: 0.9307 - val_loss: 0.1761 - val_accuracy: 0.9192\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.1657 - accuracy: 0.9199 - val_loss: 0.1496 - val_accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.1336 - accuracy: 0.9524 - val_loss: 0.1391 - val_accuracy: 0.9192\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.1503 - accuracy: 0.9286 - val_loss: 0.1704 - val_accuracy: 0.9242\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.1543 - accuracy: 0.9437 - val_loss: 0.1282 - val_accuracy: 0.9394\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1417 - accuracy: 0.9524 - val_loss: 0.1318 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1402 - accuracy: 0.9481 - val_loss: 0.1324 - val_accuracy: 0.9394\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1709 - accuracy: 0.9177 - val_loss: 0.1939 - val_accuracy: 0.9192\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.1545 - accuracy: 0.9459 - val_loss: 0.1536 - val_accuracy: 0.9293\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.1568 - accuracy: 0.9372 - val_loss: 0.1418 - val_accuracy: 0.9495\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1292 - accuracy: 0.9632 - val_loss: 0.1316 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1362 - accuracy: 0.9459 - val_loss: 0.1379 - val_accuracy: 0.9343\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1382 - accuracy: 0.9524 - val_loss: 0.1433 - val_accuracy: 0.9495\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.1295 - accuracy: 0.9545 - val_loss: 0.1452 - val_accuracy: 0.9343\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1901 - accuracy: 0.9221 - val_loss: 0.1468 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.1616 - accuracy: 0.9286 - val_loss: 0.1773 - val_accuracy: 0.9293\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1846 - accuracy: 0.9264 - val_loss: 0.2184 - val_accuracy: 0.9091\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1908 - accuracy: 0.9286 - val_loss: 0.1362 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1615 - accuracy: 0.9264 - val_loss: 0.1355 - val_accuracy: 0.9495\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1543 - accuracy: 0.9502 - val_loss: 0.1228 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.1562 - accuracy: 0.9372 - val_loss: 0.2522 - val_accuracy: 0.9242\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1851 - accuracy: 0.9199 - val_loss: 0.1481 - val_accuracy: 0.9192\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1601 - accuracy: 0.9351 - val_loss: 0.1125 - val_accuracy: 0.9596\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1328 - accuracy: 0.9502 - val_loss: 0.1428 - val_accuracy: 0.9293\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 167us/step - loss: 0.1385 - accuracy: 0.9502 - val_loss: 0.1951 - val_accuracy: 0.9192\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.1514 - accuracy: 0.9437 - val_loss: 0.1359 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a83c400>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 156us/step\n",
      "over-sampling test accuracy: 93.43%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 2, 2, 1, 0, 0, 2, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 1,\n",
       "       0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 0, 2, 1, 1, 0,\n",
       "       0, 2, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 1,\n",
       "       0, 2, 0, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa26     0     0\n",
       "1         NRS109     2     2\n",
       "2         NRS112     0     0\n",
       "3         NRS216     1     1\n",
       "4         NRS021     0     0\n",
       "..           ...   ...   ...\n",
       "193  CFBREBSa133     0     0\n",
       "194       NRS209     2     2\n",
       "195       NRS109     2     2\n",
       "196       NRS209     2     2\n",
       "197       NRS035     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.236406e-01</td>\n",
       "      <td>0.376359</td>\n",
       "      <td>3.521993e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.026161e-03</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>9.774740e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.819342e-01</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>3.455183e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.183586e-02</td>\n",
       "      <td>0.916974</td>\n",
       "      <td>1.189723e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.957193e-01</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>9.797663e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9.202144e-01</td>\n",
       "      <td>0.062758</td>\n",
       "      <td>1.702757e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8.530889e-11</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>9.999461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.026157e-03</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>9.774740e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>8.530889e-11</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>9.999461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>4.179381e-03</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>7.187761e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    6.236406e-01  0.376359  3.521993e-07\n",
       "1    7.026161e-03  0.015500  9.774740e-01\n",
       "2    9.819342e-01  0.018031  3.455183e-05\n",
       "3    8.183586e-02  0.916974  1.189723e-03\n",
       "4    9.957193e-01  0.004281  9.797663e-12\n",
       "..            ...       ...           ...\n",
       "193  9.202144e-01  0.062758  1.702757e-02\n",
       "194  8.530889e-11  0.000054  9.999461e-01\n",
       "195  7.026157e-03  0.015500  9.774740e-01\n",
       "196  8.530889e-11  0.000054  9.999461e-01\n",
       "197  4.179381e-03  0.995102  7.187761e-04\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1300 - accuracy: 0.9416 - val_loss: 0.1505 - val_accuracy: 0.9444\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1266 - accuracy: 0.9545 - val_loss: 0.1290 - val_accuracy: 0.9394\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.1517 - accuracy: 0.9351 - val_loss: 0.1825 - val_accuracy: 0.9141\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.1369 - accuracy: 0.9459 - val_loss: 0.1369 - val_accuracy: 0.9444\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1405 - accuracy: 0.9372 - val_loss: 0.1762 - val_accuracy: 0.9394\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1478 - accuracy: 0.9394 - val_loss: 0.1323 - val_accuracy: 0.9343\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1293 - accuracy: 0.9545 - val_loss: 0.1234 - val_accuracy: 0.9293\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.1453 - accuracy: 0.9329 - val_loss: 0.1375 - val_accuracy: 0.9343\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.1340 - accuracy: 0.9502 - val_loss: 0.1301 - val_accuracy: 0.9394\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.1224 - accuracy: 0.9567 - val_loss: 0.1322 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1239 - accuracy: 0.9589 - val_loss: 0.1552 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.1337 - accuracy: 0.9567 - val_loss: 0.1307 - val_accuracy: 0.9343\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.1372 - accuracy: 0.9437 - val_loss: 0.1250 - val_accuracy: 0.9394\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.1310 - accuracy: 0.9416 - val_loss: 0.1402 - val_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1371 - accuracy: 0.9502 - val_loss: 0.1280 - val_accuracy: 0.9394\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1198 - accuracy: 0.9545 - val_loss: 0.1655 - val_accuracy: 0.9192\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.1322 - accuracy: 0.9372 - val_loss: 0.1201 - val_accuracy: 0.9394\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 627us/step - loss: 0.1218 - accuracy: 0.9610 - val_loss: 0.1444 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1182 - accuracy: 0.9589 - val_loss: 0.1239 - val_accuracy: 0.9394\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.1197 - accuracy: 0.9589 - val_loss: 0.1299 - val_accuracy: 0.9343\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.1272 - accuracy: 0.9459 - val_loss: 0.1483 - val_accuracy: 0.9495\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.1199 - accuracy: 0.9610 - val_loss: 0.1411 - val_accuracy: 0.9394\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.1287 - accuracy: 0.9502 - val_loss: 0.1449 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1444 - accuracy: 0.9416 - val_loss: 0.1662 - val_accuracy: 0.9343\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.1236 - accuracy: 0.9589 - val_loss: 0.1245 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.1226 - accuracy: 0.9394 - val_loss: 0.1211 - val_accuracy: 0.9495\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1359 - accuracy: 0.9502 - val_loss: 0.1655 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.1082 - accuracy: 0.9545 - val_loss: 0.1647 - val_accuracy: 0.9495\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1363 - accuracy: 0.9459 - val_loss: 0.1396 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.1243 - accuracy: 0.9545 - val_loss: 0.1999 - val_accuracy: 0.9192\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.1229 - accuracy: 0.9394 - val_loss: 0.1827 - val_accuracy: 0.9394\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.1280 - accuracy: 0.9459 - val_loss: 0.2075 - val_accuracy: 0.9192\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.1317 - accuracy: 0.9481 - val_loss: 0.1586 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.1498 - accuracy: 0.9286 - val_loss: 0.1715 - val_accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.1654 - accuracy: 0.9199 - val_loss: 0.1579 - val_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.1946 - accuracy: 0.9113 - val_loss: 0.1565 - val_accuracy: 0.9192\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.1253 - accuracy: 0.9545 - val_loss: 0.1665 - val_accuracy: 0.9394\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.1191 - accuracy: 0.9351 - val_loss: 0.1653 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.1310 - accuracy: 0.9437 - val_loss: 0.1832 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.1207 - accuracy: 0.9502 - val_loss: 0.1902 - val_accuracy: 0.9343\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.1130 - accuracy: 0.9632 - val_loss: 0.1512 - val_accuracy: 0.9394\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.1285 - accuracy: 0.9481 - val_loss: 0.1515 - val_accuracy: 0.9242\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1204 - accuracy: 0.9545 - val_loss: 0.1682 - val_accuracy: 0.9343\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.1353 - accuracy: 0.9394 - val_loss: 0.1392 - val_accuracy: 0.9444\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.1144 - accuracy: 0.9481 - val_loss: 0.1460 - val_accuracy: 0.9394\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.1155 - accuracy: 0.9459 - val_loss: 0.2156 - val_accuracy: 0.9192\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.1388 - accuracy: 0.9329 - val_loss: 0.1838 - val_accuracy: 0.9495\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1092 - accuracy: 0.9567 - val_loss: 0.1964 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1276 - accuracy: 0.9351 - val_loss: 0.1896 - val_accuracy: 0.9495\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1634 - accuracy: 0.9177 - val_loss: 0.1409 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 0.1557 - accuracy: 0.9351 - val_loss: 0.1448 - val_accuracy: 0.9394\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 0.1165 - accuracy: 0.9524 - val_loss: 0.2632 - val_accuracy: 0.9192\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1456 - accuracy: 0.9199 - val_loss: 0.2438 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1344 - accuracy: 0.9481 - val_loss: 0.1542 - val_accuracy: 0.9242\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.1145 - accuracy: 0.9545 - val_loss: 0.1334 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.1142 - accuracy: 0.9567 - val_loss: 0.1591 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1287 - accuracy: 0.9481 - val_loss: 0.1933 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.1301 - accuracy: 0.9545 - val_loss: 0.1624 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.2237 - val_accuracy: 0.9293\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1182 - accuracy: 0.9610 - val_loss: 0.1541 - val_accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1081 - accuracy: 0.9437 - val_loss: 0.1606 - val_accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 0.1473 - val_accuracy: 0.9394\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.1774 - val_accuracy: 0.9242\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1329 - accuracy: 0.9394 - val_loss: 0.1367 - val_accuracy: 0.9394\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.1107 - accuracy: 0.9632 - val_loss: 0.1716 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1043 - accuracy: 0.9654 - val_loss: 0.1621 - val_accuracy: 0.9394\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 169us/step - loss: 0.1222 - accuracy: 0.9481 - val_loss: 0.1885 - val_accuracy: 0.9444\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.1025 - accuracy: 0.9610 - val_loss: 0.1934 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1094 - accuracy: 0.9524 - val_loss: 0.1829 - val_accuracy: 0.9495\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1262 - accuracy: 0.9524 - val_loss: 0.1495 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.1087 - accuracy: 0.9481 - val_loss: 0.2037 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.1095 - accuracy: 0.9610 - val_loss: 0.1349 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.1218 - accuracy: 0.9416 - val_loss: 0.1580 - val_accuracy: 0.9343\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1173 - accuracy: 0.9567 - val_loss: 0.1493 - val_accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 169us/step - loss: 0.1140 - accuracy: 0.9372 - val_loss: 0.2614 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1410 - accuracy: 0.9372 - val_loss: 0.2120 - val_accuracy: 0.9394\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1154 - accuracy: 0.9545 - val_loss: 0.1961 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.1076 - accuracy: 0.9589 - val_loss: 0.1573 - val_accuracy: 0.9394\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 667us/step - loss: 0.1066 - accuracy: 0.9545 - val_loss: 0.1967 - val_accuracy: 0.9141\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 440us/step - loss: 0.1576 - accuracy: 0.9481 - val_loss: 0.1503 - val_accuracy: 0.9293\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.1225 - accuracy: 0.9567 - val_loss: 0.1789 - val_accuracy: 0.9192\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.1304 - accuracy: 0.9545 - val_loss: 0.6500 - val_accuracy: 0.8485\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.5325 - accuracy: 0.8788 - val_loss: 0.5791 - val_accuracy: 0.8788\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.2593 - accuracy: 0.9286 - val_loss: 0.2401 - val_accuracy: 0.8990\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.1404 - accuracy: 0.9329 - val_loss: 0.2238 - val_accuracy: 0.9293\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.1285 - accuracy: 0.9372 - val_loss: 0.1569 - val_accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.1220 - accuracy: 0.9567 - val_loss: 0.1747 - val_accuracy: 0.9343\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.1110 - accuracy: 0.9632 - val_loss: 0.2029 - val_accuracy: 0.9394\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 583us/step - loss: 0.1477 - accuracy: 0.9372 - val_loss: 0.2434 - val_accuracy: 0.9293\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.1796 - accuracy: 0.9394 - val_loss: 0.2144 - val_accuracy: 0.9192\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 486us/step - loss: 0.1621 - accuracy: 0.9329 - val_loss: 0.2600 - val_accuracy: 0.9394\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.1293 - accuracy: 0.9437 - val_loss: 0.2241 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.1167 - accuracy: 0.9567 - val_loss: 0.1533 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 0.1032 - accuracy: 0.9654 - val_loss: 0.1738 - val_accuracy: 0.9394\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.1075 - accuracy: 0.9545 - val_loss: 0.1505 - val_accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.1073 - accuracy: 0.9632 - val_loss: 0.1807 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.1089 - accuracy: 0.9524 - val_loss: 0.2018 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 0.1000 - accuracy: 0.9589 - val_loss: 0.1608 - val_accuracy: 0.9343\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 0.1034 - accuracy: 0.9610 - val_loss: 0.1814 - val_accuracy: 0.9495\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 353us/step - loss: 0.1018 - accuracy: 0.9524 - val_loss: 0.1922 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 94.75%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [9.81934200e-01, 1.80312170e-02, 3.45518350e-05],\n",
       "       [8.18358600e-02, 9.16974370e-01, 1.18972260e-03],\n",
       "       [9.95719250e-01, 4.28071400e-03, 9.79766300e-12],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [9.95745360e-01, 4.25468200e-03, 3.33418980e-09],\n",
       "       [3.68795430e-03, 9.95647600e-01, 6.64382800e-04],\n",
       "       [9.95719250e-01, 4.28071400e-03, 9.79766300e-12],\n",
       "       [3.01927700e-02, 9.69804940e-01, 2.32754590e-06],\n",
       "       [2.35658030e-02, 8.74257900e-01, 1.02176210e-01],\n",
       "       [9.99265250e-01, 7.34733530e-04, 1.14765090e-12],\n",
       "       [7.49473130e-03, 9.92497740e-01, 7.49180440e-06],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [1.06678610e-03, 9.98655800e-01, 2.77400660e-04],\n",
       "       [3.82645130e-01, 6.17287200e-01, 6.75963000e-05],\n",
       "       [3.75259500e-04, 9.99624250e-01, 4.18709420e-07],\n",
       "       [9.99988560e-01, 1.14167680e-05, 1.16551720e-13],\n",
       "       [1.00000000e+00, 1.93192450e-21, 2.82118400e-12],\n",
       "       [1.90452780e-03, 9.97996400e-01, 9.91575500e-05],\n",
       "       [2.20542550e-02, 9.77921900e-01, 2.39308600e-05],\n",
       "       [9.34102460e-02, 9.06585930e-01, 3.78050050e-06],\n",
       "       [6.28211000e-01, 3.71786530e-01, 2.49656250e-06],\n",
       "       [5.70197900e-03, 9.41765670e-01, 5.25324270e-02],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [3.57193780e-03, 9.96427600e-01, 5.17027500e-07],\n",
       "       [9.97787830e-01, 2.21217030e-03, 4.38735600e-12],\n",
       "       [9.76811470e-01, 2.31854560e-02, 3.00671670e-06],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [3.82645130e-01, 6.17287200e-01, 6.75963000e-05],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [1.86855800e-01, 8.13140330e-01, 3.83866060e-06],\n",
       "       [9.99866960e-01, 1.32962400e-04, 1.54117400e-09],\n",
       "       [5.67384100e-03, 9.94144860e-01, 1.81354380e-04],\n",
       "       [8.62565500e-05, 9.99913450e-01, 2.25301380e-07],\n",
       "       [6.28211000e-01, 3.71786530e-01, 2.49656250e-06],\n",
       "       [9.99265250e-01, 7.34733530e-04, 1.14765090e-12],\n",
       "       [9.99971030e-01, 2.89671020e-05, 2.03530630e-13],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [8.47092330e-01, 1.52907430e-01, 1.55202070e-07],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [1.15125800e-03, 9.98848700e-01, 5.89290800e-09],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [3.51060000e-04, 9.99593100e-01, 5.59295950e-05],\n",
       "       [6.28211000e-01, 3.71786530e-01, 2.49656250e-06],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [9.99968650e-01, 3.12929440e-05, 2.93820130e-12],\n",
       "       [9.99851200e-01, 1.48767110e-04, 6.30186920e-09],\n",
       "       [4.30826800e-01, 5.69173200e-01, 2.83898420e-09],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [8.39325370e-01, 1.60674400e-01, 1.56393870e-07],\n",
       "       [9.83585500e-01, 1.63787850e-02, 3.57699600e-05],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [6.20613100e-01, 3.79386540e-01, 3.61898880e-07],\n",
       "       [7.49473130e-03, 9.92497740e-01, 7.49180440e-06],\n",
       "       [9.84900500e-01, 1.50994010e-02, 1.55051440e-07],\n",
       "       [8.88416800e-04, 9.99108730e-01, 2.87628430e-06],\n",
       "       [9.99910350e-01, 7.59397000e-05, 1.36754630e-05],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [3.82645130e-01, 6.17287200e-01, 6.75963000e-05],\n",
       "       [8.95893450e-01, 1.04099266e-01, 7.26963030e-06],\n",
       "       [5.70197900e-03, 9.41765670e-01, 5.25324270e-02],\n",
       "       [3.01927700e-02, 9.69804940e-01, 2.32754590e-06],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [8.62565500e-05, 9.99913450e-01, 2.25301380e-07],\n",
       "       [1.86855800e-01, 8.13140330e-01, 3.83866060e-06],\n",
       "       [3.75259500e-04, 9.99624250e-01, 4.18709420e-07],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [3.82645130e-01, 6.17287200e-01, 6.75963000e-05],\n",
       "       [2.24497400e-02, 9.77525900e-01, 2.44113800e-05],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [9.31298500e-01, 6.87015000e-02, 1.92777070e-10],\n",
       "       [9.94970140e-01, 5.02991540e-03, 1.14095880e-11],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [2.26359050e-02, 9.77362600e-01, 1.52492690e-06],\n",
       "       [8.88416800e-04, 9.99108730e-01, 2.87628430e-06],\n",
       "       [9.92685100e-01, 6.53665840e-03, 7.78148940e-04],\n",
       "       [7.91050430e-01, 2.08949420e-01, 1.91444030e-07],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [7.03576270e-01, 2.96423520e-01, 2.91519230e-07],\n",
       "       [1.00000000e+00, 6.94898100e-22, 1.88201130e-12],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [2.24497400e-02, 9.77525900e-01, 2.44113800e-05],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [5.67384100e-03, 9.94144860e-01, 1.81354380e-04],\n",
       "       [5.67384100e-03, 9.94144860e-01, 1.81354380e-04],\n",
       "       [7.49473130e-03, 9.92497740e-01, 7.49180440e-06],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [9.99486100e-01, 5.13422070e-04, 4.87753400e-07],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [9.63501700e-01, 3.64965540e-02, 1.71896760e-06],\n",
       "       [9.99450740e-01, 5.49057400e-04, 2.50200300e-07],\n",
       "       [9.88684360e-01, 1.12915380e-02, 2.41952220e-05],\n",
       "       [9.99956600e-01, 3.34177700e-05, 9.98953200e-06],\n",
       "       [7.70574330e-01, 2.29425490e-01, 2.22768660e-07],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [5.67384100e-03, 9.94144860e-01, 1.81354380e-04],\n",
       "       [1.06678610e-03, 9.98655800e-01, 2.77400660e-04],\n",
       "       [9.97787830e-01, 2.21217030e-03, 4.38735600e-12],\n",
       "       [7.58008700e-01, 2.41966930e-01, 2.43872000e-05],\n",
       "       [8.83983200e-01, 1.16016640e-01, 2.57741900e-07],\n",
       "       [3.53240520e-03, 9.93627400e-01, 2.84024230e-03],\n",
       "       [9.99851200e-01, 1.48767110e-04, 6.30186920e-09],\n",
       "       [9.66559000e-03, 9.90317700e-01, 1.65913970e-05],\n",
       "       [9.99642970e-01, 3.57047900e-04, 3.01863800e-09],\n",
       "       [7.49473130e-03, 9.92497740e-01, 7.49180440e-06],\n",
       "       [9.66559000e-03, 9.90317700e-01, 1.65913970e-05],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [1.86855800e-01, 8.13140330e-01, 3.83866060e-06],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [7.49473130e-03, 9.92497740e-01, 7.49180440e-06],\n",
       "       [2.34299970e-01, 7.65699400e-01, 6.01018000e-07],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [9.97787830e-01, 2.21217030e-03, 4.38735600e-12],\n",
       "       [1.00000000e+00, 4.80993100e-22, 7.90300170e-13],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [1.15125800e-03, 9.98848700e-01, 5.89290800e-09],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [5.70197900e-03, 9.41765670e-01, 5.25324270e-02],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [4.17938460e-03, 9.95101800e-01, 7.18776840e-04],\n",
       "       [7.49117500e-01, 2.50882270e-01, 2.35543610e-07],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [9.96612370e-01, 3.38766420e-03, 4.29022570e-10],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [9.74112500e-01, 2.58874260e-02, 5.17839240e-11],\n",
       "       [9.98706000e-01, 1.29336900e-03, 6.38521560e-07],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [8.63129800e-01, 1.36869980e-01, 1.67235330e-07],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [2.54970520e-01, 7.45028700e-01, 7.89519100e-07],\n",
       "       [9.99265250e-01, 7.34733530e-04, 1.14765090e-12],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [9.95719250e-01, 4.28071400e-03, 9.79766300e-12],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [3.68795430e-03, 9.95647600e-01, 6.64382800e-04],\n",
       "       [9.99786100e-01, 2.13984250e-04, 2.37885200e-09],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [5.96130640e-03, 9.63985700e-01, 3.00530940e-02],\n",
       "       [8.18358600e-02, 9.16974370e-01, 1.18972260e-03],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [9.55018900e-01, 4.49803200e-02, 7.71569260e-07],\n",
       "       [9.66559000e-03, 9.90317700e-01, 1.65913970e-05],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [3.53240520e-03, 9.93627400e-01, 2.84024230e-03],\n",
       "       [2.60903060e-01, 7.39065770e-01, 3.11783950e-05],\n",
       "       [8.53088900e-11, 5.39119760e-05, 9.99946100e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [2.35658030e-02, 8.74257900e-01, 1.02176210e-01],\n",
       "       [7.02616060e-03, 1.54997570e-02, 9.77474030e-01],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [1.23700260e-03, 9.98757100e-01, 5.80205320e-06],\n",
       "       [5.06444300e-01, 4.93555220e-01, 5.33692860e-07],\n",
       "       [3.57193780e-03, 9.96427600e-01, 5.17027500e-07],\n",
       "       [5.67384100e-03, 9.94144860e-01, 1.81354380e-04],\n",
       "       [1.86855800e-01, 8.13140330e-01, 3.83866060e-06],\n",
       "       [6.23640600e-01, 3.76359050e-01, 3.52199320e-07],\n",
       "       [1.90452780e-03, 9.97996400e-01, 9.91575500e-05],\n",
       "       [1.90452780e-03, 9.97996400e-01, 9.91575500e-05],\n",
       "       [3.53240520e-03, 9.93627400e-01, 2.84024230e-03],\n",
       "       [2.26359050e-02, 9.77362600e-01, 1.52492690e-06],\n",
       "       [8.56424870e-01, 1.43574940e-01, 1.55170270e-07],\n",
       "       [2.26359050e-02, 9.77362600e-01, 1.52492690e-06],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [3.38684830e-01, 6.61313600e-01, 1.60703090e-06],\n",
       "       [6.01573000e-05, 2.72155160e-03, 9.97218250e-01],\n",
       "       [5.70197900e-03, 9.41765670e-01, 5.25324270e-02],\n",
       "       [6.01572430e-05, 2.72154880e-03, 9.97218250e-01],\n",
       "       [9.20214350e-01, 6.27581000e-02, 1.70275660e-02],\n",
       "       [8.53088900e-11, 5.39119250e-05, 9.99946100e-01],\n",
       "       [7.02615700e-03, 1.54997490e-02, 9.77474030e-01],\n",
       "       [8.53088900e-11, 5.39119250e-05, 9.99946100e-01],\n",
       "       [4.17938100e-03, 9.95101800e-01, 7.18776140e-04]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933807774716866"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933807774716866"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS109     2\n",
       "1     NRS109     2\n",
       "2     NRS222     0\n",
       "3     NRS109     2\n",
       "4    GA50245     0\n",
       "..       ...   ...\n",
       "193   NRS148     2\n",
       "194   NRS266     1\n",
       "195   NRS109     2\n",
       "196   NRS149     0\n",
       "197   NRS109     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 467us/step - loss: 1.1895 - accuracy: 0.5714 - val_loss: 0.7791 - val_accuracy: 0.6212\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.5415 - accuracy: 0.7511 - val_loss: 0.5956 - val_accuracy: 0.7778\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.5255 - accuracy: 0.8030 - val_loss: 0.5287 - val_accuracy: 0.7879\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.4545 - val_accuracy: 0.8030\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.3567 - accuracy: 0.8550 - val_loss: 0.4191 - val_accuracy: 0.8081\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.3453 - accuracy: 0.8745 - val_loss: 0.4101 - val_accuracy: 0.8535\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.3158 - accuracy: 0.8810 - val_loss: 0.4041 - val_accuracy: 0.8384\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.3093 - accuracy: 0.8788 - val_loss: 0.3929 - val_accuracy: 0.8434\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.2888 - accuracy: 0.8896 - val_loss: 0.3781 - val_accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.3009 - accuracy: 0.8961 - val_loss: 0.4446 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.3041 - accuracy: 0.9026 - val_loss: 0.3287 - val_accuracy: 0.8737\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.2710 - accuracy: 0.9134 - val_loss: 0.3719 - val_accuracy: 0.8586\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.2700 - accuracy: 0.9069 - val_loss: 0.3428 - val_accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.3024 - accuracy: 0.8766 - val_loss: 0.3696 - val_accuracy: 0.8788\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.2613 - accuracy: 0.9199 - val_loss: 0.3460 - val_accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.2455 - accuracy: 0.9156 - val_loss: 0.3468 - val_accuracy: 0.9091\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.2717 - accuracy: 0.8831 - val_loss: 0.3103 - val_accuracy: 0.8889\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.2338 - accuracy: 0.9113 - val_loss: 0.3683 - val_accuracy: 0.8384\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.2429 - accuracy: 0.9026 - val_loss: 0.3088 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 513us/step - loss: 0.2138 - accuracy: 0.9264 - val_loss: 0.2807 - val_accuracy: 0.8737\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.2199 - accuracy: 0.9134 - val_loss: 0.2959 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 0.2172 - accuracy: 0.9199 - val_loss: 0.3329 - val_accuracy: 0.8737\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.2051 - accuracy: 0.9329 - val_loss: 0.2686 - val_accuracy: 0.9242\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.1957 - accuracy: 0.9351 - val_loss: 0.2453 - val_accuracy: 0.8990\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.1948 - accuracy: 0.9437 - val_loss: 0.3142 - val_accuracy: 0.8788\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.1900 - accuracy: 0.9307 - val_loss: 0.2626 - val_accuracy: 0.9040\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 163us/step - loss: 0.1909 - accuracy: 0.9307 - val_loss: 0.2630 - val_accuracy: 0.9040\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.2068 - accuracy: 0.9286 - val_loss: 0.2876 - val_accuracy: 0.8737\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 0.1963 - accuracy: 0.9177 - val_loss: 0.3182 - val_accuracy: 0.8586\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.1793 - accuracy: 0.9286 - val_loss: 0.2614 - val_accuracy: 0.9141\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.1856 - accuracy: 0.9372 - val_loss: 0.2911 - val_accuracy: 0.8939\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1691 - accuracy: 0.9502 - val_loss: 0.2315 - val_accuracy: 0.9141\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1666 - accuracy: 0.9286 - val_loss: 0.2848 - val_accuracy: 0.8939\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 526us/step - loss: 0.1769 - accuracy: 0.9481 - val_loss: 0.2740 - val_accuracy: 0.8838\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.1780 - accuracy: 0.9481 - val_loss: 0.2572 - val_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.1648 - accuracy: 0.9437 - val_loss: 0.2942 - val_accuracy: 0.8737\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.1598 - accuracy: 0.9502 - val_loss: 0.2818 - val_accuracy: 0.9091\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1556 - accuracy: 0.9524 - val_loss: 0.2158 - val_accuracy: 0.9242\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1474 - accuracy: 0.9545 - val_loss: 0.2643 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.1714 - accuracy: 0.9459 - val_loss: 0.2203 - val_accuracy: 0.9242\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1466 - accuracy: 0.9545 - val_loss: 0.2539 - val_accuracy: 0.9192\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.1506 - accuracy: 0.9481 - val_loss: 0.3483 - val_accuracy: 0.8384\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.1748 - accuracy: 0.9286 - val_loss: 0.2800 - val_accuracy: 0.8990\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 0.1489 - accuracy: 0.9459 - val_loss: 0.3197 - val_accuracy: 0.8687\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.1473 - accuracy: 0.9589 - val_loss: 0.2130 - val_accuracy: 0.9293\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1473 - accuracy: 0.9524 - val_loss: 0.2427 - val_accuracy: 0.9293\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.1475 - accuracy: 0.9545 - val_loss: 0.2198 - val_accuracy: 0.9242\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.1388 - accuracy: 0.9589 - val_loss: 0.2722 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.1602 - accuracy: 0.9394 - val_loss: 0.3020 - val_accuracy: 0.8990\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.1610 - accuracy: 0.9502 - val_loss: 0.2349 - val_accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.1441 - accuracy: 0.9589 - val_loss: 0.2297 - val_accuracy: 0.9343\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 462us/step - loss: 0.1605 - accuracy: 0.9524 - val_loss: 0.2877 - val_accuracy: 0.9040\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1487 - accuracy: 0.9351 - val_loss: 0.2298 - val_accuracy: 0.9242\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1403 - accuracy: 0.9567 - val_loss: 0.2050 - val_accuracy: 0.9293\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1716 - accuracy: 0.9394 - val_loss: 0.2425 - val_accuracy: 0.9141\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.1569 - accuracy: 0.9567 - val_loss: 0.2406 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1478 - accuracy: 0.9610 - val_loss: 0.2455 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1412 - accuracy: 0.9545 - val_loss: 0.1878 - val_accuracy: 0.9242\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.1341 - accuracy: 0.9567 - val_loss: 0.2141 - val_accuracy: 0.9242\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1560 - accuracy: 0.9459 - val_loss: 0.2235 - val_accuracy: 0.9242\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.1176 - accuracy: 0.9589 - val_loss: 0.2111 - val_accuracy: 0.9293\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 413us/step - loss: 0.1489 - accuracy: 0.9394 - val_loss: 0.2589 - val_accuracy: 0.9343\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.1498 - accuracy: 0.9524 - val_loss: 0.2508 - val_accuracy: 0.9192\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.1672 - accuracy: 0.9372 - val_loss: 0.2303 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.1564 - accuracy: 0.9351 - val_loss: 0.2400 - val_accuracy: 0.9242\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1365 - accuracy: 0.9545 - val_loss: 0.2141 - val_accuracy: 0.9293\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.1564 - accuracy: 0.9459 - val_loss: 0.2031 - val_accuracy: 0.9192\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.1268 - accuracy: 0.9545 - val_loss: 0.2014 - val_accuracy: 0.9242\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.1263 - accuracy: 0.9610 - val_loss: 0.2112 - val_accuracy: 0.9343\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.1910 - accuracy: 0.9134 - val_loss: 0.2388 - val_accuracy: 0.9293\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.2141 - val_accuracy: 0.9141\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1498 - accuracy: 0.9286 - val_loss: 0.2317 - val_accuracy: 0.9192\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.1372 - accuracy: 0.9567 - val_loss: 0.1895 - val_accuracy: 0.9394\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.1234 - accuracy: 0.9567 - val_loss: 0.2195 - val_accuracy: 0.9293\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.1389 - accuracy: 0.9524 - val_loss: 0.1895 - val_accuracy: 0.9293\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1293 - accuracy: 0.9589 - val_loss: 0.2533 - val_accuracy: 0.9192\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.1236 - accuracy: 0.9545 - val_loss: 0.1945 - val_accuracy: 0.9343\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.1154 - accuracy: 0.9589 - val_loss: 0.2161 - val_accuracy: 0.9242\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1228 - accuracy: 0.9524 - val_loss: 0.2463 - val_accuracy: 0.9293\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.1256 - accuracy: 0.9567 - val_loss: 0.1936 - val_accuracy: 0.9394\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 162us/step - loss: 0.1168 - accuracy: 0.9545 - val_loss: 0.1972 - val_accuracy: 0.9293\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1197 - accuracy: 0.9545 - val_loss: 0.2152 - val_accuracy: 0.9293\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1361 - accuracy: 0.9567 - val_loss: 0.3230 - val_accuracy: 0.8737\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1552 - accuracy: 0.9351 - val_loss: 0.4149 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1562 - accuracy: 0.9351 - val_loss: 0.2294 - val_accuracy: 0.8990\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1570 - accuracy: 0.9329 - val_loss: 0.2161 - val_accuracy: 0.9192\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.2172 - val_accuracy: 0.9242\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1359 - accuracy: 0.9545 - val_loss: 0.1899 - val_accuracy: 0.9192\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1152 - accuracy: 0.9610 - val_loss: 0.1893 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 147us/step - loss: 0.1190 - accuracy: 0.9502 - val_loss: 0.2135 - val_accuracy: 0.9293\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1116 - accuracy: 0.9654 - val_loss: 0.1861 - val_accuracy: 0.9343\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1346 - accuracy: 0.9437 - val_loss: 0.2125 - val_accuracy: 0.9293\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1259 - accuracy: 0.9524 - val_loss: 0.1867 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1122 - accuracy: 0.9567 - val_loss: 0.2422 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 146us/step - loss: 0.1169 - accuracy: 0.9589 - val_loss: 0.2180 - val_accuracy: 0.9293\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1285 - accuracy: 0.9502 - val_loss: 0.2023 - val_accuracy: 0.9343\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1316 - accuracy: 0.9481 - val_loss: 0.2022 - val_accuracy: 0.9394\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1712 - accuracy: 0.9372 - val_loss: 0.2536 - val_accuracy: 0.9242\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1813 - accuracy: 0.9329 - val_loss: 0.2608 - val_accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.1390 - accuracy: 0.9481 - val_loss: 0.2206 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x635088320>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 152us/step\n",
      "over-sampling test accuracy: 92.93%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 0, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 0, 0, 0, 2, 1,\n",
       "       2, 1, 0, 2, 1, 1, 1, 2, 0, 1, 0, 2, 2, 0, 2, 0, 0, 1, 1, 2, 0, 2,\n",
       "       1, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0,\n",
       "       2, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1,\n",
       "       1, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 0, 2, 1, 0,\n",
       "       0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "       0, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS109     2     2\n",
       "1     NRS109     2     2\n",
       "2     NRS222     0     0\n",
       "3     NRS109     2     2\n",
       "4    GA50245     0     0\n",
       "..       ...   ...   ...\n",
       "193   NRS148     2     2\n",
       "194   NRS266     1     1\n",
       "195   NRS109     2     2\n",
       "196   NRS149     0     0\n",
       "197   NRS109     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>9.670641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>9.670641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951918</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>2.067555e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>9.670641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.940524</td>\n",
       "      <td>0.037246</td>\n",
       "      <td>2.223014e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>9.978700e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.078068e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>9.670641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.717245</td>\n",
       "      <td>0.282755</td>\n",
       "      <td>2.331203e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>9.670641e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.015403  0.017533  9.670641e-01\n",
       "1    0.015403  0.017533  9.670641e-01\n",
       "2    0.951918  0.048061  2.067555e-05\n",
       "3    0.015403  0.017533  9.670641e-01\n",
       "4    0.940524  0.037246  2.223014e-02\n",
       "..        ...       ...           ...\n",
       "193  0.000114  0.002016  9.978700e-01\n",
       "194  0.003898  0.995024  1.078068e-03\n",
       "195  0.015403  0.017533  9.670641e-01\n",
       "196  0.717245  0.282755  2.331203e-10\n",
       "197  0.015403  0.017533  9.670641e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.1215 - accuracy: 0.9545 - val_loss: 0.2041 - val_accuracy: 0.9242\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.1427 - accuracy: 0.9372 - val_loss: 0.2095 - val_accuracy: 0.9293\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.1362 - accuracy: 0.9437 - val_loss: 0.2087 - val_accuracy: 0.9343\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1147 - accuracy: 0.9632 - val_loss: 0.2028 - val_accuracy: 0.9343\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.1134 - accuracy: 0.9654 - val_loss: 0.1875 - val_accuracy: 0.9293\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.1357 - accuracy: 0.9610 - val_loss: 0.1991 - val_accuracy: 0.9343\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.1385 - accuracy: 0.9329 - val_loss: 0.1983 - val_accuracy: 0.9394\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.1255 - accuracy: 0.9567 - val_loss: 0.2307 - val_accuracy: 0.9141\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1231 - accuracy: 0.9610 - val_loss: 0.2094 - val_accuracy: 0.9192\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1255 - accuracy: 0.9437 - val_loss: 0.1993 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.1251 - accuracy: 0.9567 - val_loss: 0.2207 - val_accuracy: 0.9242\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.1477 - accuracy: 0.9242 - val_loss: 0.2583 - val_accuracy: 0.9040\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1334 - accuracy: 0.9481 - val_loss: 0.1984 - val_accuracy: 0.9192\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1139 - accuracy: 0.9632 - val_loss: 0.2114 - val_accuracy: 0.9394\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1112 - accuracy: 0.9654 - val_loss: 0.2066 - val_accuracy: 0.9394\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.1196 - accuracy: 0.9545 - val_loss: 0.2180 - val_accuracy: 0.9242\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.1249 - accuracy: 0.9437 - val_loss: 0.2217 - val_accuracy: 0.9293\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1187 - accuracy: 0.9567 - val_loss: 0.2027 - val_accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1324 - accuracy: 0.9351 - val_loss: 0.2623 - val_accuracy: 0.8788\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1447 - accuracy: 0.9221 - val_loss: 0.2907 - val_accuracy: 0.8687\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.1475 - accuracy: 0.9286 - val_loss: 0.3273 - val_accuracy: 0.8636\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.1220 - accuracy: 0.9502 - val_loss: 0.3158 - val_accuracy: 0.9192\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1312 - accuracy: 0.9589 - val_loss: 0.3780 - val_accuracy: 0.8485\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1602 - accuracy: 0.9264 - val_loss: 0.3442 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 143us/step - loss: 0.1161 - accuracy: 0.9502 - val_loss: 0.2839 - val_accuracy: 0.8838\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1351 - accuracy: 0.9329 - val_loss: 0.3197 - val_accuracy: 0.8687\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.1697 - accuracy: 0.9221 - val_loss: 0.2231 - val_accuracy: 0.9293\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.1409 - accuracy: 0.9372 - val_loss: 0.2179 - val_accuracy: 0.9242\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.1085 - accuracy: 0.9632 - val_loss: 0.1861 - val_accuracy: 0.9394\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.1232 - accuracy: 0.9524 - val_loss: 0.2295 - val_accuracy: 0.9192\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.1309 - accuracy: 0.9437 - val_loss: 0.2104 - val_accuracy: 0.9343\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 167us/step - loss: 0.1034 - accuracy: 0.9654 - val_loss: 0.2070 - val_accuracy: 0.9293\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.2118 - val_accuracy: 0.9394\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.1114 - accuracy: 0.9567 - val_loss: 0.3137 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.1378 - accuracy: 0.9329 - val_loss: 0.2292 - val_accuracy: 0.9192\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1159 - accuracy: 0.9394 - val_loss: 0.2217 - val_accuracy: 0.9242\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 168us/step - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.2025 - val_accuracy: 0.9242\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1291 - accuracy: 0.9459 - val_loss: 0.2528 - val_accuracy: 0.9141\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.1206 - accuracy: 0.9394 - val_loss: 0.2444 - val_accuracy: 0.9293\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.1806 - accuracy: 0.9242 - val_loss: 0.2577 - val_accuracy: 0.8990\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 169us/step - loss: 0.1250 - accuracy: 0.9545 - val_loss: 0.1981 - val_accuracy: 0.9394\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1000 - accuracy: 0.9654 - val_loss: 0.2012 - val_accuracy: 0.9394\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.1042 - accuracy: 0.9610 - val_loss: 0.2116 - val_accuracy: 0.9242\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1104 - accuracy: 0.9610 - val_loss: 0.3086 - val_accuracy: 0.8687\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.1186 - accuracy: 0.9502 - val_loss: 0.2063 - val_accuracy: 0.9394\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.1054 - accuracy: 0.9589 - val_loss: 0.2280 - val_accuracy: 0.9192\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.1158 - accuracy: 0.9459 - val_loss: 0.3148 - val_accuracy: 0.8636\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 163us/step - loss: 0.1254 - accuracy: 0.9545 - val_loss: 0.2509 - val_accuracy: 0.9192\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1295 - accuracy: 0.9372 - val_loss: 0.2643 - val_accuracy: 0.8939\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1238 - accuracy: 0.9524 - val_loss: 0.3028 - val_accuracy: 0.8838\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.1123 - accuracy: 0.9545 - val_loss: 0.2365 - val_accuracy: 0.9293\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.1073 - accuracy: 0.9610 - val_loss: 0.2194 - val_accuracy: 0.9293\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.1092 - accuracy: 0.9610 - val_loss: 0.2088 - val_accuracy: 0.9394\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0973 - accuracy: 0.9632 - val_loss: 0.2322 - val_accuracy: 0.9141\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0967 - accuracy: 0.9632 - val_loss: 0.2064 - val_accuracy: 0.9394\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0979 - accuracy: 0.9654 - val_loss: 0.2374 - val_accuracy: 0.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.0996 - accuracy: 0.9589 - val_loss: 0.2071 - val_accuracy: 0.9343\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1024 - accuracy: 0.9567 - val_loss: 0.2337 - val_accuracy: 0.9192\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1045 - accuracy: 0.9524 - val_loss: 0.1896 - val_accuracy: 0.9394\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1112 - accuracy: 0.9502 - val_loss: 0.2500 - val_accuracy: 0.9343\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1221 - accuracy: 0.9481 - val_loss: 0.2597 - val_accuracy: 0.8990\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1386 - accuracy: 0.9329 - val_loss: 0.2468 - val_accuracy: 0.9242\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1358 - accuracy: 0.9307 - val_loss: 0.2316 - val_accuracy: 0.9293\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1197 - accuracy: 0.9437 - val_loss: 0.1894 - val_accuracy: 0.9394\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.0947 - accuracy: 0.9589 - val_loss: 0.2008 - val_accuracy: 0.9394\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1004 - accuracy: 0.9632 - val_loss: 0.2139 - val_accuracy: 0.9343\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.0982 - accuracy: 0.9589 - val_loss: 0.1912 - val_accuracy: 0.9394\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1254 - accuracy: 0.9394 - val_loss: 0.2256 - val_accuracy: 0.9343\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1251 - accuracy: 0.9524 - val_loss: 0.2714 - val_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 168us/step - loss: 0.1102 - accuracy: 0.9545 - val_loss: 0.2139 - val_accuracy: 0.9293\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1499 - accuracy: 0.9394 - val_loss: 0.4040 - val_accuracy: 0.9242\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.3505 - accuracy: 0.9113 - val_loss: 0.3413 - val_accuracy: 0.9293\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1650 - accuracy: 0.9459 - val_loss: 0.2639 - val_accuracy: 0.9343\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1239 - accuracy: 0.9567 - val_loss: 0.1565 - val_accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.1137 - accuracy: 0.9589 - val_loss: 0.1746 - val_accuracy: 0.9293\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1016 - accuracy: 0.9654 - val_loss: 0.1682 - val_accuracy: 0.9293\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.0986 - accuracy: 0.9524 - val_loss: 0.1512 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1092 - accuracy: 0.9459 - val_loss: 0.1707 - val_accuracy: 0.9343\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 167us/step - loss: 0.1103 - accuracy: 0.9610 - val_loss: 0.1968 - val_accuracy: 0.9343\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.1068 - accuracy: 0.9459 - val_loss: 0.1754 - val_accuracy: 0.9394\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.0944 - accuracy: 0.9589 - val_loss: 0.2031 - val_accuracy: 0.9343\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1161 - accuracy: 0.9481 - val_loss: 0.2029 - val_accuracy: 0.9343\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1191 - accuracy: 0.9437 - val_loss: 0.2187 - val_accuracy: 0.9293\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1138 - accuracy: 0.9459 - val_loss: 0.1806 - val_accuracy: 0.9394\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0938 - accuracy: 0.9632 - val_loss: 0.1951 - val_accuracy: 0.9192\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.1319 - accuracy: 0.9459 - val_loss: 0.1976 - val_accuracy: 0.9293\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.1092 - accuracy: 0.9654 - val_loss: 0.1761 - val_accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0990 - accuracy: 0.9610 - val_loss: 0.1684 - val_accuracy: 0.9293\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0937 - accuracy: 0.9654 - val_loss: 0.2078 - val_accuracy: 0.9293\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1136 - accuracy: 0.9502 - val_loss: 0.1794 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1080 - accuracy: 0.9654 - val_loss: 0.1986 - val_accuracy: 0.9293\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.1068 - accuracy: 0.9589 - val_loss: 0.2067 - val_accuracy: 0.9293\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 418us/step - loss: 0.1092 - accuracy: 0.9524 - val_loss: 0.2214 - val_accuracy: 0.9141\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1140 - accuracy: 0.9502 - val_loss: 0.2293 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.1126 - accuracy: 0.9545 - val_loss: 0.2345 - val_accuracy: 0.8939\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0984 - accuracy: 0.9610 - val_loss: 0.1623 - val_accuracy: 0.9394\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1138 - accuracy: 0.9524 - val_loss: 0.2535 - val_accuracy: 0.8737\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.1250 - accuracy: 0.9394 - val_loss: 0.3084 - val_accuracy: 0.8687\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.1820 - accuracy: 0.9307 - val_loss: 0.3404 - val_accuracy: 0.8687\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.1103 - accuracy: 0.9502 - val_loss: 0.2089 - val_accuracy: 0.9192\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.51918300e-01, 4.80610000e-02, 2.06755470e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.40524100e-01, 3.72458170e-02, 2.22301400e-02],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [7.48730100e-01, 2.51247170e-01, 2.27176600e-05],\n",
       "       [1.59230580e-03, 9.98407660e-01, 6.79445880e-09],\n",
       "       [8.93430350e-01, 1.06569680e-01, 1.12411400e-09],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.98249950e-01, 8.26172200e-04, 9.23807500e-04],\n",
       "       [1.20846760e-04, 9.99879100e-01, 4.67794340e-09],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [2.50108770e-04, 9.65306040e-01, 3.44439370e-02],\n",
       "       [1.58350880e-02, 9.84163050e-01, 1.82845860e-06],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.10075550e-03, 9.98898150e-01, 1.07561440e-06],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [4.44342940e-03, 9.95047570e-01, 5.08960160e-04],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.40524100e-01, 3.72458170e-02, 2.22301400e-02],\n",
       "       [5.64777180e-02, 9.43520200e-01, 1.99665300e-06],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [2.50108770e-04, 9.65306040e-01, 3.44439370e-02],\n",
       "       [2.70281660e-03, 9.97221800e-01, 7.53123700e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.20846760e-04, 9.99879100e-01, 4.67794340e-09],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.10368410e-01, 7.89631600e-01, 3.46352700e-10],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.10174910e-01, 8.89793400e-01, 3.17585250e-05],\n",
       "       [1.01860000e-03, 9.98355700e-01, 6.25641260e-04],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [1.10075550e-03, 9.98898150e-01, 1.07561440e-06],\n",
       "       [9.97281300e-01, 1.23015910e-03, 1.48862040e-03],\n",
       "       [2.00001650e-02, 8.82500470e-01, 9.74993400e-02],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [9.98239040e-01, 1.76093310e-03, 8.13587200e-15],\n",
       "       [9.97700630e-01, 2.28934060e-03, 9.95652600e-06],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [4.51511240e-03, 9.95479940e-01, 4.97917930e-06],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [3.83003530e-01, 6.16996470e-01, 4.39338650e-10],\n",
       "       [9.50102000e-01, 4.98749700e-02, 2.31183440e-05],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [1.16024130e-02, 9.88397540e-01, 1.48081260e-10],\n",
       "       [3.89821900e-03, 9.95023700e-01, 1.07806790e-03],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.46996600e-01, 5.29819540e-02, 2.14560220e-05],\n",
       "       [1.32655900e-03, 9.98608650e-01, 6.49056300e-05],\n",
       "       [9.97303250e-01, 2.69671860e-03, 1.26485190e-08],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [7.48730100e-01, 2.51247170e-01, 2.27176600e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.99858600e-01, 1.12224410e-04, 2.90236550e-05],\n",
       "       [9.90072850e-01, 9.92713500e-03, 4.91368860e-14],\n",
       "       [5.64777180e-02, 9.43520200e-01, 1.99665300e-06],\n",
       "       [8.15133200e-03, 9.91848700e-01, 1.31229010e-08],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [5.80120940e-02, 9.41985600e-01, 2.22556330e-06],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [9.73524000e-01, 2.64760480e-02, 1.30904940e-13],\n",
       "       [9.98027270e-01, 1.97275730e-03, 1.13179315e-08],\n",
       "       [1.23819470e-04, 9.99876000e-01, 1.68633500e-07],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [3.89821900e-03, 9.95023700e-01, 1.07806790e-03],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.78614300e-01, 1.83887130e-02, 2.99700350e-03],\n",
       "       [9.98323600e-01, 1.67637560e-03, 3.25096280e-09],\n",
       "       [1.97219000e-01, 8.02781000e-01, 8.18338600e-11],\n",
       "       [8.16867800e-02, 9.18212830e-01, 1.00364490e-04],\n",
       "       [3.86838350e-02, 9.61207600e-01, 1.08539670e-04],\n",
       "       [9.28214500e-03, 9.61676500e-01, 2.90414200e-02],\n",
       "       [9.98742640e-01, 1.25743830e-03, 1.98193640e-09],\n",
       "       [4.51511240e-03, 9.95479940e-01, 4.97917930e-06],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [5.80120940e-02, 9.41985600e-01, 2.22556330e-06],\n",
       "       [7.51590550e-01, 2.48409440e-01, 1.77555230e-10],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.99595000e-01, 4.05011470e-04, 1.18498980e-15],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.20846760e-04, 9.99879100e-01, 4.67794340e-09],\n",
       "       [1.59230580e-03, 9.98407660e-01, 6.79445880e-09],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [7.02074540e-05, 9.99929800e-01, 2.53930530e-08],\n",
       "       [4.45632040e-01, 5.54368000e-01, 5.12332800e-10],\n",
       "       [7.17252550e-01, 2.82747450e-01, 8.78854200e-10],\n",
       "       [4.44342940e-03, 9.95047570e-01, 5.08960160e-04],\n",
       "       [1.00000000e+00, 1.80910720e-17, 4.01088900e-12],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.20846760e-04, 9.99879100e-01, 4.67794340e-09],\n",
       "       [9.97303600e-01, 2.69635440e-03, 1.01396640e-10],\n",
       "       [2.10368410e-01, 7.89631600e-01, 3.46352700e-10],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.89384230e-01, 1.06158080e-02, 2.82082260e-11],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [3.86838350e-02, 9.61207600e-01, 1.08539670e-04],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [8.71772900e-04, 9.99119460e-01, 8.81504800e-06],\n",
       "       [5.64777180e-02, 9.43520200e-01, 1.99665300e-06],\n",
       "       [7.38715770e-01, 2.61284260e-01, 1.44824440e-09],\n",
       "       [9.28214500e-03, 9.61676500e-01, 2.90414200e-02],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [9.99971300e-01, 2.87063210e-05, 3.91925420e-12],\n",
       "       [6.20597060e-01, 3.79376950e-01, 2.60580220e-05],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.20210660e-01, 7.97892900e-02, 1.09365120e-07],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.37304300e-03, 9.97626960e-01, 1.91910090e-10],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [8.39399100e-03, 9.91533460e-01, 7.26238100e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.23819470e-04, 9.99876000e-01, 1.68633500e-07],\n",
       "       [9.95754000e-01, 4.24599200e-03, 2.58041240e-14],\n",
       "       [4.44342940e-03, 9.95047570e-01, 5.08960160e-04],\n",
       "       [8.39399100e-03, 9.91533460e-01, 7.26238100e-05],\n",
       "       [2.10368410e-01, 7.89631600e-01, 3.46352700e-10],\n",
       "       [1.59230580e-03, 9.98407660e-01, 6.79445880e-09],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [5.92508170e-02, 9.40749200e-01, 5.28592770e-09],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.99999170e-01, 8.81697640e-07, 5.15536400e-13],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.19595700e-01, 8.04043500e-02, 8.77253960e-11],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.62421900e-01, 3.75491270e-02, 2.88937790e-05],\n",
       "       [9.95754000e-01, 4.24599200e-03, 2.58041240e-14],\n",
       "       [1.47860290e-03, 9.98517800e-01, 3.60576540e-06],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [9.97747240e-01, 2.24749300e-03, 5.27155200e-06],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [8.39399100e-03, 9.91533460e-01, 7.26238100e-05],\n",
       "       [8.43003630e-01, 1.56996280e-01, 1.19969580e-07],\n",
       "       [9.94813800e-01, 5.18625040e-03, 3.01183880e-14],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [7.02074540e-05, 9.99929800e-01, 2.53930530e-08],\n",
       "       [9.28214500e-03, 9.61676500e-01, 2.90414200e-02],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [2.50108770e-04, 9.65306040e-01, 3.44439370e-02],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [1.22420200e-02, 9.86332500e-01, 1.42545610e-03],\n",
       "       [5.37492200e-01, 4.62507780e-01, 3.62333800e-09],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [7.48730100e-01, 2.51247170e-01, 2.27176600e-05],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.00001650e-02, 8.82500470e-01, 9.74993400e-02],\n",
       "       [8.39399100e-03, 9.91533460e-01, 7.26238100e-05],\n",
       "       [1.23819470e-04, 9.99876000e-01, 1.68633500e-07],\n",
       "       [2.40822260e-06, 1.66191220e-04, 9.99831300e-01],\n",
       "       [1.00414440e-01, 8.99554250e-01, 3.13209200e-05],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [9.94464200e-01, 5.53574970e-03, 3.17699870e-14],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [2.76879520e-01, 7.23120450e-01, 1.73949670e-11],\n",
       "       [3.86838350e-02, 9.61207600e-01, 1.08539670e-04],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [2.02768970e-01, 7.97231000e-01, 8.48579300e-10],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [5.19184800e-01, 4.80815200e-01, 2.47268800e-10],\n",
       "       [9.99987500e-01, 1.24594660e-05, 1.53998880e-11],\n",
       "       [9.94813800e-01, 5.18625040e-03, 3.01183880e-14],\n",
       "       [1.00000000e+00, 1.47649130e-13, 3.67697260e-15],\n",
       "       [9.99998700e-01, 1.36488980e-06, 1.04664480e-12],\n",
       "       [8.15133200e-03, 9.91848700e-01, 1.31229010e-08],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [1.54025920e-02, 1.75332740e-02, 9.67064100e-01],\n",
       "       [9.28214500e-03, 9.61676500e-01, 2.90414200e-02],\n",
       "       [2.39579660e-01, 7.60420000e-01, 2.47109850e-07],\n",
       "       [1.14487540e-04, 2.01551520e-03, 9.97869970e-01],\n",
       "       [3.89821900e-03, 9.95023700e-01, 1.07806840e-03],\n",
       "       [1.54025920e-02, 1.75332930e-02, 9.67064100e-01],\n",
       "       [7.17244500e-01, 2.82755500e-01, 2.33120330e-10],\n",
       "       [1.54025920e-02, 1.75332930e-02, 9.67064100e-01]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9841215182124273"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9841215182124273"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa110     0\n",
       "1    CFBREBSa131     1\n",
       "2         NRS148     2\n",
       "3         NRS169     1\n",
       "4         NRS073     0\n",
       "..           ...   ...\n",
       "193       NRS001     1\n",
       "194       NRS191     0\n",
       "195       NRS207     0\n",
       "196         CA26     0\n",
       "197     CFBRSa48     0\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 420us/step - loss: 8.6511 - accuracy: 0.3528 - val_loss: 3.9484 - val_accuracy: 0.4242\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 2.1768 - accuracy: 0.5346 - val_loss: 1.4929 - val_accuracy: 0.6313\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 1.1277 - accuracy: 0.6710 - val_loss: 1.4202 - val_accuracy: 0.6515\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.7432 - accuracy: 0.7294 - val_loss: 0.8195 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.5267 - accuracy: 0.7900 - val_loss: 0.7175 - val_accuracy: 0.7020\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.4634 - accuracy: 0.7922 - val_loss: 0.5882 - val_accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.4121 - accuracy: 0.8139 - val_loss: 0.4858 - val_accuracy: 0.7828\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.4163 - accuracy: 0.8095 - val_loss: 0.5173 - val_accuracy: 0.7626\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.3906 - accuracy: 0.8203 - val_loss: 0.4916 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.4065 - accuracy: 0.8139 - val_loss: 0.5134 - val_accuracy: 0.7727\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.3843 - accuracy: 0.8377 - val_loss: 0.4686 - val_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.3623 - accuracy: 0.8571 - val_loss: 0.4554 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.3335 - accuracy: 0.8636 - val_loss: 0.4138 - val_accuracy: 0.7929\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.3137 - accuracy: 0.8788 - val_loss: 0.4349 - val_accuracy: 0.7828\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.3309 - accuracy: 0.8636 - val_loss: 0.4003 - val_accuracy: 0.8131\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.3290 - accuracy: 0.8571 - val_loss: 0.4544 - val_accuracy: 0.7626\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 0.3243 - accuracy: 0.8550 - val_loss: 0.4272 - val_accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 462us/step - loss: 0.2912 - accuracy: 0.8961 - val_loss: 0.3806 - val_accuracy: 0.8131\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.2981 - accuracy: 0.8831 - val_loss: 0.3832 - val_accuracy: 0.8485\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.2766 - accuracy: 0.8918 - val_loss: 0.3926 - val_accuracy: 0.8131\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.2889 - accuracy: 0.8874 - val_loss: 0.3690 - val_accuracy: 0.8283\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.2743 - accuracy: 0.8918 - val_loss: 0.3538 - val_accuracy: 0.8535\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.2733 - accuracy: 0.8918 - val_loss: 0.3743 - val_accuracy: 0.8485\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 137us/step - loss: 0.2755 - accuracy: 0.8810 - val_loss: 0.3821 - val_accuracy: 0.8535\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.3147 - accuracy: 0.8571 - val_loss: 0.3793 - val_accuracy: 0.8081\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.2688 - accuracy: 0.8874 - val_loss: 0.3665 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 126us/step - loss: 0.2679 - accuracy: 0.8831 - val_loss: 0.3648 - val_accuracy: 0.8535\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.2750 - accuracy: 0.8874 - val_loss: 0.3700 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.2683 - accuracy: 0.9004 - val_loss: 0.3517 - val_accuracy: 0.8535\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.2576 - accuracy: 0.9069 - val_loss: 0.3418 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.2526 - accuracy: 0.8918 - val_loss: 0.3343 - val_accuracy: 0.8586\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.2502 - accuracy: 0.9004 - val_loss: 0.3650 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 124us/step - loss: 0.2578 - accuracy: 0.8918 - val_loss: 0.3382 - val_accuracy: 0.8535\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 125us/step - loss: 0.2538 - accuracy: 0.8983 - val_loss: 0.3190 - val_accuracy: 0.8586\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 139us/step - loss: 0.2648 - accuracy: 0.8810 - val_loss: 0.3575 - val_accuracy: 0.8434\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 129us/step - loss: 0.2655 - accuracy: 0.8766 - val_loss: 0.3510 - val_accuracy: 0.8636\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 137us/step - loss: 0.2586 - accuracy: 0.8874 - val_loss: 0.3438 - val_accuracy: 0.8535\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 0.2399 - accuracy: 0.9069 - val_loss: 0.3014 - val_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.2421 - accuracy: 0.9026 - val_loss: 0.3031 - val_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.2335 - accuracy: 0.9091 - val_loss: 0.3169 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 133us/step - loss: 0.2400 - accuracy: 0.8874 - val_loss: 0.2849 - val_accuracy: 0.8586\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 126us/step - loss: 0.2342 - accuracy: 0.9004 - val_loss: 0.2966 - val_accuracy: 0.8788\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 124us/step - loss: 0.2364 - accuracy: 0.9091 - val_loss: 0.2927 - val_accuracy: 0.8636\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 146us/step - loss: 0.2357 - accuracy: 0.8939 - val_loss: 0.2911 - val_accuracy: 0.8687\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.2411 - accuracy: 0.8918 - val_loss: 0.3925 - val_accuracy: 0.8030\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.2379 - accuracy: 0.8983 - val_loss: 0.3360 - val_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.2656 - accuracy: 0.8636 - val_loss: 0.2873 - val_accuracy: 0.8737\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.2348 - accuracy: 0.9069 - val_loss: 0.3403 - val_accuracy: 0.8384\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.2267 - accuracy: 0.8810 - val_loss: 0.2785 - val_accuracy: 0.8889\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.2035 - accuracy: 0.9134 - val_loss: 0.2672 - val_accuracy: 0.8687\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.2047 - accuracy: 0.9156 - val_loss: 0.2814 - val_accuracy: 0.8687\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 144us/step - loss: 0.2030 - accuracy: 0.9134 - val_loss: 0.2881 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 124us/step - loss: 0.2328 - accuracy: 0.9134 - val_loss: 0.2811 - val_accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 138us/step - loss: 0.2206 - accuracy: 0.8874 - val_loss: 0.2773 - val_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 136us/step - loss: 0.2148 - accuracy: 0.9091 - val_loss: 0.2702 - val_accuracy: 0.8687\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1972 - accuracy: 0.9221 - val_loss: 0.2676 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1992 - accuracy: 0.9156 - val_loss: 0.2547 - val_accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.2106 - accuracy: 0.9069 - val_loss: 0.2941 - val_accuracy: 0.8687\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 131us/step - loss: 0.2262 - accuracy: 0.9026 - val_loss: 0.3003 - val_accuracy: 0.8737\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.1846 - accuracy: 0.9264 - val_loss: 0.2575 - val_accuracy: 0.9040\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.1951 - accuracy: 0.9242 - val_loss: 0.2837 - val_accuracy: 0.8687\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1975 - accuracy: 0.9026 - val_loss: 0.3095 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 140us/step - loss: 0.1990 - accuracy: 0.9004 - val_loss: 0.2504 - val_accuracy: 0.9192\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 122us/step - loss: 0.1907 - accuracy: 0.9156 - val_loss: 0.2544 - val_accuracy: 0.8737\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 140us/step - loss: 0.2052 - accuracy: 0.9134 - val_loss: 0.2788 - val_accuracy: 0.8687\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 131us/step - loss: 0.1725 - accuracy: 0.9286 - val_loss: 0.2589 - val_accuracy: 0.8737\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1943 - accuracy: 0.9242 - val_loss: 0.2385 - val_accuracy: 0.9343\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.2202 - accuracy: 0.9242 - val_loss: 0.3575 - val_accuracy: 0.8384\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.2062 - accuracy: 0.9004 - val_loss: 0.2421 - val_accuracy: 0.9040\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 137us/step - loss: 0.1714 - accuracy: 0.9459 - val_loss: 0.2467 - val_accuracy: 0.9091\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 144us/step - loss: 0.1773 - accuracy: 0.9394 - val_loss: 0.2310 - val_accuracy: 0.9192\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1706 - accuracy: 0.9416 - val_loss: 0.2569 - val_accuracy: 0.8939\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.1893 - accuracy: 0.9372 - val_loss: 0.2251 - val_accuracy: 0.9293\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.1811 - accuracy: 0.9394 - val_loss: 0.2280 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 163us/step - loss: 0.1722 - accuracy: 0.9286 - val_loss: 0.2725 - val_accuracy: 0.8737\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1789 - accuracy: 0.9307 - val_loss: 0.2260 - val_accuracy: 0.9293\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1668 - accuracy: 0.9416 - val_loss: 0.2256 - val_accuracy: 0.9293\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1653 - accuracy: 0.9372 - val_loss: 0.2333 - val_accuracy: 0.9091\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1687 - accuracy: 0.9351 - val_loss: 0.2210 - val_accuracy: 0.9343\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.1643 - accuracy: 0.9437 - val_loss: 0.2351 - val_accuracy: 0.9040\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.1627 - accuracy: 0.9416 - val_loss: 0.2324 - val_accuracy: 0.9040\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1677 - accuracy: 0.9394 - val_loss: 0.2198 - val_accuracy: 0.9394\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.1651 - accuracy: 0.9459 - val_loss: 0.2262 - val_accuracy: 0.9343\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.1624 - accuracy: 0.9416 - val_loss: 0.2310 - val_accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 143us/step - loss: 0.1600 - accuracy: 0.9459 - val_loss: 0.2453 - val_accuracy: 0.9040\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 133us/step - loss: 0.1618 - accuracy: 0.9437 - val_loss: 0.2300 - val_accuracy: 0.9343\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 127us/step - loss: 0.1676 - accuracy: 0.9351 - val_loss: 0.2167 - val_accuracy: 0.9293\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 124us/step - loss: 0.1726 - accuracy: 0.9329 - val_loss: 0.2413 - val_accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 123us/step - loss: 0.1612 - accuracy: 0.9481 - val_loss: 0.2286 - val_accuracy: 0.9091\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.1554 - accuracy: 0.9481 - val_loss: 0.2192 - val_accuracy: 0.9141\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 122us/step - loss: 0.1560 - accuracy: 0.9481 - val_loss: 0.2122 - val_accuracy: 0.9293\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 127us/step - loss: 0.1561 - accuracy: 0.9437 - val_loss: 0.2251 - val_accuracy: 0.9141\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 123us/step - loss: 0.1528 - accuracy: 0.9524 - val_loss: 0.2114 - val_accuracy: 0.9293\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 122us/step - loss: 0.1616 - accuracy: 0.9437 - val_loss: 0.2268 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 124us/step - loss: 0.1529 - accuracy: 0.9459 - val_loss: 0.2505 - val_accuracy: 0.8990\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1752 - accuracy: 0.9221 - val_loss: 0.2166 - val_accuracy: 0.9343\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 132us/step - loss: 0.1800 - accuracy: 0.9156 - val_loss: 0.2188 - val_accuracy: 0.9192\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 127us/step - loss: 0.1778 - accuracy: 0.9199 - val_loss: 0.2194 - val_accuracy: 0.9242\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.1557 - accuracy: 0.9545 - val_loss: 0.2209 - val_accuracy: 0.9141\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 123us/step - loss: 0.1464 - accuracy: 0.9589 - val_loss: 0.2254 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a391823c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 202us/step\n",
      "over-sampling test accuracy: 91.92%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 2, 0, 2,\n",
       "       1, 1, 0, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 0, 2, 2, 1, 0, 0,\n",
       "       1, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 0,\n",
       "       0, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2,\n",
       "       2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 0, 2, 0, 2, 0, 1,\n",
       "       2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 2, 1, 1, 1, 2,\n",
       "       1, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 0, 2, 0, 1, 2, 0, 1, 0, 1,\n",
       "       1, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa110     0     0\n",
       "1    CFBREBSa131     1     1\n",
       "2         NRS148     2     2\n",
       "3         NRS169     1     1\n",
       "4         NRS073     0     0\n",
       "..           ...   ...   ...\n",
       "193       NRS001     1     0\n",
       "194       NRS191     0     1\n",
       "195       NRS207     0     0\n",
       "196         CA26     0     1\n",
       "197     CFBRSa48     0     0\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980640</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>6.385857e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.115201</td>\n",
       "      <td>0.884799</td>\n",
       "      <td>1.130102e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>9.927697e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035446</td>\n",
       "      <td>0.774842</td>\n",
       "      <td>1.897115e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979925</td>\n",
       "      <td>0.020075</td>\n",
       "      <td>1.663623e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.293403</td>\n",
       "      <td>3.508671e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.455959</td>\n",
       "      <td>0.544038</td>\n",
       "      <td>3.382804e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.894158</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>5.055511e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.431733</td>\n",
       "      <td>0.568267</td>\n",
       "      <td>4.475438e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.920266</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>6.112072e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.980640  0.019360  6.385857e-12\n",
       "1    0.115201  0.884799  1.130102e-12\n",
       "2    0.000027  0.007203  9.927697e-01\n",
       "3    0.035446  0.774842  1.897115e-01\n",
       "4    0.979925  0.020075  1.663623e-14\n",
       "..        ...       ...           ...\n",
       "193  0.706597  0.293403  3.508671e-09\n",
       "194  0.455959  0.544038  3.382804e-06\n",
       "195  0.894158  0.105841  5.055511e-07\n",
       "196  0.431733  0.568267  4.475438e-10\n",
       "197  0.920266  0.079734  6.112072e-12\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.1601 - accuracy: 0.9329 - val_loss: 0.2085 - val_accuracy: 0.9293\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1619 - accuracy: 0.9416 - val_loss: 0.2004 - val_accuracy: 0.9242\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1440 - accuracy: 0.9459 - val_loss: 0.2279 - val_accuracy: 0.9192\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 132us/step - loss: 0.1451 - accuracy: 0.9481 - val_loss: 0.2119 - val_accuracy: 0.9343\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 126us/step - loss: 0.1441 - accuracy: 0.9502 - val_loss: 0.2158 - val_accuracy: 0.9192\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 146us/step - loss: 0.1693 - accuracy: 0.9307 - val_loss: 0.2632 - val_accuracy: 0.9141\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1661 - accuracy: 0.9286 - val_loss: 0.2318 - val_accuracy: 0.9293\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.1473 - accuracy: 0.9589 - val_loss: 0.2232 - val_accuracy: 0.9192\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1389 - accuracy: 0.9567 - val_loss: 0.2019 - val_accuracy: 0.9293\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 140us/step - loss: 0.1495 - accuracy: 0.9307 - val_loss: 0.2413 - val_accuracy: 0.9091\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 128us/step - loss: 0.1456 - accuracy: 0.9502 - val_loss: 0.2144 - val_accuracy: 0.9343\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 127us/step - loss: 0.1439 - accuracy: 0.9481 - val_loss: 0.2083 - val_accuracy: 0.9293\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.1928 - val_accuracy: 0.9444\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 169us/step - loss: 0.1369 - accuracy: 0.9459 - val_loss: 0.2182 - val_accuracy: 0.9192\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.1333 - accuracy: 0.9589 - val_loss: 0.1971 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 167us/step - loss: 0.1329 - accuracy: 0.9610 - val_loss: 0.2198 - val_accuracy: 0.9192\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1365 - accuracy: 0.9589 - val_loss: 0.2181 - val_accuracy: 0.9192\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.1420 - accuracy: 0.9394 - val_loss: 0.2012 - val_accuracy: 0.9141\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1501 - accuracy: 0.9329 - val_loss: 0.2136 - val_accuracy: 0.9394\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1380 - accuracy: 0.9502 - val_loss: 0.2058 - val_accuracy: 0.9343\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 493us/step - loss: 0.1329 - accuracy: 0.9567 - val_loss: 0.1924 - val_accuracy: 0.9394\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.1302 - accuracy: 0.9589 - val_loss: 0.1939 - val_accuracy: 0.9394\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.2150 - val_accuracy: 0.9343\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1330 - accuracy: 0.9610 - val_loss: 0.2004 - val_accuracy: 0.9394\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1318 - accuracy: 0.9545 - val_loss: 0.1902 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.1516 - accuracy: 0.9524 - val_loss: 0.1979 - val_accuracy: 0.9293\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 450us/step - loss: 0.1298 - accuracy: 0.9567 - val_loss: 0.2004 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.1539 - accuracy: 0.9394 - val_loss: 0.2302 - val_accuracy: 0.9293\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.1552 - accuracy: 0.9437 - val_loss: 0.2516 - val_accuracy: 0.9141\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.1751 - accuracy: 0.9177 - val_loss: 0.2416 - val_accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 0.1621 - accuracy: 0.9394 - val_loss: 0.2833 - val_accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 638us/step - loss: 0.1527 - accuracy: 0.9286 - val_loss: 0.1979 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.1271 - accuracy: 0.9654 - val_loss: 0.2172 - val_accuracy: 0.9343\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.1305 - accuracy: 0.9654 - val_loss: 0.1957 - val_accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.1255 - accuracy: 0.9654 - val_loss: 0.1875 - val_accuracy: 0.9394\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.1296 - accuracy: 0.9632 - val_loss: 0.1884 - val_accuracy: 0.9444\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.1230 - accuracy: 0.9654 - val_loss: 0.2127 - val_accuracy: 0.9192\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.1251 - accuracy: 0.9589 - val_loss: 0.1895 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.1267 - accuracy: 0.9524 - val_loss: 0.2031 - val_accuracy: 0.9343\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.1325 - accuracy: 0.9459 - val_loss: 0.2194 - val_accuracy: 0.9343\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 167us/step - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.2074 - val_accuracy: 0.9343\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.1196 - accuracy: 0.9589 - val_loss: 0.2004 - val_accuracy: 0.9394\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.1223 - accuracy: 0.9632 - val_loss: 0.2139 - val_accuracy: 0.9343\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.1269 - accuracy: 0.9589 - val_loss: 0.1910 - val_accuracy: 0.9394\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 166us/step - loss: 0.1208 - accuracy: 0.9654 - val_loss: 0.1984 - val_accuracy: 0.9242\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 163us/step - loss: 0.1247 - accuracy: 0.9632 - val_loss: 0.1944 - val_accuracy: 0.9394\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.1237 - accuracy: 0.9481 - val_loss: 0.2283 - val_accuracy: 0.9141\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.1204 - accuracy: 0.9632 - val_loss: 0.1902 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1189 - accuracy: 0.9654 - val_loss: 0.2155 - val_accuracy: 0.9192\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.1184 - accuracy: 0.9632 - val_loss: 0.1974 - val_accuracy: 0.9343\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1165 - accuracy: 0.9654 - val_loss: 0.1925 - val_accuracy: 0.9394\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.1184 - accuracy: 0.9589 - val_loss: 0.2155 - val_accuracy: 0.9192\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.1254 - accuracy: 0.9567 - val_loss: 0.1850 - val_accuracy: 0.9293\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.1210 - accuracy: 0.9632 - val_loss: 0.2008 - val_accuracy: 0.9343\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 420us/step - loss: 0.1144 - accuracy: 0.9654 - val_loss: 0.2035 - val_accuracy: 0.9394\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.1167 - accuracy: 0.9675 - val_loss: 0.2254 - val_accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.1609 - accuracy: 0.9091 - val_loss: 0.1922 - val_accuracy: 0.9444\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.1376 - accuracy: 0.9481 - val_loss: 0.1995 - val_accuracy: 0.9394\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1293 - accuracy: 0.9610 - val_loss: 0.1785 - val_accuracy: 0.9293\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1312 - accuracy: 0.9351 - val_loss: 0.2218 - val_accuracy: 0.9091\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.1315 - accuracy: 0.9654 - val_loss: 0.2428 - val_accuracy: 0.8788\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1374 - accuracy: 0.9351 - val_loss: 0.2252 - val_accuracy: 0.9343\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1301 - accuracy: 0.9545 - val_loss: 0.1980 - val_accuracy: 0.9293\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.1394 - accuracy: 0.9459 - val_loss: 0.2087 - val_accuracy: 0.9242\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 140us/step - loss: 0.1345 - accuracy: 0.9481 - val_loss: 0.2559 - val_accuracy: 0.8737\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 136us/step - loss: 0.1635 - accuracy: 0.9264 - val_loss: 0.2438 - val_accuracy: 0.9091\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 146us/step - loss: 0.2008 - accuracy: 0.9048 - val_loss: 0.3097 - val_accuracy: 0.8586\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 159us/step - loss: 0.1266 - accuracy: 0.9481 - val_loss: 0.1981 - val_accuracy: 0.9343\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.1260 - accuracy: 0.9524 - val_loss: 0.1853 - val_accuracy: 0.9394\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1194 - accuracy: 0.9589 - val_loss: 0.2046 - val_accuracy: 0.9343\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 144us/step - loss: 0.1298 - accuracy: 0.9545 - val_loss: 0.1947 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1184 - accuracy: 0.9654 - val_loss: 0.2462 - val_accuracy: 0.9040\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1278 - accuracy: 0.9372 - val_loss: 0.1886 - val_accuracy: 0.9293\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.1188 - accuracy: 0.9502 - val_loss: 0.2205 - val_accuracy: 0.9192\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1099 - accuracy: 0.9610 - val_loss: 0.1796 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.1154 - accuracy: 0.9610 - val_loss: 0.2348 - val_accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1084 - accuracy: 0.9654 - val_loss: 0.2028 - val_accuracy: 0.9343\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 133us/step - loss: 0.1087 - accuracy: 0.9654 - val_loss: 0.1828 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 132us/step - loss: 0.1133 - accuracy: 0.9589 - val_loss: 0.2524 - val_accuracy: 0.8990\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1228 - accuracy: 0.9545 - val_loss: 0.1848 - val_accuracy: 0.9293\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 134us/step - loss: 0.1143 - accuracy: 0.9545 - val_loss: 0.2354 - val_accuracy: 0.9091\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1204 - accuracy: 0.9632 - val_loss: 0.2033 - val_accuracy: 0.9343\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1134 - accuracy: 0.9589 - val_loss: 0.1927 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1076 - accuracy: 0.9632 - val_loss: 0.1846 - val_accuracy: 0.9394\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 144us/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.1871 - val_accuracy: 0.9394\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 146us/step - loss: 0.1178 - accuracy: 0.9502 - val_loss: 0.1889 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 145us/step - loss: 0.1115 - accuracy: 0.9567 - val_loss: 0.2261 - val_accuracy: 0.9192\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 139us/step - loss: 0.1122 - accuracy: 0.9632 - val_loss: 0.1879 - val_accuracy: 0.9394\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 139us/step - loss: 0.1073 - accuracy: 0.9654 - val_loss: 0.1969 - val_accuracy: 0.9343\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.1046 - accuracy: 0.9654 - val_loss: 0.1885 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1071 - accuracy: 0.9654 - val_loss: 0.1831 - val_accuracy: 0.9394\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 143us/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.1911 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 148us/step - loss: 0.1127 - accuracy: 0.9589 - val_loss: 0.1809 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 144us/step - loss: 0.1151 - accuracy: 0.9502 - val_loss: 0.1990 - val_accuracy: 0.9394\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 138us/step - loss: 0.1071 - accuracy: 0.9654 - val_loss: 0.1941 - val_accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.1832 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 136us/step - loss: 0.1031 - accuracy: 0.9675 - val_loss: 0.1966 - val_accuracy: 0.9343\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.1052 - accuracy: 0.9632 - val_loss: 0.1812 - val_accuracy: 0.9495\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 141us/step - loss: 0.1064 - accuracy: 0.9589 - val_loss: 0.1875 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 142us/step - loss: 0.1049 - accuracy: 0.9654 - val_loss: 0.2064 - val_accuracy: 0.9343\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 95.35%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.80639640e-01, 1.93604180e-02, 6.38585670e-12],\n",
       "       [1.15201090e-01, 8.84798800e-01, 1.13010200e-12],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [3.54463200e-02, 7.74842260e-01, 1.89711510e-01],\n",
       "       [9.79925300e-01, 2.00747050e-02, 1.66362250e-14],\n",
       "       [4.21098600e-06, 9.99995800e-01, 3.91039020e-12],\n",
       "       [1.48725420e-03, 9.02751700e-01, 9.57610700e-02],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [4.16497400e-03, 9.95834950e-01, 8.53640360e-08],\n",
       "       [7.07982800e-01, 2.92017280e-01, 3.63820770e-09],\n",
       "       [9.79925300e-01, 2.00747050e-02, 1.66362250e-14],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [1.91200660e-01, 8.08799300e-01, 1.30500880e-08],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [3.33864030e-01, 6.66120500e-01, 1.54581270e-05],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.48909200e-01, 2.51090820e-01, 1.81729330e-08],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [9.86951800e-01, 1.30481550e-02, 1.71883970e-10],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [5.90016300e-01, 4.09983720e-01, 4.39416300e-13],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [1.48725420e-03, 9.02751700e-01, 9.57610700e-02],\n",
       "       [4.31733430e-01, 5.68266500e-01, 4.47543840e-10],\n",
       "       [9.44391800e-01, 5.55914380e-02, 1.67245030e-05],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [4.40248920e-02, 6.29949600e-01, 3.26025580e-01],\n",
       "       [2.02101750e-01, 7.97895670e-01, 2.61299970e-06],\n",
       "       [3.96571250e-01, 6.03428700e-01, 2.11303310e-08],\n",
       "       [2.25294770e-01, 7.74705300e-01, 9.08394470e-10],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [3.31489560e-03, 9.96671900e-01, 1.31560490e-05],\n",
       "       [9.80639640e-01, 1.93604180e-02, 6.38585670e-12],\n",
       "       [8.21631850e-01, 1.78368120e-01, 3.90306800e-11],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [3.71207300e-03, 9.96287940e-01, 7.88871400e-09],\n",
       "       [9.11656860e-01, 8.83431600e-02, 1.34230780e-09],\n",
       "       [9.83508100e-01, 1.64918470e-02, 5.94150200e-08],\n",
       "       [1.84033760e-02, 9.81596650e-01, 5.91079100e-12],\n",
       "       [2.57215020e-03, 9.97406070e-01, 2.17613960e-05],\n",
       "       [6.42218770e-01, 3.57781260e-01, 4.36712180e-09],\n",
       "       [3.54463200e-02, 7.74842260e-01, 1.89711510e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [4.40248920e-02, 6.29949600e-01, 3.26025580e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.09695200e-01, 7.90304800e-01, 6.77462530e-09],\n",
       "       [1.00000000e+00, 8.06795260e-12, 6.54383400e-18],\n",
       "       [8.59968540e-01, 1.40030860e-01, 6.30161940e-07],\n",
       "       [3.17734600e-03, 9.96822600e-01, 1.00291980e-07],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [5.77993700e-02, 9.42200500e-01, 1.15908584e-07],\n",
       "       [3.17734600e-03, 9.96822600e-01, 1.00291980e-07],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [3.58080860e-02, 9.64191850e-01, 4.07230230e-08],\n",
       "       [8.59604800e-01, 1.40394480e-01, 7.26324200e-07],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [7.14946700e-01, 2.85053280e-01, 3.57307450e-09],\n",
       "       [3.07377990e-03, 9.96926250e-01, 2.70996720e-08],\n",
       "       [7.75652400e-02, 9.22434750e-01, 5.24637840e-09],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [1.48725420e-03, 9.02751700e-01, 9.57610700e-02],\n",
       "       [2.25294770e-01, 7.74705300e-01, 9.08394470e-10],\n",
       "       [6.33848370e-01, 3.66151570e-01, 2.99013620e-10],\n",
       "       [2.02158450e-02, 9.79784130e-01, 3.57302740e-08],\n",
       "       [5.31597100e-02, 9.46840300e-01, 5.16353820e-08],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [1.05865315e-01, 8.94134040e-01, 6.40705700e-07],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [4.31733430e-01, 5.68266500e-01, 4.47543840e-10],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.80639640e-01, 1.93604180e-02, 6.38585670e-12],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [7.75652400e-02, 9.22434750e-01, 5.24637840e-09],\n",
       "       [1.00000000e+00, 1.20566690e-11, 4.71838400e-18],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [1.48725420e-03, 9.02751700e-01, 9.57610700e-02],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [4.16497400e-03, 9.95834950e-01, 8.53640360e-08],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [2.57215020e-03, 9.97406070e-01, 2.17613960e-05],\n",
       "       [4.74611430e-01, 5.25388300e-01, 1.67168540e-07],\n",
       "       [8.68446770e-01, 1.31553230e-01, 5.63153800e-13],\n",
       "       [3.54463200e-02, 7.74842260e-01, 1.89711510e-01],\n",
       "       [5.78354820e-02, 9.42161140e-01, 3.33511640e-06],\n",
       "       [9.20266570e-01, 7.97334400e-02, 6.11206140e-12],\n",
       "       [7.97178400e-01, 2.02821630e-01, 2.34400120e-09],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [2.21274100e-03, 9.97787240e-01, 6.57532470e-09],\n",
       "       [3.61117900e-03, 9.96380870e-01, 7.92520600e-06],\n",
       "       [9.87489040e-01, 1.25109910e-02, 1.00107165e-14],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [9.94344600e-01, 5.65545000e-03, 4.26828030e-15],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.83508100e-01, 1.64918470e-02, 5.94150200e-08],\n",
       "       [2.02158450e-02, 9.79784130e-01, 3.57302740e-08],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [9.80639640e-01, 1.93604180e-02, 6.38585670e-12],\n",
       "       [1.63792570e-03, 9.98362100e-01, 3.13942000e-08],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [5.31597100e-02, 9.46840300e-01, 5.16353820e-08],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [1.15201090e-01, 8.84798800e-01, 1.13010200e-12],\n",
       "       [2.61799700e-02, 9.60727750e-01, 1.30922200e-02],\n",
       "       [6.42218770e-01, 3.57781260e-01, 4.36712180e-09],\n",
       "       [6.18581030e-02, 9.38141800e-01, 1.15991890e-07],\n",
       "       [3.54463200e-02, 7.74842260e-01, 1.89711510e-01],\n",
       "       [8.21355200e-02, 9.17863130e-01, 1.35100720e-06],\n",
       "       [9.87489040e-01, 1.25109910e-02, 1.00107165e-14],\n",
       "       [1.00000000e+00, 8.06795260e-12, 6.54383400e-18],\n",
       "       [4.16497400e-03, 9.95834950e-01, 8.53640360e-08],\n",
       "       [9.80639640e-01, 1.93604180e-02, 6.38585670e-12],\n",
       "       [8.73402830e-01, 1.26596660e-01, 5.70688370e-07],\n",
       "       [2.02101750e-01, 7.97895670e-01, 2.61299970e-06],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [1.48725420e-03, 9.02751700e-01, 9.57610700e-02],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [1.75644600e-01, 8.24355100e-01, 3.32605100e-07],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [1.98822820e-04, 9.99801200e-01, 2.03602450e-13],\n",
       "       [3.71207300e-03, 9.96287940e-01, 7.88871400e-09],\n",
       "       [3.07377990e-03, 9.96926250e-01, 2.70996720e-08],\n",
       "       [8.87584500e-01, 1.07557140e-01, 4.85837400e-03],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.61799700e-02, 9.60727750e-01, 1.30922200e-02],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.85010520e-01, 7.14989400e-01, 4.40354100e-10],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.57215020e-03, 9.97406070e-01, 2.17613960e-05],\n",
       "       [5.31597100e-02, 9.46840300e-01, 5.16353820e-08],\n",
       "       [6.18581030e-02, 9.38141800e-01, 1.15991890e-07],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [1.05865315e-01, 8.94134040e-01, 6.40705700e-07],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [1.00000000e+00, 2.17268220e-12, 4.20349650e-23],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [9.99828340e-01, 1.71663520e-04, 2.53369540e-17],\n",
       "       [3.58080860e-02, 9.64191850e-01, 4.07230230e-08],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.02101750e-01, 7.97895670e-01, 2.61299970e-06],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [6.42218770e-01, 3.57781260e-01, 4.36712180e-09],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [9.79925300e-01, 2.00747050e-02, 1.66362250e-14],\n",
       "       [1.05865315e-01, 8.94134040e-01, 6.40705700e-07],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.99985930e-01, 1.40949005e-05, 3.52255100e-18],\n",
       "       [4.44138000e-01, 5.55862000e-01, 8.03377800e-09],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [1.84033760e-02, 9.81596650e-01, 5.91079100e-12],\n",
       "       [3.61117900e-03, 9.96380870e-01, 7.92520600e-06],\n",
       "       [5.78354820e-02, 9.42161140e-01, 3.33511640e-06],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.14538700e-01, 8.54612700e-02, 2.09458050e-09],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [7.32985650e-03, 5.15077300e-02, 9.41162400e-01],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [8.37177100e-01, 1.62822990e-01, 4.43174500e-12],\n",
       "       [7.06596550e-01, 2.93403500e-01, 3.50867710e-09],\n",
       "       [5.78354820e-02, 9.42161140e-01, 3.33511640e-06],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.99566850e-01, 4.33191070e-04, 3.09974380e-10],\n",
       "       [5.78354820e-02, 9.42161140e-01, 3.33511640e-06],\n",
       "       [3.64399000e-07, 2.67896950e-04, 9.99731700e-01],\n",
       "       [9.94344600e-01, 5.65545000e-03, 4.26828030e-15],\n",
       "       [2.73399070e-05, 7.20297600e-03, 9.92769660e-01],\n",
       "       [7.06596600e-01, 2.93403400e-01, 3.50867070e-09],\n",
       "       [7.06596600e-01, 2.93403400e-01, 3.50867070e-09],\n",
       "       [4.55959050e-01, 5.44037500e-01, 3.38280400e-06],\n",
       "       [8.94158070e-01, 1.05841460e-01, 5.05551100e-07],\n",
       "       [4.31733430e-01, 5.68266500e-01, 4.47543840e-10],\n",
       "       [9.20266450e-01, 7.97335060e-02, 6.11207220e-12]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796831955922864"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796831955922864"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS110     1\n",
       "1         NRS216     1\n",
       "2         NRS386     1\n",
       "3       CFBRSa25     0\n",
       "4      BCH-SA-03     1\n",
       "..           ...   ...\n",
       "193       NRS216     1\n",
       "194  CFBREBSa110     0\n",
       "195       NRS148     2\n",
       "196         GA27     0\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 6.8908 - accuracy: 0.4199 - val_loss: 1.0015 - val_accuracy: 0.7525\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 1.0966 - accuracy: 0.7078 - val_loss: 0.9414 - val_accuracy: 0.7071\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.6503 - accuracy: 0.7662 - val_loss: 0.5916 - val_accuracy: 0.7677\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.5627 - accuracy: 0.7749 - val_loss: 0.6464 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.5552 - accuracy: 0.8117 - val_loss: 0.6187 - val_accuracy: 0.6970\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.4605 - accuracy: 0.8117 - val_loss: 0.6237 - val_accuracy: 0.6465\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.4456 - accuracy: 0.7857 - val_loss: 0.5118 - val_accuracy: 0.7677\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.3887 - accuracy: 0.8290 - val_loss: 0.4370 - val_accuracy: 0.8081\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 0.3939 - accuracy: 0.8506 - val_loss: 0.4630 - val_accuracy: 0.7374\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.3619 - accuracy: 0.8485 - val_loss: 0.4125 - val_accuracy: 0.7980\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.3253 - accuracy: 0.8550 - val_loss: 0.4529 - val_accuracy: 0.7626\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.3145 - accuracy: 0.8680 - val_loss: 0.4208 - val_accuracy: 0.7626\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.3209 - accuracy: 0.8723 - val_loss: 0.4013 - val_accuracy: 0.8586\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.3056 - accuracy: 0.8896 - val_loss: 0.3894 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.2838 - accuracy: 0.8853 - val_loss: 0.3940 - val_accuracy: 0.7929\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.2846 - accuracy: 0.8853 - val_loss: 0.3645 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.3003 - accuracy: 0.8853 - val_loss: 0.3473 - val_accuracy: 0.8586\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.2722 - accuracy: 0.9026 - val_loss: 0.4082 - val_accuracy: 0.7677\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.3009 - accuracy: 0.8615 - val_loss: 0.4670 - val_accuracy: 0.7677\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.2744 - accuracy: 0.8874 - val_loss: 0.3423 - val_accuracy: 0.8939\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.2590 - accuracy: 0.9026 - val_loss: 0.3301 - val_accuracy: 0.8687\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.2414 - accuracy: 0.9026 - val_loss: 0.3424 - val_accuracy: 0.8434\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 524us/step - loss: 0.2476 - accuracy: 0.9113 - val_loss: 0.3366 - val_accuracy: 0.8535\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 0.2638 - accuracy: 0.9069 - val_loss: 0.3461 - val_accuracy: 0.8838\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.2690 - accuracy: 0.8918 - val_loss: 0.3242 - val_accuracy: 0.8384\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.2585 - accuracy: 0.8853 - val_loss: 0.3105 - val_accuracy: 0.9040\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 0.2297 - accuracy: 0.9286 - val_loss: 0.3162 - val_accuracy: 0.8838\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.2324 - accuracy: 0.9091 - val_loss: 0.3267 - val_accuracy: 0.8788\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 413us/step - loss: 0.2260 - accuracy: 0.9242 - val_loss: 0.3417 - val_accuracy: 0.8434\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.2264 - accuracy: 0.9134 - val_loss: 0.3082 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 152us/step - loss: 0.2198 - accuracy: 0.9177 - val_loss: 0.3056 - val_accuracy: 0.8788\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.2248 - accuracy: 0.8939 - val_loss: 0.3430 - val_accuracy: 0.8636\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.2058 - accuracy: 0.9372 - val_loss: 0.2880 - val_accuracy: 0.8636\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.2137 - accuracy: 0.9242 - val_loss: 0.2800 - val_accuracy: 0.8838\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 0.1952 - accuracy: 0.9286 - val_loss: 0.3004 - val_accuracy: 0.8636\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.1969 - accuracy: 0.9351 - val_loss: 0.2873 - val_accuracy: 0.8687\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 158us/step - loss: 0.2016 - accuracy: 0.9307 - val_loss: 0.2657 - val_accuracy: 0.8939\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1920 - accuracy: 0.9199 - val_loss: 0.3004 - val_accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.2140 - accuracy: 0.9177 - val_loss: 0.2700 - val_accuracy: 0.9141\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1901 - accuracy: 0.9416 - val_loss: 0.2737 - val_accuracy: 0.9141\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.1911 - accuracy: 0.9242 - val_loss: 0.2628 - val_accuracy: 0.9040\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 154us/step - loss: 0.1884 - accuracy: 0.9416 - val_loss: 0.2737 - val_accuracy: 0.8990\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.1890 - accuracy: 0.9242 - val_loss: 0.2595 - val_accuracy: 0.9293\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 390us/step - loss: 0.1933 - accuracy: 0.9351 - val_loss: 0.2592 - val_accuracy: 0.8939\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1869 - accuracy: 0.9242 - val_loss: 0.2618 - val_accuracy: 0.8939\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 165us/step - loss: 0.1861 - accuracy: 0.9264 - val_loss: 0.2739 - val_accuracy: 0.8737\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.1964 - accuracy: 0.9177 - val_loss: 0.2740 - val_accuracy: 0.8737\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.1910 - accuracy: 0.9221 - val_loss: 0.2734 - val_accuracy: 0.8737\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1814 - accuracy: 0.9351 - val_loss: 0.2595 - val_accuracy: 0.8889\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1741 - accuracy: 0.9459 - val_loss: 0.2587 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.1796 - accuracy: 0.9242 - val_loss: 0.2425 - val_accuracy: 0.9343\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.1708 - accuracy: 0.9394 - val_loss: 0.2502 - val_accuracy: 0.9293\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 164us/step - loss: 0.1696 - accuracy: 0.9416 - val_loss: 0.2543 - val_accuracy: 0.9293\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 156us/step - loss: 0.1687 - accuracy: 0.9394 - val_loss: 0.2391 - val_accuracy: 0.9293\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1679 - accuracy: 0.9394 - val_loss: 0.2357 - val_accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 0.1589 - accuracy: 0.9416 - val_loss: 0.2698 - val_accuracy: 0.8788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.1866 - accuracy: 0.9307 - val_loss: 0.2470 - val_accuracy: 0.9242\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1747 - accuracy: 0.9286 - val_loss: 0.2455 - val_accuracy: 0.9293\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1694 - accuracy: 0.9264 - val_loss: 0.2664 - val_accuracy: 0.8535\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.1627 - accuracy: 0.9221 - val_loss: 0.2699 - val_accuracy: 0.8939\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.1792 - accuracy: 0.9156 - val_loss: 0.2402 - val_accuracy: 0.9343\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1684 - accuracy: 0.9307 - val_loss: 0.2374 - val_accuracy: 0.9343\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.1583 - accuracy: 0.9372 - val_loss: 0.2480 - val_accuracy: 0.9141\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.1548 - accuracy: 0.9372 - val_loss: 0.2639 - val_accuracy: 0.8939\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.1778 - accuracy: 0.9416 - val_loss: 0.2875 - val_accuracy: 0.8636\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1912 - accuracy: 0.9242 - val_loss: 0.2274 - val_accuracy: 0.9343\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.1627 - accuracy: 0.9372 - val_loss: 0.3523 - val_accuracy: 0.8283\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.1837 - accuracy: 0.9091 - val_loss: 0.2365 - val_accuracy: 0.9343\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.1662 - accuracy: 0.9351 - val_loss: 0.3471 - val_accuracy: 0.8384\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.1637 - accuracy: 0.9372 - val_loss: 0.2414 - val_accuracy: 0.9040\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1477 - accuracy: 0.9502 - val_loss: 0.2561 - val_accuracy: 0.8939\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.1501 - accuracy: 0.9394 - val_loss: 0.2456 - val_accuracy: 0.9293\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1585 - accuracy: 0.9459 - val_loss: 0.3076 - val_accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 149us/step - loss: 0.1931 - accuracy: 0.9286 - val_loss: 0.2805 - val_accuracy: 0.8939\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1755 - accuracy: 0.9264 - val_loss: 0.2437 - val_accuracy: 0.8990\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 153us/step - loss: 0.1643 - accuracy: 0.9286 - val_loss: 0.2483 - val_accuracy: 0.9091\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.1603 - accuracy: 0.9329 - val_loss: 0.2461 - val_accuracy: 0.9040\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 155us/step - loss: 0.1858 - accuracy: 0.9113 - val_loss: 0.2291 - val_accuracy: 0.9040\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1494 - accuracy: 0.9481 - val_loss: 0.2349 - val_accuracy: 0.9141\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1453 - accuracy: 0.9502 - val_loss: 0.2667 - val_accuracy: 0.8485\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.1597 - accuracy: 0.9286 - val_loss: 0.2296 - val_accuracy: 0.9293\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.1470 - accuracy: 0.9459 - val_loss: 0.2216 - val_accuracy: 0.9343\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.1627 - accuracy: 0.9199 - val_loss: 0.2486 - val_accuracy: 0.8939\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 169us/step - loss: 0.1750 - accuracy: 0.9199 - val_loss: 0.2580 - val_accuracy: 0.8737\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1469 - accuracy: 0.9437 - val_loss: 0.2220 - val_accuracy: 0.9343\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1427 - accuracy: 0.9481 - val_loss: 0.2272 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.1548 - accuracy: 0.9372 - val_loss: 0.2126 - val_accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.1484 - accuracy: 0.9437 - val_loss: 0.2791 - val_accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.1476 - accuracy: 0.9437 - val_loss: 0.2237 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1357 - accuracy: 0.9481 - val_loss: 0.2102 - val_accuracy: 0.9343\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 161us/step - loss: 0.1406 - accuracy: 0.9394 - val_loss: 0.2444 - val_accuracy: 0.8889\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 150us/step - loss: 0.1331 - accuracy: 0.9459 - val_loss: 0.2202 - val_accuracy: 0.8990\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 151us/step - loss: 0.1450 - accuracy: 0.9416 - val_loss: 0.2093 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 162us/step - loss: 0.1459 - accuracy: 0.9372 - val_loss: 0.2113 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.1471 - accuracy: 0.9481 - val_loss: 0.2289 - val_accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.1738 - accuracy: 0.9307 - val_loss: 0.2911 - val_accuracy: 0.8434\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.1633 - accuracy: 0.9242 - val_loss: 0.2729 - val_accuracy: 0.8535\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.1525 - accuracy: 0.9394 - val_loss: 0.2316 - val_accuracy: 0.9091\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.1392 - accuracy: 0.9372 - val_loss: 0.2877 - val_accuracy: 0.8939\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1570 - accuracy: 0.9351 - val_loss: 0.2176 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3ad65f60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 158us/step\n",
      "over-sampling test accuracy: 92.93%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 2, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 1, 1, 1, 2, 0, 2, 2,\n",
       "       0, 0, 1, 2, 2, 0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 2, 0, 2, 0, 0, 1,\n",
       "       0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 0, 2, 1,\n",
       "       1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 2,\n",
       "       2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS110     1     1\n",
       "1         NRS216     1     1\n",
       "2         NRS386     1     1\n",
       "3       CFBRSa25     0     0\n",
       "4      BCH-SA-03     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS216     1     1\n",
       "194  CFBREBSa110     0     0\n",
       "195       NRS148     2     2\n",
       "196         GA27     0     0\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064765</td>\n",
       "      <td>0.935234</td>\n",
       "      <td>2.409646e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269903</td>\n",
       "      <td>0.730082</td>\n",
       "      <td>1.490763e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450719</td>\n",
       "      <td>0.549281</td>\n",
       "      <td>7.583485e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690136</td>\n",
       "      <td>0.309864</td>\n",
       "      <td>8.500910e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325264</td>\n",
       "      <td>0.674735</td>\n",
       "      <td>1.414096e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.269903</td>\n",
       "      <td>0.730082</td>\n",
       "      <td>1.490762e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.989226</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>3.609320e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>9.945990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.997779</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>2.268702e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>9.945990e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.064765  0.935234  2.409646e-07\n",
       "1    0.269903  0.730082  1.490763e-05\n",
       "2    0.450719  0.549281  7.583485e-08\n",
       "3    0.690136  0.309864  8.500910e-08\n",
       "4    0.325264  0.674735  1.414096e-08\n",
       "..        ...       ...           ...\n",
       "193  0.269903  0.730082  1.490762e-05\n",
       "194  0.989226  0.010774  3.609320e-10\n",
       "195  0.000038  0.005363  9.945990e-01\n",
       "196  0.997779  0.002221  2.268702e-13\n",
       "197  0.000038  0.005363  9.945990e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.1653 - accuracy: 0.9307 - val_loss: 0.1715 - val_accuracy: 0.9343\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.1609 - accuracy: 0.9264 - val_loss: 0.2818 - val_accuracy: 0.8384\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.1330 - accuracy: 0.9481 - val_loss: 0.1859 - val_accuracy: 0.9343\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.1209 - accuracy: 0.9610 - val_loss: 0.1667 - val_accuracy: 0.9343\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 157us/step - loss: 0.1172 - accuracy: 0.9545 - val_loss: 0.1817 - val_accuracy: 0.8939\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.1101 - accuracy: 0.9632 - val_loss: 0.1804 - val_accuracy: 0.9394\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.1392 - accuracy: 0.9264 - val_loss: 0.2475 - val_accuracy: 0.8788\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.1216 - accuracy: 0.9437 - val_loss: 0.1777 - val_accuracy: 0.9444\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1141 - accuracy: 0.9610 - val_loss: 0.1696 - val_accuracy: 0.9394\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.1138 - accuracy: 0.9589 - val_loss: 0.1676 - val_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.1182 - accuracy: 0.9567 - val_loss: 0.1691 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.1415 - accuracy: 0.9351 - val_loss: 0.2921 - val_accuracy: 0.8990\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.1237 - accuracy: 0.9502 - val_loss: 0.1752 - val_accuracy: 0.9394\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1096 - accuracy: 0.9610 - val_loss: 0.1658 - val_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.1113 - accuracy: 0.9524 - val_loss: 0.1598 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.1139 - accuracy: 0.9567 - val_loss: 0.1642 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.1063 - accuracy: 0.9610 - val_loss: 0.1599 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.1398 - accuracy: 0.9286 - val_loss: 0.1643 - val_accuracy: 0.9242\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.1147 - accuracy: 0.9524 - val_loss: 0.1636 - val_accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.1247 - accuracy: 0.9459 - val_loss: 0.2190 - val_accuracy: 0.8687\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1139 - accuracy: 0.9502 - val_loss: 0.1720 - val_accuracy: 0.9242\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.1396 - accuracy: 0.9437 - val_loss: 0.2211 - val_accuracy: 0.9141\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.1392 - accuracy: 0.9307 - val_loss: 0.2255 - val_accuracy: 0.8990\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.1112 - accuracy: 0.9459 - val_loss: 0.2223 - val_accuracy: 0.9091\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 518us/step - loss: 0.1291 - accuracy: 0.9351 - val_loss: 0.2114 - val_accuracy: 0.9040\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.1185 - accuracy: 0.9589 - val_loss: 0.1794 - val_accuracy: 0.9343\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.1235 - accuracy: 0.9524 - val_loss: 0.2352 - val_accuracy: 0.9040\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1145 - accuracy: 0.9524 - val_loss: 0.1533 - val_accuracy: 0.9394\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1018 - accuracy: 0.9632 - val_loss: 0.1531 - val_accuracy: 0.9495\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0991 - accuracy: 0.9654 - val_loss: 0.1646 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.1126 - accuracy: 0.9502 - val_loss: 0.3818 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.2036 - accuracy: 0.9221 - val_loss: 0.2817 - val_accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.1440 - accuracy: 0.9481 - val_loss: 0.1571 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.1323 - accuracy: 0.9524 - val_loss: 0.1577 - val_accuracy: 0.9394\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.1150 - accuracy: 0.9502 - val_loss: 0.1724 - val_accuracy: 0.9394\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.1033 - accuracy: 0.9610 - val_loss: 0.1702 - val_accuracy: 0.9242\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.1137 - accuracy: 0.9502 - val_loss: 0.1588 - val_accuracy: 0.9242\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0996 - accuracy: 0.9567 - val_loss: 0.1458 - val_accuracy: 0.9545\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0982 - accuracy: 0.9654 - val_loss: 0.1544 - val_accuracy: 0.9394\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.1072 - accuracy: 0.9589 - val_loss: 0.2005 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 0.1116 - accuracy: 0.9481 - val_loss: 0.3158 - val_accuracy: 0.8434\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.1462 - accuracy: 0.9437 - val_loss: 0.3153 - val_accuracy: 0.8434\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.1465 - accuracy: 0.9329 - val_loss: 0.2147 - val_accuracy: 0.8586\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.1445 - accuracy: 0.9416 - val_loss: 0.1492 - val_accuracy: 0.9343\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.1009 - accuracy: 0.9524 - val_loss: 0.1558 - val_accuracy: 0.9495\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.1091 - accuracy: 0.9567 - val_loss: 0.1560 - val_accuracy: 0.9444\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.1018 - accuracy: 0.9654 - val_loss: 0.1477 - val_accuracy: 0.9394\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.1012 - accuracy: 0.9654 - val_loss: 0.1506 - val_accuracy: 0.9545\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0969 - accuracy: 0.9654 - val_loss: 0.1539 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.1054 - accuracy: 0.9524 - val_loss: 0.1479 - val_accuracy: 0.9495\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1085 - accuracy: 0.9567 - val_loss: 0.1514 - val_accuracy: 0.9394\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 669us/step - loss: 0.0971 - accuracy: 0.9632 - val_loss: 0.1427 - val_accuracy: 0.9545\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 722us/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.2033 - val_accuracy: 0.9293\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 0.0968 - accuracy: 0.9567 - val_loss: 0.1614 - val_accuracy: 0.9394\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.1154 - accuracy: 0.9481 - val_loss: 0.1643 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0968 - accuracy: 0.9654 - val_loss: 0.1415 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0949 - accuracy: 0.9654 - val_loss: 0.1445 - val_accuracy: 0.9495\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1005 - accuracy: 0.9675 - val_loss: 0.1976 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.1256 - accuracy: 0.9524 - val_loss: 0.1843 - val_accuracy: 0.9343\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.1104 - accuracy: 0.9481 - val_loss: 0.1713 - val_accuracy: 0.9293\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1009 - accuracy: 0.9610 - val_loss: 0.1383 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.1003 - accuracy: 0.9589 - val_loss: 0.1455 - val_accuracy: 0.9444\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.1328 - accuracy: 0.9394 - val_loss: 0.1479 - val_accuracy: 0.9444\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.1169 - accuracy: 0.9481 - val_loss: 0.1850 - val_accuracy: 0.9293\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.1036 - accuracy: 0.9632 - val_loss: 0.1819 - val_accuracy: 0.9343\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0947 - accuracy: 0.9654 - val_loss: 0.1383 - val_accuracy: 0.9495\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0985 - accuracy: 0.9589 - val_loss: 0.1390 - val_accuracy: 0.9444\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.1128 - accuracy: 0.9524 - val_loss: 0.2114 - val_accuracy: 0.9091\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 459us/step - loss: 0.1151 - accuracy: 0.9481 - val_loss: 0.1432 - val_accuracy: 0.9495\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 0.0975 - accuracy: 0.9654 - val_loss: 0.1409 - val_accuracy: 0.9495\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.0962 - accuracy: 0.9524 - val_loss: 0.1772 - val_accuracy: 0.9343\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.0939 - accuracy: 0.9654 - val_loss: 0.1654 - val_accuracy: 0.9293\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.0974 - accuracy: 0.9567 - val_loss: 0.1418 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1090 - accuracy: 0.9502 - val_loss: 0.1555 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.1032 - accuracy: 0.9632 - val_loss: 0.1483 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 553us/step - loss: 0.0953 - accuracy: 0.9632 - val_loss: 0.1650 - val_accuracy: 0.9343\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 551us/step - loss: 0.1142 - accuracy: 0.9502 - val_loss: 0.1768 - val_accuracy: 0.9343\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.0937 - accuracy: 0.9524 - val_loss: 0.1479 - val_accuracy: 0.9545\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0956 - accuracy: 0.9632 - val_loss: 0.1682 - val_accuracy: 0.9394\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 0.0940 - accuracy: 0.9632 - val_loss: 0.1441 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 437us/step - loss: 0.0921 - accuracy: 0.9675 - val_loss: 0.1418 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.0904 - accuracy: 0.9675 - val_loss: 0.1438 - val_accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0960 - accuracy: 0.9524 - val_loss: 0.1434 - val_accuracy: 0.9495\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.0873 - accuracy: 0.9697 - val_loss: 0.1435 - val_accuracy: 0.9495\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.1029 - accuracy: 0.9654 - val_loss: 0.1468 - val_accuracy: 0.9394\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.1158 - accuracy: 0.9524 - val_loss: 0.2422 - val_accuracy: 0.8838\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 513us/step - loss: 0.1145 - accuracy: 0.9481 - val_loss: 0.1571 - val_accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.0963 - accuracy: 0.9654 - val_loss: 0.1365 - val_accuracy: 0.9495\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.1132 - accuracy: 0.9502 - val_loss: 0.2456 - val_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.1122 - accuracy: 0.9545 - val_loss: 0.2291 - val_accuracy: 0.8788\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0969 - accuracy: 0.9589 - val_loss: 0.1401 - val_accuracy: 0.9545\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0870 - accuracy: 0.9675 - val_loss: 0.2739 - val_accuracy: 0.8485\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.1133 - accuracy: 0.9481 - val_loss: 0.1875 - val_accuracy: 0.8838\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0994 - accuracy: 0.9545 - val_loss: 0.1472 - val_accuracy: 0.9343\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0943 - accuracy: 0.9654 - val_loss: 0.1362 - val_accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0949 - accuracy: 0.9567 - val_loss: 0.2219 - val_accuracy: 0.8838\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.1154 - accuracy: 0.9502 - val_loss: 0.1325 - val_accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.1032 - accuracy: 0.9567 - val_loss: 0.1346 - val_accuracy: 0.9495\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 0.0854 - accuracy: 0.9654 - val_loss: 0.1338 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.0979 - accuracy: 0.9632 - val_loss: 0.1346 - val_accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 95.42%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.47654200e-02, 9.35234370e-01, 2.40964620e-07],\n",
       "       [2.69903120e-01, 7.30082040e-01, 1.49076310e-05],\n",
       "       [4.50718880e-01, 5.49281000e-01, 7.58348550e-08],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [3.25264480e-01, 6.74735400e-01, 1.41409610e-08],\n",
       "       [6.47654200e-02, 9.35234370e-01, 2.40964620e-07],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [8.10910640e-01, 1.87278970e-01, 1.81037770e-03],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [9.17054060e-01, 8.29457700e-02, 2.11111550e-07],\n",
       "       [9.04337170e-01, 9.55729400e-02, 8.99474760e-05],\n",
       "       [6.93428800e-01, 3.06570980e-01, 2.28927950e-07],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [9.86825640e-01, 1.30792510e-02, 9.52231060e-05],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [6.47654200e-02, 9.35234370e-01, 2.40964620e-07],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [1.83327920e-02, 9.81667040e-01, 6.71697650e-08],\n",
       "       [2.31427740e-01, 7.68572300e-01, 6.64511000e-09],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [1.23866990e-05, 9.99987600e-01, 2.63744200e-15],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [2.56556580e-03, 9.97199060e-01, 2.35346150e-04],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [1.89933150e-01, 8.10066600e-01, 3.07792200e-07],\n",
       "       [1.04608210e-03, 9.98953800e-01, 1.26963580e-07],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [1.89933150e-01, 8.10066600e-01, 3.07792200e-07],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [3.25264480e-01, 6.74735400e-01, 1.41409610e-08],\n",
       "       [7.40606600e-02, 9.25934500e-01, 4.88754450e-06],\n",
       "       [2.31427740e-01, 7.68572300e-01, 6.64511000e-09],\n",
       "       [9.97779100e-01, 2.22092770e-03, 2.26871050e-13],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [9.83329200e-01, 1.65890590e-02, 8.18113400e-05],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [6.05707930e-04, 9.93434900e-01, 5.95933340e-03],\n",
       "       [9.94273650e-03, 9.75527300e-01, 1.45299565e-02],\n",
       "       [2.69903120e-01, 7.30082040e-01, 1.49076310e-05],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [9.21804000e-01, 7.81959740e-02, 6.30993100e-12],\n",
       "       [9.98974440e-01, 1.02552140e-03, 5.71385700e-13],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [1.89933150e-01, 8.10066600e-01, 3.07792200e-07],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [5.02240000e-03, 9.94848900e-01, 1.28681610e-04],\n",
       "       [4.90791350e-01, 5.09208560e-01, 1.28615640e-07],\n",
       "       [9.90792040e-01, 8.92048000e-03, 2.87425270e-04],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [4.51660450e-01, 5.48339550e-01, 1.59369730e-08],\n",
       "       [2.21508330e-02, 9.77849100e-01, 3.49437700e-09],\n",
       "       [3.04421930e-02, 9.69556330e-01, 1.47662820e-06],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [8.29518000e-01, 1.70481960e-01, 1.20897370e-15],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [7.49649470e-01, 2.50350530e-01, 2.82111650e-09],\n",
       "       [3.04421930e-02, 9.69556330e-01, 1.47662820e-06],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [9.24657340e-01, 7.53425960e-02, 7.72565800e-15],\n",
       "       [3.44514040e-01, 6.55485870e-01, 5.97645900e-08],\n",
       "       [1.04608210e-03, 9.98953800e-01, 1.26963580e-07],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [2.56556580e-03, 9.97199060e-01, 2.35346150e-04],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [9.00990660e-01, 9.89321500e-02, 7.71274900e-05],\n",
       "       [1.74479900e-01, 8.25515750e-01, 4.34604200e-06],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [6.90088750e-01, 3.09909800e-01, 1.42291560e-06],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [7.69033900e-01, 2.30965990e-01, 1.21279940e-07],\n",
       "       [1.00000000e+00, 2.83437030e-09, 1.24076720e-09],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [9.53391100e-01, 4.61777400e-02, 4.31149760e-04],\n",
       "       [9.97779100e-01, 2.22092770e-03, 2.26871050e-13],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [7.40606600e-02, 9.25934500e-01, 4.88754450e-06],\n",
       "       [7.40606600e-02, 9.25934500e-01, 4.88754450e-06],\n",
       "       [6.47654200e-02, 9.35234370e-01, 2.40964620e-07],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [9.98362240e-01, 1.63773380e-03, 3.50445940e-13],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [6.47654200e-02, 9.35234370e-01, 2.40964620e-07],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [9.94273650e-03, 9.75527300e-01, 1.45299565e-02],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.51660450e-01, 5.48339550e-01, 1.59369730e-08],\n",
       "       [3.04421930e-02, 9.69556330e-01, 1.47662820e-06],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [9.94404300e-01, 5.59563700e-03, 1.43596140e-13],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [3.25264480e-01, 6.74735400e-01, 1.41409610e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [3.25264480e-01, 6.74735400e-01, 1.41409610e-08],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.51660450e-01, 5.48339550e-01, 1.59369730e-08],\n",
       "       [9.90650200e-01, 9.34973450e-03, 6.55051800e-17],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.67440750e-01, 5.32557250e-01, 1.97423010e-06],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [6.70603100e-01, 3.29396400e-01, 5.41209030e-07],\n",
       "       [9.11650600e-03, 9.90883500e-01, 6.63738040e-09],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [6.36333000e-01, 3.63666950e-01, 6.75816800e-08],\n",
       "       [1.14233660e-01, 8.85766400e-01, 3.10368050e-08],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [7.40606600e-02, 9.25934500e-01, 4.88754450e-06],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [9.06135260e-01, 9.38341100e-02, 3.05940960e-05],\n",
       "       [9.89225570e-01, 1.07744190e-02, 3.60931980e-10],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [1.52079750e-01, 8.47916500e-01, 3.70234900e-06],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [7.49979400e-01, 2.50020180e-01, 4.42219060e-07],\n",
       "       [9.93064700e-01, 6.93530100e-03, 6.35706100e-11],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [2.91231670e-03, 9.97087660e-01, 4.93667640e-16],\n",
       "       [4.50718880e-01, 5.49281000e-01, 7.58348550e-08],\n",
       "       [9.89225570e-01, 1.07744190e-02, 3.60931980e-10],\n",
       "       [6.36333000e-01, 3.63666950e-01, 6.75816800e-08],\n",
       "       [8.92103200e-01, 1.07868290e-01, 2.84968000e-05],\n",
       "       [6.78700300e-02, 9.29243400e-01, 2.88655420e-03],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.90574540e-03, 9.95055300e-01, 3.88495170e-05],\n",
       "       [6.05707930e-04, 9.93434900e-01, 5.95933340e-03],\n",
       "       [3.25264480e-01, 6.74735400e-01, 1.41409610e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.94884050e-03, 8.83894600e-03, 9.86212250e-01],\n",
       "       [7.98286860e-01, 1.88753980e-01, 1.29592230e-02],\n",
       "       [2.31427740e-01, 7.68572300e-01, 6.64511000e-09],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [1.83327920e-02, 9.81667040e-01, 6.71697650e-08],\n",
       "       [9.97298540e-01, 2.70152720e-03, 3.36508060e-13],\n",
       "       [3.89154020e-01, 6.10845900e-01, 4.10859760e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [4.51660450e-01, 5.48339550e-01, 1.59369730e-08],\n",
       "       [6.78700300e-02, 9.29243400e-01, 2.88655420e-03],\n",
       "       [4.63628440e-03, 9.95363700e-01, 2.18463600e-08],\n",
       "       [4.87752830e-01, 5.12201670e-01, 4.55053500e-05],\n",
       "       [2.56556580e-03, 9.97199060e-01, 2.35346150e-04],\n",
       "       [1.83327920e-02, 9.81667040e-01, 6.71697650e-08],\n",
       "       [6.90135600e-01, 3.09864300e-01, 8.50091000e-08],\n",
       "       [9.81827560e-01, 1.81724130e-02, 3.49615730e-08],\n",
       "       [9.96851400e-01, 3.14865750e-03, 3.73676800e-12],\n",
       "       [8.87439600e-01, 1.12526230e-01, 3.41527500e-05],\n",
       "       [8.86176100e-01, 1.13823780e-01, 7.66993400e-08],\n",
       "       [3.83570880e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [7.40606600e-02, 9.25934500e-01, 4.88754450e-06],\n",
       "       [8.29518000e-01, 1.70481960e-01, 1.20897370e-15],\n",
       "       [1.83327920e-02, 9.81667040e-01, 6.71697650e-08],\n",
       "       [9.39346550e-01, 6.06534800e-02, 2.04447350e-09],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [8.96089200e-01, 1.03882070e-01, 2.87493700e-05],\n",
       "       [9.98362240e-01, 1.63773380e-03, 3.50445940e-13],\n",
       "       [9.95069400e-01, 4.93065970e-03, 2.62610960e-10],\n",
       "       [4.51660450e-01, 5.48339550e-01, 1.59369730e-08],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [9.89225570e-01, 1.07744190e-02, 3.60931980e-10],\n",
       "       [2.37929900e-05, 5.47145140e-05, 9.99921440e-01],\n",
       "       [4.94883630e-03, 8.83893300e-03, 9.86212250e-01],\n",
       "       [2.69903030e-01, 7.30082150e-01, 1.49076200e-05],\n",
       "       [9.89225570e-01, 1.07744600e-02, 3.60931980e-10],\n",
       "       [3.83571240e-05, 5.36263500e-03, 9.94599000e-01],\n",
       "       [9.97779100e-01, 2.22093200e-03, 2.26870190e-13],\n",
       "       [3.83571240e-05, 5.36263500e-03, 9.94599000e-01]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791475359657178"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791475359657178"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840832568105295"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00570454278101484"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840832568105295"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00570454278101484"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 92.80%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.00550367440540207\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 95.14%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0026521664\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS241     1\n",
       "1      NRS148     2\n",
       "2      NRS255     1\n",
       "3      NRS214     0\n",
       "4      NRS148     2\n",
       "..        ...   ...\n",
       "193  CFBRSa30     0\n",
       "194    NRS266     1\n",
       "195    SR4152     0\n",
       "196    NRS109     2\n",
       "197       115     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 997us/step - loss: 5.0409 - accuracy: 0.5476 - val_loss: 2.1682 - val_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 344us/step - loss: 3.8850 - accuracy: 0.5866 - val_loss: 1.5057 - val_accuracy: 0.6616\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 3.5170 - accuracy: 0.6104 - val_loss: 1.3378 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 3.2984 - accuracy: 0.6126 - val_loss: 1.2692 - val_accuracy: 0.6717\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 3.2609 - accuracy: 0.6082 - val_loss: 1.2305 - val_accuracy: 0.6717\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 340us/step - loss: 3.1466 - accuracy: 0.6255 - val_loss: 1.2937 - val_accuracy: 0.7020\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 3.1494 - accuracy: 0.5996 - val_loss: 1.6462 - val_accuracy: 0.7475\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 363us/step - loss: 2.7568 - accuracy: 0.6645 - val_loss: 1.0849 - val_accuracy: 0.7121\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 2.9184 - accuracy: 0.6645 - val_loss: 1.3308 - val_accuracy: 0.7677\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 3.0916 - accuracy: 0.6342 - val_loss: 1.3358 - val_accuracy: 0.7424\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 2.5321 - accuracy: 0.6537 - val_loss: 1.2385 - val_accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 2.7234 - accuracy: 0.6623 - val_loss: 1.3248 - val_accuracy: 0.7677\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 2.3608 - accuracy: 0.6688 - val_loss: 1.2810 - val_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 2.5361 - accuracy: 0.6710 - val_loss: 1.2230 - val_accuracy: 0.8081\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 2.8923 - accuracy: 0.6472 - val_loss: 1.0964 - val_accuracy: 0.7576\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 2.2675 - accuracy: 0.6861 - val_loss: 1.2213 - val_accuracy: 0.8131\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 2.6609 - accuracy: 0.6580 - val_loss: 1.1727 - val_accuracy: 0.7929\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 2.3224 - accuracy: 0.7186 - val_loss: 1.1821 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 2.1859 - accuracy: 0.6970 - val_loss: 1.2650 - val_accuracy: 0.8232\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 2.5372 - accuracy: 0.6710 - val_loss: 1.0707 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 2.1724 - accuracy: 0.6970 - val_loss: 1.1624 - val_accuracy: 0.8081\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 2.0072 - accuracy: 0.7056 - val_loss: 1.2175 - val_accuracy: 0.7879\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 363us/step - loss: 2.1615 - accuracy: 0.6840 - val_loss: 1.1315 - val_accuracy: 0.7879\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 2.0209 - accuracy: 0.7035 - val_loss: 1.1155 - val_accuracy: 0.7980\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 344us/step - loss: 2.1483 - accuracy: 0.6667 - val_loss: 1.0718 - val_accuracy: 0.8131\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 515us/step - loss: 1.9822 - accuracy: 0.6840 - val_loss: 0.9118 - val_accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 1.8766 - accuracy: 0.7359 - val_loss: 1.1552 - val_accuracy: 0.8131\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 441us/step - loss: 1.6907 - accuracy: 0.7294 - val_loss: 0.7758 - val_accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 2.2598 - accuracy: 0.7013 - val_loss: 1.0389 - val_accuracy: 0.8384\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 2.3290 - accuracy: 0.6580 - val_loss: 1.0612 - val_accuracy: 0.8081\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 357us/step - loss: 2.2114 - accuracy: 0.7013 - val_loss: 0.9860 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 1.8903 - accuracy: 0.7013 - val_loss: 0.9922 - val_accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 1.8623 - accuracy: 0.6948 - val_loss: 1.2110 - val_accuracy: 0.8131\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 1.6706 - accuracy: 0.7381 - val_loss: 0.8529 - val_accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 1.9802 - accuracy: 0.6991 - val_loss: 0.8312 - val_accuracy: 0.8131\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 1.8008 - accuracy: 0.7208 - val_loss: 0.8327 - val_accuracy: 0.8384\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 1.8564 - accuracy: 0.6861 - val_loss: 1.1196 - val_accuracy: 0.8081\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 1.8018 - accuracy: 0.7013 - val_loss: 1.0144 - val_accuracy: 0.7980\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.7693 - accuracy: 0.7446 - val_loss: 0.9444 - val_accuracy: 0.8283\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.8992 - accuracy: 0.7013 - val_loss: 0.9296 - val_accuracy: 0.8586\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 1.5512 - accuracy: 0.7446 - val_loss: 0.9192 - val_accuracy: 0.8384\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 1.5650 - accuracy: 0.7554 - val_loss: 0.7476 - val_accuracy: 0.8535\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.6798 - accuracy: 0.6840 - val_loss: 0.6689 - val_accuracy: 0.8434\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 1.5341 - accuracy: 0.7056 - val_loss: 0.8367 - val_accuracy: 0.8384\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.6750 - accuracy: 0.7273 - val_loss: 0.8644 - val_accuracy: 0.8535\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 419us/step - loss: 1.4205 - accuracy: 0.7056 - val_loss: 1.0241 - val_accuracy: 0.8081\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 428us/step - loss: 1.8544 - accuracy: 0.7078 - val_loss: 0.6521 - val_accuracy: 0.8586\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 437us/step - loss: 1.3458 - accuracy: 0.7273 - val_loss: 0.6619 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 425us/step - loss: 1.7501 - accuracy: 0.7338 - val_loss: 0.8043 - val_accuracy: 0.8283\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 407us/step - loss: 1.4501 - accuracy: 0.7684 - val_loss: 0.5097 - val_accuracy: 0.8535\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 1.4196 - accuracy: 0.7771 - val_loss: 0.6191 - val_accuracy: 0.8535\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 496us/step - loss: 1.3694 - accuracy: 0.7446 - val_loss: 0.6894 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 433us/step - loss: 1.4633 - accuracy: 0.7662 - val_loss: 0.6205 - val_accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 1.2886 - accuracy: 0.7359 - val_loss: 0.8449 - val_accuracy: 0.8586\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 1.4838 - accuracy: 0.7143 - val_loss: 0.7594 - val_accuracy: 0.8838\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 1.5590 - accuracy: 0.7100 - val_loss: 0.9603 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 1.2077 - accuracy: 0.7706 - val_loss: 0.6372 - val_accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 1.4994 - accuracy: 0.7576 - val_loss: 0.8394 - val_accuracy: 0.8788\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 1.4125 - accuracy: 0.7424 - val_loss: 0.6487 - val_accuracy: 0.8737\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 1.5338 - accuracy: 0.7165 - val_loss: 0.6797 - val_accuracy: 0.8939\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 1.6860 - accuracy: 0.7511 - val_loss: 0.7380 - val_accuracy: 0.8535\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 1.4737 - accuracy: 0.7489 - val_loss: 0.7607 - val_accuracy: 0.8687\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.2698 - accuracy: 0.7381 - val_loss: 0.9811 - val_accuracy: 0.8636\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 1.3224 - accuracy: 0.7035 - val_loss: 0.7514 - val_accuracy: 0.8737\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 1.4584 - accuracy: 0.7597 - val_loss: 0.8444 - val_accuracy: 0.8737\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.5896 - accuracy: 0.7208 - val_loss: 0.7887 - val_accuracy: 0.8737\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 1.4433 - accuracy: 0.7511 - val_loss: 0.9715 - val_accuracy: 0.8535\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 1.4132 - accuracy: 0.7597 - val_loss: 0.9274 - val_accuracy: 0.8737\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 652us/step - loss: 1.3566 - accuracy: 0.7316 - val_loss: 1.0330 - val_accuracy: 0.8737\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 1.4062 - accuracy: 0.7446 - val_loss: 0.6880 - val_accuracy: 0.8788\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.3316 - accuracy: 0.7684 - val_loss: 0.7626 - val_accuracy: 0.8838\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 1.3509 - accuracy: 0.7597 - val_loss: 0.9042 - val_accuracy: 0.8737\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 1.3205 - accuracy: 0.7424 - val_loss: 0.6072 - val_accuracy: 0.8939\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 1.1611 - accuracy: 0.7619 - val_loss: 0.8911 - val_accuracy: 0.8788\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 1.3178 - accuracy: 0.7511 - val_loss: 0.9047 - val_accuracy: 0.8788\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 1.2493 - accuracy: 0.7554 - val_loss: 0.6832 - val_accuracy: 0.8939\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 1.4103 - accuracy: 0.7338 - val_loss: 0.7080 - val_accuracy: 0.8687\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 467us/step - loss: 1.0935 - accuracy: 0.7771 - val_loss: 0.7169 - val_accuracy: 0.8838\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 463us/step - loss: 1.0721 - accuracy: 0.7727 - val_loss: 0.6281 - val_accuracy: 0.8990\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 1.1434 - accuracy: 0.7468 - val_loss: 0.7283 - val_accuracy: 0.8889\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.1701 - accuracy: 0.7576 - val_loss: 0.6360 - val_accuracy: 0.8939\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 537us/step - loss: 1.1497 - accuracy: 0.7727 - val_loss: 0.5999 - val_accuracy: 0.8788\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 489us/step - loss: 1.0011 - accuracy: 0.7727 - val_loss: 0.5828 - val_accuracy: 0.8990\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 715us/step - loss: 1.2209 - accuracy: 0.7316 - val_loss: 0.8894 - val_accuracy: 0.8687\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 648us/step - loss: 1.2480 - accuracy: 0.7468 - val_loss: 0.7312 - val_accuracy: 0.9040\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 1.2475 - accuracy: 0.7446 - val_loss: 0.5971 - val_accuracy: 0.8889\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.1475 - accuracy: 0.7619 - val_loss: 0.6900 - val_accuracy: 0.8737\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 1.2720 - accuracy: 0.7424 - val_loss: 0.6494 - val_accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.4679 - accuracy: 0.7662 - val_loss: 0.8023 - val_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 1.3031 - accuracy: 0.7403 - val_loss: 0.7797 - val_accuracy: 0.8990\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 1.1856 - accuracy: 0.7684 - val_loss: 0.9470 - val_accuracy: 0.8586\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 1.4246 - accuracy: 0.7273 - val_loss: 0.8264 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 1.4521 - accuracy: 0.7316 - val_loss: 0.7719 - val_accuracy: 0.8838\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 1.0587 - accuracy: 0.7922 - val_loss: 1.2746 - val_accuracy: 0.8434\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.3052 - accuracy: 0.7468 - val_loss: 0.6953 - val_accuracy: 0.9141\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 1.0770 - accuracy: 0.7208 - val_loss: 0.9577 - val_accuracy: 0.8889\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 1.1435 - accuracy: 0.7532 - val_loss: 0.9416 - val_accuracy: 0.8586\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 1.2113 - accuracy: 0.7338 - val_loss: 1.0066 - val_accuracy: 0.8485\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 1.1202 - accuracy: 0.7489 - val_loss: 0.7863 - val_accuracy: 0.9040\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 1.3006 - accuracy: 0.7576 - val_loss: 0.6541 - val_accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3bee10f0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 160us/step\n",
      "over-sampling test accuracy: 86.36%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 2, 1, 2, 2, 1, 0, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2,\n",
       "       0, 0, 0, 2, 2, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 1, 2, 1, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 0,\n",
       "       2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 2, 1, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 2, 1,\n",
       "       1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 1, 1, 1, 0, 2,\n",
       "       0, 1, 0, 0, 2, 1, 1, 0, 1, 2, 2, 0, 2, 0, 1, 0, 2, 1, 2, 0, 1, 2,\n",
       "       2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS241     1     1\n",
       "1      NRS148     2     2\n",
       "2      NRS255     1     1\n",
       "3      NRS214     0     0\n",
       "4      NRS148     2     2\n",
       "..        ...   ...   ...\n",
       "193  CFBRSa30     0     0\n",
       "194    NRS266     1     1\n",
       "195    SR4152     0     0\n",
       "196    NRS109     2     2\n",
       "197       115     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.251366e-13</td>\n",
       "      <td>1.614020e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.216973e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.654322e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>9.943394e-01</td>\n",
       "      <td>5.660585e-03</td>\n",
       "      <td>4.075664e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7.450425e-21</td>\n",
       "      <td>9.585720e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.320418e-03</td>\n",
       "      <td>9.963890e-01</td>\n",
       "      <td>2.905510e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.342914e-03  9.986569e-01  2.348628e-07\n",
       "1    5.170289e-08  1.017893e-07  9.999999e-01\n",
       "2    1.780311e-07  9.999999e-01  2.544841e-12\n",
       "3    1.000000e+00  2.203547e-10  5.688883e-15\n",
       "4    5.170289e-08  1.017893e-07  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "193  1.000000e+00  5.251366e-13  1.614020e-18\n",
       "194  1.216973e-08  1.000000e+00  2.654322e-14\n",
       "195  9.943394e-01  5.660585e-03  4.075664e-13\n",
       "196  7.450425e-21  9.585720e-12  1.000000e+00\n",
       "197  3.320418e-03  9.963890e-01  2.905510e-04\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 382us/step - loss: 1.4464 - accuracy: 0.7186 - val_loss: 1.4367 - val_accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 1.3780 - accuracy: 0.7035 - val_loss: 1.4334 - val_accuracy: 0.8485\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 1.2255 - accuracy: 0.7446 - val_loss: 0.9547 - val_accuracy: 0.8788\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 1.3377 - accuracy: 0.7316 - val_loss: 1.1604 - val_accuracy: 0.8384\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.1934 - accuracy: 0.7316 - val_loss: 1.1594 - val_accuracy: 0.8687\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 1.2729 - accuracy: 0.7446 - val_loss: 1.3179 - val_accuracy: 0.8535\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.1330 - accuracy: 0.7468 - val_loss: 0.9265 - val_accuracy: 0.8788\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.1356 - accuracy: 0.7489 - val_loss: 1.2852 - val_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 1.1560 - accuracy: 0.7489 - val_loss: 1.2233 - val_accuracy: 0.8737\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 436us/step - loss: 1.1252 - accuracy: 0.8030 - val_loss: 1.2279 - val_accuracy: 0.8636\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 324us/step - loss: 1.2015 - accuracy: 0.7165 - val_loss: 1.1574 - val_accuracy: 0.8838\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.9253 - accuracy: 0.7597 - val_loss: 1.0861 - val_accuracy: 0.8434\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 1.1176 - accuracy: 0.7662 - val_loss: 0.9537 - val_accuracy: 0.8838\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.9104 - accuracy: 0.7597 - val_loss: 0.9506 - val_accuracy: 0.8687\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 1.4941 - accuracy: 0.7316 - val_loss: 1.4870 - val_accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 1.3944 - accuracy: 0.7381 - val_loss: 1.0054 - val_accuracy: 0.8737\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 1.5840 - accuracy: 0.7100 - val_loss: 1.3775 - val_accuracy: 0.8636\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 1.1280 - accuracy: 0.7727 - val_loss: 0.9597 - val_accuracy: 0.8838\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 1.1829 - accuracy: 0.7403 - val_loss: 1.6360 - val_accuracy: 0.8636\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 1.3197 - accuracy: 0.7489 - val_loss: 1.5483 - val_accuracy: 0.8283\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 1.6917 - accuracy: 0.6991 - val_loss: 1.9910 - val_accuracy: 0.8586\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 1.6578 - accuracy: 0.6818 - val_loss: 0.9353 - val_accuracy: 0.8434\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 1.4465 - accuracy: 0.6991 - val_loss: 0.9872 - val_accuracy: 0.8889\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 1.1690 - accuracy: 0.7489 - val_loss: 1.1373 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 1.0149 - accuracy: 0.7532 - val_loss: 1.4391 - val_accuracy: 0.8283\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 1.4304 - accuracy: 0.7078 - val_loss: 1.1532 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 1.3272 - accuracy: 0.7078 - val_loss: 1.0111 - val_accuracy: 0.8434\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 1.1842 - accuracy: 0.7035 - val_loss: 1.2062 - val_accuracy: 0.8687\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 1.1375 - accuracy: 0.7597 - val_loss: 1.2106 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 1.1733 - accuracy: 0.7338 - val_loss: 1.2621 - val_accuracy: 0.8232\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 1.2739 - accuracy: 0.7013 - val_loss: 1.2835 - val_accuracy: 0.8283\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 1.1642 - accuracy: 0.7294 - val_loss: 1.1931 - val_accuracy: 0.8485\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 1.2545 - accuracy: 0.7446 - val_loss: 1.1483 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 1.3289 - accuracy: 0.7468 - val_loss: 1.1597 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 1.5086 - accuracy: 0.6905 - val_loss: 0.9791 - val_accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 1.3727 - accuracy: 0.7078 - val_loss: 1.3437 - val_accuracy: 0.8081\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 1.1160 - accuracy: 0.7359 - val_loss: 1.0125 - val_accuracy: 0.8434\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 636us/step - loss: 1.1279 - accuracy: 0.7554 - val_loss: 1.2339 - val_accuracy: 0.8434\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 478us/step - loss: 1.2078 - accuracy: 0.7208 - val_loss: 1.0578 - val_accuracy: 0.8434\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 1.1263 - accuracy: 0.7424 - val_loss: 1.4914 - val_accuracy: 0.8434\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 551us/step - loss: 1.4609 - accuracy: 0.7165 - val_loss: 1.5178 - val_accuracy: 0.8283\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 390us/step - loss: 1.5945 - accuracy: 0.6948 - val_loss: 2.2533 - val_accuracy: 0.8081\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 1.4096 - accuracy: 0.7121 - val_loss: 1.2364 - val_accuracy: 0.8586\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 1.6178 - accuracy: 0.7251 - val_loss: 1.8426 - val_accuracy: 0.8131\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 1.5079 - accuracy: 0.7489 - val_loss: 1.4877 - val_accuracy: 0.8434\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 1.3586 - accuracy: 0.7424 - val_loss: 0.8179 - val_accuracy: 0.8485\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 1.2338 - accuracy: 0.7424 - val_loss: 0.9227 - val_accuracy: 0.8384\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 1.0188 - accuracy: 0.7532 - val_loss: 0.9207 - val_accuracy: 0.8434\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 647us/step - loss: 1.1956 - accuracy: 0.7251 - val_loss: 1.2115 - val_accuracy: 0.8485\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 603us/step - loss: 1.2013 - accuracy: 0.7100 - val_loss: 0.8693 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 766us/step - loss: 1.1194 - accuracy: 0.7403 - val_loss: 1.3068 - val_accuracy: 0.8384\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 489us/step - loss: 1.3236 - accuracy: 0.7165 - val_loss: 0.9901 - val_accuracy: 0.8434\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 553us/step - loss: 0.9745 - accuracy: 0.6948 - val_loss: 1.2061 - val_accuracy: 0.8283\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 635us/step - loss: 1.1314 - accuracy: 0.7403 - val_loss: 0.9541 - val_accuracy: 0.8384\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.2831 - accuracy: 0.7338 - val_loss: 0.9844 - val_accuracy: 0.8384\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 490us/step - loss: 1.1175 - accuracy: 0.7554 - val_loss: 1.2445 - val_accuracy: 0.8384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 1.2665 - accuracy: 0.7294 - val_loss: 1.2587 - val_accuracy: 0.8384\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 1.2981 - accuracy: 0.7424 - val_loss: 0.8914 - val_accuracy: 0.8384\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 1.1904 - accuracy: 0.7165 - val_loss: 1.2400 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 341us/step - loss: 1.1297 - accuracy: 0.7468 - val_loss: 1.5495 - val_accuracy: 0.8131\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 1.2268 - accuracy: 0.7468 - val_loss: 1.8264 - val_accuracy: 0.8232\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 1.4871 - accuracy: 0.7056 - val_loss: 2.3550 - val_accuracy: 0.8030\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 1.2379 - accuracy: 0.7424 - val_loss: 1.1821 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 434us/step - loss: 1.1844 - accuracy: 0.7056 - val_loss: 1.0313 - val_accuracy: 0.8232\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 357us/step - loss: 1.5767 - accuracy: 0.6667 - val_loss: 1.6809 - val_accuracy: 0.8535\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 1.4855 - accuracy: 0.7316 - val_loss: 1.7490 - val_accuracy: 0.7980\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 390us/step - loss: 1.3326 - accuracy: 0.7273 - val_loss: 0.9319 - val_accuracy: 0.8434\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 1.1303 - accuracy: 0.7381 - val_loss: 1.2931 - val_accuracy: 0.8283\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 1.1873 - accuracy: 0.7316 - val_loss: 0.9180 - val_accuracy: 0.8384\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 1.3993 - accuracy: 0.7165 - val_loss: 0.8985 - val_accuracy: 0.8434\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.8894 - accuracy: 0.7424 - val_loss: 0.8995 - val_accuracy: 0.8434\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 1.0341 - accuracy: 0.7489 - val_loss: 1.1340 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 1.2498 - accuracy: 0.7381 - val_loss: 1.2061 - val_accuracy: 0.8384\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 520us/step - loss: 1.1568 - accuracy: 0.7489 - val_loss: 1.1898 - val_accuracy: 0.8384\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 1.0236 - accuracy: 0.7532 - val_loss: 1.2780 - val_accuracy: 0.8384\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 1.2347 - accuracy: 0.7121 - val_loss: 1.0868 - val_accuracy: 0.8384\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 1.2003 - accuracy: 0.7316 - val_loss: 1.2510 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 1.2352 - accuracy: 0.7251 - val_loss: 1.2048 - val_accuracy: 0.8434\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 1.1266 - accuracy: 0.7208 - val_loss: 1.2790 - val_accuracy: 0.8434\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 1.1633 - accuracy: 0.7186 - val_loss: 1.2352 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 1.3542 - accuracy: 0.7489 - val_loss: 0.9372 - val_accuracy: 0.8434\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.0606 - accuracy: 0.7165 - val_loss: 1.1807 - val_accuracy: 0.8384\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 1.1889 - accuracy: 0.7100 - val_loss: 1.3170 - val_accuracy: 0.8283\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 1.2040 - accuracy: 0.7403 - val_loss: 1.2219 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 1.1598 - accuracy: 0.7294 - val_loss: 1.1552 - val_accuracy: 0.8434\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 1.0884 - accuracy: 0.7532 - val_loss: 1.1352 - val_accuracy: 0.8384\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 1.0181 - accuracy: 0.7424 - val_loss: 1.4342 - val_accuracy: 0.8434\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.9262 - accuracy: 0.7316 - val_loss: 1.2799 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.2310 - accuracy: 0.7186 - val_loss: 1.3625 - val_accuracy: 0.8485\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 1.2099 - accuracy: 0.6883 - val_loss: 1.0629 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 0.9972 - accuracy: 0.7403 - val_loss: 1.2901 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.0023 - accuracy: 0.7576 - val_loss: 1.1587 - val_accuracy: 0.8384\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 525us/step - loss: 1.0539 - accuracy: 0.7208 - val_loss: 0.9508 - val_accuracy: 0.8535\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 474us/step - loss: 1.0970 - accuracy: 0.7619 - val_loss: 1.2262 - val_accuracy: 0.8636\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 511us/step - loss: 1.2698 - accuracy: 0.6991 - val_loss: 1.2806 - val_accuracy: 0.8283\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 475us/step - loss: 1.3956 - accuracy: 0.7229 - val_loss: 1.4764 - val_accuracy: 0.8586\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 499us/step - loss: 1.1698 - accuracy: 0.7381 - val_loss: 1.3191 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 551us/step - loss: 1.2053 - accuracy: 0.7165 - val_loss: 1.2807 - val_accuracy: 0.7929\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 1.2231 - accuracy: 0.7078 - val_loss: 1.2050 - val_accuracy: 0.8384\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 435us/step - loss: 0.9633 - accuracy: 0.7554 - val_loss: 1.1500 - val_accuracy: 0.8434\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 73.07%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34291400e-03, 9.98656870e-01, 2.34862780e-07],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.78031120e-07, 9.99999900e-01, 2.54484100e-12],\n",
       "       [1.00000000e+00, 2.20354690e-10, 5.68888330e-15],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [8.46151350e-01, 1.53848700e-01, 1.73614970e-08],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [3.27969710e-03, 9.96719400e-01, 8.87750840e-07],\n",
       "       [1.00000000e+00, 5.25136630e-13, 1.61401960e-18],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [3.96341230e-09, 1.67940110e-01, 8.32059860e-01],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [3.96341230e-09, 1.67940110e-01, 8.32059860e-01],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [4.52543110e-10, 1.00000000e+00, 9.92756100e-15],\n",
       "       [3.50649630e-12, 1.00000000e+00, 6.71626930e-16],\n",
       "       [1.35698240e-02, 9.86428700e-01, 1.53442930e-06],\n",
       "       [2.18109080e-07, 9.99997740e-01, 2.02023940e-06],\n",
       "       [9.99946100e-01, 5.38543700e-05, 1.76115860e-13],\n",
       "       [1.00000000e+00, 2.20354690e-10, 5.68888330e-15],\n",
       "       [1.00000000e+00, 2.20354690e-10, 5.68888330e-15],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [8.62136500e-05, 9.99913800e-01, 4.90407500e-15],\n",
       "       [9.99946100e-01, 5.38543700e-05, 1.76115860e-13],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.20354690e-10, 5.68888330e-15],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.20354690e-10, 5.68888330e-15],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [8.01975800e-01, 1.98024270e-01, 4.11779900e-08],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [2.18109080e-07, 9.99997740e-01, 2.02023940e-06],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.99946100e-01, 5.38543700e-05, 1.76115860e-13],\n",
       "       [9.95173500e-01, 4.82649800e-03, 2.29919170e-13],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.52347500e-10, 1.77766740e-15],\n",
       "       [9.02072300e-03, 9.90839060e-01, 1.40211500e-04],\n",
       "       [1.42252790e-01, 8.57727000e-01, 2.02149310e-05],\n",
       "       [2.91328820e-05, 9.99970900e-01, 6.61882200e-14],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.80440820e-04, 9.99619500e-01, 1.02478250e-14],\n",
       "       [1.00000000e+00, 2.27394500e-11, 2.67431070e-16],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.98303500e-17, 5.89698680e-36],\n",
       "       [4.52543110e-10, 1.00000000e+00, 9.92756100e-15],\n",
       "       [1.26834490e-15, 1.00000000e+00, 1.67872210e-21],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.99979600e-01, 2.04020020e-05, 3.11181880e-14],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.99946100e-01, 5.38543700e-05, 1.76115860e-13],\n",
       "       [1.78031120e-07, 9.99999900e-01, 2.54484100e-12],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [4.02533950e-10, 1.00000000e+00, 5.58540900e-15],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [9.99625440e-01, 3.74497550e-04, 1.77859810e-12],\n",
       "       [9.48118700e-01, 5.18812700e-02, 5.32059000e-10],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [1.26834490e-15, 1.00000000e+00, 1.67872210e-21],\n",
       "       [1.27625920e-10, 1.00000000e+00, 7.97060700e-21],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [2.91328820e-05, 9.99970900e-01, 6.61882200e-14],\n",
       "       [9.99999400e-01, 5.68380500e-07, 2.44403900e-25],\n",
       "       [3.26726360e-02, 9.67247960e-01, 7.94896100e-05],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.95173500e-01, 4.82649800e-03, 2.29919170e-13],\n",
       "       [1.00000000e+00, 2.51808520e-10, 6.79588300e-15],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.34291400e-03, 9.98656870e-01, 2.34862780e-07],\n",
       "       [9.99430600e-01, 5.69372550e-04, 1.18782490e-11],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.81417170e-15, 0.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [3.54724960e-11, 1.00000000e+00, 2.10611080e-14],\n",
       "       [5.26995400e-01, 4.73001630e-01, 2.92225510e-06],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [8.96987500e-09, 1.00000000e+00, 2.31468020e-15],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.99845740e-01, 1.54274360e-04, 6.20650000e-13],\n",
       "       [5.18039900e-03, 9.94610550e-01, 2.09038830e-04],\n",
       "       [1.46235780e-06, 9.99998570e-01, 3.67574220e-10],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [1.34291400e-03, 9.98656870e-01, 2.34862780e-07],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.80440820e-04, 9.99619500e-01, 1.02478250e-14],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.26834490e-15, 1.00000000e+00, 1.67872210e-21],\n",
       "       [2.03776020e-11, 1.00000000e+00, 5.14916160e-19],\n",
       "       [3.54724960e-11, 1.00000000e+00, 2.10611080e-14],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.99987960e-01, 1.20276320e-05, 1.91794770e-23],\n",
       "       [5.18039900e-03, 9.94610550e-01, 2.09038830e-04],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.21697810e-08, 1.00000000e+00, 2.65433190e-14],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.99413130e-01, 5.86875250e-04, 5.08849340e-12],\n",
       "       [3.54724960e-11, 1.00000000e+00, 2.10611080e-14],\n",
       "       [1.83543750e-02, 9.81645700e-01, 1.58091790e-18],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.42252790e-01, 8.57727000e-01, 2.02149310e-05],\n",
       "       [1.78031120e-07, 9.99999900e-01, 2.54484100e-12],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [2.03776020e-11, 1.00000000e+00, 5.14916160e-19],\n",
       "       [1.00000000e+00, 2.27394500e-11, 2.67431070e-16],\n",
       "       [8.53254640e-20, 1.00000000e+00, 9.09426150e-26],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [9.99982500e-01, 1.75447390e-05, 4.24942230e-22],\n",
       "       [1.00000000e+00, 3.43398500e-10, 1.02749420e-14],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.50649630e-12, 1.00000000e+00, 6.71626930e-16],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.25136630e-13, 1.61401960e-18],\n",
       "       [8.46151350e-01, 1.53848700e-01, 1.73614970e-08],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [3.80440820e-04, 9.99619500e-01, 1.02478250e-14],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [3.26726360e-02, 9.67247960e-01, 7.94896100e-05],\n",
       "       [8.53254640e-20, 1.00000000e+00, 9.09426150e-26],\n",
       "       [9.99994750e-01, 5.20484950e-06, 2.71391600e-15],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.62676900e-10, 1.10506860e-14],\n",
       "       [4.29485830e-03, 9.95466230e-01, 2.38870970e-04],\n",
       "       [1.00000000e+00, 2.53054100e-10, 6.84072360e-15],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [6.71209600e-08, 9.99999900e-01, 7.51797440e-13],\n",
       "       [8.53254640e-20, 1.00000000e+00, 9.09426150e-26],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.99954340e-01, 4.57021100e-05, 1.28684190e-20],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [8.01975800e-01, 1.98024270e-01, 4.11779900e-08],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [9.88194600e-01, 1.17869580e-02, 1.84888870e-05],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [1.26834490e-15, 1.00000000e+00, 1.67872210e-21],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.98664050e-14, 2.93586900e-30],\n",
       "       [1.04411960e-09, 1.00000000e+00, 1.73893330e-12],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [1.13043770e-02, 9.88563800e-01, 1.31847640e-04],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [9.99999900e-01, 1.42649440e-07, 9.59448900e-29],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [9.99899600e-01, 1.00352390e-04, 3.32835970e-14],\n",
       "       [9.92191200e-09, 1.72646430e-08, 1.00000000e+00],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [4.52543110e-10, 1.00000000e+00, 9.92756100e-15],\n",
       "       [4.52543110e-10, 1.00000000e+00, 9.92756100e-15],\n",
       "       [9.49341900e-01, 5.06581030e-02, 4.94066950e-10],\n",
       "       [5.17028940e-08, 1.01789280e-07, 9.99999900e-01],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04],\n",
       "       [7.96986500e-02, 9.20269600e-01, 3.17075400e-05],\n",
       "       [1.21697346e-08, 1.00000000e+00, 2.65432170e-14],\n",
       "       [1.00000000e+00, 5.25136630e-13, 1.61401960e-18],\n",
       "       [1.21697346e-08, 1.00000000e+00, 2.65432170e-14],\n",
       "       [9.94339400e-01, 5.66058470e-03, 4.07566420e-13],\n",
       "       [7.45042500e-21, 9.58572000e-12, 1.00000000e+00],\n",
       "       [3.32041760e-03, 9.96389030e-01, 2.90551020e-04]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745179063360881"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745179063360881"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS209     2\n",
       "1       NRS386     1\n",
       "2       NRS148     2\n",
       "3       NRS178     0\n",
       "4       NRS237     0\n",
       "..         ...   ...\n",
       "193     NRS209     2\n",
       "194     NRS002     0\n",
       "195     NRS109     2\n",
       "196  BCH-SA-03     1\n",
       "197  BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 772us/step - loss: 6.1974 - accuracy: 0.3506 - val_loss: 1.3443 - val_accuracy: 0.4091\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 3.7813 - accuracy: 0.5844 - val_loss: 0.9154 - val_accuracy: 0.6970\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 3.7779 - accuracy: 0.6169 - val_loss: 0.8784 - val_accuracy: 0.7374\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 3.6844 - accuracy: 0.6364 - val_loss: 0.8273 - val_accuracy: 0.7424\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 2.9144 - accuracy: 0.6797 - val_loss: 0.8410 - val_accuracy: 0.7626\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 3.0821 - accuracy: 0.6537 - val_loss: 0.7675 - val_accuracy: 0.7374\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 3.4016 - accuracy: 0.6342 - val_loss: 0.7603 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 3.2197 - accuracy: 0.6710 - val_loss: 0.7745 - val_accuracy: 0.8081\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 2.9377 - accuracy: 0.6775 - val_loss: 1.0473 - val_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 2.9385 - accuracy: 0.6775 - val_loss: 0.9683 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 3.1273 - accuracy: 0.6472 - val_loss: 1.1608 - val_accuracy: 0.7626\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 2.9092 - accuracy: 0.6472 - val_loss: 0.9898 - val_accuracy: 0.7980\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 2.6145 - accuracy: 0.6775 - val_loss: 0.9493 - val_accuracy: 0.7475\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 2.9647 - accuracy: 0.6667 - val_loss: 1.2569 - val_accuracy: 0.7323\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 407us/step - loss: 2.7297 - accuracy: 0.6364 - val_loss: 1.0681 - val_accuracy: 0.7980\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 2.4299 - accuracy: 0.6667 - val_loss: 0.9887 - val_accuracy: 0.7929\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 2.5829 - accuracy: 0.6580 - val_loss: 1.0791 - val_accuracy: 0.7929\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 2.6011 - accuracy: 0.6623 - val_loss: 1.0211 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 2.6506 - accuracy: 0.6991 - val_loss: 1.0260 - val_accuracy: 0.8131\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 474us/step - loss: 2.4218 - accuracy: 0.6926 - val_loss: 1.1034 - val_accuracy: 0.8081\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 2.5397 - accuracy: 0.6623 - val_loss: 1.2470 - val_accuracy: 0.7980\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 2.0325 - accuracy: 0.7273 - val_loss: 0.9022 - val_accuracy: 0.8232\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 2.2016 - accuracy: 0.7035 - val_loss: 1.1403 - val_accuracy: 0.7677\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 2.2707 - accuracy: 0.7078 - val_loss: 1.2217 - val_accuracy: 0.7980\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 2.4526 - accuracy: 0.6883 - val_loss: 1.0171 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 2.2528 - accuracy: 0.6948 - val_loss: 1.3601 - val_accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 2.2883 - accuracy: 0.6667 - val_loss: 1.1793 - val_accuracy: 0.8030\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 2.2324 - accuracy: 0.6580 - val_loss: 1.1108 - val_accuracy: 0.7374\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 2.0050 - accuracy: 0.7208 - val_loss: 0.8893 - val_accuracy: 0.7980\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 2.5448 - accuracy: 0.6840 - val_loss: 1.0991 - val_accuracy: 0.7980\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 1.9932 - accuracy: 0.7273 - val_loss: 1.2313 - val_accuracy: 0.8081\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 1.9281 - accuracy: 0.7338 - val_loss: 0.9160 - val_accuracy: 0.8131\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 1.7860 - accuracy: 0.7251 - val_loss: 1.1596 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 2.1729 - accuracy: 0.6926 - val_loss: 1.0012 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 529us/step - loss: 2.0288 - accuracy: 0.7208 - val_loss: 1.0176 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 549us/step - loss: 2.2247 - accuracy: 0.7229 - val_loss: 0.9912 - val_accuracy: 0.8283\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 424us/step - loss: 2.2177 - accuracy: 0.7100 - val_loss: 1.3350 - val_accuracy: 0.8232\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 502us/step - loss: 2.0403 - accuracy: 0.7078 - val_loss: 1.2082 - val_accuracy: 0.7980\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 784us/step - loss: 1.5826 - accuracy: 0.7727 - val_loss: 0.9455 - val_accuracy: 0.7980\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 434us/step - loss: 1.9433 - accuracy: 0.7359 - val_loss: 1.1989 - val_accuracy: 0.7980\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 383us/step - loss: 1.6648 - accuracy: 0.7316 - val_loss: 1.0893 - val_accuracy: 0.8283\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 509us/step - loss: 1.8289 - accuracy: 0.7100 - val_loss: 1.1496 - val_accuracy: 0.8131\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 1.9100 - accuracy: 0.6732 - val_loss: 1.4602 - val_accuracy: 0.7576\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 1.8689 - accuracy: 0.7013 - val_loss: 1.2251 - val_accuracy: 0.8232\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 1.7912 - accuracy: 0.7273 - val_loss: 1.1875 - val_accuracy: 0.8232\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.7069 - accuracy: 0.7359 - val_loss: 1.1422 - val_accuracy: 0.8030\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 1.9363 - accuracy: 0.6861 - val_loss: 0.9381 - val_accuracy: 0.8636\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 1.8929 - accuracy: 0.7121 - val_loss: 1.1874 - val_accuracy: 0.8030\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 1.8688 - accuracy: 0.7186 - val_loss: 1.2867 - val_accuracy: 0.8384\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 1.7657 - accuracy: 0.7446 - val_loss: 1.1978 - val_accuracy: 0.8586\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.8978 - accuracy: 0.7359 - val_loss: 1.2232 - val_accuracy: 0.8384\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.8274 - accuracy: 0.7273 - val_loss: 1.2512 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 482us/step - loss: 1.5298 - accuracy: 0.7511 - val_loss: 1.0107 - val_accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 1.2865 - accuracy: 0.7468 - val_loss: 1.4555 - val_accuracy: 0.8384\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 1.7003 - accuracy: 0.6970 - val_loss: 1.2158 - val_accuracy: 0.8838\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 1.7658 - accuracy: 0.7424 - val_loss: 1.1653 - val_accuracy: 0.8687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.4179 - accuracy: 0.7078 - val_loss: 0.8373 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 1.8928 - accuracy: 0.6667 - val_loss: 1.1149 - val_accuracy: 0.8283\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 1.6061 - accuracy: 0.7338 - val_loss: 0.9136 - val_accuracy: 0.8384\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 1.6161 - accuracy: 0.7316 - val_loss: 1.5014 - val_accuracy: 0.8232\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.4598 - accuracy: 0.7381 - val_loss: 1.4240 - val_accuracy: 0.8434\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.6996 - accuracy: 0.7316 - val_loss: 0.8404 - val_accuracy: 0.9091\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 1.1171 - accuracy: 0.7468 - val_loss: 1.0528 - val_accuracy: 0.8586\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 1.3792 - accuracy: 0.7641 - val_loss: 0.8680 - val_accuracy: 0.8788\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.5909 - accuracy: 0.7468 - val_loss: 1.0354 - val_accuracy: 0.8586\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.2906 - accuracy: 0.7316 - val_loss: 1.1041 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.5463 - accuracy: 0.7229 - val_loss: 0.9951 - val_accuracy: 0.8586\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 1.2950 - accuracy: 0.7576 - val_loss: 0.9089 - val_accuracy: 0.8485\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 1.4550 - accuracy: 0.7338 - val_loss: 0.7838 - val_accuracy: 0.9192\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 1.3997 - accuracy: 0.7424 - val_loss: 1.0071 - val_accuracy: 0.8838\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 1.4097 - accuracy: 0.7143 - val_loss: 1.2859 - val_accuracy: 0.8232\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 1.4825 - accuracy: 0.7229 - val_loss: 0.9063 - val_accuracy: 0.8838\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 1.2392 - accuracy: 0.7381 - val_loss: 0.8427 - val_accuracy: 0.8939\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 1.3460 - accuracy: 0.7792 - val_loss: 0.7816 - val_accuracy: 0.9141\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 1.1837 - accuracy: 0.7338 - val_loss: 0.7822 - val_accuracy: 0.8990\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 1.3134 - accuracy: 0.7554 - val_loss: 0.8882 - val_accuracy: 0.9091\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.1063 - accuracy: 0.7489 - val_loss: 0.9655 - val_accuracy: 0.8788\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 1.4341 - accuracy: 0.7251 - val_loss: 1.0994 - val_accuracy: 0.8737\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 1.4046 - accuracy: 0.7468 - val_loss: 0.8614 - val_accuracy: 0.8889\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.4226 - accuracy: 0.7229 - val_loss: 0.8948 - val_accuracy: 0.8889\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.2460 - accuracy: 0.7554 - val_loss: 1.0566 - val_accuracy: 0.8384\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 1.1514 - accuracy: 0.7424 - val_loss: 1.0209 - val_accuracy: 0.8737\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 1.3987 - accuracy: 0.7381 - val_loss: 1.2280 - val_accuracy: 0.8384\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 1.0694 - accuracy: 0.7944 - val_loss: 0.7635 - val_accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 1.2976 - accuracy: 0.7468 - val_loss: 0.9896 - val_accuracy: 0.8687\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 1.2004 - accuracy: 0.7468 - val_loss: 0.7499 - val_accuracy: 0.9192\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 1.0902 - accuracy: 0.7771 - val_loss: 1.0232 - val_accuracy: 0.8687\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 1.1747 - accuracy: 0.7706 - val_loss: 0.7416 - val_accuracy: 0.8990\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 1.1803 - accuracy: 0.7532 - val_loss: 0.7907 - val_accuracy: 0.8939\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.2259 - accuracy: 0.7489 - val_loss: 0.9168 - val_accuracy: 0.8838\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.3625 - accuracy: 0.7316 - val_loss: 1.3841 - val_accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 1.1061 - accuracy: 0.7727 - val_loss: 0.7472 - val_accuracy: 0.9040\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 1.2831 - accuracy: 0.7489 - val_loss: 0.7729 - val_accuracy: 0.9141\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 1.1977 - accuracy: 0.7597 - val_loss: 1.2618 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 1.4153 - accuracy: 0.7229 - val_loss: 1.4359 - val_accuracy: 0.8788\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 1.6271 - accuracy: 0.7208 - val_loss: 0.7757 - val_accuracy: 0.9091\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 1.0600 - accuracy: 0.7814 - val_loss: 0.7676 - val_accuracy: 0.8889\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 1.3429 - accuracy: 0.7468 - val_loss: 0.8632 - val_accuracy: 0.8990\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.0981 - accuracy: 0.7662 - val_loss: 0.7596 - val_accuracy: 0.9192\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 1.4244 - accuracy: 0.7273 - val_loss: 0.8310 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c949198>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 157us/step\n",
      "over-sampling test accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0,\n",
       "       0, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 0, 0, 0, 2, 0, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 0, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2,\n",
       "       0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 1, 0, 0,\n",
       "       1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 0, 1,\n",
       "       2, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 1, 0, 1, 0,\n",
       "       1, 1, 2, 0, 2, 2, 0, 1, 1, 1, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 2,\n",
       "       1, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1,\n",
       "       0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS209     2     2\n",
       "1       NRS386     1     1\n",
       "2       NRS148     2     2\n",
       "3       NRS178     0     1\n",
       "4       NRS237     0     1\n",
       "..         ...   ...   ...\n",
       "193     NRS209     2     2\n",
       "194     NRS002     0     1\n",
       "195     NRS109     2     2\n",
       "196  BCH-SA-03     1     1\n",
       "197  BCH-SA-03     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3.156084e-02</td>\n",
       "      <td>9.684391e-01</td>\n",
       "      <td>5.647518e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.503430e-08</td>\n",
       "      <td>3.722075e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7.681937e-03</td>\n",
       "      <td>9.922962e-01</td>\n",
       "      <td>2.191572e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>7.681937e-03</td>\n",
       "      <td>9.922962e-01</td>\n",
       "      <td>2.191572e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.790400e-08  4.141849e-08  1.000000e+00\n",
       "1    5.739934e-04  9.994259e-01  6.773014e-08\n",
       "2    5.286934e-09  1.269109e-08  1.000000e+00\n",
       "3    6.494936e-12  1.000000e+00  2.537080e-25\n",
       "4    5.701098e-02  9.399204e-01  3.068583e-03\n",
       "..            ...           ...           ...\n",
       "193  1.790400e-08  4.141849e-08  1.000000e+00\n",
       "194  3.156084e-02  9.684391e-01  5.647518e-09\n",
       "195  1.503430e-08  3.722075e-08  1.000000e+00\n",
       "196  7.681937e-03  9.922962e-01  2.191572e-05\n",
       "197  7.681937e-03  9.922962e-01  2.191572e-05\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 0.9860 - accuracy: 0.7619 - val_loss: 0.7078 - val_accuracy: 0.8737\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.8170 - accuracy: 0.7965 - val_loss: 0.7615 - val_accuracy: 0.8889\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 1.0788 - accuracy: 0.7316 - val_loss: 0.7874 - val_accuracy: 0.8889\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 1.3773 - accuracy: 0.7208 - val_loss: 0.7465 - val_accuracy: 0.8889\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 1.1219 - accuracy: 0.7554 - val_loss: 0.6550 - val_accuracy: 0.8889\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 1.0661 - accuracy: 0.7532 - val_loss: 0.7018 - val_accuracy: 0.8838\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 1.1267 - accuracy: 0.7597 - val_loss: 1.1117 - val_accuracy: 0.8636\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 1.4504 - accuracy: 0.7121 - val_loss: 1.4492 - val_accuracy: 0.8485\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 1.4567 - accuracy: 0.7554 - val_loss: 1.2994 - val_accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.4365 - accuracy: 0.7316 - val_loss: 1.0678 - val_accuracy: 0.8737\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 1.4875 - accuracy: 0.7316 - val_loss: 1.3051 - val_accuracy: 0.8687\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 1.2297 - accuracy: 0.7662 - val_loss: 1.0519 - val_accuracy: 0.8788\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 1.3604 - accuracy: 0.7186 - val_loss: 0.8735 - val_accuracy: 0.8636\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 590us/step - loss: 1.1696 - accuracy: 0.7532 - val_loss: 0.8554 - val_accuracy: 0.8737\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 375us/step - loss: 1.1649 - accuracy: 0.7359 - val_loss: 0.8641 - val_accuracy: 0.8636\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 353us/step - loss: 1.4626 - accuracy: 0.7121 - val_loss: 0.8061 - val_accuracy: 0.8889\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 639us/step - loss: 1.1116 - accuracy: 0.7424 - val_loss: 0.9879 - val_accuracy: 0.8131\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 1.2711 - accuracy: 0.7229 - val_loss: 0.7056 - val_accuracy: 0.8737\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 1.1153 - accuracy: 0.7554 - val_loss: 0.7187 - val_accuracy: 0.8939\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 1.4026 - accuracy: 0.7121 - val_loss: 0.7645 - val_accuracy: 0.8939\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 1.0489 - accuracy: 0.7792 - val_loss: 0.6543 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 344us/step - loss: 1.0709 - accuracy: 0.7532 - val_loss: 0.7282 - val_accuracy: 0.8889\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 1.1021 - accuracy: 0.7727 - val_loss: 0.5835 - val_accuracy: 0.8939\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 1.0659 - accuracy: 0.7468 - val_loss: 1.2846 - val_accuracy: 0.8687\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 1.4450 - accuracy: 0.7316 - val_loss: 0.8124 - val_accuracy: 0.8838\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 1.0946 - accuracy: 0.7403 - val_loss: 0.8580 - val_accuracy: 0.8434\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 1.4448 - accuracy: 0.7143 - val_loss: 0.9077 - val_accuracy: 0.8636\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 409us/step - loss: 1.2847 - accuracy: 0.7576 - val_loss: 1.1838 - val_accuracy: 0.8636\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 1.3335 - accuracy: 0.7359 - val_loss: 0.7850 - val_accuracy: 0.8838\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 1.2678 - accuracy: 0.7489 - val_loss: 1.0719 - val_accuracy: 0.8737\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 1.2619 - accuracy: 0.7944 - val_loss: 0.9134 - val_accuracy: 0.9141\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 420us/step - loss: 1.1264 - accuracy: 0.7229 - val_loss: 1.0665 - val_accuracy: 0.9293\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 516us/step - loss: 1.1313 - accuracy: 0.7468 - val_loss: 0.8392 - val_accuracy: 0.9141\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 478us/step - loss: 1.3433 - accuracy: 0.7446 - val_loss: 1.5444 - val_accuracy: 0.8889\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.2164 - accuracy: 0.7186 - val_loss: 0.8776 - val_accuracy: 0.8838\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 1.1570 - accuracy: 0.7403 - val_loss: 0.7116 - val_accuracy: 0.9040\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 713us/step - loss: 0.9791 - accuracy: 0.7684 - val_loss: 0.6497 - val_accuracy: 0.8889\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 849us/step - loss: 1.1487 - accuracy: 0.7381 - val_loss: 1.0128 - val_accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 1.1772 - accuracy: 0.7511 - val_loss: 1.8084 - val_accuracy: 0.8788\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 1.2936 - accuracy: 0.7511 - val_loss: 1.6339 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 1.3902 - accuracy: 0.7641 - val_loss: 0.8854 - val_accuracy: 0.8283\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.2156 - accuracy: 0.7511 - val_loss: 1.1193 - val_accuracy: 0.8384\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 1.1226 - accuracy: 0.7359 - val_loss: 0.7987 - val_accuracy: 0.8687\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 605us/step - loss: 1.1478 - accuracy: 0.7641 - val_loss: 1.0555 - val_accuracy: 0.8737\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 377us/step - loss: 1.3780 - accuracy: 0.7251 - val_loss: 0.7971 - val_accuracy: 0.8788\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 524us/step - loss: 1.1985 - accuracy: 0.7706 - val_loss: 1.0414 - val_accuracy: 0.8838\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 1.1135 - accuracy: 0.7424 - val_loss: 0.8068 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 0.9187 - accuracy: 0.7597 - val_loss: 0.8656 - val_accuracy: 0.9141\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.9652 - accuracy: 0.7489 - val_loss: 0.8937 - val_accuracy: 0.8788\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 1.2249 - accuracy: 0.7835 - val_loss: 0.9468 - val_accuracy: 0.8838\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.8745 - accuracy: 0.7771 - val_loss: 0.8788 - val_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 473us/step - loss: 1.0308 - accuracy: 0.7662 - val_loss: 1.1162 - val_accuracy: 0.8384\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 1.1127 - accuracy: 0.7554 - val_loss: 0.9284 - val_accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 1.1870 - accuracy: 0.7511 - val_loss: 1.0478 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 1.0351 - accuracy: 0.7468 - val_loss: 0.8708 - val_accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 458us/step - loss: 0.9000 - accuracy: 0.7597 - val_loss: 0.9694 - val_accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 462us/step - loss: 1.1008 - accuracy: 0.7208 - val_loss: 1.6672 - val_accuracy: 0.8889\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 1.2066 - accuracy: 0.7359 - val_loss: 0.8819 - val_accuracy: 0.8788\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 1.1541 - accuracy: 0.7338 - val_loss: 1.1870 - val_accuracy: 0.8636\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 1.4143 - accuracy: 0.7532 - val_loss: 1.1872 - val_accuracy: 0.8687\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 505us/step - loss: 1.2395 - accuracy: 0.7511 - val_loss: 1.0338 - val_accuracy: 0.8636\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 695us/step - loss: 1.1043 - accuracy: 0.7316 - val_loss: 0.9848 - val_accuracy: 0.8990\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 1.3341 - accuracy: 0.7468 - val_loss: 2.1759 - val_accuracy: 0.8232\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 1.5142 - accuracy: 0.7143 - val_loss: 1.5367 - val_accuracy: 0.8788\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 1.1844 - accuracy: 0.7619 - val_loss: 0.7909 - val_accuracy: 0.8586\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 1.1961 - accuracy: 0.7489 - val_loss: 1.1066 - val_accuracy: 0.8737\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 1.0584 - accuracy: 0.7597 - val_loss: 0.8888 - val_accuracy: 0.8535\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 1.0550 - accuracy: 0.7511 - val_loss: 0.9788 - val_accuracy: 0.8737\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 1.2675 - accuracy: 0.7619 - val_loss: 1.0286 - val_accuracy: 0.8737\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.0122 - accuracy: 0.7532 - val_loss: 1.9204 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 587us/step - loss: 1.1657 - accuracy: 0.7554 - val_loss: 0.9940 - val_accuracy: 0.8586\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 1.0973 - accuracy: 0.7597 - val_loss: 0.8686 - val_accuracy: 0.8838\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 1.0084 - accuracy: 0.7662 - val_loss: 1.0096 - val_accuracy: 0.8939\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.0943 - accuracy: 0.7771 - val_loss: 0.9049 - val_accuracy: 0.8889\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 1.0674 - accuracy: 0.7619 - val_loss: 0.7071 - val_accuracy: 0.8990\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 1.0214 - accuracy: 0.7814 - val_loss: 0.7369 - val_accuracy: 0.8889\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.9787 - accuracy: 0.7381 - val_loss: 1.0178 - val_accuracy: 0.8687\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 1.2391 - accuracy: 0.7597 - val_loss: 1.2195 - val_accuracy: 0.8535\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 1.4527 - accuracy: 0.7165 - val_loss: 1.4270 - val_accuracy: 0.8586\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 1.3566 - accuracy: 0.7468 - val_loss: 1.2106 - val_accuracy: 0.8283\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.2539 - accuracy: 0.7554 - val_loss: 1.1404 - val_accuracy: 0.8838\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.2349 - accuracy: 0.7619 - val_loss: 1.0611 - val_accuracy: 0.9040\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 1.2495 - accuracy: 0.7511 - val_loss: 1.2347 - val_accuracy: 0.8939\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 822us/step - loss: 1.0061 - accuracy: 0.7597 - val_loss: 1.3271 - val_accuracy: 0.9040\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 516us/step - loss: 1.1108 - accuracy: 0.7597 - val_loss: 1.2861 - val_accuracy: 0.8485\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 481us/step - loss: 1.2704 - accuracy: 0.7771 - val_loss: 0.8009 - val_accuracy: 0.8636\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 1.2744 - accuracy: 0.7554 - val_loss: 0.8840 - val_accuracy: 0.8889\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 1.0021 - accuracy: 0.7554 - val_loss: 1.1010 - val_accuracy: 0.8838\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 440us/step - loss: 1.0905 - accuracy: 0.7489 - val_loss: 0.9701 - val_accuracy: 0.8788\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 492us/step - loss: 0.9960 - accuracy: 0.7792 - val_loss: 0.8038 - val_accuracy: 0.8990\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 502us/step - loss: 1.0161 - accuracy: 0.7792 - val_loss: 0.8700 - val_accuracy: 0.8889\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 376us/step - loss: 1.0154 - accuracy: 0.7338 - val_loss: 0.9344 - val_accuracy: 0.8586\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 528us/step - loss: 1.0521 - accuracy: 0.7965 - val_loss: 0.8318 - val_accuracy: 0.8939\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 511us/step - loss: 0.9408 - accuracy: 0.7446 - val_loss: 1.0636 - val_accuracy: 0.8990\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 633us/step - loss: 0.9590 - accuracy: 0.7597 - val_loss: 1.3422 - val_accuracy: 0.8737\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 627us/step - loss: 1.2826 - accuracy: 0.7468 - val_loss: 1.8686 - val_accuracy: 0.8737\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 657us/step - loss: 1.7514 - accuracy: 0.7489 - val_loss: 1.8041 - val_accuracy: 0.8737\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 533us/step - loss: 1.2498 - accuracy: 0.7511 - val_loss: 1.3934 - val_accuracy: 0.9141\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 427us/step - loss: 1.1897 - accuracy: 0.7576 - val_loss: 1.4949 - val_accuracy: 0.8939\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.2145 - accuracy: 0.7792 - val_loss: 1.4353 - val_accuracy: 0.8939\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.08%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [5.73993370e-04, 9.99425900e-01, 6.77301400e-08],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [6.49493600e-12, 1.00000000e+00, 2.53707970e-25],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [1.54960120e-08, 1.00000000e+00, 7.12019400e-18],\n",
       "       [7.68193000e-03, 9.92296160e-01, 2.19156830e-05],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.54960120e-08, 1.00000000e+00, 7.12019400e-18],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [5.73993370e-04, 9.99425900e-01, 6.77301400e-08],\n",
       "       [2.52260520e-06, 9.99997500e-01, 5.17447700e-13],\n",
       "       [9.84662600e-06, 9.99990100e-01, 3.82570170e-10],\n",
       "       [2.27302350e-09, 1.00000000e+00, 1.90519700e-21],\n",
       "       [8.51542300e-01, 1.48454870e-01, 2.79731240e-06],\n",
       "       [7.68193000e-03, 9.92296160e-01, 2.19156830e-05],\n",
       "       [9.99984600e-01, 1.51759790e-05, 2.93080030e-07],\n",
       "       [1.84558290e-04, 9.99815400e-01, 1.64276460e-07],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [6.78517240e-11, 1.00000000e+00, 4.68932120e-23],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [9.69635000e-01, 3.03650480e-02, 1.02887850e-08],\n",
       "       [1.00000000e+00, 1.48775940e-13, 1.19108570e-16],\n",
       "       [8.03172000e-01, 1.95879160e-01, 9.48854800e-04],\n",
       "       [4.41966600e-09, 1.00000000e+00, 4.51755400e-19],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [4.15569070e-11, 1.00000000e+00, 1.57567100e-23],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.00261460e-11, 2.97399760e-18],\n",
       "       [3.13843750e-04, 9.99686100e-01, 6.38919500e-17],\n",
       "       [9.99984600e-01, 1.51759790e-05, 2.93080030e-07],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [9.82694570e-01, 1.72997040e-02, 5.75591370e-06],\n",
       "       [9.81234850e-01, 1.87651590e-02, 3.15782300e-09],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [9.97150840e-01, 2.84922960e-03, 1.29102950e-15],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.84558290e-04, 9.99815400e-01, 1.64276460e-07],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.64301580e-06, 9.99998330e-01, 2.01634340e-13],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.53350450e-11, 1.64882660e-17],\n",
       "       [9.99999900e-01, 6.70586360e-08, 1.34123850e-13],\n",
       "       [1.19033360e-09, 1.00000000e+00, 2.52785070e-20],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.44806280e-14, 7.49914700e-23],\n",
       "       [2.75035030e-07, 9.99999760e-01, 3.96536360e-15],\n",
       "       [5.29410600e-10, 1.00000000e+00, 4.27082000e-21],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.55685480e-10, 1.00000000e+00, 1.45274460e-31],\n",
       "       [5.29410600e-10, 1.00000000e+00, 4.27082000e-21],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [2.14702270e-11, 1.00000000e+00, 3.62622440e-24],\n",
       "       [3.22491700e-02, 9.67051740e-01, 6.99114700e-04],\n",
       "       [1.04911760e-06, 9.99998900e-01, 3.86815760e-15],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.38749870e-16, 4.03751200e-25],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [7.88186870e-07, 9.99999170e-01, 4.01184550e-14],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [2.27302350e-09, 1.00000000e+00, 1.90519700e-21],\n",
       "       [1.00000000e+00, 5.00261460e-11, 2.97399760e-18],\n",
       "       [7.68193000e-03, 9.92296160e-01, 2.19156830e-05],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [8.11168300e-01, 1.88804500e-01, 2.72056820e-05],\n",
       "       [7.67449500e-12, 1.00000000e+00, 3.62448280e-16],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [4.40721540e-13, 1.00000000e+00, 2.42508610e-17],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [4.15569070e-11, 1.00000000e+00, 1.57567100e-23],\n",
       "       [1.00000000e+00, 3.95686840e-17, 5.33633830e-26],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.59725700e-13, 7.20572400e-24],\n",
       "       [1.55685480e-10, 1.00000000e+00, 1.45274460e-31],\n",
       "       [9.99999500e-01, 5.10108600e-07, 6.53483900e-14],\n",
       "       [1.00000000e+00, 3.60217970e-09, 9.76075100e-16],\n",
       "       [2.66198600e-01, 7.33781930e-01, 1.95046090e-05],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [8.11168300e-01, 1.88804500e-01, 2.72056820e-05],\n",
       "       [6.60631770e-09, 1.00000000e+00, 1.09300890e-18],\n",
       "       [1.00000000e+00, 2.99460370e-10, 2.10601230e-16],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [8.11168300e-01, 1.88804500e-01, 2.72056820e-05],\n",
       "       [1.00000000e+00, 3.60217970e-09, 9.76075100e-16],\n",
       "       [3.49704710e-06, 9.99996540e-01, 1.06089050e-12],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [2.27302350e-09, 1.00000000e+00, 1.90519700e-21],\n",
       "       [5.73993370e-04, 9.99425900e-01, 6.77301400e-08],\n",
       "       [6.78517240e-11, 1.00000000e+00, 4.68932120e-23],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [6.60631770e-09, 1.00000000e+00, 1.09300890e-18],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.64301580e-06, 9.99998330e-01, 2.01634340e-13],\n",
       "       [1.00000000e+00, 2.29144220e-08, 4.87629100e-15],\n",
       "       [2.06691300e-13, 1.00000000e+00, 3.39668930e-30],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [3.13843750e-04, 9.99686100e-01, 6.38919500e-17],\n",
       "       [9.98722260e-01, 1.27774400e-03, 1.35866960e-16],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [3.13843750e-04, 9.99686100e-01, 6.38919500e-17],\n",
       "       [1.64301580e-06, 9.99998330e-01, 2.01634340e-13],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [2.27302350e-09, 1.00000000e+00, 1.90519700e-21],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.55685480e-10, 1.00000000e+00, 1.45274460e-31],\n",
       "       [9.84662600e-06, 9.99990100e-01, 3.82570170e-10],\n",
       "       [1.64301580e-06, 9.99998330e-01, 2.01634340e-13],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.55563750e-10, 2.02707030e-17],\n",
       "       [1.04911760e-06, 9.99998900e-01, 3.86815760e-15],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [9.32409500e-02, 9.06758900e-01, 8.93566540e-08],\n",
       "       [1.00000000e+00, 3.44806280e-14, 7.49914700e-23],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [4.10490200e-15, 1.00000000e+00, 3.37583170e-20],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [8.11168300e-01, 1.88804500e-01, 2.72056820e-05],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [8.51542300e-01, 1.48454870e-01, 2.79731240e-06],\n",
       "       [6.78517240e-11, 1.00000000e+00, 4.68932120e-23],\n",
       "       [1.03154960e-01, 8.93365860e-01, 3.47914150e-03],\n",
       "       [3.10289570e-11, 1.00000000e+00, 8.22665250e-24],\n",
       "       [4.10490200e-15, 1.00000000e+00, 3.37583170e-20],\n",
       "       [9.98645370e-01, 1.35464350e-03, 8.16882200e-16],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [9.99041000e-01, 9.58927440e-04, 1.22095420e-15],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [1.00000000e+00, 1.54012620e-10, 2.55228900e-19],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.58272050e-09, 6.45771670e-16],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [2.14702270e-11, 1.00000000e+00, 3.62622440e-24],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.19033360e-09, 1.00000000e+00, 2.52785070e-20],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [8.51542300e-01, 1.48454870e-01, 2.79731240e-06],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.44302250e-10, 1.63340740e-17],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.00261460e-11, 2.97399760e-18],\n",
       "       [1.00000000e+00, 1.60773450e-09, 3.34300400e-25],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [4.40721540e-13, 1.00000000e+00, 2.42508610e-17],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [8.51542300e-01, 1.48454870e-01, 2.79731240e-06],\n",
       "       [9.03181700e-01, 9.68178300e-02, 4.00835570e-07],\n",
       "       [5.73993370e-04, 9.99425900e-01, 6.77301400e-08],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.01969220e-07, 9.99999900e-01, 3.65329970e-16],\n",
       "       [9.11869760e-01, 8.81079960e-02, 2.22796790e-05],\n",
       "       [7.68193000e-03, 9.92296160e-01, 2.19156830e-05],\n",
       "       [3.10289570e-11, 1.00000000e+00, 8.22665250e-24],\n",
       "       [1.00000000e+00, 2.99460370e-10, 2.10601230e-16],\n",
       "       [7.37569900e-01, 2.61393700e-01, 1.03635930e-03],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [1.55685480e-10, 1.00000000e+00, 1.45274460e-31],\n",
       "       [9.98907570e-01, 1.09239910e-03, 1.78761260e-15],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [4.40721540e-13, 1.00000000e+00, 2.42508610e-17],\n",
       "       [4.40721540e-13, 1.00000000e+00, 2.42508610e-17],\n",
       "       [9.93039970e-01, 6.96006040e-03, 4.15695200e-15],\n",
       "       [5.28693440e-09, 1.26910935e-08, 1.00000000e+00],\n",
       "       [1.54960120e-08, 1.00000000e+00, 7.12019400e-18],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [5.70109800e-02, 9.39920370e-01, 3.06858290e-03],\n",
       "       [1.79040020e-08, 4.14184900e-08, 1.00000000e+00],\n",
       "       [3.15608420e-02, 9.68439100e-01, 5.64751800e-09],\n",
       "       [1.50342960e-08, 3.72207470e-08, 1.00000000e+00],\n",
       "       [7.68193740e-03, 9.92296160e-01, 2.19157250e-05],\n",
       "       [7.68193740e-03, 9.92296160e-01, 2.19157250e-05]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966215182124273"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966215182124273"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS209     2\n",
       "1      BCH-SA-09     1\n",
       "2         NRS224     0\n",
       "3         NRS209     2\n",
       "4         NRS235     1\n",
       "..           ...   ...\n",
       "193       NRS209     2\n",
       "194  CFBREBSa131     1\n",
       "195  CFBREBSa103     0\n",
       "196       NRS188     1\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 808us/step - loss: 6.3052 - accuracy: 0.4177 - val_loss: 2.6459 - val_accuracy: 0.6313\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 478us/step - loss: 4.2037 - accuracy: 0.5455 - val_loss: 1.6030 - val_accuracy: 0.7222\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 469us/step - loss: 3.6331 - accuracy: 0.5649 - val_loss: 1.2393 - val_accuracy: 0.7071\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 473us/step - loss: 3.4023 - accuracy: 0.5887 - val_loss: 1.2671 - val_accuracy: 0.6616\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 3.3145 - accuracy: 0.6234 - val_loss: 1.1075 - val_accuracy: 0.6919\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 439us/step - loss: 3.6862 - accuracy: 0.5844 - val_loss: 1.3027 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 832us/step - loss: 3.0736 - accuracy: 0.5844 - val_loss: 1.3394 - val_accuracy: 0.7172\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 2.7895 - accuracy: 0.6039 - val_loss: 1.5599 - val_accuracy: 0.7172\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 2.4366 - accuracy: 0.6126 - val_loss: 1.7630 - val_accuracy: 0.7020\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 3.0104 - accuracy: 0.5974 - val_loss: 1.4532 - val_accuracy: 0.7323\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 2.4334 - accuracy: 0.6212 - val_loss: 1.7653 - val_accuracy: 0.7020\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 2.5561 - accuracy: 0.6385 - val_loss: 1.7321 - val_accuracy: 0.7525\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 2.7943 - accuracy: 0.6407 - val_loss: 1.4813 - val_accuracy: 0.6970\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 2.8693 - accuracy: 0.6082 - val_loss: 1.7792 - val_accuracy: 0.7374\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 2.2848 - accuracy: 0.6688 - val_loss: 1.3984 - val_accuracy: 0.7525\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 2.1303 - accuracy: 0.6450 - val_loss: 1.3039 - val_accuracy: 0.7172\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 2.2942 - accuracy: 0.6667 - val_loss: 1.0662 - val_accuracy: 0.7727\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 2.3611 - accuracy: 0.6472 - val_loss: 1.3469 - val_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 2.5725 - accuracy: 0.6385 - val_loss: 1.3299 - val_accuracy: 0.7828\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 2.2256 - accuracy: 0.6494 - val_loss: 1.4386 - val_accuracy: 0.7626\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 2.2534 - accuracy: 0.6364 - val_loss: 1.0696 - val_accuracy: 0.7929\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 2.2200 - accuracy: 0.6320 - val_loss: 1.2684 - val_accuracy: 0.7828\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 2.5951 - accuracy: 0.6429 - val_loss: 1.2176 - val_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 2.3861 - accuracy: 0.6667 - val_loss: 1.3400 - val_accuracy: 0.7677\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 2.5917 - accuracy: 0.6234 - val_loss: 1.2250 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 2.3925 - accuracy: 0.6364 - val_loss: 1.0505 - val_accuracy: 0.8232\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 1.9877 - accuracy: 0.6602 - val_loss: 1.2853 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 2.2680 - accuracy: 0.7056 - val_loss: 1.0584 - val_accuracy: 0.7929\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 2.4020 - accuracy: 0.6645 - val_loss: 1.3527 - val_accuracy: 0.7576\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 2.0190 - accuracy: 0.6515 - val_loss: 1.2139 - val_accuracy: 0.7525\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 2.0104 - accuracy: 0.6840 - val_loss: 1.1616 - val_accuracy: 0.7828\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 2.1003 - accuracy: 0.6515 - val_loss: 1.1470 - val_accuracy: 0.7929\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 2.0620 - accuracy: 0.6753 - val_loss: 1.0881 - val_accuracy: 0.8030\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 2.1052 - accuracy: 0.6861 - val_loss: 1.0047 - val_accuracy: 0.7828\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 546us/step - loss: 2.2716 - accuracy: 0.6753 - val_loss: 1.1921 - val_accuracy: 0.6717\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 2.6013 - accuracy: 0.6407 - val_loss: 1.2313 - val_accuracy: 0.7626\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 1.7207 - accuracy: 0.6775 - val_loss: 0.9034 - val_accuracy: 0.7980\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.8020 - accuracy: 0.6840 - val_loss: 0.9586 - val_accuracy: 0.7929\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 2.0898 - accuracy: 0.6364 - val_loss: 0.9692 - val_accuracy: 0.7727\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 1.9549 - accuracy: 0.6688 - val_loss: 0.9660 - val_accuracy: 0.7929\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 2.1001 - accuracy: 0.6775 - val_loss: 1.7700 - val_accuracy: 0.7677\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 2.2252 - accuracy: 0.6537 - val_loss: 1.0566 - val_accuracy: 0.6970\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 1.9760 - accuracy: 0.6623 - val_loss: 0.9205 - val_accuracy: 0.7727\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 2.1288 - accuracy: 0.6905 - val_loss: 0.6931 - val_accuracy: 0.8687\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 1.8144 - accuracy: 0.6580 - val_loss: 0.7755 - val_accuracy: 0.7929\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 1.9964 - accuracy: 0.6840 - val_loss: 0.8705 - val_accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.6808 - accuracy: 0.7165 - val_loss: 1.1634 - val_accuracy: 0.8030\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 2.0476 - accuracy: 0.6861 - val_loss: 0.7266 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 1.9746 - accuracy: 0.7013 - val_loss: 0.7166 - val_accuracy: 0.8535\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 2.0298 - accuracy: 0.6688 - val_loss: 0.7338 - val_accuracy: 0.8384\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.6131 - accuracy: 0.7338 - val_loss: 0.7574 - val_accuracy: 0.8636\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 1.8823 - accuracy: 0.6753 - val_loss: 0.8384 - val_accuracy: 0.8283\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 1.9945 - accuracy: 0.6818 - val_loss: 1.0390 - val_accuracy: 0.7980\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 1.5829 - accuracy: 0.6926 - val_loss: 0.6912 - val_accuracy: 0.8838\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 1.9060 - accuracy: 0.6818 - val_loss: 0.7694 - val_accuracy: 0.8535\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.9387 - accuracy: 0.6580 - val_loss: 0.7162 - val_accuracy: 0.8485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 1.8372 - accuracy: 0.6905 - val_loss: 1.0593 - val_accuracy: 0.7828\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.9578 - accuracy: 0.6926 - val_loss: 0.9821 - val_accuracy: 0.8283\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 1.5771 - accuracy: 0.7294 - val_loss: 0.8123 - val_accuracy: 0.8131\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 1.4708 - accuracy: 0.7143 - val_loss: 0.6732 - val_accuracy: 0.8636\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 1.8062 - accuracy: 0.6883 - val_loss: 0.7497 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 1.4919 - accuracy: 0.7100 - val_loss: 0.6637 - val_accuracy: 0.8990\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 353us/step - loss: 1.6543 - accuracy: 0.7403 - val_loss: 0.7113 - val_accuracy: 0.8838\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 1.5873 - accuracy: 0.7186 - val_loss: 0.7109 - val_accuracy: 0.8232\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.4254 - accuracy: 0.7229 - val_loss: 0.6642 - val_accuracy: 0.8485\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 1.7604 - accuracy: 0.7273 - val_loss: 0.6487 - val_accuracy: 0.8485\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 1.5827 - accuracy: 0.7424 - val_loss: 0.6235 - val_accuracy: 0.9091\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.7310 - accuracy: 0.7143 - val_loss: 0.6954 - val_accuracy: 0.8990\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 1.4537 - accuracy: 0.7208 - val_loss: 0.7087 - val_accuracy: 0.8586\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 1.4907 - accuracy: 0.7273 - val_loss: 0.7594 - val_accuracy: 0.8131\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.5760 - accuracy: 0.6991 - val_loss: 0.6933 - val_accuracy: 0.8485\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 1.6836 - accuracy: 0.7165 - val_loss: 0.6731 - val_accuracy: 0.8586\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 1.5190 - accuracy: 0.7468 - val_loss: 1.4368 - val_accuracy: 0.8131\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.8036 - accuracy: 0.7078 - val_loss: 0.7574 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 1.6050 - accuracy: 0.7294 - val_loss: 1.1934 - val_accuracy: 0.8131\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 429us/step - loss: 1.8531 - accuracy: 0.6970 - val_loss: 1.2122 - val_accuracy: 0.8535\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 361us/step - loss: 1.7512 - accuracy: 0.7273 - val_loss: 0.7983 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 340us/step - loss: 1.5245 - accuracy: 0.7294 - val_loss: 0.6257 - val_accuracy: 0.8939\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 1.2391 - accuracy: 0.7749 - val_loss: 0.6781 - val_accuracy: 0.8838\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 1.4661 - accuracy: 0.7143 - val_loss: 0.6689 - val_accuracy: 0.8889\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.6210 - accuracy: 0.7294 - val_loss: 0.7167 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 1.4626 - accuracy: 0.7532 - val_loss: 0.6535 - val_accuracy: 0.8939\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 1.6045 - accuracy: 0.7143 - val_loss: 0.5624 - val_accuracy: 0.9192\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 1.5918 - accuracy: 0.7294 - val_loss: 0.6625 - val_accuracy: 0.8687\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 1.4813 - accuracy: 0.7684 - val_loss: 0.7438 - val_accuracy: 0.8838\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 1.3616 - accuracy: 0.7381 - val_loss: 0.6072 - val_accuracy: 0.9192\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 1.3357 - accuracy: 0.7662 - val_loss: 0.6796 - val_accuracy: 0.8788\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.4739 - accuracy: 0.7468 - val_loss: 0.7635 - val_accuracy: 0.8990\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 1.7014 - accuracy: 0.7165 - val_loss: 0.8962 - val_accuracy: 0.9040\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 1.4478 - accuracy: 0.7403 - val_loss: 0.9700 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.4469 - accuracy: 0.7597 - val_loss: 0.6656 - val_accuracy: 0.9141\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.1996 - accuracy: 0.7727 - val_loss: 0.6861 - val_accuracy: 0.8990\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 1.2942 - accuracy: 0.7424 - val_loss: 0.7180 - val_accuracy: 0.8990\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 1.2781 - accuracy: 0.7597 - val_loss: 0.5829 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 1.5099 - accuracy: 0.7359 - val_loss: 1.2245 - val_accuracy: 0.8586\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.5340 - accuracy: 0.7165 - val_loss: 1.0879 - val_accuracy: 0.8687\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 1.5546 - accuracy: 0.7273 - val_loss: 1.2262 - val_accuracy: 0.8434\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 1.7802 - accuracy: 0.7338 - val_loss: 1.1831 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 1.6392 - accuracy: 0.7446 - val_loss: 1.4002 - val_accuracy: 0.8586\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 1.6002 - accuracy: 0.7056 - val_loss: 1.2825 - val_accuracy: 0.8535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d505470>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 143us/step\n",
      "over-sampling test accuracy: 84.85%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0,\n",
       "       2, 0, 0, 2, 1, 0, 1, 0, 1, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 1, 2, 0,\n",
       "       2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 1, 0,\n",
       "       0, 2, 0, 2, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 1,\n",
       "       1, 0, 2, 2, 2, 2, 2, 1, 0, 2, 1, 0, 1, 2, 0, 0, 2, 1, 2, 0, 1, 1,\n",
       "       2, 2, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2,\n",
       "       0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 2,\n",
       "       0, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS209     2     2\n",
       "1      BCH-SA-09     1     1\n",
       "2         NRS224     0     0\n",
       "3         NRS209     2     2\n",
       "4         NRS235     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS209     2     2\n",
       "194  CFBREBSa131     1     0\n",
       "195  CFBREBSa103     0     0\n",
       "196       NRS188     1     1\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093109e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.243512e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.609111e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.554443e-18</td>\n",
       "      <td>8.619599e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.033436e-24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.421581e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8.301247e-22</td>\n",
       "      <td>9.958557e-21</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    8.300497e-12  1.036520e-09  1.000000e+00\n",
       "1    1.137139e-06  9.999988e-01  2.067601e-09\n",
       "2    1.000000e+00  2.093109e-31  0.000000e+00\n",
       "3    8.300497e-12  1.036520e-09  1.000000e+00\n",
       "4    2.243512e-02  9.774035e-01  1.615106e-04\n",
       "..            ...           ...           ...\n",
       "193  8.300497e-12  1.036520e-09  1.000000e+00\n",
       "194  1.000000e+00  1.609111e-29  0.000000e+00\n",
       "195  1.000000e+00  3.554443e-18  8.619599e-28\n",
       "196  1.033436e-24  1.000000e+00  4.421581e-35\n",
       "197  8.301247e-22  9.958557e-21  1.000000e+00\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.6578 - accuracy: 0.6905 - val_loss: 1.0423 - val_accuracy: 0.8535\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 1.5900 - accuracy: 0.7186 - val_loss: 0.8690 - val_accuracy: 0.8485\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 1.5007 - accuracy: 0.7229 - val_loss: 1.0957 - val_accuracy: 0.8485\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 1.5462 - accuracy: 0.7208 - val_loss: 1.0411 - val_accuracy: 0.8636\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 1.6530 - accuracy: 0.6905 - val_loss: 0.9831 - val_accuracy: 0.8485\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 1.5349 - accuracy: 0.7446 - val_loss: 1.0328 - val_accuracy: 0.8384\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 467us/step - loss: 1.4137 - accuracy: 0.7468 - val_loss: 1.2189 - val_accuracy: 0.8485\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 1.6404 - accuracy: 0.7013 - val_loss: 0.9452 - val_accuracy: 0.8636\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 601us/step - loss: 1.6318 - accuracy: 0.7273 - val_loss: 0.9512 - val_accuracy: 0.8737\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 1.3011 - accuracy: 0.7294 - val_loss: 1.1727 - val_accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 1.5391 - accuracy: 0.7208 - val_loss: 1.0928 - val_accuracy: 0.8788\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 418us/step - loss: 1.7242 - accuracy: 0.7100 - val_loss: 1.4142 - val_accuracy: 0.8535\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 1.6662 - accuracy: 0.7121 - val_loss: 1.3455 - val_accuracy: 0.8535\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 1.5760 - accuracy: 0.7359 - val_loss: 0.9545 - val_accuracy: 0.8434\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 1.3699 - accuracy: 0.7489 - val_loss: 1.3333 - val_accuracy: 0.8535\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 1.6237 - accuracy: 0.7186 - val_loss: 1.3067 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 1.8093 - accuracy: 0.6710 - val_loss: 1.4247 - val_accuracy: 0.8434\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 1.7337 - accuracy: 0.7186 - val_loss: 1.3282 - val_accuracy: 0.8384\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 656us/step - loss: 1.8603 - accuracy: 0.6840 - val_loss: 1.0180 - val_accuracy: 0.8687\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 686us/step - loss: 1.5184 - accuracy: 0.7143 - val_loss: 1.1218 - val_accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 934us/step - loss: 1.5054 - accuracy: 0.7597 - val_loss: 1.0829 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 572us/step - loss: 1.5040 - accuracy: 0.7208 - val_loss: 1.2473 - val_accuracy: 0.8535\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 559us/step - loss: 1.8032 - accuracy: 0.7056 - val_loss: 1.0363 - val_accuracy: 0.8737\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 1.3910 - accuracy: 0.7186 - val_loss: 0.9620 - val_accuracy: 0.8384\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 586us/step - loss: 1.7350 - accuracy: 0.7035 - val_loss: 1.1688 - val_accuracy: 0.8434\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 683us/step - loss: 1.6869 - accuracy: 0.7121 - val_loss: 1.1158 - val_accuracy: 0.8535\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 635us/step - loss: 1.3311 - accuracy: 0.6926 - val_loss: 1.0786 - val_accuracy: 0.8687\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 837us/step - loss: 1.5814 - accuracy: 0.7273 - val_loss: 1.1459 - val_accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 825us/step - loss: 1.4873 - accuracy: 0.7273 - val_loss: 1.3426 - val_accuracy: 0.8485\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 659us/step - loss: 1.5034 - accuracy: 0.6970 - val_loss: 1.2062 - val_accuracy: 0.8636\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 649us/step - loss: 1.6520 - accuracy: 0.7294 - val_loss: 1.6222 - val_accuracy: 0.8434\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 1.7415 - accuracy: 0.7100 - val_loss: 1.4233 - val_accuracy: 0.8434\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 1.9149 - accuracy: 0.6905 - val_loss: 1.6847 - val_accuracy: 0.8434\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 644us/step - loss: 1.7627 - accuracy: 0.6797 - val_loss: 1.0351 - val_accuracy: 0.8636\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 560us/step - loss: 1.5579 - accuracy: 0.7359 - val_loss: 1.0903 - val_accuracy: 0.8434\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 1s 2ms/step - loss: 1.5209 - accuracy: 0.7338 - val_loss: 0.9357 - val_accuracy: 0.8687\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 659us/step - loss: 1.7693 - accuracy: 0.6970 - val_loss: 1.2051 - val_accuracy: 0.8687\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 638us/step - loss: 1.6160 - accuracy: 0.7273 - val_loss: 1.1779 - val_accuracy: 0.8434\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 738us/step - loss: 1.8699 - accuracy: 0.7143 - val_loss: 1.3005 - val_accuracy: 0.8384\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 670us/step - loss: 1.8237 - accuracy: 0.7143 - val_loss: 1.2977 - val_accuracy: 0.8283\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 557us/step - loss: 1.8246 - accuracy: 0.7013 - val_loss: 1.2284 - val_accuracy: 0.8535\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 605us/step - loss: 1.7190 - accuracy: 0.7143 - val_loss: 1.1434 - val_accuracy: 0.8232\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 713us/step - loss: 1.7448 - accuracy: 0.6948 - val_loss: 1.3144 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 670us/step - loss: 1.7189 - accuracy: 0.7294 - val_loss: 1.0536 - val_accuracy: 0.8586\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 420us/step - loss: 1.9405 - accuracy: 0.7013 - val_loss: 1.3229 - val_accuracy: 0.8687\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 687us/step - loss: 1.8119 - accuracy: 0.7078 - val_loss: 1.3405 - val_accuracy: 0.8434\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 1.7322 - accuracy: 0.7251 - val_loss: 1.2768 - val_accuracy: 0.8636\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 673us/step - loss: 1.5696 - accuracy: 0.7511 - val_loss: 1.1836 - val_accuracy: 0.8636\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 492us/step - loss: 1.8578 - accuracy: 0.7446 - val_loss: 1.2863 - val_accuracy: 0.8586\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 796us/step - loss: 1.8603 - accuracy: 0.7035 - val_loss: 1.2666 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 604us/step - loss: 1.7303 - accuracy: 0.7100 - val_loss: 1.1772 - val_accuracy: 0.8384\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 497us/step - loss: 1.8011 - accuracy: 0.6753 - val_loss: 1.4470 - val_accuracy: 0.8434\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 563us/step - loss: 1.5373 - accuracy: 0.7424 - val_loss: 1.3567 - val_accuracy: 0.8586\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 663us/step - loss: 1.5590 - accuracy: 0.7359 - val_loss: 1.3260 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 577us/step - loss: 1.5918 - accuracy: 0.7229 - val_loss: 1.3424 - val_accuracy: 0.8232\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 1.7713 - accuracy: 0.7273 - val_loss: 1.2530 - val_accuracy: 0.8586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 1.5539 - accuracy: 0.7316 - val_loss: 1.6348 - val_accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.7640 - accuracy: 0.7143 - val_loss: 1.4207 - val_accuracy: 0.8434\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 462us/step - loss: 1.5907 - accuracy: 0.7403 - val_loss: 1.5577 - val_accuracy: 0.8434\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 1.5552 - accuracy: 0.7359 - val_loss: 1.2601 - val_accuracy: 0.8586\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 1.6382 - accuracy: 0.7078 - val_loss: 1.4485 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 1.7584 - accuracy: 0.7381 - val_loss: 1.4144 - val_accuracy: 0.8434\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 1.5909 - accuracy: 0.7424 - val_loss: 1.5324 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 376us/step - loss: 1.5067 - accuracy: 0.7403 - val_loss: 1.7725 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 1.7079 - accuracy: 0.7078 - val_loss: 1.2115 - val_accuracy: 0.8586\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 1.6998 - accuracy: 0.7056 - val_loss: 1.4951 - val_accuracy: 0.8434\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 1.4768 - accuracy: 0.7424 - val_loss: 1.8079 - val_accuracy: 0.8283\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 1.6470 - accuracy: 0.7143 - val_loss: 1.5929 - val_accuracy: 0.8434\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 1.5387 - accuracy: 0.7294 - val_loss: 1.6406 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 1.6484 - accuracy: 0.7078 - val_loss: 1.6360 - val_accuracy: 0.8636\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 422us/step - loss: 1.3701 - accuracy: 0.7576 - val_loss: 1.5692 - val_accuracy: 0.8384\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 1.5380 - accuracy: 0.7468 - val_loss: 1.5259 - val_accuracy: 0.8434\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 1.2636 - accuracy: 0.7576 - val_loss: 1.5491 - val_accuracy: 0.8434\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.4357 - accuracy: 0.7359 - val_loss: 1.6012 - val_accuracy: 0.8636\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 1.3117 - accuracy: 0.7511 - val_loss: 1.6540 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 1.1943 - accuracy: 0.7706 - val_loss: 1.5667 - val_accuracy: 0.8434\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.5145 - accuracy: 0.7424 - val_loss: 1.7640 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 1.6849 - accuracy: 0.7359 - val_loss: 1.4706 - val_accuracy: 0.8384\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 1.3067 - accuracy: 0.7403 - val_loss: 1.4245 - val_accuracy: 0.8535\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 1.3635 - accuracy: 0.7446 - val_loss: 1.6633 - val_accuracy: 0.8535\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 1.4928 - accuracy: 0.7251 - val_loss: 1.5190 - val_accuracy: 0.8636\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 357us/step - loss: 1.4667 - accuracy: 0.7489 - val_loss: 1.4590 - val_accuracy: 0.8586\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 1.5128 - accuracy: 0.7229 - val_loss: 1.7986 - val_accuracy: 0.8636\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 493us/step - loss: 1.5995 - accuracy: 0.7338 - val_loss: 1.8211 - val_accuracy: 0.8485\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 620us/step - loss: 1.5806 - accuracy: 0.7056 - val_loss: 1.8135 - val_accuracy: 0.8485\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 1.6702 - accuracy: 0.7186 - val_loss: 1.9881 - val_accuracy: 0.8636\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 1.6901 - accuracy: 0.7489 - val_loss: 1.7447 - val_accuracy: 0.8485\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 1.4989 - accuracy: 0.7100 - val_loss: 1.9876 - val_accuracy: 0.8586\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 1.7273 - accuracy: 0.7532 - val_loss: 1.6530 - val_accuracy: 0.8485\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 521us/step - loss: 1.4658 - accuracy: 0.6948 - val_loss: 1.5500 - val_accuracy: 0.8283\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 443us/step - loss: 1.7019 - accuracy: 0.7208 - val_loss: 1.4709 - val_accuracy: 0.8434\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 1.6826 - accuracy: 0.7056 - val_loss: 1.5453 - val_accuracy: 0.8535\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 493us/step - loss: 1.5344 - accuracy: 0.7078 - val_loss: 1.3076 - val_accuracy: 0.8687\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 1.6767 - accuracy: 0.7165 - val_loss: 1.2993 - val_accuracy: 0.8535\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 325us/step - loss: 1.5758 - accuracy: 0.7316 - val_loss: 1.9384 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 1.6287 - accuracy: 0.6883 - val_loss: 1.8024 - val_accuracy: 0.8485\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 361us/step - loss: 1.4071 - accuracy: 0.7294 - val_loss: 1.7352 - val_accuracy: 0.8434\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 1.5069 - accuracy: 0.7381 - val_loss: 1.9496 - val_accuracy: 0.8283\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 363us/step - loss: 1.6713 - accuracy: 0.7338 - val_loss: 1.8258 - val_accuracy: 0.8434\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 1.7322 - accuracy: 0.7100 - val_loss: 1.6815 - val_accuracy: 0.8283\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 72.19%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.13713930e-06, 9.99998800e-01, 2.06760080e-09],\n",
       "       [1.00000000e+00, 2.09310950e-31, 0.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [2.24351250e-02, 9.77403460e-01, 1.61510590e-04],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [4.88350900e-01, 5.11649000e-01, 6.25775800e-08],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [7.65375540e-11, 1.20261580e-09, 1.00000000e+00],\n",
       "       [2.24351250e-02, 9.77403460e-01, 1.61510590e-04],\n",
       "       [4.09843400e-06, 9.99995950e-01, 4.15722460e-20],\n",
       "       [1.00000000e+00, 5.68623340e-31, 0.00000000e+00],\n",
       "       [1.00000000e+00, 8.43185700e-34, 0.00000000e+00],\n",
       "       [1.00000000e+00, 4.08136640e-25, 7.79217000e-38],\n",
       "       [4.88350900e-01, 5.11649000e-01, 6.25775800e-08],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [7.65375540e-11, 1.20261580e-09, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.45228060e-29, 0.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [6.16856930e-01, 3.83143040e-01, 1.88939180e-08],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.13963340e-13, 0.00000000e+00],\n",
       "       [9.90197400e-01, 9.80251900e-03, 3.64199500e-13],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.98182620e-12, 1.00000000e+00, 1.12974250e-16],\n",
       "       [1.00000000e+00, 6.65209300e-23, 1.23931580e-34],\n",
       "       [2.51435250e-01, 7.48564200e-01, 5.61908050e-07],\n",
       "       [1.00000000e+00, 7.28205500e-14, 3.76915900e-28],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.46215840e-01, 1.53784110e-01, 8.96557660e-10],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [5.33759760e-12, 1.00000000e+00, 3.95729320e-16],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.49924580e-08, 2.39004050e-13],\n",
       "       [1.00000000e+00, 4.33138670e-25, 8.49233300e-38],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [1.99048030e-14, 1.00000000e+00, 2.72120060e-20],\n",
       "       [7.65375540e-11, 1.20261580e-09, 1.00000000e+00],\n",
       "       [9.53835550e-01, 4.61513140e-02, 1.31175075e-05],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.13713930e-06, 9.99998800e-01, 2.06760080e-09],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [9.94630200e-01, 5.36973300e-03, 6.95781700e-14],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.00000000e+00, 1.60911090e-29, 0.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [9.99273840e-01, 7.26136600e-04, 2.88665500e-16],\n",
       "       [9.97101250e-01, 2.89878410e-03, 1.28149140e-14],\n",
       "       [6.21380900e-02, 9.37505000e-01, 3.56975880e-04],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.00000000e+00, 8.73226200e-19, 1.13026580e-28],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.07298600e-26, 0.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.08962740e-23, 8.41215840e-35],\n",
       "       [2.07846910e-02, 9.78993000e-01, 2.22324350e-04],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.98182620e-12, 1.00000000e+00, 1.12974250e-16],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [9.98815200e-01, 1.18484300e-03, 1.10361140e-15],\n",
       "       [3.23412830e-15, 1.00000000e+00, 1.58532870e-24],\n",
       "       [1.93236900e-02, 9.80325400e-01, 3.50933090e-04],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [1.98182620e-12, 1.00000000e+00, 1.12974250e-16],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [8.81204440e-10, 1.00000000e+00, 2.53173920e-13],\n",
       "       [1.13713930e-06, 9.99998800e-01, 2.06760080e-09],\n",
       "       [2.55124900e-16, 3.52476780e-05, 9.99964700e-01],\n",
       "       [1.00000000e+00, 1.58346550e-11, 1.48978340e-25],\n",
       "       [9.99999400e-01, 6.35783070e-07, 5.11560200e-26],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [7.65375540e-11, 1.20261580e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.49924580e-08, 2.39004050e-13],\n",
       "       [1.00000000e+00, 4.49924580e-08, 2.39004050e-13],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [9.99309400e-01, 6.90633000e-04, 2.51637690e-16],\n",
       "       [1.00000000e+00, 3.11452800e-08, 1.16380790e-26],\n",
       "       [7.65375540e-11, 1.20261580e-09, 1.00000000e+00],\n",
       "       [3.23412830e-15, 1.00000000e+00, 1.58532870e-24],\n",
       "       [1.00000000e+00, 4.08136640e-25, 7.79217000e-38],\n",
       "       [9.86070700e-01, 1.39258110e-02, 3.54577510e-06],\n",
       "       [2.24351250e-02, 9.77403460e-01, 1.61510590e-04],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.08136640e-25, 7.79217000e-38],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [1.99048030e-14, 1.00000000e+00, 2.72120060e-20],\n",
       "       [1.00000000e+00, 7.37425200e-28, 0.00000000e+00],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [8.81204440e-10, 1.00000000e+00, 2.53173920e-13],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [4.88350900e-01, 5.11649000e-01, 6.25775800e-08],\n",
       "       [1.84785180e-02, 9.81028400e-01, 4.92998800e-04],\n",
       "       [9.86070700e-01, 1.39258110e-02, 3.54577510e-06],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [9.40968000e-12, 1.00000000e+00, 8.99624800e-23],\n",
       "       [8.46215840e-01, 1.53784110e-01, 8.96557660e-10],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [4.09843400e-06, 9.99995950e-01, 4.15722460e-20],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.66703760e-05, 9.99983300e-01, 2.18171560e-08],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.49924580e-08, 2.39004050e-13],\n",
       "       [9.14213600e-01, 8.57864200e-02, 1.58623540e-10],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [9.97476400e-01, 2.52358380e-03, 8.76290100e-15],\n",
       "       [3.18549700e-02, 9.68096440e-01, 4.85344500e-05],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [2.07846910e-02, 9.78993000e-01, 2.22324350e-04],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [4.31373700e-02, 9.56480740e-01, 3.81847000e-04],\n",
       "       [1.19654970e-10, 1.00000000e+00, 1.03984690e-31],\n",
       "       [9.94500900e-01, 5.49917300e-03, 7.42821540e-14],\n",
       "       [8.46215840e-01, 1.53784110e-01, 8.96557660e-10],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [6.21380900e-02, 9.37505000e-01, 3.56975880e-04],\n",
       "       [9.86458600e-01, 1.35414200e-02, 8.87797600e-13],\n",
       "       [2.51435250e-01, 7.48564200e-01, 5.61908050e-07],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [9.94151200e-01, 5.84885150e-03, 8.79910300e-14],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [9.96042500e-01, 3.95758000e-03, 3.01051300e-14],\n",
       "       [1.03342850e-24, 1.00000000e+00, 4.42154680e-35],\n",
       "       [9.99430840e-01, 5.69086300e-04, 1.48100600e-16],\n",
       "       [8.81204440e-10, 1.00000000e+00, 2.53173920e-13],\n",
       "       [1.00000000e+00, 2.97692530e-26, 0.00000000e+00],\n",
       "       [1.99048030e-14, 1.00000000e+00, 2.72120060e-20],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.00000000e+00, 4.08136640e-25, 7.79217000e-38],\n",
       "       [1.19654970e-10, 1.00000000e+00, 1.03984690e-31],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.83874480e-02, 9.81100800e-01, 5.11839100e-04],\n",
       "       [9.93871700e-01, 6.12832330e-03, 1.00032360e-13],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [2.07846910e-02, 9.78993000e-01, 2.22324350e-04],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [1.99048030e-14, 1.00000000e+00, 2.72120060e-20],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [2.72770850e-07, 9.99999760e-01, 6.89861700e-13],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [9.97274700e-01, 2.72526750e-03, 1.08194160e-14],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.68055150e-24, 3.52130550e-36],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [9.95281500e-01, 4.71842240e-03, 4.87819420e-14],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [9.85169950e-01, 1.48300740e-02, 1.14121570e-12],\n",
       "       [1.19654970e-10, 1.00000000e+00, 1.03984690e-31],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [2.00619670e-20, 1.64740060e-08, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.81204440e-10, 1.00000000e+00, 2.53173920e-13],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.13713930e-06, 9.99998800e-01, 2.06760080e-09],\n",
       "       [9.86070700e-01, 1.39258110e-02, 3.54577510e-06],\n",
       "       [1.13713930e-06, 9.99998800e-01, 2.06760080e-09],\n",
       "       [8.30049740e-12, 1.03651990e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.60911090e-29, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.55444300e-18, 8.61959900e-28],\n",
       "       [1.03343640e-24, 1.00000000e+00, 4.42158070e-35],\n",
       "       [8.30124700e-22, 9.95855700e-21, 1.00000000e+00]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9410391796755433"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9410391796755433"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa116     0\n",
       "1         NRS214     0\n",
       "2         NRS148     2\n",
       "3         NRS148     2\n",
       "4         NRS148     2\n",
       "..           ...   ...\n",
       "193       NRS148     2\n",
       "194       NRS054     0\n",
       "195       NRS109     2\n",
       "196       NRS216     1\n",
       "197    BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 781us/step - loss: 4.9098 - accuracy: 0.5498 - val_loss: 1.7761 - val_accuracy: 0.7727\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 4.1676 - accuracy: 0.5931 - val_loss: 1.7427 - val_accuracy: 0.6869\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 423us/step - loss: 3.8215 - accuracy: 0.6169 - val_loss: 1.0949 - val_accuracy: 0.7424\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 3.4556 - accuracy: 0.6429 - val_loss: 1.1181 - val_accuracy: 0.7323\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 439us/step - loss: 3.1721 - accuracy: 0.6450 - val_loss: 1.1670 - val_accuracy: 0.6768\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 3.1381 - accuracy: 0.6558 - val_loss: 1.2747 - val_accuracy: 0.7828\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 3.0135 - accuracy: 0.6494 - val_loss: 1.5050 - val_accuracy: 0.7424\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 3.1247 - accuracy: 0.6450 - val_loss: 1.7816 - val_accuracy: 0.7374\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 2.9328 - accuracy: 0.6688 - val_loss: 1.3726 - val_accuracy: 0.7778\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 2.4181 - accuracy: 0.6883 - val_loss: 1.6706 - val_accuracy: 0.7525\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 2.9368 - accuracy: 0.6537 - val_loss: 1.2881 - val_accuracy: 0.7929\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 2.4158 - accuracy: 0.7121 - val_loss: 1.4483 - val_accuracy: 0.7980\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 533us/step - loss: 2.4641 - accuracy: 0.6797 - val_loss: 1.6557 - val_accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 2.3866 - accuracy: 0.7143 - val_loss: 1.6000 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 2.1940 - accuracy: 0.7229 - val_loss: 1.3002 - val_accuracy: 0.8030\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 2.1551 - accuracy: 0.7100 - val_loss: 1.3700 - val_accuracy: 0.7828\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 2.4256 - accuracy: 0.6710 - val_loss: 1.4510 - val_accuracy: 0.7929\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 2.4895 - accuracy: 0.6948 - val_loss: 1.5243 - val_accuracy: 0.8232\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 2.4880 - accuracy: 0.6688 - val_loss: 1.6142 - val_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 2.3682 - accuracy: 0.6905 - val_loss: 1.5866 - val_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 2.1834 - accuracy: 0.6753 - val_loss: 1.6701 - val_accuracy: 0.8081\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 2.0147 - accuracy: 0.7078 - val_loss: 1.6056 - val_accuracy: 0.7828\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 2.2776 - accuracy: 0.7035 - val_loss: 1.3843 - val_accuracy: 0.8081\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 2.2392 - accuracy: 0.6797 - val_loss: 1.4554 - val_accuracy: 0.8131\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 2.2638 - accuracy: 0.6883 - val_loss: 1.6724 - val_accuracy: 0.8131\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 2.1604 - accuracy: 0.6926 - val_loss: 1.5262 - val_accuracy: 0.8030\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 2.0640 - accuracy: 0.7035 - val_loss: 1.3354 - val_accuracy: 0.8384\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 2.1608 - accuracy: 0.6991 - val_loss: 1.4664 - val_accuracy: 0.7980\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 456us/step - loss: 1.8513 - accuracy: 0.7208 - val_loss: 1.9087 - val_accuracy: 0.7677\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 434us/step - loss: 2.1950 - accuracy: 0.6970 - val_loss: 1.5353 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.7802 - accuracy: 0.7165 - val_loss: 1.4090 - val_accuracy: 0.7980\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 1.9885 - accuracy: 0.7251 - val_loss: 1.6298 - val_accuracy: 0.8081\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 1.6989 - accuracy: 0.7078 - val_loss: 1.3577 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 2.2230 - accuracy: 0.7056 - val_loss: 2.5389 - val_accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 2.0991 - accuracy: 0.6883 - val_loss: 1.8683 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 1.8222 - accuracy: 0.7165 - val_loss: 1.5860 - val_accuracy: 0.8131\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 1s 2ms/step - loss: 1.7089 - accuracy: 0.7229 - val_loss: 1.6361 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 2.0368 - accuracy: 0.7294 - val_loss: 1.6356 - val_accuracy: 0.8232\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 876us/step - loss: 1.8913 - accuracy: 0.7056 - val_loss: 2.0063 - val_accuracy: 0.7980\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 2.0208 - accuracy: 0.7035 - val_loss: 1.7704 - val_accuracy: 0.8434\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 434us/step - loss: 1.9569 - accuracy: 0.7294 - val_loss: 1.7060 - val_accuracy: 0.7576\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 1.5759 - accuracy: 0.7035 - val_loss: 1.4789 - val_accuracy: 0.8283\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 439us/step - loss: 1.7996 - accuracy: 0.6970 - val_loss: 1.9056 - val_accuracy: 0.8434\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 1.8785 - accuracy: 0.7143 - val_loss: 1.6118 - val_accuracy: 0.8232\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 623us/step - loss: 1.7652 - accuracy: 0.7273 - val_loss: 1.5325 - val_accuracy: 0.8485\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 702us/step - loss: 1.6921 - accuracy: 0.7446 - val_loss: 1.4845 - val_accuracy: 0.8131\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 546us/step - loss: 1.4708 - accuracy: 0.6991 - val_loss: 1.3746 - val_accuracy: 0.8030\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 601us/step - loss: 1.4374 - accuracy: 0.7273 - val_loss: 1.5982 - val_accuracy: 0.8384\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 640us/step - loss: 1.5294 - accuracy: 0.7359 - val_loss: 1.7890 - val_accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 507us/step - loss: 1.5491 - accuracy: 0.7359 - val_loss: 1.0613 - val_accuracy: 0.8232\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 375us/step - loss: 1.9833 - accuracy: 0.7165 - val_loss: 1.9449 - val_accuracy: 0.7626\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 390us/step - loss: 1.6643 - accuracy: 0.7251 - val_loss: 1.3461 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 1.7039 - accuracy: 0.7532 - val_loss: 1.6424 - val_accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 1.5477 - accuracy: 0.7165 - val_loss: 1.5101 - val_accuracy: 0.8384\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.3351 - accuracy: 0.7316 - val_loss: 1.5579 - val_accuracy: 0.8030\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 975us/step - loss: 1.5617 - accuracy: 0.7208 - val_loss: 1.3597 - val_accuracy: 0.8283\n",
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 744us/step - loss: 1.5176 - accuracy: 0.7338 - val_loss: 1.2998 - val_accuracy: 0.8535\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 802us/step - loss: 1.6458 - accuracy: 0.7143 - val_loss: 1.5936 - val_accuracy: 0.8384\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 775us/step - loss: 1.3581 - accuracy: 0.7597 - val_loss: 1.6047 - val_accuracy: 0.8485\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 440us/step - loss: 1.5340 - accuracy: 0.7165 - val_loss: 1.7370 - val_accuracy: 0.8232\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.4961 - accuracy: 0.7424 - val_loss: 1.5405 - val_accuracy: 0.8535\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 1.5002 - accuracy: 0.7446 - val_loss: 1.3809 - val_accuracy: 0.8535\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 1.4991 - accuracy: 0.7273 - val_loss: 1.7013 - val_accuracy: 0.8535\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 1.4350 - accuracy: 0.7446 - val_loss: 1.6448 - val_accuracy: 0.8131\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 382us/step - loss: 1.3903 - accuracy: 0.7468 - val_loss: 1.2613 - val_accuracy: 0.8485\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 1.4035 - accuracy: 0.7684 - val_loss: 1.3990 - val_accuracy: 0.8384\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 1.4665 - accuracy: 0.7359 - val_loss: 1.3936 - val_accuracy: 0.8485\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 1.3975 - accuracy: 0.7424 - val_loss: 1.4549 - val_accuracy: 0.8283\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 436us/step - loss: 1.2501 - accuracy: 0.7641 - val_loss: 1.3109 - val_accuracy: 0.8586\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 1.1773 - accuracy: 0.7641 - val_loss: 1.6200 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 1.5786 - accuracy: 0.7424 - val_loss: 1.7724 - val_accuracy: 0.8030\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 447us/step - loss: 1.2667 - accuracy: 0.7684 - val_loss: 1.5671 - val_accuracy: 0.8384\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 1.1511 - accuracy: 0.7641 - val_loss: 1.5606 - val_accuracy: 0.8081\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 1.4661 - accuracy: 0.7294 - val_loss: 1.2729 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 1.3813 - accuracy: 0.7597 - val_loss: 1.4103 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 1.2828 - accuracy: 0.7165 - val_loss: 1.4604 - val_accuracy: 0.8384\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 579us/step - loss: 1.3350 - accuracy: 0.7662 - val_loss: 1.3997 - val_accuracy: 0.8586\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.3388 - accuracy: 0.7186 - val_loss: 1.2391 - val_accuracy: 0.8636\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 625us/step - loss: 1.3194 - accuracy: 0.7208 - val_loss: 1.3306 - val_accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 900us/step - loss: 1.5250 - accuracy: 0.7251 - val_loss: 1.5499 - val_accuracy: 0.8535\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 653us/step - loss: 1.1411 - accuracy: 0.7229 - val_loss: 1.3062 - val_accuracy: 0.8636\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.0323 - accuracy: 0.7684 - val_loss: 1.6007 - val_accuracy: 0.8636\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 1.3242 - accuracy: 0.7381 - val_loss: 1.5776 - val_accuracy: 0.8636\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 406us/step - loss: 1.1849 - accuracy: 0.7662 - val_loss: 1.6180 - val_accuracy: 0.8485\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 1.4059 - accuracy: 0.7403 - val_loss: 1.5882 - val_accuracy: 0.8131\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.2301 - accuracy: 0.7532 - val_loss: 1.6176 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 1.4886 - accuracy: 0.7359 - val_loss: 1.4095 - val_accuracy: 0.8535\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 1.2877 - accuracy: 0.7403 - val_loss: 1.2060 - val_accuracy: 0.8687\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 1.4223 - accuracy: 0.7511 - val_loss: 1.5082 - val_accuracy: 0.8535\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 1.3047 - accuracy: 0.7273 - val_loss: 1.5106 - val_accuracy: 0.8535\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 1.2651 - accuracy: 0.7489 - val_loss: 1.6443 - val_accuracy: 0.8586\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 1.3221 - accuracy: 0.7294 - val_loss: 1.6110 - val_accuracy: 0.8636\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 1.2715 - accuracy: 0.7576 - val_loss: 2.4399 - val_accuracy: 0.7828\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 1.6076 - accuracy: 0.7446 - val_loss: 1.5817 - val_accuracy: 0.8081\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 1.4339 - accuracy: 0.7468 - val_loss: 1.5283 - val_accuracy: 0.8586\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 1.4268 - accuracy: 0.7446 - val_loss: 1.5238 - val_accuracy: 0.8636\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 1.2676 - accuracy: 0.7727 - val_loss: 1.2310 - val_accuracy: 0.8535\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 0.9354 - accuracy: 0.7576 - val_loss: 1.0626 - val_accuracy: 0.8586\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 1.2338 - accuracy: 0.7749 - val_loss: 1.5063 - val_accuracy: 0.8687\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.1758 - accuracy: 0.7619 - val_loss: 1.0655 - val_accuracy: 0.8434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3e093898>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 165us/step\n",
      "over-sampling test accuracy: 91.92%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2,\n",
       "       2, 2, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2,\n",
       "       0, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 0, 1, 0,\n",
       "       2, 1, 0, 2, 2, 2, 0, 1, 0, 2, 2, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 2, 0, 0, 2, 2, 1, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 2, 2,\n",
       "       2, 2, 2, 0, 0, 1, 1, 2, 0, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 2,\n",
       "       2, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa116     0     0\n",
       "1         NRS214     0     0\n",
       "2         NRS148     2     2\n",
       "3         NRS148     2     2\n",
       "4         NRS148     2     2\n",
       "..           ...   ...   ...\n",
       "193       NRS148     2     2\n",
       "194       NRS054     0     0\n",
       "195       NRS109     2     2\n",
       "196       NRS216     1     1\n",
       "197    BCH-SA-03     1     0\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480167e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839091e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.539984e-09</td>\n",
       "      <td>2.018661e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.170756e-15</td>\n",
       "      <td>7.536062e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6.065643e-03</td>\n",
       "      <td>9.939343e-01</td>\n",
       "      <td>7.595704e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.307158e-01</td>\n",
       "      <td>3.640927e-01</td>\n",
       "      <td>5.191470e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.676203e-01  3.237956e-02  1.480167e-07\n",
       "1    1.000000e+00  6.534852e-11  2.250731e-18\n",
       "2    3.948571e-11  2.839096e-07  9.999998e-01\n",
       "3    3.948571e-11  2.839096e-07  9.999998e-01\n",
       "4    3.948571e-11  2.839096e-07  9.999998e-01\n",
       "..            ...           ...           ...\n",
       "193  3.948571e-11  2.839091e-07  9.999998e-01\n",
       "194  1.000000e+00  4.539984e-09  2.018661e-15\n",
       "195  1.170756e-15  7.536062e-10  1.000000e+00\n",
       "196  6.065643e-03  9.939343e-01  7.595704e-18\n",
       "197  6.307158e-01  3.640927e-01  5.191470e-03\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p002ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 366us/step - loss: 1.2137 - accuracy: 0.7489 - val_loss: 1.0553 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 1.2706 - accuracy: 0.7381 - val_loss: 1.1689 - val_accuracy: 0.8586\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 379us/step - loss: 1.1069 - accuracy: 0.7359 - val_loss: 0.8190 - val_accuracy: 0.8636\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 438us/step - loss: 1.3298 - accuracy: 0.7446 - val_loss: 1.1741 - val_accuracy: 0.8838\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 366us/step - loss: 1.2086 - accuracy: 0.7511 - val_loss: 1.0793 - val_accuracy: 0.8838\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 318us/step - loss: 1.2321 - accuracy: 0.7641 - val_loss: 1.2733 - val_accuracy: 0.8485\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.3012 - accuracy: 0.7511 - val_loss: 0.5218 - val_accuracy: 0.8990\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 1.1029 - accuracy: 0.7511 - val_loss: 1.0457 - val_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 613us/step - loss: 1.1944 - accuracy: 0.7597 - val_loss: 1.1981 - val_accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 1.4190 - accuracy: 0.7489 - val_loss: 1.6082 - val_accuracy: 0.8535\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 496us/step - loss: 1.4392 - accuracy: 0.7056 - val_loss: 1.2657 - val_accuracy: 0.8636\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 746us/step - loss: 1.3785 - accuracy: 0.7186 - val_loss: 1.6678 - val_accuracy: 0.7929\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 1.7585 - accuracy: 0.7035 - val_loss: 1.2983 - val_accuracy: 0.8081\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 1.3053 - accuracy: 0.7381 - val_loss: 0.5002 - val_accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 389us/step - loss: 1.2661 - accuracy: 0.7294 - val_loss: 0.5213 - val_accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 472us/step - loss: 1.1127 - accuracy: 0.7403 - val_loss: 0.4084 - val_accuracy: 0.9040\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 612us/step - loss: 1.0073 - accuracy: 0.7511 - val_loss: 0.4309 - val_accuracy: 0.9192\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 1.3363 - accuracy: 0.7381 - val_loss: 0.5424 - val_accuracy: 0.8939\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 1s 1ms/step - loss: 1.0226 - accuracy: 0.7403 - val_loss: 0.4060 - val_accuracy: 0.8838\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 796us/step - loss: 1.0948 - accuracy: 0.7381 - val_loss: 0.5566 - val_accuracy: 0.9242\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 626us/step - loss: 1.0926 - accuracy: 0.7186 - val_loss: 0.4753 - val_accuracy: 0.8687\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 582us/step - loss: 1.1717 - accuracy: 0.7619 - val_loss: 0.5623 - val_accuracy: 0.8737\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 581us/step - loss: 1.2439 - accuracy: 0.6948 - val_loss: 0.5122 - val_accuracy: 0.8788\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 883us/step - loss: 1.2023 - accuracy: 0.7468 - val_loss: 0.4327 - val_accuracy: 0.8990\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 451us/step - loss: 1.5285 - accuracy: 0.7208 - val_loss: 0.6622 - val_accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 770us/step - loss: 1.1867 - accuracy: 0.7706 - val_loss: 0.4803 - val_accuracy: 0.9141\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 633us/step - loss: 1.3452 - accuracy: 0.7056 - val_loss: 0.4676 - val_accuracy: 0.9192\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 450us/step - loss: 1.3048 - accuracy: 0.7381 - val_loss: 0.5512 - val_accuracy: 0.9040\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 748us/step - loss: 1.2881 - accuracy: 0.7554 - val_loss: 0.6395 - val_accuracy: 0.8535\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 692us/step - loss: 1.1467 - accuracy: 0.7316 - val_loss: 0.5017 - val_accuracy: 0.9040\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 491us/step - loss: 1.3108 - accuracy: 0.7273 - val_loss: 0.7000 - val_accuracy: 0.8687\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 549us/step - loss: 1.3071 - accuracy: 0.7294 - val_loss: 0.5765 - val_accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 753us/step - loss: 1.3302 - accuracy: 0.7511 - val_loss: 0.6169 - val_accuracy: 0.8990\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 682us/step - loss: 1.2482 - accuracy: 0.7294 - val_loss: 0.6052 - val_accuracy: 0.8434\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 654us/step - loss: 1.1835 - accuracy: 0.7100 - val_loss: 0.4278 - val_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 735us/step - loss: 1.4060 - accuracy: 0.7359 - val_loss: 0.5516 - val_accuracy: 0.9192\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 559us/step - loss: 1.2269 - accuracy: 0.7273 - val_loss: 0.4204 - val_accuracy: 0.9242\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 1.0983 - accuracy: 0.7662 - val_loss: 1.0991 - val_accuracy: 0.8636\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 1.1467 - accuracy: 0.7381 - val_loss: 1.2002 - val_accuracy: 0.8788\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.2161 - accuracy: 0.7208 - val_loss: 0.5193 - val_accuracy: 0.9192\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 698us/step - loss: 1.3746 - accuracy: 0.7359 - val_loss: 0.6347 - val_accuracy: 0.8838\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 731us/step - loss: 1.0916 - accuracy: 0.7251 - val_loss: 0.4287 - val_accuracy: 0.8939\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 677us/step - loss: 0.9813 - accuracy: 0.7706 - val_loss: 0.4477 - val_accuracy: 0.8990\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 576us/step - loss: 1.0972 - accuracy: 0.7381 - val_loss: 0.8728 - val_accuracy: 0.8081\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 530us/step - loss: 1.0533 - accuracy: 0.7403 - val_loss: 0.6669 - val_accuracy: 0.8485\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 886us/step - loss: 1.3456 - accuracy: 0.7294 - val_loss: 0.5726 - val_accuracy: 0.8636\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 557us/step - loss: 0.9611 - accuracy: 0.7576 - val_loss: 0.3848 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 724us/step - loss: 0.9344 - accuracy: 0.7554 - val_loss: 0.5653 - val_accuracy: 0.8788\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 588us/step - loss: 1.2226 - accuracy: 0.7662 - val_loss: 1.0506 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 654us/step - loss: 1.2030 - accuracy: 0.7381 - val_loss: 0.9266 - val_accuracy: 0.8384\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 697us/step - loss: 0.9637 - accuracy: 0.7424 - val_loss: 1.1313 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 797us/step - loss: 1.4427 - accuracy: 0.7576 - val_loss: 1.1563 - val_accuracy: 0.8030\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 563us/step - loss: 1.2667 - accuracy: 0.7294 - val_loss: 1.2125 - val_accuracy: 0.8384\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 593us/step - loss: 1.3129 - accuracy: 0.7468 - val_loss: 1.0555 - val_accuracy: 0.8434\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 697us/step - loss: 0.9913 - accuracy: 0.7489 - val_loss: 0.5763 - val_accuracy: 0.8232\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 695us/step - loss: 1.0840 - accuracy: 0.7619 - val_loss: 0.5643 - val_accuracy: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 534us/step - loss: 1.2030 - accuracy: 0.7554 - val_loss: 0.7067 - val_accuracy: 0.8636\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 1.3228 - accuracy: 0.7424 - val_loss: 0.6180 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 517us/step - loss: 1.3046 - accuracy: 0.7597 - val_loss: 0.5951 - val_accuracy: 0.8939\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 1.3086 - accuracy: 0.7013 - val_loss: 0.5394 - val_accuracy: 0.8485\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 1.1036 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 1.1340 - accuracy: 0.7273 - val_loss: 0.5131 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 383us/step - loss: 1.0736 - accuracy: 0.7446 - val_loss: 0.5768 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 1.1179 - accuracy: 0.7532 - val_loss: 0.4153 - val_accuracy: 0.8384\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 412us/step - loss: 0.9280 - accuracy: 0.7749 - val_loss: 0.3976 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 0.9877 - accuracy: 0.7554 - val_loss: 0.3901 - val_accuracy: 0.8434\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.9452 - accuracy: 0.7359 - val_loss: 0.4632 - val_accuracy: 0.8434\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 0.9944 - accuracy: 0.7576 - val_loss: 0.4286 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 687us/step - loss: 0.9969 - accuracy: 0.7294 - val_loss: 0.5965 - val_accuracy: 0.8384\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 1.1006 - accuracy: 0.7554 - val_loss: 0.7977 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 1.1495 - accuracy: 0.7338 - val_loss: 0.6435 - val_accuracy: 0.8838\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 1.1717 - accuracy: 0.7165 - val_loss: 0.6343 - val_accuracy: 0.8131\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 1.0000 - accuracy: 0.7532 - val_loss: 0.5258 - val_accuracy: 0.8889\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 1.1671 - accuracy: 0.7641 - val_loss: 0.6124 - val_accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 1.1477 - accuracy: 0.7554 - val_loss: 0.5658 - val_accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 1.0894 - accuracy: 0.7532 - val_loss: 0.7039 - val_accuracy: 0.8737\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 1.0253 - accuracy: 0.7727 - val_loss: 0.4611 - val_accuracy: 0.8889\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 1.1770 - accuracy: 0.7078 - val_loss: 0.5338 - val_accuracy: 0.8586\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 479us/step - loss: 0.7265 - accuracy: 0.7403 - val_loss: 0.4364 - val_accuracy: 0.8939\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 476us/step - loss: 1.0371 - accuracy: 0.7165 - val_loss: 0.5509 - val_accuracy: 0.8687\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 1.0807 - accuracy: 0.7359 - val_loss: 0.5348 - val_accuracy: 0.8737\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 374us/step - loss: 1.0168 - accuracy: 0.7619 - val_loss: 0.4314 - val_accuracy: 0.9343\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.9307 - accuracy: 0.7576 - val_loss: 0.4794 - val_accuracy: 0.9343\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.2591 - accuracy: 0.7229 - val_loss: 0.9574 - val_accuracy: 0.8889\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 397us/step - loss: 0.9943 - accuracy: 0.7641 - val_loss: 0.5610 - val_accuracy: 0.9242\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 1.0028 - accuracy: 0.7294 - val_loss: 0.5663 - val_accuracy: 0.9242\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.8694 - accuracy: 0.7446 - val_loss: 0.4948 - val_accuracy: 0.8939\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 1.2827 - accuracy: 0.7035 - val_loss: 0.6330 - val_accuracy: 0.8232\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 341us/step - loss: 1.0126 - accuracy: 0.7273 - val_loss: 0.4990 - val_accuracy: 0.9040\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.9916 - accuracy: 0.7532 - val_loss: 0.5498 - val_accuracy: 0.9091\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 1.0769 - accuracy: 0.7424 - val_loss: 0.5769 - val_accuracy: 0.8788\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.0619 - accuracy: 0.7619 - val_loss: 0.5699 - val_accuracy: 0.8586\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 1.1843 - accuracy: 0.7316 - val_loss: 0.4295 - val_accuracy: 0.9040\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 340us/step - loss: 1.0823 - accuracy: 0.7078 - val_loss: 0.6318 - val_accuracy: 0.8384\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 418us/step - loss: 1.2936 - accuracy: 0.7208 - val_loss: 0.4550 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 312us/step - loss: 0.9926 - accuracy: 0.7662 - val_loss: 0.4302 - val_accuracy: 0.8131\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 599us/step - loss: 1.1128 - accuracy: 0.7706 - val_loss: 0.4257 - val_accuracy: 0.8081\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 375us/step - loss: 1.1389 - accuracy: 0.7229 - val_loss: 0.5974 - val_accuracy: 0.8030\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 453us/step - loss: 1.1793 - accuracy: 0.6905 - val_loss: 0.5391 - val_accuracy: 0.8030\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 900us/step - loss: 0.8668 - accuracy: 0.7013 - val_loss: 0.4270 - val_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 73.99%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [1.0000000e+00, 6.5348520e-11, 2.2507305e-18],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [6.0656667e-03, 9.9393433e-01, 7.5956460e-18],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [9.9916040e-01, 8.3955505e-04, 6.0683490e-11],\n",
       "       [9.9999990e-01, 7.1966340e-08, 1.6942623e-13],\n",
       "       [1.8313165e-03, 9.9816200e-01, 6.7235706e-06],\n",
       "       [9.9802930e-01, 1.9706318e-03, 8.2175170e-10],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.8313165e-03, 9.9816200e-01, 6.7235706e-06],\n",
       "       [1.0000000e+00, 2.2062680e-10, 1.5829654e-17],\n",
       "       [9.4680405e-01, 5.3195810e-02, 7.0303910e-08],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [9.9013734e-01, 9.8418420e-03, 2.0754898e-05],\n",
       "       [1.1755077e-05, 9.9998820e-01, 4.5515980e-10],\n",
       "       [1.0000000e+00, 1.0637724e-14, 1.9007079e-24],\n",
       "       [1.0000000e+00, 1.0010082e-10, 4.4589675e-18],\n",
       "       [1.1617010e-07, 9.9999990e-01, 6.4084340e-14],\n",
       "       [7.0318674e-07, 9.9999930e-01, 3.2457502e-11],\n",
       "       [9.9999475e-01, 5.2422010e-06, 1.6204275e-10],\n",
       "       [9.8208810e-09, 1.0000000e+00, 5.2028554e-16],\n",
       "       [9.9999940e-01, 6.5550034e-07, 5.8496240e-12],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [2.0127198e-09, 1.0000000e+00, 2.3715673e-17],\n",
       "       [1.0000000e+00, 8.0806160e-11, 3.1633775e-18],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [4.1766103e-07, 9.9965584e-01, 3.4368542e-04],\n",
       "       [1.0000000e+00, 1.1182767e-13, 6.8969520e-38],\n",
       "       [6.1325355e-11, 1.0000000e+00, 2.6363414e-20],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [9.0511936e-01, 9.4871700e-02, 8.9506370e-06],\n",
       "       [9.9451196e-01, 5.4879887e-03, 3.2593727e-16],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.0000000e+00, 8.3519560e-11, 5.7373840e-19],\n",
       "       [9.4680405e-01, 5.3195810e-02, 7.0303910e-08],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.1617010e-07, 9.9999990e-01, 6.4084340e-14],\n",
       "       [7.0642700e-05, 9.9992930e-01, 1.3772582e-08],\n",
       "       [8.4621440e-08, 9.9999990e-01, 3.4564250e-14],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.8938466e-09, 1.0000000e+00, 2.1063165e-17],\n",
       "       [9.9999950e-01, 4.4315283e-07, 2.7253917e-12],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0724748e-08, 1.0000000e+00, 2.1981408e-17],\n",
       "       [6.3071626e-01, 3.6409232e-01, 5.1914640e-03],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [1.0000000e+00, 2.7251179e-08, 2.4033959e-26],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [2.5237157e-10, 1.0000000e+00, 9.2928000e-16],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.0000000e+00, 2.2300881e-13, 2.4972260e-22],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [6.3071626e-01, 3.6409232e-01, 5.1914640e-03],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.1617010e-07, 9.9999990e-01, 6.4084340e-14],\n",
       "       [1.0000000e+00, 6.5348520e-11, 2.2507305e-18],\n",
       "       [1.0000000e+00, 1.3023561e-12, 0.0000000e+00],\n",
       "       [3.3800350e-11, 1.0000000e+00, 8.2588000e-21],\n",
       "       [3.3800350e-11, 1.0000000e+00, 8.2588000e-21],\n",
       "       [2.0127198e-09, 1.0000000e+00, 2.3715673e-17],\n",
       "       [1.0000000e+00, 6.5348520e-11, 2.2507305e-18],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [1.0724748e-08, 1.0000000e+00, 2.1981408e-17],\n",
       "       [9.9971360e-01, 2.8641685e-04, 1.1992348e-12],\n",
       "       [1.0000000e+00, 6.5348520e-11, 2.2507305e-18],\n",
       "       [9.9013734e-01, 9.8418420e-03, 2.0754898e-05],\n",
       "       [2.3153622e-04, 9.9976830e-01, 1.3161602e-07],\n",
       "       [1.0000000e+00, 2.8646930e-12, 1.4961430e-20],\n",
       "       [9.7599936e-01, 2.4000531e-02, 7.2665280e-08],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.0724748e-08, 1.0000000e+00, 2.1981408e-17],\n",
       "       [9.9999990e-01, 1.2033419e-07, 1.7009780e-24],\n",
       "       [9.8208810e-09, 1.0000000e+00, 5.2028554e-16],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [7.7975650e-07, 9.9999917e-01, 1.9382903e-13],\n",
       "       [9.9999930e-01, 7.1784683e-07, 6.7668635e-12],\n",
       "       [1.0000000e+00, 3.9525190e-12, 0.0000000e+00],\n",
       "       [9.4680405e-01, 5.3195810e-02, 7.0303910e-08],\n",
       "       [3.3614285e-07, 9.9999964e-01, 1.0000241e-12],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0000000e+00, 1.2765975e-14, 2.5462144e-24],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0000000e+00, 2.2915033e-08, 5.6756510e-26],\n",
       "       [5.1752780e-07, 9.9999950e-01, 2.9953178e-13],\n",
       "       [4.1766103e-07, 9.9965584e-01, 3.4368542e-04],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [2.3153622e-04, 9.9976830e-01, 1.3161602e-07],\n",
       "       [3.4599515e-04, 9.9965380e-01, 2.8251463e-07],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [2.4153952e-02, 9.7584460e-01, 1.3554798e-06],\n",
       "       [1.0000000e+00, 2.9884983e-10, 2.1226358e-38],\n",
       "       [1.1617010e-07, 9.9999990e-01, 6.4084340e-14],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.8313165e-03, 9.9816200e-01, 6.7235706e-06],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [1.1453752e-12, 1.0000000e+00, 1.1293765e-23],\n",
       "       [9.9965060e-01, 3.4937213e-04, 1.8388730e-12],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.1755077e-05, 9.9998820e-01, 4.5515980e-10],\n",
       "       [1.0000000e+00, 2.7148856e-13, 0.0000000e+00],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [6.1325355e-11, 1.0000000e+00, 2.6363414e-20],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [9.9999990e-01, 7.0304330e-08, 1.6319781e-13],\n",
       "       [1.0000000e+00, 1.5489924e-08, 1.5611240e-26],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [9.4680405e-01, 5.3195810e-02, 7.0303910e-08],\n",
       "       [9.9821100e-01, 1.7872818e-03, 1.6290924e-06],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.8938466e-09, 1.0000000e+00, 2.1063165e-17],\n",
       "       [1.0000000e+00, 3.6301290e-08, 8.4734866e-26],\n",
       "       [1.0000000e+00, 1.9941985e-16, 3.2368610e-27],\n",
       "       [2.3263410e-09, 1.0000000e+00, 4.7678902e-17],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [9.0511936e-01, 9.4871700e-02, 8.9506370e-06],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [1.8313165e-03, 9.9816200e-01, 6.7235706e-06],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [9.9999990e-01, 7.1966340e-08, 1.6942623e-13],\n",
       "       [1.6152933e-02, 9.8384710e-01, 2.8774420e-12],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [1.0000000e+00, 3.3967252e-13, 4.9024790e-22],\n",
       "       [9.9013734e-01, 9.8418420e-03, 2.0754898e-05],\n",
       "       [1.0724748e-08, 1.0000000e+00, 2.1981408e-17],\n",
       "       [6.0656667e-03, 9.9393433e-01, 7.5956460e-18],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0000000e+00, 2.0375591e-10, 1.3934388e-17],\n",
       "       [1.0000000e+00, 5.4406075e-09, 5.9576230e-23],\n",
       "       [9.8701197e-01, 1.2988065e-02, 5.6354870e-08],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [8.4621440e-08, 9.9999990e-01, 3.4564250e-14],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [9.7827715e-01, 2.1722771e-02, 9.3013400e-08],\n",
       "       [2.9259754e-06, 8.7246345e-04, 9.9912460e-01],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [2.8899090e-05, 9.9997115e-01, 6.2486218e-15],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0724748e-08, 1.0000000e+00, 2.1981408e-17],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [9.9999917e-01, 8.0219180e-07, 8.0860015e-12],\n",
       "       [8.7235700e-12, 9.9335040e-08, 9.9999990e-01],\n",
       "       [2.3153622e-04, 9.9976830e-01, 1.3161602e-07],\n",
       "       [1.0000000e+00, 1.5093526e-10, 8.6132000e-18],\n",
       "       [4.7723553e-01, 5.1892006e-01, 3.8443890e-03],\n",
       "       [6.3071626e-01, 3.6409232e-01, 5.1914640e-03],\n",
       "       [3.9485713e-11, 2.8390960e-07, 9.9999976e-01],\n",
       "       [8.4837495e-07, 9.9999917e-01, 8.6031840e-09],\n",
       "       [4.7676903e-01, 5.2235370e-01, 8.7730505e-04],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [2.7288563e-09, 1.0000000e+00, 4.2915043e-17],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [9.6762030e-01, 3.2379560e-02, 1.4801665e-07],\n",
       "       [1.0000000e+00, 3.3967252e-13, 4.9024790e-22],\n",
       "       [1.1707652e-15, 7.5361050e-10, 1.0000000e+00],\n",
       "       [1.0000000e+00, 1.5489983e-08, 1.5611240e-26],\n",
       "       [3.9485713e-11, 2.8390906e-07, 9.9999976e-01],\n",
       "       [1.0000000e+00, 4.5399840e-09, 2.0186612e-15],\n",
       "       [1.1707563e-15, 7.5360620e-10, 1.0000000e+00],\n",
       "       [6.0656434e-03, 9.9393433e-01, 7.5957040e-18],\n",
       "       [6.3071585e-01, 3.6409268e-01, 5.1914696e-03]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p002ykpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9608394551576369"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9608394551576369"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606529308233853"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012327917615303271"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606529308233853"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012327917615303271"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 88.01%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.02681407495931643\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 73.58%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.010700323\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
