{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0017Skpresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 103)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0017Skpresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    1\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>TTCCATCGAATCAC</th>\n",
       "      <th>TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA</th>\n",
       "      <th>...</th>\n",
       "      <th>AGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTT</th>\n",
       "      <th>AGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTTAATTT</th>\n",
       "      <th>AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT</th>\n",
       "      <th>AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT</th>\n",
       "      <th>ACTTTCGAATT</th>\n",
       "      <th>AATTAAAATCTTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTT</th>\n",
       "      <th>AATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTT</th>\n",
       "      <th>AATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATT</th>\n",
       "      <th>AAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAATACATAT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                0   \n",
       "2              0                1   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCCATCGAATCAC  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               1   \n",
       "3               0   \n",
       "4               0   \n",
       "\n",
       "   TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTTAATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACTTTCGAATT  \\\n",
       "0            0   \n",
       "1            0   \n",
       "2            1   \n",
       "3            0   \n",
       "4            0   \n",
       "\n",
       "   AATTAAAATCTTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    216\n",
       "1     35\n",
       "2      2\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 102)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT</th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC</th>\n",
       "      <th>TTCCATCGAATCAC</th>\n",
       "      <th>TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA</th>\n",
       "      <th>TTCAAGAAGGAGA</th>\n",
       "      <th>...</th>\n",
       "      <th>AGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTT</th>\n",
       "      <th>AGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTTAATTT</th>\n",
       "      <th>AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT</th>\n",
       "      <th>AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT</th>\n",
       "      <th>ACTTTCGAATT</th>\n",
       "      <th>AATTAAAATCTTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTT</th>\n",
       "      <th>AATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTT</th>\n",
       "      <th>AATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATT</th>\n",
       "      <th>AAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAATACATAT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   TTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0              0                0   \n",
       "1              0                0   \n",
       "2              0                1   \n",
       "3              0                0   \n",
       "4              0                0   \n",
       "\n",
       "   TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTAC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCCATCGAATCAC  \\\n",
       "0               0   \n",
       "1               0   \n",
       "2               1   \n",
       "3               0   \n",
       "4               0   \n",
       "\n",
       "   TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTCAAGAAGGAGA  ...  \\\n",
       "0              0  ...   \n",
       "1              0  ...   \n",
       "2              0  ...   \n",
       "3              0  ...   \n",
       "4              0  ...   \n",
       "\n",
       "   AGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTTAATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACTTTCGAATT  \\\n",
       "0            0   \n",
       "1            0   \n",
       "2            1   \n",
       "3            0   \n",
       "4            0   \n",
       "\n",
       "   AATTAAAATCTTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 102) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 216), (1, 216), (2, 216)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0          312     1\n",
       "1     CFBRSa27     0\n",
       "2    BCH-SA-01     1\n",
       "3         GA27     1\n",
       "4       NRS209     2\n",
       "..         ...   ...\n",
       "190     NRS209     2\n",
       "191     NRS235     0\n",
       "192     NRS240     1\n",
       "193     NRS110     2\n",
       "194     NRS063     1\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 315us/step - loss: 0.8689 - accuracy: 0.6358 - val_loss: 0.7299 - val_accuracy: 0.7077\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.6227 - accuracy: 0.7991 - val_loss: 0.5903 - val_accuracy: 0.7231\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.5069 - accuracy: 0.8057 - val_loss: 0.5201 - val_accuracy: 0.7590\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.4500 - accuracy: 0.8057 - val_loss: 0.4899 - val_accuracy: 0.7538\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.4057 - accuracy: 0.8124 - val_loss: 0.4994 - val_accuracy: 0.7590\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.3910 - accuracy: 0.8389 - val_loss: 0.4689 - val_accuracy: 0.7590\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.3797 - accuracy: 0.8168 - val_loss: 0.4649 - val_accuracy: 0.7538\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.3700 - accuracy: 0.8411 - val_loss: 0.4817 - val_accuracy: 0.7436\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.3560 - accuracy: 0.8455 - val_loss: 0.4358 - val_accuracy: 0.7641\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.3477 - accuracy: 0.8433 - val_loss: 0.4481 - val_accuracy: 0.7795\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.3444 - accuracy: 0.8565 - val_loss: 0.4547 - val_accuracy: 0.7744\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.3413 - accuracy: 0.8433 - val_loss: 0.4466 - val_accuracy: 0.7795\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.3407 - accuracy: 0.8499 - val_loss: 0.4428 - val_accuracy: 0.7795\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.3274 - accuracy: 0.8631 - val_loss: 0.4256 - val_accuracy: 0.7744\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.3209 - accuracy: 0.8477 - val_loss: 0.4259 - val_accuracy: 0.7744\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.3217 - accuracy: 0.8543 - val_loss: 0.4245 - val_accuracy: 0.7692\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.3164 - accuracy: 0.8477 - val_loss: 0.4203 - val_accuracy: 0.7744\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3194 - accuracy: 0.8499 - val_loss: 0.4059 - val_accuracy: 0.7692\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.3122 - accuracy: 0.8587 - val_loss: 0.4078 - val_accuracy: 0.7744\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.3113 - accuracy: 0.8609 - val_loss: 0.4085 - val_accuracy: 0.7641\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.3073 - accuracy: 0.8720 - val_loss: 0.4041 - val_accuracy: 0.7897\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.3067 - accuracy: 0.8587 - val_loss: 0.4129 - val_accuracy: 0.7795\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2999 - accuracy: 0.8786 - val_loss: 0.4134 - val_accuracy: 0.7795\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.3031 - accuracy: 0.8698 - val_loss: 0.4025 - val_accuracy: 0.7744\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.3028 - accuracy: 0.8675 - val_loss: 0.4284 - val_accuracy: 0.7795\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2987 - accuracy: 0.8631 - val_loss: 0.3959 - val_accuracy: 0.7846\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2953 - accuracy: 0.8565 - val_loss: 0.4514 - val_accuracy: 0.7897\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.3042 - accuracy: 0.8587 - val_loss: 0.3940 - val_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2921 - accuracy: 0.8653 - val_loss: 0.4183 - val_accuracy: 0.7949\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2933 - accuracy: 0.8631 - val_loss: 0.3993 - val_accuracy: 0.7846\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2929 - accuracy: 0.8675 - val_loss: 0.4007 - val_accuracy: 0.8000\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2900 - accuracy: 0.8587 - val_loss: 0.4215 - val_accuracy: 0.7846\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2885 - accuracy: 0.8675 - val_loss: 0.4235 - val_accuracy: 0.7949\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2909 - accuracy: 0.8631 - val_loss: 0.3941 - val_accuracy: 0.8154\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2798 - accuracy: 0.8720 - val_loss: 0.4137 - val_accuracy: 0.7846\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2907 - accuracy: 0.8786 - val_loss: 0.4028 - val_accuracy: 0.7846\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2901 - accuracy: 0.8653 - val_loss: 0.3865 - val_accuracy: 0.8103\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2778 - accuracy: 0.8764 - val_loss: 0.4237 - val_accuracy: 0.8051\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2867 - accuracy: 0.8631 - val_loss: 0.3966 - val_accuracy: 0.7949\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2791 - accuracy: 0.8609 - val_loss: 0.4003 - val_accuracy: 0.8051\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2851 - accuracy: 0.8631 - val_loss: 0.3879 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2760 - accuracy: 0.8631 - val_loss: 0.3899 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2778 - accuracy: 0.8653 - val_loss: 0.3872 - val_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2762 - accuracy: 0.8698 - val_loss: 0.3968 - val_accuracy: 0.8154\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2814 - accuracy: 0.8631 - val_loss: 0.3888 - val_accuracy: 0.8051\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2778 - accuracy: 0.8698 - val_loss: 0.3909 - val_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2760 - accuracy: 0.8631 - val_loss: 0.4148 - val_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2731 - accuracy: 0.8565 - val_loss: 0.3882 - val_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2700 - accuracy: 0.8742 - val_loss: 0.4036 - val_accuracy: 0.8051\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2694 - accuracy: 0.8609 - val_loss: 0.3880 - val_accuracy: 0.7897\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2711 - accuracy: 0.8742 - val_loss: 0.3890 - val_accuracy: 0.8051\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2706 - accuracy: 0.8720 - val_loss: 0.3842 - val_accuracy: 0.8154\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2768 - accuracy: 0.8764 - val_loss: 0.3926 - val_accuracy: 0.8051\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2725 - accuracy: 0.8720 - val_loss: 0.3997 - val_accuracy: 0.7897\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2767 - accuracy: 0.8653 - val_loss: 0.4355 - val_accuracy: 0.8051\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2782 - accuracy: 0.8698 - val_loss: 0.3891 - val_accuracy: 0.7949\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2699 - accuracy: 0.8675 - val_loss: 0.3860 - val_accuracy: 0.7949\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2656 - accuracy: 0.8786 - val_loss: 0.3914 - val_accuracy: 0.7949\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2645 - accuracy: 0.8675 - val_loss: 0.3908 - val_accuracy: 0.8154\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2901 - accuracy: 0.8521 - val_loss: 0.3895 - val_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2819 - accuracy: 0.8764 - val_loss: 0.3976 - val_accuracy: 0.8154\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2644 - accuracy: 0.8786 - val_loss: 0.3857 - val_accuracy: 0.7949\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2623 - accuracy: 0.8786 - val_loss: 0.3885 - val_accuracy: 0.7949\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2598 - accuracy: 0.8786 - val_loss: 0.3925 - val_accuracy: 0.8154\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2670 - accuracy: 0.8742 - val_loss: 0.3906 - val_accuracy: 0.7949\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2664 - accuracy: 0.8653 - val_loss: 0.3829 - val_accuracy: 0.8154\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2711 - accuracy: 0.8786 - val_loss: 0.3869 - val_accuracy: 0.8359\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2679 - accuracy: 0.8830 - val_loss: 0.3828 - val_accuracy: 0.7949\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2617 - accuracy: 0.8808 - val_loss: 0.3771 - val_accuracy: 0.8051\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2587 - accuracy: 0.8742 - val_loss: 0.3955 - val_accuracy: 0.8051\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2729 - accuracy: 0.8720 - val_loss: 0.3955 - val_accuracy: 0.7949\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2606 - accuracy: 0.8764 - val_loss: 0.3982 - val_accuracy: 0.8359\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2576 - accuracy: 0.8786 - val_loss: 0.4207 - val_accuracy: 0.7949\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2575 - accuracy: 0.8764 - val_loss: 0.3934 - val_accuracy: 0.8359\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2602 - accuracy: 0.8830 - val_loss: 0.3868 - val_accuracy: 0.8000\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2580 - accuracy: 0.8852 - val_loss: 0.3861 - val_accuracy: 0.7949\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2679 - accuracy: 0.8808 - val_loss: 0.3852 - val_accuracy: 0.7949\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2714 - accuracy: 0.8720 - val_loss: 0.3876 - val_accuracy: 0.7949\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2571 - accuracy: 0.8653 - val_loss: 0.3990 - val_accuracy: 0.7949\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2726 - accuracy: 0.8698 - val_loss: 0.4122 - val_accuracy: 0.7949\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2575 - accuracy: 0.8830 - val_loss: 0.3869 - val_accuracy: 0.8410\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2601 - accuracy: 0.8698 - val_loss: 0.3995 - val_accuracy: 0.7949\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2623 - accuracy: 0.8830 - val_loss: 0.3846 - val_accuracy: 0.7949\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2541 - accuracy: 0.8852 - val_loss: 0.3826 - val_accuracy: 0.7949\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2566 - accuracy: 0.8786 - val_loss: 0.3850 - val_accuracy: 0.7949\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2545 - accuracy: 0.8852 - val_loss: 0.3800 - val_accuracy: 0.7949\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2547 - accuracy: 0.8918 - val_loss: 0.3971 - val_accuracy: 0.7949\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2540 - accuracy: 0.8742 - val_loss: 0.3970 - val_accuracy: 0.8359\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2601 - accuracy: 0.8742 - val_loss: 0.3837 - val_accuracy: 0.8051\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2570 - accuracy: 0.8786 - val_loss: 0.3863 - val_accuracy: 0.8410\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2576 - accuracy: 0.8764 - val_loss: 0.4049 - val_accuracy: 0.8410\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2629 - accuracy: 0.8720 - val_loss: 0.4020 - val_accuracy: 0.8359\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2665 - accuracy: 0.8631 - val_loss: 0.3869 - val_accuracy: 0.7949\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2606 - accuracy: 0.8742 - val_loss: 0.3780 - val_accuracy: 0.8051\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2510 - accuracy: 0.8742 - val_loss: 0.3830 - val_accuracy: 0.8051\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2525 - accuracy: 0.8808 - val_loss: 0.3880 - val_accuracy: 0.8410\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2723 - accuracy: 0.8830 - val_loss: 0.3927 - val_accuracy: 0.8410\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2590 - accuracy: 0.8830 - val_loss: 0.3956 - val_accuracy: 0.7949\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2528 - accuracy: 0.8808 - val_loss: 0.3850 - val_accuracy: 0.8410\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2511 - accuracy: 0.8852 - val_loss: 0.3927 - val_accuracy: 0.7949\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2507 - accuracy: 0.8874 - val_loss: 0.3850 - val_accuracy: 0.7949\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2504 - accuracy: 0.8830 - val_loss: 0.3989 - val_accuracy: 0.8000\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2526 - accuracy: 0.8852 - val_loss: 0.3980 - val_accuracy: 0.7949\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2473 - accuracy: 0.8940 - val_loss: 0.4037 - val_accuracy: 0.8410\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2671 - accuracy: 0.8631 - val_loss: 0.4034 - val_accuracy: 0.8410\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2756 - accuracy: 0.8521 - val_loss: 0.4042 - val_accuracy: 0.8410\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2564 - accuracy: 0.8874 - val_loss: 0.3789 - val_accuracy: 0.7949\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2470 - accuracy: 0.8874 - val_loss: 0.3910 - val_accuracy: 0.7949\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2458 - accuracy: 0.8830 - val_loss: 0.3982 - val_accuracy: 0.7949\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2527 - accuracy: 0.8764 - val_loss: 0.3802 - val_accuracy: 0.7949\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2576 - accuracy: 0.8852 - val_loss: 0.3893 - val_accuracy: 0.7949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2431 - accuracy: 0.8786 - val_loss: 0.3950 - val_accuracy: 0.7949\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2483 - accuracy: 0.8786 - val_loss: 0.3900 - val_accuracy: 0.7949\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2519 - accuracy: 0.8808 - val_loss: 0.3786 - val_accuracy: 0.8154\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2506 - accuracy: 0.8808 - val_loss: 0.3750 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2602 - accuracy: 0.8852 - val_loss: 0.3733 - val_accuracy: 0.8410\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2519 - accuracy: 0.8830 - val_loss: 0.3808 - val_accuracy: 0.8256\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2498 - accuracy: 0.8830 - val_loss: 0.3744 - val_accuracy: 0.7949\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2441 - accuracy: 0.8940 - val_loss: 0.3816 - val_accuracy: 0.8410\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2655 - accuracy: 0.8764 - val_loss: 0.3825 - val_accuracy: 0.8256\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2463 - accuracy: 0.8808 - val_loss: 0.3881 - val_accuracy: 0.8410\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2478 - accuracy: 0.8874 - val_loss: 0.4019 - val_accuracy: 0.7949\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2650 - accuracy: 0.8477 - val_loss: 0.3939 - val_accuracy: 0.8154\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2481 - accuracy: 0.8808 - val_loss: 0.3817 - val_accuracy: 0.7949\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2431 - accuracy: 0.8874 - val_loss: 0.3801 - val_accuracy: 0.8154\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2416 - accuracy: 0.9029 - val_loss: 0.3997 - val_accuracy: 0.7949\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2646 - accuracy: 0.8808 - val_loss: 0.3750 - val_accuracy: 0.8154\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2413 - accuracy: 0.8918 - val_loss: 0.3805 - val_accuracy: 0.7949\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2411 - accuracy: 0.8874 - val_loss: 0.3715 - val_accuracy: 0.8154\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2418 - accuracy: 0.8896 - val_loss: 0.3767 - val_accuracy: 0.8256\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2453 - accuracy: 0.8764 - val_loss: 0.3827 - val_accuracy: 0.7949\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2533 - accuracy: 0.8786 - val_loss: 0.4245 - val_accuracy: 0.8000\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2446 - accuracy: 0.8874 - val_loss: 0.3847 - val_accuracy: 0.7949\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2419 - accuracy: 0.8940 - val_loss: 0.3929 - val_accuracy: 0.7949\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2444 - accuracy: 0.8631 - val_loss: 0.5286 - val_accuracy: 0.7897\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2654 - accuracy: 0.8786 - val_loss: 0.3881 - val_accuracy: 0.7949\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2409 - accuracy: 0.8918 - val_loss: 0.3708 - val_accuracy: 0.7949\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2377 - accuracy: 0.8918 - val_loss: 0.3805 - val_accuracy: 0.8256\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2443 - accuracy: 0.8830 - val_loss: 0.3848 - val_accuracy: 0.8256\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2411 - accuracy: 0.8830 - val_loss: 0.4043 - val_accuracy: 0.7949\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2387 - accuracy: 0.9007 - val_loss: 0.3846 - val_accuracy: 0.7949\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2410 - accuracy: 0.8896 - val_loss: 0.3852 - val_accuracy: 0.8256\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2464 - accuracy: 0.8940 - val_loss: 0.3789 - val_accuracy: 0.8256\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2383 - accuracy: 0.8808 - val_loss: 0.3901 - val_accuracy: 0.8256\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2364 - accuracy: 0.8985 - val_loss: 0.3850 - val_accuracy: 0.7949\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2456 - accuracy: 0.8962 - val_loss: 0.3913 - val_accuracy: 0.8154\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2397 - accuracy: 0.8962 - val_loss: 0.3914 - val_accuracy: 0.7949\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2386 - accuracy: 0.8985 - val_loss: 0.3768 - val_accuracy: 0.8154\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2364 - accuracy: 0.9029 - val_loss: 0.3748 - val_accuracy: 0.8256\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2390 - accuracy: 0.9073 - val_loss: 0.3720 - val_accuracy: 0.8256\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2340 - accuracy: 0.8918 - val_loss: 0.3805 - val_accuracy: 0.8256\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2416 - accuracy: 0.8962 - val_loss: 0.3987 - val_accuracy: 0.8000\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2449 - accuracy: 0.8896 - val_loss: 0.3858 - val_accuracy: 0.7949\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2329 - accuracy: 0.8896 - val_loss: 0.4000 - val_accuracy: 0.8410\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2367 - accuracy: 0.9029 - val_loss: 0.3840 - val_accuracy: 0.8154\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2441 - accuracy: 0.8962 - val_loss: 0.4053 - val_accuracy: 0.7949\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2346 - accuracy: 0.8985 - val_loss: 0.3838 - val_accuracy: 0.8154\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2391 - accuracy: 0.8896 - val_loss: 0.3768 - val_accuracy: 0.8256\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 0.3811 - val_accuracy: 0.7949\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2391 - accuracy: 0.8874 - val_loss: 0.3862 - val_accuracy: 0.8000\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2392 - accuracy: 0.8940 - val_loss: 0.3834 - val_accuracy: 0.8154\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2385 - accuracy: 0.8918 - val_loss: 0.3809 - val_accuracy: 0.8256\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2323 - accuracy: 0.8940 - val_loss: 0.3952 - val_accuracy: 0.7949\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2325 - accuracy: 0.8985 - val_loss: 0.3749 - val_accuracy: 0.8256\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2399 - accuracy: 0.8918 - val_loss: 0.3734 - val_accuracy: 0.8154\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2352 - accuracy: 0.8940 - val_loss: 0.3910 - val_accuracy: 0.8154\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2331 - accuracy: 0.8985 - val_loss: 0.3813 - val_accuracy: 0.8154\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2447 - accuracy: 0.8874 - val_loss: 0.3847 - val_accuracy: 0.8205\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2363 - accuracy: 0.9007 - val_loss: 0.3691 - val_accuracy: 0.8256\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2321 - accuracy: 0.9029 - val_loss: 0.3706 - val_accuracy: 0.8154\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2347 - accuracy: 0.8985 - val_loss: 0.3879 - val_accuracy: 0.8256\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2397 - accuracy: 0.8830 - val_loss: 0.3898 - val_accuracy: 0.8410\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2312 - accuracy: 0.9029 - val_loss: 0.3846 - val_accuracy: 0.8154\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2359 - accuracy: 0.9007 - val_loss: 0.3792 - val_accuracy: 0.8205\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2360 - accuracy: 0.9051 - val_loss: 0.3826 - val_accuracy: 0.8154\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2301 - accuracy: 0.8962 - val_loss: 0.3825 - val_accuracy: 0.8256\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2370 - accuracy: 0.8918 - val_loss: 0.3844 - val_accuracy: 0.8154\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2431 - accuracy: 0.8985 - val_loss: 0.3839 - val_accuracy: 0.8154\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2373 - accuracy: 0.9051 - val_loss: 0.3733 - val_accuracy: 0.8256\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2408 - accuracy: 0.8786 - val_loss: 0.3791 - val_accuracy: 0.8410\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2302 - accuracy: 0.8985 - val_loss: 0.3806 - val_accuracy: 0.8256\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2315 - accuracy: 0.9029 - val_loss: 0.3865 - val_accuracy: 0.8256\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2366 - accuracy: 0.9029 - val_loss: 0.3835 - val_accuracy: 0.8256\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2317 - accuracy: 0.9029 - val_loss: 0.4088 - val_accuracy: 0.8051\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2365 - accuracy: 0.9073 - val_loss: 0.4006 - val_accuracy: 0.8205\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.4201 - val_accuracy: 0.8051\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2370 - accuracy: 0.9007 - val_loss: 0.3905 - val_accuracy: 0.8205\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.3828 - val_accuracy: 0.8256\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2310 - accuracy: 0.8962 - val_loss: 0.3849 - val_accuracy: 0.8256\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.9029 - val_loss: 0.3859 - val_accuracy: 0.8154\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2293 - accuracy: 0.9029 - val_loss: 0.3850 - val_accuracy: 0.8154\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2278 - accuracy: 0.8962 - val_loss: 0.3974 - val_accuracy: 0.8410\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2375 - accuracy: 0.9007 - val_loss: 0.3903 - val_accuracy: 0.8256\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2317 - accuracy: 0.9051 - val_loss: 0.3863 - val_accuracy: 0.8205\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2313 - accuracy: 0.8985 - val_loss: 0.3988 - val_accuracy: 0.8256\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.9029 - val_loss: 0.3822 - val_accuracy: 0.8256\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2328 - accuracy: 0.9029 - val_loss: 0.3905 - val_accuracy: 0.8256\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2379 - accuracy: 0.8896 - val_loss: 0.3903 - val_accuracy: 0.8256\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2339 - accuracy: 0.9007 - val_loss: 0.3813 - val_accuracy: 0.8256\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2365 - accuracy: 0.8962 - val_loss: 0.3815 - val_accuracy: 0.8256\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2320 - accuracy: 0.9029 - val_loss: 0.4002 - val_accuracy: 0.8205\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2324 - accuracy: 0.9007 - val_loss: 0.3894 - val_accuracy: 0.8205\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2276 - accuracy: 0.9029 - val_loss: 0.3802 - val_accuracy: 0.8256\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2307 - accuracy: 0.9007 - val_loss: 0.3790 - val_accuracy: 0.8308\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2258 - accuracy: 0.8985 - val_loss: 0.4076 - val_accuracy: 0.8103\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2493 - accuracy: 0.8874 - val_loss: 0.3659 - val_accuracy: 0.8256\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2310 - accuracy: 0.8918 - val_loss: 0.3772 - val_accuracy: 0.8256\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2276 - accuracy: 0.9051 - val_loss: 0.3811 - val_accuracy: 0.8256\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2332 - accuracy: 0.9095 - val_loss: 0.3753 - val_accuracy: 0.8308\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2272 - accuracy: 0.9029 - val_loss: 0.3789 - val_accuracy: 0.8308\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2272 - accuracy: 0.9073 - val_loss: 0.3910 - val_accuracy: 0.8256\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8940 - val_loss: 0.3907 - val_accuracy: 0.8205\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2354 - accuracy: 0.8962 - val_loss: 0.3812 - val_accuracy: 0.8308\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2287 - accuracy: 0.8985 - val_loss: 0.3750 - val_accuracy: 0.8308\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2267 - accuracy: 0.9029 - val_loss: 0.3901 - val_accuracy: 0.8205\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2305 - accuracy: 0.8940 - val_loss: 0.3830 - val_accuracy: 0.8308\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2338 - accuracy: 0.8985 - val_loss: 0.3849 - val_accuracy: 0.8205\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2269 - accuracy: 0.9029 - val_loss: 0.3811 - val_accuracy: 0.8308\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2409 - accuracy: 0.8918 - val_loss: 0.3821 - val_accuracy: 0.8308\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2385 - accuracy: 0.8985 - val_loss: 0.3782 - val_accuracy: 0.8308\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2316 - accuracy: 0.9051 - val_loss: 0.3839 - val_accuracy: 0.8308\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 96us/step - loss: 0.2309 - accuracy: 0.9029 - val_loss: 0.4021 - val_accuracy: 0.8256\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2362 - accuracy: 0.9029 - val_loss: 0.3735 - val_accuracy: 0.8308\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2273 - accuracy: 0.8985 - val_loss: 0.3758 - val_accuracy: 0.8308\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2416 - accuracy: 0.8985 - val_loss: 0.3805 - val_accuracy: 0.8308\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2348 - accuracy: 0.9029 - val_loss: 0.3930 - val_accuracy: 0.8308\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2285 - accuracy: 0.9029 - val_loss: 0.3880 - val_accuracy: 0.8205\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2377 - accuracy: 0.8896 - val_loss: 0.3763 - val_accuracy: 0.8308\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2341 - accuracy: 0.8940 - val_loss: 0.3859 - val_accuracy: 0.8256\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2285 - accuracy: 0.9051 - val_loss: 0.3880 - val_accuracy: 0.8308\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2301 - accuracy: 0.8985 - val_loss: 0.4002 - val_accuracy: 0.8205\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2236 - accuracy: 0.9073 - val_loss: 0.3830 - val_accuracy: 0.8308\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2259 - accuracy: 0.9007 - val_loss: 0.3855 - val_accuracy: 0.8205\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2270 - accuracy: 0.9073 - val_loss: 0.3922 - val_accuracy: 0.8308\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2270 - accuracy: 0.9051 - val_loss: 0.3939 - val_accuracy: 0.8256\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2330 - accuracy: 0.8985 - val_loss: 0.3772 - val_accuracy: 0.8308\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2385 - accuracy: 0.8985 - val_loss: 0.3956 - val_accuracy: 0.8462\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.4026 - val_accuracy: 0.8256\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2285 - accuracy: 0.9051 - val_loss: 0.3907 - val_accuracy: 0.8205\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2240 - accuracy: 0.9007 - val_loss: 0.3921 - val_accuracy: 0.8308\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2256 - accuracy: 0.9051 - val_loss: 0.3797 - val_accuracy: 0.8308\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2286 - accuracy: 0.9051 - val_loss: 0.3892 - val_accuracy: 0.8205\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2285 - accuracy: 0.9029 - val_loss: 0.3783 - val_accuracy: 0.8308\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2218 - accuracy: 0.9051 - val_loss: 0.3825 - val_accuracy: 0.8308\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2226 - accuracy: 0.9029 - val_loss: 0.3814 - val_accuracy: 0.8308\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2259 - accuracy: 0.9051 - val_loss: 0.3876 - val_accuracy: 0.8308\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2276 - accuracy: 0.9007 - val_loss: 0.3940 - val_accuracy: 0.8308\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2241 - accuracy: 0.9073 - val_loss: 0.3913 - val_accuracy: 0.8205\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2239 - accuracy: 0.8985 - val_loss: 0.3845 - val_accuracy: 0.8462\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2263 - accuracy: 0.9029 - val_loss: 0.3863 - val_accuracy: 0.8205\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2323 - accuracy: 0.8896 - val_loss: 0.3855 - val_accuracy: 0.8308\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2206 - accuracy: 0.9029 - val_loss: 0.3887 - val_accuracy: 0.8205\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2259 - accuracy: 0.9029 - val_loss: 0.3969 - val_accuracy: 0.8205\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2241 - accuracy: 0.9029 - val_loss: 0.3852 - val_accuracy: 0.8308\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2368 - accuracy: 0.8985 - val_loss: 0.3863 - val_accuracy: 0.8308\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2242 - accuracy: 0.9073 - val_loss: 0.3873 - val_accuracy: 0.8308\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2222 - accuracy: 0.9051 - val_loss: 0.3896 - val_accuracy: 0.8308\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.9029 - val_loss: 0.3805 - val_accuracy: 0.8308\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2214 - accuracy: 0.9051 - val_loss: 0.3943 - val_accuracy: 0.8308\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2322 - accuracy: 0.8940 - val_loss: 0.3884 - val_accuracy: 0.8308\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2318 - accuracy: 0.8940 - val_loss: 0.3967 - val_accuracy: 0.8205\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2262 - accuracy: 0.9029 - val_loss: 0.3793 - val_accuracy: 0.8308\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2247 - accuracy: 0.9029 - val_loss: 0.3787 - val_accuracy: 0.8308\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2214 - accuracy: 0.9051 - val_loss: 0.3856 - val_accuracy: 0.8308\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2230 - accuracy: 0.9073 - val_loss: 0.3910 - val_accuracy: 0.8308\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2234 - accuracy: 0.9007 - val_loss: 0.3919 - val_accuracy: 0.8308\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2234 - accuracy: 0.9051 - val_loss: 0.3955 - val_accuracy: 0.8308\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2194 - accuracy: 0.9051 - val_loss: 0.4099 - val_accuracy: 0.8462\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2345 - accuracy: 0.8985 - val_loss: 0.3820 - val_accuracy: 0.8308\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2240 - accuracy: 0.8962 - val_loss: 0.3938 - val_accuracy: 0.8205\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2224 - accuracy: 0.9051 - val_loss: 0.3945 - val_accuracy: 0.8308\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2198 - accuracy: 0.9073 - val_loss: 0.3810 - val_accuracy: 0.8308\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2219 - accuracy: 0.9073 - val_loss: 0.3996 - val_accuracy: 0.8205\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2234 - accuracy: 0.9073 - val_loss: 0.3979 - val_accuracy: 0.8308\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2219 - accuracy: 0.9029 - val_loss: 0.3973 - val_accuracy: 0.8205\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2195 - accuracy: 0.9073 - val_loss: 0.3946 - val_accuracy: 0.8308\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2205 - accuracy: 0.9029 - val_loss: 0.3880 - val_accuracy: 0.8308\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2259 - accuracy: 0.9051 - val_loss: 0.3845 - val_accuracy: 0.8308\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2209 - accuracy: 0.9051 - val_loss: 0.3920 - val_accuracy: 0.8308\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2271 - accuracy: 0.9073 - val_loss: 0.3923 - val_accuracy: 0.8308\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2225 - accuracy: 0.9073 - val_loss: 0.3939 - val_accuracy: 0.8308\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2204 - accuracy: 0.9007 - val_loss: 0.3854 - val_accuracy: 0.8308\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2214 - accuracy: 0.9073 - val_loss: 0.3836 - val_accuracy: 0.8308\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2235 - accuracy: 0.9051 - val_loss: 0.3875 - val_accuracy: 0.8308\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2205 - accuracy: 0.9073 - val_loss: 0.3995 - val_accuracy: 0.8308\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2211 - accuracy: 0.9073 - val_loss: 0.3879 - val_accuracy: 0.8308\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2178 - accuracy: 0.9073 - val_loss: 0.4016 - val_accuracy: 0.8308\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2200 - accuracy: 0.9073 - val_loss: 0.3823 - val_accuracy: 0.8308\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2224 - accuracy: 0.9007 - val_loss: 0.3906 - val_accuracy: 0.8308\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2245 - accuracy: 0.9051 - val_loss: 0.3839 - val_accuracy: 0.8308\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2235 - accuracy: 0.8985 - val_loss: 0.3915 - val_accuracy: 0.8308\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2235 - accuracy: 0.8962 - val_loss: 0.4201 - val_accuracy: 0.8205\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2228 - accuracy: 0.9051 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2383 - accuracy: 0.9029 - val_loss: 0.3992 - val_accuracy: 0.8308\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2221 - accuracy: 0.9029 - val_loss: 0.3953 - val_accuracy: 0.8308\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2215 - accuracy: 0.9051 - val_loss: 0.3897 - val_accuracy: 0.8308\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2218 - accuracy: 0.9029 - val_loss: 0.3837 - val_accuracy: 0.8308\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2204 - accuracy: 0.9051 - val_loss: 0.3938 - val_accuracy: 0.8308\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2188 - accuracy: 0.9051 - val_loss: 0.4025 - val_accuracy: 0.8308\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2224 - accuracy: 0.9073 - val_loss: 0.3949 - val_accuracy: 0.8308\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2296 - accuracy: 0.8962 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2263 - accuracy: 0.9029 - val_loss: 0.3925 - val_accuracy: 0.8308\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2176 - accuracy: 0.9051 - val_loss: 0.3947 - val_accuracy: 0.8308\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2192 - accuracy: 0.9029 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2227 - accuracy: 0.9073 - val_loss: 0.4001 - val_accuracy: 0.8308\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2199 - accuracy: 0.9051 - val_loss: 0.4009 - val_accuracy: 0.8308\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2199 - accuracy: 0.9051 - val_loss: 0.3935 - val_accuracy: 0.8308\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2181 - accuracy: 0.9051 - val_loss: 0.3873 - val_accuracy: 0.8308\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2189 - accuracy: 0.9073 - val_loss: 0.4024 - val_accuracy: 0.8308\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2230 - accuracy: 0.9007 - val_loss: 0.3918 - val_accuracy: 0.8308\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2209 - accuracy: 0.9029 - val_loss: 0.4115 - val_accuracy: 0.8308\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2199 - accuracy: 0.9073 - val_loss: 0.3888 - val_accuracy: 0.8308\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2220 - accuracy: 0.9073 - val_loss: 0.3932 - val_accuracy: 0.8308\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2229 - accuracy: 0.9051 - val_loss: 0.3919 - val_accuracy: 0.8308\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2214 - accuracy: 0.9051 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2214 - accuracy: 0.9051 - val_loss: 0.3875 - val_accuracy: 0.8308\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2220 - accuracy: 0.9051 - val_loss: 0.3938 - val_accuracy: 0.8308\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2322 - accuracy: 0.9051 - val_loss: 0.3989 - val_accuracy: 0.8308\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2218 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2279 - accuracy: 0.9073 - val_loss: 0.4164 - val_accuracy: 0.8205\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2159 - accuracy: 0.9051 - val_loss: 0.4014 - val_accuracy: 0.8308\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9007 - val_loss: 0.3990 - val_accuracy: 0.8308\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2178 - accuracy: 0.9073 - val_loss: 0.4291 - val_accuracy: 0.8308\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2225 - accuracy: 0.9029 - val_loss: 0.4147 - val_accuracy: 0.8205\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2204 - accuracy: 0.9007 - val_loss: 0.3873 - val_accuracy: 0.8308\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2207 - accuracy: 0.9029 - val_loss: 0.3964 - val_accuracy: 0.8359\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2165 - accuracy: 0.9051 - val_loss: 0.3908 - val_accuracy: 0.8308\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2186 - accuracy: 0.9073 - val_loss: 0.3986 - val_accuracy: 0.8308\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2212 - accuracy: 0.9051 - val_loss: 0.3958 - val_accuracy: 0.8308\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2207 - accuracy: 0.9073 - val_loss: 0.3902 - val_accuracy: 0.8308\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.3936 - val_accuracy: 0.8308\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 136us/step - loss: 0.2168 - accuracy: 0.9051 - val_loss: 0.3899 - val_accuracy: 0.8308\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2224 - accuracy: 0.9073 - val_loss: 0.3971 - val_accuracy: 0.8308\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.4049 - val_accuracy: 0.8308\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2221 - accuracy: 0.9051 - val_loss: 0.3972 - val_accuracy: 0.8308\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2219 - accuracy: 0.9029 - val_loss: 0.3961 - val_accuracy: 0.8308\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4049 - val_accuracy: 0.8308\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2175 - accuracy: 0.9073 - val_loss: 0.3990 - val_accuracy: 0.8308\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2172 - accuracy: 0.9073 - val_loss: 0.3980 - val_accuracy: 0.8308\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2163 - accuracy: 0.9073 - val_loss: 0.4003 - val_accuracy: 0.8308\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2182 - accuracy: 0.9073 - val_loss: 0.4060 - val_accuracy: 0.8308\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2199 - accuracy: 0.9051 - val_loss: 0.4005 - val_accuracy: 0.8308\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2193 - accuracy: 0.9073 - val_loss: 0.3982 - val_accuracy: 0.8308\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.4028 - val_accuracy: 0.8308\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2219 - accuracy: 0.9007 - val_loss: 0.4120 - val_accuracy: 0.8308\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2152 - accuracy: 0.9073 - val_loss: 0.4254 - val_accuracy: 0.8308\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2198 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2233 - accuracy: 0.9073 - val_loss: 0.4044 - val_accuracy: 0.8308\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.3997 - val_accuracy: 0.8308\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2234 - accuracy: 0.9073 - val_loss: 0.4029 - val_accuracy: 0.8308\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2177 - accuracy: 0.9051 - val_loss: 0.4304 - val_accuracy: 0.8359\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2235 - accuracy: 0.9029 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2163 - accuracy: 0.9073 - val_loss: 0.4074 - val_accuracy: 0.8308\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2150 - accuracy: 0.9073 - val_loss: 0.4000 - val_accuracy: 0.8308\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4084 - val_accuracy: 0.8205\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4106 - val_accuracy: 0.8308\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2169 - accuracy: 0.9051 - val_loss: 0.3970 - val_accuracy: 0.8308\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2160 - accuracy: 0.9073 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4011 - val_accuracy: 0.8308\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3984 - val_accuracy: 0.8308\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2230 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2210 - accuracy: 0.9029 - val_loss: 0.4034 - val_accuracy: 0.8308\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2186 - accuracy: 0.9073 - val_loss: 0.4129 - val_accuracy: 0.8308\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2200 - accuracy: 0.9073 - val_loss: 0.4118 - val_accuracy: 0.8308\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4132 - val_accuracy: 0.8308\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2189 - accuracy: 0.9051 - val_loss: 0.4226 - val_accuracy: 0.8205\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.4083 - val_accuracy: 0.8308\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2170 - accuracy: 0.9073 - val_loss: 0.4061 - val_accuracy: 0.8308\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4047 - val_accuracy: 0.8308\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2130 - accuracy: 0.9095 - val_loss: 0.4428 - val_accuracy: 0.8256\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2256 - accuracy: 0.9073 - val_loss: 0.3969 - val_accuracy: 0.8308\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2226 - accuracy: 0.9029 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2246 - accuracy: 0.9073 - val_loss: 0.4034 - val_accuracy: 0.8308\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2173 - accuracy: 0.9073 - val_loss: 0.4039 - val_accuracy: 0.8308\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2151 - accuracy: 0.9073 - val_loss: 0.4197 - val_accuracy: 0.8308\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2229 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4104 - val_accuracy: 0.8308\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2199 - accuracy: 0.9073 - val_loss: 0.4043 - val_accuracy: 0.8308\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2168 - accuracy: 0.9073 - val_loss: 0.4070 - val_accuracy: 0.8308\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2173 - accuracy: 0.9073 - val_loss: 0.4056 - val_accuracy: 0.8308\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2131 - accuracy: 0.9073 - val_loss: 0.4004 - val_accuracy: 0.8308\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4009 - val_accuracy: 0.8308\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2188 - accuracy: 0.9007 - val_loss: 0.4032 - val_accuracy: 0.8308\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2210 - accuracy: 0.9029 - val_loss: 0.4109 - val_accuracy: 0.8308\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2221 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.4071 - val_accuracy: 0.8308\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.4218 - val_accuracy: 0.8308\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2203 - accuracy: 0.9073 - val_loss: 0.4126 - val_accuracy: 0.8308\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.4124 - val_accuracy: 0.8308\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2161 - accuracy: 0.9073 - val_loss: 0.4130 - val_accuracy: 0.8308\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2173 - accuracy: 0.9073 - val_loss: 0.4182 - val_accuracy: 0.8308\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4079 - val_accuracy: 0.8308\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2177 - accuracy: 0.9073 - val_loss: 0.4166 - val_accuracy: 0.8308\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2165 - accuracy: 0.9029 - val_loss: 0.4075 - val_accuracy: 0.8308\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2154 - accuracy: 0.9073 - val_loss: 0.4106 - val_accuracy: 0.8308\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2163 - accuracy: 0.9073 - val_loss: 0.4143 - val_accuracy: 0.8308\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2183 - accuracy: 0.9073 - val_loss: 0.4225 - val_accuracy: 0.8308\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2160 - accuracy: 0.9073 - val_loss: 0.4152 - val_accuracy: 0.8308\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2231 - accuracy: 0.9073 - val_loss: 0.4095 - val_accuracy: 0.8308\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2197 - accuracy: 0.9007 - val_loss: 0.4114 - val_accuracy: 0.8308\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2142 - accuracy: 0.9073 - val_loss: 0.4157 - val_accuracy: 0.8308\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2184 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2160 - accuracy: 0.9073 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2168 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2209 - accuracy: 0.9073 - val_loss: 0.4097 - val_accuracy: 0.8308\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2150 - accuracy: 0.9073 - val_loss: 0.4198 - val_accuracy: 0.8308\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2142 - accuracy: 0.9051 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4119 - val_accuracy: 0.8308\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2153 - accuracy: 0.9073 - val_loss: 0.4100 - val_accuracy: 0.8308\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2172 - accuracy: 0.9073 - val_loss: 0.4171 - val_accuracy: 0.8308\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4207 - val_accuracy: 0.8308\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2176 - accuracy: 0.9073 - val_loss: 0.4179 - val_accuracy: 0.8308\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2162 - accuracy: 0.9073 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2195 - accuracy: 0.9073 - val_loss: 0.4265 - val_accuracy: 0.8308\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4187 - val_accuracy: 0.8308\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2191 - accuracy: 0.9073 - val_loss: 0.4274 - val_accuracy: 0.8308\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2208 - accuracy: 0.9073 - val_loss: 0.4238 - val_accuracy: 0.8308\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2240 - accuracy: 0.9051 - val_loss: 0.4250 - val_accuracy: 0.8308\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2189 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4201 - val_accuracy: 0.8308\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2170 - accuracy: 0.9073 - val_loss: 0.4267 - val_accuracy: 0.8308\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4203 - val_accuracy: 0.8308\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4275 - val_accuracy: 0.8308\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2154 - accuracy: 0.9007 - val_loss: 0.4244 - val_accuracy: 0.8308\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2184 - accuracy: 0.9051 - val_loss: 0.4104 - val_accuracy: 0.8308\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4289 - val_accuracy: 0.8308\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2173 - accuracy: 0.9073 - val_loss: 0.4309 - val_accuracy: 0.8308\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2152 - accuracy: 0.9073 - val_loss: 0.4151 - val_accuracy: 0.8308\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.4324 - val_accuracy: 0.8308\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2162 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4188 - val_accuracy: 0.8308\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4200 - val_accuracy: 0.8308\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4350 - val_accuracy: 0.8308\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4281 - val_accuracy: 0.8308\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2151 - accuracy: 0.9073 - val_loss: 0.4374 - val_accuracy: 0.8308\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.4280 - val_accuracy: 0.8308\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2129 - accuracy: 0.9073 - val_loss: 0.4268 - val_accuracy: 0.8308\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2159 - accuracy: 0.9073 - val_loss: 0.4517 - val_accuracy: 0.8308\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4172 - val_accuracy: 0.8410\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2219 - accuracy: 0.9029 - val_loss: 0.4274 - val_accuracy: 0.8308\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4241 - val_accuracy: 0.8308\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2146 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2194 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2162 - accuracy: 0.9073 - val_loss: 0.4211 - val_accuracy: 0.8308\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2204 - accuracy: 0.8985 - val_loss: 0.4186 - val_accuracy: 0.8308\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4221 - val_accuracy: 0.8308\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2159 - accuracy: 0.9073 - val_loss: 0.4288 - val_accuracy: 0.8308\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2181 - accuracy: 0.9029 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2202 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4142 - val_accuracy: 0.8308\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4231 - val_accuracy: 0.8308\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2161 - accuracy: 0.9073 - val_loss: 0.4434 - val_accuracy: 0.8308\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4295 - val_accuracy: 0.8308\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4271 - val_accuracy: 0.8308\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2142 - accuracy: 0.9073 - val_loss: 0.4346 - val_accuracy: 0.8308\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2153 - accuracy: 0.9073 - val_loss: 0.4319 - val_accuracy: 0.8308\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4330 - val_accuracy: 0.8308\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2129 - accuracy: 0.9073 - val_loss: 0.4403 - val_accuracy: 0.8308\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2143 - accuracy: 0.9007 - val_loss: 0.4296 - val_accuracy: 0.8308\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4399 - val_accuracy: 0.8308\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2156 - accuracy: 0.9073 - val_loss: 0.4539 - val_accuracy: 0.8308\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4224 - val_accuracy: 0.8308\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2168 - accuracy: 0.9073 - val_loss: 0.4322 - val_accuracy: 0.8308\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4602 - val_accuracy: 0.8308\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2169 - accuracy: 0.9073 - val_loss: 0.4312 - val_accuracy: 0.8308\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4366 - val_accuracy: 0.8308\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2143 - accuracy: 0.9073 - val_loss: 0.4345 - val_accuracy: 0.8308\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2153 - accuracy: 0.9073 - val_loss: 0.4299 - val_accuracy: 0.8308\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4369 - val_accuracy: 0.8308\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4402 - val_accuracy: 0.8308\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4678 - val_accuracy: 0.8308\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2162 - accuracy: 0.9073 - val_loss: 0.4326 - val_accuracy: 0.8308\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2171 - accuracy: 0.9073 - val_loss: 0.4345 - val_accuracy: 0.8308\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2193 - accuracy: 0.9029 - val_loss: 0.4373 - val_accuracy: 0.8308\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.4336 - val_accuracy: 0.8308\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2213 - accuracy: 0.8985 - val_loss: 0.4299 - val_accuracy: 0.8308\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4342 - val_accuracy: 0.8308\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4317 - val_accuracy: 0.8308\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4301 - val_accuracy: 0.8308\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4341 - val_accuracy: 0.8308\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4334 - val_accuracy: 0.8308\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2170 - accuracy: 0.9073 - val_loss: 0.4311 - val_accuracy: 0.8308\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4287 - val_accuracy: 0.8308\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2156 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2175 - accuracy: 0.9073 - val_loss: 0.4294 - val_accuracy: 0.8308\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2214 - accuracy: 0.9029 - val_loss: 0.4349 - val_accuracy: 0.8308\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4282 - val_accuracy: 0.8308\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2165 - accuracy: 0.9073 - val_loss: 0.4370 - val_accuracy: 0.8308\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.4358 - val_accuracy: 0.8308\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2113 - accuracy: 0.9073 - val_loss: 0.4375 - val_accuracy: 0.8308\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2129 - accuracy: 0.9073 - val_loss: 0.4393 - val_accuracy: 0.8308\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4412 - val_accuracy: 0.8308\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4392 - val_accuracy: 0.8308\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2186 - accuracy: 0.9007 - val_loss: 0.4364 - val_accuracy: 0.8308\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2175 - accuracy: 0.9073 - val_loss: 0.4433 - val_accuracy: 0.8308\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4413 - val_accuracy: 0.8308\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2152 - accuracy: 0.9073 - val_loss: 0.5013 - val_accuracy: 0.8308\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2161 - accuracy: 0.9073 - val_loss: 0.4313 - val_accuracy: 0.8308\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4256 - val_accuracy: 0.8308\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2167 - accuracy: 0.9007 - val_loss: 0.4332 - val_accuracy: 0.8308\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2156 - accuracy: 0.9073 - val_loss: 0.4350 - val_accuracy: 0.8308\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2144 - accuracy: 0.9073 - val_loss: 0.4389 - val_accuracy: 0.8308\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.4684 - val_accuracy: 0.8308\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2193 - accuracy: 0.9073 - val_loss: 0.4469 - val_accuracy: 0.8308\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2163 - accuracy: 0.9073 - val_loss: 0.4439 - val_accuracy: 0.8308\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4454 - val_accuracy: 0.8308\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4471 - val_accuracy: 0.8308\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2201 - accuracy: 0.9029 - val_loss: 0.4342 - val_accuracy: 0.8308\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4269 - val_accuracy: 0.8308\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4415 - val_accuracy: 0.8308\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4420 - val_accuracy: 0.8308\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4416 - val_accuracy: 0.8308\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4445 - val_accuracy: 0.8308\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4507 - val_accuracy: 0.8308\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2160 - accuracy: 0.8985 - val_loss: 0.4508 - val_accuracy: 0.8308\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4527 - val_accuracy: 0.8308\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4503 - val_accuracy: 0.8308\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4525 - val_accuracy: 0.8308\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4496 - val_accuracy: 0.8308\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4472 - val_accuracy: 0.8308\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4528 - val_accuracy: 0.8308\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2154 - accuracy: 0.9073 - val_loss: 0.4574 - val_accuracy: 0.8308\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4498 - val_accuracy: 0.8308\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4578 - val_accuracy: 0.8308\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4569 - val_accuracy: 0.8308\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4510 - val_accuracy: 0.8308\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4547 - val_accuracy: 0.8308\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4567 - val_accuracy: 0.8308\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4559 - val_accuracy: 0.8308\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4530 - val_accuracy: 0.8308\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4465 - val_accuracy: 0.8308\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2206 - accuracy: 0.9051 - val_loss: 0.4607 - val_accuracy: 0.8308\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2131 - accuracy: 0.9073 - val_loss: 0.4487 - val_accuracy: 0.8308\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4573 - val_accuracy: 0.8308\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4457 - val_accuracy: 0.8308\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2143 - accuracy: 0.9073 - val_loss: 0.4500 - val_accuracy: 0.8308\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.4412 - val_accuracy: 0.8308\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4511 - val_accuracy: 0.8308\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4527 - val_accuracy: 0.8308\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2159 - accuracy: 0.9073 - val_loss: 0.4510 - val_accuracy: 0.8308\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 399us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4533 - val_accuracy: 0.8308\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4597 - val_accuracy: 0.8308\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2152 - accuracy: 0.9073 - val_loss: 0.4512 - val_accuracy: 0.8308\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2146 - accuracy: 0.9073 - val_loss: 0.4593 - val_accuracy: 0.8308\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 116us/step - loss: 0.2200 - accuracy: 0.9073 - val_loss: 0.4587 - val_accuracy: 0.8308\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.4408 - val_accuracy: 0.8308\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4459 - val_accuracy: 0.8308\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4480 - val_accuracy: 0.8308\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4566 - val_accuracy: 0.8308\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2130 - accuracy: 0.9051 - val_loss: 0.4480 - val_accuracy: 0.8308\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4536 - val_accuracy: 0.8308\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2161 - accuracy: 0.9029 - val_loss: 0.4490 - val_accuracy: 0.8308\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4488 - val_accuracy: 0.8308\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2146 - accuracy: 0.9073 - val_loss: 0.4637 - val_accuracy: 0.8308\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2156 - accuracy: 0.9073 - val_loss: 0.4542 - val_accuracy: 0.8308\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4525 - val_accuracy: 0.8308\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4529 - val_accuracy: 0.8308\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4545 - val_accuracy: 0.8308\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4555 - val_accuracy: 0.8308\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4587 - val_accuracy: 0.8308\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4571 - val_accuracy: 0.8308\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2143 - accuracy: 0.9073 - val_loss: 0.4590 - val_accuracy: 0.8308\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4660 - val_accuracy: 0.8308\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4555 - val_accuracy: 0.8308\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4673 - val_accuracy: 0.8308\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4487 - val_accuracy: 0.8308\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4579 - val_accuracy: 0.8308\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2143 - accuracy: 0.9051 - val_loss: 0.4528 - val_accuracy: 0.8308\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4514 - val_accuracy: 0.8308\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2238 - accuracy: 0.9007 - val_loss: 0.4541 - val_accuracy: 0.8308\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4593 - val_accuracy: 0.8308\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.4623 - val_accuracy: 0.8308\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2168 - accuracy: 0.9073 - val_loss: 0.4654 - val_accuracy: 0.8308\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.4643 - val_accuracy: 0.8308\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4544 - val_accuracy: 0.8308\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4576 - val_accuracy: 0.8308\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4610 - val_accuracy: 0.8308\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4571 - val_accuracy: 0.8308\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 429us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4633 - val_accuracy: 0.8308\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 457us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4527 - val_accuracy: 0.8308\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 355us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4442 - val_accuracy: 0.8308\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2131 - accuracy: 0.9073 - val_loss: 0.4539 - val_accuracy: 0.8308\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4554 - val_accuracy: 0.8308\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2128 - accuracy: 0.9007 - val_loss: 0.4587 - val_accuracy: 0.8308\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4671 - val_accuracy: 0.8308\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2099 - accuracy: 0.9051 - val_loss: 0.4626 - val_accuracy: 0.8308\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4670 - val_accuracy: 0.8308\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.4526 - val_accuracy: 0.8308\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4624 - val_accuracy: 0.8308\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4642 - val_accuracy: 0.8308\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2159 - accuracy: 0.9073 - val_loss: 0.4553 - val_accuracy: 0.8308\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4672 - val_accuracy: 0.8308\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 384us/step - loss: 0.2169 - accuracy: 0.9073 - val_loss: 0.4598 - val_accuracy: 0.8308\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 323us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4626 - val_accuracy: 0.8308\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 360us/step - loss: 0.2142 - accuracy: 0.9073 - val_loss: 0.4630 - val_accuracy: 0.8308\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4667 - val_accuracy: 0.8308\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2166 - accuracy: 0.8985 - val_loss: 0.4661 - val_accuracy: 0.8308\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4682 - val_accuracy: 0.8308\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4696 - val_accuracy: 0.8308\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4735 - val_accuracy: 0.8308\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4677 - val_accuracy: 0.8308\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4708 - val_accuracy: 0.8308\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4704 - val_accuracy: 0.8308\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 371us/step - loss: 0.2176 - accuracy: 0.9029 - val_loss: 0.4689 - val_accuracy: 0.8308\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4663 - val_accuracy: 0.8308\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.4505 - val_accuracy: 0.8308\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4643 - val_accuracy: 0.8308\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 317us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4521 - val_accuracy: 0.8308\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2109 - accuracy: 0.9051 - val_loss: 0.4570 - val_accuracy: 0.8308\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4592 - val_accuracy: 0.8308\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4635 - val_accuracy: 0.8308\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 350us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4624 - val_accuracy: 0.8308\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4631 - val_accuracy: 0.8308\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4648 - val_accuracy: 0.8308\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2121 - accuracy: 0.9007 - val_loss: 0.4631 - val_accuracy: 0.8308\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.5117 - val_accuracy: 0.8308\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2167 - accuracy: 0.9073 - val_loss: 0.4567 - val_accuracy: 0.8308\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4500 - val_accuracy: 0.8308\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4652 - val_accuracy: 0.8308\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2143 - accuracy: 0.9073 - val_loss: 0.4596 - val_accuracy: 0.8308\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.4687 - val_accuracy: 0.8308\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4741 - val_accuracy: 0.8308\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2167 - accuracy: 0.9073 - val_loss: 0.4718 - val_accuracy: 0.8308\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2160 - accuracy: 0.9073 - val_loss: 0.4696 - val_accuracy: 0.8308\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4650 - val_accuracy: 0.8308\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4697 - val_accuracy: 0.8308\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4684 - val_accuracy: 0.8308\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4668 - val_accuracy: 0.8308\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4685 - val_accuracy: 0.8308\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4730 - val_accuracy: 0.8308\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2166 - accuracy: 0.9073 - val_loss: 0.4733 - val_accuracy: 0.8308\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2171 - accuracy: 0.9007 - val_loss: 0.4746 - val_accuracy: 0.8308\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4741 - val_accuracy: 0.8308\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4678 - val_accuracy: 0.8308\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4766 - val_accuracy: 0.8308\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4852 - val_accuracy: 0.8308\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4729 - val_accuracy: 0.8308\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2149 - accuracy: 0.9073 - val_loss: 0.4840 - val_accuracy: 0.8308\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4717 - val_accuracy: 0.8308\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2114 - accuracy: 0.9051 - val_loss: 0.4782 - val_accuracy: 0.8308\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4750 - val_accuracy: 0.8308\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4752 - val_accuracy: 0.8308\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4800 - val_accuracy: 0.8308\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.4741 - val_accuracy: 0.8308\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4750 - val_accuracy: 0.8308\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4777 - val_accuracy: 0.8308\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2117 - accuracy: 0.9051 - val_loss: 0.4735 - val_accuracy: 0.8308\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2200 - accuracy: 0.9029 - val_loss: 0.4769 - val_accuracy: 0.8308\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4752 - val_accuracy: 0.8308\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4755 - val_accuracy: 0.8308\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4814 - val_accuracy: 0.8308\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2115 - accuracy: 0.9073 - val_loss: 0.4590 - val_accuracy: 0.8308\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4580 - val_accuracy: 0.8308\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4668 - val_accuracy: 0.8308\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 122us/step - loss: 0.2129 - accuracy: 0.9073 - val_loss: 0.4709 - val_accuracy: 0.8308\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4717 - val_accuracy: 0.8308\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4761 - val_accuracy: 0.8308\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2113 - accuracy: 0.9051 - val_loss: 0.4700 - val_accuracy: 0.8308\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4806 - val_accuracy: 0.8308\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4772 - val_accuracy: 0.8308\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4764 - val_accuracy: 0.8308\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4791 - val_accuracy: 0.8308\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2145 - accuracy: 0.9073 - val_loss: 0.4777 - val_accuracy: 0.8308\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4789 - val_accuracy: 0.8308\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2206 - accuracy: 0.9073 - val_loss: 0.4914 - val_accuracy: 0.8308\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4754 - val_accuracy: 0.8308\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4859 - val_accuracy: 0.8308\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4750 - val_accuracy: 0.8308\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4844 - val_accuracy: 0.8308\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2137 - accuracy: 0.9051 - val_loss: 0.4874 - val_accuracy: 0.8308\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4779 - val_accuracy: 0.8308\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4834 - val_accuracy: 0.8308\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.5524 - val_accuracy: 0.8410\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2206 - accuracy: 0.9051 - val_loss: 0.4557 - val_accuracy: 0.8308\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4664 - val_accuracy: 0.8308\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4787 - val_accuracy: 0.8308\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.4661 - val_accuracy: 0.8308\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2203 - accuracy: 0.9117 - val_loss: 0.4698 - val_accuracy: 0.8308\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4805 - val_accuracy: 0.8308\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4758 - val_accuracy: 0.8308\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2165 - accuracy: 0.9073 - val_loss: 0.4766 - val_accuracy: 0.8308\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4804 - val_accuracy: 0.8308\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4742 - val_accuracy: 0.8308\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4819 - val_accuracy: 0.8308\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4768 - val_accuracy: 0.8308\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.4837 - val_accuracy: 0.8308\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4848 - val_accuracy: 0.8308\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4773 - val_accuracy: 0.8308\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4883 - val_accuracy: 0.8308\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.4819 - val_accuracy: 0.8308\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2129 - accuracy: 0.9073 - val_loss: 0.4772 - val_accuracy: 0.8308\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4865 - val_accuracy: 0.8308\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4807 - val_accuracy: 0.8308\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2159 - accuracy: 0.9073 - val_loss: 0.4791 - val_accuracy: 0.8308\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4843 - val_accuracy: 0.8308\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4736 - val_accuracy: 0.8308\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.4867 - val_accuracy: 0.8308\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2178 - accuracy: 0.9073 - val_loss: 0.4914 - val_accuracy: 0.8308\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4738 - val_accuracy: 0.8308\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2178 - accuracy: 0.9073 - val_loss: 0.4836 - val_accuracy: 0.8308\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4780 - val_accuracy: 0.8308\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4795 - val_accuracy: 0.8308\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4778 - val_accuracy: 0.8308\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2161 - accuracy: 0.9073 - val_loss: 0.5338 - val_accuracy: 0.8308\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4654 - val_accuracy: 0.8308\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4703 - val_accuracy: 0.8308\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4690 - val_accuracy: 0.8308\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 503us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4670 - val_accuracy: 0.8308\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4758 - val_accuracy: 0.8308\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.9073 - val_loss: 0.4791 - val_accuracy: 0.8308\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2161 - accuracy: 0.9073 - val_loss: 0.4726 - val_accuracy: 0.8308\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4741 - val_accuracy: 0.8308\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4761 - val_accuracy: 0.8308\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4782 - val_accuracy: 0.8308\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 349us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4814 - val_accuracy: 0.8308\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2187 - accuracy: 0.9029 - val_loss: 0.4720 - val_accuracy: 0.8308\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4780 - val_accuracy: 0.8308\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4781 - val_accuracy: 0.8308\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4854 - val_accuracy: 0.8308\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 373us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4798 - val_accuracy: 0.8308\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4846 - val_accuracy: 0.8308\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2156 - accuracy: 0.9073 - val_loss: 0.4841 - val_accuracy: 0.8308\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4795 - val_accuracy: 0.8308\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4835 - val_accuracy: 0.8308\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4822 - val_accuracy: 0.8308\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4699 - val_accuracy: 0.8308\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4692 - val_accuracy: 0.8308\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2149 - accuracy: 0.9073 - val_loss: 0.4739 - val_accuracy: 0.8308\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4703 - val_accuracy: 0.8308\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2160 - accuracy: 0.9073 - val_loss: 0.4808 - val_accuracy: 0.8308\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4787 - val_accuracy: 0.8308\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4794 - val_accuracy: 0.8308\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2135 - accuracy: 0.9007 - val_loss: 0.4795 - val_accuracy: 0.8308\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4811 - val_accuracy: 0.8308\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4760 - val_accuracy: 0.8308\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4801 - val_accuracy: 0.8308\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4878 - val_accuracy: 0.8308\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4834 - val_accuracy: 0.8308\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4798 - val_accuracy: 0.8308\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4862 - val_accuracy: 0.8308\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4857 - val_accuracy: 0.8308\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4854 - val_accuracy: 0.8308\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4899 - val_accuracy: 0.8308\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2142 - accuracy: 0.9073 - val_loss: 0.4845 - val_accuracy: 0.8308\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4878 - val_accuracy: 0.8308\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.4838 - val_accuracy: 0.8308\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2113 - accuracy: 0.9073 - val_loss: 0.4886 - val_accuracy: 0.8308\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 377us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4827 - val_accuracy: 0.8308\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4826 - val_accuracy: 0.8308\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4907 - val_accuracy: 0.8308\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4861 - val_accuracy: 0.8308\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4877 - val_accuracy: 0.8308\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4801 - val_accuracy: 0.8308\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4930 - val_accuracy: 0.8308\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4672 - val_accuracy: 0.8308\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4671 - val_accuracy: 0.8308\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2142 - accuracy: 0.9073 - val_loss: 0.4799 - val_accuracy: 0.8308\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4761 - val_accuracy: 0.8308\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4835 - val_accuracy: 0.8308\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4742 - val_accuracy: 0.8308\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4846 - val_accuracy: 0.8308\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2149 - accuracy: 0.9073 - val_loss: 0.4841 - val_accuracy: 0.8308\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4833 - val_accuracy: 0.8308\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4845 - val_accuracy: 0.8308\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 126us/step - loss: 0.2133 - accuracy: 0.9051 - val_loss: 0.4789 - val_accuracy: 0.8308\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2147 - accuracy: 0.9029 - val_loss: 0.4956 - val_accuracy: 0.8308\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4873 - val_accuracy: 0.8308\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4915 - val_accuracy: 0.8308\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2153 - accuracy: 0.9073 - val_loss: 0.4849 - val_accuracy: 0.8308\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2138 - accuracy: 0.9051 - val_loss: 0.4868 - val_accuracy: 0.8308\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4896 - val_accuracy: 0.8308\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4866 - val_accuracy: 0.8308\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4953 - val_accuracy: 0.8308\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4838 - val_accuracy: 0.8308\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4880 - val_accuracy: 0.8308\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4868 - val_accuracy: 0.8308\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4837 - val_accuracy: 0.8308\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2147 - accuracy: 0.9073 - val_loss: 0.4850 - val_accuracy: 0.8308\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4877 - val_accuracy: 0.8308\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4831 - val_accuracy: 0.8308\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4867 - val_accuracy: 0.8308\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4786 - val_accuracy: 0.8308\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4800 - val_accuracy: 0.8308\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4783 - val_accuracy: 0.8308\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4849 - val_accuracy: 0.8308\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4840 - val_accuracy: 0.8308\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4873 - val_accuracy: 0.8308\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4897 - val_accuracy: 0.8308\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4854 - val_accuracy: 0.8308\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4922 - val_accuracy: 0.8308\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4823 - val_accuracy: 0.8308\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4866 - val_accuracy: 0.8308\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4948 - val_accuracy: 0.8308\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4847 - val_accuracy: 0.8308\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4857 - val_accuracy: 0.8308\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4910 - val_accuracy: 0.8308\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4878 - val_accuracy: 0.8308\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4859 - val_accuracy: 0.8308\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4969 - val_accuracy: 0.8308\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4872 - val_accuracy: 0.8308\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4892 - val_accuracy: 0.8308\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4913 - val_accuracy: 0.8308\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2173 - accuracy: 0.8985 - val_loss: 0.4999 - val_accuracy: 0.8308\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4904 - val_accuracy: 0.8308\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4901 - val_accuracy: 0.8308\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4908 - val_accuracy: 0.8308\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4913 - val_accuracy: 0.8308\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4900 - val_accuracy: 0.8308\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.4859 - val_accuracy: 0.8308\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4931 - val_accuracy: 0.8308\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4899 - val_accuracy: 0.8308\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.5932 - val_accuracy: 0.8308\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2212 - accuracy: 0.9073 - val_loss: 0.4770 - val_accuracy: 0.8308\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4787 - val_accuracy: 0.8308\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4814 - val_accuracy: 0.8308\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4832 - val_accuracy: 0.8308\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4866 - val_accuracy: 0.8308\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4823 - val_accuracy: 0.8308\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4866 - val_accuracy: 0.8308\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4880 - val_accuracy: 0.8308\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4879 - val_accuracy: 0.8308\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4952 - val_accuracy: 0.8308\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4822 - val_accuracy: 0.8308\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4874 - val_accuracy: 0.8308\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4944 - val_accuracy: 0.8308\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4918 - val_accuracy: 0.8308\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4930 - val_accuracy: 0.8308\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4892 - val_accuracy: 0.8308\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4931 - val_accuracy: 0.8308\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4963 - val_accuracy: 0.8308\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4929 - val_accuracy: 0.8308\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2187 - accuracy: 0.9073 - val_loss: 0.4932 - val_accuracy: 0.8308\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4975 - val_accuracy: 0.8308\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4952 - val_accuracy: 0.8308\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4988 - val_accuracy: 0.8308\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.5587 - val_accuracy: 0.8308\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2189 - accuracy: 0.9029 - val_loss: 0.4760 - val_accuracy: 0.8308\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4817 - val_accuracy: 0.8308\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4835 - val_accuracy: 0.8308\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4822 - val_accuracy: 0.8308\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4907 - val_accuracy: 0.8308\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4887 - val_accuracy: 0.8308\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2087 - accuracy: 0.9051 - val_loss: 0.4815 - val_accuracy: 0.8410\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4878 - val_accuracy: 0.8308\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4886 - val_accuracy: 0.8308\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4928 - val_accuracy: 0.8308\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4936 - val_accuracy: 0.8308\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4909 - val_accuracy: 0.8308\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4992 - val_accuracy: 0.8308\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.4967 - val_accuracy: 0.8308\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.5007 - val_accuracy: 0.8308\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4955 - val_accuracy: 0.8308\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4969 - val_accuracy: 0.8308\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.5006 - val_accuracy: 0.8308\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4973 - val_accuracy: 0.8308\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.5004 - val_accuracy: 0.8308\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4955 - val_accuracy: 0.8308\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4953 - val_accuracy: 0.8308\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2169 - accuracy: 0.9073 - val_loss: 0.4962 - val_accuracy: 0.8308\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4946 - val_accuracy: 0.8308\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2163 - accuracy: 0.9073 - val_loss: 0.4975 - val_accuracy: 0.8308\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4934 - val_accuracy: 0.8308\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4985 - val_accuracy: 0.8308\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.5004 - val_accuracy: 0.8308\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4974 - val_accuracy: 0.8308\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.5021 - val_accuracy: 0.8308\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.9073 - val_loss: 0.5059 - val_accuracy: 0.8308\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4974 - val_accuracy: 0.8308\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4893 - val_accuracy: 0.8308\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2150 - accuracy: 0.9073 - val_loss: 0.5114 - val_accuracy: 0.8308\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4841 - val_accuracy: 0.8308\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4882 - val_accuracy: 0.8308\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4891 - val_accuracy: 0.8308\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4911 - val_accuracy: 0.8308\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 124us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4832 - val_accuracy: 0.8308\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4908 - val_accuracy: 0.8308\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4975 - val_accuracy: 0.8308\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4950 - val_accuracy: 0.8308\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4933 - val_accuracy: 0.8308\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4964 - val_accuracy: 0.8308\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.5038 - val_accuracy: 0.8308\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4923 - val_accuracy: 0.8308\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.5004 - val_accuracy: 0.8308\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.5022 - val_accuracy: 0.8308\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.5005 - val_accuracy: 0.8308\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.5012 - val_accuracy: 0.8308\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.5031 - val_accuracy: 0.8308\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.5008 - val_accuracy: 0.8308\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4963 - val_accuracy: 0.8308\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.5074 - val_accuracy: 0.8308\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2141 - accuracy: 0.9051 - val_loss: 0.4935 - val_accuracy: 0.8308\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2132 - accuracy: 0.9073 - val_loss: 0.4967 - val_accuracy: 0.8308\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4992 - val_accuracy: 0.8308\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2101 - accuracy: 0.9007 - val_loss: 0.5008 - val_accuracy: 0.8308\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4957 - val_accuracy: 0.8308\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.5026 - val_accuracy: 0.8308\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4981 - val_accuracy: 0.8308\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4966 - val_accuracy: 0.8308\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4952 - val_accuracy: 0.8308\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4762 - val_accuracy: 0.8308\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4770 - val_accuracy: 0.8308\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4827 - val_accuracy: 0.8308\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4840 - val_accuracy: 0.8308\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4894 - val_accuracy: 0.8308\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 340us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4909 - val_accuracy: 0.8308\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2171 - accuracy: 0.9029 - val_loss: 0.4853 - val_accuracy: 0.8308\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2158 - accuracy: 0.8985 - val_loss: 0.4919 - val_accuracy: 0.8308\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4916 - val_accuracy: 0.8308\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4969 - val_accuracy: 0.8308\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2117 - accuracy: 0.8985 - val_loss: 0.4902 - val_accuracy: 0.8308\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4981 - val_accuracy: 0.8308\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2170 - accuracy: 0.9073 - val_loss: 0.4989 - val_accuracy: 0.8308\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4966 - val_accuracy: 0.8308\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4953 - val_accuracy: 0.8308\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4928 - val_accuracy: 0.8308\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4958 - val_accuracy: 0.8308\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4973 - val_accuracy: 0.8308\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.5007 - val_accuracy: 0.8308\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4959 - val_accuracy: 0.8308\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.5120 - val_accuracy: 0.8308\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2173 - accuracy: 0.9073 - val_loss: 0.5033 - val_accuracy: 0.8308\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4980 - val_accuracy: 0.8308\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.5000 - val_accuracy: 0.8308\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.4982 - val_accuracy: 0.8308\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4951 - val_accuracy: 0.8308\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2116 - accuracy: 0.9007 - val_loss: 0.4974 - val_accuracy: 0.8308\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2115 - accuracy: 0.9073 - val_loss: 0.5045 - val_accuracy: 0.8308\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4972 - val_accuracy: 0.8308\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4917 - val_accuracy: 0.8308\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4988 - val_accuracy: 0.8308\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.5779 - val_accuracy: 0.8308\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2200 - accuracy: 0.9073 - val_loss: 0.4976 - val_accuracy: 0.8308\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4954 - val_accuracy: 0.8308\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2151 - accuracy: 0.9073 - val_loss: 0.4969 - val_accuracy: 0.8308\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.5021 - val_accuracy: 0.8308\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4973 - val_accuracy: 0.8308\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2136 - accuracy: 0.9073 - val_loss: 0.5003 - val_accuracy: 0.8308\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2095 - accuracy: 0.9051 - val_loss: 0.4968 - val_accuracy: 0.8308\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.5057 - val_accuracy: 0.8308\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.5008 - val_accuracy: 0.8308\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.5040 - val_accuracy: 0.8308\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4977 - val_accuracy: 0.8308\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.5049 - val_accuracy: 0.8308\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.5019 - val_accuracy: 0.8308\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.5060 - val_accuracy: 0.8308\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4925 - val_accuracy: 0.8308\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4873 - val_accuracy: 0.8308\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4901 - val_accuracy: 0.8308\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4917 - val_accuracy: 0.8308\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4910 - val_accuracy: 0.8308\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4908 - val_accuracy: 0.8308\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2098 - accuracy: 0.9007 - val_loss: 0.4983 - val_accuracy: 0.8308\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4978 - val_accuracy: 0.8308\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2137 - accuracy: 0.9029 - val_loss: 0.4956 - val_accuracy: 0.8308\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2113 - accuracy: 0.9073 - val_loss: 0.4998 - val_accuracy: 0.8308\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.5010 - val_accuracy: 0.8308\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.5044 - val_accuracy: 0.8308\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2137 - accuracy: 0.9051 - val_loss: 0.5018 - val_accuracy: 0.8308\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2143 - accuracy: 0.9073 - val_loss: 0.5019 - val_accuracy: 0.8308\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.5010 - val_accuracy: 0.8308\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.5019 - val_accuracy: 0.8308\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.5021 - val_accuracy: 0.8308\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.5004 - val_accuracy: 0.8308\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.5075 - val_accuracy: 0.8308\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2137 - accuracy: 0.9073 - val_loss: 0.5002 - val_accuracy: 0.8308\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.5034 - val_accuracy: 0.8308\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.5052 - val_accuracy: 0.8308\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.5021 - val_accuracy: 0.8308\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2174 - accuracy: 0.9073 - val_loss: 0.5014 - val_accuracy: 0.8308\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.5017 - val_accuracy: 0.8308\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.5041 - val_accuracy: 0.8308\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4999 - val_accuracy: 0.8308\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.5053 - val_accuracy: 0.8308\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.5012 - val_accuracy: 0.8308\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.5043 - val_accuracy: 0.8308\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.5039 - val_accuracy: 0.8308\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.5071 - val_accuracy: 0.8308\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.5088 - val_accuracy: 0.8308\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.5066 - val_accuracy: 0.8308\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.5034 - val_accuracy: 0.8308\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.5047 - val_accuracy: 0.8308\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.5095 - val_accuracy: 0.8308\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.5889 - val_accuracy: 0.8308\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2165 - accuracy: 0.9073 - val_loss: 0.4808 - val_accuracy: 0.8308\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4873 - val_accuracy: 0.8308\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4924 - val_accuracy: 0.8308\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4934 - val_accuracy: 0.8308\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4950 - val_accuracy: 0.8308\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2115 - accuracy: 0.9073 - val_loss: 0.5055 - val_accuracy: 0.8308\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2123 - accuracy: 0.9073 - val_loss: 0.4960 - val_accuracy: 0.8308\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.5069 - val_accuracy: 0.8308\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.5008 - val_accuracy: 0.8308\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.5044 - val_accuracy: 0.8308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36a1a080>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 83.08%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 1, 0,\n",
       "       2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 2,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2,\n",
       "       2, 1, 0, 1, 0, 2, 2, 2, 1, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 0, 2,\n",
       "       0, 0, 1, 2, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 0, 2,\n",
       "       0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0          312     1     0\n",
       "1     CFBRSa27     0     0\n",
       "2    BCH-SA-01     1     1\n",
       "3         GA27     1     1\n",
       "4       NRS209     2     2\n",
       "..         ...   ...   ...\n",
       "190     NRS209     2     2\n",
       "191     NRS235     0     0\n",
       "192     NRS240     1     1\n",
       "193     NRS110     2     2\n",
       "194     NRS063     1     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.352306e-01</td>\n",
       "      <td>2.647694e-01</td>\n",
       "      <td>2.742082e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.352306e-01</td>\n",
       "      <td>2.647694e-01</td>\n",
       "      <td>2.742082e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.729426e-01</td>\n",
       "      <td>8.270574e-01</td>\n",
       "      <td>5.515762e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.531625e-01</td>\n",
       "      <td>7.468375e-01</td>\n",
       "      <td>1.100956e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.784774e-09</td>\n",
       "      <td>9.270067e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>5.784774e-09</td>\n",
       "      <td>9.270067e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9.986609e-01</td>\n",
       "      <td>1.339073e-03</td>\n",
       "      <td>2.859718e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>5.067671e-04</td>\n",
       "      <td>9.994932e-01</td>\n",
       "      <td>4.060507e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.642337e-08</td>\n",
       "      <td>1.409822e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.962181e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.847052e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    7.352306e-01  2.647694e-01  2.742082e-10\n",
       "1    7.352306e-01  2.647694e-01  2.742082e-10\n",
       "2    1.729426e-01  8.270574e-01  5.515762e-12\n",
       "3    2.531625e-01  7.468375e-01  1.100956e-10\n",
       "4    5.784774e-09  9.270067e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "190  5.784774e-09  9.270067e-09  1.000000e+00\n",
       "191  9.986609e-01  1.339073e-03  2.859718e-11\n",
       "192  5.067671e-04  9.994932e-01  4.060507e-09\n",
       "193  1.642337e-08  1.409822e-08  1.000000e+00\n",
       "194  1.962181e-12  1.000000e+00  2.847052e-22\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4066 - val_accuracy: 0.8308\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4070 - val_accuracy: 0.8308\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4069 - val_accuracy: 0.8308\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2113 - accuracy: 0.9073 - val_loss: 0.4113 - val_accuracy: 0.8308\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4069 - val_accuracy: 0.8308\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4055 - val_accuracy: 0.8308\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4103 - val_accuracy: 0.8308\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4157 - val_accuracy: 0.8308\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4088 - val_accuracy: 0.8308\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4050 - val_accuracy: 0.8308\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4122 - val_accuracy: 0.8308\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4150 - val_accuracy: 0.8308\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2164 - accuracy: 0.9007 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4127 - val_accuracy: 0.8308\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4108 - val_accuracy: 0.8308\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4053 - val_accuracy: 0.8308\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4111 - val_accuracy: 0.8308\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2101 - accuracy: 0.9007 - val_loss: 0.4123 - val_accuracy: 0.8308\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4102 - val_accuracy: 0.8308\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4116 - val_accuracy: 0.8308\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4099 - val_accuracy: 0.8308\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4118 - val_accuracy: 0.8308\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2172 - accuracy: 0.9051 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4215 - val_accuracy: 0.8308\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2164 - accuracy: 0.9073 - val_loss: 0.4130 - val_accuracy: 0.8308\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4095 - val_accuracy: 0.8308\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4131 - val_accuracy: 0.8308\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4098 - val_accuracy: 0.8308\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4072 - val_accuracy: 0.8308\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4086 - val_accuracy: 0.8308\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4199 - val_accuracy: 0.8308\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4093 - val_accuracy: 0.8308\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2114 - accuracy: 0.9007 - val_loss: 0.4042 - val_accuracy: 0.8308\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4040 - val_accuracy: 0.8308\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4087 - val_accuracy: 0.8308\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4089 - val_accuracy: 0.8308\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4039 - val_accuracy: 0.8308\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4078 - val_accuracy: 0.8308\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4069 - val_accuracy: 0.8308\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4151 - val_accuracy: 0.8308\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4107 - val_accuracy: 0.8308\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4108 - val_accuracy: 0.8308\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4078 - val_accuracy: 0.8308\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4100 - val_accuracy: 0.8308\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4140 - val_accuracy: 0.8308\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4184 - val_accuracy: 0.8308\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4181 - val_accuracy: 0.8308\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4183 - val_accuracy: 0.8308\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4153 - val_accuracy: 0.8308\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4096 - val_accuracy: 0.8308\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4080 - val_accuracy: 0.8308\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4078 - val_accuracy: 0.8308\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4129 - val_accuracy: 0.8308\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4140 - val_accuracy: 0.8308\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4183 - val_accuracy: 0.8308\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4112 - val_accuracy: 0.8308\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4165 - val_accuracy: 0.8308\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4150 - val_accuracy: 0.8308\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2263 - accuracy: 0.9029 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2170 - accuracy: 0.9073 - val_loss: 0.4387 - val_accuracy: 0.8308\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.9051 - val_loss: 0.4332 - val_accuracy: 0.8308\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2146 - accuracy: 0.9073 - val_loss: 0.4235 - val_accuracy: 0.8308\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4247 - val_accuracy: 0.8308\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4265 - val_accuracy: 0.8308\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2143 - accuracy: 0.8962 - val_loss: 0.4236 - val_accuracy: 0.8308\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.4197 - val_accuracy: 0.8308\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2141 - accuracy: 0.9051 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4236 - val_accuracy: 0.8308\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2105 - accuracy: 0.8985 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4213 - val_accuracy: 0.8308\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4169 - val_accuracy: 0.8308\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4194 - val_accuracy: 0.8308\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4229 - val_accuracy: 0.8308\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2059 - accuracy: 0.9073 - val_loss: 0.4253 - val_accuracy: 0.8308\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2101 - accuracy: 0.9051 - val_loss: 0.4297 - val_accuracy: 0.8308\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2119 - accuracy: 0.9073 - val_loss: 0.4280 - val_accuracy: 0.8308\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4170 - val_accuracy: 0.8308\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4206 - val_accuracy: 0.8308\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4202 - val_accuracy: 0.8308\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4212 - val_accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4270 - val_accuracy: 0.8308\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4294 - val_accuracy: 0.8308\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4216 - val_accuracy: 0.8308\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4211 - val_accuracy: 0.8308\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4157 - val_accuracy: 0.8308\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4193 - val_accuracy: 0.8308\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4195 - val_accuracy: 0.8308\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4234 - val_accuracy: 0.8308\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4186 - val_accuracy: 0.8308\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4183 - val_accuracy: 0.8308\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4237 - val_accuracy: 0.8308\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4209 - val_accuracy: 0.8308\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4121 - val_accuracy: 0.8308\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4206 - val_accuracy: 0.8308\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 454us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4223 - val_accuracy: 0.8308\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4268 - val_accuracy: 0.8308\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4219 - val_accuracy: 0.8308\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4221 - val_accuracy: 0.8308\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4188 - val_accuracy: 0.8308\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4202 - val_accuracy: 0.8308\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4201 - val_accuracy: 0.8308\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4226 - val_accuracy: 0.8308\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2076 - accuracy: 0.9051 - val_loss: 0.4208 - val_accuracy: 0.8154\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4237 - val_accuracy: 0.8308\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4262 - val_accuracy: 0.8308\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4223 - val_accuracy: 0.8308\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4323 - val_accuracy: 0.8308\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4240 - val_accuracy: 0.8308\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4249 - val_accuracy: 0.8308\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4248 - val_accuracy: 0.8308\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4244 - val_accuracy: 0.8308\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4228 - val_accuracy: 0.8308\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4278 - val_accuracy: 0.8308\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4292 - val_accuracy: 0.8308\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.4288 - val_accuracy: 0.8308\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4248 - val_accuracy: 0.8308\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4277 - val_accuracy: 0.8308\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4240 - val_accuracy: 0.8308\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4264 - val_accuracy: 0.8308\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4326 - val_accuracy: 0.8308\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 461us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4273 - val_accuracy: 0.8308\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4265 - val_accuracy: 0.8308\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4254 - val_accuracy: 0.8308\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 1s 1ms/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4237 - val_accuracy: 0.8308\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4221 - val_accuracy: 0.8308\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4235 - val_accuracy: 0.8308\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.4187 - val_accuracy: 0.8308\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4228 - val_accuracy: 0.8308\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4177 - val_accuracy: 0.8308\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4238 - val_accuracy: 0.8308\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4232 - val_accuracy: 0.8308\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4224 - val_accuracy: 0.8308\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4236 - val_accuracy: 0.8308\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2153 - accuracy: 0.9051 - val_loss: 0.4275 - val_accuracy: 0.8308\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4287 - val_accuracy: 0.8308\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2138 - accuracy: 0.9073 - val_loss: 0.4279 - val_accuracy: 0.8308\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4210 - val_accuracy: 0.8308\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4193 - val_accuracy: 0.8308\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4251 - val_accuracy: 0.8308\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4249 - val_accuracy: 0.8308\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4302 - val_accuracy: 0.8308\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4322 - val_accuracy: 0.8308\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.91 - 0s 394us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4386 - val_accuracy: 0.8308\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4281 - val_accuracy: 0.8308\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4225 - val_accuracy: 0.8308\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4269 - val_accuracy: 0.8308\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4250 - val_accuracy: 0.8308\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4286 - val_accuracy: 0.8308\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4257 - val_accuracy: 0.8308\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4273 - val_accuracy: 0.8308\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2122 - accuracy: 0.9073 - val_loss: 0.4313 - val_accuracy: 0.8308\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 392us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4335 - val_accuracy: 0.8308\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4307 - val_accuracy: 0.8308\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4311 - val_accuracy: 0.8308\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2099 - accuracy: 0.9051 - val_loss: 0.4278 - val_accuracy: 0.8308\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4301 - val_accuracy: 0.8308\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4287 - val_accuracy: 0.8308\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4267 - val_accuracy: 0.8308\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4344 - val_accuracy: 0.8308\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4358 - val_accuracy: 0.8308\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4291 - val_accuracy: 0.8308\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4304 - val_accuracy: 0.8308\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4277 - val_accuracy: 0.8308\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4254 - val_accuracy: 0.8308\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4261 - val_accuracy: 0.8308\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4390 - val_accuracy: 0.8308\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4330 - val_accuracy: 0.8308\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4274 - val_accuracy: 0.8308\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4278 - val_accuracy: 0.8308\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4251 - val_accuracy: 0.8308\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 350us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4274 - val_accuracy: 0.8308\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4306 - val_accuracy: 0.8308\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4369 - val_accuracy: 0.8308\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4352 - val_accuracy: 0.8308\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4273 - val_accuracy: 0.8308\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4352 - val_accuracy: 0.8308\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4329 - val_accuracy: 0.8308\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4314 - val_accuracy: 0.8308\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4267 - val_accuracy: 0.8308\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4288 - val_accuracy: 0.8308\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4253 - val_accuracy: 0.8308\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4296 - val_accuracy: 0.8308\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4313 - val_accuracy: 0.8308\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4276 - val_accuracy: 0.8308\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4243 - val_accuracy: 0.8308\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4251 - val_accuracy: 0.8308\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4284 - val_accuracy: 0.8308\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4258 - val_accuracy: 0.8308\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4249 - val_accuracy: 0.8308\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4435 - val_accuracy: 0.8308\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2158 - accuracy: 0.9073 - val_loss: 0.4467 - val_accuracy: 0.8308\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 356us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4432 - val_accuracy: 0.8308\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4406 - val_accuracy: 0.8308\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4379 - val_accuracy: 0.8308\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4363 - val_accuracy: 0.8308\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4332 - val_accuracy: 0.8308\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4321 - val_accuracy: 0.8308\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4320 - val_accuracy: 0.8308\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4308 - val_accuracy: 0.8308\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4262 - val_accuracy: 0.8308\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4410 - val_accuracy: 0.8308\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4387 - val_accuracy: 0.8308\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4394 - val_accuracy: 0.8308\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4382 - val_accuracy: 0.8308\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4341 - val_accuracy: 0.8308\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4461 - val_accuracy: 0.8308\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4338 - val_accuracy: 0.8308\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4279 - val_accuracy: 0.8308\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2139 - accuracy: 0.9073 - val_loss: 0.4325 - val_accuracy: 0.8308\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4351 - val_accuracy: 0.8308\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4330 - val_accuracy: 0.8308\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4365 - val_accuracy: 0.8308\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4332 - val_accuracy: 0.8308\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4359 - val_accuracy: 0.8308\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4340 - val_accuracy: 0.8308\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4302 - val_accuracy: 0.8308\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4325 - val_accuracy: 0.8308\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4330 - val_accuracy: 0.8308\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 341us/step - loss: 0.2155 - accuracy: 0.9073 - val_loss: 0.4348 - val_accuracy: 0.8308\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2134 - accuracy: 0.8985 - val_loss: 0.4388 - val_accuracy: 0.8308\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4428 - val_accuracy: 0.8308\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4364 - val_accuracy: 0.8308\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4347 - val_accuracy: 0.8308\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4337 - val_accuracy: 0.8308\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4414 - val_accuracy: 0.8308\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2148 - accuracy: 0.9051 - val_loss: 0.4519 - val_accuracy: 0.8205\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4455 - val_accuracy: 0.8205\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4425 - val_accuracy: 0.8308\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4357 - val_accuracy: 0.8308\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4306 - val_accuracy: 0.8308\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4335 - val_accuracy: 0.8308\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4282 - val_accuracy: 0.8308\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4291 - val_accuracy: 0.8308\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4271 - val_accuracy: 0.8308\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4276 - val_accuracy: 0.8308\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4314 - val_accuracy: 0.8308\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4323 - val_accuracy: 0.8308\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4328 - val_accuracy: 0.8308\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4335 - val_accuracy: 0.8308\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4322 - val_accuracy: 0.8308\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4231 - val_accuracy: 0.8308\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4264 - val_accuracy: 0.8308\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4256 - val_accuracy: 0.8308\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4275 - val_accuracy: 0.8308\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4262 - val_accuracy: 0.8308\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4211 - val_accuracy: 0.8308\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4221 - val_accuracy: 0.8308\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4213 - val_accuracy: 0.8308\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4284 - val_accuracy: 0.8308\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4299 - val_accuracy: 0.8308\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4323 - val_accuracy: 0.8308\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4295 - val_accuracy: 0.8308\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2124 - accuracy: 0.9073 - val_loss: 0.4346 - val_accuracy: 0.8308\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4228 - val_accuracy: 0.8308\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4265 - val_accuracy: 0.8308\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4251 - val_accuracy: 0.8308\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4296 - val_accuracy: 0.8308\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4257 - val_accuracy: 0.8308\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4264 - val_accuracy: 0.8308\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4276 - val_accuracy: 0.8308\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2189 - accuracy: 0.9007 - val_loss: 0.4424 - val_accuracy: 0.8308\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4315 - val_accuracy: 0.8308\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4293 - val_accuracy: 0.8308\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4316 - val_accuracy: 0.8308\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4234 - val_accuracy: 0.8308\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4248 - val_accuracy: 0.8308\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4192 - val_accuracy: 0.8308\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 111us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4163 - val_accuracy: 0.8308\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2100 - accuracy: 0.9051 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4199 - val_accuracy: 0.8308\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4240 - val_accuracy: 0.8308\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4183 - val_accuracy: 0.8308\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4328 - val_accuracy: 0.8308\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2130 - accuracy: 0.9073 - val_loss: 0.4305 - val_accuracy: 0.8308\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4267 - val_accuracy: 0.8308\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4276 - val_accuracy: 0.8308\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4284 - val_accuracy: 0.8308\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2154 - accuracy: 0.9073 - val_loss: 0.4213 - val_accuracy: 0.8308\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4179 - val_accuracy: 0.8308\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4172 - val_accuracy: 0.8308\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2064 - accuracy: 0.9073 - val_loss: 0.4188 - val_accuracy: 0.8308\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4201 - val_accuracy: 0.8308\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4198 - val_accuracy: 0.8308\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4373 - val_accuracy: 0.8308\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4322 - val_accuracy: 0.8308\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4359 - val_accuracy: 0.8308\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4309 - val_accuracy: 0.8308\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2091 - accuracy: 0.9051 - val_loss: 0.4262 - val_accuracy: 0.8308\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4266 - val_accuracy: 0.8308\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4273 - val_accuracy: 0.8308\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4289 - val_accuracy: 0.8308\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4176 - val_accuracy: 0.8308\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4218 - val_accuracy: 0.8308\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4176 - val_accuracy: 0.8308\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4204 - val_accuracy: 0.8308\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4229 - val_accuracy: 0.8308\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4220 - val_accuracy: 0.8308\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4318 - val_accuracy: 0.8308\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4308 - val_accuracy: 0.8308\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4286 - val_accuracy: 0.8308\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4299 - val_accuracy: 0.8308\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4237 - val_accuracy: 0.8308\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4283 - val_accuracy: 0.8308\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4304 - val_accuracy: 0.8308\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4279 - val_accuracy: 0.8308\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4219 - val_accuracy: 0.8308\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4221 - val_accuracy: 0.8308\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4307 - val_accuracy: 0.8154\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4325 - val_accuracy: 0.8308\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4274 - val_accuracy: 0.8308\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4261 - val_accuracy: 0.8308\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4237 - val_accuracy: 0.8308\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4166 - val_accuracy: 0.8308\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4200 - val_accuracy: 0.8308\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4201 - val_accuracy: 0.8308\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4213 - val_accuracy: 0.8308\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4269 - val_accuracy: 0.8308\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4260 - val_accuracy: 0.8308\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4190 - val_accuracy: 0.8308\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4195 - val_accuracy: 0.8308\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4255 - val_accuracy: 0.8308\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4195 - val_accuracy: 0.8308\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4212 - val_accuracy: 0.8308\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4473 - val_accuracy: 0.8308\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4314 - val_accuracy: 0.8308\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4301 - val_accuracy: 0.8308\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4293 - val_accuracy: 0.8308\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4291 - val_accuracy: 0.8308\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 312us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4295 - val_accuracy: 0.8308\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4248 - val_accuracy: 0.8308\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4284 - val_accuracy: 0.8308\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4266 - val_accuracy: 0.8308\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4272 - val_accuracy: 0.8308\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4220 - val_accuracy: 0.8308\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2128 - accuracy: 0.9073 - val_loss: 0.4247 - val_accuracy: 0.8308\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4333 - val_accuracy: 0.8308\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4269 - val_accuracy: 0.8308\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4293 - val_accuracy: 0.8308\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4266 - val_accuracy: 0.8308\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4224 - val_accuracy: 0.8308\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4198 - val_accuracy: 0.8308\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4331 - val_accuracy: 0.8308\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4300 - val_accuracy: 0.8308\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4291 - val_accuracy: 0.8308\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4223 - val_accuracy: 0.8308\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4163 - val_accuracy: 0.8308\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4211 - val_accuracy: 0.8308\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4132 - val_accuracy: 0.8308\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4152 - val_accuracy: 0.8308\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4178 - val_accuracy: 0.8308\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4138 - val_accuracy: 0.8308\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 383us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4168 - val_accuracy: 0.8308\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2125 - accuracy: 0.9073 - val_loss: 0.4465 - val_accuracy: 0.8308\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4246 - val_accuracy: 0.8308\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4192 - val_accuracy: 0.8308\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4164 - val_accuracy: 0.8308\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4164 - val_accuracy: 0.8308\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4394 - val_accuracy: 0.8308\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4297 - val_accuracy: 0.8308\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4311 - val_accuracy: 0.8308\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4172 - val_accuracy: 0.8308\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4190 - val_accuracy: 0.8308\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4197 - val_accuracy: 0.8308\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4171 - val_accuracy: 0.8308\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4206 - val_accuracy: 0.8308\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4517 - val_accuracy: 0.8308\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2129 - accuracy: 0.9051 - val_loss: 0.4421 - val_accuracy: 0.8308\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4213 - val_accuracy: 0.8308\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4261 - val_accuracy: 0.8308\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2090 - accuracy: 0.9007 - val_loss: 0.4218 - val_accuracy: 0.8308\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4229 - val_accuracy: 0.8308\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4244 - val_accuracy: 0.8308\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4203 - val_accuracy: 0.8308\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 365us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4188 - val_accuracy: 0.8308\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4179 - val_accuracy: 0.8308\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.4169 - val_accuracy: 0.8308\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4200 - val_accuracy: 0.8308\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4339 - val_accuracy: 0.8308\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4147 - val_accuracy: 0.8308\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4133 - val_accuracy: 0.8308\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4170 - val_accuracy: 0.8308\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4159 - val_accuracy: 0.8308\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4128 - val_accuracy: 0.8308\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4162 - val_accuracy: 0.8308\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.4199 - val_accuracy: 0.8308\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4100 - val_accuracy: 0.8308\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4097 - val_accuracy: 0.8308\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4094 - val_accuracy: 0.8308\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4150 - val_accuracy: 0.8308\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4202 - val_accuracy: 0.8308\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4209 - val_accuracy: 0.8308\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4208 - val_accuracy: 0.8308\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4197 - val_accuracy: 0.8308\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4171 - val_accuracy: 0.8308\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4180 - val_accuracy: 0.8308\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4162 - val_accuracy: 0.8308\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4202 - val_accuracy: 0.8308\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4149 - val_accuracy: 0.8308\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4144 - val_accuracy: 0.8308\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4182 - val_accuracy: 0.8308\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4195 - val_accuracy: 0.8308\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4177 - val_accuracy: 0.8308\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4129 - val_accuracy: 0.8308\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4187 - val_accuracy: 0.8308\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4289 - val_accuracy: 0.8308\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4278 - val_accuracy: 0.8308\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4162 - val_accuracy: 0.8308\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2209 - accuracy: 0.9029 - val_loss: 0.4297 - val_accuracy: 0.8308\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4142 - val_accuracy: 0.8308\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2105 - accuracy: 0.9073 - val_loss: 0.4219 - val_accuracy: 0.8308\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4189 - val_accuracy: 0.8308\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4193 - val_accuracy: 0.8308\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4188 - val_accuracy: 0.8308\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4212 - val_accuracy: 0.8308\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4178 - val_accuracy: 0.8308\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4145 - val_accuracy: 0.8308\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4265 - val_accuracy: 0.8308\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4253 - val_accuracy: 0.8308\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4251 - val_accuracy: 0.8308\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4231 - val_accuracy: 0.8308\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4193 - val_accuracy: 0.8308\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4201 - val_accuracy: 0.8308\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4182 - val_accuracy: 0.8308\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4195 - val_accuracy: 0.8308\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4173 - val_accuracy: 0.8308\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4176 - val_accuracy: 0.8308\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2064 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4103 - val_accuracy: 0.8308\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4111 - val_accuracy: 0.8308\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4106 - val_accuracy: 0.8308\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4357 - val_accuracy: 0.8308\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4229 - val_accuracy: 0.8308\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4184 - val_accuracy: 0.8308\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4187 - val_accuracy: 0.8308\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4233 - val_accuracy: 0.8308\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4169 - val_accuracy: 0.8308\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4100 - val_accuracy: 0.8308\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4092 - val_accuracy: 0.8308\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2121 - accuracy: 0.9073 - val_loss: 0.4295 - val_accuracy: 0.8308\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 112us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4267 - val_accuracy: 0.8308\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4220 - val_accuracy: 0.8308\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4258 - val_accuracy: 0.8308\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4216 - val_accuracy: 0.8308\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4186 - val_accuracy: 0.8308\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4184 - val_accuracy: 0.8308\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4133 - val_accuracy: 0.8308\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4091 - val_accuracy: 0.8308\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4132 - val_accuracy: 0.8308\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4181 - val_accuracy: 0.8308\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4108 - val_accuracy: 0.8308\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4116 - val_accuracy: 0.8308\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4086 - val_accuracy: 0.8308\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4114 - val_accuracy: 0.8308\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4069 - val_accuracy: 0.8308\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4098 - val_accuracy: 0.8308\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4087 - val_accuracy: 0.8308\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4106 - val_accuracy: 0.8308\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4114 - val_accuracy: 0.8308\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4092 - val_accuracy: 0.8308\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4436 - val_accuracy: 0.8308\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4366 - val_accuracy: 0.8308\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4310 - val_accuracy: 0.8308\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 438us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 310us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4225 - val_accuracy: 0.8308\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4183 - val_accuracy: 0.8308\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4228 - val_accuracy: 0.8308\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4157 - val_accuracy: 0.8308\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4234 - val_accuracy: 0.8308\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4212 - val_accuracy: 0.8308\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4175 - val_accuracy: 0.8308\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4150 - val_accuracy: 0.8308\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4143 - val_accuracy: 0.8308\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4282 - val_accuracy: 0.8308\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4185 - val_accuracy: 0.8308\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4180 - val_accuracy: 0.8308\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4159 - val_accuracy: 0.8308\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 356us/step - loss: 0.2101 - accuracy: 0.9007 - val_loss: 0.4194 - val_accuracy: 0.8308\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4154 - val_accuracy: 0.8308\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4164 - val_accuracy: 0.8308\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4151 - val_accuracy: 0.8308\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4144 - val_accuracy: 0.8308\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4149 - val_accuracy: 0.8308\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4135 - val_accuracy: 0.8308\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4133 - val_accuracy: 0.8308\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2127 - accuracy: 0.9073 - val_loss: 0.4130 - val_accuracy: 0.8308\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 361us/step - loss: 0.2117 - accuracy: 0.9073 - val_loss: 0.4096 - val_accuracy: 0.8308\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 316us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4081 - val_accuracy: 0.8308\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2167 - accuracy: 0.9073 - val_loss: 0.4232 - val_accuracy: 0.8308\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2133 - accuracy: 0.9073 - val_loss: 0.4455 - val_accuracy: 0.8308\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4311 - val_accuracy: 0.8308\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4198 - val_accuracy: 0.8308\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4228 - val_accuracy: 0.8308\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4181 - val_accuracy: 0.8308\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4176 - val_accuracy: 0.8308\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4194 - val_accuracy: 0.8308\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 449us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4170 - val_accuracy: 0.8308\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4170 - val_accuracy: 0.8308\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4174 - val_accuracy: 0.8308\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2105 - accuracy: 0.9051 - val_loss: 0.4176 - val_accuracy: 0.8308\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4169 - val_accuracy: 0.8308\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 368us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4187 - val_accuracy: 0.8308\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4149 - val_accuracy: 0.8308\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4168 - val_accuracy: 0.8308\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4190 - val_accuracy: 0.8308\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4200 - val_accuracy: 0.8308\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4179 - val_accuracy: 0.8308\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4131 - val_accuracy: 0.8308\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4139 - val_accuracy: 0.8308\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4121 - val_accuracy: 0.8308\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4130 - val_accuracy: 0.8308\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4190 - val_accuracy: 0.8308\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4136 - val_accuracy: 0.8308\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4247 - val_accuracy: 0.8308\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4252 - val_accuracy: 0.8308\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4255 - val_accuracy: 0.8308\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4222 - val_accuracy: 0.8308\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4212 - val_accuracy: 0.8308\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4239 - val_accuracy: 0.8308\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4163 - val_accuracy: 0.8308\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4155 - val_accuracy: 0.8308\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2109 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4146 - val_accuracy: 0.8308\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4148 - val_accuracy: 0.8308\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4120 - val_accuracy: 0.8308\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4124 - val_accuracy: 0.8308\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4133 - val_accuracy: 0.8308\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4224 - val_accuracy: 0.8308\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2111 - accuracy: 0.9073 - val_loss: 0.4217 - val_accuracy: 0.8308\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4122 - val_accuracy: 0.8308\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4160 - val_accuracy: 0.8308\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4162 - val_accuracy: 0.8308\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4119 - val_accuracy: 0.8308\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 112us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4114 - val_accuracy: 0.8308\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2108 - accuracy: 0.9073 - val_loss: 0.4406 - val_accuracy: 0.8308\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4329 - val_accuracy: 0.8308\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4317 - val_accuracy: 0.8308\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4254 - val_accuracy: 0.8308\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4196 - val_accuracy: 0.8308\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4131 - val_accuracy: 0.8308\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2099 - accuracy: 0.9007 - val_loss: 0.4135 - val_accuracy: 0.8308\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4215 - val_accuracy: 0.8308\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4145 - val_accuracy: 0.8308\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4123 - val_accuracy: 0.8308\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4170 - val_accuracy: 0.8308\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4128 - val_accuracy: 0.8308\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4157 - val_accuracy: 0.8308\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 381us/step - loss: 0.2061 - accuracy: 0.9073 - val_loss: 0.4165 - val_accuracy: 0.8308\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4300 - val_accuracy: 0.8308\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.2098 - accuracy: 0.9073 - val_loss: 0.4230 - val_accuracy: 0.8308\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4141 - val_accuracy: 0.8308\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4154 - val_accuracy: 0.8308\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4166 - val_accuracy: 0.8308\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4144 - val_accuracy: 0.8308\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4131 - val_accuracy: 0.8308\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4140 - val_accuracy: 0.8308\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4123 - val_accuracy: 0.8308\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2064 - accuracy: 0.9073 - val_loss: 0.4099 - val_accuracy: 0.8308\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4158 - val_accuracy: 0.8308\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4119 - val_accuracy: 0.8308\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4135 - val_accuracy: 0.8308\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4130 - val_accuracy: 0.8308\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4140 - val_accuracy: 0.8308\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4104 - val_accuracy: 0.8308\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4153 - val_accuracy: 0.8308\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4094 - val_accuracy: 0.8308\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2118 - accuracy: 0.9073 - val_loss: 0.4191 - val_accuracy: 0.8308\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4442 - val_accuracy: 0.8308\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4236 - val_accuracy: 0.8308\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4169 - val_accuracy: 0.8308\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4153 - val_accuracy: 0.8308\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4166 - val_accuracy: 0.8308\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4117 - val_accuracy: 0.8308\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4116 - val_accuracy: 0.8308\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4117 - val_accuracy: 0.8308\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4115 - val_accuracy: 0.8308\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4132 - val_accuracy: 0.8308\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4117 - val_accuracy: 0.8308\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2102 - accuracy: 0.9073 - val_loss: 0.4123 - val_accuracy: 0.8308\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4149 - val_accuracy: 0.8308\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4197 - val_accuracy: 0.8308\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.4218 - val_accuracy: 0.8308\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4137 - val_accuracy: 0.8308\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4109 - val_accuracy: 0.8308\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2102 - accuracy: 0.8985 - val_loss: 0.4163 - val_accuracy: 0.8308\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4149 - val_accuracy: 0.8308\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4154 - val_accuracy: 0.8308\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4060 - val_accuracy: 0.8308\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4046 - val_accuracy: 0.8308\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4089 - val_accuracy: 0.8308\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4063 - val_accuracy: 0.8308\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4096 - val_accuracy: 0.8308\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4004 - val_accuracy: 0.8308\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3990 - val_accuracy: 0.8308\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4008 - val_accuracy: 0.8308\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4033 - val_accuracy: 0.8308\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.4032 - val_accuracy: 0.8308\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.4418 - val_accuracy: 0.8308\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2121 - accuracy: 0.9051 - val_loss: 0.4366 - val_accuracy: 0.8308\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2113 - accuracy: 0.9051 - val_loss: 0.4312 - val_accuracy: 0.8308\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2128 - accuracy: 0.9051 - val_loss: 0.4275 - val_accuracy: 0.8308\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2112 - accuracy: 0.9051 - val_loss: 0.4307 - val_accuracy: 0.8308\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2105 - accuracy: 0.9051 - val_loss: 0.4235 - val_accuracy: 0.8308\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2109 - accuracy: 0.9051 - val_loss: 0.4144 - val_accuracy: 0.8308\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.3927 - val_accuracy: 0.8308\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4034 - val_accuracy: 0.8308\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4051 - val_accuracy: 0.8308\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2112 - accuracy: 0.9073 - val_loss: 0.4052 - val_accuracy: 0.8308\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.3967 - val_accuracy: 0.8308\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.3975 - val_accuracy: 0.8308\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.3959 - val_accuracy: 0.8308\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.3990 - val_accuracy: 0.8308\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.3960 - val_accuracy: 0.8308\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4021 - val_accuracy: 0.8308\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2061 - accuracy: 0.9073 - val_loss: 0.3978 - val_accuracy: 0.8308\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.3971 - val_accuracy: 0.8308\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2058 - accuracy: 0.9073 - val_loss: 0.4006 - val_accuracy: 0.8308\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4039 - val_accuracy: 0.8308\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4025 - val_accuracy: 0.8308\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3987 - val_accuracy: 0.8308\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2068 - accuracy: 0.9029 - val_loss: 0.3920 - val_accuracy: 0.8308\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2141 - accuracy: 0.9073 - val_loss: 0.4106 - val_accuracy: 0.8308\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4069 - val_accuracy: 0.8308\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.4058 - val_accuracy: 0.8308\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.3983 - val_accuracy: 0.8308\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4019 - val_accuracy: 0.8308\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4009 - val_accuracy: 0.8308\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4011 - val_accuracy: 0.8308\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4049 - val_accuracy: 0.8308\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4032 - val_accuracy: 0.8308\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.3984 - val_accuracy: 0.8308\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3981 - val_accuracy: 0.8308\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2107 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2084 - accuracy: 0.9007 - val_loss: 0.4242 - val_accuracy: 0.8308\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 100us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4286 - val_accuracy: 0.8308\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4225 - val_accuracy: 0.8308\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4167 - val_accuracy: 0.8308\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4093 - val_accuracy: 0.8308\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4061 - val_accuracy: 0.8308\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4084 - val_accuracy: 0.8308\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4060 - val_accuracy: 0.8308\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4025 - val_accuracy: 0.8308\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.4052 - val_accuracy: 0.8308\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4044 - val_accuracy: 0.8308\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4040 - val_accuracy: 0.8308\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4067 - val_accuracy: 0.8308\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4066 - val_accuracy: 0.8308\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4099 - val_accuracy: 0.8308\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4066 - val_accuracy: 0.8308\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.4058 - val_accuracy: 0.8308\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2120 - accuracy: 0.9073 - val_loss: 0.4094 - val_accuracy: 0.8308\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4085 - val_accuracy: 0.8308\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2097 - accuracy: 0.9073 - val_loss: 0.4259 - val_accuracy: 0.8308\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4119 - val_accuracy: 0.8308\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4080 - val_accuracy: 0.8308\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4051 - val_accuracy: 0.8308\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4070 - val_accuracy: 0.8308\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 347us/step - loss: 0.2100 - accuracy: 0.9073 - val_loss: 0.4034 - val_accuracy: 0.8308\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4026 - val_accuracy: 0.8308\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4061 - val_accuracy: 0.8308\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4053 - val_accuracy: 0.8308\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4028 - val_accuracy: 0.8308\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4045 - val_accuracy: 0.8308\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4023 - val_accuracy: 0.8308\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4035 - val_accuracy: 0.8308\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.4020 - val_accuracy: 0.8308\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4058 - val_accuracy: 0.8308\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4080 - val_accuracy: 0.8308\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4058 - val_accuracy: 0.8308\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.4019 - val_accuracy: 0.8308\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4008 - val_accuracy: 0.8308\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.3976 - val_accuracy: 0.8308\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4011 - val_accuracy: 0.8308\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4000 - val_accuracy: 0.8308\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.3996 - val_accuracy: 0.8308\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4013 - val_accuracy: 0.8308\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2061 - accuracy: 0.9073 - val_loss: 0.4138 - val_accuracy: 0.8308\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2114 - accuracy: 0.9073 - val_loss: 0.4219 - val_accuracy: 0.8308\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 334us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4166 - val_accuracy: 0.8308\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 384us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4098 - val_accuracy: 0.8308\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4051 - val_accuracy: 0.8308\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4057 - val_accuracy: 0.8308\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4142 - val_accuracy: 0.8308\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4058 - val_accuracy: 0.8308\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4052 - val_accuracy: 0.8308\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4054 - val_accuracy: 0.8308\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4050 - val_accuracy: 0.8308\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.4001 - val_accuracy: 0.8308\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4016 - val_accuracy: 0.8308\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4002 - val_accuracy: 0.8308\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4020 - val_accuracy: 0.8308\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4017 - val_accuracy: 0.8308\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4028 - val_accuracy: 0.8308\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4063 - val_accuracy: 0.8308\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2110 - accuracy: 0.9073 - val_loss: 0.4061 - val_accuracy: 0.8308\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2135 - accuracy: 0.9007 - val_loss: 0.4005 - val_accuracy: 0.8308\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2078 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3991 - val_accuracy: 0.8308\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.3983 - val_accuracy: 0.8308\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.3987 - val_accuracy: 0.8308\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4002 - val_accuracy: 0.8308\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.3934 - val_accuracy: 0.8308\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.3959 - val_accuracy: 0.8308\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4001 - val_accuracy: 0.8308\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.3966 - val_accuracy: 0.8308\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3977 - val_accuracy: 0.8308\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4116 - val_accuracy: 0.8308\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2105 - accuracy: 0.9051 - val_loss: 0.4206 - val_accuracy: 0.8308\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4179 - val_accuracy: 0.8308\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4127 - val_accuracy: 0.8308\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4156 - val_accuracy: 0.8308\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4109 - val_accuracy: 0.8308\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2090 - accuracy: 0.9073 - val_loss: 0.4143 - val_accuracy: 0.8308\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2081 - accuracy: 0.9073 - val_loss: 0.4079 - val_accuracy: 0.8308\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4096 - val_accuracy: 0.8308\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4057 - val_accuracy: 0.8308\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4050 - val_accuracy: 0.8308\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4070 - val_accuracy: 0.8308\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4066 - val_accuracy: 0.8308\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.4038 - val_accuracy: 0.8308\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4042 - val_accuracy: 0.8308\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4016 - val_accuracy: 0.8308\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2099 - accuracy: 0.9073 - val_loss: 0.3984 - val_accuracy: 0.8308\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4010 - val_accuracy: 0.8308\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.3989 - val_accuracy: 0.8308\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4002 - val_accuracy: 0.8308\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4051 - val_accuracy: 0.8308\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 126us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4020 - val_accuracy: 0.8308\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4029 - val_accuracy: 0.8308\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.3989 - val_accuracy: 0.8308\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2103 - accuracy: 0.9073 - val_loss: 0.4030 - val_accuracy: 0.8308\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4005 - val_accuracy: 0.8308\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.3978 - val_accuracy: 0.8308\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2094 - accuracy: 0.9073 - val_loss: 0.3999 - val_accuracy: 0.8308\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3967 - val_accuracy: 0.8308\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4007 - val_accuracy: 0.8308\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4040 - val_accuracy: 0.8308\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2083 - accuracy: 0.9073 - val_loss: 0.4013 - val_accuracy: 0.8308\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.4074 - val_accuracy: 0.8308\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4006 - val_accuracy: 0.8308\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.3968 - val_accuracy: 0.8308\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4000 - val_accuracy: 0.8308\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2096 - accuracy: 0.9073 - val_loss: 0.3988 - val_accuracy: 0.8308\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.3992 - val_accuracy: 0.8308\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.2093 - accuracy: 0.9073 - val_loss: 0.3966 - val_accuracy: 0.8308\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2062 - accuracy: 0.9073 - val_loss: 0.4006 - val_accuracy: 0.8308\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.4003 - val_accuracy: 0.8308\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.4011 - val_accuracy: 0.8308\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3995 - val_accuracy: 0.8308\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4008 - val_accuracy: 0.8308\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.3978 - val_accuracy: 0.8308\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4002 - val_accuracy: 0.8308\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.3979 - val_accuracy: 0.8308\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.3985 - val_accuracy: 0.8308\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2055 - accuracy: 0.9073 - val_loss: 0.3990 - val_accuracy: 0.8308\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3984 - val_accuracy: 0.8308\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4005 - val_accuracy: 0.8308\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3987 - val_accuracy: 0.8308\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.3980 - val_accuracy: 0.8308\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.3999 - val_accuracy: 0.8308\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.4019 - val_accuracy: 0.8308\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3984 - val_accuracy: 0.8308\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.3985 - val_accuracy: 0.8308\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.3951 - val_accuracy: 0.8308\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2077 - accuracy: 0.9073 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4014 - val_accuracy: 0.8308\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2135 - accuracy: 0.9073 - val_loss: 0.4055 - val_accuracy: 0.8308\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.3988 - val_accuracy: 0.8308\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4040 - val_accuracy: 0.8308\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.4059 - val_accuracy: 0.8308\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4037 - val_accuracy: 0.8308\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4044 - val_accuracy: 0.8308\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.4026 - val_accuracy: 0.8308\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2095 - accuracy: 0.9073 - val_loss: 0.4040 - val_accuracy: 0.8308\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.3998 - val_accuracy: 0.8308\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.4028 - val_accuracy: 0.8308\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2057 - accuracy: 0.9073 - val_loss: 0.4021 - val_accuracy: 0.8308\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.4018 - val_accuracy: 0.8308\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2068 - accuracy: 0.9073 - val_loss: 0.4045 - val_accuracy: 0.8308\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4016 - val_accuracy: 0.8308\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.3976 - val_accuracy: 0.8308\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.3994 - val_accuracy: 0.8308\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.3970 - val_accuracy: 0.8308\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.3923 - val_accuracy: 0.8308\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3957 - val_accuracy: 0.8308\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3928 - val_accuracy: 0.8308\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.3951 - val_accuracy: 0.8308\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2079 - accuracy: 0.9073 - val_loss: 0.3962 - val_accuracy: 0.8308\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2075 - accuracy: 0.9073 - val_loss: 0.3920 - val_accuracy: 0.8308\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.3935 - val_accuracy: 0.8308\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.3952 - val_accuracy: 0.8308\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2061 - accuracy: 0.9073 - val_loss: 0.3935 - val_accuracy: 0.8308\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3946 - val_accuracy: 0.8308\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.3955 - val_accuracy: 0.8308\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2106 - accuracy: 0.9007 - val_loss: 0.3906 - val_accuracy: 0.8410\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.3940 - val_accuracy: 0.8308\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.3985 - val_accuracy: 0.8308\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2086 - accuracy: 0.9073 - val_loss: 0.3971 - val_accuracy: 0.8308\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.3951 - val_accuracy: 0.8308\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2076 - accuracy: 0.9073 - val_loss: 0.3960 - val_accuracy: 0.8308\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2066 - accuracy: 0.9073 - val_loss: 0.3952 - val_accuracy: 0.8308\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4012 - val_accuracy: 0.8308\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2058 - accuracy: 0.9073 - val_loss: 0.3997 - val_accuracy: 0.8308\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.3994 - val_accuracy: 0.8308\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2106 - accuracy: 0.9073 - val_loss: 0.3989 - val_accuracy: 0.8308\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2092 - accuracy: 0.9073 - val_loss: 0.3975 - val_accuracy: 0.8308\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2074 - accuracy: 0.9073 - val_loss: 0.3996 - val_accuracy: 0.8308\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4000 - val_accuracy: 0.8308\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2069 - accuracy: 0.9073 - val_loss: 0.3986 - val_accuracy: 0.8308\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2088 - accuracy: 0.9073 - val_loss: 0.3971 - val_accuracy: 0.8308\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2126 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.3971 - val_accuracy: 0.8308\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.4017 - val_accuracy: 0.8308\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3975 - val_accuracy: 0.8308\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2101 - accuracy: 0.9073 - val_loss: 0.4223 - val_accuracy: 0.8308\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2073 - accuracy: 0.9073 - val_loss: 0.4164 - val_accuracy: 0.8308\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4088 - val_accuracy: 0.8308\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.4105 - val_accuracy: 0.8308\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.4103 - val_accuracy: 0.8308\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4095 - val_accuracy: 0.8308\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.4049 - val_accuracy: 0.8308\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.4082 - val_accuracy: 0.8308\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2070 - accuracy: 0.9073 - val_loss: 0.4052 - val_accuracy: 0.8308\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.4068 - val_accuracy: 0.8308\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2091 - accuracy: 0.9073 - val_loss: 0.4024 - val_accuracy: 0.8308\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2085 - accuracy: 0.9073 - val_loss: 0.3979 - val_accuracy: 0.8308\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2065 - accuracy: 0.9073 - val_loss: 0.3959 - val_accuracy: 0.8308\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2063 - accuracy: 0.9073 - val_loss: 0.3958 - val_accuracy: 0.8308\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3977 - val_accuracy: 0.8308\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 149us/step - loss: 0.2082 - accuracy: 0.9073 - val_loss: 0.3973 - val_accuracy: 0.8308\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2072 - accuracy: 0.9073 - val_loss: 0.3998 - val_accuracy: 0.8308\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4011 - val_accuracy: 0.8308\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2087 - accuracy: 0.9073 - val_loss: 0.4048 - val_accuracy: 0.8308\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3999 - val_accuracy: 0.8308\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 322us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4023 - val_accuracy: 0.8308\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 341us/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 0.3975 - val_accuracy: 0.8308\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 340us/step - loss: 0.2089 - accuracy: 0.9073 - val_loss: 0.3954 - val_accuracy: 0.8308\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2071 - accuracy: 0.9073 - val_loss: 0.3968 - val_accuracy: 0.8308\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 90.71%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.7294256e-01, 8.2705740e-01, 5.5157623e-12],\n",
       "       [2.5316253e-01, 7.4683750e-01, 1.1009565e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.5481790e-20],\n",
       "       [1.0000000e+00, 3.4427258e-22, 1.2000968e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [3.1088975e-18, 1.0000000e+00, 9.4137320e-13],\n",
       "       [1.9179791e-22, 1.0000000e+00, 7.7481400e-34],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [1.0000000e+00, 1.1838190e-10, 2.3183300e-11],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [7.5840634e-01, 2.4159370e-01, 1.9421769e-12],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.9621810e-12, 1.0000000e+00, 2.8470518e-22],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [9.7665800e-01, 2.3342090e-02, 1.6380720e-09],\n",
       "       [5.4737720e-07, 9.9999940e-01, 6.8601293e-13],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.5481790e-20],\n",
       "       [3.2851616e-01, 6.7148340e-01, 4.0612827e-07],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.7294256e-01, 8.2705740e-01, 5.5157623e-12],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.7665800e-01, 2.3342090e-02, 1.6380720e-09],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [3.7057810e-05, 9.9996290e-01, 4.1306327e-09],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [1.9179791e-22, 1.0000000e+00, 7.7481400e-34],\n",
       "       [2.7888072e-01, 7.2111934e-01, 2.9543235e-09],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [9.9893147e-01, 1.0684644e-03, 3.1705831e-09],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.5840634e-01, 2.4159370e-01, 1.9421769e-12],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [9.9990270e-01, 9.7238740e-05, 4.1596895e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.5481790e-20],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.9366137e-04, 9.9980634e-01, 6.9878096e-11],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.7075605e-01, 2.9243907e-02, 1.3994768e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [9.9817120e-01, 1.8287565e-03, 2.4805314e-11],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.0676710e-04, 9.9949324e-01, 4.0605066e-09],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [3.7057810e-05, 9.9996290e-01, 4.1306327e-09],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [9.9976500e-01, 2.3499418e-04, 3.5878723e-14],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.4737720e-07, 9.9999940e-01, 6.8601293e-13],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.5481790e-20],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.0676710e-04, 9.9949324e-01, 4.0605066e-09],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.7294256e-01, 8.2705740e-01, 5.5157623e-12],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.7294256e-01, 8.2705740e-01, 5.5157623e-12],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [2.7888072e-01, 7.2111934e-01, 2.9543235e-09],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [3.0706320e-01, 6.9293684e-01, 7.3992507e-10],\n",
       "       [2.7888072e-01, 7.2111934e-01, 2.9543235e-09],\n",
       "       [9.9843100e-01, 1.5689041e-03, 1.6599081e-09],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.9701655e-01, 2.9834544e-03, 1.3278338e-12],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.9555415e-01, 4.4457912e-03, 7.2072643e-12],\n",
       "       [6.9209725e-01, 3.0790278e-01, 4.5875950e-10],\n",
       "       [3.0706320e-01, 6.9293684e-01, 7.3992507e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [3.5960724e-07, 9.9999964e-01, 1.9944075e-12],\n",
       "       [9.2341110e-01, 7.6588960e-02, 2.6507303e-11],\n",
       "       [1.9262820e-08, 1.0000000e+00, 1.5855416e-15],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [3.5960724e-07, 9.9999964e-01, 1.9944075e-12],\n",
       "       [9.9999535e-01, 4.6862910e-06, 2.4069628e-11],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.9179791e-22, 1.0000000e+00, 7.7481400e-34],\n",
       "       [1.0000000e+00, 8.4331436e-19, 9.1765510e-16],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.5481790e-20],\n",
       "       [2.3931356e-05, 9.9997590e-01, 8.6147450e-08],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.5840634e-01, 2.4159370e-01, 1.9421769e-12],\n",
       "       [1.0291363e-17, 1.0000000e+00, 7.4281643e-09],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [2.9149520e-01, 7.0850486e-01, 1.6221762e-08],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.9621810e-12, 1.0000000e+00, 2.8470518e-22],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [2.6357245e-01, 7.3642755e-01, 3.2974622e-08],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.3683064e-02, 9.0631700e-01, 2.1053805e-09],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [2.5316253e-01, 7.4683750e-01, 1.1009565e-10],\n",
       "       [1.9179791e-22, 1.0000000e+00, 7.7481400e-34],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [7.3523060e-01, 2.6476938e-01, 2.7420820e-10],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [7.5840634e-01, 2.4159370e-01, 1.9421769e-12],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [3.7057810e-05, 9.9996290e-01, 4.1306327e-09],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.0676710e-04, 9.9949324e-01, 4.0605066e-09],\n",
       "       [9.8219840e-01, 1.7801536e-02, 1.0375410e-11],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [9.3683064e-02, 9.0631700e-01, 2.1053805e-09],\n",
       "       [7.5840634e-01, 2.4159370e-01, 1.9421769e-12],\n",
       "       [5.7847735e-09, 9.2700670e-09, 1.0000000e+00],\n",
       "       [9.9866090e-01, 1.3390726e-03, 2.8597182e-11],\n",
       "       [5.0676710e-04, 9.9949324e-01, 4.0605066e-09],\n",
       "       [1.6423370e-08, 1.4098223e-08, 1.0000000e+00],\n",
       "       [1.9621810e-12, 1.0000000e+00, 2.8470518e-22]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933491124260355"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933491124260355"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS110     2\n",
       "1       NRS254     1\n",
       "2    BCH-SA-09     0\n",
       "3       NRS177     0\n",
       "4         GA27     1\n",
       "..         ...   ...\n",
       "190     NRS001     1\n",
       "191     NRS209     2\n",
       "192     NRS272     0\n",
       "193     NRS110     2\n",
       "194     NRS204     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 326us/step - loss: 0.9344 - accuracy: 0.5298 - val_loss: 0.7770 - val_accuracy: 0.7795\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.6988 - accuracy: 0.7859 - val_loss: 0.6353 - val_accuracy: 0.8256\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.5811 - accuracy: 0.7969 - val_loss: 0.5465 - val_accuracy: 0.7949\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.5121 - accuracy: 0.8013 - val_loss: 0.4804 - val_accuracy: 0.8256\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.4660 - accuracy: 0.7837 - val_loss: 0.4428 - val_accuracy: 0.8154\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.4387 - accuracy: 0.8013 - val_loss: 0.4212 - val_accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.4188 - accuracy: 0.8124 - val_loss: 0.4035 - val_accuracy: 0.8359\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.4066 - accuracy: 0.8102 - val_loss: 0.4029 - val_accuracy: 0.8051\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.4083 - accuracy: 0.8190 - val_loss: 0.3892 - val_accuracy: 0.7949\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.3999 - accuracy: 0.8013 - val_loss: 0.3759 - val_accuracy: 0.8103\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.3954 - accuracy: 0.7859 - val_loss: 0.3687 - val_accuracy: 0.8462\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.3900 - accuracy: 0.8013 - val_loss: 0.3645 - val_accuracy: 0.8205\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.3771 - accuracy: 0.7991 - val_loss: 0.3626 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.3697 - accuracy: 0.8212 - val_loss: 0.3598 - val_accuracy: 0.8256\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.3603 - accuracy: 0.8300 - val_loss: 0.3514 - val_accuracy: 0.8513\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.3571 - accuracy: 0.8300 - val_loss: 0.3510 - val_accuracy: 0.8564\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.3544 - accuracy: 0.8212 - val_loss: 0.3452 - val_accuracy: 0.8615\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.3531 - accuracy: 0.8212 - val_loss: 0.3745 - val_accuracy: 0.7282\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.3466 - accuracy: 0.8146 - val_loss: 0.3439 - val_accuracy: 0.8410\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.3405 - accuracy: 0.8322 - val_loss: 0.3372 - val_accuracy: 0.8256\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.3565 - accuracy: 0.8278 - val_loss: 0.3593 - val_accuracy: 0.8359\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.3434 - accuracy: 0.8212 - val_loss: 0.3324 - val_accuracy: 0.8513\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.3334 - accuracy: 0.8366 - val_loss: 0.3305 - val_accuracy: 0.8513\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.3322 - accuracy: 0.8300 - val_loss: 0.3646 - val_accuracy: 0.8359\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3441 - accuracy: 0.8344 - val_loss: 0.3254 - val_accuracy: 0.8359\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.3301 - accuracy: 0.8477 - val_loss: 0.3322 - val_accuracy: 0.8256\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.3205 - accuracy: 0.8344 - val_loss: 0.3366 - val_accuracy: 0.8513\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.3221 - accuracy: 0.8389 - val_loss: 0.3330 - val_accuracy: 0.8256\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 421us/step - loss: 0.3215 - accuracy: 0.8389 - val_loss: 0.3227 - val_accuracy: 0.8359\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.3179 - accuracy: 0.8366 - val_loss: 0.3200 - val_accuracy: 0.8564\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.3150 - accuracy: 0.8411 - val_loss: 0.3166 - val_accuracy: 0.8410\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.3264 - accuracy: 0.8278 - val_loss: 0.3319 - val_accuracy: 0.8205\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.3271 - accuracy: 0.8455 - val_loss: 0.3866 - val_accuracy: 0.7179\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.3337 - accuracy: 0.8234 - val_loss: 0.3373 - val_accuracy: 0.8205\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3132 - accuracy: 0.8455 - val_loss: 0.3177 - val_accuracy: 0.8410\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.3096 - accuracy: 0.8389 - val_loss: 0.3139 - val_accuracy: 0.8359\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.3064 - accuracy: 0.8411 - val_loss: 0.3228 - val_accuracy: 0.8410\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.3202 - accuracy: 0.8234 - val_loss: 0.3134 - val_accuracy: 0.8410\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.3080 - accuracy: 0.8477 - val_loss: 0.3147 - val_accuracy: 0.8410\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.3120 - accuracy: 0.8300 - val_loss: 0.3431 - val_accuracy: 0.8205\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.3004 - accuracy: 0.8477 - val_loss: 0.3110 - val_accuracy: 0.8359\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2983 - accuracy: 0.8389 - val_loss: 0.3125 - val_accuracy: 0.8359\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 406us/step - loss: 0.2993 - accuracy: 0.8433 - val_loss: 0.3140 - val_accuracy: 0.8410\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.2999 - accuracy: 0.8344 - val_loss: 0.3102 - val_accuracy: 0.8410\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2988 - accuracy: 0.8477 - val_loss: 0.3144 - val_accuracy: 0.8410\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2946 - accuracy: 0.8389 - val_loss: 0.3109 - val_accuracy: 0.8513\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2994 - accuracy: 0.8455 - val_loss: 0.3188 - val_accuracy: 0.8462\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2986 - accuracy: 0.8433 - val_loss: 0.3195 - val_accuracy: 0.8462\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2966 - accuracy: 0.8499 - val_loss: 0.3078 - val_accuracy: 0.8410\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2908 - accuracy: 0.8344 - val_loss: 0.3147 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2877 - accuracy: 0.8543 - val_loss: 0.3083 - val_accuracy: 0.8410\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.3005 - accuracy: 0.8543 - val_loss: 0.3257 - val_accuracy: 0.8462\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2932 - accuracy: 0.8300 - val_loss: 0.3121 - val_accuracy: 0.8462\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2975 - accuracy: 0.8565 - val_loss: 0.3138 - val_accuracy: 0.8462\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 317us/step - loss: 0.2888 - accuracy: 0.8631 - val_loss: 0.3049 - val_accuracy: 0.8564\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2944 - accuracy: 0.8411 - val_loss: 0.3128 - val_accuracy: 0.8564\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2881 - accuracy: 0.8499 - val_loss: 0.3083 - val_accuracy: 0.8564\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2902 - accuracy: 0.8455 - val_loss: 0.3133 - val_accuracy: 0.8462\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2927 - accuracy: 0.8499 - val_loss: 0.3120 - val_accuracy: 0.8462\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2832 - accuracy: 0.8499 - val_loss: 0.3082 - val_accuracy: 0.8615\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2898 - accuracy: 0.8433 - val_loss: 0.3068 - val_accuracy: 0.8462\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2808 - accuracy: 0.8543 - val_loss: 0.3090 - val_accuracy: 0.8462\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2846 - accuracy: 0.8565 - val_loss: 0.3035 - val_accuracy: 0.8462\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2828 - accuracy: 0.8521 - val_loss: 0.3053 - val_accuracy: 0.8564\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2871 - accuracy: 0.8565 - val_loss: 0.3058 - val_accuracy: 0.8462\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2777 - accuracy: 0.8521 - val_loss: 0.3089 - val_accuracy: 0.8513\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2847 - accuracy: 0.8565 - val_loss: 0.3237 - val_accuracy: 0.8359\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2782 - accuracy: 0.8653 - val_loss: 0.3056 - val_accuracy: 0.8564\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2794 - accuracy: 0.8609 - val_loss: 0.3050 - val_accuracy: 0.8513\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2750 - accuracy: 0.8609 - val_loss: 0.3076 - val_accuracy: 0.8462\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2908 - accuracy: 0.8366 - val_loss: 0.3023 - val_accuracy: 0.8615\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2849 - accuracy: 0.8543 - val_loss: 0.3013 - val_accuracy: 0.8564\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2838 - accuracy: 0.8499 - val_loss: 0.3045 - val_accuracy: 0.8564\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2773 - accuracy: 0.8653 - val_loss: 0.3028 - val_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2821 - accuracy: 0.8609 - val_loss: 0.3042 - val_accuracy: 0.8462\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2775 - accuracy: 0.8587 - val_loss: 0.3143 - val_accuracy: 0.8359\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.3055 - accuracy: 0.8344 - val_loss: 0.3238 - val_accuracy: 0.8513\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2811 - accuracy: 0.8653 - val_loss: 0.3056 - val_accuracy: 0.8564\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2748 - accuracy: 0.8675 - val_loss: 0.3044 - val_accuracy: 0.8462\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2776 - accuracy: 0.8543 - val_loss: 0.3110 - val_accuracy: 0.8462\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2699 - accuracy: 0.8698 - val_loss: 0.3069 - val_accuracy: 0.8462\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2719 - accuracy: 0.8698 - val_loss: 0.3014 - val_accuracy: 0.8513\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2688 - accuracy: 0.8587 - val_loss: 0.3047 - val_accuracy: 0.8564\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2682 - accuracy: 0.8675 - val_loss: 0.3043 - val_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2686 - accuracy: 0.8698 - val_loss: 0.3051 - val_accuracy: 0.8564\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2727 - accuracy: 0.8675 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2714 - accuracy: 0.8698 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2656 - accuracy: 0.8720 - val_loss: 0.3175 - val_accuracy: 0.8513\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2672 - accuracy: 0.8631 - val_loss: 0.3029 - val_accuracy: 0.8564\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2676 - accuracy: 0.8653 - val_loss: 0.3019 - val_accuracy: 0.8410\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2767 - accuracy: 0.8543 - val_loss: 0.3179 - val_accuracy: 0.8513\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2677 - accuracy: 0.8653 - val_loss: 0.3073 - val_accuracy: 0.8513\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2652 - accuracy: 0.8587 - val_loss: 0.3309 - val_accuracy: 0.8359\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2764 - accuracy: 0.8675 - val_loss: 0.3080 - val_accuracy: 0.8513\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2623 - accuracy: 0.8720 - val_loss: 0.3038 - val_accuracy: 0.8513\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2614 - accuracy: 0.8698 - val_loss: 0.3067 - val_accuracy: 0.8410\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2618 - accuracy: 0.8786 - val_loss: 0.3028 - val_accuracy: 0.8462\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2630 - accuracy: 0.8720 - val_loss: 0.3040 - val_accuracy: 0.8564\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2619 - accuracy: 0.8808 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2587 - accuracy: 0.8675 - val_loss: 0.3109 - val_accuracy: 0.8564\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2616 - accuracy: 0.8764 - val_loss: 0.3045 - val_accuracy: 0.8462\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2621 - accuracy: 0.8742 - val_loss: 0.3119 - val_accuracy: 0.8462\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2601 - accuracy: 0.8698 - val_loss: 0.3110 - val_accuracy: 0.8513\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2622 - accuracy: 0.8786 - val_loss: 0.3052 - val_accuracy: 0.8462\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2618 - accuracy: 0.8698 - val_loss: 0.3062 - val_accuracy: 0.8462\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2557 - accuracy: 0.8698 - val_loss: 0.3202 - val_accuracy: 0.8410\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2659 - accuracy: 0.8764 - val_loss: 0.3051 - val_accuracy: 0.8564\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2612 - accuracy: 0.8653 - val_loss: 0.3056 - val_accuracy: 0.8513\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2576 - accuracy: 0.8675 - val_loss: 0.3077 - val_accuracy: 0.8513\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2709 - accuracy: 0.8653 - val_loss: 0.3083 - val_accuracy: 0.8513\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2676 - accuracy: 0.8675 - val_loss: 0.3079 - val_accuracy: 0.8513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2731 - accuracy: 0.8720 - val_loss: 0.3067 - val_accuracy: 0.8513\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2635 - accuracy: 0.8587 - val_loss: 0.3065 - val_accuracy: 0.8564\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2655 - accuracy: 0.8786 - val_loss: 0.3044 - val_accuracy: 0.8462\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2593 - accuracy: 0.8698 - val_loss: 0.3032 - val_accuracy: 0.8564\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2567 - accuracy: 0.8764 - val_loss: 0.3088 - val_accuracy: 0.8513\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2669 - accuracy: 0.8830 - val_loss: 0.3131 - val_accuracy: 0.8513\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2609 - accuracy: 0.8675 - val_loss: 0.3035 - val_accuracy: 0.8564\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2554 - accuracy: 0.8653 - val_loss: 0.3320 - val_accuracy: 0.8359\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2567 - accuracy: 0.8852 - val_loss: 0.3071 - val_accuracy: 0.8462\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2574 - accuracy: 0.8720 - val_loss: 0.3080 - val_accuracy: 0.8513\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2606 - accuracy: 0.8830 - val_loss: 0.3101 - val_accuracy: 0.8513\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2586 - accuracy: 0.8653 - val_loss: 0.3111 - val_accuracy: 0.8513\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2550 - accuracy: 0.8742 - val_loss: 0.3074 - val_accuracy: 0.8564\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2537 - accuracy: 0.8764 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2544 - accuracy: 0.8786 - val_loss: 0.3080 - val_accuracy: 0.8564\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2568 - accuracy: 0.8764 - val_loss: 0.3113 - val_accuracy: 0.8462\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2693 - accuracy: 0.8609 - val_loss: 0.3946 - val_accuracy: 0.7538\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2743 - accuracy: 0.8587 - val_loss: 0.3143 - val_accuracy: 0.8462\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2607 - accuracy: 0.8675 - val_loss: 0.3094 - val_accuracy: 0.8462\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2535 - accuracy: 0.8808 - val_loss: 0.3076 - val_accuracy: 0.8564\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2556 - accuracy: 0.8764 - val_loss: 0.3131 - val_accuracy: 0.8462\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2629 - accuracy: 0.8720 - val_loss: 0.3221 - val_accuracy: 0.8462\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2619 - accuracy: 0.8764 - val_loss: 0.3131 - val_accuracy: 0.8667\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2472 - accuracy: 0.8852 - val_loss: 0.3130 - val_accuracy: 0.8410\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2627 - accuracy: 0.8675 - val_loss: 0.3196 - val_accuracy: 0.8462\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2637 - accuracy: 0.8764 - val_loss: 0.3124 - val_accuracy: 0.8667\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2496 - accuracy: 0.8830 - val_loss: 0.3119 - val_accuracy: 0.8564\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2513 - accuracy: 0.8764 - val_loss: 0.3066 - val_accuracy: 0.8410\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2607 - accuracy: 0.8499 - val_loss: 0.3091 - val_accuracy: 0.8564\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2486 - accuracy: 0.8808 - val_loss: 0.3135 - val_accuracy: 0.8462\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2555 - accuracy: 0.8742 - val_loss: 0.3179 - val_accuracy: 0.8462\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2585 - accuracy: 0.8764 - val_loss: 0.3188 - val_accuracy: 0.8462\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2536 - accuracy: 0.8742 - val_loss: 0.3091 - val_accuracy: 0.8462\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2507 - accuracy: 0.8830 - val_loss: 0.3332 - val_accuracy: 0.7590\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.2567 - accuracy: 0.8609 - val_loss: 0.3072 - val_accuracy: 0.8462\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2527 - accuracy: 0.8808 - val_loss: 0.3086 - val_accuracy: 0.8564\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2466 - accuracy: 0.8764 - val_loss: 0.3105 - val_accuracy: 0.8410\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2546 - accuracy: 0.8786 - val_loss: 0.3108 - val_accuracy: 0.8462\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2494 - accuracy: 0.8720 - val_loss: 0.3110 - val_accuracy: 0.8564\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2466 - accuracy: 0.8830 - val_loss: 0.3128 - val_accuracy: 0.8410\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2537 - accuracy: 0.8742 - val_loss: 0.3169 - val_accuracy: 0.8410\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2564 - accuracy: 0.8852 - val_loss: 0.3270 - val_accuracy: 0.8513\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.3106 - val_accuracy: 0.8667\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2509 - accuracy: 0.8830 - val_loss: 0.3152 - val_accuracy: 0.8462\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2558 - accuracy: 0.8830 - val_loss: 0.3134 - val_accuracy: 0.8410\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2488 - accuracy: 0.8675 - val_loss: 0.3099 - val_accuracy: 0.8462\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2476 - accuracy: 0.8786 - val_loss: 0.3111 - val_accuracy: 0.8462\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2459 - accuracy: 0.8808 - val_loss: 0.3148 - val_accuracy: 0.8410\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2490 - accuracy: 0.8808 - val_loss: 0.3122 - val_accuracy: 0.8462\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2466 - accuracy: 0.8830 - val_loss: 0.3463 - val_accuracy: 0.7590\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2512 - accuracy: 0.8631 - val_loss: 0.3134 - val_accuracy: 0.8462\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2506 - accuracy: 0.8874 - val_loss: 0.3129 - val_accuracy: 0.8462\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2534 - accuracy: 0.8720 - val_loss: 0.3197 - val_accuracy: 0.8410\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2609 - accuracy: 0.8808 - val_loss: 0.3184 - val_accuracy: 0.8410\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2437 - accuracy: 0.8742 - val_loss: 0.3167 - val_accuracy: 0.8462\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2433 - accuracy: 0.8764 - val_loss: 0.3136 - val_accuracy: 0.8462\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2447 - accuracy: 0.8742 - val_loss: 0.3213 - val_accuracy: 0.8462\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2465 - accuracy: 0.8786 - val_loss: 0.3212 - val_accuracy: 0.8462\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2589 - accuracy: 0.8698 - val_loss: 0.3169 - val_accuracy: 0.8462\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2474 - accuracy: 0.8830 - val_loss: 0.3174 - val_accuracy: 0.8462\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2464 - accuracy: 0.8874 - val_loss: 0.3161 - val_accuracy: 0.8462\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2435 - accuracy: 0.8742 - val_loss: 0.3144 - val_accuracy: 0.8564\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2454 - accuracy: 0.8808 - val_loss: 0.3132 - val_accuracy: 0.8462\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2485 - accuracy: 0.8830 - val_loss: 0.3260 - val_accuracy: 0.8462\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2485 - accuracy: 0.8808 - val_loss: 0.3137 - val_accuracy: 0.8462\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2436 - accuracy: 0.8918 - val_loss: 0.3144 - val_accuracy: 0.8462\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2507 - accuracy: 0.8786 - val_loss: 0.3150 - val_accuracy: 0.8462\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2455 - accuracy: 0.8742 - val_loss: 0.3166 - val_accuracy: 0.8359\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2462 - accuracy: 0.8786 - val_loss: 0.3178 - val_accuracy: 0.8462\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2442 - accuracy: 0.8764 - val_loss: 0.3269 - val_accuracy: 0.8410\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2421 - accuracy: 0.8830 - val_loss: 0.3164 - val_accuracy: 0.8359\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2438 - accuracy: 0.8874 - val_loss: 0.3292 - val_accuracy: 0.8410\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2454 - accuracy: 0.8808 - val_loss: 0.3231 - val_accuracy: 0.8564\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2412 - accuracy: 0.8830 - val_loss: 0.3215 - val_accuracy: 0.8410\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2515 - accuracy: 0.8808 - val_loss: 0.3211 - val_accuracy: 0.8462\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2435 - accuracy: 0.8742 - val_loss: 0.3190 - val_accuracy: 0.8462\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2602 - accuracy: 0.8521 - val_loss: 0.3211 - val_accuracy: 0.8410\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2433 - accuracy: 0.8808 - val_loss: 0.3198 - val_accuracy: 0.8462\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2422 - accuracy: 0.8852 - val_loss: 0.3291 - val_accuracy: 0.8462\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2528 - accuracy: 0.8764 - val_loss: 0.3208 - val_accuracy: 0.8462\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2532 - accuracy: 0.8786 - val_loss: 0.3216 - val_accuracy: 0.8564\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2422 - accuracy: 0.8808 - val_loss: 0.3219 - val_accuracy: 0.8462\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2425 - accuracy: 0.8786 - val_loss: 0.3354 - val_accuracy: 0.8513\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2468 - accuracy: 0.8742 - val_loss: 0.3214 - val_accuracy: 0.8462\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2543 - accuracy: 0.8742 - val_loss: 0.3184 - val_accuracy: 0.8462\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2522 - accuracy: 0.8808 - val_loss: 0.3209 - val_accuracy: 0.8462\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 0.3258 - val_accuracy: 0.8462\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2456 - accuracy: 0.8808 - val_loss: 0.3441 - val_accuracy: 0.8410\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2486 - accuracy: 0.8808 - val_loss: 0.3206 - val_accuracy: 0.8462\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2430 - accuracy: 0.8720 - val_loss: 0.3221 - val_accuracy: 0.8462\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2402 - accuracy: 0.8786 - val_loss: 0.3243 - val_accuracy: 0.8462\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2419 - accuracy: 0.8852 - val_loss: 0.3368 - val_accuracy: 0.8462\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2457 - accuracy: 0.8764 - val_loss: 0.3338 - val_accuracy: 0.8462\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2579 - accuracy: 0.8786 - val_loss: 0.3376 - val_accuracy: 0.8462\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2459 - accuracy: 0.8830 - val_loss: 0.3226 - val_accuracy: 0.8462\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2507 - accuracy: 0.8499 - val_loss: 0.3418 - val_accuracy: 0.8410\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2532 - accuracy: 0.8852 - val_loss: 0.3242 - val_accuracy: 0.8462\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2437 - accuracy: 0.8698 - val_loss: 0.3344 - val_accuracy: 0.8410\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2443 - accuracy: 0.8874 - val_loss: 0.3238 - val_accuracy: 0.8462\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2416 - accuracy: 0.8698 - val_loss: 0.3265 - val_accuracy: 0.8564\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2440 - accuracy: 0.8896 - val_loss: 0.3298 - val_accuracy: 0.8462\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2412 - accuracy: 0.8808 - val_loss: 0.3221 - val_accuracy: 0.8462\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2374 - accuracy: 0.8874 - val_loss: 0.3259 - val_accuracy: 0.8462\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2481 - accuracy: 0.8698 - val_loss: 0.3245 - val_accuracy: 0.8462\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2416 - accuracy: 0.8852 - val_loss: 0.3298 - val_accuracy: 0.8564\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2392 - accuracy: 0.8786 - val_loss: 0.3389 - val_accuracy: 0.8462\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2535 - accuracy: 0.8631 - val_loss: 0.3300 - val_accuracy: 0.8462\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2427 - accuracy: 0.8742 - val_loss: 0.3258 - val_accuracy: 0.8462\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2416 - accuracy: 0.8830 - val_loss: 0.3253 - val_accuracy: 0.8564\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2408 - accuracy: 0.8786 - val_loss: 0.3284 - val_accuracy: 0.8462\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 137us/step - loss: 0.2433 - accuracy: 0.8764 - val_loss: 0.3271 - val_accuracy: 0.8462\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2438 - accuracy: 0.8852 - val_loss: 0.3346 - val_accuracy: 0.8564\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2399 - accuracy: 0.8852 - val_loss: 0.3368 - val_accuracy: 0.8564\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.3308 - val_accuracy: 0.8564\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2398 - accuracy: 0.8874 - val_loss: 0.3334 - val_accuracy: 0.8564\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2428 - accuracy: 0.8808 - val_loss: 0.3402 - val_accuracy: 0.8410\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2434 - accuracy: 0.8808 - val_loss: 0.3251 - val_accuracy: 0.8462\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2379 - accuracy: 0.8852 - val_loss: 0.3299 - val_accuracy: 0.8564\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2404 - accuracy: 0.8830 - val_loss: 0.3290 - val_accuracy: 0.8513\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2394 - accuracy: 0.8874 - val_loss: 0.3362 - val_accuracy: 0.8462\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.3238 - val_accuracy: 0.8462\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2453 - accuracy: 0.8764 - val_loss: 0.3307 - val_accuracy: 0.8462\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2503 - accuracy: 0.8808 - val_loss: 0.3281 - val_accuracy: 0.8462\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.3345 - val_accuracy: 0.8462\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2546 - accuracy: 0.8742 - val_loss: 0.3383 - val_accuracy: 0.8564\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2365 - accuracy: 0.8896 - val_loss: 0.3273 - val_accuracy: 0.8462\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2389 - accuracy: 0.8874 - val_loss: 0.3294 - val_accuracy: 0.8462\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.3297 - val_accuracy: 0.8462\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2393 - accuracy: 0.8852 - val_loss: 0.3351 - val_accuracy: 0.8462\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2424 - accuracy: 0.8742 - val_loss: 0.3317 - val_accuracy: 0.8359\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2415 - accuracy: 0.8874 - val_loss: 0.3348 - val_accuracy: 0.8462\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2363 - accuracy: 0.8764 - val_loss: 0.3271 - val_accuracy: 0.8462\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2361 - accuracy: 0.8874 - val_loss: 0.3344 - val_accuracy: 0.8564\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2409 - accuracy: 0.8808 - val_loss: 0.3444 - val_accuracy: 0.8410\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8462\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.3411 - val_accuracy: 0.8513\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.3340 - val_accuracy: 0.8462\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2426 - accuracy: 0.8808 - val_loss: 0.3314 - val_accuracy: 0.8462\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2379 - accuracy: 0.8874 - val_loss: 0.3441 - val_accuracy: 0.8462\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2450 - accuracy: 0.8808 - val_loss: 0.3328 - val_accuracy: 0.8462\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.2427 - accuracy: 0.8698 - val_loss: 0.3410 - val_accuracy: 0.8410\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2433 - accuracy: 0.8742 - val_loss: 0.3351 - val_accuracy: 0.8462\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2382 - accuracy: 0.8852 - val_loss: 0.3339 - val_accuracy: 0.8462\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2428 - accuracy: 0.8742 - val_loss: 0.3466 - val_accuracy: 0.8410\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2433 - accuracy: 0.8720 - val_loss: 0.3730 - val_accuracy: 0.7590\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2580 - accuracy: 0.8455 - val_loss: 0.3437 - val_accuracy: 0.8410\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2425 - accuracy: 0.8764 - val_loss: 0.3285 - val_accuracy: 0.8462\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2380 - accuracy: 0.8852 - val_loss: 0.3272 - val_accuracy: 0.8462\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2366 - accuracy: 0.8918 - val_loss: 0.3357 - val_accuracy: 0.8564\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2313 - accuracy: 0.8918 - val_loss: 0.3395 - val_accuracy: 0.8462\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2502 - accuracy: 0.8830 - val_loss: 0.3328 - val_accuracy: 0.8462\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2512 - accuracy: 0.8830 - val_loss: 0.3312 - val_accuracy: 0.8462\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.3310 - val_accuracy: 0.8462\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.3369 - val_accuracy: 0.8564\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2403 - accuracy: 0.8786 - val_loss: 0.3329 - val_accuracy: 0.8564\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.3299 - val_accuracy: 0.8462\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.3367 - val_accuracy: 0.8462\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2461 - accuracy: 0.8808 - val_loss: 0.3408 - val_accuracy: 0.8462\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2403 - accuracy: 0.8830 - val_loss: 0.3364 - val_accuracy: 0.8462\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2491 - accuracy: 0.8786 - val_loss: 0.3396 - val_accuracy: 0.8564\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2398 - accuracy: 0.8830 - val_loss: 0.3322 - val_accuracy: 0.8462\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2445 - accuracy: 0.8830 - val_loss: 0.3341 - val_accuracy: 0.8462\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.3356 - val_accuracy: 0.8462\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2393 - accuracy: 0.8852 - val_loss: 0.3367 - val_accuracy: 0.8564\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2468 - accuracy: 0.8698 - val_loss: 0.3334 - val_accuracy: 0.8462\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.3351 - val_accuracy: 0.8462\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.3326 - val_accuracy: 0.8462\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2345 - accuracy: 0.8874 - val_loss: 0.3414 - val_accuracy: 0.8564\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.3334 - val_accuracy: 0.8462\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.3360 - val_accuracy: 0.8410\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2427 - accuracy: 0.8852 - val_loss: 0.3340 - val_accuracy: 0.8462\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2377 - accuracy: 0.8874 - val_loss: 0.3429 - val_accuracy: 0.8462\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2395 - accuracy: 0.8742 - val_loss: 0.3369 - val_accuracy: 0.8462\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2449 - accuracy: 0.8786 - val_loss: 0.3367 - val_accuracy: 0.8462\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 0.3439 - val_accuracy: 0.8462\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2408 - accuracy: 0.8852 - val_loss: 0.3409 - val_accuracy: 0.8462\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2358 - accuracy: 0.8852 - val_loss: 0.3351 - val_accuracy: 0.8462\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2385 - accuracy: 0.8874 - val_loss: 0.3430 - val_accuracy: 0.8564\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.3402 - val_accuracy: 0.8462\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2435 - accuracy: 0.8587 - val_loss: 0.3545 - val_accuracy: 0.8564\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2384 - accuracy: 0.8830 - val_loss: 0.3396 - val_accuracy: 0.8462\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2378 - accuracy: 0.8874 - val_loss: 0.3402 - val_accuracy: 0.8462\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.3376 - val_accuracy: 0.8462\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.3416 - val_accuracy: 0.8564\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2380 - accuracy: 0.8808 - val_loss: 0.3449 - val_accuracy: 0.8462\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.3410 - val_accuracy: 0.8462\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.3646 - val_accuracy: 0.8410\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2414 - accuracy: 0.8852 - val_loss: 0.3407 - val_accuracy: 0.8359\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.3392 - val_accuracy: 0.8462\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2439 - accuracy: 0.8675 - val_loss: 0.3481 - val_accuracy: 0.8564\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2437 - accuracy: 0.8830 - val_loss: 0.3439 - val_accuracy: 0.8462\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2386 - accuracy: 0.8874 - val_loss: 0.3399 - val_accuracy: 0.8462\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2401 - accuracy: 0.8786 - val_loss: 0.3501 - val_accuracy: 0.8410\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2460 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8462\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2378 - accuracy: 0.8874 - val_loss: 0.3472 - val_accuracy: 0.8462\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.3422 - val_accuracy: 0.8462\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2388 - accuracy: 0.8808 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2333 - accuracy: 0.8764 - val_loss: 0.3448 - val_accuracy: 0.8462\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.3505 - val_accuracy: 0.8564\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2419 - accuracy: 0.8852 - val_loss: 0.3446 - val_accuracy: 0.8564\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2369 - accuracy: 0.8698 - val_loss: 0.3402 - val_accuracy: 0.8462\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.3389 - val_accuracy: 0.8462\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 0.3425 - val_accuracy: 0.8462\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2397 - accuracy: 0.8808 - val_loss: 0.3404 - val_accuracy: 0.8359\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.3438 - val_accuracy: 0.8462\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2401 - accuracy: 0.8808 - val_loss: 0.3435 - val_accuracy: 0.8462\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2415 - accuracy: 0.8653 - val_loss: 0.3440 - val_accuracy: 0.8462\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2490 - accuracy: 0.8808 - val_loss: 0.3415 - val_accuracy: 0.8462\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2426 - accuracy: 0.8786 - val_loss: 0.3424 - val_accuracy: 0.8564\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.3439 - val_accuracy: 0.8462\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2381 - accuracy: 0.8852 - val_loss: 0.3528 - val_accuracy: 0.8564\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.3468 - val_accuracy: 0.8462\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2379 - accuracy: 0.8808 - val_loss: 0.3470 - val_accuracy: 0.8462\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2344 - accuracy: 0.8874 - val_loss: 0.3463 - val_accuracy: 0.8462\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2360 - accuracy: 0.8874 - val_loss: 0.3451 - val_accuracy: 0.8359\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.3472 - val_accuracy: 0.8462\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.3424 - val_accuracy: 0.8462\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2379 - accuracy: 0.8808 - val_loss: 0.3407 - val_accuracy: 0.8462\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.3426 - val_accuracy: 0.8462\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 114us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 0.3417 - val_accuracy: 0.8462\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2453 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2355 - accuracy: 0.8786 - val_loss: 0.3426 - val_accuracy: 0.8462\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.3444 - val_accuracy: 0.8462\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.3443 - val_accuracy: 0.8462\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.3459 - val_accuracy: 0.8359\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.3447 - val_accuracy: 0.8462\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2382 - accuracy: 0.8874 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.3437 - val_accuracy: 0.8462\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.3524 - val_accuracy: 0.8462\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.3454 - val_accuracy: 0.8462\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2426 - accuracy: 0.8808 - val_loss: 0.3558 - val_accuracy: 0.8564\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.3474 - val_accuracy: 0.8462\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2347 - accuracy: 0.8786 - val_loss: 0.3479 - val_accuracy: 0.8359\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2343 - accuracy: 0.8786 - val_loss: 0.3496 - val_accuracy: 0.8462\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2407 - accuracy: 0.8830 - val_loss: 0.3538 - val_accuracy: 0.8462\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.3497 - val_accuracy: 0.8359\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.3480 - val_accuracy: 0.8462\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.8462\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.3493 - val_accuracy: 0.8462\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2421 - accuracy: 0.8786 - val_loss: 0.3589 - val_accuracy: 0.8410\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.3610 - val_accuracy: 0.8564\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 0.3515 - val_accuracy: 0.8462\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2359 - accuracy: 0.8896 - val_loss: 0.3520 - val_accuracy: 0.8462\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.3511 - val_accuracy: 0.8462\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2392 - accuracy: 0.8786 - val_loss: 0.3538 - val_accuracy: 0.8462\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.3637 - val_accuracy: 0.8513\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2386 - accuracy: 0.8852 - val_loss: 0.3475 - val_accuracy: 0.8462\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.3469 - val_accuracy: 0.8462\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.3485 - val_accuracy: 0.8513\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2384 - accuracy: 0.8830 - val_loss: 0.3482 - val_accuracy: 0.8564\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2373 - accuracy: 0.8874 - val_loss: 0.3498 - val_accuracy: 0.8462\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.3490 - val_accuracy: 0.8462\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2401 - accuracy: 0.8874 - val_loss: 0.3487 - val_accuracy: 0.8462\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.3488 - val_accuracy: 0.8462\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.3607 - val_accuracy: 0.8462\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2371 - accuracy: 0.8742 - val_loss: 0.3493 - val_accuracy: 0.8462\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2397 - accuracy: 0.8764 - val_loss: 0.3529 - val_accuracy: 0.8462\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.3509 - val_accuracy: 0.8462\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.3494 - val_accuracy: 0.8462\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2361 - accuracy: 0.8874 - val_loss: 0.3542 - val_accuracy: 0.8564\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.3532 - val_accuracy: 0.8462\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.3493 - val_accuracy: 0.8462\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 0.3518 - val_accuracy: 0.8462\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.3523 - val_accuracy: 0.8462\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.3522 - val_accuracy: 0.8462\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2412 - accuracy: 0.8786 - val_loss: 0.3586 - val_accuracy: 0.8462\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.3545 - val_accuracy: 0.8462\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2335 - accuracy: 0.8874 - val_loss: 0.3535 - val_accuracy: 0.8462\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.3539 - val_accuracy: 0.8462\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 0.3577 - val_accuracy: 0.8462\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2328 - accuracy: 0.8786 - val_loss: 0.3683 - val_accuracy: 0.8410\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2339 - accuracy: 0.8786 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2380 - accuracy: 0.8852 - val_loss: 0.3591 - val_accuracy: 0.8462\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2385 - accuracy: 0.8852 - val_loss: 0.3620 - val_accuracy: 0.8462\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2368 - accuracy: 0.8653 - val_loss: 0.3705 - val_accuracy: 0.8410\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2474 - accuracy: 0.8808 - val_loss: 0.3658 - val_accuracy: 0.8564\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.3509 - val_accuracy: 0.8564\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8462\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2407 - accuracy: 0.8786 - val_loss: 0.3595 - val_accuracy: 0.8410\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.3589 - val_accuracy: 0.8410\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.3634 - val_accuracy: 0.8410\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.3612 - val_accuracy: 0.8410\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.3743 - val_accuracy: 0.8462\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2505 - accuracy: 0.8764 - val_loss: 0.3592 - val_accuracy: 0.8359\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 0.3484 - val_accuracy: 0.8513\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.3526 - val_accuracy: 0.8462\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.3508 - val_accuracy: 0.8513\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.3547 - val_accuracy: 0.8410\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2330 - accuracy: 0.8896 - val_loss: 0.3557 - val_accuracy: 0.8462\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.3522 - val_accuracy: 0.8462\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.3569 - val_accuracy: 0.8462\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2397 - accuracy: 0.8742 - val_loss: 0.3605 - val_accuracy: 0.8462\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2412 - accuracy: 0.8786 - val_loss: 0.3733 - val_accuracy: 0.8462\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2339 - accuracy: 0.8720 - val_loss: 0.3617 - val_accuracy: 0.8513\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2371 - accuracy: 0.8808 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.3516 - val_accuracy: 0.8462\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2358 - accuracy: 0.8808 - val_loss: 0.3621 - val_accuracy: 0.8564\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.3540 - val_accuracy: 0.8462\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.3561 - val_accuracy: 0.8462\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2347 - accuracy: 0.8874 - val_loss: 0.3620 - val_accuracy: 0.8564\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.3616 - val_accuracy: 0.8359\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.3557 - val_accuracy: 0.8462\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2365 - accuracy: 0.8874 - val_loss: 0.3592 - val_accuracy: 0.8564\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.3565 - val_accuracy: 0.8462\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2343 - accuracy: 0.8764 - val_loss: 0.3679 - val_accuracy: 0.8564\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 0.3580 - val_accuracy: 0.8462\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.3636 - val_accuracy: 0.8359\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.3570 - val_accuracy: 0.8462\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2386 - accuracy: 0.8764 - val_loss: 0.3641 - val_accuracy: 0.8359\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.3596 - val_accuracy: 0.8462\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.3566 - val_accuracy: 0.8564\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2360 - accuracy: 0.8874 - val_loss: 0.3590 - val_accuracy: 0.8462\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2407 - accuracy: 0.8742 - val_loss: 0.3599 - val_accuracy: 0.8462\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 0.3617 - val_accuracy: 0.8462\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.3608 - val_accuracy: 0.8462\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2350 - accuracy: 0.8874 - val_loss: 0.3612 - val_accuracy: 0.8359\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.3622 - val_accuracy: 0.8462\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.3595 - val_accuracy: 0.8462\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2353 - accuracy: 0.8918 - val_loss: 0.3616 - val_accuracy: 0.8462\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.3593 - val_accuracy: 0.8462\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.3632 - val_accuracy: 0.8359\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.3633 - val_accuracy: 0.8462\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2367 - accuracy: 0.8786 - val_loss: 0.3614 - val_accuracy: 0.8359\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2354 - accuracy: 0.8808 - val_loss: 0.3632 - val_accuracy: 0.8462\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.3717 - val_accuracy: 0.8359\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.3605 - val_accuracy: 0.8462\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.3706 - val_accuracy: 0.8564\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.3639 - val_accuracy: 0.8462\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.3637 - val_accuracy: 0.8462\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.3697 - val_accuracy: 0.8462\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.3688 - val_accuracy: 0.8462\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.3652 - val_accuracy: 0.8462\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2319 - accuracy: 0.8918 - val_loss: 0.3678 - val_accuracy: 0.8513\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2455 - accuracy: 0.8786 - val_loss: 0.3710 - val_accuracy: 0.8462\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.3767 - val_accuracy: 0.8410\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 0.3610 - val_accuracy: 0.8513\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.3615 - val_accuracy: 0.8513\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.3672 - val_accuracy: 0.8513\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.3679 - val_accuracy: 0.8410\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 0.3702 - val_accuracy: 0.8615\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 0.3638 - val_accuracy: 0.8513\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.3633 - val_accuracy: 0.8513\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.3644 - val_accuracy: 0.8513\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.3667 - val_accuracy: 0.8513\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.3655 - val_accuracy: 0.8462\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2355 - accuracy: 0.8786 - val_loss: 0.3651 - val_accuracy: 0.8462\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.3644 - val_accuracy: 0.8462\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.3707 - val_accuracy: 0.8462\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.3682 - val_accuracy: 0.8462\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2397 - accuracy: 0.8742 - val_loss: 0.3668 - val_accuracy: 0.8462\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2417 - accuracy: 0.8896 - val_loss: 0.3734 - val_accuracy: 0.8564\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.3669 - val_accuracy: 0.8462\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.3699 - val_accuracy: 0.8462\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2340 - accuracy: 0.8764 - val_loss: 0.3669 - val_accuracy: 0.8410\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.3654 - val_accuracy: 0.8462\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.3677 - val_accuracy: 0.8462\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2360 - accuracy: 0.8764 - val_loss: 0.3714 - val_accuracy: 0.8564\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.3679 - val_accuracy: 0.8462\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.3740 - val_accuracy: 0.8462\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.3723 - val_accuracy: 0.8462\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2354 - accuracy: 0.8874 - val_loss: 0.3711 - val_accuracy: 0.8564\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.3761 - val_accuracy: 0.8359\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.3711 - val_accuracy: 0.8462\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.3780 - val_accuracy: 0.8462\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.3720 - val_accuracy: 0.8462\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.3806 - val_accuracy: 0.8359\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2395 - accuracy: 0.8918 - val_loss: 0.3770 - val_accuracy: 0.8462\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.3766 - val_accuracy: 0.8462\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.3732 - val_accuracy: 0.8513\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.3802 - val_accuracy: 0.8462\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2344 - accuracy: 0.8874 - val_loss: 0.3760 - val_accuracy: 0.8462\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.3752 - val_accuracy: 0.8462\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.3749 - val_accuracy: 0.8462\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.3776 - val_accuracy: 0.8462\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.3781 - val_accuracy: 0.8462\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.3767 - val_accuracy: 0.8462\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.3822 - val_accuracy: 0.8410\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2387 - accuracy: 0.8764 - val_loss: 0.3790 - val_accuracy: 0.8462\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.3813 - val_accuracy: 0.8410\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2358 - accuracy: 0.8786 - val_loss: 0.3807 - val_accuracy: 0.8410\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.3833 - val_accuracy: 0.8462\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 0.3780 - val_accuracy: 0.8513\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.3844 - val_accuracy: 0.8410\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.3842 - val_accuracy: 0.8410\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.3851 - val_accuracy: 0.8513\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.3820 - val_accuracy: 0.8462\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.3828 - val_accuracy: 0.8410\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.3825 - val_accuracy: 0.8410\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.3836 - val_accuracy: 0.8410\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2413 - accuracy: 0.8874 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2346 - accuracy: 0.8874 - val_loss: 0.3858 - val_accuracy: 0.8410\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.3871 - val_accuracy: 0.8410\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.3847 - val_accuracy: 0.8462\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.3835 - val_accuracy: 0.8410\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.3909 - val_accuracy: 0.8410\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.3852 - val_accuracy: 0.8410\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2399 - accuracy: 0.8786 - val_loss: 0.3873 - val_accuracy: 0.8410\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2385 - accuracy: 0.8874 - val_loss: 0.3876 - val_accuracy: 0.8410\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2369 - accuracy: 0.8808 - val_loss: 0.3903 - val_accuracy: 0.8513\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.3848 - val_accuracy: 0.8410\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.3933 - val_accuracy: 0.8308\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.3906 - val_accuracy: 0.8410\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2323 - accuracy: 0.8896 - val_loss: 0.3881 - val_accuracy: 0.8410\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.3884 - val_accuracy: 0.8410\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.3917 - val_accuracy: 0.8410\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2355 - accuracy: 0.8874 - val_loss: 0.3857 - val_accuracy: 0.8410\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2375 - accuracy: 0.8874 - val_loss: 0.3969 - val_accuracy: 0.8410\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.3942 - val_accuracy: 0.8410\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2344 - accuracy: 0.8742 - val_loss: 0.3926 - val_accuracy: 0.8410\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.3918 - val_accuracy: 0.8410\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.3915 - val_accuracy: 0.8410\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.3926 - val_accuracy: 0.8410\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.3908 - val_accuracy: 0.8410\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.3921 - val_accuracy: 0.8410\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.3917 - val_accuracy: 0.8410\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.3987 - val_accuracy: 0.8410\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.3945 - val_accuracy: 0.8410\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2350 - accuracy: 0.8874 - val_loss: 0.3910 - val_accuracy: 0.8410\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.4062 - val_accuracy: 0.8410\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2366 - accuracy: 0.8786 - val_loss: 0.3926 - val_accuracy: 0.8410\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.3967 - val_accuracy: 0.8410\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.3958 - val_accuracy: 0.8410\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2341 - accuracy: 0.8918 - val_loss: 0.3914 - val_accuracy: 0.8410\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2407 - accuracy: 0.8742 - val_loss: 0.4090 - val_accuracy: 0.8410\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.3932 - val_accuracy: 0.8410\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.3945 - val_accuracy: 0.8410\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.3965 - val_accuracy: 0.8410\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.3974 - val_accuracy: 0.8410\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.3943 - val_accuracy: 0.8410\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2405 - accuracy: 0.8786 - val_loss: 0.3887 - val_accuracy: 0.8410\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.3832 - val_accuracy: 0.8513\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2345 - accuracy: 0.8874 - val_loss: 0.3835 - val_accuracy: 0.8564\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.3793 - val_accuracy: 0.8513\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 87us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.3825 - val_accuracy: 0.8513\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.3829 - val_accuracy: 0.8513\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2345 - accuracy: 0.8874 - val_loss: 0.3859 - val_accuracy: 0.8513\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.3835 - val_accuracy: 0.8513\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2307 - accuracy: 0.8830 - val_loss: 0.3842 - val_accuracy: 0.8513\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2339 - accuracy: 0.8808 - val_loss: 0.3886 - val_accuracy: 0.8410\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.3844 - val_accuracy: 0.8513\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.3866 - val_accuracy: 0.8513\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.3860 - val_accuracy: 0.8513\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.3792 - val_accuracy: 0.8564\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2413 - accuracy: 0.8874 - val_loss: 0.4172 - val_accuracy: 0.8359\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2402 - accuracy: 0.8852 - val_loss: 0.3878 - val_accuracy: 0.8513\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.3811 - val_accuracy: 0.8513\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.3822 - val_accuracy: 0.8513\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.3826 - val_accuracy: 0.8513\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.3821 - val_accuracy: 0.8564\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.3852 - val_accuracy: 0.8513\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2344 - accuracy: 0.8874 - val_loss: 0.3834 - val_accuracy: 0.8564\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.3850 - val_accuracy: 0.8513\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.3892 - val_accuracy: 0.8615\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2361 - accuracy: 0.8896 - val_loss: 0.3865 - val_accuracy: 0.8513\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.3908 - val_accuracy: 0.8513\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.3896 - val_accuracy: 0.8564\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.3906 - val_accuracy: 0.8513\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.3906 - val_accuracy: 0.8513\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.3895 - val_accuracy: 0.8513\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2395 - accuracy: 0.8786 - val_loss: 0.3942 - val_accuracy: 0.8513\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.3892 - val_accuracy: 0.8564\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.3897 - val_accuracy: 0.8513\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.3909 - val_accuracy: 0.8513\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.3893 - val_accuracy: 0.8513\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.3898 - val_accuracy: 0.8513\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.3922 - val_accuracy: 0.8513\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.3937 - val_accuracy: 0.8564\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.4009 - val_accuracy: 0.8513\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.3927 - val_accuracy: 0.8513\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.3941 - val_accuracy: 0.8667\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.3908 - val_accuracy: 0.8564\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.3929 - val_accuracy: 0.8513\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.3945 - val_accuracy: 0.8513\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.3901 - val_accuracy: 0.8564\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.3941 - val_accuracy: 0.8513\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.3941 - val_accuracy: 0.8564\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2384 - accuracy: 0.8896 - val_loss: 0.3979 - val_accuracy: 0.8513\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.3934 - val_accuracy: 0.8513\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.3932 - val_accuracy: 0.8513\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.3946 - val_accuracy: 0.8513\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4027 - val_accuracy: 0.8564\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.3965 - val_accuracy: 0.8564\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.3972 - val_accuracy: 0.8564\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.3958 - val_accuracy: 0.8513\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.4001 - val_accuracy: 0.8410\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.3958 - val_accuracy: 0.8564\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.3996 - val_accuracy: 0.8513\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.3984 - val_accuracy: 0.8564\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4020 - val_accuracy: 0.8513\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.4003 - val_accuracy: 0.8564\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.3990 - val_accuracy: 0.8564\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2371 - accuracy: 0.8786 - val_loss: 0.4023 - val_accuracy: 0.8513\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4093 - val_accuracy: 0.8410\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.4002 - val_accuracy: 0.8564\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.4034 - val_accuracy: 0.8513\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.4000 - val_accuracy: 0.8513\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.4014 - val_accuracy: 0.8513\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.4012 - val_accuracy: 0.8513\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4065 - val_accuracy: 0.8410\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.4081 - val_accuracy: 0.8615\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.4031 - val_accuracy: 0.8513\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.4068 - val_accuracy: 0.8410\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4029 - val_accuracy: 0.8513\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.8874 - val_loss: 0.4031 - val_accuracy: 0.8564\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2389 - accuracy: 0.8720 - val_loss: 0.4023 - val_accuracy: 0.8564\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4033 - val_accuracy: 0.8462\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4030 - val_accuracy: 0.8513\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2354 - accuracy: 0.8874 - val_loss: 0.4022 - val_accuracy: 0.8513\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.4093 - val_accuracy: 0.8462\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.4040 - val_accuracy: 0.8513\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.4090 - val_accuracy: 0.8410\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.4029 - val_accuracy: 0.8564\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 0.4150 - val_accuracy: 0.8462\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.4029 - val_accuracy: 0.8564\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4057 - val_accuracy: 0.8513\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.4046 - val_accuracy: 0.8513\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4064 - val_accuracy: 0.8513\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.4037 - val_accuracy: 0.8564\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4017 - val_accuracy: 0.8564\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.4070 - val_accuracy: 0.8513\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.4111 - val_accuracy: 0.8462\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.4078 - val_accuracy: 0.8462\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.4075 - val_accuracy: 0.8513\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.4059 - val_accuracy: 0.8513\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4104 - val_accuracy: 0.8462\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.4048 - val_accuracy: 0.8564\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4091 - val_accuracy: 0.8462\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2388 - accuracy: 0.8874 - val_loss: 0.4082 - val_accuracy: 0.8513\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4077 - val_accuracy: 0.8513\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.4086 - val_accuracy: 0.8513\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2349 - accuracy: 0.8874 - val_loss: 0.4145 - val_accuracy: 0.8462\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.4139 - val_accuracy: 0.8462\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4106 - val_accuracy: 0.8513\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4169 - val_accuracy: 0.8410\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.4096 - val_accuracy: 0.8513\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4182 - val_accuracy: 0.8462\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.90 - 0s 183us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4178 - val_accuracy: 0.8462\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2324 - accuracy: 0.8742 - val_loss: 0.4102 - val_accuracy: 0.8513\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.4131 - val_accuracy: 0.8462\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.4110 - val_accuracy: 0.8513\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.4194 - val_accuracy: 0.8359\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.4131 - val_accuracy: 0.8513\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.4134 - val_accuracy: 0.8513\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4162 - val_accuracy: 0.8462\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4138 - val_accuracy: 0.8462\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.4168 - val_accuracy: 0.8462\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2318 - accuracy: 0.8764 - val_loss: 0.4117 - val_accuracy: 0.8513\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.4135 - val_accuracy: 0.8513\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.4144 - val_accuracy: 0.8462\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.4133 - val_accuracy: 0.8513\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4155 - val_accuracy: 0.8513\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2351 - accuracy: 0.8874 - val_loss: 0.4177 - val_accuracy: 0.8462\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4176 - val_accuracy: 0.8513\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 0.4210 - val_accuracy: 0.8462\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.4172 - val_accuracy: 0.8513\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 362us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.4157 - val_accuracy: 0.8513\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.4155 - val_accuracy: 0.8513\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.4174 - val_accuracy: 0.8513\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4178 - val_accuracy: 0.8513\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.4203 - val_accuracy: 0.8462\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.4176 - val_accuracy: 0.8513\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.4204 - val_accuracy: 0.8462\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.4194 - val_accuracy: 0.8513\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.4219 - val_accuracy: 0.8513\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4207 - val_accuracy: 0.8513\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4220 - val_accuracy: 0.8513\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.4283 - val_accuracy: 0.8359\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.4223 - val_accuracy: 0.8513\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4230 - val_accuracy: 0.8513\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.4243 - val_accuracy: 0.8513\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4240 - val_accuracy: 0.8513\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.4279 - val_accuracy: 0.8462\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.4239 - val_accuracy: 0.8513\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4269 - val_accuracy: 0.8462\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4245 - val_accuracy: 0.8513\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4224 - val_accuracy: 0.8513\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4236 - val_accuracy: 0.8513\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4216 - val_accuracy: 0.8513\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.4255 - val_accuracy: 0.8462\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.4220 - val_accuracy: 0.8513\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4220 - val_accuracy: 0.8513\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4251 - val_accuracy: 0.8462\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2341 - accuracy: 0.8874 - val_loss: 0.4304 - val_accuracy: 0.8410\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2363 - accuracy: 0.8786 - val_loss: 0.4253 - val_accuracy: 0.8462\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.4245 - val_accuracy: 0.8513\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4238 - val_accuracy: 0.8513\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.4252 - val_accuracy: 0.8513\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2352 - accuracy: 0.8808 - val_loss: 0.4250 - val_accuracy: 0.8513\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4253 - val_accuracy: 0.8513\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4274 - val_accuracy: 0.8513\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4300 - val_accuracy: 0.8513\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4253 - val_accuracy: 0.8513\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4250 - val_accuracy: 0.8513\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2335 - accuracy: 0.8896 - val_loss: 0.4293 - val_accuracy: 0.8513\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4282 - val_accuracy: 0.8513\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4290 - val_accuracy: 0.8513\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.4311 - val_accuracy: 0.8513\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.4271 - val_accuracy: 0.8513\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4275 - val_accuracy: 0.8513\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.4335 - val_accuracy: 0.8462\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2309 - accuracy: 0.8786 - val_loss: 0.4317 - val_accuracy: 0.8410\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.4292 - val_accuracy: 0.8513\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.4296 - val_accuracy: 0.8513\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.4311 - val_accuracy: 0.8462\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4308 - val_accuracy: 0.8513\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4322 - val_accuracy: 0.8462\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.4320 - val_accuracy: 0.8513\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2319 - accuracy: 0.8896 - val_loss: 0.4290 - val_accuracy: 0.8513\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.4302 - val_accuracy: 0.8513\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4318 - val_accuracy: 0.8513\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4291 - val_accuracy: 0.8513\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4343 - val_accuracy: 0.8462\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4382 - val_accuracy: 0.8359\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.4381 - val_accuracy: 0.8462\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4334 - val_accuracy: 0.8513\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2345 - accuracy: 0.8874 - val_loss: 0.4330 - val_accuracy: 0.8513\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4353 - val_accuracy: 0.8513\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4338 - val_accuracy: 0.8513\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.4342 - val_accuracy: 0.8513\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4340 - val_accuracy: 0.8513\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.4377 - val_accuracy: 0.8462\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2376 - accuracy: 0.8874 - val_loss: 0.4340 - val_accuracy: 0.8462\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.4365 - val_accuracy: 0.8462\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.4352 - val_accuracy: 0.8462\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.4387 - val_accuracy: 0.8410\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.4358 - val_accuracy: 0.8462\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4408 - val_accuracy: 0.8462\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4443 - val_accuracy: 0.8359\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.4422 - val_accuracy: 0.8462\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4400 - val_accuracy: 0.8410\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4401 - val_accuracy: 0.8513\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4403 - val_accuracy: 0.8462\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4390 - val_accuracy: 0.8513\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2365 - accuracy: 0.8874 - val_loss: 0.4421 - val_accuracy: 0.8462\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4374 - val_accuracy: 0.8513\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4402 - val_accuracy: 0.8462\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4378 - val_accuracy: 0.8513\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4397 - val_accuracy: 0.8462\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2342 - accuracy: 0.8874 - val_loss: 0.4436 - val_accuracy: 0.8462\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2376 - accuracy: 0.8808 - val_loss: 0.4381 - val_accuracy: 0.8462\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4427 - val_accuracy: 0.8410\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.4413 - val_accuracy: 0.8462\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.4414 - val_accuracy: 0.8462\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4407 - val_accuracy: 0.8513\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.4379 - val_accuracy: 0.8462\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4410 - val_accuracy: 0.8462\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.4415 - val_accuracy: 0.8462\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.4410 - val_accuracy: 0.8462\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4420 - val_accuracy: 0.8462\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4443 - val_accuracy: 0.8462\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2371 - accuracy: 0.8874 - val_loss: 0.4437 - val_accuracy: 0.8462\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2335 - accuracy: 0.8874 - val_loss: 0.4453 - val_accuracy: 0.8410\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.4416 - val_accuracy: 0.8462\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 116us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4424 - val_accuracy: 0.8462\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4458 - val_accuracy: 0.8462\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.4514 - val_accuracy: 0.8308\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.4447 - val_accuracy: 0.8462\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.4445 - val_accuracy: 0.8462\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4431 - val_accuracy: 0.8462\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4439 - val_accuracy: 0.8462\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.4465 - val_accuracy: 0.8462\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.4481 - val_accuracy: 0.8462\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.4422 - val_accuracy: 0.8462\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.4461 - val_accuracy: 0.8462\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.4465 - val_accuracy: 0.8462\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.4500 - val_accuracy: 0.8462\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.4487 - val_accuracy: 0.8410\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4473 - val_accuracy: 0.8462\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4487 - val_accuracy: 0.8462\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4474 - val_accuracy: 0.8462\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4520 - val_accuracy: 0.8462\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4470 - val_accuracy: 0.8462\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.4478 - val_accuracy: 0.8462\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.4469 - val_accuracy: 0.8462\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2381 - accuracy: 0.8874 - val_loss: 0.4584 - val_accuracy: 0.8410\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2341 - accuracy: 0.8874 - val_loss: 0.4464 - val_accuracy: 0.8462\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4530 - val_accuracy: 0.8410\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2366 - accuracy: 0.8874 - val_loss: 0.4536 - val_accuracy: 0.8462\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.4515 - val_accuracy: 0.8462\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.4527 - val_accuracy: 0.8462\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4480 - val_accuracy: 0.8462\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.4493 - val_accuracy: 0.8410\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.4530 - val_accuracy: 0.8410\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.4557 - val_accuracy: 0.8462\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4483 - val_accuracy: 0.8462\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4512 - val_accuracy: 0.8462\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4529 - val_accuracy: 0.8462\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.4507 - val_accuracy: 0.8462\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4520 - val_accuracy: 0.8462\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4529 - val_accuracy: 0.8462\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4531 - val_accuracy: 0.8462\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.4522 - val_accuracy: 0.8462\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4509 - val_accuracy: 0.8462\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4552 - val_accuracy: 0.8462\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.4503 - val_accuracy: 0.8462\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.4566 - val_accuracy: 0.8410\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4542 - val_accuracy: 0.8462\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4569 - val_accuracy: 0.8462\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4626 - val_accuracy: 0.8410\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.4571 - val_accuracy: 0.8462\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4619 - val_accuracy: 0.8462\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4586 - val_accuracy: 0.8410\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2335 - accuracy: 0.8874 - val_loss: 0.4575 - val_accuracy: 0.8462\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.4548 - val_accuracy: 0.8462\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4626 - val_accuracy: 0.8410\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.4645 - val_accuracy: 0.8359\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.4589 - val_accuracy: 0.8462\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4593 - val_accuracy: 0.8462\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4588 - val_accuracy: 0.8462\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.4607 - val_accuracy: 0.8462\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4590 - val_accuracy: 0.8462\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4607 - val_accuracy: 0.8462\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.4608 - val_accuracy: 0.8462\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4649 - val_accuracy: 0.8462\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4619 - val_accuracy: 0.8462\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.4626 - val_accuracy: 0.8410\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4601 - val_accuracy: 0.8462\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4622 - val_accuracy: 0.8462\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 0.4696 - val_accuracy: 0.8462\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.4650 - val_accuracy: 0.8462\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.4634 - val_accuracy: 0.8462\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.4657 - val_accuracy: 0.8462\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.4608 - val_accuracy: 0.8462\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.4691 - val_accuracy: 0.8462\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4640 - val_accuracy: 0.8462\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.4647 - val_accuracy: 0.8462\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4650 - val_accuracy: 0.8462\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4646 - val_accuracy: 0.8462\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.4615 - val_accuracy: 0.8462\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2339 - accuracy: 0.8786 - val_loss: 0.4650 - val_accuracy: 0.8359\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.4664 - val_accuracy: 0.8359\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4636 - val_accuracy: 0.8462\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.4672 - val_accuracy: 0.8462\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.4689 - val_accuracy: 0.8462\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2353 - accuracy: 0.8874 - val_loss: 0.4640 - val_accuracy: 0.8462\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.4665 - val_accuracy: 0.8462\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.4666 - val_accuracy: 0.8462\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.4723 - val_accuracy: 0.8462\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.4739 - val_accuracy: 0.8359\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.4656 - val_accuracy: 0.8462\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4680 - val_accuracy: 0.8462\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2344 - accuracy: 0.8874 - val_loss: 0.4676 - val_accuracy: 0.8462\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.4660 - val_accuracy: 0.8462\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.4665 - val_accuracy: 0.8462\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.4728 - val_accuracy: 0.8462\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4687 - val_accuracy: 0.8462\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.4702 - val_accuracy: 0.8462\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4694 - val_accuracy: 0.8462\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.4564 - val_accuracy: 0.8564\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2346 - accuracy: 0.8896 - val_loss: 0.4544 - val_accuracy: 0.8564\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4533 - val_accuracy: 0.8564\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4537 - val_accuracy: 0.8564\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4562 - val_accuracy: 0.8564\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4566 - val_accuracy: 0.8564\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.4572 - val_accuracy: 0.8564\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.4592 - val_accuracy: 0.8513\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.4563 - val_accuracy: 0.8564\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.4562 - val_accuracy: 0.8564\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4620 - val_accuracy: 0.8564\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.4572 - val_accuracy: 0.8564\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4579 - val_accuracy: 0.8564\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 109us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.4577 - val_accuracy: 0.8564\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.4581 - val_accuracy: 0.8564\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.4596 - val_accuracy: 0.8564\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.4583 - val_accuracy: 0.8564\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4597 - val_accuracy: 0.8564\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4596 - val_accuracy: 0.8564\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.4674 - val_accuracy: 0.8462\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.4637 - val_accuracy: 0.8564\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.4608 - val_accuracy: 0.8564\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.4645 - val_accuracy: 0.8513\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4652 - val_accuracy: 0.8564\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.4635 - val_accuracy: 0.8564\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.4667 - val_accuracy: 0.8564\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4657 - val_accuracy: 0.8564\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.4617 - val_accuracy: 0.8564\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.4683 - val_accuracy: 0.8564\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4673 - val_accuracy: 0.8564\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4663 - val_accuracy: 0.8564\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.4669 - val_accuracy: 0.8564\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.4679 - val_accuracy: 0.8513\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2326 - accuracy: 0.8764 - val_loss: 0.4673 - val_accuracy: 0.8564\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.4693 - val_accuracy: 0.8564\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4688 - val_accuracy: 0.8564\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4675 - val_accuracy: 0.8564\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4664 - val_accuracy: 0.8564\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4653 - val_accuracy: 0.8564\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.4694 - val_accuracy: 0.8564\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4630 - val_accuracy: 0.8564\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4654 - val_accuracy: 0.8564\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.4682 - val_accuracy: 0.8564\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4663 - val_accuracy: 0.8564\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.4703 - val_accuracy: 0.8564\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.4679 - val_accuracy: 0.8564\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4689 - val_accuracy: 0.8513\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4688 - val_accuracy: 0.8564\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.4717 - val_accuracy: 0.8564\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.4682 - val_accuracy: 0.8564\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.4714 - val_accuracy: 0.8564\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4735 - val_accuracy: 0.8462\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.4723 - val_accuracy: 0.8564\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2353 - accuracy: 0.8742 - val_loss: 0.4841 - val_accuracy: 0.8667\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2411 - accuracy: 0.8874 - val_loss: 0.4669 - val_accuracy: 0.8513\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4646 - val_accuracy: 0.8564\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4669 - val_accuracy: 0.8564\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.4664 - val_accuracy: 0.8564\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4666 - val_accuracy: 0.8564\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4677 - val_accuracy: 0.8564\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4694 - val_accuracy: 0.8564\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4696 - val_accuracy: 0.8564\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4682 - val_accuracy: 0.8564\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 0.4758 - val_accuracy: 0.8462\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.4698 - val_accuracy: 0.8564\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4727 - val_accuracy: 0.8564\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4674 - val_accuracy: 0.8564\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.4695 - val_accuracy: 0.8564\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4679 - val_accuracy: 0.8564\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4696 - val_accuracy: 0.8564\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.4721 - val_accuracy: 0.8564\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4717 - val_accuracy: 0.8564\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.4712 - val_accuracy: 0.8564\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4735 - val_accuracy: 0.8564\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4773 - val_accuracy: 0.8564\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2348 - accuracy: 0.8764 - val_loss: 0.4720 - val_accuracy: 0.8564\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.4754 - val_accuracy: 0.8564\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.4774 - val_accuracy: 0.8513\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.4776 - val_accuracy: 0.8513\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4773 - val_accuracy: 0.8564\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4774 - val_accuracy: 0.8564\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4788 - val_accuracy: 0.8564\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4794 - val_accuracy: 0.8564\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4771 - val_accuracy: 0.8564\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.4810 - val_accuracy: 0.8462\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4775 - val_accuracy: 0.8564\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.4792 - val_accuracy: 0.8462\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.4785 - val_accuracy: 0.8564\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4758 - val_accuracy: 0.8564\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.4767 - val_accuracy: 0.8564\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4791 - val_accuracy: 0.8564\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4772 - val_accuracy: 0.8564\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.4789 - val_accuracy: 0.8564\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.4820 - val_accuracy: 0.8564\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4796 - val_accuracy: 0.8564\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 1.00 - 0s 107us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4804 - val_accuracy: 0.8564\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4801 - val_accuracy: 0.8564\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.4787 - val_accuracy: 0.8564\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.4798 - val_accuracy: 0.8564\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4799 - val_accuracy: 0.8564\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.4835 - val_accuracy: 0.8564\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.4830 - val_accuracy: 0.8564\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4824 - val_accuracy: 0.8564\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.4822 - val_accuracy: 0.8564\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4842 - val_accuracy: 0.8564\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4859 - val_accuracy: 0.8564\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.4827 - val_accuracy: 0.8564\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2363 - accuracy: 0.8874 - val_loss: 0.4879 - val_accuracy: 0.8513\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.4856 - val_accuracy: 0.8564\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2412 - accuracy: 0.8874 - val_loss: 0.4830 - val_accuracy: 0.8564\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4862 - val_accuracy: 0.8462\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.4904 - val_accuracy: 0.8513\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.4847 - val_accuracy: 0.8564\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2353 - accuracy: 0.8874 - val_loss: 0.4880 - val_accuracy: 0.8513\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.4877 - val_accuracy: 0.8564\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.4845 - val_accuracy: 0.8564\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4889 - val_accuracy: 0.8513\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4880 - val_accuracy: 0.8513\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.4875 - val_accuracy: 0.8564\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4853 - val_accuracy: 0.8564\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4874 - val_accuracy: 0.8513\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.4879 - val_accuracy: 0.8513\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4836 - val_accuracy: 0.8564\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4860 - val_accuracy: 0.8513\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4916 - val_accuracy: 0.8513\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.4898 - val_accuracy: 0.8564\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4860 - val_accuracy: 0.8564\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.4890 - val_accuracy: 0.8513\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4884 - val_accuracy: 0.8564\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.4897 - val_accuracy: 0.8564\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4879 - val_accuracy: 0.8513\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2348 - accuracy: 0.8874 - val_loss: 0.4896 - val_accuracy: 0.8513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36f6c320>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 56us/step\n",
      "over-sampling test accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 0, 0,\n",
       "       2, 1, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 2, 0,\n",
       "       2, 0, 0, 2, 2, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2,\n",
       "       1, 0, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 1, 2, 1, 1,\n",
       "       2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 1, 2, 0, 2, 2, 0, 0, 2,\n",
       "       0, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2, 1, 2, 1, 0, 2, 1, 2, 1, 1,\n",
       "       1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 2, 2, 1, 0, 2,\n",
       "       1, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS110     2     2\n",
       "1       NRS254     1     1\n",
       "2    BCH-SA-09     0     0\n",
       "3       NRS177     0     1\n",
       "4         GA27     1     1\n",
       "..         ...   ...   ...\n",
       "190     NRS001     1     0\n",
       "191     NRS209     2     2\n",
       "192     NRS272     0     0\n",
       "193     NRS110     2     2\n",
       "194     NRS204     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.240305e-11</td>\n",
       "      <td>3.785083e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.868346e-30</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.587276e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.095264e-01</td>\n",
       "      <td>1.904736e-01</td>\n",
       "      <td>5.845330e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.929480e-02</td>\n",
       "      <td>9.707052e-01</td>\n",
       "      <td>1.982460e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.331409e-01</td>\n",
       "      <td>7.668591e-01</td>\n",
       "      <td>1.356124e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>5.476567e-01</td>\n",
       "      <td>4.523419e-01</td>\n",
       "      <td>1.395371e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.173925e-08</td>\n",
       "      <td>7.917819e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.999931e-01</td>\n",
       "      <td>9.342754e-07</td>\n",
       "      <td>5.903541e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2.240305e-11</td>\n",
       "      <td>3.785083e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8.095264e-01</td>\n",
       "      <td>1.904736e-01</td>\n",
       "      <td>5.845330e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    2.240305e-11  3.785083e-08  1.000000e+00\n",
       "1    1.868346e-30  1.000000e+00  1.587276e-25\n",
       "2    8.095264e-01  1.904736e-01  5.845330e-09\n",
       "3    2.929480e-02  9.707052e-01  1.982460e-08\n",
       "4    2.331409e-01  7.668591e-01  1.356124e-07\n",
       "..            ...           ...           ...\n",
       "190  5.476567e-01  4.523419e-01  1.395371e-06\n",
       "191  1.173925e-08  7.917819e-09  1.000000e+00\n",
       "192  9.999931e-01  9.342754e-07  5.903541e-06\n",
       "193  2.240305e-11  3.785083e-08  1.000000e+00\n",
       "194  8.095264e-01  1.904736e-01  5.845330e-09\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4641 - val_accuracy: 0.8462\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.4648 - val_accuracy: 0.8462\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2337 - accuracy: 0.8896 - val_loss: 0.4610 - val_accuracy: 0.8410\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2421 - accuracy: 0.8786 - val_loss: 0.4594 - val_accuracy: 0.8462\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4639 - val_accuracy: 0.8462\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.4649 - val_accuracy: 0.8462\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.4650 - val_accuracy: 0.8462\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4656 - val_accuracy: 0.8462\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4632 - val_accuracy: 0.8410\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.4663 - val_accuracy: 0.8462\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.4654 - val_accuracy: 0.8462\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4655 - val_accuracy: 0.8462\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.4657 - val_accuracy: 0.8462\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.4655 - val_accuracy: 0.8462\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4678 - val_accuracy: 0.8462\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.4650 - val_accuracy: 0.8359\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.4695 - val_accuracy: 0.8410\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.4692 - val_accuracy: 0.8410\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4666 - val_accuracy: 0.8410\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.4676 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4653 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.4704 - val_accuracy: 0.8410\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4672 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4670 - val_accuracy: 0.8410\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.4700 - val_accuracy: 0.8410\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4683 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.4735 - val_accuracy: 0.8410\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4695 - val_accuracy: 0.8410\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2354 - accuracy: 0.8808 - val_loss: 0.4703 - val_accuracy: 0.8308\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 578us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4705 - val_accuracy: 0.8410\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4701 - val_accuracy: 0.8410\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.4671 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 381us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4707 - val_accuracy: 0.8410\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.4708 - val_accuracy: 0.8410\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4712 - val_accuracy: 0.8410\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.4707 - val_accuracy: 0.8410\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4714 - val_accuracy: 0.8410\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.4725 - val_accuracy: 0.8410\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4751 - val_accuracy: 0.8410\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.4744 - val_accuracy: 0.8410\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4775 - val_accuracy: 0.8410\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.4732 - val_accuracy: 0.8462\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4719 - val_accuracy: 0.8410\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.4734 - val_accuracy: 0.8410\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.4768 - val_accuracy: 0.8410\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2391 - accuracy: 0.8874 - val_loss: 0.4747 - val_accuracy: 0.8462\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4747 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.4751 - val_accuracy: 0.8462\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4713 - val_accuracy: 0.8462\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4740 - val_accuracy: 0.8462\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4774 - val_accuracy: 0.8410\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.4723 - val_accuracy: 0.8410\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.4720 - val_accuracy: 0.8462\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.4737 - val_accuracy: 0.8410\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.4747 - val_accuracy: 0.8410\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4778 - val_accuracy: 0.8410\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.4800 - val_accuracy: 0.8410\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4739 - val_accuracy: 0.8462\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.4735 - val_accuracy: 0.8462\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.4787 - val_accuracy: 0.8410\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4781 - val_accuracy: 0.8410\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.4786 - val_accuracy: 0.8410\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4751 - val_accuracy: 0.8410\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.4752 - val_accuracy: 0.8410\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.4770 - val_accuracy: 0.8410\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4774 - val_accuracy: 0.8410\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 386us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.4759 - val_accuracy: 0.8410\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.4739 - val_accuracy: 0.8359\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.4747 - val_accuracy: 0.8410\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4773 - val_accuracy: 0.8410\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4781 - val_accuracy: 0.8410\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4761 - val_accuracy: 0.8410\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4759 - val_accuracy: 0.8462\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.4791 - val_accuracy: 0.8410\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4790 - val_accuracy: 0.8410\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4807 - val_accuracy: 0.8410\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.4790 - val_accuracy: 0.8410\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4759 - val_accuracy: 0.8410\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.4817 - val_accuracy: 0.8410\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.4788 - val_accuracy: 0.8410\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4844 - val_accuracy: 0.8410\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.4796 - val_accuracy: 0.8462\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4851 - val_accuracy: 0.8410\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2276 - accuracy: 0.8852 - val_loss: 0.4790 - val_accuracy: 0.8462\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.4769 - val_accuracy: 0.8462\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 0.4802 - val_accuracy: 0.8410\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 548us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.4819 - val_accuracy: 0.8462\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.4789 - val_accuracy: 0.8410\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.4798 - val_accuracy: 0.8410\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4778 - val_accuracy: 0.8462\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4805 - val_accuracy: 0.8410\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.4800 - val_accuracy: 0.8410\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.4822 - val_accuracy: 0.8410\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4800 - val_accuracy: 0.8410\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4811 - val_accuracy: 0.8410\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.4815 - val_accuracy: 0.8410\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.4821 - val_accuracy: 0.8410\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.4818 - val_accuracy: 0.8410\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.4880 - val_accuracy: 0.8410\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4837 - val_accuracy: 0.8410\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2307 - accuracy: 0.8786 - val_loss: 0.4824 - val_accuracy: 0.8410\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4835 - val_accuracy: 0.8410\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.4782 - val_accuracy: 0.8462\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2374 - accuracy: 0.8764 - val_loss: 0.4831 - val_accuracy: 0.8462\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.4825 - val_accuracy: 0.8410\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4811 - val_accuracy: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.4835 - val_accuracy: 0.8359\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.4770 - val_accuracy: 0.8564\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2293 - accuracy: 0.8896 - val_loss: 0.4822 - val_accuracy: 0.8410\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.4833 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4861 - val_accuracy: 0.8410\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.4848 - val_accuracy: 0.8410\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.4841 - val_accuracy: 0.8462\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2286 - accuracy: 0.8786 - val_loss: 0.4846 - val_accuracy: 0.8410\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4868 - val_accuracy: 0.8410\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4840 - val_accuracy: 0.8462\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4864 - val_accuracy: 0.8410\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.4834 - val_accuracy: 0.8410\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4846 - val_accuracy: 0.8410\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.4828 - val_accuracy: 0.8410\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4906 - val_accuracy: 0.8462\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.4851 - val_accuracy: 0.8410\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4889 - val_accuracy: 0.8410\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4885 - val_accuracy: 0.8410\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.4858 - val_accuracy: 0.8410\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4839 - val_accuracy: 0.8410\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.4834 - val_accuracy: 0.8308\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4860 - val_accuracy: 0.8410\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4847 - val_accuracy: 0.8410\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.4880 - val_accuracy: 0.8410\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.4870 - val_accuracy: 0.8410\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.4863 - val_accuracy: 0.8462\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.4853 - val_accuracy: 0.8462\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4843 - val_accuracy: 0.8410\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4899 - val_accuracy: 0.8410\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4876 - val_accuracy: 0.8410\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.4843 - val_accuracy: 0.8462\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4860 - val_accuracy: 0.8462\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2325 - accuracy: 0.8874 - val_loss: 0.4862 - val_accuracy: 0.8462\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4869 - val_accuracy: 0.8410\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.4876 - val_accuracy: 0.8410\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.4882 - val_accuracy: 0.8410\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.4907 - val_accuracy: 0.8410\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.4921 - val_accuracy: 0.8410\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 457us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.4884 - val_accuracy: 0.8462\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 353us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.4873 - val_accuracy: 0.8410\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 397us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.4844 - val_accuracy: 0.8462\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 338us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.4871 - val_accuracy: 0.8410\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.4874 - val_accuracy: 0.8462\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4886 - val_accuracy: 0.8410\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4903 - val_accuracy: 0.8410\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4901 - val_accuracy: 0.8462\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 348us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.4903 - val_accuracy: 0.8462\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4899 - val_accuracy: 0.8410\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.4892 - val_accuracy: 0.8410\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4881 - val_accuracy: 0.8462\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.4866 - val_accuracy: 0.8462\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.4893 - val_accuracy: 0.8359\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.4923 - val_accuracy: 0.8462\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.4905 - val_accuracy: 0.8462\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4911 - val_accuracy: 0.8410\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.4883 - val_accuracy: 0.8308\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2286 - accuracy: 0.8896 - val_loss: 0.4941 - val_accuracy: 0.8410\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.4948 - val_accuracy: 0.8410\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.4896 - val_accuracy: 0.8410\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.4863 - val_accuracy: 0.8462\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.4888 - val_accuracy: 0.8462\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4939 - val_accuracy: 0.8410\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4915 - val_accuracy: 0.8410\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4916 - val_accuracy: 0.8462\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4958 - val_accuracy: 0.8410\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.4922 - val_accuracy: 0.8410\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.4929 - val_accuracy: 0.8308\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4912 - val_accuracy: 0.8462\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4970 - val_accuracy: 0.8410\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.4911 - val_accuracy: 0.8462\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.4944 - val_accuracy: 0.8462\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.4915 - val_accuracy: 0.8462\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5011 - val_accuracy: 0.8462\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4956 - val_accuracy: 0.8462\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.4894 - val_accuracy: 0.8462\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4951 - val_accuracy: 0.8462\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4904 - val_accuracy: 0.8462\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4891 - val_accuracy: 0.8462\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.4950 - val_accuracy: 0.8462\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.4920 - val_accuracy: 0.8462\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4896 - val_accuracy: 0.8462\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4969 - val_accuracy: 0.8462\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.4942 - val_accuracy: 0.8462\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.4963 - val_accuracy: 0.8462\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.4898 - val_accuracy: 0.8462\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.4934 - val_accuracy: 0.8462\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.4940 - val_accuracy: 0.8462\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.4931 - val_accuracy: 0.8462\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.4884 - val_accuracy: 0.8462\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.4946 - val_accuracy: 0.8462\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.4970 - val_accuracy: 0.8410\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.4941 - val_accuracy: 0.8462\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.4943 - val_accuracy: 0.8462\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4952 - val_accuracy: 0.8462\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.4954 - val_accuracy: 0.8462\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.4995 - val_accuracy: 0.8462\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.4981 - val_accuracy: 0.8410\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4976 - val_accuracy: 0.8462\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4941 - val_accuracy: 0.8462\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.4949 - val_accuracy: 0.8462\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.4950 - val_accuracy: 0.8462\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2382 - accuracy: 0.8874 - val_loss: 0.5051 - val_accuracy: 0.8462\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.4918 - val_accuracy: 0.8462\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.4936 - val_accuracy: 0.8462\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4944 - val_accuracy: 0.8462\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.4971 - val_accuracy: 0.8462\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.4968 - val_accuracy: 0.8462\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.4957 - val_accuracy: 0.8462\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.4987 - val_accuracy: 0.8462\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.4966 - val_accuracy: 0.8462\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.4995 - val_accuracy: 0.8462\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4998 - val_accuracy: 0.8462\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5003 - val_accuracy: 0.8462\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.4985 - val_accuracy: 0.8462\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5003 - val_accuracy: 0.8462\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.5001 - val_accuracy: 0.8462\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.4999 - val_accuracy: 0.8462\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.87 - 0s 106us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5024 - val_accuracy: 0.8462\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.4978 - val_accuracy: 0.8513\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.5051 - val_accuracy: 0.8462\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5004 - val_accuracy: 0.8462\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5006 - val_accuracy: 0.8462\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.5082 - val_accuracy: 0.8462\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5021 - val_accuracy: 0.8462\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5057 - val_accuracy: 0.8359\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5017 - val_accuracy: 0.8462\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2285 - accuracy: 0.8896 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.5039 - val_accuracy: 0.8462\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.5017 - val_accuracy: 0.8462\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.5031 - val_accuracy: 0.8462\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.5014 - val_accuracy: 0.8462\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5063 - val_accuracy: 0.8462\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5010 - val_accuracy: 0.8462\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.5018 - val_accuracy: 0.8513\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.4975 - val_accuracy: 0.8462\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.5005 - val_accuracy: 0.8462\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5034 - val_accuracy: 0.8462\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.5030 - val_accuracy: 0.8462\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5058 - val_accuracy: 0.8462\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5060 - val_accuracy: 0.8462\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5073 - val_accuracy: 0.8462\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5045 - val_accuracy: 0.8462\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5083 - val_accuracy: 0.8462\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5047 - val_accuracy: 0.8462\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.5063 - val_accuracy: 0.8462\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8852 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5100 - val_accuracy: 0.8462\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.5056 - val_accuracy: 0.8462\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5064 - val_accuracy: 0.8462\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5105 - val_accuracy: 0.8462\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.5110 - val_accuracy: 0.8359\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5139 - val_accuracy: 0.8462\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.5078 - val_accuracy: 0.8462\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5097 - val_accuracy: 0.8462\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.5037 - val_accuracy: 0.8513\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.4960 - val_accuracy: 0.8564\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.4980 - val_accuracy: 0.8513\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.5054 - val_accuracy: 0.8513\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5076 - val_accuracy: 0.8513\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.5083 - val_accuracy: 0.8462\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.5101 - val_accuracy: 0.8462\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.5178 - val_accuracy: 0.8462\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.5120 - val_accuracy: 0.8462\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5131 - val_accuracy: 0.8462\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5146 - val_accuracy: 0.8462\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.5100 - val_accuracy: 0.8462\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.5133 - val_accuracy: 0.8462\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.5172 - val_accuracy: 0.8462\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.5089 - val_accuracy: 0.8462\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5128 - val_accuracy: 0.8359\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5153 - val_accuracy: 0.8462\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 200us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.5085 - val_accuracy: 0.8359\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8462\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5119 - val_accuracy: 0.8462\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.5083 - val_accuracy: 0.8462\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.5079 - val_accuracy: 0.8462\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.5139 - val_accuracy: 0.8462\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5138 - val_accuracy: 0.8462\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5077 - val_accuracy: 0.8462\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5101 - val_accuracy: 0.8462\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5130 - val_accuracy: 0.8462\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.5120 - val_accuracy: 0.8462\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.5102 - val_accuracy: 0.8359\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5171 - val_accuracy: 0.8462\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.5138 - val_accuracy: 0.8359\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.5192 - val_accuracy: 0.8462\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.5102 - val_accuracy: 0.8462\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.5134 - val_accuracy: 0.8462\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5181 - val_accuracy: 0.8462\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5155 - val_accuracy: 0.8462\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.5174 - val_accuracy: 0.8462\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.5157 - val_accuracy: 0.8462\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5124 - val_accuracy: 0.8462\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5178 - val_accuracy: 0.8462\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5094 - val_accuracy: 0.8462\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.5134 - val_accuracy: 0.8462\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.5143 - val_accuracy: 0.8462\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5166 - val_accuracy: 0.8462\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5128 - val_accuracy: 0.8462\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5183 - val_accuracy: 0.8462\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 0.5168 - val_accuracy: 0.8462\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.5164 - val_accuracy: 0.8359\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.5113 - val_accuracy: 0.8462\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5152 - val_accuracy: 0.8462\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5221 - val_accuracy: 0.8462\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.5163 - val_accuracy: 0.8462\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5125 - val_accuracy: 0.8462\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2321 - accuracy: 0.8764 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5155 - val_accuracy: 0.8462\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5169 - val_accuracy: 0.8462\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5218 - val_accuracy: 0.8462\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 421us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.5174 - val_accuracy: 0.8462\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5205 - val_accuracy: 0.8462\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5094 - val_accuracy: 0.8564\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.5106 - val_accuracy: 0.8513\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8462\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5182 - val_accuracy: 0.8462\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5206 - val_accuracy: 0.8462\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 317us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.5235 - val_accuracy: 0.8462\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.5239 - val_accuracy: 0.8462\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5239 - val_accuracy: 0.8462\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5254 - val_accuracy: 0.8462\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.5265 - val_accuracy: 0.8359\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.5262 - val_accuracy: 0.8462\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5263 - val_accuracy: 0.8462\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5230 - val_accuracy: 0.8462\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.5189 - val_accuracy: 0.8462\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5160 - val_accuracy: 0.8462\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5170 - val_accuracy: 0.8462\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.5227 - val_accuracy: 0.8462\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.5259 - val_accuracy: 0.8462\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5252 - val_accuracy: 0.8462\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.5257 - val_accuracy: 0.8462\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5260 - val_accuracy: 0.8462\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.5266 - val_accuracy: 0.8462\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5262 - val_accuracy: 0.8462\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5242 - val_accuracy: 0.8462\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.5254 - val_accuracy: 0.8462\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5263 - val_accuracy: 0.8462\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.5277 - val_accuracy: 0.8462\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.5157 - val_accuracy: 0.8359\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.5177 - val_accuracy: 0.8462\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.5205 - val_accuracy: 0.8359\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5234 - val_accuracy: 0.8462\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5241 - val_accuracy: 0.8462\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.5252 - val_accuracy: 0.8462\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.5052 - val_accuracy: 0.8564\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.5077 - val_accuracy: 0.8667\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.5054 - val_accuracy: 0.8667\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.5092 - val_accuracy: 0.8564\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5100 - val_accuracy: 0.8564\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.5070 - val_accuracy: 0.8564\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.5051 - val_accuracy: 0.8564\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 191us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5092 - val_accuracy: 0.8564\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5061 - val_accuracy: 0.8564\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5076 - val_accuracy: 0.8564\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5073 - val_accuracy: 0.8564\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5100 - val_accuracy: 0.8564\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5072 - val_accuracy: 0.8564\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5079 - val_accuracy: 0.8564\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5092 - val_accuracy: 0.8564\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5078 - val_accuracy: 0.8564\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5112 - val_accuracy: 0.8564\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5095 - val_accuracy: 0.8564\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5092 - val_accuracy: 0.8564\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.5100 - val_accuracy: 0.8564\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.5072 - val_accuracy: 0.8564\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8564\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5098 - val_accuracy: 0.8564\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5129 - val_accuracy: 0.8564\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.5104 - val_accuracy: 0.8564\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5121 - val_accuracy: 0.8564\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.5159 - val_accuracy: 0.8564\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5111 - val_accuracy: 0.8564\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5143 - val_accuracy: 0.8564\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5144 - val_accuracy: 0.8564\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5119 - val_accuracy: 0.8564\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5111 - val_accuracy: 0.8564\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5112 - val_accuracy: 0.8564\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.5106 - val_accuracy: 0.8462\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.5102 - val_accuracy: 0.8564\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2369 - accuracy: 0.8720 - val_loss: 0.5094 - val_accuracy: 0.8667\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.5121 - val_accuracy: 0.8564\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5078 - val_accuracy: 0.8564\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.5100 - val_accuracy: 0.8564\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.5121 - val_accuracy: 0.8564\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.5076 - val_accuracy: 0.8564\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5097 - val_accuracy: 0.8564\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5095 - val_accuracy: 0.8564\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5118 - val_accuracy: 0.8564\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5143 - val_accuracy: 0.8564\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.5040 - val_accuracy: 0.8667\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.5099 - val_accuracy: 0.8564\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.5113 - val_accuracy: 0.8564\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.5127 - val_accuracy: 0.8564\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8564\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.5065 - val_accuracy: 0.8564\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5105 - val_accuracy: 0.8564\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.5068 - val_accuracy: 0.8564\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5089 - val_accuracy: 0.8564\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.5148 - val_accuracy: 0.8564\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.5126 - val_accuracy: 0.8564\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.5112 - val_accuracy: 0.8564\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5119 - val_accuracy: 0.8564\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5120 - val_accuracy: 0.8564\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5079 - val_accuracy: 0.8564\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.5127 - val_accuracy: 0.8564\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5127 - val_accuracy: 0.8564\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5101 - val_accuracy: 0.8564\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5136 - val_accuracy: 0.8564\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.5124 - val_accuracy: 0.8564\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2263 - accuracy: 0.8874 - val_loss: 0.5125 - val_accuracy: 0.8564\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5120 - val_accuracy: 0.8564\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5141 - val_accuracy: 0.8564\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.5153 - val_accuracy: 0.8564\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.5082 - val_accuracy: 0.8564\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5125 - val_accuracy: 0.8564\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5102 - val_accuracy: 0.8564\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.5147 - val_accuracy: 0.8564\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.5148 - val_accuracy: 0.8564\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5112 - val_accuracy: 0.8564\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5124 - val_accuracy: 0.8564\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5117 - val_accuracy: 0.8564\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5155 - val_accuracy: 0.8564\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.5079 - val_accuracy: 0.8564\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.5112 - val_accuracy: 0.8564\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5205 - val_accuracy: 0.8564\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.5159 - val_accuracy: 0.8564\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.5143 - val_accuracy: 0.8564\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.5129 - val_accuracy: 0.8564\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5144 - val_accuracy: 0.8564\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.5109 - val_accuracy: 0.8564\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.5093 - val_accuracy: 0.8564\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5098 - val_accuracy: 0.8564\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.5122 - val_accuracy: 0.8564\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5094 - val_accuracy: 0.8564\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5092 - val_accuracy: 0.8564\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5111 - val_accuracy: 0.8564\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5140 - val_accuracy: 0.8564\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.5107 - val_accuracy: 0.8564\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5128 - val_accuracy: 0.8564\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5113 - val_accuracy: 0.8564\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5127 - val_accuracy: 0.8564\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5125 - val_accuracy: 0.8462\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.5090 - val_accuracy: 0.8564\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 363us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.5102 - val_accuracy: 0.8564\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5091 - val_accuracy: 0.8564\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5099 - val_accuracy: 0.8462\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.5101 - val_accuracy: 0.8564\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 178us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5098 - val_accuracy: 0.8564\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5067 - val_accuracy: 0.8564\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 452us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5085 - val_accuracy: 0.8564\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5081 - val_accuracy: 0.8564\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5088 - val_accuracy: 0.8564\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5102 - val_accuracy: 0.8564\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2307 - accuracy: 0.8830 - val_loss: 0.5111 - val_accuracy: 0.8564\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.5098 - val_accuracy: 0.8564\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5113 - val_accuracy: 0.8564\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5083 - val_accuracy: 0.8564\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5140 - val_accuracy: 0.8462\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.5117 - val_accuracy: 0.8564\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.5093 - val_accuracy: 0.8564\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5137 - val_accuracy: 0.8564\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5116 - val_accuracy: 0.8564\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 380us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.5110 - val_accuracy: 0.8564\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5084 - val_accuracy: 0.8564\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5097 - val_accuracy: 0.8564\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5108 - val_accuracy: 0.8564\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.5078 - val_accuracy: 0.8564\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5095 - val_accuracy: 0.8564\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5084 - val_accuracy: 0.8564\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.5078 - val_accuracy: 0.8564\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5125 - val_accuracy: 0.8564\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.5178 - val_accuracy: 0.8462\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.5109 - val_accuracy: 0.8564\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5151 - val_accuracy: 0.8564\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5124 - val_accuracy: 0.8564\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2292 - accuracy: 0.8896 - val_loss: 0.5146 - val_accuracy: 0.8564\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5134 - val_accuracy: 0.8564\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5135 - val_accuracy: 0.8564\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5126 - val_accuracy: 0.8564\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5142 - val_accuracy: 0.8564\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8564\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5145 - val_accuracy: 0.8564\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8564\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.5140 - val_accuracy: 0.8564\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5156 - val_accuracy: 0.8564\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5129 - val_accuracy: 0.8564\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5149 - val_accuracy: 0.8564\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.5191 - val_accuracy: 0.8564\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5155 - val_accuracy: 0.8564\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.5154 - val_accuracy: 0.8462\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5131 - val_accuracy: 0.8564\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.5200 - val_accuracy: 0.8564\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5181 - val_accuracy: 0.8564\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5166 - val_accuracy: 0.8564\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.5201 - val_accuracy: 0.8462\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.5162 - val_accuracy: 0.8564\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5184 - val_accuracy: 0.8564\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.5163 - val_accuracy: 0.8564\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5162 - val_accuracy: 0.8564\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5174 - val_accuracy: 0.8564\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5188 - val_accuracy: 0.8564\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5172 - val_accuracy: 0.8564\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.5190 - val_accuracy: 0.8564\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5192 - val_accuracy: 0.8564\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5202 - val_accuracy: 0.8564\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5243 - val_accuracy: 0.8564\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 334us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5219 - val_accuracy: 0.8564\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 392us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5190 - val_accuracy: 0.8564\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 326us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.5189 - val_accuracy: 0.8564\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5219 - val_accuracy: 0.8564\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.5233 - val_accuracy: 0.8462\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.5201 - val_accuracy: 0.8564\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.5221 - val_accuracy: 0.8564\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5212 - val_accuracy: 0.8564\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5203 - val_accuracy: 0.8564\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5229 - val_accuracy: 0.8564\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5210 - val_accuracy: 0.8564\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5236 - val_accuracy: 0.8564\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.5241 - val_accuracy: 0.8462\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5225 - val_accuracy: 0.8564\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5249 - val_accuracy: 0.8564\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.5204 - val_accuracy: 0.8564\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5237 - val_accuracy: 0.8564\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5233 - val_accuracy: 0.8564\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.5227 - val_accuracy: 0.8564\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5261 - val_accuracy: 0.8564\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5226 - val_accuracy: 0.8564\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5227 - val_accuracy: 0.8564\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5242 - val_accuracy: 0.8564\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2292 - accuracy: 0.8896 - val_loss: 0.5257 - val_accuracy: 0.8564\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5289 - val_accuracy: 0.8564\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5246 - val_accuracy: 0.8564\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5265 - val_accuracy: 0.8564\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.5308 - val_accuracy: 0.8564\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5260 - val_accuracy: 0.8564\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5274 - val_accuracy: 0.8564\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5270 - val_accuracy: 0.8564\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5259 - val_accuracy: 0.8564\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5259 - val_accuracy: 0.8564\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2287 - accuracy: 0.8808 - val_loss: 0.5277 - val_accuracy: 0.8564\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5284 - val_accuracy: 0.8564\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.5256 - val_accuracy: 0.8564\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5271 - val_accuracy: 0.8564\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5285 - val_accuracy: 0.8564\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5264 - val_accuracy: 0.8564\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.5265 - val_accuracy: 0.8564\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5260 - val_accuracy: 0.8564\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5276 - val_accuracy: 0.8564\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.5292 - val_accuracy: 0.8564\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.5292 - val_accuracy: 0.8564\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5281 - val_accuracy: 0.8564\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5289 - val_accuracy: 0.8564\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5341 - val_accuracy: 0.8564\n",
      "Epoch 662/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5289 - val_accuracy: 0.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.5282 - val_accuracy: 0.8564\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5317 - val_accuracy: 0.8564\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2264 - accuracy: 0.8874 - val_loss: 0.5284 - val_accuracy: 0.8564\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5270 - val_accuracy: 0.8564\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5302 - val_accuracy: 0.8564\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5327 - val_accuracy: 0.8564\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.5295 - val_accuracy: 0.8564\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.5348 - val_accuracy: 0.8564\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5322 - val_accuracy: 0.8564\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5339 - val_accuracy: 0.8564\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5373 - val_accuracy: 0.8564\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.5340 - val_accuracy: 0.8564\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5358 - val_accuracy: 0.8564\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5337 - val_accuracy: 0.8564\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2261 - accuracy: 0.8874 - val_loss: 0.5346 - val_accuracy: 0.8564\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5346 - val_accuracy: 0.8564\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5369 - val_accuracy: 0.8564\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5370 - val_accuracy: 0.8564\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5368 - val_accuracy: 0.8564\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5361 - val_accuracy: 0.8564\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.5371 - val_accuracy: 0.8564\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5370 - val_accuracy: 0.8564\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.5378 - val_accuracy: 0.8462\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.5358 - val_accuracy: 0.8564\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5373 - val_accuracy: 0.8564\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.5377 - val_accuracy: 0.8564\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.5399 - val_accuracy: 0.8564\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5365 - val_accuracy: 0.8564\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.5352 - val_accuracy: 0.8564\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.5352 - val_accuracy: 0.8564\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.5319 - val_accuracy: 0.8564\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5245 - val_accuracy: 0.8564\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.5281 - val_accuracy: 0.8564\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5285 - val_accuracy: 0.8564\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.5298 - val_accuracy: 0.8564\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5291 - val_accuracy: 0.8564\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5340 - val_accuracy: 0.8564\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5302 - val_accuracy: 0.8564\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.5290 - val_accuracy: 0.8564\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.5287 - val_accuracy: 0.8564\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5283 - val_accuracy: 0.8564\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.5276 - val_accuracy: 0.8564\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.5309 - val_accuracy: 0.8564\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5272 - val_accuracy: 0.8564\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5302 - val_accuracy: 0.8564\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2274 - accuracy: 0.8808 - val_loss: 0.5302 - val_accuracy: 0.8462\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5312 - val_accuracy: 0.8564\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5290 - val_accuracy: 0.8564\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5312 - val_accuracy: 0.8462\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.5283 - val_accuracy: 0.8564\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5295 - val_accuracy: 0.8564\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5300 - val_accuracy: 0.8564\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.5311 - val_accuracy: 0.8564\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5318 - val_accuracy: 0.8564\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5302 - val_accuracy: 0.8564\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.5296 - val_accuracy: 0.8564\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5327 - val_accuracy: 0.8564\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.5327 - val_accuracy: 0.8564\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.5333 - val_accuracy: 0.8564\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5334 - val_accuracy: 0.8564\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5356 - val_accuracy: 0.8564\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5329 - val_accuracy: 0.8564\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.5331 - val_accuracy: 0.8564\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.5335 - val_accuracy: 0.8667\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2280 - accuracy: 0.8852 - val_loss: 0.5324 - val_accuracy: 0.8564\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5332 - val_accuracy: 0.8564\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5338 - val_accuracy: 0.8564\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5336 - val_accuracy: 0.8564\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.5359 - val_accuracy: 0.8564\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5354 - val_accuracy: 0.8564\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.5371 - val_accuracy: 0.8564\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5356 - val_accuracy: 0.8564\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5366 - val_accuracy: 0.8564\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.5364 - val_accuracy: 0.8564\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5379 - val_accuracy: 0.8564\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5371 - val_accuracy: 0.8564\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5429 - val_accuracy: 0.8564\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5389 - val_accuracy: 0.8564\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5383 - val_accuracy: 0.8564\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5352 - val_accuracy: 0.8564\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5337 - val_accuracy: 0.8564\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.5415 - val_accuracy: 0.8667\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.5402 - val_accuracy: 0.8564\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.5373 - val_accuracy: 0.8564\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5381 - val_accuracy: 0.8564\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2263 - accuracy: 0.8874 - val_loss: 0.5372 - val_accuracy: 0.8564\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5394 - val_accuracy: 0.8564\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5372 - val_accuracy: 0.8564\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.5377 - val_accuracy: 0.8564\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5399 - val_accuracy: 0.8564\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.5419 - val_accuracy: 0.8564\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5425 - val_accuracy: 0.8564\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.5411 - val_accuracy: 0.8564\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5410 - val_accuracy: 0.8564\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.5419 - val_accuracy: 0.8564\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5442 - val_accuracy: 0.8564\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.5404 - val_accuracy: 0.8564\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5441 - val_accuracy: 0.8564\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5459 - val_accuracy: 0.8564\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5356 - val_accuracy: 0.8564\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5314 - val_accuracy: 0.8564\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5344 - val_accuracy: 0.8564\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.5315 - val_accuracy: 0.8564\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5315 - val_accuracy: 0.8564\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5310 - val_accuracy: 0.8564\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5301 - val_accuracy: 0.8564\n",
      "Epoch 772/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5337 - val_accuracy: 0.8564\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 112us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.5295 - val_accuracy: 0.8564\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5323 - val_accuracy: 0.8564\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5301 - val_accuracy: 0.8564\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.5357 - val_accuracy: 0.8564\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.5350 - val_accuracy: 0.8564\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5358 - val_accuracy: 0.8564\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5300 - val_accuracy: 0.8564\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.5323 - val_accuracy: 0.8564\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5342 - val_accuracy: 0.8564\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5334 - val_accuracy: 0.8564\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2273 - accuracy: 0.8852 - val_loss: 0.5342 - val_accuracy: 0.8564\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2258 - accuracy: 0.8874 - val_loss: 0.5380 - val_accuracy: 0.8564\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5342 - val_accuracy: 0.8564\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2279 - accuracy: 0.8786 - val_loss: 0.5337 - val_accuracy: 0.8462\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.5369 - val_accuracy: 0.8564\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5361 - val_accuracy: 0.8564\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.5345 - val_accuracy: 0.8564\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5359 - val_accuracy: 0.8564\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.5363 - val_accuracy: 0.8564\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5384 - val_accuracy: 0.8564\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.5348 - val_accuracy: 0.8564\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5381 - val_accuracy: 0.8564\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5375 - val_accuracy: 0.8564\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5371 - val_accuracy: 0.8564\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5365 - val_accuracy: 0.8564\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5357 - val_accuracy: 0.8564\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.5333 - val_accuracy: 0.8564\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5354 - val_accuracy: 0.8564\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5334 - val_accuracy: 0.8564\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5352 - val_accuracy: 0.8564\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5353 - val_accuracy: 0.8564\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.5358 - val_accuracy: 0.8564\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.5353 - val_accuracy: 0.8564\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5368 - val_accuracy: 0.8564\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.5363 - val_accuracy: 0.8564\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5356 - val_accuracy: 0.8564\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5360 - val_accuracy: 0.8564\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5379 - val_accuracy: 0.8564\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.5357 - val_accuracy: 0.8564\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.5382 - val_accuracy: 0.8564\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5381 - val_accuracy: 0.8564\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2277 - accuracy: 0.8852 - val_loss: 0.5384 - val_accuracy: 0.8564\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5400 - val_accuracy: 0.8564\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5383 - val_accuracy: 0.8564\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5389 - val_accuracy: 0.8564\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2277 - accuracy: 0.8786 - val_loss: 0.5384 - val_accuracy: 0.8564\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2286 - accuracy: 0.8830 - val_loss: 0.5418 - val_accuracy: 0.8564\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5392 - val_accuracy: 0.8564\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5411 - val_accuracy: 0.8564\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5429 - val_accuracy: 0.8564\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5405 - val_accuracy: 0.8564\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5453 - val_accuracy: 0.8564\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2274 - accuracy: 0.8808 - val_loss: 0.5422 - val_accuracy: 0.8564\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5415 - val_accuracy: 0.8564\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5423 - val_accuracy: 0.8564\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.5422 - val_accuracy: 0.8564\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5427 - val_accuracy: 0.8564\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5420 - val_accuracy: 0.8564\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2271 - accuracy: 0.8830 - val_loss: 0.5423 - val_accuracy: 0.8667\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.5437 - val_accuracy: 0.8564\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5439 - val_accuracy: 0.8564\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5437 - val_accuracy: 0.8564\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5446 - val_accuracy: 0.8564\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5455 - val_accuracy: 0.8564\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.5498 - val_accuracy: 0.8564\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.5483 - val_accuracy: 0.8564\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5467 - val_accuracy: 0.8564\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2280 - accuracy: 0.8852 - val_loss: 0.5470 - val_accuracy: 0.8462\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.5468 - val_accuracy: 0.8564\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5467 - val_accuracy: 0.8564\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5482 - val_accuracy: 0.8564\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5477 - val_accuracy: 0.8564\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5482 - val_accuracy: 0.8564\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.5463 - val_accuracy: 0.8564\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5508 - val_accuracy: 0.8564\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2264 - accuracy: 0.8830 - val_loss: 0.5492 - val_accuracy: 0.8564\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5499 - val_accuracy: 0.8564\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5487 - val_accuracy: 0.8564\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.5501 - val_accuracy: 0.8564\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5501 - val_accuracy: 0.8564\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.5502 - val_accuracy: 0.8564\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5540 - val_accuracy: 0.8564\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.5517 - val_accuracy: 0.8564\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.5509 - val_accuracy: 0.8564\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5488 - val_accuracy: 0.8564\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5511 - val_accuracy: 0.8564\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5517 - val_accuracy: 0.8564\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5500 - val_accuracy: 0.8564\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5519 - val_accuracy: 0.8564\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5517 - val_accuracy: 0.8564\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2259 - accuracy: 0.8874 - val_loss: 0.5519 - val_accuracy: 0.8564\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.5530 - val_accuracy: 0.8564\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5596 - val_accuracy: 0.8564\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5525 - val_accuracy: 0.8564\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5556 - val_accuracy: 0.8564\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5525 - val_accuracy: 0.8564\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5540 - val_accuracy: 0.8564\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5514 - val_accuracy: 0.8564\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5549 - val_accuracy: 0.8564\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5544 - val_accuracy: 0.8564\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.5550 - val_accuracy: 0.8564\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.5599 - val_accuracy: 0.8564\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5541 - val_accuracy: 0.8564\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5546 - val_accuracy: 0.8564\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5556 - val_accuracy: 0.8564\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5538 - val_accuracy: 0.8564\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.5552 - val_accuracy: 0.8564\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2264 - accuracy: 0.8874 - val_loss: 0.5554 - val_accuracy: 0.8564\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.5571 - val_accuracy: 0.8564\n",
      "Epoch 882/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.5552 - val_accuracy: 0.8462\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 106us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.5566 - val_accuracy: 0.8564\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.5564 - val_accuracy: 0.8564\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5536 - val_accuracy: 0.8564\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5599 - val_accuracy: 0.8564\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5571 - val_accuracy: 0.8564\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5579 - val_accuracy: 0.8564\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5596 - val_accuracy: 0.8564\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.5578 - val_accuracy: 0.8564\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5598 - val_accuracy: 0.8564\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5593 - val_accuracy: 0.8564\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5606 - val_accuracy: 0.8564\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.5600 - val_accuracy: 0.8564\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5611 - val_accuracy: 0.8564\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.5583 - val_accuracy: 0.8564\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5641 - val_accuracy: 0.8564\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2263 - accuracy: 0.8874 - val_loss: 0.5596 - val_accuracy: 0.8564\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.5607 - val_accuracy: 0.8564\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5620 - val_accuracy: 0.8564\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5625 - val_accuracy: 0.8564\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5624 - val_accuracy: 0.8564\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5640 - val_accuracy: 0.8564\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5632 - val_accuracy: 0.8564\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.5626 - val_accuracy: 0.8564\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5649 - val_accuracy: 0.8564\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.5638 - val_accuracy: 0.8564\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2270 - accuracy: 0.8852 - val_loss: 0.5622 - val_accuracy: 0.8564\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - 0s 105us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5656 - val_accuracy: 0.8564\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5632 - val_accuracy: 0.8564\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2264 - accuracy: 0.8874 - val_loss: 0.5649 - val_accuracy: 0.8564\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.5648 - val_accuracy: 0.8564\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.5657 - val_accuracy: 0.8564\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5678 - val_accuracy: 0.8564\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5658 - val_accuracy: 0.8564\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.5666 - val_accuracy: 0.8564\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5681 - val_accuracy: 0.8564\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.5672 - val_accuracy: 0.8564\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5666 - val_accuracy: 0.8564\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5673 - val_accuracy: 0.8564\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.5680 - val_accuracy: 0.8564\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2282 - accuracy: 0.8786 - val_loss: 0.5683 - val_accuracy: 0.8564\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.5672 - val_accuracy: 0.8564\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5693 - val_accuracy: 0.8564\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5677 - val_accuracy: 0.8564\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.87 - 0s 105us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.5682 - val_accuracy: 0.8564\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5694 - val_accuracy: 0.8564\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5688 - val_accuracy: 0.8564\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5710 - val_accuracy: 0.8564\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5695 - val_accuracy: 0.8564\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.5695 - val_accuracy: 0.8564\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.5726 - val_accuracy: 0.8564\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5703 - val_accuracy: 0.8564\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.5720 - val_accuracy: 0.8564\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5721 - val_accuracy: 0.8564\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.5732 - val_accuracy: 0.8564\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5642 - val_accuracy: 0.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5634 - val_accuracy: 0.8564\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5649 - val_accuracy: 0.8564\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.5646 - val_accuracy: 0.8564\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5633 - val_accuracy: 0.8564\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5654 - val_accuracy: 0.8564\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.5625 - val_accuracy: 0.8462\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.5637 - val_accuracy: 0.8564\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.5638 - val_accuracy: 0.8564\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.5620 - val_accuracy: 0.8564\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.5639 - val_accuracy: 0.8564\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5639 - val_accuracy: 0.8564\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.5673 - val_accuracy: 0.8564\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5690 - val_accuracy: 0.8564\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5697 - val_accuracy: 0.8564\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5709 - val_accuracy: 0.8564\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5699 - val_accuracy: 0.8564\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.5687 - val_accuracy: 0.8462\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.5705 - val_accuracy: 0.8564\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.5693 - val_accuracy: 0.8564\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2250 - accuracy: 0.8852 - val_loss: 0.5693 - val_accuracy: 0.8462\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.5711 - val_accuracy: 0.8462\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5687 - val_accuracy: 0.8564\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.5709 - val_accuracy: 0.8564\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5695 - val_accuracy: 0.8564\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.5703 - val_accuracy: 0.8462\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2265 - accuracy: 0.8896 - val_loss: 0.5707 - val_accuracy: 0.8564\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.5717 - val_accuracy: 0.8564\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5691 - val_accuracy: 0.8564\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.5710 - val_accuracy: 0.8564\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.5724 - val_accuracy: 0.8564\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.5750 - val_accuracy: 0.8564\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.5701 - val_accuracy: 0.8667\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.5704 - val_accuracy: 0.8564\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5755 - val_accuracy: 0.8564\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5735 - val_accuracy: 0.8564\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.5725 - val_accuracy: 0.8564\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5729 - val_accuracy: 0.8564\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5724 - val_accuracy: 0.8564\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.5777 - val_accuracy: 0.8564\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.5740 - val_accuracy: 0.8564\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5739 - val_accuracy: 0.8564\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5748 - val_accuracy: 0.8564\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5754 - val_accuracy: 0.8564\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.5751 - val_accuracy: 0.8564\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.5769 - val_accuracy: 0.8564\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5767 - val_accuracy: 0.8564\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.5758 - val_accuracy: 0.8564\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.5749 - val_accuracy: 0.8564\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.5771 - val_accuracy: 0.8564\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.5764 - val_accuracy: 0.8564\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.5772 - val_accuracy: 0.8564\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.5766 - val_accuracy: 0.8564\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.5789 - val_accuracy: 0.8564\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2280 - accuracy: 0.8852 - val_loss: 0.5761 - val_accuracy: 0.8564\n",
      "Epoch 992/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2275 - accuracy: 0.8808 - val_loss: 0.5766 - val_accuracy: 0.8564\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.5765 - val_accuracy: 0.8564\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.5773 - val_accuracy: 0.8564\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.5794 - val_accuracy: 0.8564\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.5772 - val_accuracy: 0.8564\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2273 - accuracy: 0.8786 - val_loss: 0.5783 - val_accuracy: 0.8564\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.5790 - val_accuracy: 0.8564\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.5767 - val_accuracy: 0.8564\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.5772 - val_accuracy: 0.8564\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.58%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.8683458e-30, 1.0000000e+00, 1.5872764e-25],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [2.9294800e-02, 9.7070515e-01, 1.9824599e-08],\n",
       "       [2.3314092e-01, 7.6685905e-01, 1.3561241e-07],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.6571120e-04, 9.9973420e-01, 2.3860011e-11],\n",
       "       [3.5755882e-05, 9.9996424e-01, 4.0667150e-09],\n",
       "       [9.9998700e-01, 1.3037817e-05, 1.4557464e-12],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [5.4765666e-01, 4.5234194e-01, 1.3953713e-06],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [3.5508074e-35, 1.0000000e+00, 1.9292610e-26],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [5.4765666e-01, 4.5234194e-01, 1.3953713e-06],\n",
       "       [4.2269326e-07, 9.9999950e-01, 8.6079380e-11],\n",
       "       [9.9999810e-01, 1.9233212e-06, 6.1433210e-10],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [4.2269326e-07, 9.9999950e-01, 8.6079380e-11],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [3.7593058e-01, 6.2406933e-01, 6.9294740e-08],\n",
       "       [9.9999680e-01, 3.0790638e-06, 1.0898660e-07],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [9.9951970e-01, 4.8029496e-04, 2.1664736e-25],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.8683458e-30, 1.0000000e+00, 1.5872764e-25],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.8683458e-30, 1.0000000e+00, 1.5872764e-25],\n",
       "       [1.3363351e-01, 8.6636645e-01, 5.4430394e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [9.7850220e-08, 9.9999990e-01, 9.2517355e-23],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.0000000e+00, 3.8392150e-08, 2.9420620e-12],\n",
       "       [1.3252849e-08, 1.0000000e+00, 2.5866430e-12],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [3.7712005e-06, 9.9999620e-01, 3.1052453e-19],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [5.4765666e-01, 4.5234194e-01, 1.3953713e-06],\n",
       "       [9.7952855e-01, 2.0471431e-02, 6.1132654e-10],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [9.9998580e-01, 1.4193462e-05, 9.2559546e-14],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [3.7593058e-01, 6.2406933e-01, 6.9294740e-08],\n",
       "       [1.0000000e+00, 3.8392150e-08, 2.9420620e-12],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.3363351e-01, 8.6636645e-01, 5.4430394e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.3123935e-07, 9.9999976e-01, 6.0515674e-08],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [3.7593058e-01, 6.2406933e-01, 6.9294740e-08],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [6.1055360e-06, 9.9999390e-01, 4.2856892e-16],\n",
       "       [3.3614448e-01, 6.6385550e-01, 2.4477190e-12],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.1055360e-06, 9.9999390e-01, 4.2856892e-16],\n",
       "       [9.9998700e-01, 1.3037817e-05, 1.4557464e-12],\n",
       "       [9.7444160e-01, 2.5558440e-02, 1.2761991e-12],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [4.2269326e-07, 9.9999950e-01, 8.6079380e-11],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [9.9788090e-01, 2.1191381e-03, 2.1961288e-09],\n",
       "       [3.7712005e-06, 9.9999620e-01, 3.1052453e-19],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.9294800e-02, 9.7070515e-01, 1.9824599e-08],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [9.3349183e-07, 9.9999905e-01, 8.9655910e-20],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [4.2447516e-21, 1.0000000e+00, 2.4826863e-35],\n",
       "       [9.9894600e-01, 1.0219377e-03, 3.2085885e-05],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [2.6571120e-04, 9.9973420e-01, 2.3860011e-11],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [3.5508074e-35, 1.0000000e+00, 1.9292610e-26],\n",
       "       [9.5624400e-02, 9.0437550e-01, 6.0462670e-08],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [3.7593058e-01, 6.2406933e-01, 6.9294740e-08],\n",
       "       [6.2442327e-01, 3.7557680e-01, 3.7886990e-12],\n",
       "       [9.9998700e-01, 1.3037817e-05, 1.4557464e-12],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [3.3614448e-01, 6.6385550e-01, 2.4477190e-12],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09],\n",
       "       [3.5508074e-35, 1.0000000e+00, 1.9292610e-26],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [9.7850220e-08, 9.9999990e-01, 9.2517355e-23],\n",
       "       [3.7712005e-06, 9.9999620e-01, 3.1052453e-19],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [3.5755882e-05, 9.9996424e-01, 4.0667150e-09],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [9.9999810e-01, 1.9233212e-06, 6.1433210e-10],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [3.5508074e-35, 1.0000000e+00, 1.9292610e-26],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [4.8243132e-01, 5.1756865e-01, 7.9054874e-10],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.1055360e-06, 9.9999390e-01, 4.2856892e-16],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [4.2447516e-21, 1.0000000e+00, 2.4826863e-35],\n",
       "       [3.5508074e-35, 1.0000000e+00, 1.9292610e-26],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [2.6571120e-04, 9.9973420e-01, 2.3860011e-11],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [9.8172057e-01, 1.8279409e-02, 2.9995550e-08],\n",
       "       [3.5133177e-16, 1.0000000e+00, 1.2638487e-22],\n",
       "       [9.8172057e-01, 1.8279409e-02, 2.9995550e-08],\n",
       "       [1.3363351e-01, 8.6636645e-01, 5.4430394e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [3.3614448e-01, 6.6385550e-01, 2.4477190e-12],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [9.9992680e-01, 7.3186486e-05, 2.4816790e-29],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.0994130e-06, 9.9999785e-01, 2.0525808e-13],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [9.7850220e-08, 9.9999990e-01, 9.2517355e-23],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [3.7593058e-01, 6.2406933e-01, 6.9294740e-08],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [9.9788090e-01, 2.1191381e-03, 2.1961288e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [3.3614448e-01, 6.6385550e-01, 2.4477190e-12],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [6.2456760e-01, 3.7543230e-01, 2.2127670e-09],\n",
       "       [6.1807954e-01, 3.8192046e-01, 1.0686076e-08],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [6.9079690e-01, 3.0920310e-01, 2.4776810e-09],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [5.4765666e-01, 4.5234194e-01, 1.3953713e-06],\n",
       "       [1.1739245e-08, 7.9178190e-09, 1.0000000e+00],\n",
       "       [9.9999310e-01, 9.3427536e-07, 5.9035406e-06],\n",
       "       [2.2403053e-11, 3.7850830e-08, 1.0000000e+00],\n",
       "       [8.0952640e-01, 1.9047360e-01, 5.8453300e-09]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491518737672585"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491518737672585"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS249     1\n",
       "1    NRS172     1\n",
       "2    NRS209     2\n",
       "3    NRS108     1\n",
       "4    NRS209     2\n",
       "..      ...   ...\n",
       "190  NRS209     2\n",
       "191  NRS110     2\n",
       "192  NRS255     1\n",
       "193  NRS175     1\n",
       "194  NRS241     1\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 332us/step - loss: 0.8319 - accuracy: 0.6380 - val_loss: 0.6758 - val_accuracy: 0.6513\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.6140 - accuracy: 0.7064 - val_loss: 0.5367 - val_accuracy: 0.7231\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.5266 - accuracy: 0.7285 - val_loss: 0.4662 - val_accuracy: 0.7538\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.4733 - accuracy: 0.7616 - val_loss: 0.4347 - val_accuracy: 0.7385\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.4429 - accuracy: 0.7770 - val_loss: 0.4002 - val_accuracy: 0.7846\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.4258 - accuracy: 0.8079 - val_loss: 0.3868 - val_accuracy: 0.8051\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.4113 - accuracy: 0.7991 - val_loss: 0.3952 - val_accuracy: 0.8205\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.4099 - accuracy: 0.7881 - val_loss: 0.3735 - val_accuracy: 0.8359\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.3944 - accuracy: 0.8300 - val_loss: 0.3743 - val_accuracy: 0.8205\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.3975 - accuracy: 0.8212 - val_loss: 0.3548 - val_accuracy: 0.8154\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.3842 - accuracy: 0.8190 - val_loss: 0.3513 - val_accuracy: 0.8051\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.3879 - accuracy: 0.8146 - val_loss: 0.3461 - val_accuracy: 0.8154\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.3729 - accuracy: 0.8212 - val_loss: 0.3384 - val_accuracy: 0.8615\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.3648 - accuracy: 0.8234 - val_loss: 0.3750 - val_accuracy: 0.7179\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.3614 - accuracy: 0.8234 - val_loss: 0.3371 - val_accuracy: 0.8154\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.3610 - accuracy: 0.8344 - val_loss: 0.3298 - val_accuracy: 0.8462\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.3532 - accuracy: 0.8411 - val_loss: 0.3349 - val_accuracy: 0.8308\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.3537 - accuracy: 0.8366 - val_loss: 0.3324 - val_accuracy: 0.8359\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.3456 - accuracy: 0.8366 - val_loss: 0.3309 - val_accuracy: 0.8308\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.3567 - accuracy: 0.8102 - val_loss: 0.3237 - val_accuracy: 0.8462\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.3393 - accuracy: 0.8278 - val_loss: 0.3308 - val_accuracy: 0.8359\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.3378 - accuracy: 0.8477 - val_loss: 0.3178 - val_accuracy: 0.8410\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.3346 - accuracy: 0.8411 - val_loss: 0.3285 - val_accuracy: 0.8308\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 500us/step - loss: 0.3319 - accuracy: 0.8389 - val_loss: 0.3173 - val_accuracy: 0.8359\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.3322 - accuracy: 0.8477 - val_loss: 0.3168 - val_accuracy: 0.8359\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 345us/step - loss: 0.3272 - accuracy: 0.8411 - val_loss: 0.3110 - val_accuracy: 0.8410\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.3312 - accuracy: 0.8477 - val_loss: 0.3092 - val_accuracy: 0.8410\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3304 - accuracy: 0.8455 - val_loss: 0.3176 - val_accuracy: 0.8359\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.3301 - accuracy: 0.8433 - val_loss: 0.3188 - val_accuracy: 0.8359\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.3219 - accuracy: 0.8499 - val_loss: 0.3039 - val_accuracy: 0.8410\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.3197 - accuracy: 0.8455 - val_loss: 0.3044 - val_accuracy: 0.8410\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 345us/step - loss: 0.3159 - accuracy: 0.8455 - val_loss: 0.3165 - val_accuracy: 0.8359\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 353us/step - loss: 0.3122 - accuracy: 0.8543 - val_loss: 0.3064 - val_accuracy: 0.8564\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.3140 - accuracy: 0.8565 - val_loss: 0.3094 - val_accuracy: 0.8359\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.3131 - accuracy: 0.8499 - val_loss: 0.3041 - val_accuracy: 0.8359\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.3073 - accuracy: 0.8477 - val_loss: 0.2979 - val_accuracy: 0.8513\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.3068 - accuracy: 0.8565 - val_loss: 0.3221 - val_accuracy: 0.8359\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.3042 - accuracy: 0.8477 - val_loss: 0.3030 - val_accuracy: 0.8564\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.3202 - accuracy: 0.8499 - val_loss: 0.3087 - val_accuracy: 0.8564\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 300us/step - loss: 0.3055 - accuracy: 0.8565 - val_loss: 0.2947 - val_accuracy: 0.8513\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.3056 - accuracy: 0.8499 - val_loss: 0.3006 - val_accuracy: 0.8513\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.3109 - accuracy: 0.8322 - val_loss: 0.2932 - val_accuracy: 0.8513\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.3035 - accuracy: 0.8499 - val_loss: 0.2955 - val_accuracy: 0.8462\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.3029 - accuracy: 0.8543 - val_loss: 0.2938 - val_accuracy: 0.8513\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2966 - accuracy: 0.8477 - val_loss: 0.2978 - val_accuracy: 0.8462\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2956 - accuracy: 0.8565 - val_loss: 0.2879 - val_accuracy: 0.8513\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.3149 - accuracy: 0.8499 - val_loss: 0.2909 - val_accuracy: 0.8513\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.3048 - accuracy: 0.8499 - val_loss: 0.2952 - val_accuracy: 0.8462\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2932 - accuracy: 0.8543 - val_loss: 0.3302 - val_accuracy: 0.8513\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.3000 - accuracy: 0.8499 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2978 - accuracy: 0.8631 - val_loss: 0.3177 - val_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.3124 - accuracy: 0.8433 - val_loss: 0.2883 - val_accuracy: 0.8513\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3028 - accuracy: 0.8631 - val_loss: 0.3012 - val_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2911 - accuracy: 0.8543 - val_loss: 0.2895 - val_accuracy: 0.8462\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2851 - accuracy: 0.8675 - val_loss: 0.2897 - val_accuracy: 0.8615\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2926 - accuracy: 0.8631 - val_loss: 0.2859 - val_accuracy: 0.8513\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2885 - accuracy: 0.8609 - val_loss: 0.2859 - val_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2833 - accuracy: 0.8587 - val_loss: 0.2968 - val_accuracy: 0.8667\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2846 - accuracy: 0.8609 - val_loss: 0.2826 - val_accuracy: 0.8513\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2852 - accuracy: 0.8565 - val_loss: 0.2913 - val_accuracy: 0.8462\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2822 - accuracy: 0.8609 - val_loss: 0.2839 - val_accuracy: 0.8513\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2883 - accuracy: 0.8499 - val_loss: 0.3039 - val_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2824 - accuracy: 0.8543 - val_loss: 0.2901 - val_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2869 - accuracy: 0.8653 - val_loss: 0.2853 - val_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2849 - accuracy: 0.8587 - val_loss: 0.2788 - val_accuracy: 0.8513\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2845 - accuracy: 0.8631 - val_loss: 0.2975 - val_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2877 - accuracy: 0.8609 - val_loss: 0.2853 - val_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2769 - accuracy: 0.8720 - val_loss: 0.2821 - val_accuracy: 0.8564\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2823 - accuracy: 0.8587 - val_loss: 0.2809 - val_accuracy: 0.8513\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2768 - accuracy: 0.8720 - val_loss: 0.2779 - val_accuracy: 0.8564\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2737 - accuracy: 0.8698 - val_loss: 0.2884 - val_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2760 - accuracy: 0.8653 - val_loss: 0.2792 - val_accuracy: 0.8513\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2747 - accuracy: 0.8720 - val_loss: 0.2780 - val_accuracy: 0.8513\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2759 - accuracy: 0.8653 - val_loss: 0.2788 - val_accuracy: 0.8564\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2696 - accuracy: 0.8631 - val_loss: 0.3477 - val_accuracy: 0.7641\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2878 - accuracy: 0.8521 - val_loss: 0.3032 - val_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2802 - accuracy: 0.8477 - val_loss: 0.2762 - val_accuracy: 0.8769\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2707 - accuracy: 0.8720 - val_loss: 0.3194 - val_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2676 - accuracy: 0.8764 - val_loss: 0.2791 - val_accuracy: 0.8564\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2751 - accuracy: 0.8587 - val_loss: 0.2795 - val_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2708 - accuracy: 0.8720 - val_loss: 0.2794 - val_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2712 - accuracy: 0.8675 - val_loss: 0.2823 - val_accuracy: 0.8564\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2869 - accuracy: 0.8587 - val_loss: 0.2814 - val_accuracy: 0.8564\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2761 - accuracy: 0.8653 - val_loss: 0.2838 - val_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2653 - accuracy: 0.8764 - val_loss: 0.2764 - val_accuracy: 0.8462\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2683 - accuracy: 0.8764 - val_loss: 0.2758 - val_accuracy: 0.8513\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2616 - accuracy: 0.8653 - val_loss: 0.3442 - val_accuracy: 0.7590\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2807 - accuracy: 0.8543 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2684 - accuracy: 0.8786 - val_loss: 0.2758 - val_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2705 - accuracy: 0.8786 - val_loss: 0.2730 - val_accuracy: 0.8564\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.2673 - accuracy: 0.8764 - val_loss: 0.2754 - val_accuracy: 0.8769\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2651 - accuracy: 0.8896 - val_loss: 0.2745 - val_accuracy: 0.8667\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2698 - accuracy: 0.8808 - val_loss: 0.2710 - val_accuracy: 0.8667\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2635 - accuracy: 0.8808 - val_loss: 0.2786 - val_accuracy: 0.8718\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2640 - accuracy: 0.8852 - val_loss: 0.2783 - val_accuracy: 0.8667\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2663 - accuracy: 0.8675 - val_loss: 0.2719 - val_accuracy: 0.8718\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2602 - accuracy: 0.8896 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2792 - accuracy: 0.8698 - val_loss: 0.2952 - val_accuracy: 0.8667\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2651 - accuracy: 0.8631 - val_loss: 0.2703 - val_accuracy: 0.8769\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2682 - accuracy: 0.8852 - val_loss: 0.2761 - val_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2647 - accuracy: 0.8808 - val_loss: 0.2716 - val_accuracy: 0.8718\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2650 - accuracy: 0.8786 - val_loss: 0.2740 - val_accuracy: 0.8667\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2634 - accuracy: 0.8764 - val_loss: 0.2743 - val_accuracy: 0.8667\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2584 - accuracy: 0.8896 - val_loss: 0.2722 - val_accuracy: 0.8718\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2609 - accuracy: 0.8720 - val_loss: 0.2730 - val_accuracy: 0.8769\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2676 - accuracy: 0.8830 - val_loss: 0.2697 - val_accuracy: 0.8718\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2586 - accuracy: 0.8896 - val_loss: 0.2766 - val_accuracy: 0.8462\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2657 - accuracy: 0.8786 - val_loss: 0.2707 - val_accuracy: 0.8718\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2551 - accuracy: 0.8808 - val_loss: 0.2769 - val_accuracy: 0.8667\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2559 - accuracy: 0.8896 - val_loss: 0.2714 - val_accuracy: 0.8667\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2529 - accuracy: 0.8896 - val_loss: 0.2717 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2512 - accuracy: 0.8874 - val_loss: 0.2755 - val_accuracy: 0.8667\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2628 - accuracy: 0.8786 - val_loss: 0.2800 - val_accuracy: 0.8667\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2568 - accuracy: 0.8830 - val_loss: 0.2685 - val_accuracy: 0.8718\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2529 - accuracy: 0.8808 - val_loss: 0.2686 - val_accuracy: 0.8615\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2564 - accuracy: 0.8830 - val_loss: 0.2704 - val_accuracy: 0.8667\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2586 - accuracy: 0.8808 - val_loss: 0.2695 - val_accuracy: 0.8667\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2589 - accuracy: 0.8896 - val_loss: 0.2789 - val_accuracy: 0.8667\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2529 - accuracy: 0.8786 - val_loss: 0.2766 - val_accuracy: 0.8615\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.2595 - accuracy: 0.8808 - val_loss: 0.2743 - val_accuracy: 0.8615\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2559 - accuracy: 0.8874 - val_loss: 0.2868 - val_accuracy: 0.8667\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2526 - accuracy: 0.8874 - val_loss: 0.2964 - val_accuracy: 0.8667\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2526 - accuracy: 0.8786 - val_loss: 0.2730 - val_accuracy: 0.8667\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.81 - 0s 119us/step - loss: 0.2502 - accuracy: 0.8852 - val_loss: 0.2695 - val_accuracy: 0.8667\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2634 - accuracy: 0.8698 - val_loss: 0.2659 - val_accuracy: 0.8718\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2573 - accuracy: 0.8808 - val_loss: 0.2681 - val_accuracy: 0.8667\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2492 - accuracy: 0.8940 - val_loss: 0.2869 - val_accuracy: 0.8667\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2614 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8615\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2461 - accuracy: 0.8874 - val_loss: 0.2926 - val_accuracy: 0.8667\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2483 - accuracy: 0.8874 - val_loss: 0.2750 - val_accuracy: 0.8667\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2532 - accuracy: 0.8874 - val_loss: 0.2702 - val_accuracy: 0.8615\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2563 - accuracy: 0.8808 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2513 - accuracy: 0.8874 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2573 - accuracy: 0.8874 - val_loss: 0.2770 - val_accuracy: 0.8667\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2477 - accuracy: 0.8918 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2503 - accuracy: 0.8786 - val_loss: 0.2869 - val_accuracy: 0.8667\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2519 - accuracy: 0.8874 - val_loss: 0.2692 - val_accuracy: 0.8718\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2604 - accuracy: 0.8631 - val_loss: 0.2660 - val_accuracy: 0.8564\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2553 - accuracy: 0.8874 - val_loss: 0.2707 - val_accuracy: 0.8667\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2548 - accuracy: 0.8874 - val_loss: 0.2762 - val_accuracy: 0.8667\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2462 - accuracy: 0.8918 - val_loss: 0.2746 - val_accuracy: 0.8667\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2468 - accuracy: 0.8896 - val_loss: 0.2673 - val_accuracy: 0.8667\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2502 - accuracy: 0.8742 - val_loss: 0.2829 - val_accuracy: 0.8667\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2545 - accuracy: 0.8852 - val_loss: 0.2667 - val_accuracy: 0.8718\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2543 - accuracy: 0.8918 - val_loss: 0.2716 - val_accuracy: 0.8718\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2489 - accuracy: 0.8808 - val_loss: 0.2711 - val_accuracy: 0.8513\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2483 - accuracy: 0.8874 - val_loss: 0.2747 - val_accuracy: 0.8513\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2452 - accuracy: 0.8896 - val_loss: 0.2758 - val_accuracy: 0.8667\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2443 - accuracy: 0.8918 - val_loss: 0.2704 - val_accuracy: 0.8667\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2430 - accuracy: 0.8918 - val_loss: 0.2702 - val_accuracy: 0.8667\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2442 - accuracy: 0.8896 - val_loss: 0.2663 - val_accuracy: 0.8718\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2526 - accuracy: 0.8852 - val_loss: 0.2661 - val_accuracy: 0.8718\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2462 - accuracy: 0.8852 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2487 - accuracy: 0.8742 - val_loss: 0.2847 - val_accuracy: 0.8667\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2457 - accuracy: 0.8786 - val_loss: 0.2764 - val_accuracy: 0.8667\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2456 - accuracy: 0.8918 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2519 - accuracy: 0.8918 - val_loss: 0.2819 - val_accuracy: 0.8667\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2479 - accuracy: 0.8896 - val_loss: 0.2734 - val_accuracy: 0.8667\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2461 - accuracy: 0.8830 - val_loss: 0.2627 - val_accuracy: 0.8667\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 0.2688 - val_accuracy: 0.8821\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2486 - accuracy: 0.8940 - val_loss: 0.2669 - val_accuracy: 0.8718\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2504 - accuracy: 0.8962 - val_loss: 0.2733 - val_accuracy: 0.8667\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2465 - accuracy: 0.8918 - val_loss: 0.2876 - val_accuracy: 0.8667\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2500 - accuracy: 0.8808 - val_loss: 0.2777 - val_accuracy: 0.8667\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2429 - accuracy: 0.8896 - val_loss: 0.2682 - val_accuracy: 0.8769\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2464 - accuracy: 0.8896 - val_loss: 0.2645 - val_accuracy: 0.8667\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2463 - accuracy: 0.8852 - val_loss: 0.2662 - val_accuracy: 0.8718\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2528 - accuracy: 0.8742 - val_loss: 0.2691 - val_accuracy: 0.8718\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2468 - accuracy: 0.8918 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2424 - accuracy: 0.8830 - val_loss: 0.2805 - val_accuracy: 0.8564\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2465 - accuracy: 0.8896 - val_loss: 0.2662 - val_accuracy: 0.8667\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2397 - accuracy: 0.8918 - val_loss: 0.2705 - val_accuracy: 0.8667\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2421 - accuracy: 0.8918 - val_loss: 0.2688 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2495 - accuracy: 0.8786 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2421 - accuracy: 0.8874 - val_loss: 0.2779 - val_accuracy: 0.8667\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2404 - accuracy: 0.8896 - val_loss: 0.2699 - val_accuracy: 0.8718\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2394 - accuracy: 0.8896 - val_loss: 0.2738 - val_accuracy: 0.8667\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2381 - accuracy: 0.8918 - val_loss: 0.2685 - val_accuracy: 0.8667\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2395 - accuracy: 0.8896 - val_loss: 0.2640 - val_accuracy: 0.8718\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2513 - accuracy: 0.8830 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2406 - accuracy: 0.8896 - val_loss: 0.2823 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2432 - accuracy: 0.8918 - val_loss: 0.3072 - val_accuracy: 0.8667\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2391 - accuracy: 0.8918 - val_loss: 0.2718 - val_accuracy: 0.8718\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2429 - accuracy: 0.8830 - val_loss: 0.2713 - val_accuracy: 0.8667\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2409 - accuracy: 0.8808 - val_loss: 0.2791 - val_accuracy: 0.8667\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2385 - accuracy: 0.8852 - val_loss: 0.2709 - val_accuracy: 0.8718\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2449 - accuracy: 0.8918 - val_loss: 0.2721 - val_accuracy: 0.8667\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2414 - accuracy: 0.8852 - val_loss: 0.2871 - val_accuracy: 0.8564\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2410 - accuracy: 0.8786 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2416 - accuracy: 0.8874 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 0.2675 - val_accuracy: 0.8667\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2364 - accuracy: 0.8918 - val_loss: 0.2745 - val_accuracy: 0.8667\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2417 - accuracy: 0.8940 - val_loss: 0.2820 - val_accuracy: 0.8667\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2375 - accuracy: 0.8874 - val_loss: 0.2665 - val_accuracy: 0.8718\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2377 - accuracy: 0.8896 - val_loss: 0.2838 - val_accuracy: 0.8564\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2382 - accuracy: 0.8918 - val_loss: 0.2648 - val_accuracy: 0.8667\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2391 - accuracy: 0.8918 - val_loss: 0.2936 - val_accuracy: 0.8564\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2341 - accuracy: 0.8940 - val_loss: 0.2711 - val_accuracy: 0.8718\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2421 - accuracy: 0.8918 - val_loss: 0.2672 - val_accuracy: 0.8667\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2394 - accuracy: 0.8918 - val_loss: 0.2626 - val_accuracy: 0.8718\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2458 - accuracy: 0.8918 - val_loss: 0.2667 - val_accuracy: 0.8667\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2377 - accuracy: 0.8918 - val_loss: 0.2692 - val_accuracy: 0.8718\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2382 - accuracy: 0.8874 - val_loss: 0.2802 - val_accuracy: 0.8667\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2385 - accuracy: 0.8918 - val_loss: 0.2666 - val_accuracy: 0.8667\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2370 - accuracy: 0.8896 - val_loss: 0.2893 - val_accuracy: 0.8564\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.2857 - val_accuracy: 0.8564\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 0.2674 - val_accuracy: 0.8667\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 0.2635 - val_accuracy: 0.8718\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2346 - accuracy: 0.8896 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2360 - accuracy: 0.8786 - val_loss: 0.3143 - val_accuracy: 0.8564\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2411 - accuracy: 0.8764 - val_loss: 0.2683 - val_accuracy: 0.8667\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2386 - accuracy: 0.8896 - val_loss: 0.2651 - val_accuracy: 0.8667\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2383 - accuracy: 0.8896 - val_loss: 0.2621 - val_accuracy: 0.8718\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2350 - accuracy: 0.8896 - val_loss: 0.3120 - val_accuracy: 0.8615\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2503 - accuracy: 0.8742 - val_loss: 0.3131 - val_accuracy: 0.8615\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2605 - val_accuracy: 0.8718\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2324 - accuracy: 0.8896 - val_loss: 0.2684 - val_accuracy: 0.8667\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2353 - accuracy: 0.8918 - val_loss: 0.2625 - val_accuracy: 0.8769\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2396 - accuracy: 0.8874 - val_loss: 0.2749 - val_accuracy: 0.8667\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2383 - accuracy: 0.8874 - val_loss: 0.2722 - val_accuracy: 0.8667\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2380 - accuracy: 0.8918 - val_loss: 0.2712 - val_accuracy: 0.8667\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 168us/step - loss: 0.2362 - accuracy: 0.8874 - val_loss: 0.2680 - val_accuracy: 0.8667\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2417 - accuracy: 0.8808 - val_loss: 0.2868 - val_accuracy: 0.8667\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 0.2705 - val_accuracy: 0.8667\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2363 - accuracy: 0.8896 - val_loss: 0.2665 - val_accuracy: 0.8564\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.3019 - val_accuracy: 0.8564\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2358 - accuracy: 0.8874 - val_loss: 0.2838 - val_accuracy: 0.8564\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.2683 - val_accuracy: 0.8667\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2349 - accuracy: 0.8918 - val_loss: 0.2659 - val_accuracy: 0.8667\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2367 - accuracy: 0.8918 - val_loss: 0.2740 - val_accuracy: 0.8667\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2745 - val_accuracy: 0.8667\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2413 - accuracy: 0.8918 - val_loss: 0.2762 - val_accuracy: 0.8667\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2304 - accuracy: 0.8918 - val_loss: 0.2860 - val_accuracy: 0.8564\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2378 - accuracy: 0.8896 - val_loss: 0.2783 - val_accuracy: 0.8667\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2309 - accuracy: 0.8896 - val_loss: 0.2664 - val_accuracy: 0.8667\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2330 - accuracy: 0.8918 - val_loss: 0.2713 - val_accuracy: 0.8667\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 0.2792 - val_accuracy: 0.8564\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2297 - accuracy: 0.8918 - val_loss: 0.2657 - val_accuracy: 0.8667\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2309 - accuracy: 0.8918 - val_loss: 0.2648 - val_accuracy: 0.8667\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2379 - accuracy: 0.8896 - val_loss: 0.2660 - val_accuracy: 0.8667\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2330 - accuracy: 0.8918 - val_loss: 0.2893 - val_accuracy: 0.8564\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2363 - accuracy: 0.8918 - val_loss: 0.2692 - val_accuracy: 0.8667\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2385 - accuracy: 0.8896 - val_loss: 0.2749 - val_accuracy: 0.8564\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2334 - accuracy: 0.8918 - val_loss: 0.2795 - val_accuracy: 0.8564\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8564\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2332 - accuracy: 0.8896 - val_loss: 0.2658 - val_accuracy: 0.8667\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2397 - accuracy: 0.8852 - val_loss: 0.2718 - val_accuracy: 0.8667\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2398 - accuracy: 0.8896 - val_loss: 0.2772 - val_accuracy: 0.8667\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8564\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.2753 - val_accuracy: 0.8667\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2305 - accuracy: 0.8896 - val_loss: 0.2650 - val_accuracy: 0.8667\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2314 - accuracy: 0.8918 - val_loss: 0.2643 - val_accuracy: 0.8718\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.2638 - val_accuracy: 0.8718\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2386 - accuracy: 0.8852 - val_loss: 0.2643 - val_accuracy: 0.8667\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.2624 - val_accuracy: 0.8769\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2700 - val_accuracy: 0.8667\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2313 - accuracy: 0.8896 - val_loss: 0.3069 - val_accuracy: 0.8564\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 0.2647 - val_accuracy: 0.8667\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2345 - accuracy: 0.8896 - val_loss: 0.3243 - val_accuracy: 0.8564\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2503 - accuracy: 0.8587 - val_loss: 0.2687 - val_accuracy: 0.8667\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2285 - accuracy: 0.8918 - val_loss: 0.2643 - val_accuracy: 0.8718\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2311 - accuracy: 0.8918 - val_loss: 0.2790 - val_accuracy: 0.8564\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2306 - accuracy: 0.8918 - val_loss: 0.2747 - val_accuracy: 0.8564\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2295 - accuracy: 0.8896 - val_loss: 0.2698 - val_accuracy: 0.8667\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2292 - accuracy: 0.8918 - val_loss: 0.2671 - val_accuracy: 0.8667\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.2670 - val_accuracy: 0.8667\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2279 - accuracy: 0.8918 - val_loss: 0.2762 - val_accuracy: 0.8564\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2325 - accuracy: 0.8896 - val_loss: 0.3079 - val_accuracy: 0.8564\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2317 - accuracy: 0.8918 - val_loss: 0.2632 - val_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2308 - accuracy: 0.8918 - val_loss: 0.2651 - val_accuracy: 0.8667\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.2622 - val_accuracy: 0.8667\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 0.2656 - val_accuracy: 0.8718\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2378 - accuracy: 0.8896 - val_loss: 0.2778 - val_accuracy: 0.8667\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2325 - accuracy: 0.8896 - val_loss: 0.2827 - val_accuracy: 0.8564\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2355 - accuracy: 0.8918 - val_loss: 0.2657 - val_accuracy: 0.8667\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2307 - accuracy: 0.8896 - val_loss: 0.2624 - val_accuracy: 0.8821\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.2653 - val_accuracy: 0.8667\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 0.2703 - val_accuracy: 0.8564\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2324 - accuracy: 0.8896 - val_loss: 0.2672 - val_accuracy: 0.8769\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.2659 - val_accuracy: 0.8667\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2280 - accuracy: 0.8918 - val_loss: 0.2692 - val_accuracy: 0.8667\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2273 - accuracy: 0.8918 - val_loss: 0.2668 - val_accuracy: 0.8667\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2338 - accuracy: 0.8918 - val_loss: 0.2695 - val_accuracy: 0.8667\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2274 - accuracy: 0.8918 - val_loss: 0.2654 - val_accuracy: 0.8667\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2274 - accuracy: 0.8918 - val_loss: 0.2740 - val_accuracy: 0.8667\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2274 - accuracy: 0.8918 - val_loss: 0.2635 - val_accuracy: 0.8667\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2312 - accuracy: 0.8896 - val_loss: 0.2618 - val_accuracy: 0.8718\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2290 - accuracy: 0.8896 - val_loss: 0.2699 - val_accuracy: 0.8667\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2943 - val_accuracy: 0.8564\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2344 - accuracy: 0.8720 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2412 - accuracy: 0.8653 - val_loss: 0.2884 - val_accuracy: 0.8564\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2422 - accuracy: 0.8786 - val_loss: 0.2640 - val_accuracy: 0.8718\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.2994 - val_accuracy: 0.8564\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2302 - accuracy: 0.8918 - val_loss: 0.2716 - val_accuracy: 0.8564\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2329 - accuracy: 0.8918 - val_loss: 0.2718 - val_accuracy: 0.8667\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.2739 - val_accuracy: 0.8564\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2296 - accuracy: 0.8918 - val_loss: 0.2809 - val_accuracy: 0.8564\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2432 - accuracy: 0.8698 - val_loss: 0.2909 - val_accuracy: 0.8564\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2274 - accuracy: 0.8918 - val_loss: 0.2676 - val_accuracy: 0.8667\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2296 - accuracy: 0.8896 - val_loss: 0.2728 - val_accuracy: 0.8615\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.2694 - val_accuracy: 0.8667\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.2761 - val_accuracy: 0.8564\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2305 - accuracy: 0.8609 - val_loss: 0.2675 - val_accuracy: 0.8923\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2761 - val_accuracy: 0.8564\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2289 - accuracy: 0.8918 - val_loss: 0.2746 - val_accuracy: 0.8564\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2320 - accuracy: 0.8918 - val_loss: 0.2920 - val_accuracy: 0.8564\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2350 - accuracy: 0.8918 - val_loss: 0.2988 - val_accuracy: 0.8564\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2302 - accuracy: 0.8896 - val_loss: 0.2653 - val_accuracy: 0.8564\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.2728 - val_accuracy: 0.8667\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.2682 - val_accuracy: 0.8667\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2266 - accuracy: 0.8918 - val_loss: 0.2910 - val_accuracy: 0.8564\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2323 - accuracy: 0.8918 - val_loss: 0.2924 - val_accuracy: 0.8564\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2260 - accuracy: 0.8896 - val_loss: 0.2663 - val_accuracy: 0.8718\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2273 - accuracy: 0.8918 - val_loss: 0.2909 - val_accuracy: 0.8564\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2318 - accuracy: 0.8918 - val_loss: 0.2735 - val_accuracy: 0.8718\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2288 - accuracy: 0.8896 - val_loss: 0.2893 - val_accuracy: 0.8564\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2376 - accuracy: 0.8918 - val_loss: 0.2748 - val_accuracy: 0.8667\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.2640 - val_accuracy: 0.8718\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2354 - accuracy: 0.8918 - val_loss: 0.2693 - val_accuracy: 0.8667\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2282 - accuracy: 0.8918 - val_loss: 0.2759 - val_accuracy: 0.8564\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.2979 - val_accuracy: 0.8564\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2199 - accuracy: 0.8874 - val_loss: 0.2647 - val_accuracy: 0.8821\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2442 - accuracy: 0.8742 - val_loss: 0.2634 - val_accuracy: 0.8769\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2414 - accuracy: 0.8896 - val_loss: 0.2693 - val_accuracy: 0.8667\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2280 - accuracy: 0.8896 - val_loss: 0.2763 - val_accuracy: 0.8564\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.2731 - val_accuracy: 0.8564\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.2827 - val_accuracy: 0.8564\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.2689 - val_accuracy: 0.8718\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2302 - accuracy: 0.8918 - val_loss: 0.2834 - val_accuracy: 0.8667\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2274 - accuracy: 0.8918 - val_loss: 0.2660 - val_accuracy: 0.8667\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 183us/step - loss: 0.2257 - accuracy: 0.8874 - val_loss: 0.2762 - val_accuracy: 0.8564\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2278 - accuracy: 0.8852 - val_loss: 0.2711 - val_accuracy: 0.8667\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 0.3075 - val_accuracy: 0.8564\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2290 - accuracy: 0.8918 - val_loss: 0.2730 - val_accuracy: 0.8564\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.2675 - val_accuracy: 0.8667\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2258 - accuracy: 0.8918 - val_loss: 0.2897 - val_accuracy: 0.8564\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2292 - accuracy: 0.8918 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2251 - accuracy: 0.8918 - val_loss: 0.2667 - val_accuracy: 0.8615\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2277 - accuracy: 0.8940 - val_loss: 0.2819 - val_accuracy: 0.8564\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2315 - accuracy: 0.8896 - val_loss: 0.2888 - val_accuracy: 0.8564\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2279 - accuracy: 0.8918 - val_loss: 0.3032 - val_accuracy: 0.8564\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2282 - accuracy: 0.8918 - val_loss: 0.2727 - val_accuracy: 0.8667\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2305 - accuracy: 0.8918 - val_loss: 0.2707 - val_accuracy: 0.8667\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2242 - accuracy: 0.8940 - val_loss: 0.2993 - val_accuracy: 0.8564\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 0.2732 - val_accuracy: 0.8667\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.2688 - val_accuracy: 0.8718\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2271 - accuracy: 0.8918 - val_loss: 0.2772 - val_accuracy: 0.8564\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2261 - accuracy: 0.8918 - val_loss: 0.2701 - val_accuracy: 0.8667\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.2691 - val_accuracy: 0.8667\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2283 - accuracy: 0.8918 - val_loss: 0.2671 - val_accuracy: 0.8667\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2287 - accuracy: 0.8918 - val_loss: 0.2656 - val_accuracy: 0.8667\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.2777 - val_accuracy: 0.8667\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.3052 - val_accuracy: 0.8564\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2310 - accuracy: 0.8698 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2254 - accuracy: 0.8874 - val_loss: 0.2986 - val_accuracy: 0.8564\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2264 - accuracy: 0.8874 - val_loss: 0.2882 - val_accuracy: 0.8564\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2353 - accuracy: 0.8940 - val_loss: 0.2958 - val_accuracy: 0.8564\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2273 - accuracy: 0.8918 - val_loss: 0.2650 - val_accuracy: 0.8667\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.2743 - val_accuracy: 0.8667\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.2686 - val_accuracy: 0.8667\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 0.2699 - val_accuracy: 0.8718\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.2702 - val_accuracy: 0.8667\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2262 - accuracy: 0.8918 - val_loss: 0.2732 - val_accuracy: 0.8718\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2241 - accuracy: 0.8874 - val_loss: 0.2805 - val_accuracy: 0.8564\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.2700 - val_accuracy: 0.8718\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2236 - accuracy: 0.8896 - val_loss: 0.2778 - val_accuracy: 0.8564\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2242 - accuracy: 0.8918 - val_loss: 0.2755 - val_accuracy: 0.8564\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2255 - accuracy: 0.8874 - val_loss: 0.2925 - val_accuracy: 0.8564\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.2702 - val_accuracy: 0.8718\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2325 - accuracy: 0.8896 - val_loss: 0.2812 - val_accuracy: 0.8564\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.2842 - val_accuracy: 0.8564\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2249 - accuracy: 0.8896 - val_loss: 0.2781 - val_accuracy: 0.8564\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2268 - accuracy: 0.8896 - val_loss: 0.2738 - val_accuracy: 0.8564\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2243 - accuracy: 0.8918 - val_loss: 0.2703 - val_accuracy: 0.8718\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.2776 - val_accuracy: 0.8564\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2263 - accuracy: 0.8896 - val_loss: 0.2808 - val_accuracy: 0.8564\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2252 - accuracy: 0.8896 - val_loss: 0.2787 - val_accuracy: 0.8564\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2295 - accuracy: 0.8918 - val_loss: 0.2939 - val_accuracy: 0.8564\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2718 - val_accuracy: 0.8667\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.2990 - val_accuracy: 0.8564\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2283 - accuracy: 0.8918 - val_loss: 0.2814 - val_accuracy: 0.8615\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2263 - accuracy: 0.8896 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2244 - accuracy: 0.8874 - val_loss: 0.2678 - val_accuracy: 0.8667\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2254 - accuracy: 0.8852 - val_loss: 0.2693 - val_accuracy: 0.8718\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2268 - accuracy: 0.8918 - val_loss: 0.2832 - val_accuracy: 0.8564\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2255 - accuracy: 0.8896 - val_loss: 0.2975 - val_accuracy: 0.8564\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2250 - accuracy: 0.8896 - val_loss: 0.2807 - val_accuracy: 0.8564\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2231 - accuracy: 0.8830 - val_loss: 0.2709 - val_accuracy: 0.8718\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2884 - val_accuracy: 0.8564\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2258 - accuracy: 0.8918 - val_loss: 0.2691 - val_accuracy: 0.8718\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2861 - val_accuracy: 0.8564\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.2833 - val_accuracy: 0.8667\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2282 - accuracy: 0.8940 - val_loss: 0.2800 - val_accuracy: 0.8615\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2249 - accuracy: 0.8874 - val_loss: 0.2770 - val_accuracy: 0.8667\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2258 - accuracy: 0.8918 - val_loss: 0.2768 - val_accuracy: 0.8667\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.2778 - val_accuracy: 0.8564\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.2824 - val_accuracy: 0.8564\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2284 - accuracy: 0.8918 - val_loss: 0.2750 - val_accuracy: 0.8667\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2276 - accuracy: 0.8918 - val_loss: 0.2932 - val_accuracy: 0.8564\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.2854 - val_accuracy: 0.8564\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2280 - accuracy: 0.8918 - val_loss: 0.2906 - val_accuracy: 0.8564\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2712 - val_accuracy: 0.8564\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2302 - accuracy: 0.8918 - val_loss: 0.2693 - val_accuracy: 0.8718\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2240 - accuracy: 0.8918 - val_loss: 0.2661 - val_accuracy: 0.8769\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2282 - accuracy: 0.8918 - val_loss: 0.2868 - val_accuracy: 0.8564\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2275 - accuracy: 0.8918 - val_loss: 0.2774 - val_accuracy: 0.8667\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2289 - accuracy: 0.8896 - val_loss: 0.2829 - val_accuracy: 0.8564\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.2702 - val_accuracy: 0.8667\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.2782 - val_accuracy: 0.8564\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2252 - accuracy: 0.8918 - val_loss: 0.2846 - val_accuracy: 0.8564\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.2707 - val_accuracy: 0.8615\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2263 - accuracy: 0.8874 - val_loss: 0.2796 - val_accuracy: 0.8564\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2275 - accuracy: 0.8896 - val_loss: 0.2688 - val_accuracy: 0.8718\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.3175 - val_accuracy: 0.8564\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2283 - accuracy: 0.8918 - val_loss: 0.2709 - val_accuracy: 0.8667\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2797 - val_accuracy: 0.8667\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2220 - accuracy: 0.8852 - val_loss: 0.2826 - val_accuracy: 0.8564\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.2706 - val_accuracy: 0.8667\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2220 - accuracy: 0.8918 - val_loss: 0.2922 - val_accuracy: 0.8564\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2254 - accuracy: 0.8918 - val_loss: 0.2785 - val_accuracy: 0.8564\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.2687 - val_accuracy: 0.8769\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2352 - accuracy: 0.8874 - val_loss: 0.2746 - val_accuracy: 0.8718\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2285 - accuracy: 0.8896 - val_loss: 0.2956 - val_accuracy: 0.8564\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2253 - accuracy: 0.8918 - val_loss: 0.2973 - val_accuracy: 0.8564\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2284 - accuracy: 0.8918 - val_loss: 0.2785 - val_accuracy: 0.8564\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2249 - accuracy: 0.8874 - val_loss: 0.2698 - val_accuracy: 0.8769\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2233 - accuracy: 0.8896 - val_loss: 0.2740 - val_accuracy: 0.8667\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2245 - accuracy: 0.8896 - val_loss: 0.2740 - val_accuracy: 0.8667\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.2813 - val_accuracy: 0.8564\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2246 - accuracy: 0.8918 - val_loss: 0.2750 - val_accuracy: 0.8667\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2235 - accuracy: 0.8918 - val_loss: 0.2746 - val_accuracy: 0.8564\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2322 - accuracy: 0.8918 - val_loss: 0.3021 - val_accuracy: 0.8564\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2752 - val_accuracy: 0.8615\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.8896 - val_loss: 0.2903 - val_accuracy: 0.8615\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2288 - accuracy: 0.8896 - val_loss: 0.2996 - val_accuracy: 0.8564\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.2690 - val_accuracy: 0.8718\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2776 - val_accuracy: 0.8564\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.2793 - val_accuracy: 0.8667\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 115us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.2649 - val_accuracy: 0.8872\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2227 - accuracy: 0.8896 - val_loss: 0.2866 - val_accuracy: 0.8564\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2207 - accuracy: 0.8918 - val_loss: 0.2726 - val_accuracy: 0.8718\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2255 - accuracy: 0.8918 - val_loss: 0.2820 - val_accuracy: 0.8564\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2231 - accuracy: 0.8918 - val_loss: 0.2929 - val_accuracy: 0.8564\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2250 - accuracy: 0.8918 - val_loss: 0.2907 - val_accuracy: 0.8564\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.2826 - val_accuracy: 0.8615\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.2713 - val_accuracy: 0.8718\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2251 - accuracy: 0.8918 - val_loss: 0.2831 - val_accuracy: 0.8564\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2306 - accuracy: 0.8918 - val_loss: 0.3056 - val_accuracy: 0.8564\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.3158 - val_accuracy: 0.8564\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2224 - accuracy: 0.8918 - val_loss: 0.2757 - val_accuracy: 0.8667\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2283 - accuracy: 0.8896 - val_loss: 0.2732 - val_accuracy: 0.8821\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.2830 - val_accuracy: 0.8564\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2232 - accuracy: 0.8918 - val_loss: 0.2743 - val_accuracy: 0.8615\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.2836 - val_accuracy: 0.8564\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2263 - accuracy: 0.8918 - val_loss: 0.2900 - val_accuracy: 0.8410\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2282 - accuracy: 0.8896 - val_loss: 0.2989 - val_accuracy: 0.8564\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.2817 - val_accuracy: 0.8564\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2250 - accuracy: 0.8918 - val_loss: 0.2717 - val_accuracy: 0.8718\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.2854 - val_accuracy: 0.8564\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.2891 - val_accuracy: 0.8564\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2276 - accuracy: 0.8918 - val_loss: 0.2744 - val_accuracy: 0.8564\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2253 - accuracy: 0.8918 - val_loss: 0.2703 - val_accuracy: 0.8769\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2210 - accuracy: 0.8896 - val_loss: 0.2915 - val_accuracy: 0.8564\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2234 - accuracy: 0.8918 - val_loss: 0.3018 - val_accuracy: 0.8564\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.2735 - val_accuracy: 0.8615\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2238 - accuracy: 0.8896 - val_loss: 0.3017 - val_accuracy: 0.8564\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2250 - accuracy: 0.8918 - val_loss: 0.2824 - val_accuracy: 0.8564\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.2899 - val_accuracy: 0.8564\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2234 - accuracy: 0.8896 - val_loss: 0.2772 - val_accuracy: 0.8615\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.2982 - val_accuracy: 0.8564\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2293 - accuracy: 0.8609 - val_loss: 0.2840 - val_accuracy: 0.8821\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2330 - accuracy: 0.8896 - val_loss: 0.2819 - val_accuracy: 0.8564\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.2890 - val_accuracy: 0.8564\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2256 - accuracy: 0.8896 - val_loss: 0.3164 - val_accuracy: 0.8564\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2318 - accuracy: 0.8918 - val_loss: 0.2799 - val_accuracy: 0.8564\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.2955 - val_accuracy: 0.8564\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2261 - accuracy: 0.8918 - val_loss: 0.2882 - val_accuracy: 0.8564\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.2836 - val_accuracy: 0.8615\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2344 - accuracy: 0.8918 - val_loss: 0.3172 - val_accuracy: 0.8564\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2200 - accuracy: 0.8918 - val_loss: 0.2707 - val_accuracy: 0.8718\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.2789 - val_accuracy: 0.8564\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.2751 - val_accuracy: 0.8718\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2241 - accuracy: 0.8918 - val_loss: 0.2889 - val_accuracy: 0.8564\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2207 - accuracy: 0.8918 - val_loss: 0.2810 - val_accuracy: 0.8564\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2249 - accuracy: 0.8918 - val_loss: 0.3030 - val_accuracy: 0.8564\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2254 - accuracy: 0.8918 - val_loss: 0.2754 - val_accuracy: 0.8564\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2254 - accuracy: 0.8918 - val_loss: 0.2863 - val_accuracy: 0.8564\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.2808 - val_accuracy: 0.8564\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2293 - accuracy: 0.8896 - val_loss: 0.3105 - val_accuracy: 0.8564\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2281 - accuracy: 0.8940 - val_loss: 0.2995 - val_accuracy: 0.8564\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2733 - val_accuracy: 0.8718\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2232 - accuracy: 0.8918 - val_loss: 0.3014 - val_accuracy: 0.8564\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2750 - val_accuracy: 0.8718\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2260 - accuracy: 0.8940 - val_loss: 0.2796 - val_accuracy: 0.8667\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2246 - accuracy: 0.8874 - val_loss: 0.2721 - val_accuracy: 0.8718\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 0.2867 - val_accuracy: 0.8564\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2246 - accuracy: 0.8940 - val_loss: 0.2958 - val_accuracy: 0.8564\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2267 - accuracy: 0.8918 - val_loss: 0.2770 - val_accuracy: 0.8615\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2257 - accuracy: 0.8896 - val_loss: 0.2716 - val_accuracy: 0.8718\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3120 - val_accuracy: 0.8564\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.2725 - val_accuracy: 0.8718\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2225 - accuracy: 0.8940 - val_loss: 0.3122 - val_accuracy: 0.8564\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2292 - accuracy: 0.8918 - val_loss: 0.2744 - val_accuracy: 0.8718\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.2789 - val_accuracy: 0.8615\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2242 - accuracy: 0.8918 - val_loss: 0.2868 - val_accuracy: 0.8564\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2274 - accuracy: 0.8852 - val_loss: 0.2988 - val_accuracy: 0.8564\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2291 - accuracy: 0.8918 - val_loss: 0.2798 - val_accuracy: 0.8718\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2237 - accuracy: 0.8896 - val_loss: 0.2833 - val_accuracy: 0.8564\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.2771 - val_accuracy: 0.8718\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2231 - accuracy: 0.8918 - val_loss: 0.2711 - val_accuracy: 0.8769\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2266 - accuracy: 0.8918 - val_loss: 0.3024 - val_accuracy: 0.8564\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2252 - accuracy: 0.8918 - val_loss: 0.2699 - val_accuracy: 0.8923\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.2941 - val_accuracy: 0.8564\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2232 - accuracy: 0.8918 - val_loss: 0.2798 - val_accuracy: 0.8564\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2286 - accuracy: 0.8830 - val_loss: 0.3113 - val_accuracy: 0.8564\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2325 - accuracy: 0.8918 - val_loss: 0.3025 - val_accuracy: 0.8564\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2350 - accuracy: 0.8896 - val_loss: 0.2743 - val_accuracy: 0.8923\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2313 - accuracy: 0.8918 - val_loss: 0.2763 - val_accuracy: 0.8615\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.2811 - val_accuracy: 0.8564\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2773 - val_accuracy: 0.8718\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2238 - accuracy: 0.8896 - val_loss: 0.2791 - val_accuracy: 0.8615\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2226 - accuracy: 0.8918 - val_loss: 0.2797 - val_accuracy: 0.8615\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2221 - accuracy: 0.8918 - val_loss: 0.2857 - val_accuracy: 0.8564\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.2753 - val_accuracy: 0.8718\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2241 - accuracy: 0.8918 - val_loss: 0.2765 - val_accuracy: 0.8718\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2220 - accuracy: 0.8874 - val_loss: 0.2995 - val_accuracy: 0.8564\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2247 - accuracy: 0.8918 - val_loss: 0.2814 - val_accuracy: 0.8564\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2942 - val_accuracy: 0.8564\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2208 - accuracy: 0.8918 - val_loss: 0.2859 - val_accuracy: 0.8564\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.2867 - val_accuracy: 0.8564\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.2794 - val_accuracy: 0.8615\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2258 - accuracy: 0.8962 - val_loss: 0.2936 - val_accuracy: 0.8564\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2230 - accuracy: 0.8896 - val_loss: 0.2785 - val_accuracy: 0.8718\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2218 - accuracy: 0.8918 - val_loss: 0.2968 - val_accuracy: 0.8564\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.2888 - val_accuracy: 0.8564\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2271 - accuracy: 0.8896 - val_loss: 0.2928 - val_accuracy: 0.8564\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2890 - val_accuracy: 0.8615\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2256 - accuracy: 0.8918 - val_loss: 0.2837 - val_accuracy: 0.8564\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2271 - accuracy: 0.8918 - val_loss: 0.3081 - val_accuracy: 0.8564\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2251 - accuracy: 0.8918 - val_loss: 0.2823 - val_accuracy: 0.8564\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2216 - accuracy: 0.8918 - val_loss: 0.2975 - val_accuracy: 0.8564\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2849 - val_accuracy: 0.8615\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.2690 - val_accuracy: 0.8872\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2268 - accuracy: 0.8852 - val_loss: 0.3110 - val_accuracy: 0.8564\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2270 - accuracy: 0.8918 - val_loss: 0.2882 - val_accuracy: 0.8564\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2252 - accuracy: 0.8918 - val_loss: 0.3137 - val_accuracy: 0.8564\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2226 - accuracy: 0.8918 - val_loss: 0.2882 - val_accuracy: 0.8667\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 113us/step - loss: 0.2284 - accuracy: 0.8918 - val_loss: 0.3011 - val_accuracy: 0.8564\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2223 - accuracy: 0.8896 - val_loss: 0.2851 - val_accuracy: 0.8615\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2246 - accuracy: 0.8918 - val_loss: 0.2760 - val_accuracy: 0.8718\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2252 - accuracy: 0.8940 - val_loss: 0.2867 - val_accuracy: 0.8564\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.2804 - val_accuracy: 0.8615\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2229 - accuracy: 0.8896 - val_loss: 0.2808 - val_accuracy: 0.8615\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2281 - accuracy: 0.8918 - val_loss: 0.2765 - val_accuracy: 0.8718\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2194 - accuracy: 0.8940 - val_loss: 0.2923 - val_accuracy: 0.8564\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2227 - accuracy: 0.8874 - val_loss: 0.2770 - val_accuracy: 0.8615\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2276 - accuracy: 0.8918 - val_loss: 0.2850 - val_accuracy: 0.8615\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.3008 - val_accuracy: 0.8564\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.2782 - val_accuracy: 0.8769\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2289 - accuracy: 0.8918 - val_loss: 0.2794 - val_accuracy: 0.8615\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2298 - accuracy: 0.8918 - val_loss: 0.3088 - val_accuracy: 0.8564\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.2766 - val_accuracy: 0.8769\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.2911 - val_accuracy: 0.8564\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.2893 - val_accuracy: 0.8564\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2275 - accuracy: 0.8918 - val_loss: 0.2825 - val_accuracy: 0.8615\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.8918 - val_loss: 0.2941 - val_accuracy: 0.8564\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.2918 - val_accuracy: 0.8564\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2963 - val_accuracy: 0.8564\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.2778 - val_accuracy: 0.8718\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2236 - accuracy: 0.8940 - val_loss: 0.3227 - val_accuracy: 0.8564\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2295 - accuracy: 0.8918 - val_loss: 0.2863 - val_accuracy: 0.8667\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2893 - val_accuracy: 0.8615\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.2735 - val_accuracy: 0.8821\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2259 - accuracy: 0.8874 - val_loss: 0.2897 - val_accuracy: 0.8615\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.2772 - val_accuracy: 0.8769\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2267 - accuracy: 0.8896 - val_loss: 0.3061 - val_accuracy: 0.8564\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2278 - accuracy: 0.8918 - val_loss: 0.3047 - val_accuracy: 0.8564\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.2979 - val_accuracy: 0.8564\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2238 - accuracy: 0.8918 - val_loss: 0.2817 - val_accuracy: 0.8615\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.2810 - val_accuracy: 0.8615\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2201 - accuracy: 0.8918 - val_loss: 0.2788 - val_accuracy: 0.8718\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.2931 - val_accuracy: 0.8564\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2229 - accuracy: 0.8874 - val_loss: 0.2818 - val_accuracy: 0.8615\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2254 - accuracy: 0.8918 - val_loss: 0.3004 - val_accuracy: 0.8564\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2251 - accuracy: 0.8918 - val_loss: 0.2852 - val_accuracy: 0.8615\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2211 - accuracy: 0.8874 - val_loss: 0.2855 - val_accuracy: 0.8615\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.3038 - val_accuracy: 0.8564\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.2886 - val_accuracy: 0.8615\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2253 - accuracy: 0.8918 - val_loss: 0.2955 - val_accuracy: 0.8615\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2229 - accuracy: 0.8962 - val_loss: 0.2877 - val_accuracy: 0.8615\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2239 - accuracy: 0.8874 - val_loss: 0.2814 - val_accuracy: 0.8615\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2830 - val_accuracy: 0.8615\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 0.2938 - val_accuracy: 0.8564\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2202 - accuracy: 0.8918 - val_loss: 0.2760 - val_accuracy: 0.8718\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2216 - accuracy: 0.8852 - val_loss: 0.3140 - val_accuracy: 0.8564\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2825 - val_accuracy: 0.8615\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3071 - val_accuracy: 0.8564\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2218 - accuracy: 0.8918 - val_loss: 0.2785 - val_accuracy: 0.8718\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.2847 - val_accuracy: 0.8615\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2235 - accuracy: 0.8896 - val_loss: 0.2907 - val_accuracy: 0.8615\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.8896 - val_loss: 0.3031 - val_accuracy: 0.8564\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2788 - val_accuracy: 0.8718\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2263 - accuracy: 0.8918 - val_loss: 0.2795 - val_accuracy: 0.8615\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2244 - accuracy: 0.8940 - val_loss: 0.2988 - val_accuracy: 0.8564\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.2746 - val_accuracy: 0.8718\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2269 - accuracy: 0.8918 - val_loss: 0.2764 - val_accuracy: 0.8718\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2268 - accuracy: 0.8918 - val_loss: 0.2798 - val_accuracy: 0.8718\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2940 - val_accuracy: 0.8615\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2226 - accuracy: 0.8852 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2226 - accuracy: 0.8874 - val_loss: 0.2888 - val_accuracy: 0.8564\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.3006 - val_accuracy: 0.8615\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.2864 - val_accuracy: 0.8615\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.2795 - val_accuracy: 0.8615\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2235 - accuracy: 0.8940 - val_loss: 0.2971 - val_accuracy: 0.8564\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2235 - accuracy: 0.8918 - val_loss: 0.2894 - val_accuracy: 0.8615\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2228 - accuracy: 0.8852 - val_loss: 0.2778 - val_accuracy: 0.8769\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2867 - val_accuracy: 0.8615\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.2870 - val_accuracy: 0.8615\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2208 - accuracy: 0.8918 - val_loss: 0.2866 - val_accuracy: 0.8615\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2204 - accuracy: 0.8918 - val_loss: 0.2799 - val_accuracy: 0.8718\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2233 - accuracy: 0.8830 - val_loss: 0.2849 - val_accuracy: 0.8615\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2252 - accuracy: 0.8918 - val_loss: 0.2998 - val_accuracy: 0.8564\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.2884 - val_accuracy: 0.8564\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2245 - accuracy: 0.8896 - val_loss: 0.2942 - val_accuracy: 0.8564\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2239 - accuracy: 0.8940 - val_loss: 0.3053 - val_accuracy: 0.8564\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2173 - accuracy: 0.8918 - val_loss: 0.2840 - val_accuracy: 0.8718\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2869 - val_accuracy: 0.8615\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2193 - accuracy: 0.8852 - val_loss: 0.2998 - val_accuracy: 0.8564\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.2854 - val_accuracy: 0.8615\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2256 - accuracy: 0.8896 - val_loss: 0.2896 - val_accuracy: 0.8615\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2260 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8615\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2268 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8667\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.2778 - val_accuracy: 0.8615\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2262 - accuracy: 0.8896 - val_loss: 0.2786 - val_accuracy: 0.8667\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.2833 - val_accuracy: 0.8564\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2264 - accuracy: 0.8918 - val_loss: 0.3007 - val_accuracy: 0.8564\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2222 - accuracy: 0.8874 - val_loss: 0.2962 - val_accuracy: 0.8615\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2899 - val_accuracy: 0.8615\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2256 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8615\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2221 - accuracy: 0.8918 - val_loss: 0.2867 - val_accuracy: 0.8615\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.2802 - val_accuracy: 0.8718\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2955 - val_accuracy: 0.8615\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2869 - val_accuracy: 0.8615\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2226 - accuracy: 0.8918 - val_loss: 0.2804 - val_accuracy: 0.8769\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.2999 - val_accuracy: 0.8564\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8615\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2222 - accuracy: 0.8918 - val_loss: 0.2807 - val_accuracy: 0.8718\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2267 - accuracy: 0.8940 - val_loss: 0.2957 - val_accuracy: 0.8564\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2940 - val_accuracy: 0.8615\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2250 - accuracy: 0.8874 - val_loss: 0.2770 - val_accuracy: 0.8667\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2376 - accuracy: 0.8786 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.2917 - val_accuracy: 0.8564\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2893 - val_accuracy: 0.8564\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 115us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.3019 - val_accuracy: 0.8564\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2253 - accuracy: 0.8918 - val_loss: 0.3032 - val_accuracy: 0.8564\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8615\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.2989 - val_accuracy: 0.8564\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2240 - accuracy: 0.8918 - val_loss: 0.2967 - val_accuracy: 0.8564\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.3019 - val_accuracy: 0.8564\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2251 - accuracy: 0.8918 - val_loss: 0.2853 - val_accuracy: 0.8615\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2196 - accuracy: 0.8918 - val_loss: 0.3030 - val_accuracy: 0.8564\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2244 - accuracy: 0.8830 - val_loss: 0.2925 - val_accuracy: 0.8564\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2224 - accuracy: 0.8918 - val_loss: 0.2921 - val_accuracy: 0.8564\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2220 - accuracy: 0.8918 - val_loss: 0.2853 - val_accuracy: 0.8718\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2192 - accuracy: 0.8918 - val_loss: 0.2999 - val_accuracy: 0.8615\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2221 - accuracy: 0.8918 - val_loss: 0.2869 - val_accuracy: 0.8615\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2202 - accuracy: 0.8896 - val_loss: 0.2881 - val_accuracy: 0.8615\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3003 - val_accuracy: 0.8615\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2224 - accuracy: 0.8918 - val_loss: 0.2875 - val_accuracy: 0.8615\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2190 - accuracy: 0.8918 - val_loss: 0.2910 - val_accuracy: 0.8615\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2940 - val_accuracy: 0.8615\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2196 - accuracy: 0.8918 - val_loss: 0.2882 - val_accuracy: 0.8615\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2903 - val_accuracy: 0.8615\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2956 - val_accuracy: 0.8615\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.3012 - val_accuracy: 0.8564\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2243 - accuracy: 0.8896 - val_loss: 0.2857 - val_accuracy: 0.8615\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2249 - accuracy: 0.8918 - val_loss: 0.2858 - val_accuracy: 0.8615\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2196 - accuracy: 0.8918 - val_loss: 0.2870 - val_accuracy: 0.8564\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2219 - accuracy: 0.8896 - val_loss: 0.2887 - val_accuracy: 0.8564\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2201 - accuracy: 0.8918 - val_loss: 0.2876 - val_accuracy: 0.8667\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.2964 - val_accuracy: 0.8564\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.2949 - val_accuracy: 0.8564\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.2925 - val_accuracy: 0.8564\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2273 - accuracy: 0.8896 - val_loss: 0.3214 - val_accuracy: 0.8564\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2859 - val_accuracy: 0.8615\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2224 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8615\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2221 - accuracy: 0.8940 - val_loss: 0.3068 - val_accuracy: 0.8564\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2232 - accuracy: 0.8896 - val_loss: 0.2837 - val_accuracy: 0.8667\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.3018 - val_accuracy: 0.8564\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3092 - val_accuracy: 0.8564\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2251 - accuracy: 0.8896 - val_loss: 0.2876 - val_accuracy: 0.8615\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2249 - accuracy: 0.8874 - val_loss: 0.2964 - val_accuracy: 0.8564\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2891 - val_accuracy: 0.8718\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2210 - accuracy: 0.8918 - val_loss: 0.3041 - val_accuracy: 0.8564\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2254 - accuracy: 0.8940 - val_loss: 0.2976 - val_accuracy: 0.8564\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2231 - accuracy: 0.8874 - val_loss: 0.2933 - val_accuracy: 0.8615\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2257 - accuracy: 0.8896 - val_loss: 0.3017 - val_accuracy: 0.8615\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2207 - accuracy: 0.8918 - val_loss: 0.2900 - val_accuracy: 0.8615\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2210 - accuracy: 0.8896 - val_loss: 0.2968 - val_accuracy: 0.8615\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2230 - accuracy: 0.8918 - val_loss: 0.2792 - val_accuracy: 0.8615\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2229 - accuracy: 0.8918 - val_loss: 0.3065 - val_accuracy: 0.8564\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.2896 - val_accuracy: 0.8615\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2289 - accuracy: 0.8918 - val_loss: 0.3053 - val_accuracy: 0.8564\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3013 - val_accuracy: 0.8615\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2250 - accuracy: 0.8918 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2200 - accuracy: 0.8918 - val_loss: 0.2935 - val_accuracy: 0.8615\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2313 - accuracy: 0.8918 - val_loss: 0.2886 - val_accuracy: 0.8615\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2208 - accuracy: 0.8918 - val_loss: 0.2905 - val_accuracy: 0.8615\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2950 - val_accuracy: 0.8564\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2885 - val_accuracy: 0.8615\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2227 - accuracy: 0.8896 - val_loss: 0.3041 - val_accuracy: 0.8564\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2983 - val_accuracy: 0.8564\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2211 - accuracy: 0.8896 - val_loss: 0.2853 - val_accuracy: 0.8769\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2289 - accuracy: 0.8896 - val_loss: 0.3258 - val_accuracy: 0.8564\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.2889 - val_accuracy: 0.8564\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2250 - accuracy: 0.8918 - val_loss: 0.2934 - val_accuracy: 0.8564\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2209 - accuracy: 0.8874 - val_loss: 0.3183 - val_accuracy: 0.8564\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2297 - accuracy: 0.8918 - val_loss: 0.3055 - val_accuracy: 0.8564\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2210 - accuracy: 0.8918 - val_loss: 0.2981 - val_accuracy: 0.8564\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2220 - accuracy: 0.8918 - val_loss: 0.2944 - val_accuracy: 0.8564\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2921 - val_accuracy: 0.8564\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2235 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8718\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2220 - accuracy: 0.8896 - val_loss: 0.2916 - val_accuracy: 0.8564\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2196 - accuracy: 0.8918 - val_loss: 0.3064 - val_accuracy: 0.8564\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2220 - accuracy: 0.8918 - val_loss: 0.2862 - val_accuracy: 0.8718\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2263 - accuracy: 0.8962 - val_loss: 0.2993 - val_accuracy: 0.8564\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2200 - accuracy: 0.8940 - val_loss: 0.3008 - val_accuracy: 0.8564\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2275 - accuracy: 0.8918 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2295 - accuracy: 0.8940 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2234 - accuracy: 0.8940 - val_loss: 0.3119 - val_accuracy: 0.8564\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2229 - accuracy: 0.8918 - val_loss: 0.3006 - val_accuracy: 0.8564\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2271 - accuracy: 0.8940 - val_loss: 0.3026 - val_accuracy: 0.8564\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2229 - accuracy: 0.8918 - val_loss: 0.3050 - val_accuracy: 0.8564\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3182 - val_accuracy: 0.8564\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.2978 - val_accuracy: 0.8564\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2978 - val_accuracy: 0.8564\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2259 - accuracy: 0.8918 - val_loss: 0.2870 - val_accuracy: 0.8718\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.3085 - val_accuracy: 0.8564\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2243 - accuracy: 0.8830 - val_loss: 0.2954 - val_accuracy: 0.8564\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2202 - accuracy: 0.8918 - val_loss: 0.3013 - val_accuracy: 0.8564\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.8918 - val_loss: 0.2749 - val_accuracy: 0.8718\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2246 - accuracy: 0.8940 - val_loss: 0.2976 - val_accuracy: 0.8564\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2297 - accuracy: 0.8918 - val_loss: 0.2945 - val_accuracy: 0.8564\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2243 - accuracy: 0.8918 - val_loss: 0.2890 - val_accuracy: 0.8564\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2215 - accuracy: 0.8896 - val_loss: 0.2963 - val_accuracy: 0.8564\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2249 - accuracy: 0.8786 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2294 - accuracy: 0.8918 - val_loss: 0.3043 - val_accuracy: 0.8564\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2229 - accuracy: 0.8874 - val_loss: 0.2961 - val_accuracy: 0.8564\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.3086 - val_accuracy: 0.8564\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2218 - accuracy: 0.8918 - val_loss: 0.2980 - val_accuracy: 0.8564\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2275 - accuracy: 0.8896 - val_loss: 0.3158 - val_accuracy: 0.8564\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.2889 - val_accuracy: 0.8564\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8564\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.2870 - val_accuracy: 0.8564\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2234 - accuracy: 0.8918 - val_loss: 0.3018 - val_accuracy: 0.8564\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2221 - accuracy: 0.8918 - val_loss: 0.2999 - val_accuracy: 0.8615\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.2971 - val_accuracy: 0.8615\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2186 - accuracy: 0.8918 - val_loss: 0.2906 - val_accuracy: 0.8615\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2253 - accuracy: 0.8918 - val_loss: 0.2917 - val_accuracy: 0.8615\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.3123 - val_accuracy: 0.8615\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2201 - accuracy: 0.8918 - val_loss: 0.2874 - val_accuracy: 0.8615\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 111us/step - loss: 0.2211 - accuracy: 0.8896 - val_loss: 0.3074 - val_accuracy: 0.8615\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2279 - accuracy: 0.8918 - val_loss: 0.2955 - val_accuracy: 0.8615\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2216 - accuracy: 0.8918 - val_loss: 0.2868 - val_accuracy: 0.8615\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.3009 - val_accuracy: 0.8615\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2285 - accuracy: 0.8918 - val_loss: 0.3006 - val_accuracy: 0.8615\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2199 - accuracy: 0.8896 - val_loss: 0.2936 - val_accuracy: 0.8615\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 0.3103 - val_accuracy: 0.8564\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2240 - accuracy: 0.8918 - val_loss: 0.2907 - val_accuracy: 0.8615\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2210 - accuracy: 0.8918 - val_loss: 0.3048 - val_accuracy: 0.8564\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.3010 - val_accuracy: 0.8564\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2238 - accuracy: 0.8940 - val_loss: 0.3090 - val_accuracy: 0.8564\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2295 - accuracy: 0.8918 - val_loss: 0.2953 - val_accuracy: 0.8615\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.2908 - val_accuracy: 0.8564\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2174 - accuracy: 0.8918 - val_loss: 0.3155 - val_accuracy: 0.8564\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2212 - accuracy: 0.8896 - val_loss: 0.3084 - val_accuracy: 0.8564\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2198 - accuracy: 0.8896 - val_loss: 0.3083 - val_accuracy: 0.8564\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2226 - accuracy: 0.8918 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.2905 - val_accuracy: 0.8564\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2209 - accuracy: 0.8940 - val_loss: 0.3110 - val_accuracy: 0.8564\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2266 - accuracy: 0.8918 - val_loss: 0.3164 - val_accuracy: 0.8564\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.2906 - val_accuracy: 0.8615\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2210 - accuracy: 0.8940 - val_loss: 0.3051 - val_accuracy: 0.8564\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2193 - accuracy: 0.8918 - val_loss: 0.3004 - val_accuracy: 0.8564\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2230 - accuracy: 0.8874 - val_loss: 0.2924 - val_accuracy: 0.8564\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2204 - accuracy: 0.8940 - val_loss: 0.2918 - val_accuracy: 0.8564\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2188 - accuracy: 0.8852 - val_loss: 0.2915 - val_accuracy: 0.8564\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2236 - accuracy: 0.8940 - val_loss: 0.3052 - val_accuracy: 0.8564\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2318 - accuracy: 0.8698 - val_loss: 0.2859 - val_accuracy: 0.8667\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2219 - accuracy: 0.8874 - val_loss: 0.2885 - val_accuracy: 0.8667\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2194 - accuracy: 0.8852 - val_loss: 0.2879 - val_accuracy: 0.8667\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2222 - accuracy: 0.8918 - val_loss: 0.3070 - val_accuracy: 0.8564\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2199 - accuracy: 0.8918 - val_loss: 0.2978 - val_accuracy: 0.8615\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.2953 - val_accuracy: 0.8615\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3048 - val_accuracy: 0.8564\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2213 - accuracy: 0.8896 - val_loss: 0.2923 - val_accuracy: 0.8718\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2208 - accuracy: 0.8918 - val_loss: 0.2895 - val_accuracy: 0.8718\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2243 - accuracy: 0.8852 - val_loss: 0.3155 - val_accuracy: 0.8564\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2998 - val_accuracy: 0.8615\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2219 - accuracy: 0.8940 - val_loss: 0.3032 - val_accuracy: 0.8615\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2221 - accuracy: 0.8874 - val_loss: 0.3033 - val_accuracy: 0.8564\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.3088 - val_accuracy: 0.8564\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2195 - accuracy: 0.8918 - val_loss: 0.2990 - val_accuracy: 0.8564\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.2974 - val_accuracy: 0.8615\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2195 - accuracy: 0.8918 - val_loss: 0.2914 - val_accuracy: 0.8615\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2206 - accuracy: 0.8918 - val_loss: 0.2979 - val_accuracy: 0.8615\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.3002 - val_accuracy: 0.8564\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2221 - accuracy: 0.8918 - val_loss: 0.3104 - val_accuracy: 0.8564\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2206 - accuracy: 0.8808 - val_loss: 0.2890 - val_accuracy: 0.8769\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.2977 - val_accuracy: 0.8564\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2247 - accuracy: 0.8918 - val_loss: 0.3001 - val_accuracy: 0.8615\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.2903 - val_accuracy: 0.8718\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2219 - accuracy: 0.8940 - val_loss: 0.2956 - val_accuracy: 0.8615\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2192 - accuracy: 0.8940 - val_loss: 0.3010 - val_accuracy: 0.8615\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.2969 - val_accuracy: 0.8615\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.2938 - val_accuracy: 0.8615\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2212 - accuracy: 0.8896 - val_loss: 0.3118 - val_accuracy: 0.8615\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.3003 - val_accuracy: 0.8615\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2231 - accuracy: 0.8896 - val_loss: 0.2976 - val_accuracy: 0.8615\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2204 - accuracy: 0.8918 - val_loss: 0.2868 - val_accuracy: 0.8718\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.2967 - val_accuracy: 0.8615\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2200 - accuracy: 0.8874 - val_loss: 0.2982 - val_accuracy: 0.8615\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2189 - accuracy: 0.8918 - val_loss: 0.2937 - val_accuracy: 0.8615\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2197 - accuracy: 0.8940 - val_loss: 0.2994 - val_accuracy: 0.8615\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2221 - accuracy: 0.8940 - val_loss: 0.2999 - val_accuracy: 0.8615\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2219 - accuracy: 0.8940 - val_loss: 0.3188 - val_accuracy: 0.8615\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2936 - val_accuracy: 0.8615\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 0.2967 - val_accuracy: 0.8615\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2216 - accuracy: 0.8896 - val_loss: 0.2922 - val_accuracy: 0.8615\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2209 - accuracy: 0.8874 - val_loss: 0.2982 - val_accuracy: 0.8615\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2227 - accuracy: 0.8896 - val_loss: 0.2925 - val_accuracy: 0.8615\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2218 - accuracy: 0.8940 - val_loss: 0.2929 - val_accuracy: 0.8615\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2194 - accuracy: 0.8940 - val_loss: 0.2894 - val_accuracy: 0.8615\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3053 - val_accuracy: 0.8615\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2183 - accuracy: 0.8918 - val_loss: 0.2918 - val_accuracy: 0.8718\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2189 - accuracy: 0.8940 - val_loss: 0.2927 - val_accuracy: 0.8615\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2177 - accuracy: 0.8918 - val_loss: 0.2986 - val_accuracy: 0.8615\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2185 - accuracy: 0.8918 - val_loss: 0.2982 - val_accuracy: 0.8615\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2253 - accuracy: 0.8896 - val_loss: 0.3088 - val_accuracy: 0.8615\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2209 - accuracy: 0.8940 - val_loss: 0.2929 - val_accuracy: 0.8615\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2215 - accuracy: 0.8918 - val_loss: 0.2956 - val_accuracy: 0.8615\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2206 - accuracy: 0.8940 - val_loss: 0.3128 - val_accuracy: 0.8615\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2242 - accuracy: 0.8918 - val_loss: 0.3080 - val_accuracy: 0.8615\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2227 - accuracy: 0.8896 - val_loss: 0.3049 - val_accuracy: 0.8615\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2236 - accuracy: 0.8874 - val_loss: 0.3164 - val_accuracy: 0.8615\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.2975 - val_accuracy: 0.8615\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2220 - accuracy: 0.8940 - val_loss: 0.3032 - val_accuracy: 0.8615\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2196 - accuracy: 0.8896 - val_loss: 0.2883 - val_accuracy: 0.8769\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.2937 - val_accuracy: 0.8667\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2210 - accuracy: 0.8896 - val_loss: 0.3007 - val_accuracy: 0.8615\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.2920 - val_accuracy: 0.8718\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2230 - accuracy: 0.8940 - val_loss: 0.2973 - val_accuracy: 0.8615\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.2971 - val_accuracy: 0.8615\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.2980 - val_accuracy: 0.8615\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3034 - val_accuracy: 0.8615\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2204 - accuracy: 0.8940 - val_loss: 0.3066 - val_accuracy: 0.8564\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.2957 - val_accuracy: 0.8615\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.2930 - val_accuracy: 0.8667\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2199 - accuracy: 0.8874 - val_loss: 0.2957 - val_accuracy: 0.8615\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.3035 - val_accuracy: 0.8615\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2281 - accuracy: 0.8742 - val_loss: 0.3169 - val_accuracy: 0.8564\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2894 - val_accuracy: 0.8718\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2220 - accuracy: 0.8918 - val_loss: 0.3021 - val_accuracy: 0.8564\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2218 - accuracy: 0.8896 - val_loss: 0.3069 - val_accuracy: 0.8564\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.2969 - val_accuracy: 0.8615\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.3076 - val_accuracy: 0.8564\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 137us/step - loss: 0.2275 - accuracy: 0.8918 - val_loss: 0.2968 - val_accuracy: 0.8564\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2993 - val_accuracy: 0.8615\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.3129 - val_accuracy: 0.8564\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.2931 - val_accuracy: 0.8615\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.3031 - val_accuracy: 0.8564\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2190 - accuracy: 0.8940 - val_loss: 0.3017 - val_accuracy: 0.8564\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2189 - accuracy: 0.8918 - val_loss: 0.3022 - val_accuracy: 0.8564\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2228 - accuracy: 0.8896 - val_loss: 0.3171 - val_accuracy: 0.8564\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2294 - accuracy: 0.8918 - val_loss: 0.2932 - val_accuracy: 0.8718\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2191 - accuracy: 0.8918 - val_loss: 0.3120 - val_accuracy: 0.8564\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.2920 - val_accuracy: 0.8718\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2210 - accuracy: 0.8874 - val_loss: 0.3089 - val_accuracy: 0.8564\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2243 - accuracy: 0.8940 - val_loss: 0.2945 - val_accuracy: 0.8667\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2230 - accuracy: 0.8940 - val_loss: 0.3061 - val_accuracy: 0.8615\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2234 - accuracy: 0.8962 - val_loss: 0.3168 - val_accuracy: 0.8564\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2261 - accuracy: 0.8896 - val_loss: 0.3100 - val_accuracy: 0.8564\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2319 - accuracy: 0.8587 - val_loss: 0.2953 - val_accuracy: 0.8615\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2211 - accuracy: 0.8940 - val_loss: 0.3167 - val_accuracy: 0.8564\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2271 - accuracy: 0.8940 - val_loss: 0.3079 - val_accuracy: 0.8564\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.2967 - val_accuracy: 0.8564\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2225 - accuracy: 0.8940 - val_loss: 0.3011 - val_accuracy: 0.8667\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.2978 - val_accuracy: 0.8615\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.2999 - val_accuracy: 0.8615\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2198 - accuracy: 0.8874 - val_loss: 0.3167 - val_accuracy: 0.8564\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2209 - accuracy: 0.8896 - val_loss: 0.3156 - val_accuracy: 0.8615\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2226 - accuracy: 0.8896 - val_loss: 0.3061 - val_accuracy: 0.8615\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2898 - val_accuracy: 0.8718\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2291 - accuracy: 0.8940 - val_loss: 0.3045 - val_accuracy: 0.8615\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2301 - accuracy: 0.8940 - val_loss: 0.3009 - val_accuracy: 0.8615\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2208 - accuracy: 0.8918 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2204 - accuracy: 0.8940 - val_loss: 0.3041 - val_accuracy: 0.8615\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2192 - accuracy: 0.8852 - val_loss: 0.2915 - val_accuracy: 0.8615\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2190 - accuracy: 0.8940 - val_loss: 0.3025 - val_accuracy: 0.8615\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2191 - accuracy: 0.8896 - val_loss: 0.2920 - val_accuracy: 0.8718\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2212 - accuracy: 0.8940 - val_loss: 0.2946 - val_accuracy: 0.8615\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.2883 - val_accuracy: 0.8821\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2343 - accuracy: 0.8896 - val_loss: 0.3032 - val_accuracy: 0.8615\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2215 - accuracy: 0.8896 - val_loss: 0.2944 - val_accuracy: 0.8615\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2198 - accuracy: 0.8940 - val_loss: 0.3061 - val_accuracy: 0.8615\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2244 - accuracy: 0.8940 - val_loss: 0.3008 - val_accuracy: 0.8615\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2215 - accuracy: 0.8874 - val_loss: 0.2913 - val_accuracy: 0.8667\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2189 - accuracy: 0.8962 - val_loss: 0.2938 - val_accuracy: 0.8615\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2190 - accuracy: 0.8918 - val_loss: 0.2918 - val_accuracy: 0.8615\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2203 - accuracy: 0.8896 - val_loss: 0.3013 - val_accuracy: 0.8615\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2217 - accuracy: 0.8940 - val_loss: 0.3051 - val_accuracy: 0.8615\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2215 - accuracy: 0.8918 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2189 - accuracy: 0.8940 - val_loss: 0.3045 - val_accuracy: 0.8615\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2238 - accuracy: 0.8852 - val_loss: 0.3000 - val_accuracy: 0.8615\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2277 - accuracy: 0.8940 - val_loss: 0.2901 - val_accuracy: 0.8718\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2269 - accuracy: 0.8940 - val_loss: 0.2921 - val_accuracy: 0.8615\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2223 - accuracy: 0.8940 - val_loss: 0.2901 - val_accuracy: 0.8615\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2223 - accuracy: 0.8874 - val_loss: 0.3023 - val_accuracy: 0.8615\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2185 - accuracy: 0.8918 - val_loss: 0.2957 - val_accuracy: 0.8615\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2194 - accuracy: 0.8940 - val_loss: 0.3038 - val_accuracy: 0.8615\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2186 - accuracy: 0.8918 - val_loss: 0.2929 - val_accuracy: 0.8718\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2211 - accuracy: 0.8940 - val_loss: 0.3117 - val_accuracy: 0.8615\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.2937 - val_accuracy: 0.8615\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.8918 - val_loss: 0.2947 - val_accuracy: 0.8718\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2256 - accuracy: 0.8852 - val_loss: 0.2914 - val_accuracy: 0.8718\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2190 - accuracy: 0.8940 - val_loss: 0.3036 - val_accuracy: 0.8615\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2193 - accuracy: 0.8940 - val_loss: 0.3027 - val_accuracy: 0.8615\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2189 - accuracy: 0.8830 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3021 - val_accuracy: 0.8615\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2180 - accuracy: 0.8896 - val_loss: 0.2958 - val_accuracy: 0.8615\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2217 - accuracy: 0.8940 - val_loss: 0.3003 - val_accuracy: 0.8615\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2231 - accuracy: 0.8918 - val_loss: 0.3133 - val_accuracy: 0.8564\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.2926 - val_accuracy: 0.8718\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.2937 - val_accuracy: 0.8718\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2242 - accuracy: 0.8918 - val_loss: 0.2987 - val_accuracy: 0.8615\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2233 - accuracy: 0.8918 - val_loss: 0.2982 - val_accuracy: 0.8615\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2208 - accuracy: 0.8896 - val_loss: 0.3117 - val_accuracy: 0.8564\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2213 - accuracy: 0.8940 - val_loss: 0.2930 - val_accuracy: 0.8615\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2245 - accuracy: 0.8918 - val_loss: 0.3106 - val_accuracy: 0.8615\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2224 - accuracy: 0.8918 - val_loss: 0.2927 - val_accuracy: 0.8615\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2264 - accuracy: 0.8786 - val_loss: 0.2908 - val_accuracy: 0.8718\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2200 - accuracy: 0.8896 - val_loss: 0.2909 - val_accuracy: 0.8615\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.2950 - val_accuracy: 0.8615\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2229 - accuracy: 0.8940 - val_loss: 0.3093 - val_accuracy: 0.8564\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2171 - accuracy: 0.8918 - val_loss: 0.2918 - val_accuracy: 0.8615\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.2998 - val_accuracy: 0.8564\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.2931 - val_accuracy: 0.8718\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2216 - accuracy: 0.8918 - val_loss: 0.3157 - val_accuracy: 0.8564\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2221 - accuracy: 0.8874 - val_loss: 0.2923 - val_accuracy: 0.8769\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3161 - val_accuracy: 0.8564\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2178 - accuracy: 0.8918 - val_loss: 0.2928 - val_accuracy: 0.8718\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.3023 - val_accuracy: 0.8564\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2229 - accuracy: 0.8896 - val_loss: 0.3063 - val_accuracy: 0.8564\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2165 - accuracy: 0.8918 - val_loss: 0.3003 - val_accuracy: 0.8615\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2232 - accuracy: 0.8940 - val_loss: 0.3063 - val_accuracy: 0.8564\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2232 - accuracy: 0.8940 - val_loss: 0.3137 - val_accuracy: 0.8564\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2168 - accuracy: 0.8918 - val_loss: 0.2968 - val_accuracy: 0.8718\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2224 - accuracy: 0.8852 - val_loss: 0.3043 - val_accuracy: 0.8564\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2191 - accuracy: 0.8918 - val_loss: 0.3020 - val_accuracy: 0.8564\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2239 - accuracy: 0.8940 - val_loss: 0.2983 - val_accuracy: 0.8718\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2217 - accuracy: 0.8940 - val_loss: 0.3060 - val_accuracy: 0.8564\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3043 - val_accuracy: 0.8564\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2245 - accuracy: 0.8940 - val_loss: 0.2927 - val_accuracy: 0.8718\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2351 - accuracy: 0.8940 - val_loss: 0.2959 - val_accuracy: 0.8718\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2225 - accuracy: 0.8940 - val_loss: 0.3070 - val_accuracy: 0.8564\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2209 - accuracy: 0.8940 - val_loss: 0.3037 - val_accuracy: 0.8564\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2210 - accuracy: 0.8918 - val_loss: 0.2995 - val_accuracy: 0.8615\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.2940 - val_accuracy: 0.8769\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2225 - accuracy: 0.8918 - val_loss: 0.3118 - val_accuracy: 0.8564\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.3029 - val_accuracy: 0.8615\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.3088 - val_accuracy: 0.8564\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2195 - accuracy: 0.8940 - val_loss: 0.3016 - val_accuracy: 0.8615\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2231 - accuracy: 0.8874 - val_loss: 0.3079 - val_accuracy: 0.8564\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2219 - accuracy: 0.8918 - val_loss: 0.3013 - val_accuracy: 0.8615\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2257 - accuracy: 0.8896 - val_loss: 0.3092 - val_accuracy: 0.8564\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 119us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.2973 - val_accuracy: 0.8615\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3021 - val_accuracy: 0.8615\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2190 - accuracy: 0.8940 - val_loss: 0.3133 - val_accuracy: 0.8564\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.2941 - val_accuracy: 0.8615\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2207 - accuracy: 0.8874 - val_loss: 0.3127 - val_accuracy: 0.8564\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3029 - val_accuracy: 0.8564\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2251 - accuracy: 0.8874 - val_loss: 0.2876 - val_accuracy: 0.8821\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2252 - accuracy: 0.8918 - val_loss: 0.2909 - val_accuracy: 0.8615\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3057 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a372cbf98>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 59us/step\n",
      "over-sampling test accuracy: 86.15%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 2,\n",
       "       1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 0, 1,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 2,\n",
       "       1, 2, 0, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0,\n",
       "       2, 0, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 2, 1, 1, 0, 1, 0, 2, 2, 0, 1,\n",
       "       2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 2, 0, 2, 2, 1, 2, 1, 0,\n",
       "       1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 0, 1, 2, 2,\n",
       "       0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 2, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS249     1     1\n",
       "1    NRS172     1     1\n",
       "2    NRS209     2     2\n",
       "3    NRS108     1     1\n",
       "4    NRS209     2     2\n",
       "..      ...   ...   ...\n",
       "190  NRS209     2     2\n",
       "191  NRS110     2     2\n",
       "192  NRS255     1     1\n",
       "193  NRS175     1     0\n",
       "194  NRS241     1     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.308234e-06</td>\n",
       "      <td>9.999946e-01</td>\n",
       "      <td>5.502656e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.188718e-35</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.864103e-09</td>\n",
       "      <td>9.563090e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.188718e-35</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.864103e-09</td>\n",
       "      <td>9.563090e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3.864103e-09</td>\n",
       "      <td>9.563090e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9.944022e-09</td>\n",
       "      <td>1.225267e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>5.171805e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.021424e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>6.193884e-01</td>\n",
       "      <td>3.806116e-01</td>\n",
       "      <td>7.403208e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.302416e-06</td>\n",
       "      <td>9.999987e-01</td>\n",
       "      <td>2.140235e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    5.308234e-06  9.999946e-01  5.502656e-08\n",
       "1    1.188718e-35  1.000000e+00  0.000000e+00\n",
       "2    3.864103e-09  9.563090e-09  1.000000e+00\n",
       "3    1.188718e-35  1.000000e+00  0.000000e+00\n",
       "4    3.864103e-09  9.563090e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "190  3.864103e-09  9.563090e-09  1.000000e+00\n",
       "191  9.944022e-09  1.225267e-08  1.000000e+00\n",
       "192  5.171805e-17  1.000000e+00  1.021424e-31\n",
       "193  6.193884e-01  3.806116e-01  7.403208e-11\n",
       "194  1.302416e-06  9.999987e-01  2.140235e-16\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3294 - val_accuracy: 0.8667\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2183 - accuracy: 0.8918 - val_loss: 0.3476 - val_accuracy: 0.8615\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2194 - accuracy: 0.8896 - val_loss: 0.3358 - val_accuracy: 0.8615\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2161 - accuracy: 0.8896 - val_loss: 0.3384 - val_accuracy: 0.8615\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2192 - accuracy: 0.8918 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2182 - accuracy: 0.8896 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2226 - accuracy: 0.8896 - val_loss: 0.3425 - val_accuracy: 0.8615\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3341 - val_accuracy: 0.8615\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2264 - accuracy: 0.8940 - val_loss: 0.3374 - val_accuracy: 0.8615\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2216 - accuracy: 0.8918 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3406 - val_accuracy: 0.8615\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3270 - val_accuracy: 0.8615\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2221 - accuracy: 0.8896 - val_loss: 0.3301 - val_accuracy: 0.8615\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3372 - val_accuracy: 0.8615\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2200 - accuracy: 0.8896 - val_loss: 0.3495 - val_accuracy: 0.8615\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2206 - accuracy: 0.8940 - val_loss: 0.3390 - val_accuracy: 0.8615\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2220 - accuracy: 0.8940 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.3369 - val_accuracy: 0.8615\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2200 - accuracy: 0.8940 - val_loss: 0.3528 - val_accuracy: 0.8615\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2211 - accuracy: 0.8918 - val_loss: 0.3359 - val_accuracy: 0.8615\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3294 - val_accuracy: 0.8615\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2201 - accuracy: 0.8940 - val_loss: 0.3390 - val_accuracy: 0.8615\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.2235 - accuracy: 0.8896 - val_loss: 0.3343 - val_accuracy: 0.8615\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.3320 - val_accuracy: 0.8615\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3404 - val_accuracy: 0.8615\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2279 - accuracy: 0.8940 - val_loss: 0.3638 - val_accuracy: 0.8564\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2204 - accuracy: 0.8940 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 573us/step - loss: 0.2156 - accuracy: 0.8918 - val_loss: 0.3350 - val_accuracy: 0.8615\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2177 - accuracy: 0.8918 - val_loss: 0.3467 - val_accuracy: 0.8615\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 749us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3359 - val_accuracy: 0.8564\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3346 - val_accuracy: 0.8615\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 379us/step - loss: 0.2182 - accuracy: 0.8896 - val_loss: 0.3480 - val_accuracy: 0.8564\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 308us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3349 - val_accuracy: 0.8615\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2181 - accuracy: 0.8852 - val_loss: 0.3462 - val_accuracy: 0.8564\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2189 - accuracy: 0.8918 - val_loss: 0.3363 - val_accuracy: 0.8615\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2203 - accuracy: 0.8852 - val_loss: 0.3485 - val_accuracy: 0.8564\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2193 - accuracy: 0.8874 - val_loss: 0.3411 - val_accuracy: 0.8615\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.3527 - val_accuracy: 0.8615\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3572 - val_accuracy: 0.8615\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2188 - accuracy: 0.8940 - val_loss: 0.3438 - val_accuracy: 0.8615\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2202 - accuracy: 0.8896 - val_loss: 0.3633 - val_accuracy: 0.8615\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3456 - val_accuracy: 0.8615\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2190 - accuracy: 0.8940 - val_loss: 0.3602 - val_accuracy: 0.8615\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.3636 - val_accuracy: 0.8615\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2209 - accuracy: 0.8786 - val_loss: 0.3393 - val_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2214 - accuracy: 0.8940 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3590 - val_accuracy: 0.8615\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3506 - val_accuracy: 0.8615\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2174 - accuracy: 0.8874 - val_loss: 0.3599 - val_accuracy: 0.8615\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.3208 - val_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2184 - accuracy: 0.8896 - val_loss: 0.3332 - val_accuracy: 0.8615\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2193 - accuracy: 0.8940 - val_loss: 0.3319 - val_accuracy: 0.8615\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2193 - accuracy: 0.8896 - val_loss: 0.3425 - val_accuracy: 0.8615\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2184 - accuracy: 0.8896 - val_loss: 0.3509 - val_accuracy: 0.8615\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3496 - val_accuracy: 0.8615\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 335us/step - loss: 0.2176 - accuracy: 0.8896 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 478us/step - loss: 0.2197 - accuracy: 0.8940 - val_loss: 0.3635 - val_accuracy: 0.8564\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3417 - val_accuracy: 0.8615\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3432 - val_accuracy: 0.8615\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2215 - accuracy: 0.8896 - val_loss: 0.3468 - val_accuracy: 0.8615\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2183 - accuracy: 0.8896 - val_loss: 0.3453 - val_accuracy: 0.8615\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3422 - val_accuracy: 0.8615\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3530 - val_accuracy: 0.8615\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2234 - accuracy: 0.8896 - val_loss: 0.3631 - val_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2217 - accuracy: 0.8940 - val_loss: 0.3443 - val_accuracy: 0.8615\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3595 - val_accuracy: 0.8564\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2162 - accuracy: 0.8918 - val_loss: 0.3435 - val_accuracy: 0.8615\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3520 - val_accuracy: 0.8615\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2251 - accuracy: 0.8896 - val_loss: 0.3709 - val_accuracy: 0.8615\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2194 - accuracy: 0.8874 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2200 - accuracy: 0.8874 - val_loss: 0.3589 - val_accuracy: 0.8615\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.3634 - val_accuracy: 0.8615\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2193 - accuracy: 0.8896 - val_loss: 0.3578 - val_accuracy: 0.8615\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2183 - accuracy: 0.8874 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3599 - val_accuracy: 0.8564\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2208 - accuracy: 0.8896 - val_loss: 0.3412 - val_accuracy: 0.8615\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.3475 - val_accuracy: 0.8615\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2174 - accuracy: 0.8918 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2218 - accuracy: 0.8940 - val_loss: 0.3472 - val_accuracy: 0.8615\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.3428 - val_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3495 - val_accuracy: 0.8615\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2216 - accuracy: 0.8874 - val_loss: 0.3535 - val_accuracy: 0.8615\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3504 - val_accuracy: 0.8615\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2208 - accuracy: 0.8896 - val_loss: 0.3520 - val_accuracy: 0.8615\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3510 - val_accuracy: 0.8615\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3475 - val_accuracy: 0.8615\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2207 - accuracy: 0.8918 - val_loss: 0.3550 - val_accuracy: 0.8615\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3576 - val_accuracy: 0.8615\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.3607 - val_accuracy: 0.8564\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2192 - accuracy: 0.8940 - val_loss: 0.3458 - val_accuracy: 0.8615\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2176 - accuracy: 0.8896 - val_loss: 0.3513 - val_accuracy: 0.8615\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2196 - accuracy: 0.8918 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2184 - accuracy: 0.8918 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3505 - val_accuracy: 0.8615\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2219 - accuracy: 0.8940 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2211 - accuracy: 0.8896 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3523 - val_accuracy: 0.8615\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3445 - val_accuracy: 0.8615\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2189 - accuracy: 0.8918 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2215 - accuracy: 0.8874 - val_loss: 0.3627 - val_accuracy: 0.8615\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3405 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2178 - accuracy: 0.8874 - val_loss: 0.3469 - val_accuracy: 0.8615\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.3581 - val_accuracy: 0.8615\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3456 - val_accuracy: 0.8615\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.3311 - val_accuracy: 0.8615\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2161 - accuracy: 0.8918 - val_loss: 0.3397 - val_accuracy: 0.8615\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 370us/step - loss: 0.2262 - accuracy: 0.8918 - val_loss: 0.3332 - val_accuracy: 0.8615\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3436 - val_accuracy: 0.8615\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2190 - accuracy: 0.8918 - val_loss: 0.3310 - val_accuracy: 0.8667\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2185 - accuracy: 0.8918 - val_loss: 0.3459 - val_accuracy: 0.8615\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.3427 - val_accuracy: 0.8667\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2195 - accuracy: 0.8874 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2251 - accuracy: 0.8874 - val_loss: 0.3546 - val_accuracy: 0.8564\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2195 - accuracy: 0.8852 - val_loss: 0.3321 - val_accuracy: 0.8667\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2161 - accuracy: 0.8896 - val_loss: 0.3505 - val_accuracy: 0.8615\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2183 - accuracy: 0.8918 - val_loss: 0.3519 - val_accuracy: 0.8615\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2187 - accuracy: 0.8896 - val_loss: 0.3448 - val_accuracy: 0.8615\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3507 - val_accuracy: 0.8615\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3445 - val_accuracy: 0.8615\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3461 - val_accuracy: 0.8615\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3541 - val_accuracy: 0.8615\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2179 - accuracy: 0.8896 - val_loss: 0.3522 - val_accuracy: 0.8615\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2222 - accuracy: 0.8874 - val_loss: 0.3476 - val_accuracy: 0.8615\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2226 - accuracy: 0.8940 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2232 - accuracy: 0.8918 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2132 - accuracy: 0.8918 - val_loss: 0.3389 - val_accuracy: 0.8615\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3418 - val_accuracy: 0.8615\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2200 - accuracy: 0.8896 - val_loss: 0.3565 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2189 - accuracy: 0.8940 - val_loss: 0.3485 - val_accuracy: 0.8615\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2209 - accuracy: 0.8940 - val_loss: 0.3420 - val_accuracy: 0.8615\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2161 - accuracy: 0.8896 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2209 - accuracy: 0.8896 - val_loss: 0.3612 - val_accuracy: 0.8615\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3468 - val_accuracy: 0.8615\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2206 - accuracy: 0.8940 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2166 - accuracy: 0.8962 - val_loss: 0.4015 - val_accuracy: 0.8615\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2180 - accuracy: 0.8962 - val_loss: 0.3477 - val_accuracy: 0.8615\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.3515 - val_accuracy: 0.8615\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2244 - accuracy: 0.8918 - val_loss: 0.3577 - val_accuracy: 0.8667\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2186 - accuracy: 0.8918 - val_loss: 0.3501 - val_accuracy: 0.8667\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2226 - accuracy: 0.8896 - val_loss: 0.3635 - val_accuracy: 0.8667\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3426 - val_accuracy: 0.8667\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2183 - accuracy: 0.8896 - val_loss: 0.3456 - val_accuracy: 0.8667\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2153 - accuracy: 0.8918 - val_loss: 0.3644 - val_accuracy: 0.8615\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2230 - accuracy: 0.8940 - val_loss: 0.3463 - val_accuracy: 0.8615\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2175 - accuracy: 0.8896 - val_loss: 0.3466 - val_accuracy: 0.8615\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3547 - val_accuracy: 0.8615\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2162 - accuracy: 0.8918 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.3649 - val_accuracy: 0.8615\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2175 - accuracy: 0.8896 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2160 - accuracy: 0.8962 - val_loss: 0.3426 - val_accuracy: 0.8615\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3321 - val_accuracy: 0.8615\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2234 - accuracy: 0.8918 - val_loss: 0.3325 - val_accuracy: 0.8667\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2225 - accuracy: 0.8896 - val_loss: 0.3413 - val_accuracy: 0.8615\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.3525 - val_accuracy: 0.8615\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3511 - val_accuracy: 0.8615\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3422 - val_accuracy: 0.8615\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3544 - val_accuracy: 0.8615\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2195 - accuracy: 0.8940 - val_loss: 0.3450 - val_accuracy: 0.8615\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2217 - accuracy: 0.8918 - val_loss: 0.3434 - val_accuracy: 0.8667\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.3725 - val_accuracy: 0.8667\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2236 - accuracy: 0.8874 - val_loss: 0.3448 - val_accuracy: 0.8667\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2190 - accuracy: 0.8918 - val_loss: 0.3542 - val_accuracy: 0.8615\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2170 - accuracy: 0.8896 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2157 - accuracy: 0.8896 - val_loss: 0.3552 - val_accuracy: 0.8615\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3458 - val_accuracy: 0.8615\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2213 - accuracy: 0.8874 - val_loss: 0.3461 - val_accuracy: 0.8615\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3431 - val_accuracy: 0.8615\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3441 - val_accuracy: 0.8615\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2188 - accuracy: 0.8852 - val_loss: 0.3399 - val_accuracy: 0.8615\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2198 - accuracy: 0.8940 - val_loss: 0.3429 - val_accuracy: 0.8615\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2189 - accuracy: 0.8896 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3489 - val_accuracy: 0.8615\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2174 - accuracy: 0.8918 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3457 - val_accuracy: 0.8615\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2181 - accuracy: 0.8896 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3249 - val_accuracy: 0.8615\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2183 - accuracy: 0.8962 - val_loss: 0.3344 - val_accuracy: 0.8667\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3460 - val_accuracy: 0.8615\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3578 - val_accuracy: 0.8615\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2213 - accuracy: 0.8940 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 351us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3401 - val_accuracy: 0.8615\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 383us/step - loss: 0.2200 - accuracy: 0.8852 - val_loss: 0.3425 - val_accuracy: 0.8615\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2184 - accuracy: 0.8896 - val_loss: 0.3552 - val_accuracy: 0.8615\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2236 - accuracy: 0.8918 - val_loss: 0.3630 - val_accuracy: 0.8615\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2170 - accuracy: 0.8918 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2270 - accuracy: 0.8852 - val_loss: 0.3421 - val_accuracy: 0.8615\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2220 - accuracy: 0.8940 - val_loss: 0.3438 - val_accuracy: 0.8615\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3554 - val_accuracy: 0.8615\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 123us/step - loss: 0.2197 - accuracy: 0.8874 - val_loss: 0.3377 - val_accuracy: 0.8615\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3446 - val_accuracy: 0.8615\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.3574 - val_accuracy: 0.8615\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.3322 - val_accuracy: 0.8667\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2262 - accuracy: 0.8940 - val_loss: 0.3538 - val_accuracy: 0.8615\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3485 - val_accuracy: 0.8667\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2160 - accuracy: 0.8896 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2218 - accuracy: 0.8874 - val_loss: 0.3650 - val_accuracy: 0.8615\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2247 - accuracy: 0.8874 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2212 - accuracy: 0.8896 - val_loss: 0.3560 - val_accuracy: 0.8667\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2190 - accuracy: 0.8985 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.3557 - val_accuracy: 0.8615\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2187 - accuracy: 0.8896 - val_loss: 0.3496 - val_accuracy: 0.8615\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2205 - accuracy: 0.8896 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2214 - accuracy: 0.8940 - val_loss: 0.3470 - val_accuracy: 0.8615\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3316 - val_accuracy: 0.8615\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2195 - accuracy: 0.8896 - val_loss: 0.3404 - val_accuracy: 0.8615\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2206 - accuracy: 0.8940 - val_loss: 0.3460 - val_accuracy: 0.8667\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3509 - val_accuracy: 0.8615\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3413 - val_accuracy: 0.8615\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3462 - val_accuracy: 0.8615\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 388us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3555 - val_accuracy: 0.8615\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2168 - accuracy: 0.8896 - val_loss: 0.3472 - val_accuracy: 0.8615\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2214 - accuracy: 0.8896 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.3513 - val_accuracy: 0.8615\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2164 - accuracy: 0.8874 - val_loss: 0.3505 - val_accuracy: 0.8615\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3525 - val_accuracy: 0.8615\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2170 - accuracy: 0.8896 - val_loss: 0.3435 - val_accuracy: 0.8615\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2197 - accuracy: 0.8940 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3459 - val_accuracy: 0.8615\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3419 - val_accuracy: 0.8615\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.3421 - val_accuracy: 0.8615\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2169 - accuracy: 0.8896 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3457 - val_accuracy: 0.8615\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2209 - accuracy: 0.8896 - val_loss: 0.3617 - val_accuracy: 0.8615\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3445 - val_accuracy: 0.8615\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2231 - accuracy: 0.8852 - val_loss: 0.3485 - val_accuracy: 0.8615\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3469 - val_accuracy: 0.8615\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2212 - accuracy: 0.8940 - val_loss: 0.3566 - val_accuracy: 0.8615\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2189 - accuracy: 0.8896 - val_loss: 0.3509 - val_accuracy: 0.8615\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2192 - accuracy: 0.8830 - val_loss: 0.3475 - val_accuracy: 0.8615\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3468 - val_accuracy: 0.8615\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2195 - accuracy: 0.8874 - val_loss: 0.3542 - val_accuracy: 0.8615\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2200 - accuracy: 0.8940 - val_loss: 0.3498 - val_accuracy: 0.8615\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3443 - val_accuracy: 0.8615\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2227 - accuracy: 0.8918 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2212 - accuracy: 0.8852 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.3359 - val_accuracy: 0.8615\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2194 - accuracy: 0.8896 - val_loss: 0.3458 - val_accuracy: 0.8615\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2146 - accuracy: 0.8918 - val_loss: 0.3456 - val_accuracy: 0.8667\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2205 - accuracy: 0.8896 - val_loss: 0.3445 - val_accuracy: 0.8615\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2187 - accuracy: 0.8918 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2203 - accuracy: 0.8918 - val_loss: 0.3627 - val_accuracy: 0.8615\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3469 - val_accuracy: 0.8615\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2173 - accuracy: 0.8918 - val_loss: 0.3525 - val_accuracy: 0.8615\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.3437 - val_accuracy: 0.8667\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2181 - accuracy: 0.8940 - val_loss: 0.3460 - val_accuracy: 0.8615\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2177 - accuracy: 0.8896 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3468 - val_accuracy: 0.8615\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3392 - val_accuracy: 0.8615\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2234 - accuracy: 0.8896 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3577 - val_accuracy: 0.8615\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3470 - val_accuracy: 0.8615\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3491 - val_accuracy: 0.8615\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2206 - accuracy: 0.8896 - val_loss: 0.3583 - val_accuracy: 0.8615\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.3550 - val_accuracy: 0.8615\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3446 - val_accuracy: 0.8615\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2191 - accuracy: 0.8896 - val_loss: 0.3582 - val_accuracy: 0.8615\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3555 - val_accuracy: 0.8615\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2184 - accuracy: 0.8896 - val_loss: 0.3532 - val_accuracy: 0.8615\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2218 - accuracy: 0.8940 - val_loss: 0.3525 - val_accuracy: 0.8615\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2168 - accuracy: 0.8874 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3455 - val_accuracy: 0.8615\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3491 - val_accuracy: 0.8615\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2165 - accuracy: 0.8896 - val_loss: 0.3479 - val_accuracy: 0.8615\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2170 - accuracy: 0.8874 - val_loss: 0.3603 - val_accuracy: 0.8615\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2227 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2237 - accuracy: 0.8918 - val_loss: 0.3472 - val_accuracy: 0.8667\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3507 - val_accuracy: 0.8615\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3356 - val_accuracy: 0.8615\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2161 - accuracy: 0.8896 - val_loss: 0.3437 - val_accuracy: 0.8667\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3545 - val_accuracy: 0.8615\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2186 - accuracy: 0.8918 - val_loss: 0.3416 - val_accuracy: 0.8615\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2198 - accuracy: 0.8874 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2198 - accuracy: 0.8940 - val_loss: 0.3476 - val_accuracy: 0.8615\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3554 - val_accuracy: 0.8615\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2202 - accuracy: 0.8874 - val_loss: 0.3448 - val_accuracy: 0.8615\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2219 - accuracy: 0.8874 - val_loss: 0.3459 - val_accuracy: 0.8667\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2192 - accuracy: 0.8918 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2250 - accuracy: 0.8896 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3380 - val_accuracy: 0.8615\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3467 - val_accuracy: 0.8615\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3559 - val_accuracy: 0.8615\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2200 - accuracy: 0.8896 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3506 - val_accuracy: 0.8615\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3520 - val_accuracy: 0.8615\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 137us/step - loss: 0.2175 - accuracy: 0.8918 - val_loss: 0.3475 - val_accuracy: 0.8667\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3536 - val_accuracy: 0.8615\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2212 - accuracy: 0.8940 - val_loss: 0.3361 - val_accuracy: 0.8615\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2193 - accuracy: 0.8874 - val_loss: 0.3448 - val_accuracy: 0.8615\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3436 - val_accuracy: 0.8615\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.2192 - accuracy: 0.8940 - val_loss: 0.3426 - val_accuracy: 0.8667\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.3520 - val_accuracy: 0.8615\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2184 - accuracy: 0.8896 - val_loss: 0.3556 - val_accuracy: 0.8615\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3607 - val_accuracy: 0.8615\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3320 - val_accuracy: 0.8615\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3383 - val_accuracy: 0.8615\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2176 - accuracy: 0.8852 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2171 - accuracy: 0.8918 - val_loss: 0.3429 - val_accuracy: 0.8615\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2194 - accuracy: 0.8940 - val_loss: 0.3505 - val_accuracy: 0.8615\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2209 - accuracy: 0.8896 - val_loss: 0.3457 - val_accuracy: 0.8667\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3543 - val_accuracy: 0.8615\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2175 - accuracy: 0.8896 - val_loss: 0.3512 - val_accuracy: 0.8615\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 490us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3413 - val_accuracy: 0.8615\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2262 - accuracy: 0.8962 - val_loss: 0.3550 - val_accuracy: 0.8615\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2237 - accuracy: 0.8940 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3493 - val_accuracy: 0.8615\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3529 - val_accuracy: 0.8615\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2208 - accuracy: 0.8808 - val_loss: 0.3471 - val_accuracy: 0.8615\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3420 - val_accuracy: 0.8615\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3622 - val_accuracy: 0.8615\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2176 - accuracy: 0.8918 - val_loss: 0.3508 - val_accuracy: 0.8615\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2180 - accuracy: 0.8896 - val_loss: 0.3581 - val_accuracy: 0.8615\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3558 - val_accuracy: 0.8615\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3567 - val_accuracy: 0.8615\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2153 - accuracy: 0.8918 - val_loss: 0.3524 - val_accuracy: 0.8615\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3570 - val_accuracy: 0.8615\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3548 - val_accuracy: 0.8615\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2165 - accuracy: 0.8918 - val_loss: 0.3548 - val_accuracy: 0.8615\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2193 - accuracy: 0.8852 - val_loss: 0.3542 - val_accuracy: 0.8615\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3542 - val_accuracy: 0.8615\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3537 - val_accuracy: 0.8615\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2146 - accuracy: 0.8940 - val_loss: 0.3581 - val_accuracy: 0.8615\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3539 - val_accuracy: 0.8615\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3605 - val_accuracy: 0.8615\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2179 - accuracy: 0.8874 - val_loss: 0.3507 - val_accuracy: 0.8615\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3618 - val_accuracy: 0.8615\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3485 - val_accuracy: 0.8667\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3511 - val_accuracy: 0.8615\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3569 - val_accuracy: 0.8615\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3566 - val_accuracy: 0.8615\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2247 - accuracy: 0.8896 - val_loss: 0.3630 - val_accuracy: 0.8667\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2176 - accuracy: 0.8874 - val_loss: 0.3425 - val_accuracy: 0.8615\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3576 - val_accuracy: 0.8615\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 383us/step - loss: 0.2193 - accuracy: 0.8896 - val_loss: 0.3490 - val_accuracy: 0.8615\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2197 - accuracy: 0.8940 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2173 - accuracy: 0.8918 - val_loss: 0.3464 - val_accuracy: 0.8615\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3623 - val_accuracy: 0.8615\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2206 - accuracy: 0.8896 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3619 - val_accuracy: 0.8615\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2174 - accuracy: 0.8874 - val_loss: 0.3555 - val_accuracy: 0.8615\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2175 - accuracy: 0.8896 - val_loss: 0.3543 - val_accuracy: 0.8615\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2155 - accuracy: 0.8918 - val_loss: 0.3395 - val_accuracy: 0.8667\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2263 - accuracy: 0.8874 - val_loss: 0.3463 - val_accuracy: 0.8615\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3523 - val_accuracy: 0.8615\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2193 - accuracy: 0.8940 - val_loss: 0.3524 - val_accuracy: 0.8615\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2160 - accuracy: 0.8896 - val_loss: 0.3491 - val_accuracy: 0.8615\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3523 - val_accuracy: 0.8615\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3489 - val_accuracy: 0.8667\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2156 - accuracy: 0.8896 - val_loss: 0.3599 - val_accuracy: 0.8615\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2162 - accuracy: 0.8896 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2150 - accuracy: 0.8874 - val_loss: 0.3550 - val_accuracy: 0.8615\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2183 - accuracy: 0.8896 - val_loss: 0.3578 - val_accuracy: 0.8615\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3568 - val_accuracy: 0.8615\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3540 - val_accuracy: 0.8615\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2161 - accuracy: 0.8918 - val_loss: 0.3493 - val_accuracy: 0.8615\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3568 - val_accuracy: 0.8615\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.3553 - val_accuracy: 0.8615\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3537 - val_accuracy: 0.8615\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2176 - accuracy: 0.8918 - val_loss: 0.3541 - val_accuracy: 0.8615\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3519 - val_accuracy: 0.8615\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3618 - val_accuracy: 0.8615\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2176 - accuracy: 0.8918 - val_loss: 0.3476 - val_accuracy: 0.8667\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3586 - val_accuracy: 0.8615\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3575 - val_accuracy: 0.8615\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2156 - accuracy: 0.8918 - val_loss: 0.3523 - val_accuracy: 0.8615\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2140 - accuracy: 0.8940 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2176 - accuracy: 0.8874 - val_loss: 0.3523 - val_accuracy: 0.8615\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3617 - val_accuracy: 0.8615\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2166 - accuracy: 0.8874 - val_loss: 0.3529 - val_accuracy: 0.8667\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3557 - val_accuracy: 0.8615\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3469 - val_accuracy: 0.8667\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3407 - val_accuracy: 0.8615\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3415 - val_accuracy: 0.8615\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3500 - val_accuracy: 0.8615\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3607 - val_accuracy: 0.8615\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3513 - val_accuracy: 0.8615\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2171 - accuracy: 0.8918 - val_loss: 0.3556 - val_accuracy: 0.8615\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.3579 - val_accuracy: 0.8615\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2171 - accuracy: 0.8896 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2180 - accuracy: 0.8918 - val_loss: 0.3629 - val_accuracy: 0.8615\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2166 - accuracy: 0.8874 - val_loss: 0.3567 - val_accuracy: 0.8615\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2165 - accuracy: 0.8896 - val_loss: 0.3593 - val_accuracy: 0.8615\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2214 - accuracy: 0.8896 - val_loss: 0.3581 - val_accuracy: 0.8615\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3504 - val_accuracy: 0.8615\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2190 - accuracy: 0.8918 - val_loss: 0.3509 - val_accuracy: 0.8615\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2164 - accuracy: 0.8874 - val_loss: 0.3616 - val_accuracy: 0.8615\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 92us/step - loss: 0.2158 - accuracy: 0.8896 - val_loss: 0.3494 - val_accuracy: 0.8615\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2193 - accuracy: 0.8918 - val_loss: 0.3537 - val_accuracy: 0.8615\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2160 - accuracy: 0.8918 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3657 - val_accuracy: 0.8615\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2204 - accuracy: 0.8918 - val_loss: 0.3692 - val_accuracy: 0.8615\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2179 - accuracy: 0.8896 - val_loss: 0.3589 - val_accuracy: 0.8667\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3595 - val_accuracy: 0.8667\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2171 - accuracy: 0.8852 - val_loss: 0.3751 - val_accuracy: 0.8615\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3713 - val_accuracy: 0.8615\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3715 - val_accuracy: 0.8667\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3713 - val_accuracy: 0.8615\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3637 - val_accuracy: 0.8667\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2213 - accuracy: 0.8874 - val_loss: 0.3651 - val_accuracy: 0.8615\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3706 - val_accuracy: 0.8615\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3694 - val_accuracy: 0.8615\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3718 - val_accuracy: 0.8615\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2190 - accuracy: 0.8896 - val_loss: 0.3810 - val_accuracy: 0.8564\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3550 - val_accuracy: 0.8615\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2189 - accuracy: 0.8874 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2205 - accuracy: 0.8918 - val_loss: 0.3694 - val_accuracy: 0.8615\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2196 - accuracy: 0.8896 - val_loss: 0.3767 - val_accuracy: 0.8615\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3704 - val_accuracy: 0.8615\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3701 - val_accuracy: 0.8615\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2180 - accuracy: 0.8896 - val_loss: 0.3680 - val_accuracy: 0.8615\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2162 - accuracy: 0.8874 - val_loss: 0.3720 - val_accuracy: 0.8615\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2174 - accuracy: 0.8896 - val_loss: 0.3741 - val_accuracy: 0.8564\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3703 - val_accuracy: 0.8615\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.3600 - val_accuracy: 0.8615\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2190 - accuracy: 0.8896 - val_loss: 0.3651 - val_accuracy: 0.8615\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3715 - val_accuracy: 0.8564\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3597 - val_accuracy: 0.8615\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3655 - val_accuracy: 0.8615\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2183 - accuracy: 0.8962 - val_loss: 0.3745 - val_accuracy: 0.8615\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2174 - accuracy: 0.8918 - val_loss: 0.3607 - val_accuracy: 0.8615\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3721 - val_accuracy: 0.8615\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3663 - val_accuracy: 0.8615\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2170 - accuracy: 0.8896 - val_loss: 0.3637 - val_accuracy: 0.8615\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2146 - accuracy: 0.8896 - val_loss: 0.3736 - val_accuracy: 0.8615\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3712 - val_accuracy: 0.8615\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3670 - val_accuracy: 0.8615\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3672 - val_accuracy: 0.8615\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.3694 - val_accuracy: 0.8615\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3689 - val_accuracy: 0.8615\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2193 - accuracy: 0.8874 - val_loss: 0.3678 - val_accuracy: 0.8615\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2209 - accuracy: 0.8940 - val_loss: 0.3636 - val_accuracy: 0.8667\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2188 - accuracy: 0.8874 - val_loss: 0.3616 - val_accuracy: 0.8615\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2181 - accuracy: 0.8940 - val_loss: 0.3764 - val_accuracy: 0.8615\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2178 - accuracy: 0.8896 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2243 - accuracy: 0.8918 - val_loss: 0.3632 - val_accuracy: 0.8667\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2230 - accuracy: 0.8962 - val_loss: 0.3645 - val_accuracy: 0.8615\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3665 - val_accuracy: 0.8667\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2183 - accuracy: 0.8918 - val_loss: 0.3694 - val_accuracy: 0.8615\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3615 - val_accuracy: 0.8667\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3643 - val_accuracy: 0.8615\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2171 - accuracy: 0.8874 - val_loss: 0.3686 - val_accuracy: 0.8615\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3650 - val_accuracy: 0.8615\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3653 - val_accuracy: 0.8615\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2149 - accuracy: 0.8918 - val_loss: 0.3636 - val_accuracy: 0.8615\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2184 - accuracy: 0.8940 - val_loss: 0.3677 - val_accuracy: 0.8615\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.93 - 0s 105us/step - loss: 0.2186 - accuracy: 0.8940 - val_loss: 0.3597 - val_accuracy: 0.8615\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3609 - val_accuracy: 0.8667\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3677 - val_accuracy: 0.8615\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3687 - val_accuracy: 0.8615\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3615 - val_accuracy: 0.8667\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2163 - accuracy: 0.8874 - val_loss: 0.3705 - val_accuracy: 0.8615\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3587 - val_accuracy: 0.8667\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3686 - val_accuracy: 0.8615\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2193 - accuracy: 0.8918 - val_loss: 0.3549 - val_accuracy: 0.8667\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2157 - accuracy: 0.8985 - val_loss: 0.3730 - val_accuracy: 0.8615\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2153 - accuracy: 0.8896 - val_loss: 0.3565 - val_accuracy: 0.8615\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2193 - accuracy: 0.8940 - val_loss: 0.3703 - val_accuracy: 0.8615\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3689 - val_accuracy: 0.8615\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2196 - accuracy: 0.8962 - val_loss: 0.3620 - val_accuracy: 0.8667\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2218 - accuracy: 0.8874 - val_loss: 0.3632 - val_accuracy: 0.8615\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2242 - accuracy: 0.8918 - val_loss: 0.3551 - val_accuracy: 0.8615\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2192 - accuracy: 0.8940 - val_loss: 0.3615 - val_accuracy: 0.8615\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2183 - accuracy: 0.8874 - val_loss: 0.3591 - val_accuracy: 0.8615\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2168 - accuracy: 0.8830 - val_loss: 0.3588 - val_accuracy: 0.8615\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2168 - accuracy: 0.8874 - val_loss: 0.3639 - val_accuracy: 0.8615\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2189 - accuracy: 0.8940 - val_loss: 0.3597 - val_accuracy: 0.8615\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3699 - val_accuracy: 0.8615\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2153 - accuracy: 0.8918 - val_loss: 0.3557 - val_accuracy: 0.8667\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2157 - accuracy: 0.8874 - val_loss: 0.3697 - val_accuracy: 0.8615\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3577 - val_accuracy: 0.8615\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3689 - val_accuracy: 0.8615\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2173 - accuracy: 0.8874 - val_loss: 0.3643 - val_accuracy: 0.8667\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2173 - accuracy: 0.8896 - val_loss: 0.3631 - val_accuracy: 0.8615\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2166 - accuracy: 0.8874 - val_loss: 0.3643 - val_accuracy: 0.8615\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.3595 - val_accuracy: 0.8615\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2156 - accuracy: 0.8918 - val_loss: 0.3549 - val_accuracy: 0.8667\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2191 - accuracy: 0.8918 - val_loss: 0.3683 - val_accuracy: 0.8615\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2195 - accuracy: 0.8940 - val_loss: 0.3652 - val_accuracy: 0.8615\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3616 - val_accuracy: 0.8615\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2200 - accuracy: 0.8830 - val_loss: 0.3576 - val_accuracy: 0.8615\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2196 - accuracy: 0.8874 - val_loss: 0.3621 - val_accuracy: 0.8615\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2147 - accuracy: 0.8940 - val_loss: 0.3620 - val_accuracy: 0.8615\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3651 - val_accuracy: 0.8615\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.3623 - val_accuracy: 0.8615\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2230 - accuracy: 0.8896 - val_loss: 0.3540 - val_accuracy: 0.8615\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2211 - accuracy: 0.8896 - val_loss: 0.3651 - val_accuracy: 0.8615\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8874 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3636 - val_accuracy: 0.8615\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3584 - val_accuracy: 0.8615\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2188 - accuracy: 0.8874 - val_loss: 0.3622 - val_accuracy: 0.8615\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3642 - val_accuracy: 0.8615\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3632 - val_accuracy: 0.8615\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3637 - val_accuracy: 0.8615\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2216 - accuracy: 0.8918 - val_loss: 0.3569 - val_accuracy: 0.8667\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3673 - val_accuracy: 0.8615\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3500 - val_accuracy: 0.8615\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 109us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3653 - val_accuracy: 0.8615\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2154 - accuracy: 0.8918 - val_loss: 0.3607 - val_accuracy: 0.8667\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3540 - val_accuracy: 0.8615\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3462 - val_accuracy: 0.8667\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2173 - accuracy: 0.8852 - val_loss: 0.3465 - val_accuracy: 0.8667\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2161 - accuracy: 0.8918 - val_loss: 0.3533 - val_accuracy: 0.8615\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3545 - val_accuracy: 0.8667\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2179 - accuracy: 0.8918 - val_loss: 0.3621 - val_accuracy: 0.8615\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.3705 - val_accuracy: 0.8615\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3606 - val_accuracy: 0.8615\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3603 - val_accuracy: 0.8615\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2136 - accuracy: 0.8940 - val_loss: 0.3663 - val_accuracy: 0.8615\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3636 - val_accuracy: 0.8615\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3619 - val_accuracy: 0.8615\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2156 - accuracy: 0.8874 - val_loss: 0.3568 - val_accuracy: 0.8615\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3594 - val_accuracy: 0.8615\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3536 - val_accuracy: 0.8615\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2229 - accuracy: 0.8918 - val_loss: 0.3555 - val_accuracy: 0.8667\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2171 - accuracy: 0.8918 - val_loss: 0.3605 - val_accuracy: 0.8615\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3589 - val_accuracy: 0.8615\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3564 - val_accuracy: 0.8667\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2150 - accuracy: 0.8918 - val_loss: 0.3617 - val_accuracy: 0.8615\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2150 - accuracy: 0.8874 - val_loss: 0.3622 - val_accuracy: 0.8615\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2181 - accuracy: 0.8940 - val_loss: 0.3654 - val_accuracy: 0.8615\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3599 - val_accuracy: 0.8615\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3544 - val_accuracy: 0.8615\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2156 - accuracy: 0.8874 - val_loss: 0.3517 - val_accuracy: 0.8615\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2194 - accuracy: 0.8896 - val_loss: 0.3677 - val_accuracy: 0.8615\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2188 - accuracy: 0.8852 - val_loss: 0.3491 - val_accuracy: 0.8667\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2193 - accuracy: 0.8918 - val_loss: 0.3565 - val_accuracy: 0.8667\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2169 - accuracy: 0.8962 - val_loss: 0.3683 - val_accuracy: 0.8615\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3670 - val_accuracy: 0.8615\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2143 - accuracy: 0.8918 - val_loss: 0.3535 - val_accuracy: 0.8667\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3586 - val_accuracy: 0.8615\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3462 - val_accuracy: 0.8667\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2195 - accuracy: 0.8896 - val_loss: 0.3551 - val_accuracy: 0.8615\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2189 - accuracy: 0.8896 - val_loss: 0.3564 - val_accuracy: 0.8615\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3599 - val_accuracy: 0.8615\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2195 - accuracy: 0.8918 - val_loss: 0.3566 - val_accuracy: 0.8615\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3582 - val_accuracy: 0.8615\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2158 - accuracy: 0.8918 - val_loss: 0.3553 - val_accuracy: 0.8615\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3527 - val_accuracy: 0.8615\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3583 - val_accuracy: 0.8615\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2175 - accuracy: 0.8896 - val_loss: 0.3610 - val_accuracy: 0.8615\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3611 - val_accuracy: 0.8615\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2174 - accuracy: 0.8874 - val_loss: 0.3453 - val_accuracy: 0.8667\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2168 - accuracy: 0.8918 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2173 - accuracy: 0.8918 - val_loss: 0.3567 - val_accuracy: 0.8615\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2183 - accuracy: 0.8874 - val_loss: 0.3508 - val_accuracy: 0.8615\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3485 - val_accuracy: 0.8615\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3614 - val_accuracy: 0.8615\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2155 - accuracy: 0.8896 - val_loss: 0.3574 - val_accuracy: 0.8615\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2174 - accuracy: 0.8896 - val_loss: 0.3642 - val_accuracy: 0.8615\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2163 - accuracy: 0.8896 - val_loss: 0.3541 - val_accuracy: 0.8615\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2171 - accuracy: 0.8918 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3608 - val_accuracy: 0.8615\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3516 - val_accuracy: 0.8667\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2185 - accuracy: 0.8918 - val_loss: 0.3557 - val_accuracy: 0.8615\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2156 - accuracy: 0.8874 - val_loss: 0.3579 - val_accuracy: 0.8667\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2195 - accuracy: 0.8918 - val_loss: 0.3617 - val_accuracy: 0.8615\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.3585 - val_accuracy: 0.8667\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3610 - val_accuracy: 0.8615\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2236 - accuracy: 0.8940 - val_loss: 0.3612 - val_accuracy: 0.8615\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2147 - accuracy: 0.8940 - val_loss: 0.3578 - val_accuracy: 0.8615\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2179 - accuracy: 0.8874 - val_loss: 0.3578 - val_accuracy: 0.8615\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2191 - accuracy: 0.8852 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3596 - val_accuracy: 0.8615\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3534 - val_accuracy: 0.8615\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3564 - val_accuracy: 0.8615\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2186 - accuracy: 0.8874 - val_loss: 0.3616 - val_accuracy: 0.8615\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.3462 - val_accuracy: 0.8667\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2194 - accuracy: 0.8918 - val_loss: 0.3579 - val_accuracy: 0.8615\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8896 - val_loss: 0.3600 - val_accuracy: 0.8615\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2145 - accuracy: 0.8940 - val_loss: 0.3590 - val_accuracy: 0.8615\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3579 - val_accuracy: 0.8615\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2146 - accuracy: 0.8940 - val_loss: 0.3601 - val_accuracy: 0.8615\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2145 - accuracy: 0.8940 - val_loss: 0.3564 - val_accuracy: 0.8615\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2158 - accuracy: 0.8918 - val_loss: 0.3591 - val_accuracy: 0.8615\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3532 - val_accuracy: 0.8615\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3569 - val_accuracy: 0.8615\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2215 - accuracy: 0.8918 - val_loss: 0.3709 - val_accuracy: 0.8615\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3508 - val_accuracy: 0.8615\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2183 - accuracy: 0.8874 - val_loss: 0.3549 - val_accuracy: 0.8667\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3582 - val_accuracy: 0.8615\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.3607 - val_accuracy: 0.8615\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2193 - accuracy: 0.8918 - val_loss: 0.3601 - val_accuracy: 0.8667\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3383 - val_accuracy: 0.8615\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3206 - val_accuracy: 0.8615\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3328 - val_accuracy: 0.8615\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3312 - val_accuracy: 0.8615\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2149 - accuracy: 0.8918 - val_loss: 0.3341 - val_accuracy: 0.8615\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3377 - val_accuracy: 0.8615\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3365 - val_accuracy: 0.8615\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3342 - val_accuracy: 0.8615\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2162 - accuracy: 0.8874 - val_loss: 0.3379 - val_accuracy: 0.8615\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2140 - accuracy: 0.8940 - val_loss: 0.3388 - val_accuracy: 0.8615\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3379 - val_accuracy: 0.8615\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2177 - accuracy: 0.8918 - val_loss: 0.3446 - val_accuracy: 0.8615\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2200 - accuracy: 0.8874 - val_loss: 0.3244 - val_accuracy: 0.8667\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2186 - accuracy: 0.8896 - val_loss: 0.3403 - val_accuracy: 0.8615\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2183 - accuracy: 0.8896 - val_loss: 0.3327 - val_accuracy: 0.8667\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3411 - val_accuracy: 0.8615\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3398 - val_accuracy: 0.8615\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3364 - val_accuracy: 0.8615\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.8874 - val_loss: 0.3335 - val_accuracy: 0.8615\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3422 - val_accuracy: 0.8615\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3367 - val_accuracy: 0.8667\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2183 - accuracy: 0.8918 - val_loss: 0.3369 - val_accuracy: 0.8615\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3418 - val_accuracy: 0.8615\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2251 - accuracy: 0.8874 - val_loss: 0.3398 - val_accuracy: 0.8513\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2238 - accuracy: 0.8918 - val_loss: 0.3377 - val_accuracy: 0.8615\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2192 - accuracy: 0.8874 - val_loss: 0.3341 - val_accuracy: 0.8615\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3393 - val_accuracy: 0.8615\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8896 - val_loss: 0.3365 - val_accuracy: 0.8615\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3366 - val_accuracy: 0.8615\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2176 - accuracy: 0.8874 - val_loss: 0.3380 - val_accuracy: 0.8615\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3430 - val_accuracy: 0.8615\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2146 - accuracy: 0.8940 - val_loss: 0.3322 - val_accuracy: 0.8667\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2192 - accuracy: 0.8918 - val_loss: 0.3307 - val_accuracy: 0.8667\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3460 - val_accuracy: 0.8615\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2181 - accuracy: 0.8940 - val_loss: 0.3356 - val_accuracy: 0.8615\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.3390 - val_accuracy: 0.8615\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2206 - accuracy: 0.8940 - val_loss: 0.3401 - val_accuracy: 0.8615\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3382 - val_accuracy: 0.8615\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3428 - val_accuracy: 0.8615\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3440 - val_accuracy: 0.8615\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2204 - accuracy: 0.8874 - val_loss: 0.3452 - val_accuracy: 0.8615\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3367 - val_accuracy: 0.8615\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2171 - accuracy: 0.8874 - val_loss: 0.3479 - val_accuracy: 0.8615\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2171 - accuracy: 0.8896 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2152 - accuracy: 0.8918 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2160 - accuracy: 0.8896 - val_loss: 0.3477 - val_accuracy: 0.8615\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3317 - val_accuracy: 0.8667\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2169 - accuracy: 0.8874 - val_loss: 0.3416 - val_accuracy: 0.8615\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3400 - val_accuracy: 0.8615\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2165 - accuracy: 0.8874 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2161 - accuracy: 0.8896 - val_loss: 0.3516 - val_accuracy: 0.8615\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3397 - val_accuracy: 0.8615\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3409 - val_accuracy: 0.8615\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2148 - accuracy: 0.8940 - val_loss: 0.3391 - val_accuracy: 0.8615\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2170 - accuracy: 0.8918 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2170 - accuracy: 0.8896 - val_loss: 0.3394 - val_accuracy: 0.8667\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.8962 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2198 - accuracy: 0.8874 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3436 - val_accuracy: 0.8615\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2159 - accuracy: 0.8874 - val_loss: 0.3452 - val_accuracy: 0.8667\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3450 - val_accuracy: 0.8615\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3426 - val_accuracy: 0.8615\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2216 - accuracy: 0.8830 - val_loss: 0.3419 - val_accuracy: 0.8615\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2200 - accuracy: 0.8918 - val_loss: 0.3358 - val_accuracy: 0.8667\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2183 - accuracy: 0.8874 - val_loss: 0.3380 - val_accuracy: 0.8718\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8874 - val_loss: 0.3302 - val_accuracy: 0.8615\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3333 - val_accuracy: 0.8615\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2168 - accuracy: 0.8874 - val_loss: 0.3415 - val_accuracy: 0.8615\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3354 - val_accuracy: 0.8615\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3413 - val_accuracy: 0.8615\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2157 - accuracy: 0.8918 - val_loss: 0.3392 - val_accuracy: 0.8615\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2136 - accuracy: 0.8940 - val_loss: 0.3392 - val_accuracy: 0.8615\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3386 - val_accuracy: 0.8615\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2163 - accuracy: 0.8874 - val_loss: 0.3428 - val_accuracy: 0.8615\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2176 - accuracy: 0.8852 - val_loss: 0.3406 - val_accuracy: 0.8615\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2143 - accuracy: 0.8940 - val_loss: 0.3412 - val_accuracy: 0.8615\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3406 - val_accuracy: 0.8615\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2229 - accuracy: 0.8918 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2165 - accuracy: 0.8896 - val_loss: 0.3417 - val_accuracy: 0.8615\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3434 - val_accuracy: 0.8615\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2171 - accuracy: 0.8940 - val_loss: 0.3419 - val_accuracy: 0.8615\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2202 - accuracy: 0.8940 - val_loss: 0.3405 - val_accuracy: 0.8615\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3388 - val_accuracy: 0.8615\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2181 - accuracy: 0.8896 - val_loss: 0.3381 - val_accuracy: 0.8615\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3435 - val_accuracy: 0.8615\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2172 - accuracy: 0.8940 - val_loss: 0.3389 - val_accuracy: 0.8615\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2172 - accuracy: 0.8874 - val_loss: 0.3449 - val_accuracy: 0.8615\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3464 - val_accuracy: 0.8615\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3500 - val_accuracy: 0.8615\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2181 - accuracy: 0.8940 - val_loss: 0.3460 - val_accuracy: 0.8615\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2209 - accuracy: 0.8896 - val_loss: 0.3347 - val_accuracy: 0.8615\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2207 - accuracy: 0.8896 - val_loss: 0.3404 - val_accuracy: 0.8615\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2175 - accuracy: 0.8874 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2185 - accuracy: 0.8940 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2191 - accuracy: 0.8940 - val_loss: 0.3511 - val_accuracy: 0.8615\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3381 - val_accuracy: 0.8667\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2168 - accuracy: 0.8896 - val_loss: 0.3426 - val_accuracy: 0.8615\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2212 - accuracy: 0.8918 - val_loss: 0.3385 - val_accuracy: 0.8667\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2173 - accuracy: 0.8896 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2141 - accuracy: 0.8940 - val_loss: 0.3477 - val_accuracy: 0.8615\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3426 - val_accuracy: 0.8615\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2146 - accuracy: 0.8896 - val_loss: 0.3397 - val_accuracy: 0.8667\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2151 - accuracy: 0.8896 - val_loss: 0.3403 - val_accuracy: 0.8615\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2142 - accuracy: 0.8940 - val_loss: 0.3479 - val_accuracy: 0.8615\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3354 - val_accuracy: 0.8667\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.87 - 0s 105us/step - loss: 0.2171 - accuracy: 0.8874 - val_loss: 0.3452 - val_accuracy: 0.8615\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2169 - accuracy: 0.8918 - val_loss: 0.3383 - val_accuracy: 0.8615\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3462 - val_accuracy: 0.8615\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2205 - accuracy: 0.8940 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3409 - val_accuracy: 0.8615\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 109us/step - loss: 0.2138 - accuracy: 0.8940 - val_loss: 0.3455 - val_accuracy: 0.8615\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3532 - val_accuracy: 0.8615\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3437 - val_accuracy: 0.8615\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3419 - val_accuracy: 0.8615\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2161 - accuracy: 0.8874 - val_loss: 0.3530 - val_accuracy: 0.8615\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3436 - val_accuracy: 0.8615\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2176 - accuracy: 0.8896 - val_loss: 0.3436 - val_accuracy: 0.8615\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3433 - val_accuracy: 0.8615\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3459 - val_accuracy: 0.8615\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3475 - val_accuracy: 0.8615\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2187 - accuracy: 0.8940 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2192 - accuracy: 0.8896 - val_loss: 0.3490 - val_accuracy: 0.8615\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3534 - val_accuracy: 0.8615\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8896 - val_loss: 0.3432 - val_accuracy: 0.8615\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2167 - accuracy: 0.8940 - val_loss: 0.3464 - val_accuracy: 0.8615\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2151 - accuracy: 0.8918 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3530 - val_accuracy: 0.8615\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2172 - accuracy: 0.8896 - val_loss: 0.3475 - val_accuracy: 0.8615\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2160 - accuracy: 0.8896 - val_loss: 0.3470 - val_accuracy: 0.8615\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3394 - val_accuracy: 0.8615\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2173 - accuracy: 0.8918 - val_loss: 0.3384 - val_accuracy: 0.8615\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3340 - val_accuracy: 0.8718\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2200 - accuracy: 0.8764 - val_loss: 0.3479 - val_accuracy: 0.8615\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2198 - accuracy: 0.8940 - val_loss: 0.3453 - val_accuracy: 0.8615\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.3505 - val_accuracy: 0.8615\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2145 - accuracy: 0.8940 - val_loss: 0.3422 - val_accuracy: 0.8615\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3421 - val_accuracy: 0.8615\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2171 - accuracy: 0.8896 - val_loss: 0.3483 - val_accuracy: 0.8615\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2156 - accuracy: 0.8896 - val_loss: 0.3433 - val_accuracy: 0.8615\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3416 - val_accuracy: 0.8615\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3489 - val_accuracy: 0.8615\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2163 - accuracy: 0.8896 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2142 - accuracy: 0.8940 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3498 - val_accuracy: 0.8615\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3389 - val_accuracy: 0.8615\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2147 - accuracy: 0.8918 - val_loss: 0.3489 - val_accuracy: 0.8615\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2151 - accuracy: 0.8896 - val_loss: 0.3450 - val_accuracy: 0.8615\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3471 - val_accuracy: 0.8615\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2182 - accuracy: 0.8896 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2176 - accuracy: 0.8896 - val_loss: 0.3351 - val_accuracy: 0.8615\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2165 - accuracy: 0.8918 - val_loss: 0.3390 - val_accuracy: 0.8615\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2153 - accuracy: 0.8918 - val_loss: 0.3364 - val_accuracy: 0.8667\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2152 - accuracy: 0.8962 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3427 - val_accuracy: 0.8615\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2156 - accuracy: 0.8852 - val_loss: 0.3446 - val_accuracy: 0.8615\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.93 - 0s 106us/step - loss: 0.2147 - accuracy: 0.8940 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3468 - val_accuracy: 0.8615\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.3378 - val_accuracy: 0.8615\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2164 - accuracy: 0.8896 - val_loss: 0.3394 - val_accuracy: 0.8615\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2180 - accuracy: 0.8896 - val_loss: 0.3411 - val_accuracy: 0.8615\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2177 - accuracy: 0.8874 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3433 - val_accuracy: 0.8615\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3474 - val_accuracy: 0.8615\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3448 - val_accuracy: 0.8615\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2149 - accuracy: 0.8874 - val_loss: 0.3471 - val_accuracy: 0.8615\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3575 - val_accuracy: 0.8615\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2195 - accuracy: 0.8940 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2162 - accuracy: 0.8852 - val_loss: 0.3566 - val_accuracy: 0.8615\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3501 - val_accuracy: 0.8615\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3493 - val_accuracy: 0.8615\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3433 - val_accuracy: 0.8615\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2206 - accuracy: 0.8874 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2168 - accuracy: 0.8940 - val_loss: 0.3432 - val_accuracy: 0.8615\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3409 - val_accuracy: 0.8718\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3384 - val_accuracy: 0.8718\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2185 - accuracy: 0.8896 - val_loss: 0.3429 - val_accuracy: 0.8615\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3402 - val_accuracy: 0.8769\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3515 - val_accuracy: 0.8615\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3400 - val_accuracy: 0.8615\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2189 - accuracy: 0.8896 - val_loss: 0.3465 - val_accuracy: 0.8615\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2207 - accuracy: 0.8918 - val_loss: 0.3447 - val_accuracy: 0.8615\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2176 - accuracy: 0.8874 - val_loss: 0.3491 - val_accuracy: 0.8615\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.93 - 0s 110us/step - loss: 0.2176 - accuracy: 0.8940 - val_loss: 0.3504 - val_accuracy: 0.8615\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3439 - val_accuracy: 0.8615\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3483 - val_accuracy: 0.8615\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2179 - accuracy: 0.8874 - val_loss: 0.3392 - val_accuracy: 0.8615\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3424 - val_accuracy: 0.8615\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2145 - accuracy: 0.8918 - val_loss: 0.3479 - val_accuracy: 0.8615\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2143 - accuracy: 0.8940 - val_loss: 0.3476 - val_accuracy: 0.8615\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2148 - accuracy: 0.8940 - val_loss: 0.3421 - val_accuracy: 0.8615\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2158 - accuracy: 0.8918 - val_loss: 0.3468 - val_accuracy: 0.8667\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2161 - accuracy: 0.8918 - val_loss: 0.3504 - val_accuracy: 0.8615\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3545 - val_accuracy: 0.8615\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2172 - accuracy: 0.8918 - val_loss: 0.3410 - val_accuracy: 0.8667\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2181 - accuracy: 0.8918 - val_loss: 0.3488 - val_accuracy: 0.8615\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3482 - val_accuracy: 0.8615\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2179 - accuracy: 0.8896 - val_loss: 0.3486 - val_accuracy: 0.8615\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2155 - accuracy: 0.8918 - val_loss: 0.3614 - val_accuracy: 0.8615\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3410 - val_accuracy: 0.8718\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3453 - val_accuracy: 0.8615\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2164 - accuracy: 0.8918 - val_loss: 0.3477 - val_accuracy: 0.8615\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2163 - accuracy: 0.8918 - val_loss: 0.3339 - val_accuracy: 0.8667\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8896 - val_loss: 0.3440 - val_accuracy: 0.8615\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2160 - accuracy: 0.8940 - val_loss: 0.3423 - val_accuracy: 0.8615\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2139 - accuracy: 0.8940 - val_loss: 0.3454 - val_accuracy: 0.8615\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2150 - accuracy: 0.8874 - val_loss: 0.3429 - val_accuracy: 0.8615\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2194 - accuracy: 0.8940 - val_loss: 0.3521 - val_accuracy: 0.8615\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3543 - val_accuracy: 0.8615\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3471 - val_accuracy: 0.8615\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2138 - accuracy: 0.8918 - val_loss: 0.3556 - val_accuracy: 0.8615\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3559 - val_accuracy: 0.8615\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2165 - accuracy: 0.8918 - val_loss: 0.3438 - val_accuracy: 0.8615\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2147 - accuracy: 0.8940 - val_loss: 0.3537 - val_accuracy: 0.8615\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2189 - accuracy: 0.8940 - val_loss: 0.3443 - val_accuracy: 0.8615\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2209 - accuracy: 0.8918 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2193 - accuracy: 0.8874 - val_loss: 0.3519 - val_accuracy: 0.8615\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2154 - accuracy: 0.8918 - val_loss: 0.3495 - val_accuracy: 0.8615\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2213 - accuracy: 0.8940 - val_loss: 0.3442 - val_accuracy: 0.8615\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2159 - accuracy: 0.8874 - val_loss: 0.3455 - val_accuracy: 0.8615\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3526 - val_accuracy: 0.8615\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2175 - accuracy: 0.8874 - val_loss: 0.3517 - val_accuracy: 0.8615\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3474 - val_accuracy: 0.8615\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2170 - accuracy: 0.8918 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3490 - val_accuracy: 0.8615\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3462 - val_accuracy: 0.8615\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2185 - accuracy: 0.8896 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2199 - accuracy: 0.8874 - val_loss: 0.3579 - val_accuracy: 0.8667\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2199 - accuracy: 0.8918 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.3562 - val_accuracy: 0.8615\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2170 - accuracy: 0.8918 - val_loss: 0.3431 - val_accuracy: 0.8667\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2177 - accuracy: 0.8896 - val_loss: 0.3517 - val_accuracy: 0.8615\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2147 - accuracy: 0.8918 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2165 - accuracy: 0.8940 - val_loss: 0.3549 - val_accuracy: 0.8615\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2173 - accuracy: 0.8896 - val_loss: 0.3409 - val_accuracy: 0.8667\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2212 - accuracy: 0.8874 - val_loss: 0.3476 - val_accuracy: 0.8615\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2196 - accuracy: 0.8940 - val_loss: 0.3851 - val_accuracy: 0.8564\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3498 - val_accuracy: 0.8667\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2147 - accuracy: 0.8918 - val_loss: 0.3483 - val_accuracy: 0.8667\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3517 - val_accuracy: 0.8615\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3540 - val_accuracy: 0.8615\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2150 - accuracy: 0.8874 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2143 - accuracy: 0.8940 - val_loss: 0.3518 - val_accuracy: 0.8615\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3547 - val_accuracy: 0.8615\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2137 - accuracy: 0.8940 - val_loss: 0.3513 - val_accuracy: 0.8615\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.87 - 0s 111us/step - loss: 0.2169 - accuracy: 0.8874 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2146 - accuracy: 0.8940 - val_loss: 0.3508 - val_accuracy: 0.8615\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2167 - accuracy: 0.8918 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2180 - accuracy: 0.8896 - val_loss: 0.3473 - val_accuracy: 0.8718\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3436 - val_accuracy: 0.8718\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3502 - val_accuracy: 0.8615\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2144 - accuracy: 0.8874 - val_loss: 0.3388 - val_accuracy: 0.8769\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3466 - val_accuracy: 0.8615\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2142 - accuracy: 0.8940 - val_loss: 0.3455 - val_accuracy: 0.8615\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3510 - val_accuracy: 0.8615\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3511 - val_accuracy: 0.8615\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2176 - accuracy: 0.8896 - val_loss: 0.3527 - val_accuracy: 0.8615\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.8940 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3485 - val_accuracy: 0.8615\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2157 - accuracy: 0.8918 - val_loss: 0.3458 - val_accuracy: 0.8667\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2170 - accuracy: 0.8918 - val_loss: 0.3541 - val_accuracy: 0.8615\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3473 - val_accuracy: 0.8615\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3503 - val_accuracy: 0.8615\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2163 - accuracy: 0.8918 - val_loss: 0.3499 - val_accuracy: 0.8615\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2166 - accuracy: 0.8852 - val_loss: 0.3544 - val_accuracy: 0.8615\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2174 - accuracy: 0.8940 - val_loss: 0.3495 - val_accuracy: 0.8615\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2172 - accuracy: 0.8896 - val_loss: 0.3525 - val_accuracy: 0.8615\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2154 - accuracy: 0.8940 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2195 - accuracy: 0.8940 - val_loss: 0.3524 - val_accuracy: 0.8615\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2183 - accuracy: 0.8940 - val_loss: 0.3496 - val_accuracy: 0.8615\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2188 - accuracy: 0.8896 - val_loss: 0.3480 - val_accuracy: 0.8615\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.3558 - val_accuracy: 0.8615\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.8940 - val_loss: 0.3487 - val_accuracy: 0.8615\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2195 - accuracy: 0.8830 - val_loss: 0.3560 - val_accuracy: 0.8615\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2163 - accuracy: 0.8940 - val_loss: 0.3531 - val_accuracy: 0.8615\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2175 - accuracy: 0.8940 - val_loss: 0.3564 - val_accuracy: 0.8615\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2197 - accuracy: 0.8874 - val_loss: 0.3519 - val_accuracy: 0.8615\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3469 - val_accuracy: 0.8615\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2181 - accuracy: 0.8896 - val_loss: 0.3446 - val_accuracy: 0.8615\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2162 - accuracy: 0.8874 - val_loss: 0.3519 - val_accuracy: 0.8615\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3509 - val_accuracy: 0.8615\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2172 - accuracy: 0.8896 - val_loss: 0.3486 - val_accuracy: 0.8667\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2152 - accuracy: 0.8896 - val_loss: 0.3547 - val_accuracy: 0.8615\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3522 - val_accuracy: 0.8615\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2174 - accuracy: 0.8896 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2180 - accuracy: 0.8940 - val_loss: 0.3586 - val_accuracy: 0.8615\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3551 - val_accuracy: 0.8615\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2159 - accuracy: 0.8918 - val_loss: 0.3662 - val_accuracy: 0.8615\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2162 - accuracy: 0.8940 - val_loss: 0.3539 - val_accuracy: 0.8615\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2145 - accuracy: 0.8918 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2150 - accuracy: 0.8918 - val_loss: 0.3574 - val_accuracy: 0.8615\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2166 - accuracy: 0.8918 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2151 - accuracy: 0.8940 - val_loss: 0.3521 - val_accuracy: 0.8615\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3514 - val_accuracy: 0.8615\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2144 - accuracy: 0.8874 - val_loss: 0.3507 - val_accuracy: 0.8615\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2159 - accuracy: 0.8940 - val_loss: 0.3666 - val_accuracy: 0.8615\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2173 - accuracy: 0.8940 - val_loss: 0.3553 - val_accuracy: 0.8615\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2136 - accuracy: 0.8940 - val_loss: 0.3569 - val_accuracy: 0.8615\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2144 - accuracy: 0.8896 - val_loss: 0.3577 - val_accuracy: 0.8615\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2175 - accuracy: 0.8852 - val_loss: 0.3457 - val_accuracy: 0.8615\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.8940 - val_loss: 0.3497 - val_accuracy: 0.8615\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3481 - val_accuracy: 0.8615\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3538 - val_accuracy: 0.8615\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2166 - accuracy: 0.8940 - val_loss: 0.3543 - val_accuracy: 0.8615\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2146 - accuracy: 0.8896 - val_loss: 0.3555 - val_accuracy: 0.8615\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2164 - accuracy: 0.8896 - val_loss: 0.3478 - val_accuracy: 0.8615\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3440 - val_accuracy: 0.8718\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2153 - accuracy: 0.8940 - val_loss: 0.3502 - val_accuracy: 0.8615\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2144 - accuracy: 0.8940 - val_loss: 0.3495 - val_accuracy: 0.8615\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2172 - accuracy: 0.8896 - val_loss: 0.3484 - val_accuracy: 0.8769\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3555 - val_accuracy: 0.8615\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2155 - accuracy: 0.8940 - val_loss: 0.3569 - val_accuracy: 0.8615\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2158 - accuracy: 0.8940 - val_loss: 0.3561 - val_accuracy: 0.8615\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2145 - accuracy: 0.8940 - val_loss: 0.3545 - val_accuracy: 0.8615\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2149 - accuracy: 0.8940 - val_loss: 0.3593 - val_accuracy: 0.8615\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2156 - accuracy: 0.8940 - val_loss: 0.3538 - val_accuracy: 0.8615\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2143 - accuracy: 0.8940 - val_loss: 0.3614 - val_accuracy: 0.8615\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.3541 - val_accuracy: 0.8615\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2160 - accuracy: 0.8874 - val_loss: 0.3634 - val_accuracy: 0.8615\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2203 - accuracy: 0.8940 - val_loss: 0.3567 - val_accuracy: 0.8615\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2206 - accuracy: 0.8874 - val_loss: 0.3489 - val_accuracy: 0.8615\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.3545 - val_accuracy: 0.8615\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 113us/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.3539 - val_accuracy: 0.8615\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2179 - accuracy: 0.8896 - val_loss: 0.3572 - val_accuracy: 0.8615\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2199 - accuracy: 0.8940 - val_loss: 0.3606 - val_accuracy: 0.8615\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2150 - accuracy: 0.8940 - val_loss: 0.3534 - val_accuracy: 0.8615\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2161 - accuracy: 0.8940 - val_loss: 0.3575 - val_accuracy: 0.8615\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2168 - accuracy: 0.8962 - val_loss: 0.3543 - val_accuracy: 0.8667\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2174 - accuracy: 0.8896 - val_loss: 0.3627 - val_accuracy: 0.8615\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2218 - accuracy: 0.8896 - val_loss: 0.3650 - val_accuracy: 0.8564\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2207 - accuracy: 0.8940 - val_loss: 0.3431 - val_accuracy: 0.8718\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 89.20%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.30823400e-06, 9.99994640e-01, 5.50265580e-08],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [5.30823400e-06, 9.99994640e-01, 5.50265580e-08],\n",
       "       [8.37566200e-02, 9.16243430e-01, 2.59588990e-08],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [9.99961730e-01, 3.82956680e-05, 3.64965120e-08],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [6.19388400e-01, 3.80611630e-01, 7.40320800e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [7.25352900e-01, 2.74647000e-01, 7.35279140e-08],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [7.25352900e-01, 2.74647000e-01, 7.35279140e-08],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [2.71173800e-10, 1.00000000e+00, 3.67883450e-17],\n",
       "       [9.99445740e-01, 5.54241600e-04, 2.21928540e-10],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [5.04767800e-01, 4.95232280e-01, 2.42314290e-14],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.56214280e-01, 6.43785700e-01, 8.78455400e-11],\n",
       "       [1.00000000e+00, 2.48974830e-08, 2.67168810e-10],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [1.33085630e-25, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.79229000e-07, 9.99999300e-01, 3.45447000e-30],\n",
       "       [3.00107940e-06, 9.99997000e-01, 3.63144430e-10],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [6.19388400e-01, 3.80611630e-01, 7.40320800e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [5.30823400e-06, 9.99994640e-01, 5.50265580e-08],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [4.14230140e-01, 5.85769900e-01, 2.75869100e-09],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [5.14052000e-02, 9.48594800e-01, 3.65369570e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [5.14052000e-02, 9.48594800e-01, 3.65369570e-11],\n",
       "       [1.52743370e-01, 8.47256600e-01, 5.94654370e-09],\n",
       "       [5.01820830e-05, 9.99949700e-01, 6.12745400e-08],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [2.93332000e-01, 7.06667960e-01, 4.58036900e-09],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [5.14052000e-02, 9.48594800e-01, 3.65369570e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.99990000e-01, 1.00284490e-05, 2.02881300e-14],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [1.42678370e-08, 1.00000000e+00, 1.61928890e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.56214280e-01, 6.43785700e-01, 8.78455400e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [1.41631300e-06, 9.99998570e-01, 0.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.99998570e-01, 1.43675890e-06, 1.46107070e-12],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [1.36234040e-30, 1.00000000e+00, 0.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [1.36234040e-30, 1.00000000e+00, 0.00000000e+00],\n",
       "       [8.37566200e-02, 9.16243430e-01, 2.59588990e-08],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [5.28450500e-09, 1.00000000e+00, 1.32778490e-15],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.99998570e-01, 1.43675890e-06, 1.46107070e-12],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.19388400e-01, 3.80611630e-01, 7.40320800e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [1.42678370e-08, 1.00000000e+00, 1.61928890e-11],\n",
       "       [5.14052000e-02, 9.48594800e-01, 3.65369570e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.19388400e-01, 3.80611630e-01, 7.40320800e-11],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.19221900e-09, 1.00000000e+00, 2.97186640e-10],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [9.99969000e-01, 3.10403450e-05, 1.66937390e-19],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.99999400e-01, 6.19166300e-07, 2.80283690e-10],\n",
       "       [1.30241550e-06, 9.99998700e-01, 2.14023550e-16],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.99969000e-01, 3.10403450e-05, 1.66937390e-19],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.99961730e-01, 3.82956680e-05, 3.64965120e-08],\n",
       "       [9.99994750e-01, 2.09919380e-14, 5.26300940e-06],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [2.71173800e-10, 1.00000000e+00, 3.67883450e-17],\n",
       "       [1.36234040e-30, 1.00000000e+00, 0.00000000e+00],\n",
       "       [8.37566200e-02, 9.16243430e-01, 2.59588990e-08],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [5.14052000e-02, 9.48594800e-01, 3.65369570e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.12964600e-11, 1.00000000e+00, 3.48535000e-17],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.04950420e-15, 1.00000000e+00, 1.77062730e-17],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [7.25352900e-01, 2.74647000e-01, 7.35279140e-08],\n",
       "       [1.00000000e+00, 2.48974830e-08, 2.67168810e-10],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.99955060e-01, 4.49767760e-05, 2.63114890e-09],\n",
       "       [2.52227510e-01, 7.47772460e-01, 2.06558500e-10],\n",
       "       [8.03140300e-14, 1.00000000e+00, 4.14180160e-38],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [9.37320800e-01, 6.26791300e-02, 9.36070300e-12],\n",
       "       [1.18871840e-35, 1.00000000e+00, 0.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [7.25352900e-01, 2.74647000e-01, 7.35279140e-08],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [4.85634230e-04, 9.99514340e-01, 5.15793040e-16],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [3.19221900e-09, 1.00000000e+00, 2.97186640e-10],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [6.78003200e-01, 3.21996870e-01, 4.50554180e-11],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [3.86410330e-09, 9.56309000e-09, 1.00000000e+00],\n",
       "       [9.94402200e-09, 1.22526735e-08, 1.00000000e+00],\n",
       "       [5.17180520e-17, 1.00000000e+00, 1.02142410e-31],\n",
       "       [6.19388400e-01, 3.80611630e-01, 7.40320800e-11],\n",
       "       [1.30241550e-06, 9.99998700e-01, 2.14023550e-16]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636686390532544"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636686390532544"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GA15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS241     1\n",
       "1      BCH-SA-01     1\n",
       "2         NRS219     1\n",
       "3         NRS209     2\n",
       "4         NRS001     1\n",
       "..           ...   ...\n",
       "190         GA15     1\n",
       "191       NRS246     1\n",
       "192          115     1\n",
       "193          312     1\n",
       "194  CFBREBSa112     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 448us/step - loss: 0.8501 - accuracy: 0.7020 - val_loss: 0.6750 - val_accuracy: 0.7179\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.6133 - accuracy: 0.7594 - val_loss: 0.5578 - val_accuracy: 0.7128\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.5148 - accuracy: 0.7815 - val_loss: 0.4737 - val_accuracy: 0.8359\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.4762 - accuracy: 0.7947 - val_loss: 0.4469 - val_accuracy: 0.8410\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.4600 - accuracy: 0.7704 - val_loss: 0.4376 - val_accuracy: 0.7282\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.4216 - accuracy: 0.7903 - val_loss: 0.4192 - val_accuracy: 0.8205\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.4202 - accuracy: 0.8057 - val_loss: 0.3999 - val_accuracy: 0.8308\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.3874 - val_accuracy: 0.7795\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 344us/step - loss: 0.3929 - accuracy: 0.8234 - val_loss: 0.4023 - val_accuracy: 0.7897\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.3863 - accuracy: 0.8146 - val_loss: 0.3707 - val_accuracy: 0.8051\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.3743 - accuracy: 0.8300 - val_loss: 0.3667 - val_accuracy: 0.8308\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.3665 - accuracy: 0.8278 - val_loss: 0.3678 - val_accuracy: 0.8308\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.3707 - accuracy: 0.8499 - val_loss: 0.3603 - val_accuracy: 0.8154\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.3653 - accuracy: 0.8256 - val_loss: 0.3544 - val_accuracy: 0.8051\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.3628 - accuracy: 0.8300 - val_loss: 0.3723 - val_accuracy: 0.8359\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.3635 - accuracy: 0.8190 - val_loss: 0.3576 - val_accuracy: 0.8513\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.3494 - accuracy: 0.8234 - val_loss: 0.3512 - val_accuracy: 0.8564\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.3480 - accuracy: 0.8366 - val_loss: 0.3467 - val_accuracy: 0.8359\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.3445 - accuracy: 0.8411 - val_loss: 0.3405 - val_accuracy: 0.8256\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.3401 - accuracy: 0.8300 - val_loss: 0.3406 - val_accuracy: 0.8513\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.3386 - accuracy: 0.8411 - val_loss: 0.3478 - val_accuracy: 0.8462\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.3359 - accuracy: 0.8455 - val_loss: 0.3503 - val_accuracy: 0.8462\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3420 - accuracy: 0.8344 - val_loss: 0.3310 - val_accuracy: 0.8410\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.3319 - accuracy: 0.8411 - val_loss: 0.3333 - val_accuracy: 0.8154\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 486us/step - loss: 0.3336 - accuracy: 0.8521 - val_loss: 0.3412 - val_accuracy: 0.8256\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.3292 - accuracy: 0.8300 - val_loss: 0.3266 - val_accuracy: 0.8205\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.3228 - accuracy: 0.8609 - val_loss: 0.3229 - val_accuracy: 0.8513\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.3254 - accuracy: 0.8411 - val_loss: 0.3254 - val_accuracy: 0.8308\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3223 - accuracy: 0.8477 - val_loss: 0.3223 - val_accuracy: 0.8564\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.3346 - accuracy: 0.8366 - val_loss: 0.3268 - val_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 421us/step - loss: 0.3187 - accuracy: 0.8344 - val_loss: 0.3209 - val_accuracy: 0.8308\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 407us/step - loss: 0.3174 - accuracy: 0.8587 - val_loss: 0.3327 - val_accuracy: 0.8410\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 341us/step - loss: 0.3203 - accuracy: 0.8455 - val_loss: 0.3175 - val_accuracy: 0.8615\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.3157 - accuracy: 0.8521 - val_loss: 0.3192 - val_accuracy: 0.8308\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.3091 - accuracy: 0.8477 - val_loss: 0.3131 - val_accuracy: 0.8359\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.3140 - accuracy: 0.8389 - val_loss: 0.3129 - val_accuracy: 0.8615\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.3111 - accuracy: 0.8609 - val_loss: 0.3705 - val_accuracy: 0.8154\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.3187 - accuracy: 0.8411 - val_loss: 0.3338 - val_accuracy: 0.8256\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 370us/step - loss: 0.3093 - accuracy: 0.8433 - val_loss: 0.3112 - val_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.3077 - accuracy: 0.8675 - val_loss: 0.3105 - val_accuracy: 0.8615\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.3019 - accuracy: 0.8455 - val_loss: 0.3129 - val_accuracy: 0.8205\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.3011 - accuracy: 0.8521 - val_loss: 0.3073 - val_accuracy: 0.8513\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2984 - accuracy: 0.8631 - val_loss: 0.3423 - val_accuracy: 0.8256\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3093 - accuracy: 0.8499 - val_loss: 0.3064 - val_accuracy: 0.8615\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.3022 - accuracy: 0.8411 - val_loss: 0.3103 - val_accuracy: 0.8718\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.3046 - accuracy: 0.8411 - val_loss: 0.3043 - val_accuracy: 0.8615\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3000 - accuracy: 0.8587 - val_loss: 0.3301 - val_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.3027 - accuracy: 0.8609 - val_loss: 0.3027 - val_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2951 - accuracy: 0.8499 - val_loss: 0.3329 - val_accuracy: 0.8564\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.3050 - accuracy: 0.8499 - val_loss: 0.3018 - val_accuracy: 0.8615\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3069 - accuracy: 0.8609 - val_loss: 0.3044 - val_accuracy: 0.8359\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.3172 - accuracy: 0.8234 - val_loss: 0.3221 - val_accuracy: 0.8256\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 324us/step - loss: 0.2903 - accuracy: 0.8653 - val_loss: 0.3019 - val_accuracy: 0.8718\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2962 - accuracy: 0.8477 - val_loss: 0.3055 - val_accuracy: 0.8718\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2914 - accuracy: 0.8521 - val_loss: 0.3096 - val_accuracy: 0.8256\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2930 - accuracy: 0.8631 - val_loss: 0.3086 - val_accuracy: 0.8308\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2838 - accuracy: 0.8698 - val_loss: 0.2962 - val_accuracy: 0.8718\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.3060 - accuracy: 0.8543 - val_loss: 0.2991 - val_accuracy: 0.8718\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2836 - accuracy: 0.8631 - val_loss: 0.2965 - val_accuracy: 0.8769\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2861 - accuracy: 0.8631 - val_loss: 0.3119 - val_accuracy: 0.8718\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2923 - accuracy: 0.8631 - val_loss: 0.3033 - val_accuracy: 0.8718\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2916 - accuracy: 0.8477 - val_loss: 0.2953 - val_accuracy: 0.8718\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2949 - accuracy: 0.8499 - val_loss: 0.3015 - val_accuracy: 0.8718\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2811 - accuracy: 0.8698 - val_loss: 0.3064 - val_accuracy: 0.8615\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.3009 - accuracy: 0.8587 - val_loss: 0.3068 - val_accuracy: 0.8769\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2913 - accuracy: 0.8521 - val_loss: 0.2912 - val_accuracy: 0.8718\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2844 - accuracy: 0.8764 - val_loss: 0.3030 - val_accuracy: 0.8718\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2882 - accuracy: 0.8433 - val_loss: 0.2988 - val_accuracy: 0.8718\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2991 - accuracy: 0.8477 - val_loss: 0.2880 - val_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2777 - accuracy: 0.8720 - val_loss: 0.2903 - val_accuracy: 0.8718\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2800 - accuracy: 0.8653 - val_loss: 0.3035 - val_accuracy: 0.8718\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2827 - accuracy: 0.8698 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2867 - accuracy: 0.8675 - val_loss: 0.2950 - val_accuracy: 0.8769\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2826 - accuracy: 0.8631 - val_loss: 0.2885 - val_accuracy: 0.8821\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2834 - accuracy: 0.8653 - val_loss: 0.2982 - val_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2826 - accuracy: 0.8764 - val_loss: 0.2999 - val_accuracy: 0.8769\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2776 - accuracy: 0.8742 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2787 - accuracy: 0.8587 - val_loss: 0.2897 - val_accuracy: 0.8718\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2747 - accuracy: 0.8698 - val_loss: 0.2864 - val_accuracy: 0.8821\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2780 - accuracy: 0.8609 - val_loss: 0.2953 - val_accuracy: 0.8718\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2718 - accuracy: 0.8742 - val_loss: 0.2880 - val_accuracy: 0.8769\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2811 - accuracy: 0.8720 - val_loss: 0.2914 - val_accuracy: 0.8718\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2835 - accuracy: 0.8609 - val_loss: 0.2834 - val_accuracy: 0.8821\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2841 - accuracy: 0.8698 - val_loss: 0.2887 - val_accuracy: 0.8923\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2910 - accuracy: 0.8411 - val_loss: 0.2956 - val_accuracy: 0.8718\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2959 - accuracy: 0.8499 - val_loss: 0.3114 - val_accuracy: 0.8718\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2905 - accuracy: 0.8565 - val_loss: 0.2877 - val_accuracy: 0.8821\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2765 - accuracy: 0.8764 - val_loss: 0.2914 - val_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2734 - accuracy: 0.8764 - val_loss: 0.2872 - val_accuracy: 0.8821\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2708 - accuracy: 0.8720 - val_loss: 0.3035 - val_accuracy: 0.8667\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2732 - accuracy: 0.8742 - val_loss: 0.2859 - val_accuracy: 0.8667\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2715 - accuracy: 0.8631 - val_loss: 0.2862 - val_accuracy: 0.8769\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2735 - accuracy: 0.8742 - val_loss: 0.2847 - val_accuracy: 0.8667\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2734 - accuracy: 0.8698 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2739 - accuracy: 0.8499 - val_loss: 0.2912 - val_accuracy: 0.8615\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2703 - accuracy: 0.8764 - val_loss: 0.2805 - val_accuracy: 0.8923\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2645 - accuracy: 0.8720 - val_loss: 0.3038 - val_accuracy: 0.8769\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2762 - accuracy: 0.8631 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2801 - accuracy: 0.8631 - val_loss: 0.2842 - val_accuracy: 0.8821\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2698 - accuracy: 0.8764 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2681 - accuracy: 0.8742 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2684 - accuracy: 0.8720 - val_loss: 0.2804 - val_accuracy: 0.8769\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2708 - accuracy: 0.8742 - val_loss: 0.2956 - val_accuracy: 0.8769\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2720 - accuracy: 0.8631 - val_loss: 0.2818 - val_accuracy: 0.8923\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2706 - accuracy: 0.8698 - val_loss: 0.2855 - val_accuracy: 0.8667\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2724 - accuracy: 0.8653 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2627 - accuracy: 0.8786 - val_loss: 0.2847 - val_accuracy: 0.8821\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2735 - accuracy: 0.8720 - val_loss: 0.2903 - val_accuracy: 0.8821\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2658 - accuracy: 0.8852 - val_loss: 0.2837 - val_accuracy: 0.8667\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2688 - accuracy: 0.8808 - val_loss: 0.2932 - val_accuracy: 0.8769\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2783 - accuracy: 0.8764 - val_loss: 0.2821 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2698 - accuracy: 0.8786 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2652 - accuracy: 0.8786 - val_loss: 0.2902 - val_accuracy: 0.8769\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2783 - accuracy: 0.8675 - val_loss: 0.3117 - val_accuracy: 0.8769\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2734 - accuracy: 0.8653 - val_loss: 0.2823 - val_accuracy: 0.8769\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2625 - accuracy: 0.8764 - val_loss: 0.2780 - val_accuracy: 0.8769\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2638 - accuracy: 0.8698 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2711 - accuracy: 0.8742 - val_loss: 0.2905 - val_accuracy: 0.8769\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2709 - accuracy: 0.8653 - val_loss: 0.2818 - val_accuracy: 0.8821\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2648 - accuracy: 0.8698 - val_loss: 0.2787 - val_accuracy: 0.8821\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2774 - accuracy: 0.8587 - val_loss: 0.2801 - val_accuracy: 0.8667\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2616 - accuracy: 0.8742 - val_loss: 0.2805 - val_accuracy: 0.8769\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2626 - accuracy: 0.8742 - val_loss: 0.2818 - val_accuracy: 0.8769\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2630 - accuracy: 0.8698 - val_loss: 0.2802 - val_accuracy: 0.8769\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2709 - accuracy: 0.8720 - val_loss: 0.2780 - val_accuracy: 0.8821\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2583 - accuracy: 0.8786 - val_loss: 0.2827 - val_accuracy: 0.8769\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2712 - accuracy: 0.8720 - val_loss: 0.2813 - val_accuracy: 0.8769\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2705 - accuracy: 0.8631 - val_loss: 0.2781 - val_accuracy: 0.8769\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2686 - accuracy: 0.8742 - val_loss: 0.2780 - val_accuracy: 0.8769\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2668 - accuracy: 0.8720 - val_loss: 0.2777 - val_accuracy: 0.8769\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2616 - accuracy: 0.8675 - val_loss: 0.2852 - val_accuracy: 0.8615\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2683 - accuracy: 0.8653 - val_loss: 0.2816 - val_accuracy: 0.8821\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2658 - accuracy: 0.8675 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2599 - accuracy: 0.8742 - val_loss: 0.2800 - val_accuracy: 0.8769\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2618 - accuracy: 0.8720 - val_loss: 0.2773 - val_accuracy: 0.8769\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2561 - accuracy: 0.8830 - val_loss: 0.3286 - val_accuracy: 0.8564\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2726 - accuracy: 0.8896 - val_loss: 0.2787 - val_accuracy: 0.8769\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2623 - accuracy: 0.8698 - val_loss: 0.2933 - val_accuracy: 0.8769\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2622 - accuracy: 0.8587 - val_loss: 0.2780 - val_accuracy: 0.8923\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2587 - accuracy: 0.8764 - val_loss: 0.2770 - val_accuracy: 0.8769\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2576 - accuracy: 0.8698 - val_loss: 0.2844 - val_accuracy: 0.8615\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2623 - accuracy: 0.8764 - val_loss: 0.2773 - val_accuracy: 0.8769\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2629 - accuracy: 0.8720 - val_loss: 0.2821 - val_accuracy: 0.8769\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2557 - accuracy: 0.8698 - val_loss: 0.2948 - val_accuracy: 0.8718\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2731 - accuracy: 0.8742 - val_loss: 0.2807 - val_accuracy: 0.8769\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2569 - accuracy: 0.8742 - val_loss: 0.2739 - val_accuracy: 0.8769\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2589 - accuracy: 0.8764 - val_loss: 0.2794 - val_accuracy: 0.8769\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2645 - accuracy: 0.8786 - val_loss: 0.2795 - val_accuracy: 0.8769\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2564 - accuracy: 0.8720 - val_loss: 0.2823 - val_accuracy: 0.8615\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2585 - accuracy: 0.8720 - val_loss: 0.2795 - val_accuracy: 0.8769\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2577 - accuracy: 0.8808 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2641 - accuracy: 0.8631 - val_loss: 0.2783 - val_accuracy: 0.8769\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2593 - accuracy: 0.8764 - val_loss: 0.2777 - val_accuracy: 0.8769\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2655 - accuracy: 0.8786 - val_loss: 0.2857 - val_accuracy: 0.8769\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2582 - accuracy: 0.8653 - val_loss: 0.2786 - val_accuracy: 0.8769\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2565 - accuracy: 0.8764 - val_loss: 0.2837 - val_accuracy: 0.8769\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2601 - accuracy: 0.8698 - val_loss: 0.2797 - val_accuracy: 0.8821\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2557 - accuracy: 0.8764 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2615 - accuracy: 0.8742 - val_loss: 0.2767 - val_accuracy: 0.8923\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2615 - accuracy: 0.8543 - val_loss: 0.2925 - val_accuracy: 0.8615\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2577 - accuracy: 0.8720 - val_loss: 0.2869 - val_accuracy: 0.8923\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2619 - accuracy: 0.8587 - val_loss: 0.2838 - val_accuracy: 0.8769\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2644 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8769\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2571 - accuracy: 0.8808 - val_loss: 0.2758 - val_accuracy: 0.8923\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2528 - accuracy: 0.8808 - val_loss: 0.2774 - val_accuracy: 0.8769\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2609 - accuracy: 0.8742 - val_loss: 0.2770 - val_accuracy: 0.8923\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2552 - accuracy: 0.8742 - val_loss: 0.2752 - val_accuracy: 0.8769\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2564 - accuracy: 0.8786 - val_loss: 0.2841 - val_accuracy: 0.8718\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2616 - accuracy: 0.8786 - val_loss: 0.2947 - val_accuracy: 0.8769\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2520 - accuracy: 0.8698 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2648 - accuracy: 0.8698 - val_loss: 0.2906 - val_accuracy: 0.8769\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2495 - accuracy: 0.8808 - val_loss: 0.2757 - val_accuracy: 0.8769\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2474 - accuracy: 0.8720 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2498 - accuracy: 0.8698 - val_loss: 0.3162 - val_accuracy: 0.7795\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2626 - accuracy: 0.8587 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2554 - accuracy: 0.8609 - val_loss: 0.2801 - val_accuracy: 0.8769\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2528 - accuracy: 0.8786 - val_loss: 0.2878 - val_accuracy: 0.8615\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2729 - accuracy: 0.8742 - val_loss: 0.2888 - val_accuracy: 0.8718\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2592 - accuracy: 0.8720 - val_loss: 0.2744 - val_accuracy: 0.8769\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2507 - accuracy: 0.8764 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2640 - accuracy: 0.8764 - val_loss: 0.2785 - val_accuracy: 0.8769\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2516 - accuracy: 0.8764 - val_loss: 0.2784 - val_accuracy: 0.8769\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2507 - accuracy: 0.8764 - val_loss: 0.2758 - val_accuracy: 0.8923\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2512 - accuracy: 0.8742 - val_loss: 0.2802 - val_accuracy: 0.8667\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2509 - accuracy: 0.8830 - val_loss: 0.2782 - val_accuracy: 0.8821\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2558 - accuracy: 0.8720 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2611 - accuracy: 0.8742 - val_loss: 0.2768 - val_accuracy: 0.8923\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2505 - accuracy: 0.8786 - val_loss: 0.2815 - val_accuracy: 0.8769\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2595 - accuracy: 0.8543 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2539 - accuracy: 0.8786 - val_loss: 0.2975 - val_accuracy: 0.8769\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2542 - accuracy: 0.8675 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2534 - accuracy: 0.8764 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2561 - accuracy: 0.8675 - val_loss: 0.2948 - val_accuracy: 0.8769\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2685 - accuracy: 0.8764 - val_loss: 0.2918 - val_accuracy: 0.8769\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2511 - accuracy: 0.8808 - val_loss: 0.2798 - val_accuracy: 0.8769\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2502 - accuracy: 0.8764 - val_loss: 0.2837 - val_accuracy: 0.8769\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2547 - accuracy: 0.8764 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2702 - accuracy: 0.8764 - val_loss: 0.2805 - val_accuracy: 0.8923\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2601 - accuracy: 0.8521 - val_loss: 0.2775 - val_accuracy: 0.8872\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2541 - accuracy: 0.8786 - val_loss: 0.2989 - val_accuracy: 0.8718\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2628 - accuracy: 0.8720 - val_loss: 0.2815 - val_accuracy: 0.8769\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2635 - accuracy: 0.8587 - val_loss: 0.2874 - val_accuracy: 0.8615\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2606 - accuracy: 0.8764 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2522 - accuracy: 0.8764 - val_loss: 0.2783 - val_accuracy: 0.8923\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2571 - accuracy: 0.8786 - val_loss: 0.2896 - val_accuracy: 0.8821\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2601 - accuracy: 0.8675 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2483 - accuracy: 0.8631 - val_loss: 0.2798 - val_accuracy: 0.8769\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2504 - accuracy: 0.8764 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2536 - accuracy: 0.8764 - val_loss: 0.2774 - val_accuracy: 0.8769\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2624 - accuracy: 0.8565 - val_loss: 0.2778 - val_accuracy: 0.8872\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2461 - accuracy: 0.8764 - val_loss: 0.2928 - val_accuracy: 0.8769\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2630 - accuracy: 0.8720 - val_loss: 0.2773 - val_accuracy: 0.8769\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2502 - accuracy: 0.8830 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2742 - accuracy: 0.8521 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2520 - accuracy: 0.8675 - val_loss: 0.2784 - val_accuracy: 0.8769\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2480 - accuracy: 0.8764 - val_loss: 0.2774 - val_accuracy: 0.8872\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2444 - accuracy: 0.8764 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2514 - accuracy: 0.8720 - val_loss: 0.2786 - val_accuracy: 0.8769\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2478 - accuracy: 0.8786 - val_loss: 0.2841 - val_accuracy: 0.8615\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2536 - accuracy: 0.8786 - val_loss: 0.2778 - val_accuracy: 0.8718\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2531 - accuracy: 0.8720 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 119us/step - loss: 0.2491 - accuracy: 0.8786 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2534 - accuracy: 0.8764 - val_loss: 0.2738 - val_accuracy: 0.8923\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2483 - accuracy: 0.8742 - val_loss: 0.2793 - val_accuracy: 0.8769\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 358us/step - loss: 0.2489 - accuracy: 0.8764 - val_loss: 0.2796 - val_accuracy: 0.8769\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2595 - accuracy: 0.8742 - val_loss: 0.2872 - val_accuracy: 0.8769\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2506 - accuracy: 0.8675 - val_loss: 0.2772 - val_accuracy: 0.8769\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2467 - accuracy: 0.8808 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2526 - accuracy: 0.8720 - val_loss: 0.2787 - val_accuracy: 0.8769\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2485 - accuracy: 0.8742 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2527 - accuracy: 0.8742 - val_loss: 0.2785 - val_accuracy: 0.8923\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2496 - accuracy: 0.8764 - val_loss: 0.2823 - val_accuracy: 0.8615\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2515 - accuracy: 0.8830 - val_loss: 0.2802 - val_accuracy: 0.8769\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2506 - accuracy: 0.8786 - val_loss: 0.2919 - val_accuracy: 0.8718\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2586 - accuracy: 0.8742 - val_loss: 0.2813 - val_accuracy: 0.8769\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2578 - accuracy: 0.8830 - val_loss: 0.3027 - val_accuracy: 0.8718\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2522 - accuracy: 0.8808 - val_loss: 0.2779 - val_accuracy: 0.8769\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2516 - accuracy: 0.8830 - val_loss: 0.2792 - val_accuracy: 0.8872\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2479 - accuracy: 0.8808 - val_loss: 0.2796 - val_accuracy: 0.8769\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 0.2864 - val_accuracy: 0.8769\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2527 - accuracy: 0.8808 - val_loss: 0.2785 - val_accuracy: 0.8769\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2444 - accuracy: 0.8764 - val_loss: 0.2804 - val_accuracy: 0.8769\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2451 - accuracy: 0.8764 - val_loss: 0.2869 - val_accuracy: 0.8769\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2480 - accuracy: 0.8764 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2487 - accuracy: 0.8808 - val_loss: 0.2754 - val_accuracy: 0.8718\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2494 - accuracy: 0.8675 - val_loss: 0.2785 - val_accuracy: 0.8923\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2499 - accuracy: 0.8742 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2560 - accuracy: 0.8609 - val_loss: 0.2774 - val_accuracy: 0.8923\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2617 - accuracy: 0.8786 - val_loss: 0.2800 - val_accuracy: 0.8769\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2506 - accuracy: 0.8786 - val_loss: 0.2866 - val_accuracy: 0.8718\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2593 - accuracy: 0.8521 - val_loss: 0.2963 - val_accuracy: 0.8718\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2572 - accuracy: 0.8543 - val_loss: 0.2849 - val_accuracy: 0.8769\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2443 - accuracy: 0.8698 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2479 - accuracy: 0.8698 - val_loss: 0.2856 - val_accuracy: 0.8821\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2442 - accuracy: 0.8698 - val_loss: 0.2821 - val_accuracy: 0.8769\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2496 - accuracy: 0.8720 - val_loss: 0.2786 - val_accuracy: 0.8923\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2475 - accuracy: 0.8786 - val_loss: 0.2835 - val_accuracy: 0.8769\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2470 - accuracy: 0.8675 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2590 - accuracy: 0.8808 - val_loss: 0.3097 - val_accuracy: 0.8718\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2551 - accuracy: 0.8764 - val_loss: 0.2796 - val_accuracy: 0.8872\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2508 - accuracy: 0.8698 - val_loss: 0.2809 - val_accuracy: 0.8821\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2551 - accuracy: 0.8742 - val_loss: 0.2842 - val_accuracy: 0.8872\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2497 - accuracy: 0.8808 - val_loss: 0.2793 - val_accuracy: 0.8769\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2493 - accuracy: 0.8742 - val_loss: 0.2864 - val_accuracy: 0.8769\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2502 - accuracy: 0.8698 - val_loss: 0.2875 - val_accuracy: 0.8769\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2441 - accuracy: 0.8764 - val_loss: 0.2984 - val_accuracy: 0.8769\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2508 - accuracy: 0.8830 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2556 - accuracy: 0.8786 - val_loss: 0.2879 - val_accuracy: 0.8718\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2800 - val_accuracy: 0.8923\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2538 - accuracy: 0.8698 - val_loss: 0.2875 - val_accuracy: 0.8872\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2760 - accuracy: 0.8322 - val_loss: 0.2838 - val_accuracy: 0.8769\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2569 - accuracy: 0.8698 - val_loss: 0.3355 - val_accuracy: 0.7795\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2643 - accuracy: 0.8543 - val_loss: 0.2828 - val_accuracy: 0.8923\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2447 - accuracy: 0.8852 - val_loss: 0.2831 - val_accuracy: 0.8769\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2489 - accuracy: 0.8764 - val_loss: 0.2922 - val_accuracy: 0.8872\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2423 - accuracy: 0.8808 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2551 - accuracy: 0.8675 - val_loss: 0.2900 - val_accuracy: 0.8821\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2452 - accuracy: 0.8720 - val_loss: 0.2837 - val_accuracy: 0.8872\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2486 - accuracy: 0.8764 - val_loss: 0.2806 - val_accuracy: 0.8872\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.2820 - val_accuracy: 0.8872\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2506 - accuracy: 0.8852 - val_loss: 0.2962 - val_accuracy: 0.8769\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2523 - accuracy: 0.8565 - val_loss: 0.2803 - val_accuracy: 0.8872\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2428 - accuracy: 0.8786 - val_loss: 0.2827 - val_accuracy: 0.8872\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2562 - accuracy: 0.8698 - val_loss: 0.2791 - val_accuracy: 0.8718\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2448 - accuracy: 0.8764 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2473 - accuracy: 0.8742 - val_loss: 0.2845 - val_accuracy: 0.8769\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2444 - accuracy: 0.8742 - val_loss: 0.2838 - val_accuracy: 0.8769\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2448 - accuracy: 0.8786 - val_loss: 0.2859 - val_accuracy: 0.8769\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2444 - accuracy: 0.8808 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2605 - accuracy: 0.8698 - val_loss: 0.2811 - val_accuracy: 0.8923\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2524 - accuracy: 0.8698 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2443 - accuracy: 0.8764 - val_loss: 0.2844 - val_accuracy: 0.8769\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2561 - accuracy: 0.8764 - val_loss: 0.2821 - val_accuracy: 0.8872\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2524 - accuracy: 0.8675 - val_loss: 0.2819 - val_accuracy: 0.8923\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2500 - accuracy: 0.8764 - val_loss: 0.2835 - val_accuracy: 0.8872\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2451 - accuracy: 0.8764 - val_loss: 0.2795 - val_accuracy: 0.8718\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2460 - accuracy: 0.8764 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2502 - accuracy: 0.8764 - val_loss: 0.2857 - val_accuracy: 0.8718\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2524 - accuracy: 0.8698 - val_loss: 0.2801 - val_accuracy: 0.8872\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2479 - accuracy: 0.8742 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2480 - accuracy: 0.8808 - val_loss: 0.2811 - val_accuracy: 0.8872\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2475 - accuracy: 0.8786 - val_loss: 0.2812 - val_accuracy: 0.8872\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2427 - accuracy: 0.8720 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.2421 - accuracy: 0.8808 - val_loss: 0.2834 - val_accuracy: 0.8769\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 350us/step - loss: 0.2426 - accuracy: 0.8698 - val_loss: 0.2819 - val_accuracy: 0.8872\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2517 - accuracy: 0.8764 - val_loss: 0.2800 - val_accuracy: 0.8923\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8872\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.2470 - accuracy: 0.8742 - val_loss: 0.2805 - val_accuracy: 0.8872\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2452 - accuracy: 0.8808 - val_loss: 0.2851 - val_accuracy: 0.8769\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2454 - accuracy: 0.8720 - val_loss: 0.2794 - val_accuracy: 0.8872\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2499 - accuracy: 0.8653 - val_loss: 0.2832 - val_accuracy: 0.8769\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2410 - accuracy: 0.8742 - val_loss: 0.2857 - val_accuracy: 0.8615\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2482 - accuracy: 0.8720 - val_loss: 0.2847 - val_accuracy: 0.8769\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2518 - accuracy: 0.8808 - val_loss: 0.2837 - val_accuracy: 0.8872\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2485 - accuracy: 0.8720 - val_loss: 0.2967 - val_accuracy: 0.8769\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2406 - accuracy: 0.8786 - val_loss: 0.2876 - val_accuracy: 0.8872\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2442 - accuracy: 0.8764 - val_loss: 0.2831 - val_accuracy: 0.8769\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2514 - accuracy: 0.8764 - val_loss: 0.2823 - val_accuracy: 0.8872\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2447 - accuracy: 0.8698 - val_loss: 0.2931 - val_accuracy: 0.8872\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2501 - accuracy: 0.8742 - val_loss: 0.2828 - val_accuracy: 0.8872\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2479 - accuracy: 0.8786 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2428 - accuracy: 0.8720 - val_loss: 0.2893 - val_accuracy: 0.8718\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 0.2895 - val_accuracy: 0.8769\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2442 - accuracy: 0.8720 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2487 - accuracy: 0.8742 - val_loss: 0.2822 - val_accuracy: 0.8872\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2624 - accuracy: 0.8653 - val_loss: 0.2898 - val_accuracy: 0.8769\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2478 - accuracy: 0.8808 - val_loss: 0.2867 - val_accuracy: 0.8872\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2446 - accuracy: 0.8786 - val_loss: 0.2824 - val_accuracy: 0.8872\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2451 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.2835 - val_accuracy: 0.8872\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 115us/step - loss: 0.2465 - accuracy: 0.8786 - val_loss: 0.2824 - val_accuracy: 0.8923\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2479 - accuracy: 0.8808 - val_loss: 0.2921 - val_accuracy: 0.8769\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2463 - accuracy: 0.8852 - val_loss: 0.2849 - val_accuracy: 0.8769\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2450 - accuracy: 0.8808 - val_loss: 0.2800 - val_accuracy: 0.8821\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2433 - accuracy: 0.8764 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2449 - accuracy: 0.8609 - val_loss: 0.2920 - val_accuracy: 0.8769\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2427 - accuracy: 0.8764 - val_loss: 0.2821 - val_accuracy: 0.8872\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2443 - accuracy: 0.8720 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2479 - accuracy: 0.8808 - val_loss: 0.2842 - val_accuracy: 0.8872\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2436 - accuracy: 0.8786 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2600 - accuracy: 0.8742 - val_loss: 0.2866 - val_accuracy: 0.8872\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2503 - accuracy: 0.8742 - val_loss: 0.2940 - val_accuracy: 0.8718\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2473 - accuracy: 0.8764 - val_loss: 0.2822 - val_accuracy: 0.8872\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2425 - accuracy: 0.8808 - val_loss: 0.2927 - val_accuracy: 0.8769\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2456 - accuracy: 0.8720 - val_loss: 0.2835 - val_accuracy: 0.8718\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2447 - accuracy: 0.8830 - val_loss: 0.2880 - val_accuracy: 0.8872\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.2883 - val_accuracy: 0.8718\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2460 - accuracy: 0.8830 - val_loss: 0.2891 - val_accuracy: 0.8872\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2434 - accuracy: 0.8808 - val_loss: 0.2863 - val_accuracy: 0.8872\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2452 - accuracy: 0.8786 - val_loss: 0.2860 - val_accuracy: 0.8718\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2454 - accuracy: 0.8698 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2405 - accuracy: 0.8764 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2400 - accuracy: 0.8786 - val_loss: 0.2893 - val_accuracy: 0.8769\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2438 - accuracy: 0.8764 - val_loss: 0.2828 - val_accuracy: 0.8718\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2428 - accuracy: 0.8764 - val_loss: 0.2849 - val_accuracy: 0.8769\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2423 - accuracy: 0.8653 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2477 - accuracy: 0.8742 - val_loss: 0.2873 - val_accuracy: 0.8718\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2471 - accuracy: 0.8786 - val_loss: 0.2802 - val_accuracy: 0.8872\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2445 - accuracy: 0.8720 - val_loss: 0.2912 - val_accuracy: 0.8718\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2475 - accuracy: 0.8764 - val_loss: 0.2835 - val_accuracy: 0.8872\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2464 - accuracy: 0.8742 - val_loss: 0.2858 - val_accuracy: 0.8872\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2442 - accuracy: 0.8764 - val_loss: 0.2876 - val_accuracy: 0.8872\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2412 - accuracy: 0.8742 - val_loss: 0.2827 - val_accuracy: 0.8769\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2440 - accuracy: 0.8830 - val_loss: 0.3003 - val_accuracy: 0.8872\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2839 - val_accuracy: 0.8667\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2438 - accuracy: 0.8698 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2448 - accuracy: 0.8764 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2502 - accuracy: 0.8720 - val_loss: 0.2936 - val_accuracy: 0.8769\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2394 - accuracy: 0.8764 - val_loss: 0.2910 - val_accuracy: 0.8718\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2481 - accuracy: 0.8675 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2511 - accuracy: 0.8808 - val_loss: 0.2851 - val_accuracy: 0.8872\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2447 - accuracy: 0.8786 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2460 - accuracy: 0.8742 - val_loss: 0.2869 - val_accuracy: 0.8872\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2417 - accuracy: 0.8742 - val_loss: 0.2915 - val_accuracy: 0.8769\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2492 - accuracy: 0.8764 - val_loss: 0.2987 - val_accuracy: 0.8718\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2448 - accuracy: 0.8764 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2434 - accuracy: 0.8742 - val_loss: 0.2896 - val_accuracy: 0.8718\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2462 - accuracy: 0.8764 - val_loss: 0.2856 - val_accuracy: 0.8872\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2480 - accuracy: 0.8675 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2403 - accuracy: 0.8874 - val_loss: 0.2929 - val_accuracy: 0.8872\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2385 - accuracy: 0.8764 - val_loss: 0.2868 - val_accuracy: 0.8718\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.2829 - val_accuracy: 0.8667\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2432 - accuracy: 0.8764 - val_loss: 0.2851 - val_accuracy: 0.8718\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2396 - accuracy: 0.8764 - val_loss: 0.3015 - val_accuracy: 0.8769\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2416 - accuracy: 0.8742 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2426 - accuracy: 0.8742 - val_loss: 0.2915 - val_accuracy: 0.8872\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2463 - accuracy: 0.8653 - val_loss: 0.2855 - val_accuracy: 0.8718\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2435 - accuracy: 0.8808 - val_loss: 0.2861 - val_accuracy: 0.8872\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2466 - accuracy: 0.8786 - val_loss: 0.2948 - val_accuracy: 0.8718\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2488 - accuracy: 0.8764 - val_loss: 0.2855 - val_accuracy: 0.8923\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2468 - accuracy: 0.8764 - val_loss: 0.2877 - val_accuracy: 0.8564\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2380 - accuracy: 0.8786 - val_loss: 0.2827 - val_accuracy: 0.8872\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2417 - accuracy: 0.8852 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2411 - accuracy: 0.8698 - val_loss: 0.2855 - val_accuracy: 0.8923\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2480 - accuracy: 0.8653 - val_loss: 0.2851 - val_accuracy: 0.8667\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2410 - accuracy: 0.8742 - val_loss: 0.2901 - val_accuracy: 0.8615\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2410 - accuracy: 0.8808 - val_loss: 0.2988 - val_accuracy: 0.8718\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2415 - accuracy: 0.8764 - val_loss: 0.2876 - val_accuracy: 0.8872\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2444 - accuracy: 0.8698 - val_loss: 0.2914 - val_accuracy: 0.8718\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2393 - accuracy: 0.8764 - val_loss: 0.2903 - val_accuracy: 0.8872\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2510 - accuracy: 0.8830 - val_loss: 0.2962 - val_accuracy: 0.8769\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2470 - accuracy: 0.8742 - val_loss: 0.2956 - val_accuracy: 0.8718\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2401 - accuracy: 0.8786 - val_loss: 0.2980 - val_accuracy: 0.8769\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2436 - accuracy: 0.8742 - val_loss: 0.2886 - val_accuracy: 0.8872\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2465 - accuracy: 0.8720 - val_loss: 0.2947 - val_accuracy: 0.8718\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2463 - accuracy: 0.8653 - val_loss: 0.2875 - val_accuracy: 0.8821\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2411 - accuracy: 0.8830 - val_loss: 0.2911 - val_accuracy: 0.8718\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.2887 - val_accuracy: 0.8718\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2404 - accuracy: 0.8764 - val_loss: 0.2901 - val_accuracy: 0.8718\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.2884 - val_accuracy: 0.8667\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2425 - accuracy: 0.8720 - val_loss: 0.2851 - val_accuracy: 0.8821\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2974 - val_accuracy: 0.8718\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2463 - accuracy: 0.8764 - val_loss: 0.2885 - val_accuracy: 0.8872\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2472 - accuracy: 0.8764 - val_loss: 0.2899 - val_accuracy: 0.8872\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2413 - accuracy: 0.8675 - val_loss: 0.2865 - val_accuracy: 0.8667\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2420 - accuracy: 0.8764 - val_loss: 0.2843 - val_accuracy: 0.8667\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.2900 - val_accuracy: 0.8872\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2407 - accuracy: 0.8742 - val_loss: 0.2859 - val_accuracy: 0.8667\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2435 - accuracy: 0.8742 - val_loss: 0.2873 - val_accuracy: 0.8872\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2420 - accuracy: 0.8808 - val_loss: 0.2924 - val_accuracy: 0.8667\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2450 - accuracy: 0.8764 - val_loss: 0.2897 - val_accuracy: 0.8769\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2430 - accuracy: 0.8764 - val_loss: 0.2931 - val_accuracy: 0.8872\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2395 - accuracy: 0.8764 - val_loss: 0.2853 - val_accuracy: 0.8718\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2412 - accuracy: 0.8808 - val_loss: 0.2901 - val_accuracy: 0.8872\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.2879 - val_accuracy: 0.8718\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2394 - accuracy: 0.8742 - val_loss: 0.2946 - val_accuracy: 0.8769\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2378 - accuracy: 0.8786 - val_loss: 0.2871 - val_accuracy: 0.8667\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2453 - accuracy: 0.8653 - val_loss: 0.2952 - val_accuracy: 0.8718\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2466 - accuracy: 0.8698 - val_loss: 0.2899 - val_accuracy: 0.8667\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.2939 - val_accuracy: 0.8872\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2423 - accuracy: 0.8852 - val_loss: 0.2881 - val_accuracy: 0.8821\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2436 - accuracy: 0.8720 - val_loss: 0.2966 - val_accuracy: 0.8872\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2513 - accuracy: 0.8742 - val_loss: 0.2881 - val_accuracy: 0.8718\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2455 - accuracy: 0.8808 - val_loss: 0.2909 - val_accuracy: 0.8872\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2436 - accuracy: 0.8852 - val_loss: 0.2989 - val_accuracy: 0.8718\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.2879 - val_accuracy: 0.8821\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2384 - accuracy: 0.8830 - val_loss: 0.2919 - val_accuracy: 0.8872\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2931 - val_accuracy: 0.8718\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2416 - accuracy: 0.8830 - val_loss: 0.2907 - val_accuracy: 0.8821\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2422 - accuracy: 0.8675 - val_loss: 0.2893 - val_accuracy: 0.8667\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 111us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2926 - val_accuracy: 0.8872\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2914 - val_accuracy: 0.8872\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2905 - val_accuracy: 0.8667\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2395 - accuracy: 0.8698 - val_loss: 0.2886 - val_accuracy: 0.8718\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2420 - accuracy: 0.8764 - val_loss: 0.2895 - val_accuracy: 0.8821\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2455 - accuracy: 0.8764 - val_loss: 0.2982 - val_accuracy: 0.8718\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8718\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2391 - accuracy: 0.8720 - val_loss: 0.2989 - val_accuracy: 0.8718\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2367 - accuracy: 0.8698 - val_loss: 0.2946 - val_accuracy: 0.8872\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2449 - accuracy: 0.8830 - val_loss: 0.2898 - val_accuracy: 0.8872\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2446 - accuracy: 0.8764 - val_loss: 0.2954 - val_accuracy: 0.8872\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.2952 - val_accuracy: 0.8769\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2527 - accuracy: 0.8411 - val_loss: 0.2971 - val_accuracy: 0.8718\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2396 - accuracy: 0.8764 - val_loss: 0.2894 - val_accuracy: 0.8667\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2403 - accuracy: 0.8720 - val_loss: 0.2924 - val_accuracy: 0.8667\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2385 - accuracy: 0.8786 - val_loss: 0.2905 - val_accuracy: 0.8667\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2458 - accuracy: 0.8764 - val_loss: 0.2916 - val_accuracy: 0.8821\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2450 - accuracy: 0.8742 - val_loss: 0.2946 - val_accuracy: 0.8667\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2442 - accuracy: 0.8742 - val_loss: 0.2938 - val_accuracy: 0.8821\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2461 - accuracy: 0.8720 - val_loss: 0.2986 - val_accuracy: 0.8769\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2447 - accuracy: 0.8808 - val_loss: 0.2933 - val_accuracy: 0.8718\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.3039 - val_accuracy: 0.8769\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2422 - accuracy: 0.8764 - val_loss: 0.2947 - val_accuracy: 0.8718\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2401 - accuracy: 0.8786 - val_loss: 0.2946 - val_accuracy: 0.8667\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.2890 - val_accuracy: 0.8821\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2383 - accuracy: 0.8742 - val_loss: 0.2925 - val_accuracy: 0.8718\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2947 - val_accuracy: 0.8872\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2397 - accuracy: 0.8808 - val_loss: 0.2940 - val_accuracy: 0.8667\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2406 - accuracy: 0.8653 - val_loss: 0.2944 - val_accuracy: 0.8872\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2448 - accuracy: 0.8720 - val_loss: 0.2990 - val_accuracy: 0.8872\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2377 - accuracy: 0.8764 - val_loss: 0.2937 - val_accuracy: 0.8718\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2455 - accuracy: 0.8675 - val_loss: 0.2980 - val_accuracy: 0.8718\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2374 - accuracy: 0.8808 - val_loss: 0.2935 - val_accuracy: 0.8821\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2444 - accuracy: 0.8742 - val_loss: 0.2971 - val_accuracy: 0.8821\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2392 - accuracy: 0.8764 - val_loss: 0.2910 - val_accuracy: 0.8769\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2923 - val_accuracy: 0.8821\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2400 - accuracy: 0.8764 - val_loss: 0.2951 - val_accuracy: 0.8821\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2435 - accuracy: 0.8764 - val_loss: 0.2888 - val_accuracy: 0.8769\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2451 - accuracy: 0.8698 - val_loss: 0.2949 - val_accuracy: 0.8718\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.2964 - val_accuracy: 0.8872\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2369 - accuracy: 0.8742 - val_loss: 0.2927 - val_accuracy: 0.8667\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2406 - accuracy: 0.8742 - val_loss: 0.2917 - val_accuracy: 0.8667\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2472 - accuracy: 0.8720 - val_loss: 0.2984 - val_accuracy: 0.8821\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2450 - accuracy: 0.8698 - val_loss: 0.2906 - val_accuracy: 0.8667\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2370 - accuracy: 0.8808 - val_loss: 0.2982 - val_accuracy: 0.8821\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2417 - accuracy: 0.8764 - val_loss: 0.2957 - val_accuracy: 0.8821\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 0.2907 - val_accuracy: 0.8872\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.3054 - val_accuracy: 0.8769\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2473 - accuracy: 0.8720 - val_loss: 0.2904 - val_accuracy: 0.8872\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2911 - val_accuracy: 0.8821\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2368 - accuracy: 0.8786 - val_loss: 0.2971 - val_accuracy: 0.8718\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2476 - accuracy: 0.8698 - val_loss: 0.2906 - val_accuracy: 0.8821\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2407 - accuracy: 0.8808 - val_loss: 0.2962 - val_accuracy: 0.8667\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2364 - accuracy: 0.8720 - val_loss: 0.2918 - val_accuracy: 0.8872\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2363 - accuracy: 0.8742 - val_loss: 0.2931 - val_accuracy: 0.8821\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2451 - accuracy: 0.8698 - val_loss: 0.2930 - val_accuracy: 0.8821\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2378 - accuracy: 0.8764 - val_loss: 0.2921 - val_accuracy: 0.8718\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.3020 - val_accuracy: 0.8821\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2411 - accuracy: 0.8786 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2416 - accuracy: 0.8720 - val_loss: 0.2942 - val_accuracy: 0.8821\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.2906 - val_accuracy: 0.8718\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2366 - accuracy: 0.8764 - val_loss: 0.2938 - val_accuracy: 0.8667\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2385 - accuracy: 0.8698 - val_loss: 0.2961 - val_accuracy: 0.8718\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2910 - val_accuracy: 0.8821\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2367 - accuracy: 0.8786 - val_loss: 0.2943 - val_accuracy: 0.8667\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2949 - val_accuracy: 0.8821\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2360 - accuracy: 0.8808 - val_loss: 0.2963 - val_accuracy: 0.8821\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2371 - accuracy: 0.8764 - val_loss: 0.2935 - val_accuracy: 0.8821\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.2915 - val_accuracy: 0.8872\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.2997 - val_accuracy: 0.8718\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2386 - accuracy: 0.8852 - val_loss: 0.2993 - val_accuracy: 0.8821\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2423 - accuracy: 0.8918 - val_loss: 0.2920 - val_accuracy: 0.8872\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2407 - accuracy: 0.8764 - val_loss: 0.2928 - val_accuracy: 0.8718\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2385 - accuracy: 0.8698 - val_loss: 0.2940 - val_accuracy: 0.8718\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.2953 - val_accuracy: 0.8667\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2433 - accuracy: 0.8830 - val_loss: 0.2955 - val_accuracy: 0.8872\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2379 - accuracy: 0.8786 - val_loss: 0.2972 - val_accuracy: 0.8718\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2367 - accuracy: 0.8698 - val_loss: 0.2976 - val_accuracy: 0.8718\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2972 - val_accuracy: 0.8718\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2397 - accuracy: 0.8720 - val_loss: 0.2984 - val_accuracy: 0.8718\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2941 - val_accuracy: 0.8821\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2945 - val_accuracy: 0.8821\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2400 - accuracy: 0.8852 - val_loss: 0.3018 - val_accuracy: 0.8718\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2915 - val_accuracy: 0.8821\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2446 - accuracy: 0.8720 - val_loss: 0.2977 - val_accuracy: 0.8718\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.2934 - val_accuracy: 0.8718\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2956 - val_accuracy: 0.8667\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2949 - val_accuracy: 0.8821\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.2923 - val_accuracy: 0.8821\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2953 - val_accuracy: 0.8718\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2347 - accuracy: 0.8764 - val_loss: 0.2970 - val_accuracy: 0.8821\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2370 - accuracy: 0.8742 - val_loss: 0.2970 - val_accuracy: 0.8821\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2970 - val_accuracy: 0.8872\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2929 - val_accuracy: 0.8667\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2387 - accuracy: 0.8764 - val_loss: 0.3033 - val_accuracy: 0.8821\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2394 - accuracy: 0.8786 - val_loss: 0.2989 - val_accuracy: 0.8667\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2888 - val_accuracy: 0.8872\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2345 - accuracy: 0.8764 - val_loss: 0.2964 - val_accuracy: 0.8667\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2962 - val_accuracy: 0.8718\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.3008 - val_accuracy: 0.8718\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2427 - accuracy: 0.8742 - val_loss: 0.3029 - val_accuracy: 0.8718\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2417 - accuracy: 0.8653 - val_loss: 0.3017 - val_accuracy: 0.8769\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2381 - accuracy: 0.8786 - val_loss: 0.2951 - val_accuracy: 0.8872\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2431 - accuracy: 0.8698 - val_loss: 0.2934 - val_accuracy: 0.8615\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2407 - accuracy: 0.8786 - val_loss: 0.3028 - val_accuracy: 0.8718\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2342 - accuracy: 0.8742 - val_loss: 0.2940 - val_accuracy: 0.8821\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2375 - accuracy: 0.8786 - val_loss: 0.2940 - val_accuracy: 0.8667\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2350 - accuracy: 0.8742 - val_loss: 0.2924 - val_accuracy: 0.8667\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2344 - accuracy: 0.8808 - val_loss: 0.2949 - val_accuracy: 0.8667\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2427 - accuracy: 0.8852 - val_loss: 0.2924 - val_accuracy: 0.8821\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 113us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2935 - val_accuracy: 0.8718\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2984 - val_accuracy: 0.8667\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2392 - accuracy: 0.8764 - val_loss: 0.2955 - val_accuracy: 0.8821\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.2922 - val_accuracy: 0.8821\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.2941 - val_accuracy: 0.8718\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2397 - accuracy: 0.8720 - val_loss: 0.2917 - val_accuracy: 0.8718\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.2970 - val_accuracy: 0.8667\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2944 - val_accuracy: 0.8872\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8808 - val_loss: 0.2909 - val_accuracy: 0.8821\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2952 - val_accuracy: 0.8667\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2905 - val_accuracy: 0.8821\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2448 - accuracy: 0.8698 - val_loss: 0.2957 - val_accuracy: 0.8718\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2350 - accuracy: 0.8742 - val_loss: 0.2926 - val_accuracy: 0.8667\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2964 - val_accuracy: 0.8718\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.2934 - val_accuracy: 0.8667\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2942 - val_accuracy: 0.8667\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2350 - accuracy: 0.8786 - val_loss: 0.2959 - val_accuracy: 0.8821\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2345 - accuracy: 0.8742 - val_loss: 0.2936 - val_accuracy: 0.8872\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2950 - val_accuracy: 0.8821\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2961 - val_accuracy: 0.8821\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2339 - accuracy: 0.8742 - val_loss: 0.2935 - val_accuracy: 0.8667\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2352 - accuracy: 0.8698 - val_loss: 0.2957 - val_accuracy: 0.8667\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2357 - accuracy: 0.8764 - val_loss: 0.2976 - val_accuracy: 0.8667\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.2942 - val_accuracy: 0.8667\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2339 - accuracy: 0.8808 - val_loss: 0.2960 - val_accuracy: 0.8821\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2924 - val_accuracy: 0.8872\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2339 - accuracy: 0.8764 - val_loss: 0.2982 - val_accuracy: 0.8821\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2381 - accuracy: 0.8764 - val_loss: 0.2928 - val_accuracy: 0.8667\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2998 - val_accuracy: 0.8718\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.2921 - val_accuracy: 0.8667\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2346 - accuracy: 0.8742 - val_loss: 0.2900 - val_accuracy: 0.8769\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2335 - accuracy: 0.8764 - val_loss: 0.2971 - val_accuracy: 0.8667\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2338 - accuracy: 0.8764 - val_loss: 0.2975 - val_accuracy: 0.8821\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.3001 - val_accuracy: 0.8769\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2391 - accuracy: 0.8720 - val_loss: 0.2948 - val_accuracy: 0.8821\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2982 - val_accuracy: 0.8718\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.3006 - val_accuracy: 0.8718\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2417 - accuracy: 0.8720 - val_loss: 0.2946 - val_accuracy: 0.8821\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2977 - val_accuracy: 0.8718\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2358 - accuracy: 0.8808 - val_loss: 0.2949 - val_accuracy: 0.8718\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2928 - val_accuracy: 0.8667\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2361 - accuracy: 0.8720 - val_loss: 0.2927 - val_accuracy: 0.8769\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2946 - val_accuracy: 0.8821\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2961 - val_accuracy: 0.8667\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2952 - val_accuracy: 0.8821\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.2966 - val_accuracy: 0.8821\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2350 - accuracy: 0.8764 - val_loss: 0.2954 - val_accuracy: 0.8667\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2352 - accuracy: 0.8764 - val_loss: 0.2940 - val_accuracy: 0.8718\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2954 - val_accuracy: 0.8718\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2298 - accuracy: 0.8720 - val_loss: 0.2909 - val_accuracy: 0.8821\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2335 - accuracy: 0.8742 - val_loss: 0.3012 - val_accuracy: 0.8821\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2365 - accuracy: 0.8764 - val_loss: 0.2947 - val_accuracy: 0.8821\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.2952 - val_accuracy: 0.8821\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2969 - val_accuracy: 0.8718\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2353 - accuracy: 0.8698 - val_loss: 0.2943 - val_accuracy: 0.8821\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2390 - accuracy: 0.8653 - val_loss: 0.2984 - val_accuracy: 0.8718\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2371 - accuracy: 0.8698 - val_loss: 0.2945 - val_accuracy: 0.8821\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2368 - accuracy: 0.8675 - val_loss: 0.3030 - val_accuracy: 0.8718\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2373 - accuracy: 0.8786 - val_loss: 0.2939 - val_accuracy: 0.8821\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.2989 - val_accuracy: 0.8821\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2955 - val_accuracy: 0.8821\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2358 - accuracy: 0.8742 - val_loss: 0.2911 - val_accuracy: 0.8821\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2994 - val_accuracy: 0.8718\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2933 - val_accuracy: 0.8821\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2942 - val_accuracy: 0.8821\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2329 - accuracy: 0.8786 - val_loss: 0.2920 - val_accuracy: 0.8718\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2943 - val_accuracy: 0.8821\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2905 - val_accuracy: 0.8821\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.2961 - val_accuracy: 0.8718\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2362 - accuracy: 0.8742 - val_loss: 0.2942 - val_accuracy: 0.8667\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.2943 - val_accuracy: 0.8872\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.2938 - val_accuracy: 0.8821\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2319 - accuracy: 0.8742 - val_loss: 0.2960 - val_accuracy: 0.8667\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2953 - val_accuracy: 0.8667\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2385 - accuracy: 0.8698 - val_loss: 0.2937 - val_accuracy: 0.8923\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2964 - val_accuracy: 0.8718\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2399 - accuracy: 0.8698 - val_loss: 0.2929 - val_accuracy: 0.8718\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2377 - accuracy: 0.8720 - val_loss: 0.2975 - val_accuracy: 0.8667\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2959 - val_accuracy: 0.8667\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.3025 - val_accuracy: 0.8718\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.2964 - val_accuracy: 0.8667\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.2944 - val_accuracy: 0.8667\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2374 - accuracy: 0.8742 - val_loss: 0.2941 - val_accuracy: 0.8718\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2339 - accuracy: 0.8742 - val_loss: 0.2916 - val_accuracy: 0.8872\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.3001 - val_accuracy: 0.8718\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2928 - val_accuracy: 0.8821\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2973 - val_accuracy: 0.8718\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2929 - val_accuracy: 0.8769\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2948 - val_accuracy: 0.8667\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2304 - accuracy: 0.8742 - val_loss: 0.2958 - val_accuracy: 0.8718\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2938 - val_accuracy: 0.8667\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2943 - val_accuracy: 0.8667\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2329 - accuracy: 0.8720 - val_loss: 0.2956 - val_accuracy: 0.8718\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2293 - accuracy: 0.8720 - val_loss: 0.2957 - val_accuracy: 0.8667\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.2937 - val_accuracy: 0.8769\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2952 - val_accuracy: 0.8821\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2995 - val_accuracy: 0.8718\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2317 - accuracy: 0.8742 - val_loss: 0.2944 - val_accuracy: 0.8667\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.2970 - val_accuracy: 0.8718\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2358 - accuracy: 0.8764 - val_loss: 0.3007 - val_accuracy: 0.8769\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2365 - accuracy: 0.8698 - val_loss: 0.2941 - val_accuracy: 0.8769\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.8808 - val_loss: 0.2977 - val_accuracy: 0.8718\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.2952 - val_accuracy: 0.8821\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8742 - val_loss: 0.2924 - val_accuracy: 0.8872\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2982 - val_accuracy: 0.8821\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2312 - accuracy: 0.8698 - val_loss: 0.2969 - val_accuracy: 0.8718\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2955 - val_accuracy: 0.8821\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 129us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.2954 - val_accuracy: 0.8769\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.2946 - val_accuracy: 0.8718\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2300 - accuracy: 0.8675 - val_loss: 0.2978 - val_accuracy: 0.8667\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2938 - val_accuracy: 0.8872\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2298 - accuracy: 0.8720 - val_loss: 0.2940 - val_accuracy: 0.8821\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2315 - accuracy: 0.8742 - val_loss: 0.2985 - val_accuracy: 0.8821\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2950 - val_accuracy: 0.8872\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2331 - accuracy: 0.8720 - val_loss: 0.2979 - val_accuracy: 0.8769\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2940 - val_accuracy: 0.8872\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2323 - accuracy: 0.8720 - val_loss: 0.2933 - val_accuracy: 0.8718\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2370 - accuracy: 0.8764 - val_loss: 0.3012 - val_accuracy: 0.8769\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2964 - val_accuracy: 0.8821\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.3069 - val_accuracy: 0.8564\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2312 - accuracy: 0.8698 - val_loss: 0.2958 - val_accuracy: 0.8769\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2972 - val_accuracy: 0.8821\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.2995 - val_accuracy: 0.8821\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2299 - accuracy: 0.8742 - val_loss: 0.2951 - val_accuracy: 0.8821\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2988 - val_accuracy: 0.8821\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2328 - accuracy: 0.8742 - val_loss: 0.2946 - val_accuracy: 0.8821\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.2976 - val_accuracy: 0.8667\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2328 - accuracy: 0.8631 - val_loss: 0.2941 - val_accuracy: 0.8821\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2321 - accuracy: 0.8720 - val_loss: 0.2959 - val_accuracy: 0.8821\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.2950 - val_accuracy: 0.8769\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2327 - accuracy: 0.8742 - val_loss: 0.2982 - val_accuracy: 0.8821\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.2961 - val_accuracy: 0.8769\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2313 - accuracy: 0.8764 - val_loss: 0.3001 - val_accuracy: 0.8821\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2980 - val_accuracy: 0.8821\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2998 - val_accuracy: 0.8667\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2334 - accuracy: 0.8742 - val_loss: 0.2978 - val_accuracy: 0.8769\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2322 - accuracy: 0.8786 - val_loss: 0.2927 - val_accuracy: 0.8872\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.2986 - val_accuracy: 0.8667\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2331 - accuracy: 0.8742 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.3004 - val_accuracy: 0.8821\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2992 - val_accuracy: 0.8718\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.8742 - val_loss: 0.3007 - val_accuracy: 0.8821\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.3012 - val_accuracy: 0.8821\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.2961 - val_accuracy: 0.8821\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.2982 - val_accuracy: 0.8872\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.3030 - val_accuracy: 0.8667\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.2965 - val_accuracy: 0.8872\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.2991 - val_accuracy: 0.8718\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2287 - accuracy: 0.8764 - val_loss: 0.2985 - val_accuracy: 0.8821\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2971 - val_accuracy: 0.8923\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2989 - val_accuracy: 0.8667\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.8786 - val_loss: 0.3003 - val_accuracy: 0.8718\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2295 - accuracy: 0.8764 - val_loss: 0.3026 - val_accuracy: 0.8718\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.3124 - val_accuracy: 0.8769\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.2976 - val_accuracy: 0.8718\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.2982 - val_accuracy: 0.8821\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8742 - val_loss: 0.3012 - val_accuracy: 0.8821\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2311 - accuracy: 0.8786 - val_loss: 0.3008 - val_accuracy: 0.8667\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.3039 - val_accuracy: 0.8821\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2345 - accuracy: 0.8720 - val_loss: 0.2958 - val_accuracy: 0.8821\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 0.3008 - val_accuracy: 0.8667\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2307 - accuracy: 0.8764 - val_loss: 0.3007 - val_accuracy: 0.8718\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.3036 - val_accuracy: 0.8718\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.3030 - val_accuracy: 0.8821\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2268 - accuracy: 0.8786 - val_loss: 0.3031 - val_accuracy: 0.8718\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.3014 - val_accuracy: 0.8769\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2298 - accuracy: 0.8764 - val_loss: 0.3027 - val_accuracy: 0.8718\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.3000 - val_accuracy: 0.8872\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.2999 - val_accuracy: 0.8718\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2280 - accuracy: 0.8786 - val_loss: 0.3027 - val_accuracy: 0.8821\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2314 - accuracy: 0.8720 - val_loss: 0.2982 - val_accuracy: 0.8872\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2270 - accuracy: 0.8830 - val_loss: 0.3007 - val_accuracy: 0.8821\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.2989 - val_accuracy: 0.8718\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2985 - val_accuracy: 0.8821\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2997 - val_accuracy: 0.8821\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.3042 - val_accuracy: 0.8718\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2361 - accuracy: 0.8786 - val_loss: 0.3107 - val_accuracy: 0.8769\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2380 - accuracy: 0.8786 - val_loss: 0.3003 - val_accuracy: 0.8821\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2292 - accuracy: 0.8720 - val_loss: 0.2975 - val_accuracy: 0.8821\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.3017 - val_accuracy: 0.8667\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2366 - accuracy: 0.8742 - val_loss: 0.3056 - val_accuracy: 0.8718\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.3024 - val_accuracy: 0.8872\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2283 - accuracy: 0.8764 - val_loss: 0.3021 - val_accuracy: 0.8821\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2288 - accuracy: 0.8764 - val_loss: 0.3008 - val_accuracy: 0.8821\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.3006 - val_accuracy: 0.8821\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2996 - val_accuracy: 0.8821\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.3056 - val_accuracy: 0.8718\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2996 - val_accuracy: 0.8821\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.3024 - val_accuracy: 0.8718\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.3014 - val_accuracy: 0.8821\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.3000 - val_accuracy: 0.8821\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.3009 - val_accuracy: 0.8821\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.3063 - val_accuracy: 0.8667\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2273 - accuracy: 0.8786 - val_loss: 0.3015 - val_accuracy: 0.8821\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2310 - accuracy: 0.8720 - val_loss: 0.2994 - val_accuracy: 0.8923\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2283 - accuracy: 0.8786 - val_loss: 0.3034 - val_accuracy: 0.8821\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2354 - accuracy: 0.8786 - val_loss: 0.3166 - val_accuracy: 0.8718\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2416 - accuracy: 0.8720 - val_loss: 0.3031 - val_accuracy: 0.8821\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2268 - accuracy: 0.8786 - val_loss: 0.3026 - val_accuracy: 0.8821\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2276 - accuracy: 0.8764 - val_loss: 0.3048 - val_accuracy: 0.8821\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2275 - accuracy: 0.8742 - val_loss: 0.3021 - val_accuracy: 0.8821\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2273 - accuracy: 0.8830 - val_loss: 0.3035 - val_accuracy: 0.8718\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2307 - accuracy: 0.8786 - val_loss: 0.3026 - val_accuracy: 0.8821\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.3014 - val_accuracy: 0.8872\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2297 - accuracy: 0.8764 - val_loss: 0.3057 - val_accuracy: 0.8667\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.3042 - val_accuracy: 0.8821\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.3021 - val_accuracy: 0.8821\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 0.3058 - val_accuracy: 0.8821\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.3030 - val_accuracy: 0.8821\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.3036 - val_accuracy: 0.8821\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2265 - accuracy: 0.8808 - val_loss: 0.3047 - val_accuracy: 0.8667\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.3021 - val_accuracy: 0.8667\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3014 - val_accuracy: 0.8667\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.3032 - val_accuracy: 0.8821\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2321 - accuracy: 0.8764 - val_loss: 0.3077 - val_accuracy: 0.8718\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8720 - val_loss: 0.3121 - val_accuracy: 0.8769\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 132us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.3027 - val_accuracy: 0.8821\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.3040 - val_accuracy: 0.8872\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2322 - accuracy: 0.8764 - val_loss: 0.3027 - val_accuracy: 0.8872\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2290 - accuracy: 0.8742 - val_loss: 0.3064 - val_accuracy: 0.8821\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2284 - accuracy: 0.8786 - val_loss: 0.3084 - val_accuracy: 0.8821\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.3111 - val_accuracy: 0.8821\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2279 - accuracy: 0.8742 - val_loss: 0.3105 - val_accuracy: 0.8718\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3096 - val_accuracy: 0.8821\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2295 - accuracy: 0.8698 - val_loss: 0.3091 - val_accuracy: 0.8718\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.3060 - val_accuracy: 0.8872\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.3086 - val_accuracy: 0.8872\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2300 - accuracy: 0.8764 - val_loss: 0.3047 - val_accuracy: 0.8872\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.3040 - val_accuracy: 0.8821\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.3056 - val_accuracy: 0.8667\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2318 - accuracy: 0.8742 - val_loss: 0.3054 - val_accuracy: 0.8821\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2335 - accuracy: 0.8742 - val_loss: 0.3063 - val_accuracy: 0.8718\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.3046 - val_accuracy: 0.8821\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2285 - accuracy: 0.8764 - val_loss: 0.3043 - val_accuracy: 0.8821\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.3045 - val_accuracy: 0.8718\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.3054 - val_accuracy: 0.8821\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2280 - accuracy: 0.8786 - val_loss: 0.3037 - val_accuracy: 0.8718\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2273 - accuracy: 0.8830 - val_loss: 0.3066 - val_accuracy: 0.8667\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2269 - accuracy: 0.8852 - val_loss: 0.3066 - val_accuracy: 0.8718\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.3045 - val_accuracy: 0.8821\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.3043 - val_accuracy: 0.8667\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2317 - accuracy: 0.8764 - val_loss: 0.3063 - val_accuracy: 0.8667\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.3028 - val_accuracy: 0.8821\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.3050 - val_accuracy: 0.8821\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2287 - accuracy: 0.8786 - val_loss: 0.3120 - val_accuracy: 0.8718\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2252 - accuracy: 0.8808 - val_loss: 0.3111 - val_accuracy: 0.8821\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2321 - accuracy: 0.8698 - val_loss: 0.3056 - val_accuracy: 0.8872\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.3102 - val_accuracy: 0.8718\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.3098 - val_accuracy: 0.8821\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2333 - accuracy: 0.8742 - val_loss: 0.3074 - val_accuracy: 0.8821\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2280 - accuracy: 0.8720 - val_loss: 0.3050 - val_accuracy: 0.8667\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2266 - accuracy: 0.8786 - val_loss: 0.3075 - val_accuracy: 0.8718\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2269 - accuracy: 0.8720 - val_loss: 0.3102 - val_accuracy: 0.8821\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.3081 - val_accuracy: 0.8769\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2271 - accuracy: 0.8808 - val_loss: 0.3060 - val_accuracy: 0.8821\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.3100 - val_accuracy: 0.8718\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2326 - accuracy: 0.8742 - val_loss: 0.3074 - val_accuracy: 0.8821\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3056 - val_accuracy: 0.8821\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.3079 - val_accuracy: 0.8821\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.3070 - val_accuracy: 0.8667\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2286 - accuracy: 0.8830 - val_loss: 0.3082 - val_accuracy: 0.8821\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.3099 - val_accuracy: 0.8718\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.3064 - val_accuracy: 0.8821\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3092 - val_accuracy: 0.8667\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3082 - val_accuracy: 0.8667\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.3091 - val_accuracy: 0.8821\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.3086 - val_accuracy: 0.8718\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2270 - accuracy: 0.8764 - val_loss: 0.3074 - val_accuracy: 0.8821\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.3065 - val_accuracy: 0.8872\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.3118 - val_accuracy: 0.8667\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.3119 - val_accuracy: 0.8821\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.3084 - val_accuracy: 0.8821\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2319 - accuracy: 0.8742 - val_loss: 0.3097 - val_accuracy: 0.8718\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2319 - accuracy: 0.8786 - val_loss: 0.3102 - val_accuracy: 0.8821\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.3069 - val_accuracy: 0.8872\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2281 - accuracy: 0.8720 - val_loss: 0.3130 - val_accuracy: 0.8821\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2264 - accuracy: 0.8852 - val_loss: 0.3094 - val_accuracy: 0.8667\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2263 - accuracy: 0.8764 - val_loss: 0.3077 - val_accuracy: 0.8821\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.3089 - val_accuracy: 0.8821\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.3145 - val_accuracy: 0.8821\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2258 - accuracy: 0.8830 - val_loss: 0.3094 - val_accuracy: 0.8821\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2282 - accuracy: 0.8786 - val_loss: 0.3113 - val_accuracy: 0.8667\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2261 - accuracy: 0.8786 - val_loss: 0.3102 - val_accuracy: 0.8718\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3118 - val_accuracy: 0.8821\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.3089 - val_accuracy: 0.8872\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2295 - accuracy: 0.8720 - val_loss: 0.3101 - val_accuracy: 0.8821\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2257 - accuracy: 0.8852 - val_loss: 0.3104 - val_accuracy: 0.8821\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2280 - accuracy: 0.8786 - val_loss: 0.3140 - val_accuracy: 0.8667\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.3113 - val_accuracy: 0.8821\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2251 - accuracy: 0.8852 - val_loss: 0.3096 - val_accuracy: 0.8821\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2278 - accuracy: 0.8742 - val_loss: 0.3144 - val_accuracy: 0.8667\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.3149 - val_accuracy: 0.8769\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3119 - val_accuracy: 0.8821\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2330 - accuracy: 0.8742 - val_loss: 0.3132 - val_accuracy: 0.8718\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2269 - accuracy: 0.8764 - val_loss: 0.3095 - val_accuracy: 0.8872\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8718\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2274 - accuracy: 0.8808 - val_loss: 0.3117 - val_accuracy: 0.8872\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.3114 - val_accuracy: 0.8821\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.3117 - val_accuracy: 0.8821\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.3099 - val_accuracy: 0.8821\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.3130 - val_accuracy: 0.8718\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3153 - val_accuracy: 0.8718\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2267 - accuracy: 0.8720 - val_loss: 0.3149 - val_accuracy: 0.8923\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2317 - accuracy: 0.8764 - val_loss: 0.3127 - val_accuracy: 0.8769\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2262 - accuracy: 0.8786 - val_loss: 0.3125 - val_accuracy: 0.8821\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2277 - accuracy: 0.8786 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.3150 - val_accuracy: 0.8872\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3122 - val_accuracy: 0.8667\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2269 - accuracy: 0.8742 - val_loss: 0.3109 - val_accuracy: 0.8821\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.3109 - val_accuracy: 0.8923\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.3129 - val_accuracy: 0.8718\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2262 - accuracy: 0.8808 - val_loss: 0.3131 - val_accuracy: 0.8821\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2253 - accuracy: 0.8830 - val_loss: 0.3133 - val_accuracy: 0.8718\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2264 - accuracy: 0.8720 - val_loss: 0.3120 - val_accuracy: 0.8821\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2275 - accuracy: 0.8764 - val_loss: 0.3124 - val_accuracy: 0.8718\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.3206 - val_accuracy: 0.8667\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2259 - accuracy: 0.8852 - val_loss: 0.3123 - val_accuracy: 0.8821\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.3119 - val_accuracy: 0.8821\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2257 - accuracy: 0.8852 - val_loss: 0.3131 - val_accuracy: 0.8821\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2277 - accuracy: 0.8764 - val_loss: 0.3144 - val_accuracy: 0.8718\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3128 - val_accuracy: 0.8667\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2272 - accuracy: 0.8764 - val_loss: 0.3164 - val_accuracy: 0.8821\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3119 - val_accuracy: 0.8872\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.3293 - val_accuracy: 0.8821\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 173us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.3162 - val_accuracy: 0.8769\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2271 - accuracy: 0.8786 - val_loss: 0.3138 - val_accuracy: 0.8923\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.3140 - val_accuracy: 0.8769\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2262 - accuracy: 0.8852 - val_loss: 0.3195 - val_accuracy: 0.8667\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2271 - accuracy: 0.8786 - val_loss: 0.3196 - val_accuracy: 0.8718\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.3145 - val_accuracy: 0.8821\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2264 - accuracy: 0.8786 - val_loss: 0.3144 - val_accuracy: 0.8821\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3135 - val_accuracy: 0.8821\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2271 - accuracy: 0.8830 - val_loss: 0.3166 - val_accuracy: 0.8718\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2250 - accuracy: 0.8830 - val_loss: 0.3149 - val_accuracy: 0.8821\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2275 - accuracy: 0.8786 - val_loss: 0.3177 - val_accuracy: 0.8718\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2275 - accuracy: 0.8786 - val_loss: 0.3156 - val_accuracy: 0.8821\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2257 - accuracy: 0.8742 - val_loss: 0.3169 - val_accuracy: 0.8821\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2265 - accuracy: 0.8786 - val_loss: 0.3148 - val_accuracy: 0.8821\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.3204 - val_accuracy: 0.8667\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2302 - accuracy: 0.8720 - val_loss: 0.3172 - val_accuracy: 0.8821\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3182 - val_accuracy: 0.8667\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.3157 - val_accuracy: 0.8821\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2262 - accuracy: 0.8852 - val_loss: 0.3182 - val_accuracy: 0.8821\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2268 - accuracy: 0.8852 - val_loss: 0.3158 - val_accuracy: 0.8667\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2279 - accuracy: 0.8764 - val_loss: 0.3155 - val_accuracy: 0.8821\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3174 - val_accuracy: 0.8667\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2282 - accuracy: 0.8764 - val_loss: 0.3190 - val_accuracy: 0.8667\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2384 - accuracy: 0.8786 - val_loss: 0.3177 - val_accuracy: 0.8718\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.3168 - val_accuracy: 0.8821\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2273 - accuracy: 0.8808 - val_loss: 0.3190 - val_accuracy: 0.8718\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.3186 - val_accuracy: 0.8821\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.3161 - val_accuracy: 0.8821\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3141 - val_accuracy: 0.8821\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.3196 - val_accuracy: 0.8667\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.3211 - val_accuracy: 0.8667\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.3206 - val_accuracy: 0.8821\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2271 - accuracy: 0.8786 - val_loss: 0.3193 - val_accuracy: 0.8821\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2266 - accuracy: 0.8852 - val_loss: 0.3201 - val_accuracy: 0.8821\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2261 - accuracy: 0.8808 - val_loss: 0.3194 - val_accuracy: 0.8821\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2296 - accuracy: 0.8742 - val_loss: 0.3188 - val_accuracy: 0.8821\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3165 - val_accuracy: 0.8821\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2269 - accuracy: 0.8808 - val_loss: 0.3192 - val_accuracy: 0.8667\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2244 - accuracy: 0.8830 - val_loss: 0.3194 - val_accuracy: 0.8821\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2265 - accuracy: 0.8852 - val_loss: 0.3171 - val_accuracy: 0.8872\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2275 - accuracy: 0.8764 - val_loss: 0.3184 - val_accuracy: 0.8718\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3193 - val_accuracy: 0.8821\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8667\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2263 - accuracy: 0.8742 - val_loss: 0.3187 - val_accuracy: 0.8667\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2293 - accuracy: 0.8742 - val_loss: 0.3176 - val_accuracy: 0.8667\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.3220 - val_accuracy: 0.8667\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3173 - val_accuracy: 0.8769\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2276 - accuracy: 0.8808 - val_loss: 0.3196 - val_accuracy: 0.8821\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2254 - accuracy: 0.8764 - val_loss: 0.3161 - val_accuracy: 0.8821\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2251 - accuracy: 0.8852 - val_loss: 0.3201 - val_accuracy: 0.8667\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.3186 - val_accuracy: 0.8821\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2278 - accuracy: 0.8786 - val_loss: 0.3193 - val_accuracy: 0.8821\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3217 - val_accuracy: 0.8821\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.3174 - val_accuracy: 0.8821\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3207 - val_accuracy: 0.8821\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2257 - accuracy: 0.8808 - val_loss: 0.3211 - val_accuracy: 0.8821\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2266 - accuracy: 0.8786 - val_loss: 0.3181 - val_accuracy: 0.8821\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.3216 - val_accuracy: 0.8769\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2263 - accuracy: 0.8808 - val_loss: 0.3211 - val_accuracy: 0.8667\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3185 - val_accuracy: 0.8872\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.3200 - val_accuracy: 0.8821\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2258 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8821\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2267 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8821\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3206 - val_accuracy: 0.8667\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2268 - accuracy: 0.8808 - val_loss: 0.3214 - val_accuracy: 0.8821\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.3179 - val_accuracy: 0.8821\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3247 - val_accuracy: 0.8821\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2252 - accuracy: 0.8808 - val_loss: 0.3201 - val_accuracy: 0.8821\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.3219 - val_accuracy: 0.8718\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8821\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2282 - accuracy: 0.8786 - val_loss: 0.3224 - val_accuracy: 0.8667\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2261 - accuracy: 0.8808 - val_loss: 0.3219 - val_accuracy: 0.8667\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2263 - accuracy: 0.8852 - val_loss: 0.3208 - val_accuracy: 0.8821\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.3196 - val_accuracy: 0.8923\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2271 - accuracy: 0.8830 - val_loss: 0.3228 - val_accuracy: 0.8872\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.3236 - val_accuracy: 0.8718\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3201 - val_accuracy: 0.8667\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3225 - val_accuracy: 0.8872\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.3211 - val_accuracy: 0.8872\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2250 - accuracy: 0.8874 - val_loss: 0.3212 - val_accuracy: 0.8821\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3200 - val_accuracy: 0.8821\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3240 - val_accuracy: 0.8821\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2275 - accuracy: 0.8786 - val_loss: 0.3204 - val_accuracy: 0.8821\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2285 - accuracy: 0.8720 - val_loss: 0.3224 - val_accuracy: 0.8872\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.3244 - val_accuracy: 0.8667\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.3211 - val_accuracy: 0.8821\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.3245 - val_accuracy: 0.8872\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.3205 - val_accuracy: 0.8821\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2251 - accuracy: 0.8852 - val_loss: 0.3211 - val_accuracy: 0.8821\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.3253 - val_accuracy: 0.8667\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8872\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2339 - accuracy: 0.8742 - val_loss: 0.3219 - val_accuracy: 0.8769\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.3248 - val_accuracy: 0.8821\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3223 - val_accuracy: 0.8821\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2263 - accuracy: 0.8808 - val_loss: 0.3250 - val_accuracy: 0.8821\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3199 - val_accuracy: 0.8821\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2260 - accuracy: 0.8786 - val_loss: 0.3231 - val_accuracy: 0.8872\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.3217 - val_accuracy: 0.8821\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2265 - accuracy: 0.8742 - val_loss: 0.3203 - val_accuracy: 0.8821\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.3214 - val_accuracy: 0.8667\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2302 - accuracy: 0.8698 - val_loss: 0.3221 - val_accuracy: 0.8667\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2255 - accuracy: 0.8808 - val_loss: 0.3190 - val_accuracy: 0.8821\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2247 - accuracy: 0.8764 - val_loss: 0.3199 - val_accuracy: 0.8821\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3230 - val_accuracy: 0.8821\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2271 - accuracy: 0.8808 - val_loss: 0.3226 - val_accuracy: 0.8667\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2269 - accuracy: 0.8808 - val_loss: 0.3217 - val_accuracy: 0.8821\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2257 - accuracy: 0.8852 - val_loss: 0.3228 - val_accuracy: 0.8667\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2304 - accuracy: 0.8675 - val_loss: 0.3216 - val_accuracy: 0.8667\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 122us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3235 - val_accuracy: 0.8821\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.3243 - val_accuracy: 0.8769\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3269 - val_accuracy: 0.8667\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.3227 - val_accuracy: 0.8821\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2285 - accuracy: 0.8786 - val_loss: 0.3235 - val_accuracy: 0.8821\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3207 - val_accuracy: 0.8821\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2265 - accuracy: 0.8852 - val_loss: 0.3237 - val_accuracy: 0.8821\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3216 - val_accuracy: 0.8821\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2284 - accuracy: 0.8808 - val_loss: 0.3248 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a379044e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 56us/step\n",
      "over-sampling test accuracy: 89.23%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 0, 2, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 2, 0, 0, 1,\n",
       "       0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0,\n",
       "       0, 0, 2, 2, 1, 0, 2, 0, 1, 2, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0,\n",
       "       1, 0, 0, 2, 1, 0, 2, 1, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 0, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0,\n",
       "       2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 1,\n",
       "       0, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1,\n",
       "       1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0,\n",
       "       1, 2, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GA15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS241     1     1\n",
       "1      BCH-SA-01     1     1\n",
       "2         NRS219     1     0\n",
       "3         NRS209     2     2\n",
       "4         NRS001     1     0\n",
       "..           ...   ...   ...\n",
       "190         GA15     1     0\n",
       "191       NRS246     1     1\n",
       "192          115     1     1\n",
       "193          312     1     0\n",
       "194  CFBREBSa112     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.876360e-05</td>\n",
       "      <td>9.999713e-01</td>\n",
       "      <td>9.790981e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.245487e-01</td>\n",
       "      <td>8.754513e-01</td>\n",
       "      <td>3.463491e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.177501e-01</td>\n",
       "      <td>8.224987e-02</td>\n",
       "      <td>5.389061e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.315624e-09</td>\n",
       "      <td>4.960074e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.213648e-01</td>\n",
       "      <td>4.786352e-01</td>\n",
       "      <td>1.483967e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>6.677842e-01</td>\n",
       "      <td>3.322158e-01</td>\n",
       "      <td>9.752275e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2.405064e-01</td>\n",
       "      <td>7.594936e-01</td>\n",
       "      <td>1.233132e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.010262e-04</td>\n",
       "      <td>9.998989e-01</td>\n",
       "      <td>7.971936e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>6.677842e-01</td>\n",
       "      <td>3.322158e-01</td>\n",
       "      <td>9.752275e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>6.677842e-01</td>\n",
       "      <td>3.322158e-01</td>\n",
       "      <td>9.752275e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    2.876360e-05  9.999713e-01  9.790981e-15\n",
       "1    1.245487e-01  8.754513e-01  3.463491e-13\n",
       "2    9.177501e-01  8.224987e-02  5.389061e-10\n",
       "3    3.315624e-09  4.960074e-09  1.000000e+00\n",
       "4    5.213648e-01  4.786352e-01  1.483967e-11\n",
       "..            ...           ...           ...\n",
       "190  6.677842e-01  3.322158e-01  9.752275e-09\n",
       "191  2.405064e-01  7.594936e-01  1.233132e-09\n",
       "192  1.010262e-04  9.998989e-01  7.971936e-12\n",
       "193  6.677842e-01  3.322158e-01  9.752275e-09\n",
       "194  6.677842e-01  3.322158e-01  9.752275e-09\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.3139 - val_accuracy: 0.8769\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 0.3119 - val_accuracy: 0.8769\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2288 - accuracy: 0.8720 - val_loss: 0.3092 - val_accuracy: 0.8718\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.3131 - val_accuracy: 0.8872\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2379 - accuracy: 0.8808 - val_loss: 0.3105 - val_accuracy: 0.8923\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.3080 - val_accuracy: 0.8718\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2282 - accuracy: 0.8742 - val_loss: 0.3070 - val_accuracy: 0.8769\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2290 - accuracy: 0.8742 - val_loss: 0.3091 - val_accuracy: 0.8872\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2269 - accuracy: 0.8852 - val_loss: 0.3130 - val_accuracy: 0.8872\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2301 - accuracy: 0.8653 - val_loss: 0.3074 - val_accuracy: 0.8923\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2275 - accuracy: 0.8764 - val_loss: 0.3095 - val_accuracy: 0.8769\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2266 - accuracy: 0.8830 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2279 - accuracy: 0.8786 - val_loss: 0.3095 - val_accuracy: 0.8923\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2259 - accuracy: 0.8808 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3095 - val_accuracy: 0.8872\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3115 - val_accuracy: 0.8872\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.3108 - val_accuracy: 0.8769\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.3143 - val_accuracy: 0.8718\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2264 - accuracy: 0.8852 - val_loss: 0.3112 - val_accuracy: 0.8872\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3106 - val_accuracy: 0.8718\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.3094 - val_accuracy: 0.8923\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2276 - accuracy: 0.8830 - val_loss: 0.3090 - val_accuracy: 0.8872\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2262 - accuracy: 0.8786 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2320 - accuracy: 0.8742 - val_loss: 0.3089 - val_accuracy: 0.8718\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2260 - accuracy: 0.8852 - val_loss: 0.3114 - val_accuracy: 0.8872\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2273 - accuracy: 0.8852 - val_loss: 0.3118 - val_accuracy: 0.8769\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.3116 - val_accuracy: 0.8718\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.3106 - val_accuracy: 0.8872\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2277 - accuracy: 0.8764 - val_loss: 0.3126 - val_accuracy: 0.8718\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2263 - accuracy: 0.8808 - val_loss: 0.3083 - val_accuracy: 0.8923\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2263 - accuracy: 0.8720 - val_loss: 0.3099 - val_accuracy: 0.8872\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2274 - accuracy: 0.8698 - val_loss: 0.3072 - val_accuracy: 0.8821\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.3092 - val_accuracy: 0.8718\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2250 - accuracy: 0.8764 - val_loss: 0.3129 - val_accuracy: 0.8872\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2263 - accuracy: 0.8764 - val_loss: 0.3047 - val_accuracy: 0.8923\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.3094 - val_accuracy: 0.8821\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2298 - accuracy: 0.8764 - val_loss: 0.3063 - val_accuracy: 0.8872\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.3096 - val_accuracy: 0.8769\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2292 - accuracy: 0.8720 - val_loss: 0.3075 - val_accuracy: 0.8872\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.3072 - val_accuracy: 0.8872\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.3080 - val_accuracy: 0.8718\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2247 - accuracy: 0.8786 - val_loss: 0.3049 - val_accuracy: 0.8872\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2258 - accuracy: 0.8830 - val_loss: 0.3108 - val_accuracy: 0.8872\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2279 - accuracy: 0.8786 - val_loss: 0.3077 - val_accuracy: 0.8769\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.3095 - val_accuracy: 0.8872\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2254 - accuracy: 0.8830 - val_loss: 0.3081 - val_accuracy: 0.8718\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2284 - accuracy: 0.8764 - val_loss: 0.3047 - val_accuracy: 0.8872\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2268 - accuracy: 0.8808 - val_loss: 0.3121 - val_accuracy: 0.8769\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3077 - val_accuracy: 0.8872\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2319 - accuracy: 0.8742 - val_loss: 0.3093 - val_accuracy: 0.8769\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2311 - accuracy: 0.8764 - val_loss: 0.3094 - val_accuracy: 0.8872\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2283 - accuracy: 0.8786 - val_loss: 0.3067 - val_accuracy: 0.8923\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2341 - accuracy: 0.8698 - val_loss: 0.3040 - val_accuracy: 0.8872\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2274 - accuracy: 0.8786 - val_loss: 0.3104 - val_accuracy: 0.8872\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.3097 - val_accuracy: 0.8872\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2315 - accuracy: 0.8698 - val_loss: 0.3091 - val_accuracy: 0.8769\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.3089 - val_accuracy: 0.8769\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3096 - val_accuracy: 0.8872\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.3070 - val_accuracy: 0.8872\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2255 - accuracy: 0.8786 - val_loss: 0.3133 - val_accuracy: 0.8718\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2318 - accuracy: 0.8742 - val_loss: 0.3164 - val_accuracy: 0.8718\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2364 - accuracy: 0.8764 - val_loss: 0.3150 - val_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.3098 - val_accuracy: 0.8872\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2254 - accuracy: 0.8852 - val_loss: 0.3077 - val_accuracy: 0.8872\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2275 - accuracy: 0.8830 - val_loss: 0.3071 - val_accuracy: 0.8923\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2259 - accuracy: 0.8764 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2270 - accuracy: 0.8808 - val_loss: 0.3116 - val_accuracy: 0.8872\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3076 - val_accuracy: 0.8872\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.3077 - val_accuracy: 0.8872\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3062 - val_accuracy: 0.8974\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2258 - accuracy: 0.8698 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2310 - accuracy: 0.8720 - val_loss: 0.3168 - val_accuracy: 0.8718\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2332 - accuracy: 0.8720 - val_loss: 0.3058 - val_accuracy: 0.8872\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3144 - val_accuracy: 0.8769\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2276 - accuracy: 0.8764 - val_loss: 0.3116 - val_accuracy: 0.8872\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.3065 - val_accuracy: 0.8872\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3085 - val_accuracy: 0.8872\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2272 - accuracy: 0.8808 - val_loss: 0.3103 - val_accuracy: 0.8872\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3110 - val_accuracy: 0.8872\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2292 - accuracy: 0.8720 - val_loss: 0.3097 - val_accuracy: 0.8872\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.3114 - val_accuracy: 0.8769\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2276 - accuracy: 0.8786 - val_loss: 0.3135 - val_accuracy: 0.8718\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.3099 - val_accuracy: 0.8872\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.3107 - val_accuracy: 0.8872\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2245 - accuracy: 0.8742 - val_loss: 0.3123 - val_accuracy: 0.8923\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.3108 - val_accuracy: 0.8718\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2254 - accuracy: 0.8808 - val_loss: 0.3103 - val_accuracy: 0.8923\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2274 - accuracy: 0.8852 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2396 - accuracy: 0.8764 - val_loss: 0.3102 - val_accuracy: 0.8718\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2275 - accuracy: 0.8808 - val_loss: 0.3094 - val_accuracy: 0.8872\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3052 - val_accuracy: 0.8718\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3071 - val_accuracy: 0.8769\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2248 - accuracy: 0.8830 - val_loss: 0.3057 - val_accuracy: 0.8872\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2261 - accuracy: 0.8808 - val_loss: 0.3079 - val_accuracy: 0.8872\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.3096 - val_accuracy: 0.8769\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2286 - accuracy: 0.8764 - val_loss: 0.3056 - val_accuracy: 0.8872\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2276 - accuracy: 0.8830 - val_loss: 0.3050 - val_accuracy: 0.8923\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2284 - accuracy: 0.8764 - val_loss: 0.3067 - val_accuracy: 0.8718\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3065 - val_accuracy: 0.8872\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2274 - accuracy: 0.8808 - val_loss: 0.3048 - val_accuracy: 0.8923\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2273 - accuracy: 0.8830 - val_loss: 0.3075 - val_accuracy: 0.8923\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2256 - accuracy: 0.8830 - val_loss: 0.3072 - val_accuracy: 0.8872\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2258 - accuracy: 0.8786 - val_loss: 0.3097 - val_accuracy: 0.8718\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.3056 - val_accuracy: 0.8872\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 379us/step - loss: 0.2261 - accuracy: 0.8808 - val_loss: 0.3059 - val_accuracy: 0.8769\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3074 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.3109 - val_accuracy: 0.8872\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.3074 - val_accuracy: 0.8923\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2305 - accuracy: 0.8918 - val_loss: 0.3149 - val_accuracy: 0.8872\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.3127 - val_accuracy: 0.8718\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2254 - accuracy: 0.8764 - val_loss: 0.3048 - val_accuracy: 0.8872\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.3130 - val_accuracy: 0.8667\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2300 - accuracy: 0.8742 - val_loss: 0.3053 - val_accuracy: 0.8923\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2349 - accuracy: 0.8742 - val_loss: 0.3118 - val_accuracy: 0.8769\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2271 - accuracy: 0.8896 - val_loss: 0.3096 - val_accuracy: 0.8872\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2257 - accuracy: 0.8852 - val_loss: 0.3094 - val_accuracy: 0.8872\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2256 - accuracy: 0.8786 - val_loss: 0.3088 - val_accuracy: 0.8769\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2257 - accuracy: 0.8852 - val_loss: 0.3086 - val_accuracy: 0.8872\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2260 - accuracy: 0.8786 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3130 - val_accuracy: 0.8872\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2273 - accuracy: 0.8852 - val_loss: 0.3117 - val_accuracy: 0.8718\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2259 - accuracy: 0.8808 - val_loss: 0.3103 - val_accuracy: 0.8923\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2255 - accuracy: 0.8808 - val_loss: 0.3095 - val_accuracy: 0.8769\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3122 - val_accuracy: 0.8872\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 497us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.3108 - val_accuracy: 0.8769\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2233 - accuracy: 0.8874 - val_loss: 0.3089 - val_accuracy: 0.8872\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3073 - val_accuracy: 0.8872\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2249 - accuracy: 0.8698 - val_loss: 0.3066 - val_accuracy: 0.8923\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2284 - accuracy: 0.8808 - val_loss: 0.3073 - val_accuracy: 0.8923\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 447us/step - loss: 0.2235 - accuracy: 0.8852 - val_loss: 0.3096 - val_accuracy: 0.8923\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3103 - val_accuracy: 0.8769\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2250 - accuracy: 0.8764 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.3102 - val_accuracy: 0.8769\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2256 - accuracy: 0.8786 - val_loss: 0.3108 - val_accuracy: 0.8872\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.3084 - val_accuracy: 0.8923\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2274 - accuracy: 0.8852 - val_loss: 0.3090 - val_accuracy: 0.8872\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2276 - accuracy: 0.8852 - val_loss: 0.3131 - val_accuracy: 0.8923\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3071 - val_accuracy: 0.8923\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2251 - accuracy: 0.8830 - val_loss: 0.3104 - val_accuracy: 0.8872\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3098 - val_accuracy: 0.8872\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2288 - accuracy: 0.8720 - val_loss: 0.3047 - val_accuracy: 0.8923\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2264 - accuracy: 0.8742 - val_loss: 0.3124 - val_accuracy: 0.8821\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2266 - accuracy: 0.8720 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2258 - accuracy: 0.8830 - val_loss: 0.3099 - val_accuracy: 0.8872\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2276 - accuracy: 0.8786 - val_loss: 0.3099 - val_accuracy: 0.8872\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2230 - accuracy: 0.8852 - val_loss: 0.3091 - val_accuracy: 0.8872\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.3119 - val_accuracy: 0.8923\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3106 - val_accuracy: 0.8872\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2260 - accuracy: 0.8698 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.3093 - val_accuracy: 0.8872\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 331us/step - loss: 0.2274 - accuracy: 0.8786 - val_loss: 0.3081 - val_accuracy: 0.8923\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 399us/step - loss: 0.2294 - accuracy: 0.8742 - val_loss: 0.3089 - val_accuracy: 0.8872\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 647us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.3107 - val_accuracy: 0.8718\n",
      "Epoch 160/1000\n",
      " 16/453 [>.............................] - ETA: 0s - loss: 0.3460 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.130633). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 319us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3101 - val_accuracy: 0.8923\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3098 - val_accuracy: 0.8718\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2259 - accuracy: 0.8852 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2293 - accuracy: 0.8742 - val_loss: 0.3093 - val_accuracy: 0.8872\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2271 - accuracy: 0.8764 - val_loss: 0.3132 - val_accuracy: 0.8769\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2268 - accuracy: 0.8764 - val_loss: 0.3083 - val_accuracy: 0.8923\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2273 - accuracy: 0.8720 - val_loss: 0.3132 - val_accuracy: 0.8718\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3150 - val_accuracy: 0.8769\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2265 - accuracy: 0.8786 - val_loss: 0.3112 - val_accuracy: 0.8769\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2294 - accuracy: 0.8742 - val_loss: 0.3104 - val_accuracy: 0.8769\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2257 - accuracy: 0.8764 - val_loss: 0.3184 - val_accuracy: 0.8872\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2426 - accuracy: 0.8764 - val_loss: 0.3104 - val_accuracy: 0.8923\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2281 - accuracy: 0.8786 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2230 - accuracy: 0.8808 - val_loss: 0.3114 - val_accuracy: 0.8769\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2273 - accuracy: 0.8830 - val_loss: 0.3110 - val_accuracy: 0.8769\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2258 - accuracy: 0.8830 - val_loss: 0.3058 - val_accuracy: 0.8872\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.3096 - val_accuracy: 0.8923\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2266 - accuracy: 0.8808 - val_loss: 0.3097 - val_accuracy: 0.8872\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2247 - accuracy: 0.8786 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 341us/step - loss: 0.2258 - accuracy: 0.8786 - val_loss: 0.3084 - val_accuracy: 0.8923\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2279 - accuracy: 0.8764 - val_loss: 0.3083 - val_accuracy: 0.8872\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2281 - accuracy: 0.8764 - val_loss: 0.3138 - val_accuracy: 0.8769\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3120 - val_accuracy: 0.8718\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2301 - accuracy: 0.8742 - val_loss: 0.3115 - val_accuracy: 0.8769\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.3117 - val_accuracy: 0.8872\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.3144 - val_accuracy: 0.8769\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.3110 - val_accuracy: 0.8923\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2256 - accuracy: 0.8764 - val_loss: 0.3113 - val_accuracy: 0.8872\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2273 - accuracy: 0.8764 - val_loss: 0.3114 - val_accuracy: 0.8872\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2274 - accuracy: 0.8764 - val_loss: 0.3113 - val_accuracy: 0.8872\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2260 - accuracy: 0.8830 - val_loss: 0.3108 - val_accuracy: 0.8872\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2273 - accuracy: 0.8764 - val_loss: 0.3112 - val_accuracy: 0.8769\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2259 - accuracy: 0.8786 - val_loss: 0.3162 - val_accuracy: 0.8718\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2275 - accuracy: 0.8830 - val_loss: 0.3130 - val_accuracy: 0.8769\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.3089 - val_accuracy: 0.8872\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2275 - accuracy: 0.8808 - val_loss: 0.3124 - val_accuracy: 0.8718\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2268 - accuracy: 0.8808 - val_loss: 0.3111 - val_accuracy: 0.8872\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2250 - accuracy: 0.8852 - val_loss: 0.3116 - val_accuracy: 0.8872\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3083 - val_accuracy: 0.8872\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3100 - val_accuracy: 0.8872\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2255 - accuracy: 0.8786 - val_loss: 0.3105 - val_accuracy: 0.8923\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2246 - accuracy: 0.8830 - val_loss: 0.3142 - val_accuracy: 0.8872\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2250 - accuracy: 0.8764 - val_loss: 0.3136 - val_accuracy: 0.8718\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2288 - accuracy: 0.8698 - val_loss: 0.3131 - val_accuracy: 0.8769\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2262 - accuracy: 0.8830 - val_loss: 0.3122 - val_accuracy: 0.8872\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.3126 - val_accuracy: 0.8923\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2255 - accuracy: 0.8675 - val_loss: 0.3080 - val_accuracy: 0.8872\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3133 - val_accuracy: 0.8872\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2273 - accuracy: 0.8808 - val_loss: 0.3161 - val_accuracy: 0.8718\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2266 - accuracy: 0.8720 - val_loss: 0.3105 - val_accuracy: 0.8872\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2258 - accuracy: 0.8786 - val_loss: 0.3095 - val_accuracy: 0.8821\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2253 - accuracy: 0.8808 - val_loss: 0.3126 - val_accuracy: 0.8872\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2267 - accuracy: 0.8742 - val_loss: 0.3115 - val_accuracy: 0.8769\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2263 - accuracy: 0.8720 - val_loss: 0.3109 - val_accuracy: 0.8923\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3126 - val_accuracy: 0.8923\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2250 - accuracy: 0.8786 - val_loss: 0.3133 - val_accuracy: 0.8718\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2272 - accuracy: 0.8742 - val_loss: 0.3106 - val_accuracy: 0.8769\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.3171 - val_accuracy: 0.8718\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2284 - accuracy: 0.8808 - val_loss: 0.3130 - val_accuracy: 0.8718\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 346us/step - loss: 0.2279 - accuracy: 0.8786 - val_loss: 0.3118 - val_accuracy: 0.8769\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.2240 - accuracy: 0.8786 - val_loss: 0.3135 - val_accuracy: 0.8923\n",
      "Epoch 222/1000\n",
      "453/453 [==============================] - 0s 376us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.3119 - val_accuracy: 0.8872\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2264 - accuracy: 0.8786 - val_loss: 0.3192 - val_accuracy: 0.8923\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2290 - accuracy: 0.8720 - val_loss: 0.3107 - val_accuracy: 0.8974\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2265 - accuracy: 0.8852 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2281 - accuracy: 0.8742 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2302 - accuracy: 0.8786 - val_loss: 0.3156 - val_accuracy: 0.8769\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2286 - accuracy: 0.8764 - val_loss: 0.3086 - val_accuracy: 0.8974\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 345us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.3130 - val_accuracy: 0.8718\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2275 - accuracy: 0.8808 - val_loss: 0.3110 - val_accuracy: 0.8923\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3156 - val_accuracy: 0.8923\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3121 - val_accuracy: 0.8872\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3151 - val_accuracy: 0.8872\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2250 - accuracy: 0.8830 - val_loss: 0.3136 - val_accuracy: 0.8769\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2275 - accuracy: 0.8786 - val_loss: 0.3124 - val_accuracy: 0.8923\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3125 - val_accuracy: 0.8872\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2241 - accuracy: 0.8808 - val_loss: 0.3112 - val_accuracy: 0.8872\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2268 - accuracy: 0.8786 - val_loss: 0.3121 - val_accuracy: 0.8872\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2260 - accuracy: 0.8764 - val_loss: 0.3130 - val_accuracy: 0.8923\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2263 - accuracy: 0.8852 - val_loss: 0.3126 - val_accuracy: 0.8872\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3148 - val_accuracy: 0.8769\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3135 - val_accuracy: 0.8872\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.3124 - val_accuracy: 0.8872\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2268 - accuracy: 0.8742 - val_loss: 0.3155 - val_accuracy: 0.8718\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2268 - accuracy: 0.8720 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.3165 - val_accuracy: 0.8872\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2262 - accuracy: 0.8808 - val_loss: 0.3141 - val_accuracy: 0.8718\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2261 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8718\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2306 - accuracy: 0.8698 - val_loss: 0.3116 - val_accuracy: 0.8872\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3157 - val_accuracy: 0.8923\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3137 - val_accuracy: 0.8872\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3124 - val_accuracy: 0.8872\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2246 - accuracy: 0.8852 - val_loss: 0.3149 - val_accuracy: 0.8718\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2247 - accuracy: 0.8830 - val_loss: 0.3187 - val_accuracy: 0.8718\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2249 - accuracy: 0.8764 - val_loss: 0.3131 - val_accuracy: 0.8769\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2273 - accuracy: 0.8786 - val_loss: 0.3159 - val_accuracy: 0.8872\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2238 - accuracy: 0.8852 - val_loss: 0.3118 - val_accuracy: 0.8923\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2262 - accuracy: 0.8720 - val_loss: 0.3159 - val_accuracy: 0.8769\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3145 - val_accuracy: 0.8769\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.3163 - val_accuracy: 0.8923\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2343 - accuracy: 0.8764 - val_loss: 0.3049 - val_accuracy: 0.8821\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2273 - accuracy: 0.8786 - val_loss: 0.3069 - val_accuracy: 0.8872\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2244 - accuracy: 0.8830 - val_loss: 0.3064 - val_accuracy: 0.8718\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3018 - val_accuracy: 0.8872\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2245 - accuracy: 0.8852 - val_loss: 0.3042 - val_accuracy: 0.8872\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2267 - accuracy: 0.8786 - val_loss: 0.3073 - val_accuracy: 0.8872\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2235 - accuracy: 0.8808 - val_loss: 0.3015 - val_accuracy: 0.8923\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 203us/step - loss: 0.2250 - accuracy: 0.8830 - val_loss: 0.3072 - val_accuracy: 0.8769\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3079 - val_accuracy: 0.8872\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3066 - val_accuracy: 0.8769\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3051 - val_accuracy: 0.8923\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2241 - accuracy: 0.8742 - val_loss: 0.3069 - val_accuracy: 0.8923\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2264 - accuracy: 0.8852 - val_loss: 0.3051 - val_accuracy: 0.8923\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3093 - val_accuracy: 0.8923\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3142 - val_accuracy: 0.8872\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3084 - val_accuracy: 0.8872\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2261 - accuracy: 0.8786 - val_loss: 0.3053 - val_accuracy: 0.8923\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2295 - accuracy: 0.8742 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2234 - accuracy: 0.8764 - val_loss: 0.3063 - val_accuracy: 0.8872\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3126 - val_accuracy: 0.8769\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2271 - accuracy: 0.8808 - val_loss: 0.3125 - val_accuracy: 0.8718\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2235 - accuracy: 0.8808 - val_loss: 0.3113 - val_accuracy: 0.8872\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2247 - accuracy: 0.8786 - val_loss: 0.3101 - val_accuracy: 0.8872\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.3145 - val_accuracy: 0.8923\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.3047 - val_accuracy: 0.8974\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2280 - accuracy: 0.8698 - val_loss: 0.3131 - val_accuracy: 0.8872\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8923\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3136 - val_accuracy: 0.8718\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3111 - val_accuracy: 0.8923\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2242 - accuracy: 0.8764 - val_loss: 0.3117 - val_accuracy: 0.8821\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2249 - accuracy: 0.8720 - val_loss: 0.3103 - val_accuracy: 0.8872\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 359us/step - loss: 0.2251 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8718\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 333us/step - loss: 0.2239 - accuracy: 0.8852 - val_loss: 0.3130 - val_accuracy: 0.8769\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2282 - accuracy: 0.8742 - val_loss: 0.3108 - val_accuracy: 0.8769\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2263 - accuracy: 0.8720 - val_loss: 0.3175 - val_accuracy: 0.8769\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2228 - accuracy: 0.8808 - val_loss: 0.3130 - val_accuracy: 0.8872\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2238 - accuracy: 0.8830 - val_loss: 0.3131 - val_accuracy: 0.8872\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2241 - accuracy: 0.8786 - val_loss: 0.3137 - val_accuracy: 0.8718\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2291 - accuracy: 0.8720 - val_loss: 0.3122 - val_accuracy: 0.8769\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2245 - accuracy: 0.8852 - val_loss: 0.3127 - val_accuracy: 0.8872\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.3145 - val_accuracy: 0.8769\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3116 - val_accuracy: 0.8923\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2277 - accuracy: 0.8764 - val_loss: 0.3131 - val_accuracy: 0.8872\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2272 - accuracy: 0.8720 - val_loss: 0.3149 - val_accuracy: 0.8872\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2268 - accuracy: 0.8830 - val_loss: 0.3134 - val_accuracy: 0.8923\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2250 - accuracy: 0.8764 - val_loss: 0.3188 - val_accuracy: 0.8718\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3122 - val_accuracy: 0.8923\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2250 - accuracy: 0.8852 - val_loss: 0.3168 - val_accuracy: 0.8872\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3148 - val_accuracy: 0.8872\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2277 - accuracy: 0.8698 - val_loss: 0.3139 - val_accuracy: 0.8872\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2243 - accuracy: 0.8786 - val_loss: 0.3118 - val_accuracy: 0.8872\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3145 - val_accuracy: 0.8872\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.3198 - val_accuracy: 0.8872\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2269 - accuracy: 0.8830 - val_loss: 0.3128 - val_accuracy: 0.8821\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2266 - accuracy: 0.8764 - val_loss: 0.3133 - val_accuracy: 0.8872\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2273 - accuracy: 0.8786 - val_loss: 0.3173 - val_accuracy: 0.8718\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2249 - accuracy: 0.8874 - val_loss: 0.3093 - val_accuracy: 0.8923\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3114 - val_accuracy: 0.8923\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3176 - val_accuracy: 0.8718\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2267 - accuracy: 0.8786 - val_loss: 0.3179 - val_accuracy: 0.8718\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2259 - accuracy: 0.8720 - val_loss: 0.3130 - val_accuracy: 0.8821\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2266 - accuracy: 0.8830 - val_loss: 0.3117 - val_accuracy: 0.8872\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 421us/step - loss: 0.2257 - accuracy: 0.8764 - val_loss: 0.3162 - val_accuracy: 0.8872\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.2262 - accuracy: 0.8742 - val_loss: 0.3181 - val_accuracy: 0.8923\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2239 - accuracy: 0.8786 - val_loss: 0.3125 - val_accuracy: 0.8872\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2265 - accuracy: 0.8786 - val_loss: 0.3138 - val_accuracy: 0.8872\n",
      "Epoch 332/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2253 - accuracy: 0.8742 - val_loss: 0.3108 - val_accuracy: 0.8923\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2229 - accuracy: 0.8764 - val_loss: 0.3162 - val_accuracy: 0.8872\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.3147 - val_accuracy: 0.8769\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.3149 - val_accuracy: 0.8872\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.3152 - val_accuracy: 0.8872\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2265 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2243 - accuracy: 0.8742 - val_loss: 0.3125 - val_accuracy: 0.8872\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2257 - accuracy: 0.8764 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2260 - accuracy: 0.8830 - val_loss: 0.3135 - val_accuracy: 0.8872\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2258 - accuracy: 0.8764 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2235 - accuracy: 0.8786 - val_loss: 0.3130 - val_accuracy: 0.8872\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3123 - val_accuracy: 0.8923\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3134 - val_accuracy: 0.8872\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2262 - accuracy: 0.8742 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.3246 - val_accuracy: 0.8718\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2242 - accuracy: 0.8764 - val_loss: 0.3165 - val_accuracy: 0.8872\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.3166 - val_accuracy: 0.8769\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2267 - accuracy: 0.8830 - val_loss: 0.3145 - val_accuracy: 0.8923\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3151 - val_accuracy: 0.8872\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2267 - accuracy: 0.8720 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2266 - accuracy: 0.8808 - val_loss: 0.3164 - val_accuracy: 0.8718\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2249 - accuracy: 0.8786 - val_loss: 0.3135 - val_accuracy: 0.8872\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3135 - val_accuracy: 0.8923\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3153 - val_accuracy: 0.8872\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3177 - val_accuracy: 0.8718\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3129 - val_accuracy: 0.8872\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2245 - accuracy: 0.8830 - val_loss: 0.3136 - val_accuracy: 0.8769\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3129 - val_accuracy: 0.8872\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3120 - val_accuracy: 0.8872\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.3175 - val_accuracy: 0.8821\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.3246 - val_accuracy: 0.8769\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2258 - accuracy: 0.8874 - val_loss: 0.3211 - val_accuracy: 0.8718\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.3151 - val_accuracy: 0.8923\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2288 - accuracy: 0.8720 - val_loss: 0.3096 - val_accuracy: 0.8821\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.3120 - val_accuracy: 0.8872\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2234 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8923\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2258 - accuracy: 0.8786 - val_loss: 0.3142 - val_accuracy: 0.8769\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3150 - val_accuracy: 0.8769\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2287 - accuracy: 0.8742 - val_loss: 0.3125 - val_accuracy: 0.8923\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2239 - accuracy: 0.8764 - val_loss: 0.3161 - val_accuracy: 0.8872\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2276 - accuracy: 0.8764 - val_loss: 0.3158 - val_accuracy: 0.8872\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2266 - accuracy: 0.8742 - val_loss: 0.3144 - val_accuracy: 0.8923\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2237 - accuracy: 0.8830 - val_loss: 0.3159 - val_accuracy: 0.8923\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3138 - val_accuracy: 0.8872\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 123us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3131 - val_accuracy: 0.8872\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2270 - accuracy: 0.8808 - val_loss: 0.3162 - val_accuracy: 0.8718\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 386us/step - loss: 0.2273 - accuracy: 0.8764 - val_loss: 0.3147 - val_accuracy: 0.8769\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.3198 - val_accuracy: 0.8769\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2240 - accuracy: 0.8786 - val_loss: 0.3156 - val_accuracy: 0.8872\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3152 - val_accuracy: 0.8872\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2254 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8769\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2254 - accuracy: 0.8830 - val_loss: 0.3158 - val_accuracy: 0.8769\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.3138 - val_accuracy: 0.8923\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3142 - val_accuracy: 0.8923\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2256 - accuracy: 0.8764 - val_loss: 0.3145 - val_accuracy: 0.8769\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3145 - val_accuracy: 0.8872\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3238 - val_accuracy: 0.8769\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2269 - accuracy: 0.8852 - val_loss: 0.3218 - val_accuracy: 0.8821\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2250 - accuracy: 0.8786 - val_loss: 0.3171 - val_accuracy: 0.8872\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2248 - accuracy: 0.8830 - val_loss: 0.3148 - val_accuracy: 0.8872\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2276 - accuracy: 0.8808 - val_loss: 0.3174 - val_accuracy: 0.8821\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2265 - accuracy: 0.8808 - val_loss: 0.3174 - val_accuracy: 0.8872\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2235 - accuracy: 0.8786 - val_loss: 0.3129 - val_accuracy: 0.8974\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3153 - val_accuracy: 0.8872\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2272 - accuracy: 0.8808 - val_loss: 0.3124 - val_accuracy: 0.8923\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2286 - accuracy: 0.8830 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3142 - val_accuracy: 0.8923\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2253 - accuracy: 0.8764 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2266 - accuracy: 0.8808 - val_loss: 0.3134 - val_accuracy: 0.8872\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2264 - accuracy: 0.8852 - val_loss: 0.3151 - val_accuracy: 0.8769\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2271 - accuracy: 0.8742 - val_loss: 0.3145 - val_accuracy: 0.8769\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2261 - accuracy: 0.8786 - val_loss: 0.3125 - val_accuracy: 0.8872\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2255 - accuracy: 0.8764 - val_loss: 0.3133 - val_accuracy: 0.8923\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2258 - accuracy: 0.8764 - val_loss: 0.3153 - val_accuracy: 0.8923\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2230 - accuracy: 0.8742 - val_loss: 0.3161 - val_accuracy: 0.8872\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3111 - val_accuracy: 0.8872\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3138 - val_accuracy: 0.8923\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3152 - val_accuracy: 0.8872\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8718\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2251 - accuracy: 0.8764 - val_loss: 0.3146 - val_accuracy: 0.8923\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3158 - val_accuracy: 0.8769\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2274 - accuracy: 0.8808 - val_loss: 0.3181 - val_accuracy: 0.8923\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2288 - accuracy: 0.8764 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2247 - accuracy: 0.8808 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2260 - accuracy: 0.8786 - val_loss: 0.3137 - val_accuracy: 0.8872\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8718\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 319us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.3123 - val_accuracy: 0.8923\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3141 - val_accuracy: 0.8872\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2260 - accuracy: 0.8808 - val_loss: 0.3133 - val_accuracy: 0.8821\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2258 - accuracy: 0.8698 - val_loss: 0.3151 - val_accuracy: 0.8718\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2393 - accuracy: 0.8742 - val_loss: 0.3202 - val_accuracy: 0.8974\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2265 - accuracy: 0.8830 - val_loss: 0.3110 - val_accuracy: 0.8872\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2329 - accuracy: 0.8764 - val_loss: 0.3088 - val_accuracy: 0.8821\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 437us/step - loss: 0.2272 - accuracy: 0.8830 - val_loss: 0.3098 - val_accuracy: 0.8923\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3087 - val_accuracy: 0.8872\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2253 - accuracy: 0.8808 - val_loss: 0.3099 - val_accuracy: 0.8872\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2257 - accuracy: 0.8808 - val_loss: 0.3078 - val_accuracy: 0.8872\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2243 - accuracy: 0.8874 - val_loss: 0.3117 - val_accuracy: 0.8769\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2242 - accuracy: 0.8830 - val_loss: 0.3058 - val_accuracy: 0.8923\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3071 - val_accuracy: 0.8872\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2250 - accuracy: 0.8852 - val_loss: 0.3095 - val_accuracy: 0.8872\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.3094 - val_accuracy: 0.8769\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3043 - val_accuracy: 0.8923\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2237 - accuracy: 0.8764 - val_loss: 0.3104 - val_accuracy: 0.8718\n",
      "Epoch 442/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2243 - accuracy: 0.8786 - val_loss: 0.3083 - val_accuracy: 0.8872\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3109 - val_accuracy: 0.8872\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 369us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3070 - val_accuracy: 0.8872\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3112 - val_accuracy: 0.8718\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2236 - accuracy: 0.8786 - val_loss: 0.3100 - val_accuracy: 0.8718\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2242 - accuracy: 0.8830 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.3109 - val_accuracy: 0.8872\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2249 - accuracy: 0.8808 - val_loss: 0.3129 - val_accuracy: 0.8718\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.3112 - val_accuracy: 0.8872\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2238 - accuracy: 0.8852 - val_loss: 0.3129 - val_accuracy: 0.8872\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2221 - accuracy: 0.8742 - val_loss: 0.3096 - val_accuracy: 0.8872\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2239 - accuracy: 0.8830 - val_loss: 0.3113 - val_accuracy: 0.8923\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2227 - accuracy: 0.8808 - val_loss: 0.3129 - val_accuracy: 0.8872\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2250 - accuracy: 0.8720 - val_loss: 0.3145 - val_accuracy: 0.8872\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 337us/step - loss: 0.2237 - accuracy: 0.8786 - val_loss: 0.3102 - val_accuracy: 0.8872\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2252 - accuracy: 0.8852 - val_loss: 0.3122 - val_accuracy: 0.8923\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.3142 - val_accuracy: 0.8769\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2286 - accuracy: 0.8786 - val_loss: 0.3148 - val_accuracy: 0.8769\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2261 - accuracy: 0.8764 - val_loss: 0.3130 - val_accuracy: 0.8769\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3108 - val_accuracy: 0.8923\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2270 - accuracy: 0.8830 - val_loss: 0.3108 - val_accuracy: 0.8923\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2252 - accuracy: 0.8852 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2227 - accuracy: 0.8830 - val_loss: 0.3121 - val_accuracy: 0.8872\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3139 - val_accuracy: 0.8923\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2231 - accuracy: 0.8808 - val_loss: 0.3160 - val_accuracy: 0.8769\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3161 - val_accuracy: 0.8872\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2225 - accuracy: 0.8830 - val_loss: 0.3134 - val_accuracy: 0.8923\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2239 - accuracy: 0.8830 - val_loss: 0.3136 - val_accuracy: 0.8718\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2257 - accuracy: 0.8808 - val_loss: 0.3146 - val_accuracy: 0.8769\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2251 - accuracy: 0.8786 - val_loss: 0.3140 - val_accuracy: 0.8769\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2247 - accuracy: 0.8786 - val_loss: 0.3132 - val_accuracy: 0.8923\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2254 - accuracy: 0.8786 - val_loss: 0.3143 - val_accuracy: 0.8872\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2260 - accuracy: 0.8764 - val_loss: 0.3142 - val_accuracy: 0.8872\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2242 - accuracy: 0.8852 - val_loss: 0.3149 - val_accuracy: 0.8872\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3173 - val_accuracy: 0.8718\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.3149 - val_accuracy: 0.8923\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2271 - accuracy: 0.8742 - val_loss: 0.3166 - val_accuracy: 0.8718\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2234 - accuracy: 0.8830 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2262 - accuracy: 0.8808 - val_loss: 0.3150 - val_accuracy: 0.8923\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2252 - accuracy: 0.8764 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2262 - accuracy: 0.8720 - val_loss: 0.3164 - val_accuracy: 0.8872\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2278 - accuracy: 0.8764 - val_loss: 0.3183 - val_accuracy: 0.8718\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 399us/step - loss: 0.2264 - accuracy: 0.8720 - val_loss: 0.3157 - val_accuracy: 0.8923\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3170 - val_accuracy: 0.8923\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2227 - accuracy: 0.8852 - val_loss: 0.3204 - val_accuracy: 0.8872\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3200 - val_accuracy: 0.8718\n",
      "Epoch 490/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 199us/step - loss: 0.2236 - accuracy: 0.8830 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2260 - accuracy: 0.8852 - val_loss: 0.3133 - val_accuracy: 0.8974\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3172 - val_accuracy: 0.8923\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2265 - accuracy: 0.8808 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3162 - val_accuracy: 0.8872\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2227 - accuracy: 0.8830 - val_loss: 0.3191 - val_accuracy: 0.8769\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.2246 - accuracy: 0.8675 - val_loss: 0.3156 - val_accuracy: 0.8923\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2265 - accuracy: 0.8852 - val_loss: 0.3143 - val_accuracy: 0.8872\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2278 - accuracy: 0.8764 - val_loss: 0.3191 - val_accuracy: 0.8872\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3160 - val_accuracy: 0.8923\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2232 - accuracy: 0.8830 - val_loss: 0.3186 - val_accuracy: 0.8718\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2235 - accuracy: 0.8786 - val_loss: 0.3171 - val_accuracy: 0.8872\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2248 - accuracy: 0.8764 - val_loss: 0.3179 - val_accuracy: 0.8718\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2245 - accuracy: 0.8764 - val_loss: 0.3182 - val_accuracy: 0.8872\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.3214 - val_accuracy: 0.8769\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2254 - accuracy: 0.8852 - val_loss: 0.3174 - val_accuracy: 0.8923\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2257 - accuracy: 0.8808 - val_loss: 0.3165 - val_accuracy: 0.8923\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.3196 - val_accuracy: 0.8769\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2237 - accuracy: 0.8830 - val_loss: 0.3198 - val_accuracy: 0.8718\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2250 - accuracy: 0.8830 - val_loss: 0.3169 - val_accuracy: 0.8923\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3199 - val_accuracy: 0.8872\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3208 - val_accuracy: 0.8718\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2239 - accuracy: 0.8786 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2240 - accuracy: 0.8808 - val_loss: 0.3230 - val_accuracy: 0.8718\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2226 - accuracy: 0.8830 - val_loss: 0.3203 - val_accuracy: 0.8718\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3165 - val_accuracy: 0.8923\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2231 - accuracy: 0.8808 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2264 - accuracy: 0.8764 - val_loss: 0.3191 - val_accuracy: 0.8872\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2254 - accuracy: 0.8830 - val_loss: 0.3183 - val_accuracy: 0.8872\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2276 - accuracy: 0.8786 - val_loss: 0.3232 - val_accuracy: 0.8718\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2256 - accuracy: 0.8786 - val_loss: 0.3194 - val_accuracy: 0.8923\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.3185 - val_accuracy: 0.8872\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2281 - accuracy: 0.8852 - val_loss: 0.3239 - val_accuracy: 0.8667\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2241 - accuracy: 0.8786 - val_loss: 0.3212 - val_accuracy: 0.8923\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2274 - accuracy: 0.8852 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.3260 - val_accuracy: 0.8718\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.3207 - val_accuracy: 0.8872\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3198 - val_accuracy: 0.8769\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2248 - accuracy: 0.8830 - val_loss: 0.3244 - val_accuracy: 0.8872\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 366us/step - loss: 0.2246 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8923\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3197 - val_accuracy: 0.8872\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3181 - val_accuracy: 0.8872\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2272 - accuracy: 0.8786 - val_loss: 0.3209 - val_accuracy: 0.8923\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2254 - accuracy: 0.8786 - val_loss: 0.3212 - val_accuracy: 0.8718\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 407us/step - loss: 0.2264 - accuracy: 0.8698 - val_loss: 0.3219 - val_accuracy: 0.8769\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2221 - accuracy: 0.8830 - val_loss: 0.3195 - val_accuracy: 0.8872\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 342us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3187 - val_accuracy: 0.8923\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.3202 - val_accuracy: 0.8718\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 472us/step - loss: 0.2225 - accuracy: 0.8742 - val_loss: 0.3214 - val_accuracy: 0.8872\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 354us/step - loss: 0.2258 - accuracy: 0.8698 - val_loss: 0.3205 - val_accuracy: 0.8872\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3234 - val_accuracy: 0.8872\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2255 - accuracy: 0.8698 - val_loss: 0.3177 - val_accuracy: 0.8923\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2263 - accuracy: 0.8742 - val_loss: 0.3268 - val_accuracy: 0.8872\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2248 - accuracy: 0.8786 - val_loss: 0.3190 - val_accuracy: 0.8923\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3186 - val_accuracy: 0.8923\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2273 - accuracy: 0.8764 - val_loss: 0.3202 - val_accuracy: 0.8769\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3213 - val_accuracy: 0.8872\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2255 - accuracy: 0.8720 - val_loss: 0.3217 - val_accuracy: 0.8872\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2271 - accuracy: 0.8786 - val_loss: 0.3224 - val_accuracy: 0.8769\n",
      "Epoch 552/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3204 - val_accuracy: 0.8769\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3187 - val_accuracy: 0.8923\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2250 - accuracy: 0.8764 - val_loss: 0.3197 - val_accuracy: 0.8923\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3195 - val_accuracy: 0.8923\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3218 - val_accuracy: 0.8872\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2272 - accuracy: 0.8786 - val_loss: 0.3260 - val_accuracy: 0.8872\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2245 - accuracy: 0.8830 - val_loss: 0.3239 - val_accuracy: 0.8718\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3179 - val_accuracy: 0.8923\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2255 - accuracy: 0.8808 - val_loss: 0.3280 - val_accuracy: 0.8872\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2240 - accuracy: 0.8786 - val_loss: 0.3211 - val_accuracy: 0.8923\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3227 - val_accuracy: 0.8718\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2239 - accuracy: 0.8742 - val_loss: 0.3216 - val_accuracy: 0.8923\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3195 - val_accuracy: 0.8872\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3246 - val_accuracy: 0.8769\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2247 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2284 - accuracy: 0.8742 - val_loss: 0.3225 - val_accuracy: 0.8718\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2255 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2221 - accuracy: 0.8852 - val_loss: 0.3219 - val_accuracy: 0.8872\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3225 - val_accuracy: 0.8923\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 451us/step - loss: 0.2251 - accuracy: 0.8764 - val_loss: 0.3219 - val_accuracy: 0.8923\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3197 - val_accuracy: 0.8872\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3220 - val_accuracy: 0.8923\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2267 - accuracy: 0.8808 - val_loss: 0.3224 - val_accuracy: 0.8872\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2252 - accuracy: 0.8764 - val_loss: 0.3262 - val_accuracy: 0.8872\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2234 - accuracy: 0.8786 - val_loss: 0.3243 - val_accuracy: 0.8718\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2264 - accuracy: 0.8830 - val_loss: 0.3223 - val_accuracy: 0.8872\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2271 - accuracy: 0.8830 - val_loss: 0.3176 - val_accuracy: 0.8974\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3306 - val_accuracy: 0.8769\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2244 - accuracy: 0.8852 - val_loss: 0.3253 - val_accuracy: 0.8872\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2231 - accuracy: 0.8830 - val_loss: 0.3223 - val_accuracy: 0.8872\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2232 - accuracy: 0.8786 - val_loss: 0.3191 - val_accuracy: 0.8872\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 388us/step - loss: 0.2254 - accuracy: 0.8720 - val_loss: 0.3219 - val_accuracy: 0.8872\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3230 - val_accuracy: 0.8769\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2251 - accuracy: 0.8786 - val_loss: 0.3235 - val_accuracy: 0.8718\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2228 - accuracy: 0.8786 - val_loss: 0.3217 - val_accuracy: 0.8872\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 335us/step - loss: 0.2238 - accuracy: 0.8852 - val_loss: 0.3202 - val_accuracy: 0.8872\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3237 - val_accuracy: 0.8769\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 301us/step - loss: 0.2224 - accuracy: 0.8852 - val_loss: 0.3195 - val_accuracy: 0.8872\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 393us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3205 - val_accuracy: 0.8872\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2238 - accuracy: 0.8786 - val_loss: 0.3222 - val_accuracy: 0.8718\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2253 - accuracy: 0.8808 - val_loss: 0.3235 - val_accuracy: 0.8872\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.2250 - accuracy: 0.8720 - val_loss: 0.3198 - val_accuracy: 0.8923\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3211 - val_accuracy: 0.8872\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.3210 - val_accuracy: 0.8718\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2229 - accuracy: 0.8874 - val_loss: 0.3236 - val_accuracy: 0.8872\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2232 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8923\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.3251 - val_accuracy: 0.8718\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 140us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.3274 - val_accuracy: 0.8923\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2248 - accuracy: 0.8786 - val_loss: 0.3189 - val_accuracy: 0.8923\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2273 - accuracy: 0.8808 - val_loss: 0.3196 - val_accuracy: 0.8872\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2258 - accuracy: 0.8808 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3192 - val_accuracy: 0.8872\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2248 - accuracy: 0.8786 - val_loss: 0.3227 - val_accuracy: 0.8872\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2265 - accuracy: 0.8830 - val_loss: 0.3204 - val_accuracy: 0.8923\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3210 - val_accuracy: 0.8872\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3181 - val_accuracy: 0.8923\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3229 - val_accuracy: 0.8769\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2252 - accuracy: 0.8786 - val_loss: 0.3207 - val_accuracy: 0.8769\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2241 - accuracy: 0.8808 - val_loss: 0.3229 - val_accuracy: 0.8718\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3216 - val_accuracy: 0.8872\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2227 - accuracy: 0.8742 - val_loss: 0.3195 - val_accuracy: 0.8923\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2248 - accuracy: 0.8808 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2244 - accuracy: 0.8830 - val_loss: 0.3188 - val_accuracy: 0.8923\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2258 - accuracy: 0.8852 - val_loss: 0.3242 - val_accuracy: 0.8923\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3199 - val_accuracy: 0.8872\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2248 - accuracy: 0.8786 - val_loss: 0.3232 - val_accuracy: 0.8718\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2240 - accuracy: 0.8786 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2252 - accuracy: 0.8720 - val_loss: 0.3218 - val_accuracy: 0.8718\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2246 - accuracy: 0.8830 - val_loss: 0.3215 - val_accuracy: 0.8923\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2213 - accuracy: 0.8808 - val_loss: 0.3258 - val_accuracy: 0.8718\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2227 - accuracy: 0.8852 - val_loss: 0.3209 - val_accuracy: 0.8923\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3207 - val_accuracy: 0.8872\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2249 - accuracy: 0.8808 - val_loss: 0.3286 - val_accuracy: 0.8718\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 584us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.3246 - val_accuracy: 0.8769\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 469us/step - loss: 0.2255 - accuracy: 0.8830 - val_loss: 0.3238 - val_accuracy: 0.8872\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2240 - accuracy: 0.8852 - val_loss: 0.3211 - val_accuracy: 0.8923\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2248 - accuracy: 0.8720 - val_loss: 0.3231 - val_accuracy: 0.8718\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2246 - accuracy: 0.8808 - val_loss: 0.3207 - val_accuracy: 0.8923\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3201 - val_accuracy: 0.8769\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2283 - accuracy: 0.8764 - val_loss: 0.3249 - val_accuracy: 0.8872\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2254 - accuracy: 0.8808 - val_loss: 0.3203 - val_accuracy: 0.8923\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2263 - accuracy: 0.8830 - val_loss: 0.3236 - val_accuracy: 0.8769\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3208 - val_accuracy: 0.8923\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2227 - accuracy: 0.8830 - val_loss: 0.3246 - val_accuracy: 0.8872\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2237 - accuracy: 0.8764 - val_loss: 0.3189 - val_accuracy: 0.8923\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.3234 - val_accuracy: 0.8923\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3223 - val_accuracy: 0.8923\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2231 - accuracy: 0.8808 - val_loss: 0.3210 - val_accuracy: 0.8718\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2275 - accuracy: 0.8852 - val_loss: 0.3257 - val_accuracy: 0.8923\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2251 - accuracy: 0.8808 - val_loss: 0.3230 - val_accuracy: 0.8769\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2251 - accuracy: 0.8786 - val_loss: 0.3234 - val_accuracy: 0.8923\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2265 - accuracy: 0.8675 - val_loss: 0.3199 - val_accuracy: 0.8769\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2248 - accuracy: 0.8742 - val_loss: 0.3202 - val_accuracy: 0.8872\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2243 - accuracy: 0.8852 - val_loss: 0.3183 - val_accuracy: 0.8872\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3225 - val_accuracy: 0.8923\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2260 - accuracy: 0.8786 - val_loss: 0.3173 - val_accuracy: 0.8872\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2248 - accuracy: 0.8698 - val_loss: 0.3219 - val_accuracy: 0.8872\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2275 - accuracy: 0.8786 - val_loss: 0.3210 - val_accuracy: 0.8923\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2260 - accuracy: 0.8830 - val_loss: 0.3202 - val_accuracy: 0.8923\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2268 - accuracy: 0.8764 - val_loss: 0.3195 - val_accuracy: 0.8923\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3209 - val_accuracy: 0.8872\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3213 - val_accuracy: 0.8872\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2250 - accuracy: 0.8852 - val_loss: 0.3231 - val_accuracy: 0.8872\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3207 - val_accuracy: 0.8872\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2256 - accuracy: 0.8786 - val_loss: 0.3179 - val_accuracy: 0.8974\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2245 - accuracy: 0.8808 - val_loss: 0.3205 - val_accuracy: 0.8872\n",
      "Epoch 662/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2234 - accuracy: 0.8830 - val_loss: 0.3234 - val_accuracy: 0.8769\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2264 - accuracy: 0.8830 - val_loss: 0.3249 - val_accuracy: 0.8872\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3231 - val_accuracy: 0.8872\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2246 - accuracy: 0.8786 - val_loss: 0.3193 - val_accuracy: 0.8872\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.2255 - accuracy: 0.8808 - val_loss: 0.3211 - val_accuracy: 0.8872\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3189 - val_accuracy: 0.8923\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2232 - accuracy: 0.8808 - val_loss: 0.3196 - val_accuracy: 0.8872\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2269 - accuracy: 0.8720 - val_loss: 0.3204 - val_accuracy: 0.8872\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2230 - accuracy: 0.8852 - val_loss: 0.3215 - val_accuracy: 0.8872\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3208 - val_accuracy: 0.8872\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 338us/step - loss: 0.2230 - accuracy: 0.8742 - val_loss: 0.3176 - val_accuracy: 0.8974\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2236 - accuracy: 0.8720 - val_loss: 0.3193 - val_accuracy: 0.8872\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2246 - accuracy: 0.8830 - val_loss: 0.3192 - val_accuracy: 0.8872\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3169 - val_accuracy: 0.8923\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3264 - val_accuracy: 0.8923\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.3269 - val_accuracy: 0.8718\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3224 - val_accuracy: 0.8872\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2238 - accuracy: 0.8852 - val_loss: 0.3217 - val_accuracy: 0.8923\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2236 - accuracy: 0.8786 - val_loss: 0.3221 - val_accuracy: 0.8769\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2263 - accuracy: 0.8786 - val_loss: 0.3197 - val_accuracy: 0.8872\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2228 - accuracy: 0.8852 - val_loss: 0.3193 - val_accuracy: 0.8872\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2226 - accuracy: 0.8786 - val_loss: 0.3213 - val_accuracy: 0.8872\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3199 - val_accuracy: 0.8718\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.3209 - val_accuracy: 0.8769\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2239 - accuracy: 0.8808 - val_loss: 0.3194 - val_accuracy: 0.8872\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2256 - accuracy: 0.8742 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2274 - accuracy: 0.8786 - val_loss: 0.3266 - val_accuracy: 0.8718\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2254 - accuracy: 0.8720 - val_loss: 0.3174 - val_accuracy: 0.8872\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2262 - accuracy: 0.8786 - val_loss: 0.3228 - val_accuracy: 0.8718\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3208 - val_accuracy: 0.8718\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2239 - accuracy: 0.8720 - val_loss: 0.3168 - val_accuracy: 0.8923\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2235 - accuracy: 0.8852 - val_loss: 0.3184 - val_accuracy: 0.8923\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8923\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 312us/step - loss: 0.2211 - accuracy: 0.8874 - val_loss: 0.3253 - val_accuracy: 0.8769\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2238 - accuracy: 0.8786 - val_loss: 0.3170 - val_accuracy: 0.8872\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.3191 - val_accuracy: 0.8923\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2282 - accuracy: 0.8764 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2261 - accuracy: 0.8874 - val_loss: 0.3186 - val_accuracy: 0.8923\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3178 - val_accuracy: 0.8923\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2263 - accuracy: 0.8742 - val_loss: 0.3151 - val_accuracy: 0.8923\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.3255 - val_accuracy: 0.8872\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2259 - accuracy: 0.8808 - val_loss: 0.3193 - val_accuracy: 0.8923\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2253 - accuracy: 0.8808 - val_loss: 0.3243 - val_accuracy: 0.8718\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 342us/step - loss: 0.2243 - accuracy: 0.8830 - val_loss: 0.3152 - val_accuracy: 0.8872\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2249 - accuracy: 0.8808 - val_loss: 0.3152 - val_accuracy: 0.8923\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2237 - accuracy: 0.8786 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 562us/step - loss: 0.2231 - accuracy: 0.8786 - val_loss: 0.3135 - val_accuracy: 0.8923\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 351us/step - loss: 0.2222 - accuracy: 0.8808 - val_loss: 0.3195 - val_accuracy: 0.8923\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3189 - val_accuracy: 0.8769\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2275 - accuracy: 0.8764 - val_loss: 0.3197 - val_accuracy: 0.8872\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2247 - accuracy: 0.8764 - val_loss: 0.3166 - val_accuracy: 0.8821\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2223 - accuracy: 0.8764 - val_loss: 0.3158 - val_accuracy: 0.8872\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2248 - accuracy: 0.8742 - val_loss: 0.3188 - val_accuracy: 0.8872\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2239 - accuracy: 0.8830 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2279 - accuracy: 0.8720 - val_loss: 0.3155 - val_accuracy: 0.8872\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2223 - accuracy: 0.8830 - val_loss: 0.3157 - val_accuracy: 0.8872\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8872\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2252 - accuracy: 0.8852 - val_loss: 0.3160 - val_accuracy: 0.8923\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2251 - accuracy: 0.8830 - val_loss: 0.3218 - val_accuracy: 0.8718\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2272 - accuracy: 0.8808 - val_loss: 0.3180 - val_accuracy: 0.8872\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2229 - accuracy: 0.8808 - val_loss: 0.3186 - val_accuracy: 0.8718\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2248 - accuracy: 0.8808 - val_loss: 0.3247 - val_accuracy: 0.8718\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3200 - val_accuracy: 0.8974\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2236 - accuracy: 0.8830 - val_loss: 0.3210 - val_accuracy: 0.8872\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3210 - val_accuracy: 0.8769\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2242 - accuracy: 0.8764 - val_loss: 0.3176 - val_accuracy: 0.8872\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 319us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3212 - val_accuracy: 0.8718\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2234 - accuracy: 0.8808 - val_loss: 0.3202 - val_accuracy: 0.8872\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2235 - accuracy: 0.8786 - val_loss: 0.3202 - val_accuracy: 0.8923\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2230 - accuracy: 0.8742 - val_loss: 0.3184 - val_accuracy: 0.8872\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 393us/step - loss: 0.2256 - accuracy: 0.8830 - val_loss: 0.3216 - val_accuracy: 0.8769\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.3183 - val_accuracy: 0.8923\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2265 - accuracy: 0.8786 - val_loss: 0.3210 - val_accuracy: 0.8718\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2224 - accuracy: 0.8852 - val_loss: 0.3181 - val_accuracy: 0.8923\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2252 - accuracy: 0.8742 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.3217 - val_accuracy: 0.8872\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2246 - accuracy: 0.8742 - val_loss: 0.3191 - val_accuracy: 0.8923\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2239 - accuracy: 0.8808 - val_loss: 0.3194 - val_accuracy: 0.8872\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2303 - accuracy: 0.8742 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2287 - accuracy: 0.8808 - val_loss: 0.3198 - val_accuracy: 0.8769\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2257 - accuracy: 0.8742 - val_loss: 0.3204 - val_accuracy: 0.8769\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2261 - accuracy: 0.8698 - val_loss: 0.3176 - val_accuracy: 0.8923\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2244 - accuracy: 0.8742 - val_loss: 0.3196 - val_accuracy: 0.8872\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3237 - val_accuracy: 0.8769\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.3238 - val_accuracy: 0.8923\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2232 - accuracy: 0.8764 - val_loss: 0.3244 - val_accuracy: 0.8718\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2265 - accuracy: 0.8830 - val_loss: 0.3217 - val_accuracy: 0.8872\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.8808 - val_loss: 0.3206 - val_accuracy: 0.8923\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3225 - val_accuracy: 0.8872\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2264 - accuracy: 0.8764 - val_loss: 0.3203 - val_accuracy: 0.8923\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2237 - accuracy: 0.8786 - val_loss: 0.3193 - val_accuracy: 0.8718\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2233 - accuracy: 0.8808 - val_loss: 0.3203 - val_accuracy: 0.8872\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3186 - val_accuracy: 0.8923\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2234 - accuracy: 0.8786 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.3209 - val_accuracy: 0.8923\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2268 - accuracy: 0.8830 - val_loss: 0.3221 - val_accuracy: 0.8872\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2225 - accuracy: 0.8720 - val_loss: 0.3208 - val_accuracy: 0.8821\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2256 - accuracy: 0.8742 - val_loss: 0.3241 - val_accuracy: 0.8923\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2249 - accuracy: 0.8830 - val_loss: 0.3229 - val_accuracy: 0.8872\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3231 - val_accuracy: 0.8872\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2250 - accuracy: 0.8742 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2240 - accuracy: 0.8786 - val_loss: 0.3219 - val_accuracy: 0.8872\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2230 - accuracy: 0.8852 - val_loss: 0.3198 - val_accuracy: 0.8872\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2265 - accuracy: 0.8764 - val_loss: 0.3190 - val_accuracy: 0.8923\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2251 - accuracy: 0.8852 - val_loss: 0.3210 - val_accuracy: 0.8923\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2233 - accuracy: 0.8786 - val_loss: 0.3177 - val_accuracy: 0.8923\n",
      "Epoch 772/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2234 - accuracy: 0.8742 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2227 - accuracy: 0.8852 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2258 - accuracy: 0.8742 - val_loss: 0.3218 - val_accuracy: 0.8872\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2222 - accuracy: 0.8852 - val_loss: 0.3229 - val_accuracy: 0.8923\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2256 - accuracy: 0.8808 - val_loss: 0.3208 - val_accuracy: 0.8923\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.3218 - val_accuracy: 0.8718\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2230 - accuracy: 0.8852 - val_loss: 0.3201 - val_accuracy: 0.8923\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2227 - accuracy: 0.8764 - val_loss: 0.3199 - val_accuracy: 0.8769\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2241 - accuracy: 0.8808 - val_loss: 0.3240 - val_accuracy: 0.8718\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3201 - val_accuracy: 0.8872\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2225 - accuracy: 0.8764 - val_loss: 0.3194 - val_accuracy: 0.8769\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2249 - accuracy: 0.8764 - val_loss: 0.3180 - val_accuracy: 0.8923\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2241 - accuracy: 0.8852 - val_loss: 0.3212 - val_accuracy: 0.8923\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2268 - accuracy: 0.8852 - val_loss: 0.3202 - val_accuracy: 0.8923\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3214 - val_accuracy: 0.8769\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2212 - accuracy: 0.8874 - val_loss: 0.3193 - val_accuracy: 0.8872\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2231 - accuracy: 0.8852 - val_loss: 0.3213 - val_accuracy: 0.8718\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2238 - accuracy: 0.8786 - val_loss: 0.3170 - val_accuracy: 0.8923\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3195 - val_accuracy: 0.8769\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2220 - accuracy: 0.8896 - val_loss: 0.3218 - val_accuracy: 0.8872\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2238 - accuracy: 0.8742 - val_loss: 0.3193 - val_accuracy: 0.8769\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2240 - accuracy: 0.8852 - val_loss: 0.3188 - val_accuracy: 0.8872\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3214 - val_accuracy: 0.8769\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2247 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8718\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2217 - accuracy: 0.8830 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2223 - accuracy: 0.8852 - val_loss: 0.3189 - val_accuracy: 0.8872\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2241 - accuracy: 0.8764 - val_loss: 0.3194 - val_accuracy: 0.8872\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3179 - val_accuracy: 0.8769\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2268 - accuracy: 0.8830 - val_loss: 0.3211 - val_accuracy: 0.8872\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2232 - accuracy: 0.8808 - val_loss: 0.3167 - val_accuracy: 0.8923\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2225 - accuracy: 0.8786 - val_loss: 0.3168 - val_accuracy: 0.8872\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2213 - accuracy: 0.8830 - val_loss: 0.3202 - val_accuracy: 0.8769\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2229 - accuracy: 0.8720 - val_loss: 0.3199 - val_accuracy: 0.8769\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2231 - accuracy: 0.8808 - val_loss: 0.3193 - val_accuracy: 0.8769\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2251 - accuracy: 0.8830 - val_loss: 0.3186 - val_accuracy: 0.8923\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2253 - accuracy: 0.8808 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2270 - accuracy: 0.8852 - val_loss: 0.3203 - val_accuracy: 0.8769\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2252 - accuracy: 0.8764 - val_loss: 0.3166 - val_accuracy: 0.8923\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2239 - accuracy: 0.8742 - val_loss: 0.3193 - val_accuracy: 0.8923\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2236 - accuracy: 0.8808 - val_loss: 0.3197 - val_accuracy: 0.8718\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2269 - accuracy: 0.8764 - val_loss: 0.3160 - val_accuracy: 0.8974\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2270 - accuracy: 0.8852 - val_loss: 0.3198 - val_accuracy: 0.8872\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2235 - accuracy: 0.8764 - val_loss: 0.3169 - val_accuracy: 0.8923\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2255 - accuracy: 0.8852 - val_loss: 0.3227 - val_accuracy: 0.8718\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2237 - accuracy: 0.8830 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 116us/step - loss: 0.2238 - accuracy: 0.8720 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2231 - accuracy: 0.8830 - val_loss: 0.3194 - val_accuracy: 0.8769\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2222 - accuracy: 0.8808 - val_loss: 0.3203 - val_accuracy: 0.8872\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2262 - accuracy: 0.8720 - val_loss: 0.3177 - val_accuracy: 0.8923\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2244 - accuracy: 0.8874 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2259 - accuracy: 0.8808 - val_loss: 0.3199 - val_accuracy: 0.8872\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3214 - val_accuracy: 0.8872\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2233 - accuracy: 0.8764 - val_loss: 0.3192 - val_accuracy: 0.8923\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2252 - accuracy: 0.8852 - val_loss: 0.3188 - val_accuracy: 0.8872\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2234 - accuracy: 0.8742 - val_loss: 0.3182 - val_accuracy: 0.8769\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3180 - val_accuracy: 0.8923\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2232 - accuracy: 0.8786 - val_loss: 0.3205 - val_accuracy: 0.8872\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2225 - accuracy: 0.8852 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2252 - accuracy: 0.8764 - val_loss: 0.3216 - val_accuracy: 0.8718\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2252 - accuracy: 0.8808 - val_loss: 0.3157 - val_accuracy: 0.8923\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3217 - val_accuracy: 0.8923\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2226 - accuracy: 0.8852 - val_loss: 0.3186 - val_accuracy: 0.8769\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2233 - accuracy: 0.8830 - val_loss: 0.3164 - val_accuracy: 0.8872\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2221 - accuracy: 0.8852 - val_loss: 0.3159 - val_accuracy: 0.8923\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2232 - accuracy: 0.8852 - val_loss: 0.3161 - val_accuracy: 0.8821\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2236 - accuracy: 0.8786 - val_loss: 0.3161 - val_accuracy: 0.8923\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3171 - val_accuracy: 0.8872\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2239 - accuracy: 0.8852 - val_loss: 0.3172 - val_accuracy: 0.8923\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3181 - val_accuracy: 0.8923\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2240 - accuracy: 0.8720 - val_loss: 0.3147 - val_accuracy: 0.8872\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2238 - accuracy: 0.8808 - val_loss: 0.3186 - val_accuracy: 0.8769\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2238 - accuracy: 0.8742 - val_loss: 0.3153 - val_accuracy: 0.8923\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2226 - accuracy: 0.8742 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3196 - val_accuracy: 0.8769\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2240 - accuracy: 0.8764 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3146 - val_accuracy: 0.8923\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2240 - accuracy: 0.8764 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2227 - accuracy: 0.8852 - val_loss: 0.3158 - val_accuracy: 0.8872\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2239 - accuracy: 0.8830 - val_loss: 0.3145 - val_accuracy: 0.8923\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2219 - accuracy: 0.8852 - val_loss: 0.3161 - val_accuracy: 0.8872\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2226 - accuracy: 0.8786 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.3152 - val_accuracy: 0.8923\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2265 - accuracy: 0.8786 - val_loss: 0.3171 - val_accuracy: 0.8718\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3218 - val_accuracy: 0.8872\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2246 - accuracy: 0.8830 - val_loss: 0.3188 - val_accuracy: 0.8718\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2266 - accuracy: 0.8742 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3185 - val_accuracy: 0.8718\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 373us/step - loss: 0.2262 - accuracy: 0.8830 - val_loss: 0.3192 - val_accuracy: 0.8872\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2230 - accuracy: 0.8852 - val_loss: 0.3156 - val_accuracy: 0.8872\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2256 - accuracy: 0.8786 - val_loss: 0.3168 - val_accuracy: 0.8923\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.3211 - val_accuracy: 0.8718\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.3194 - val_accuracy: 0.8923\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2271 - accuracy: 0.8808 - val_loss: 0.3185 - val_accuracy: 0.8872\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2268 - accuracy: 0.8786 - val_loss: 0.3157 - val_accuracy: 0.8974\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2257 - accuracy: 0.8830 - val_loss: 0.3211 - val_accuracy: 0.8718\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2241 - accuracy: 0.8786 - val_loss: 0.3176 - val_accuracy: 0.8872\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2247 - accuracy: 0.8786 - val_loss: 0.3185 - val_accuracy: 0.8718\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2235 - accuracy: 0.8764 - val_loss: 0.3196 - val_accuracy: 0.8872\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2256 - accuracy: 0.8852 - val_loss: 0.3178 - val_accuracy: 0.8923\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2250 - accuracy: 0.8786 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2234 - accuracy: 0.8742 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2231 - accuracy: 0.8742 - val_loss: 0.3172 - val_accuracy: 0.8872\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2229 - accuracy: 0.8808 - val_loss: 0.3168 - val_accuracy: 0.8872\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2226 - accuracy: 0.8764 - val_loss: 0.3161 - val_accuracy: 0.8923\n",
      "Epoch 882/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2236 - accuracy: 0.8786 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2256 - accuracy: 0.8720 - val_loss: 0.3158 - val_accuracy: 0.8872\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2253 - accuracy: 0.8852 - val_loss: 0.3182 - val_accuracy: 0.8872\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2217 - accuracy: 0.8808 - val_loss: 0.3158 - val_accuracy: 0.8923\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2229 - accuracy: 0.8852 - val_loss: 0.3180 - val_accuracy: 0.8923\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2233 - accuracy: 0.8874 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2220 - accuracy: 0.8808 - val_loss: 0.3178 - val_accuracy: 0.8923\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2241 - accuracy: 0.8830 - val_loss: 0.3161 - val_accuracy: 0.8769\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2233 - accuracy: 0.8786 - val_loss: 0.3152 - val_accuracy: 0.8769\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2214 - accuracy: 0.8874 - val_loss: 0.3175 - val_accuracy: 0.8872\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2248 - accuracy: 0.8852 - val_loss: 0.3176 - val_accuracy: 0.8872\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2245 - accuracy: 0.8786 - val_loss: 0.3158 - val_accuracy: 0.8923\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2236 - accuracy: 0.8675 - val_loss: 0.3157 - val_accuracy: 0.8923\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2240 - accuracy: 0.8830 - val_loss: 0.3194 - val_accuracy: 0.8872\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2243 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8769\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 496us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3185 - val_accuracy: 0.8872\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2217 - accuracy: 0.8808 - val_loss: 0.3181 - val_accuracy: 0.8718\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2251 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8769\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3156 - val_accuracy: 0.8923\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2229 - accuracy: 0.8830 - val_loss: 0.3166 - val_accuracy: 0.8769\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2248 - accuracy: 0.8764 - val_loss: 0.3177 - val_accuracy: 0.8718\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3204 - val_accuracy: 0.8769\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2232 - accuracy: 0.8742 - val_loss: 0.3144 - val_accuracy: 0.8923\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2229 - accuracy: 0.8720 - val_loss: 0.3157 - val_accuracy: 0.8872\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3171 - val_accuracy: 0.8923\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2226 - accuracy: 0.8830 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2225 - accuracy: 0.8830 - val_loss: 0.3149 - val_accuracy: 0.8872\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2270 - accuracy: 0.8852 - val_loss: 0.3170 - val_accuracy: 0.8923\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2235 - accuracy: 0.8786 - val_loss: 0.3172 - val_accuracy: 0.8769\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2231 - accuracy: 0.8852 - val_loss: 0.3155 - val_accuracy: 0.8923\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2268 - accuracy: 0.8675 - val_loss: 0.3173 - val_accuracy: 0.8872\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2217 - accuracy: 0.8786 - val_loss: 0.3153 - val_accuracy: 0.8974\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2239 - accuracy: 0.8808 - val_loss: 0.3176 - val_accuracy: 0.8769\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2237 - accuracy: 0.8808 - val_loss: 0.3157 - val_accuracy: 0.8872\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2223 - accuracy: 0.8852 - val_loss: 0.3187 - val_accuracy: 0.8769\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2232 - accuracy: 0.8830 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.3167 - val_accuracy: 0.8923\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2270 - accuracy: 0.8786 - val_loss: 0.3229 - val_accuracy: 0.8718\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2255 - accuracy: 0.8808 - val_loss: 0.3162 - val_accuracy: 0.8923\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2271 - accuracy: 0.8808 - val_loss: 0.3197 - val_accuracy: 0.8821\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2228 - accuracy: 0.8764 - val_loss: 0.3188 - val_accuracy: 0.8718\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2235 - accuracy: 0.8830 - val_loss: 0.3181 - val_accuracy: 0.8769\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2242 - accuracy: 0.8786 - val_loss: 0.3155 - val_accuracy: 0.8974\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2242 - accuracy: 0.8808 - val_loss: 0.3171 - val_accuracy: 0.8923\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3179 - val_accuracy: 0.8872\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2252 - accuracy: 0.8830 - val_loss: 0.3195 - val_accuracy: 0.8769\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2247 - accuracy: 0.8852 - val_loss: 0.3174 - val_accuracy: 0.8923\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3176 - val_accuracy: 0.8718\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 134us/step - loss: 0.2245 - accuracy: 0.8830 - val_loss: 0.3199 - val_accuracy: 0.8769\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2228 - accuracy: 0.8764 - val_loss: 0.3179 - val_accuracy: 0.8923\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2239 - accuracy: 0.8764 - val_loss: 0.3167 - val_accuracy: 0.8872\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2254 - accuracy: 0.8742 - val_loss: 0.3179 - val_accuracy: 0.8872\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2228 - accuracy: 0.8830 - val_loss: 0.3155 - val_accuracy: 0.8923\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2239 - accuracy: 0.8830 - val_loss: 0.3187 - val_accuracy: 0.8769\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2320 - accuracy: 0.8764 - val_loss: 0.3227 - val_accuracy: 0.8872\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2233 - accuracy: 0.8830 - val_loss: 0.3195 - val_accuracy: 0.8923\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2244 - accuracy: 0.8764 - val_loss: 0.3207 - val_accuracy: 0.8872\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2224 - accuracy: 0.8830 - val_loss: 0.3157 - val_accuracy: 0.8923\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2239 - accuracy: 0.8808 - val_loss: 0.3201 - val_accuracy: 0.8718\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2231 - accuracy: 0.8808 - val_loss: 0.3165 - val_accuracy: 0.8923\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2227 - accuracy: 0.8720 - val_loss: 0.3150 - val_accuracy: 0.8923\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2249 - accuracy: 0.8808 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2262 - accuracy: 0.8786 - val_loss: 0.3188 - val_accuracy: 0.8718\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2270 - accuracy: 0.8742 - val_loss: 0.3173 - val_accuracy: 0.8923\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2258 - accuracy: 0.8786 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2253 - accuracy: 0.8786 - val_loss: 0.3198 - val_accuracy: 0.8769\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2259 - accuracy: 0.8830 - val_loss: 0.3212 - val_accuracy: 0.8923\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3192 - val_accuracy: 0.8769\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2239 - accuracy: 0.8742 - val_loss: 0.3182 - val_accuracy: 0.8923\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2243 - accuracy: 0.8786 - val_loss: 0.3188 - val_accuracy: 0.8872\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2242 - accuracy: 0.8698 - val_loss: 0.3154 - val_accuracy: 0.8718\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2241 - accuracy: 0.8852 - val_loss: 0.3155 - val_accuracy: 0.8872\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2231 - accuracy: 0.8852 - val_loss: 0.3136 - val_accuracy: 0.8923\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2225 - accuracy: 0.8786 - val_loss: 0.3155 - val_accuracy: 0.8872\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2226 - accuracy: 0.8830 - val_loss: 0.3168 - val_accuracy: 0.8923\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3161 - val_accuracy: 0.8769\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2205 - accuracy: 0.8874 - val_loss: 0.3183 - val_accuracy: 0.8872\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2243 - accuracy: 0.8852 - val_loss: 0.3163 - val_accuracy: 0.8872\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2224 - accuracy: 0.8786 - val_loss: 0.3164 - val_accuracy: 0.8923\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.3180 - val_accuracy: 0.8923\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2230 - accuracy: 0.8808 - val_loss: 0.3156 - val_accuracy: 0.8923\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2246 - accuracy: 0.8742 - val_loss: 0.3159 - val_accuracy: 0.8872\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2227 - accuracy: 0.8830 - val_loss: 0.3164 - val_accuracy: 0.8872\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2251 - accuracy: 0.8786 - val_loss: 0.3153 - val_accuracy: 0.8974\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2213 - accuracy: 0.8852 - val_loss: 0.3178 - val_accuracy: 0.8718\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2264 - accuracy: 0.8720 - val_loss: 0.3180 - val_accuracy: 0.8923\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2239 - accuracy: 0.8808 - val_loss: 0.3213 - val_accuracy: 0.8872\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2230 - accuracy: 0.8808 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2236 - accuracy: 0.8764 - val_loss: 0.3174 - val_accuracy: 0.8872\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2233 - accuracy: 0.8764 - val_loss: 0.3154 - val_accuracy: 0.8923\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2237 - accuracy: 0.8852 - val_loss: 0.3170 - val_accuracy: 0.8923\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2215 - accuracy: 0.8852 - val_loss: 0.3160 - val_accuracy: 0.8872\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2227 - accuracy: 0.8852 - val_loss: 0.3184 - val_accuracy: 0.8872\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2216 - accuracy: 0.8786 - val_loss: 0.3147 - val_accuracy: 0.8923\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2249 - accuracy: 0.8852 - val_loss: 0.3167 - val_accuracy: 0.8923\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2238 - accuracy: 0.8808 - val_loss: 0.3145 - val_accuracy: 0.8923\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2233 - accuracy: 0.8764 - val_loss: 0.3184 - val_accuracy: 0.8872\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.3153 - val_accuracy: 0.8872\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2231 - accuracy: 0.8720 - val_loss: 0.3149 - val_accuracy: 0.8923\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2243 - accuracy: 0.8786 - val_loss: 0.3154 - val_accuracy: 0.8872\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2227 - accuracy: 0.8742 - val_loss: 0.3203 - val_accuracy: 0.8718\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2244 - accuracy: 0.8808 - val_loss: 0.3191 - val_accuracy: 0.8872\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2243 - accuracy: 0.8808 - val_loss: 0.3171 - val_accuracy: 0.8923\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2236 - accuracy: 0.8830 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2254 - accuracy: 0.8720 - val_loss: 0.3191 - val_accuracy: 0.8718\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2235 - accuracy: 0.8742 - val_loss: 0.3180 - val_accuracy: 0.8872\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2238 - accuracy: 0.8720 - val_loss: 0.3167 - val_accuracy: 0.8923\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2232 - accuracy: 0.8764 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2231 - accuracy: 0.8852 - val_loss: 0.3168 - val_accuracy: 0.8923\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2226 - accuracy: 0.8808 - val_loss: 0.3182 - val_accuracy: 0.8923\n",
      "Epoch 992/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2233 - accuracy: 0.8764 - val_loss: 0.3163 - val_accuracy: 0.8923\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2232 - accuracy: 0.8786 - val_loss: 0.3171 - val_accuracy: 0.8872\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2244 - accuracy: 0.8786 - val_loss: 0.3179 - val_accuracy: 0.8872\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2245 - accuracy: 0.8874 - val_loss: 0.3205 - val_accuracy: 0.8769\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2242 - accuracy: 0.8830 - val_loss: 0.3182 - val_accuracy: 0.8923\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2236 - accuracy: 0.8852 - val_loss: 0.3190 - val_accuracy: 0.8872\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2250 - accuracy: 0.8808 - val_loss: 0.3177 - val_accuracy: 0.8872\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2257 - accuracy: 0.8786 - val_loss: 0.3170 - val_accuracy: 0.8821\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2260 - accuracy: 0.8786 - val_loss: 0.3191 - val_accuracy: 0.8769\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.87635960e-05, 9.99971300e-01, 9.79098100e-15],\n",
       "       [1.24548726e-01, 8.75451270e-01, 3.46349100e-13],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [1.38076260e-06, 9.99998570e-01, 0.00000000e+00],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [6.44286930e-01, 3.55713070e-01, 4.28992500e-10],\n",
       "       [4.17960100e-01, 5.82039800e-01, 1.29178620e-07],\n",
       "       [2.79833970e-02, 9.72012160e-01, 4.44106500e-06],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [1.01026220e-04, 9.99898900e-01, 7.97193600e-12],\n",
       "       [9.99998000e-01, 1.98930770e-06, 1.68998830e-14],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [2.77286540e-06, 9.99997260e-01, 9.16013400e-21],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [1.67231600e-08, 1.00000000e+00, 2.69197760e-38],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [1.66145970e-02, 9.83384970e-01, 4.77303500e-07],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [2.49513320e-09, 1.00000000e+00, 7.57513800e-23],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [2.77286540e-06, 9.99997260e-01, 9.16013400e-21],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [2.77286540e-06, 9.99997260e-01, 9.16013400e-21],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [2.87635960e-05, 9.99971300e-01, 9.79098100e-15],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [4.17960100e-01, 5.82039800e-01, 1.29178620e-07],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [2.02852500e-03, 9.97971500e-01, 3.47802680e-10],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [2.49513320e-09, 1.00000000e+00, 7.57513800e-23],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [4.17960100e-01, 5.82039800e-01, 1.29178620e-07],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.97770300e-01, 2.22965590e-03, 1.17126050e-15],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [5.00749300e-01, 4.99250680e-01, 1.82173240e-14],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [2.77286540e-06, 9.99997260e-01, 9.16013400e-21],\n",
       "       [9.99998100e-01, 1.88439830e-06, 1.97180750e-20],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [9.99951500e-01, 4.85390230e-05, 5.04768160e-13],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.09168150e-06, 9.99996900e-01, 3.47731530e-11],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [5.00749300e-01, 4.99250680e-01, 1.82173240e-14],\n",
       "       [9.78620900e-01, 2.13790760e-02, 3.78436750e-22],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [2.85939950e-11, 1.00000000e+00, 0.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.45018170e-09, 1.00000000e+00, 3.14993420e-36],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.68921360e-01, 3.10777440e-02, 9.54774100e-07],\n",
       "       [6.44286930e-01, 3.55713070e-01, 4.28992500e-10],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.99951500e-01, 4.85390230e-05, 5.04768160e-13],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [8.49479400e-08, 9.99999900e-01, 1.97443830e-27],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [2.87635960e-05, 9.99971300e-01, 9.79098100e-15],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.95120940e-01, 4.87904160e-03, 1.75282660e-14],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [1.00000000e+00, 1.72224800e-08, 1.68035080e-27],\n",
       "       [9.64322600e-01, 3.56773250e-02, 4.16631100e-14],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.99999900e-01, 1.54034880e-07, 4.61219530e-33],\n",
       "       [3.09168150e-06, 9.99996900e-01, 3.47731530e-11],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [6.40258900e-01, 3.59706430e-01, 3.46262460e-05],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [1.24548726e-01, 8.75451270e-01, 3.46349100e-13],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [9.98347640e-01, 1.65241620e-03, 4.90336750e-22],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [1.01026220e-04, 9.99898900e-01, 7.97193600e-12],\n",
       "       [9.99986400e-01, 1.36403960e-05, 9.71581700e-16],\n",
       "       [2.49513320e-09, 1.00000000e+00, 7.57513800e-23],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [9.99951500e-01, 4.85390230e-05, 5.04768160e-13],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [4.17960100e-01, 5.82039800e-01, 1.29178620e-07],\n",
       "       [1.07246860e-06, 9.99998900e-01, 1.34168830e-08],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [5.00749300e-01, 4.99250680e-01, 1.82173240e-14],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.44286930e-01, 3.55713070e-01, 4.28992500e-10],\n",
       "       [1.38076260e-06, 9.99998570e-01, 0.00000000e+00],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [9.99881860e-01, 1.18122894e-04, 4.55971740e-13],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.17750100e-01, 8.22498700e-02, 5.38906140e-10],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [9.68921360e-01, 3.10777440e-02, 9.54774100e-07],\n",
       "       [5.00749300e-01, 4.99250680e-01, 1.82173240e-14],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [9.97770300e-01, 2.22965590e-03, 1.17126050e-15],\n",
       "       [3.09168150e-06, 9.99996900e-01, 3.47731530e-11],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [9.99951500e-01, 4.85390230e-05, 5.04768160e-13],\n",
       "       [6.45018170e-09, 1.00000000e+00, 3.14993420e-36],\n",
       "       [3.03811450e-10, 5.95940600e-08, 9.99999900e-01],\n",
       "       [5.00749300e-01, 4.99250680e-01, 1.82173240e-14],\n",
       "       [3.31562380e-09, 4.96007370e-09, 1.00000000e+00],\n",
       "       [5.21364800e-01, 4.78635160e-01, 1.48396750e-11],\n",
       "       [2.30924580e-01, 7.69075450e-01, 3.30027400e-11],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.73224100e-26, 1.00000000e+00, 0.00000000e+00],\n",
       "       [8.49479400e-08, 9.99999900e-01, 1.97443830e-27],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [2.40506400e-01, 7.59493600e-01, 1.23313160e-09],\n",
       "       [1.01026220e-04, 9.99898900e-01, 7.97193600e-12],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09],\n",
       "       [6.67784200e-01, 3.32215820e-01, 9.75227500e-09]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617357001972388"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617357001972388"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520118343195267"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012058510891320956"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520118343195267"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012058510891320956"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 85.77%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.02275415165566839\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 89.12%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.01007798\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 101\n",
      "selected features: 60\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  4,  5,  8,  9, 10, 12, 14, 19, 20, 22, 24, 25, 26, 28,\n",
       "        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49,\n",
       "        50, 51, 52, 53, 56, 57, 58, 61, 62, 63, 65, 66, 67, 68, 72, 73,\n",
       "        77, 78, 81, 82, 83, 85, 88, 89, 90, 94, 95, 96]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTAATACATAT', 'TTTATCTTTATGA', 'TTTAATTTAGTAAGT',\n",
       "       'TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA',\n",
       "       'TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA',\n",
       "       'TTCAAGAAGGAGA', 'TTATTATGAGAATTACAAAAGCTACATAAATTAC',\n",
       "       'TTATAAAAAGAAC',\n",
       "       'TTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTTT',\n",
       "       'TTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAG',\n",
       "       'TGTTCCTGTTTTTATA',\n",
       "       'TGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATTCG',\n",
       "       'TGGAGAAAGCAG', 'TGCTGCGGGTAG',\n",
       "       'TGCAAAGACTTTTTTAGGTAACGGTAAGTCTAATGCCATCAATAAAATAGGCCAAATAATTGAGTGGAATCGCACAATTTCCTTAGCCATTAAATGAATA',\n",
       "       'TGAAAACAAAGCT', 'TCTCCTTCTTGA',\n",
       "       'TCCTTAAAAATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTC',\n",
       "       'TCCGTTAGTGCC',\n",
       "       'TCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACAT',\n",
       "       'TATTTATGCAGT', 'TATTATGAGAATTACAAAAGCTACATAAATTAC',\n",
       "       'TATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGTAATCTTAATGCTTCAAAAGATTTTAATTTCTTA',\n",
       "       'TATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTTTTAAAT',\n",
       "       'TATACTCATATTAC',\n",
       "       'TACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTTTT',\n",
       "       'TACATATTCAATAT', 'TACAACGTCTT', 'TAAAAGGAGAGTT',\n",
       "       'TAAAAATGGTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCC',\n",
       "       'TAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAGT',\n",
       "       'GTGTCTTTATAC',\n",
       "       'GTGCAAAGACTTTTTTAGGTAACGGTAAGTCTAATGCCATCAATAAAATAGGCCAAATAATTGAGTGGAATCGCACAATTTCCTTAGCCATTAAATGAAT',\n",
       "       'GTATGCCTTTGTTTGTATAGTTTTCACTTCCACCTTTGGGAGTCTTTCCACTACCTATTTTGGTAGTAAGATTCCCTAACTTCTTCTCTTCCCATTCGCC',\n",
       "       'GTAAGTCCATTTT',\n",
       "       'GTAAGAAATTAAAATCTTTTGAAGCATTAAGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAAT',\n",
       "       'GGAATCTTACT', 'GCTGCGGGTAG', 'GCTAAAAGAAATT',\n",
       "       'GCAAAGACTTTTTTAGGTAACGGTAAGTCTAATGCCATCAATAAAATAGGCCAAATAATTGAGTGGAATCGCACAATTTCCTTAGCCATTAAATGAATAT',\n",
       "       'GATTGCTAATGG',\n",
       "       'GATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTT',\n",
       "       'GATCCGTTAGT', 'GATATTTATGCAGT',\n",
       "       'GATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTG',\n",
       "       'GAATGGGAAGAGAAGAAGTTAGGGAATCTTACTACCAAAATAGGTAGTGGAAAGACTCCCAAAGGTGGAAGTGAAAACTATACAAACAAAGGCATACCAT',\n",
       "       'GAAGAAGTTAGGGAATCTTACTACCAAAATAGGTAGTGGAAAGACTCCCAAAGGTGGAAGTGAAAACTATACAAACAAAGGCATACCATTTTTAAGGAGT',\n",
       "       'GAAAAATAGTAAT', 'CTGGATCCG', 'CTGGATCCGTT',\n",
       "       'CCATGTGCAAAGACTTTTTTAGGTAACGGTAAGTCTAATGCCATCAATAAAATAGGCCAAATAATTGAGTGGAATCGCACAATTTCCTTAGCCATTAAAT',\n",
       "       'CCAGAGAAATGT',\n",
       "       'CATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACATG',\n",
       "       'ATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTT',\n",
       "       'ATCCCATAGTGTGATAATTACTAT', 'ATATTTTAATAATTATT', 'ATATTTATGCAGT',\n",
       "       'AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT',\n",
       "       'AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT',\n",
       "       'ACTTTCGAATT'], dtype='<U100')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTAATACATAT</th>\n",
       "      <th>TTTATCTTTATGA</th>\n",
       "      <th>TTTAATTTAGTAAGT</th>\n",
       "      <th>TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA</th>\n",
       "      <th>TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA</th>\n",
       "      <th>TTCAAGAAGGAGA</th>\n",
       "      <th>TTATTATGAGAATTACAAAAGCTACATAAATTAC</th>\n",
       "      <th>TTATAAAAAGAAC</th>\n",
       "      <th>TTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTTT</th>\n",
       "      <th>TTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAG</th>\n",
       "      <th>...</th>\n",
       "      <th>CATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACATG</th>\n",
       "      <th>ATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTT</th>\n",
       "      <th>ATCCCATAGTGTGATAATTACTAT</th>\n",
       "      <th>ATATTTTAATAATTATT</th>\n",
       "      <th>ATATTTATGCAGT</th>\n",
       "      <th>AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT</th>\n",
       "      <th>AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT</th>\n",
       "      <th>ACTTTCGAATT</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTAATACATAT  TTTATCTTTATGA  TTTAATTTAGTAAGT  \\\n",
       "0                0              0                0   \n",
       "1                0              0                0   \n",
       "2                1              0                1   \n",
       "3                0              0                0   \n",
       "4                0              0                0   \n",
       "..             ...            ...              ...   \n",
       "248              0              0                0   \n",
       "249              0              0                0   \n",
       "250              0              0                0   \n",
       "251              0              0                0   \n",
       "252              0              0                0   \n",
       "\n",
       "     TTTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTCAAGAAGGAGA  TTATTATGAGAATTACAAAAGCTACATAAATTAC  TTATAAAAAGAAC  \\\n",
       "0                0                                   1              1   \n",
       "1                0                                   1              1   \n",
       "2                0                                   1              1   \n",
       "3                0                                   1              1   \n",
       "4                0                                   1              1   \n",
       "..             ...                                 ...            ...   \n",
       "248              0                                   1              1   \n",
       "249              0                                   1              1   \n",
       "250              0                                   1              1   \n",
       "251              0                                   1              1   \n",
       "252              0                                   1              1   \n",
       "\n",
       "     TTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTAAAAAGATGAATAATGTAAATGAAGTAAAGGTTATTATGAGAATTACAAAAGCTACATAAATTACTGTTAGTTTAAATTGAAATTTAAAAATGATAAG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     ...  \\\n",
       "0    ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "..   ...   \n",
       "248  ...   \n",
       "249  ...   \n",
       "250  ...   \n",
       "251  ...   \n",
       "252  ...   \n",
       "\n",
       "     CATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTTGCACATG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     ATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCTTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     ATCCCATAGTGTGATAATTACTAT  ATATTTTAATAATTATT  ATATTTATGCAGT  \\\n",
       "0                           1                  0              1   \n",
       "1                           1                  0              1   \n",
       "2                           1                  1              1   \n",
       "3                           1                  0              1   \n",
       "4                           1                  0              1   \n",
       "..                        ...                ...            ...   \n",
       "248                         1                  0              1   \n",
       "249                         1                  0              1   \n",
       "250                         1                  0              1   \n",
       "251                         1                  0              1   \n",
       "252                         1                  0              1   \n",
       "\n",
       "     AGATTACTTATCATTTTTAAATTTCAATTTAAACTAACAGTAATTTATGTAGCTTTTGTAATTCTCATAATAACCTTTACTTCATTTACATTATTCATCT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AGATATTCATTTAATGGCTAAGGAAATTGTGCGATTCCACTCAATTATTTGGCCTATTTTATTGATGGCATTAGACTTACCGTTACCTAAAAAAGTCTTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     ACTTTCGAATT  pheno  strain  \n",
       "0              0      0     107  \n",
       "1              0      0     109  \n",
       "2              1      1     115  \n",
       "3              0      0  120335  \n",
       "4              0      0  120337  \n",
       "..           ...    ...     ...  \n",
       "248            0      1  SR4152  \n",
       "249            0      0  SR4153  \n",
       "250            0      0  SR4155  \n",
       "251            0      0  SR4156  \n",
       "252            0      0  SR4187  \n",
       "\n",
       "[253 rows x 62 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 61) (253,) (253, 62)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    216\n",
       "1     35\n",
       "2      2\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 216), (1, 216), (2, 216)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0          312     1\n",
       "1    BCH-SA-12     0\n",
       "2       NRS209     2\n",
       "3     CFBRSa29     0\n",
       "4       NRS209     2\n",
       "..         ...   ...\n",
       "190      CA541     1\n",
       "191     SR4152     1\n",
       "192     NRS110     2\n",
       "193   CFBRSa70     0\n",
       "194     NRS021     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 465us/step - loss: 1.0143 - accuracy: 0.5254 - val_loss: 0.8433 - val_accuracy: 0.7026\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.7200 - accuracy: 0.7572 - val_loss: 0.6478 - val_accuracy: 0.7538\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.5477 - accuracy: 0.8013 - val_loss: 0.5202 - val_accuracy: 0.7744\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.4523 - accuracy: 0.8146 - val_loss: 0.4757 - val_accuracy: 0.7641\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.4057 - accuracy: 0.8168 - val_loss: 0.4419 - val_accuracy: 0.7795\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.3853 - accuracy: 0.8322 - val_loss: 0.4412 - val_accuracy: 0.7744\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.3702 - accuracy: 0.8322 - val_loss: 0.4153 - val_accuracy: 0.7795\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.3604 - accuracy: 0.8322 - val_loss: 0.4094 - val_accuracy: 0.7795\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.3549 - accuracy: 0.8389 - val_loss: 0.4366 - val_accuracy: 0.7846\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.3518 - accuracy: 0.8411 - val_loss: 0.4162 - val_accuracy: 0.7949\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.3375 - accuracy: 0.8477 - val_loss: 0.3965 - val_accuracy: 0.7795\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.3334 - accuracy: 0.8344 - val_loss: 0.4189 - val_accuracy: 0.7949\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.3301 - accuracy: 0.8609 - val_loss: 0.3916 - val_accuracy: 0.7795\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.3243 - accuracy: 0.8543 - val_loss: 0.4360 - val_accuracy: 0.7846\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.3317 - accuracy: 0.8455 - val_loss: 0.3943 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.3178 - accuracy: 0.8521 - val_loss: 0.3851 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.3149 - accuracy: 0.8499 - val_loss: 0.3827 - val_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.3180 - accuracy: 0.8389 - val_loss: 0.3884 - val_accuracy: 0.8103\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3135 - accuracy: 0.8609 - val_loss: 0.4150 - val_accuracy: 0.8051\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.3122 - accuracy: 0.8543 - val_loss: 0.3790 - val_accuracy: 0.8000\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.3048 - accuracy: 0.8587 - val_loss: 0.3772 - val_accuracy: 0.8051\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.3036 - accuracy: 0.8543 - val_loss: 0.4136 - val_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 407us/step - loss: 0.3117 - accuracy: 0.8499 - val_loss: 0.4066 - val_accuracy: 0.8000\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2976 - accuracy: 0.8433 - val_loss: 0.3706 - val_accuracy: 0.8051\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2961 - accuracy: 0.8477 - val_loss: 0.3757 - val_accuracy: 0.8103\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2927 - accuracy: 0.8631 - val_loss: 0.3722 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2903 - accuracy: 0.8653 - val_loss: 0.3697 - val_accuracy: 0.8103\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2880 - accuracy: 0.8565 - val_loss: 0.3678 - val_accuracy: 0.8205\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2883 - accuracy: 0.8543 - val_loss: 0.3637 - val_accuracy: 0.8154\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2832 - accuracy: 0.8631 - val_loss: 0.3718 - val_accuracy: 0.8103\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2856 - accuracy: 0.8609 - val_loss: 0.3633 - val_accuracy: 0.8154\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2805 - accuracy: 0.8609 - val_loss: 0.3607 - val_accuracy: 0.8256\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2790 - accuracy: 0.8587 - val_loss: 0.3808 - val_accuracy: 0.8154\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2777 - accuracy: 0.8653 - val_loss: 0.3600 - val_accuracy: 0.8205\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 291us/step - loss: 0.2778 - accuracy: 0.8631 - val_loss: 0.3559 - val_accuracy: 0.8205\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2815 - accuracy: 0.8521 - val_loss: 0.3561 - val_accuracy: 0.8256\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2708 - accuracy: 0.8675 - val_loss: 0.3605 - val_accuracy: 0.8205\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2735 - accuracy: 0.8565 - val_loss: 0.3592 - val_accuracy: 0.8205\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2695 - accuracy: 0.8675 - val_loss: 0.3553 - val_accuracy: 0.8205\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2857 - accuracy: 0.8631 - val_loss: 0.3507 - val_accuracy: 0.8205\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2702 - accuracy: 0.8653 - val_loss: 0.3500 - val_accuracy: 0.8205\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.2662 - accuracy: 0.8675 - val_loss: 0.3545 - val_accuracy: 0.8205\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2604 - accuracy: 0.8742 - val_loss: 0.3510 - val_accuracy: 0.8103\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2651 - accuracy: 0.8675 - val_loss: 0.3491 - val_accuracy: 0.8205\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2596 - accuracy: 0.8675 - val_loss: 0.3547 - val_accuracy: 0.8205\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2665 - accuracy: 0.8698 - val_loss: 0.3597 - val_accuracy: 0.8103\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2589 - accuracy: 0.8764 - val_loss: 0.3469 - val_accuracy: 0.8154\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2592 - accuracy: 0.8742 - val_loss: 0.3548 - val_accuracy: 0.8103\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2545 - accuracy: 0.8675 - val_loss: 0.3472 - val_accuracy: 0.8359\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2580 - accuracy: 0.8631 - val_loss: 0.3472 - val_accuracy: 0.8103\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2543 - accuracy: 0.8742 - val_loss: 0.3519 - val_accuracy: 0.8103\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2512 - accuracy: 0.8808 - val_loss: 0.3472 - val_accuracy: 0.8154\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2560 - accuracy: 0.8720 - val_loss: 0.3571 - val_accuracy: 0.8205\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2542 - accuracy: 0.8764 - val_loss: 0.3453 - val_accuracy: 0.8359\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2524 - accuracy: 0.8698 - val_loss: 0.3440 - val_accuracy: 0.8103\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2641 - accuracy: 0.8742 - val_loss: 0.3494 - val_accuracy: 0.8103\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2572 - accuracy: 0.8874 - val_loss: 0.3411 - val_accuracy: 0.8359\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2564 - accuracy: 0.8874 - val_loss: 0.3545 - val_accuracy: 0.8051\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2511 - accuracy: 0.8786 - val_loss: 0.3596 - val_accuracy: 0.8154\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2463 - accuracy: 0.8896 - val_loss: 0.3415 - val_accuracy: 0.8359\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2524 - accuracy: 0.8852 - val_loss: 0.3354 - val_accuracy: 0.8462\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2455 - accuracy: 0.8742 - val_loss: 0.3403 - val_accuracy: 0.8359\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2551 - accuracy: 0.8786 - val_loss: 0.3491 - val_accuracy: 0.8359\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2604 - accuracy: 0.8808 - val_loss: 0.3381 - val_accuracy: 0.8359\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2464 - accuracy: 0.8962 - val_loss: 0.3430 - val_accuracy: 0.8359\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2428 - accuracy: 0.8830 - val_loss: 0.3444 - val_accuracy: 0.8154\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2444 - accuracy: 0.8940 - val_loss: 0.3967 - val_accuracy: 0.8205\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2641 - accuracy: 0.8808 - val_loss: 0.3488 - val_accuracy: 0.8103\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2439 - accuracy: 0.8874 - val_loss: 0.3440 - val_accuracy: 0.8359\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2411 - accuracy: 0.8896 - val_loss: 0.3488 - val_accuracy: 0.8154\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2435 - accuracy: 0.8852 - val_loss: 0.3403 - val_accuracy: 0.8359\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2399 - accuracy: 0.8830 - val_loss: 0.3388 - val_accuracy: 0.8410\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2454 - accuracy: 0.8830 - val_loss: 0.3423 - val_accuracy: 0.8359\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2435 - accuracy: 0.8830 - val_loss: 0.3501 - val_accuracy: 0.8154\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2393 - accuracy: 0.8874 - val_loss: 0.3433 - val_accuracy: 0.8410\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2376 - accuracy: 0.8918 - val_loss: 0.3410 - val_accuracy: 0.8359\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.3402 - val_accuracy: 0.8410\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2373 - accuracy: 0.8720 - val_loss: 0.3440 - val_accuracy: 0.8410\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2367 - accuracy: 0.8962 - val_loss: 0.3497 - val_accuracy: 0.8359\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2434 - accuracy: 0.8830 - val_loss: 0.3330 - val_accuracy: 0.8359\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2374 - accuracy: 0.8896 - val_loss: 0.3436 - val_accuracy: 0.8359\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 0.3406 - val_accuracy: 0.8359\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2325 - accuracy: 0.8940 - val_loss: 0.3371 - val_accuracy: 0.8410\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 0.3551 - val_accuracy: 0.8205\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2434 - accuracy: 0.8918 - val_loss: 0.3385 - val_accuracy: 0.8410\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2380 - accuracy: 0.8874 - val_loss: 0.3420 - val_accuracy: 0.8410\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2386 - accuracy: 0.8896 - val_loss: 0.3449 - val_accuracy: 0.8359\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 0.3440 - val_accuracy: 0.8410\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2343 - accuracy: 0.8896 - val_loss: 0.3659 - val_accuracy: 0.8103\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2372 - accuracy: 0.8896 - val_loss: 0.3506 - val_accuracy: 0.8154\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2339 - accuracy: 0.9029 - val_loss: 0.3527 - val_accuracy: 0.8359\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.3367 - val_accuracy: 0.8410\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2350 - accuracy: 0.8940 - val_loss: 0.3401 - val_accuracy: 0.8410\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2414 - accuracy: 0.8918 - val_loss: 0.3441 - val_accuracy: 0.8410\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2356 - accuracy: 0.8940 - val_loss: 0.3363 - val_accuracy: 0.8410\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2327 - accuracy: 0.8962 - val_loss: 0.3427 - val_accuracy: 0.8410\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2300 - accuracy: 0.8985 - val_loss: 0.3445 - val_accuracy: 0.8410\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2378 - accuracy: 0.8874 - val_loss: 0.3441 - val_accuracy: 0.8410\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.3430 - val_accuracy: 0.8308\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2364 - accuracy: 0.8918 - val_loss: 0.3431 - val_accuracy: 0.8410\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2344 - accuracy: 0.9007 - val_loss: 0.3428 - val_accuracy: 0.8410\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2356 - accuracy: 0.8918 - val_loss: 0.3368 - val_accuracy: 0.8410\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2263 - accuracy: 0.9007 - val_loss: 0.3564 - val_accuracy: 0.8410\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2330 - accuracy: 0.8896 - val_loss: 0.3458 - val_accuracy: 0.8410\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2533 - accuracy: 0.8742 - val_loss: 0.3550 - val_accuracy: 0.8359\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2341 - accuracy: 0.8874 - val_loss: 0.3503 - val_accuracy: 0.8410\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2322 - accuracy: 0.8962 - val_loss: 0.3475 - val_accuracy: 0.8359\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.2328 - accuracy: 0.8918 - val_loss: 0.3521 - val_accuracy: 0.8410\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2286 - accuracy: 0.8918 - val_loss: 0.3614 - val_accuracy: 0.8308\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2365 - accuracy: 0.8874 - val_loss: 0.3446 - val_accuracy: 0.8410\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2255 - accuracy: 0.9051 - val_loss: 0.3453 - val_accuracy: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2320 - accuracy: 0.8896 - val_loss: 0.3439 - val_accuracy: 0.8410\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2332 - accuracy: 0.8962 - val_loss: 0.3485 - val_accuracy: 0.8359\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2255 - accuracy: 0.8940 - val_loss: 0.3731 - val_accuracy: 0.8205\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2459 - accuracy: 0.8896 - val_loss: 0.3434 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2297 - accuracy: 0.9007 - val_loss: 0.3432 - val_accuracy: 0.8462\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2302 - accuracy: 0.9007 - val_loss: 0.3287 - val_accuracy: 0.8410\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2288 - accuracy: 0.8962 - val_loss: 0.3361 - val_accuracy: 0.8410\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2360 - accuracy: 0.9007 - val_loss: 0.3355 - val_accuracy: 0.8410\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.3437 - val_accuracy: 0.8359\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.3399 - val_accuracy: 0.8410\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2277 - accuracy: 0.9007 - val_loss: 0.3334 - val_accuracy: 0.8410\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2246 - accuracy: 0.9029 - val_loss: 0.3416 - val_accuracy: 0.8410\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2303 - accuracy: 0.8962 - val_loss: 0.3373 - val_accuracy: 0.8410\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2252 - accuracy: 0.8940 - val_loss: 0.3404 - val_accuracy: 0.8410\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2320 - accuracy: 0.8896 - val_loss: 0.3426 - val_accuracy: 0.8359\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.3361 - val_accuracy: 0.8410\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2243 - accuracy: 0.9007 - val_loss: 0.3400 - val_accuracy: 0.8410\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2224 - accuracy: 0.9007 - val_loss: 0.3395 - val_accuracy: 0.8410\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2284 - accuracy: 0.8962 - val_loss: 0.3867 - val_accuracy: 0.8410\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2321 - accuracy: 0.8962 - val_loss: 0.3509 - val_accuracy: 0.8410\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2265 - accuracy: 0.9007 - val_loss: 0.3443 - val_accuracy: 0.8410\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2273 - accuracy: 0.8962 - val_loss: 0.3399 - val_accuracy: 0.8410\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2220 - accuracy: 0.9029 - val_loss: 0.3404 - val_accuracy: 0.8410\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2270 - accuracy: 0.8962 - val_loss: 0.3529 - val_accuracy: 0.8410\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2273 - accuracy: 0.8962 - val_loss: 0.3385 - val_accuracy: 0.8410\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2233 - accuracy: 0.9007 - val_loss: 0.3540 - val_accuracy: 0.8410\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2302 - accuracy: 0.8896 - val_loss: 0.3476 - val_accuracy: 0.8410\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.8918 - val_loss: 0.3376 - val_accuracy: 0.8410\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2257 - accuracy: 0.8940 - val_loss: 0.3433 - val_accuracy: 0.8410\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2241 - accuracy: 0.8985 - val_loss: 0.3460 - val_accuracy: 0.8410\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2320 - accuracy: 0.8962 - val_loss: 0.3565 - val_accuracy: 0.8359\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2361 - accuracy: 0.8940 - val_loss: 0.3411 - val_accuracy: 0.8410\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2238 - accuracy: 0.9007 - val_loss: 0.3547 - val_accuracy: 0.8462\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2240 - accuracy: 0.9007 - val_loss: 0.3463 - val_accuracy: 0.8410\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2258 - accuracy: 0.8985 - val_loss: 0.3506 - val_accuracy: 0.8410\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2274 - accuracy: 0.9007 - val_loss: 0.3415 - val_accuracy: 0.8410\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2247 - accuracy: 0.9007 - val_loss: 0.3391 - val_accuracy: 0.8410\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2225 - accuracy: 0.8874 - val_loss: 0.3673 - val_accuracy: 0.8308\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.3545 - val_accuracy: 0.8410\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2329 - accuracy: 0.8896 - val_loss: 0.3442 - val_accuracy: 0.8410\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2257 - accuracy: 0.8918 - val_loss: 0.3527 - val_accuracy: 0.8410\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2257 - accuracy: 0.9007 - val_loss: 0.3528 - val_accuracy: 0.8410\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2205 - accuracy: 0.9007 - val_loss: 0.3449 - val_accuracy: 0.8410\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2241 - accuracy: 0.9007 - val_loss: 0.3595 - val_accuracy: 0.8410\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2342 - accuracy: 0.8962 - val_loss: 0.3549 - val_accuracy: 0.8410\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2305 - accuracy: 0.8918 - val_loss: 0.3508 - val_accuracy: 0.8410\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2366 - accuracy: 0.9007 - val_loss: 0.3678 - val_accuracy: 0.8410\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2262 - accuracy: 0.9007 - val_loss: 0.3469 - val_accuracy: 0.8359\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2244 - accuracy: 0.8985 - val_loss: 0.3529 - val_accuracy: 0.8410\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2266 - accuracy: 0.8962 - val_loss: 0.3578 - val_accuracy: 0.8462\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2234 - accuracy: 0.9007 - val_loss: 0.3539 - val_accuracy: 0.8410\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2257 - accuracy: 0.9007 - val_loss: 0.3586 - val_accuracy: 0.8410\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2210 - accuracy: 0.9007 - val_loss: 0.3415 - val_accuracy: 0.8410\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2201 - accuracy: 0.9007 - val_loss: 0.3479 - val_accuracy: 0.8410\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2217 - accuracy: 0.9029 - val_loss: 0.3483 - val_accuracy: 0.8410\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2237 - accuracy: 0.9007 - val_loss: 0.3491 - val_accuracy: 0.8410\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2207 - accuracy: 0.9007 - val_loss: 0.3417 - val_accuracy: 0.8410\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2203 - accuracy: 0.9007 - val_loss: 0.3568 - val_accuracy: 0.8410\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2216 - accuracy: 0.9007 - val_loss: 0.3498 - val_accuracy: 0.8410\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2239 - accuracy: 0.9007 - val_loss: 0.3457 - val_accuracy: 0.8410\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2267 - accuracy: 0.9007 - val_loss: 0.3499 - val_accuracy: 0.8410\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 398us/step - loss: 0.2225 - accuracy: 0.9007 - val_loss: 0.3500 - val_accuracy: 0.8410\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2241 - accuracy: 0.8985 - val_loss: 0.3704 - val_accuracy: 0.8410\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.3558 - val_accuracy: 0.8410\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2261 - accuracy: 0.8962 - val_loss: 0.3547 - val_accuracy: 0.8410\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2254 - accuracy: 0.9007 - val_loss: 0.3584 - val_accuracy: 0.8410\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2256 - accuracy: 0.9007 - val_loss: 0.3546 - val_accuracy: 0.8410\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2197 - accuracy: 0.9007 - val_loss: 0.3539 - val_accuracy: 0.8410\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2242 - accuracy: 0.8962 - val_loss: 0.3512 - val_accuracy: 0.8410\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2248 - accuracy: 0.8918 - val_loss: 0.3507 - val_accuracy: 0.8410\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.92 - 0s 258us/step - loss: 0.2243 - accuracy: 0.9007 - val_loss: 0.3570 - val_accuracy: 0.8410\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2237 - accuracy: 0.8940 - val_loss: 0.3601 - val_accuracy: 0.8410\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2218 - accuracy: 0.9029 - val_loss: 0.3609 - val_accuracy: 0.8410\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2211 - accuracy: 0.9029 - val_loss: 0.3532 - val_accuracy: 0.8410\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2190 - accuracy: 0.9007 - val_loss: 0.3647 - val_accuracy: 0.8410\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2208 - accuracy: 0.9007 - val_loss: 0.3625 - val_accuracy: 0.8410\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2202 - accuracy: 0.9007 - val_loss: 0.3591 - val_accuracy: 0.8410\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2219 - accuracy: 0.8962 - val_loss: 0.3566 - val_accuracy: 0.8410\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2223 - accuracy: 0.8918 - val_loss: 0.3577 - val_accuracy: 0.8410\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2225 - accuracy: 0.9007 - val_loss: 0.3720 - val_accuracy: 0.8410\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2164 - accuracy: 0.9007 - val_loss: 0.3576 - val_accuracy: 0.8410\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.3606 - val_accuracy: 0.8513\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2224 - accuracy: 0.9029 - val_loss: 0.3579 - val_accuracy: 0.8410\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2246 - accuracy: 0.9007 - val_loss: 0.3602 - val_accuracy: 0.8410\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2223 - accuracy: 0.9007 - val_loss: 0.3535 - val_accuracy: 0.8410\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2186 - accuracy: 0.9007 - val_loss: 0.3558 - val_accuracy: 0.8410\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2235 - accuracy: 0.8962 - val_loss: 0.3565 - val_accuracy: 0.8410\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2191 - accuracy: 0.9007 - val_loss: 0.3573 - val_accuracy: 0.8410\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2216 - accuracy: 0.9007 - val_loss: 0.3559 - val_accuracy: 0.8410\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2210 - accuracy: 0.9007 - val_loss: 0.3575 - val_accuracy: 0.8410\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2306 - accuracy: 0.8896 - val_loss: 0.3584 - val_accuracy: 0.8410\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2212 - accuracy: 0.9007 - val_loss: 0.3534 - val_accuracy: 0.8410\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2208 - accuracy: 0.8985 - val_loss: 0.3638 - val_accuracy: 0.8410\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2259 - accuracy: 0.8808 - val_loss: 0.3732 - val_accuracy: 0.8410\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2225 - accuracy: 0.9007 - val_loss: 0.3544 - val_accuracy: 0.8410\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2267 - accuracy: 0.9029 - val_loss: 0.3616 - val_accuracy: 0.8410\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2196 - accuracy: 0.8985 - val_loss: 0.3578 - val_accuracy: 0.8410\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2246 - accuracy: 0.9007 - val_loss: 0.3501 - val_accuracy: 0.8410\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2295 - accuracy: 0.8985 - val_loss: 0.3727 - val_accuracy: 0.8359\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2339 - accuracy: 0.8940 - val_loss: 0.3608 - val_accuracy: 0.8410\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2180 - accuracy: 0.9007 - val_loss: 0.3604 - val_accuracy: 0.8410\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2208 - accuracy: 0.9007 - val_loss: 0.3612 - val_accuracy: 0.8410\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2216 - accuracy: 0.9007 - val_loss: 0.3617 - val_accuracy: 0.8410\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2184 - accuracy: 0.9007 - val_loss: 0.3575 - val_accuracy: 0.8410\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.3653 - val_accuracy: 0.8410\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2189 - accuracy: 0.9007 - val_loss: 0.3706 - val_accuracy: 0.8410\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2259 - accuracy: 0.8940 - val_loss: 0.3626 - val_accuracy: 0.8410\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2216 - accuracy: 0.9029 - val_loss: 0.3666 - val_accuracy: 0.8410\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2193 - accuracy: 0.9007 - val_loss: 0.3538 - val_accuracy: 0.8410\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2183 - accuracy: 0.9029 - val_loss: 0.3626 - val_accuracy: 0.8410\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 126us/step - loss: 0.2181 - accuracy: 0.9029 - val_loss: 0.3637 - val_accuracy: 0.8410\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2209 - accuracy: 0.9007 - val_loss: 0.3592 - val_accuracy: 0.8410\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2168 - accuracy: 0.8962 - val_loss: 0.3649 - val_accuracy: 0.8513\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2186 - accuracy: 0.8985 - val_loss: 0.3584 - val_accuracy: 0.8410\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2174 - accuracy: 0.9007 - val_loss: 0.3645 - val_accuracy: 0.8410\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 385us/step - loss: 0.2172 - accuracy: 0.9007 - val_loss: 0.3653 - val_accuracy: 0.8410\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 349us/step - loss: 0.2201 - accuracy: 0.9007 - val_loss: 0.3606 - val_accuracy: 0.8410\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2277 - accuracy: 0.8896 - val_loss: 0.3748 - val_accuracy: 0.8410\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2208 - accuracy: 0.9007 - val_loss: 0.3729 - val_accuracy: 0.8410\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2248 - accuracy: 0.8874 - val_loss: 0.3697 - val_accuracy: 0.8359\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.3626 - val_accuracy: 0.8410\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2226 - accuracy: 0.9007 - val_loss: 0.3756 - val_accuracy: 0.8410\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2175 - accuracy: 0.9029 - val_loss: 0.3686 - val_accuracy: 0.8410\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2230 - accuracy: 0.8985 - val_loss: 0.3657 - val_accuracy: 0.8410\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2222 - accuracy: 0.9029 - val_loss: 0.3668 - val_accuracy: 0.8410\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2272 - accuracy: 0.8918 - val_loss: 0.3894 - val_accuracy: 0.8359\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2176 - accuracy: 0.8985 - val_loss: 0.3668 - val_accuracy: 0.8410\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2249 - accuracy: 0.8962 - val_loss: 0.3601 - val_accuracy: 0.8410\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2203 - accuracy: 0.8962 - val_loss: 0.3661 - val_accuracy: 0.8410\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2212 - accuracy: 0.9029 - val_loss: 0.3651 - val_accuracy: 0.8410\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2230 - accuracy: 0.9007 - val_loss: 0.3792 - val_accuracy: 0.8410\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2207 - accuracy: 0.9029 - val_loss: 0.3668 - val_accuracy: 0.8410\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2161 - accuracy: 0.9029 - val_loss: 0.3641 - val_accuracy: 0.8410\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2178 - accuracy: 0.9007 - val_loss: 0.3647 - val_accuracy: 0.8410\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2188 - accuracy: 0.9029 - val_loss: 0.3649 - val_accuracy: 0.8410\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2164 - accuracy: 0.8985 - val_loss: 0.3692 - val_accuracy: 0.8462\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2230 - accuracy: 0.8896 - val_loss: 0.3689 - val_accuracy: 0.8410\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2202 - accuracy: 0.9007 - val_loss: 0.3745 - val_accuracy: 0.8410\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2229 - accuracy: 0.9007 - val_loss: 0.3621 - val_accuracy: 0.8410\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2198 - accuracy: 0.8918 - val_loss: 0.3728 - val_accuracy: 0.8410\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2182 - accuracy: 0.9029 - val_loss: 0.3637 - val_accuracy: 0.8410\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2200 - accuracy: 0.9007 - val_loss: 0.3728 - val_accuracy: 0.8410\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2186 - accuracy: 0.9029 - val_loss: 0.3665 - val_accuracy: 0.8410\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2200 - accuracy: 0.9007 - val_loss: 0.3725 - val_accuracy: 0.8410\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2222 - accuracy: 0.8962 - val_loss: 0.3638 - val_accuracy: 0.8513\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2185 - accuracy: 0.9029 - val_loss: 0.3622 - val_accuracy: 0.8410\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2204 - accuracy: 0.9029 - val_loss: 0.3603 - val_accuracy: 0.8410\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2174 - accuracy: 0.9029 - val_loss: 0.3725 - val_accuracy: 0.8410\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2191 - accuracy: 0.9029 - val_loss: 0.3687 - val_accuracy: 0.8410\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2180 - accuracy: 0.9029 - val_loss: 0.3716 - val_accuracy: 0.8410\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2226 - accuracy: 0.9007 - val_loss: 0.3728 - val_accuracy: 0.8410\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2158 - accuracy: 0.9029 - val_loss: 0.3670 - val_accuracy: 0.8410\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2190 - accuracy: 0.9029 - val_loss: 0.3701 - val_accuracy: 0.8410\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2206 - accuracy: 0.9029 - val_loss: 0.3700 - val_accuracy: 0.8410\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2172 - accuracy: 0.9029 - val_loss: 0.3793 - val_accuracy: 0.8410\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2183 - accuracy: 0.9029 - val_loss: 0.3671 - val_accuracy: 0.8410\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3675 - val_accuracy: 0.8410\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2185 - accuracy: 0.9029 - val_loss: 0.3700 - val_accuracy: 0.8410\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3733 - val_accuracy: 0.8410\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2235 - accuracy: 0.8962 - val_loss: 0.3870 - val_accuracy: 0.8410\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.3716 - val_accuracy: 0.8410\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2222 - accuracy: 0.9007 - val_loss: 0.3694 - val_accuracy: 0.8410\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2186 - accuracy: 0.9029 - val_loss: 0.3796 - val_accuracy: 0.8410\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2280 - accuracy: 0.8985 - val_loss: 0.3695 - val_accuracy: 0.8410\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2192 - accuracy: 0.8962 - val_loss: 0.3762 - val_accuracy: 0.8410\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.3696 - val_accuracy: 0.8410\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2143 - accuracy: 0.9029 - val_loss: 0.3732 - val_accuracy: 0.8410\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2210 - accuracy: 0.9029 - val_loss: 0.3759 - val_accuracy: 0.8410\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.3734 - val_accuracy: 0.8410\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.3708 - val_accuracy: 0.8410\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2174 - accuracy: 0.9029 - val_loss: 0.3739 - val_accuracy: 0.8410\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2166 - accuracy: 0.9029 - val_loss: 0.3683 - val_accuracy: 0.8513\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.3719 - val_accuracy: 0.8410\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2203 - accuracy: 0.8962 - val_loss: 0.3723 - val_accuracy: 0.8410\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2178 - accuracy: 0.9029 - val_loss: 0.3735 - val_accuracy: 0.8410\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2154 - accuracy: 0.9029 - val_loss: 0.3639 - val_accuracy: 0.8410\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2178 - accuracy: 0.9007 - val_loss: 0.3721 - val_accuracy: 0.8410\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2181 - accuracy: 0.9007 - val_loss: 0.3683 - val_accuracy: 0.8410\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.3756 - val_accuracy: 0.8410\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2228 - accuracy: 0.8918 - val_loss: 0.3825 - val_accuracy: 0.8256\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2179 - accuracy: 0.9007 - val_loss: 0.3778 - val_accuracy: 0.8410\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2164 - accuracy: 0.9007 - val_loss: 0.3812 - val_accuracy: 0.8410\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2205 - accuracy: 0.8962 - val_loss: 0.3797 - val_accuracy: 0.8410\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2168 - accuracy: 0.9029 - val_loss: 0.3652 - val_accuracy: 0.8410\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2210 - accuracy: 0.8985 - val_loss: 0.3799 - val_accuracy: 0.8410\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.3790 - val_accuracy: 0.8410\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2208 - accuracy: 0.8985 - val_loss: 0.3762 - val_accuracy: 0.8410\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2184 - accuracy: 0.8962 - val_loss: 0.3720 - val_accuracy: 0.8410\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2248 - accuracy: 0.8940 - val_loss: 0.3812 - val_accuracy: 0.8410\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2153 - accuracy: 0.9029 - val_loss: 0.3922 - val_accuracy: 0.8410\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2164 - accuracy: 0.9029 - val_loss: 0.3858 - val_accuracy: 0.8410\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.3764 - val_accuracy: 0.8410\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2165 - accuracy: 0.9007 - val_loss: 0.3768 - val_accuracy: 0.8410\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2201 - accuracy: 0.8962 - val_loss: 0.3740 - val_accuracy: 0.8410\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2165 - accuracy: 0.9029 - val_loss: 0.3756 - val_accuracy: 0.8410\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.3726 - val_accuracy: 0.8410\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.3809 - val_accuracy: 0.8410\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2163 - accuracy: 0.9029 - val_loss: 0.3767 - val_accuracy: 0.8410\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2190 - accuracy: 0.8985 - val_loss: 0.3794 - val_accuracy: 0.8410\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2186 - accuracy: 0.9029 - val_loss: 0.3933 - val_accuracy: 0.8410\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3756 - val_accuracy: 0.8410\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2185 - accuracy: 0.9029 - val_loss: 0.3708 - val_accuracy: 0.8410\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.3798 - val_accuracy: 0.8410\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2188 - accuracy: 0.9029 - val_loss: 0.3903 - val_accuracy: 0.8410\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2186 - accuracy: 0.9029 - val_loss: 0.3867 - val_accuracy: 0.8410\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2155 - accuracy: 0.8985 - val_loss: 0.3765 - val_accuracy: 0.8410\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2191 - accuracy: 0.8985 - val_loss: 0.3802 - val_accuracy: 0.8410\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.3928 - val_accuracy: 0.8410\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2187 - accuracy: 0.9029 - val_loss: 0.3806 - val_accuracy: 0.8410\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.3761 - val_accuracy: 0.8410\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3810 - val_accuracy: 0.8410\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2163 - accuracy: 0.9029 - val_loss: 0.3846 - val_accuracy: 0.8410\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2168 - accuracy: 0.8896 - val_loss: 0.3843 - val_accuracy: 0.8410\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2179 - accuracy: 0.8985 - val_loss: 0.3723 - val_accuracy: 0.8410\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2164 - accuracy: 0.8985 - val_loss: 0.3819 - val_accuracy: 0.8410\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.3848 - val_accuracy: 0.8410\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.3874 - val_accuracy: 0.8410\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3813 - val_accuracy: 0.8410\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2171 - accuracy: 0.9029 - val_loss: 0.3797 - val_accuracy: 0.8410\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.3858 - val_accuracy: 0.8410\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 156us/step - loss: 0.2202 - accuracy: 0.8985 - val_loss: 0.3960 - val_accuracy: 0.8410\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2235 - accuracy: 0.9051 - val_loss: 0.3909 - val_accuracy: 0.8410\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.3821 - val_accuracy: 0.8410\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2147 - accuracy: 0.9007 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2168 - accuracy: 0.9029 - val_loss: 0.3872 - val_accuracy: 0.8410\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2201 - accuracy: 0.9029 - val_loss: 0.3905 - val_accuracy: 0.8410\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2215 - accuracy: 0.9029 - val_loss: 0.3796 - val_accuracy: 0.8410\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2232 - accuracy: 0.8962 - val_loss: 0.3895 - val_accuracy: 0.8410\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2175 - accuracy: 0.9029 - val_loss: 0.3882 - val_accuracy: 0.8410\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2175 - accuracy: 0.9029 - val_loss: 0.3884 - val_accuracy: 0.8410\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3874 - val_accuracy: 0.8410\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2202 - accuracy: 0.9029 - val_loss: 0.4042 - val_accuracy: 0.8410\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3918 - val_accuracy: 0.8410\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2201 - accuracy: 0.9007 - val_loss: 0.4007 - val_accuracy: 0.8410\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.3953 - val_accuracy: 0.8410\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2192 - accuracy: 0.8985 - val_loss: 0.3913 - val_accuracy: 0.8410\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2167 - accuracy: 0.9029 - val_loss: 0.4007 - val_accuracy: 0.8410\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2193 - accuracy: 0.9029 - val_loss: 0.3867 - val_accuracy: 0.8410\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2153 - accuracy: 0.9029 - val_loss: 0.4029 - val_accuracy: 0.8410\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2156 - accuracy: 0.9029 - val_loss: 0.3864 - val_accuracy: 0.8410\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.3967 - val_accuracy: 0.8410\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2195 - accuracy: 0.8985 - val_loss: 0.3969 - val_accuracy: 0.8410\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.3938 - val_accuracy: 0.8410\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.3891 - val_accuracy: 0.8410\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3978 - val_accuracy: 0.8410\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.3972 - val_accuracy: 0.8410\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.3967 - val_accuracy: 0.8410\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2179 - accuracy: 0.8940 - val_loss: 0.3947 - val_accuracy: 0.8410\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2173 - accuracy: 0.9051 - val_loss: 0.3922 - val_accuracy: 0.8410\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.3947 - val_accuracy: 0.8410\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2145 - accuracy: 0.9029 - val_loss: 0.3925 - val_accuracy: 0.8410\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3945 - val_accuracy: 0.8410\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2186 - accuracy: 0.8985 - val_loss: 0.3908 - val_accuracy: 0.8410\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2177 - accuracy: 0.9029 - val_loss: 0.3994 - val_accuracy: 0.8410\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2147 - accuracy: 0.9029 - val_loss: 0.3909 - val_accuracy: 0.8410\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2153 - accuracy: 0.9051 - val_loss: 0.3983 - val_accuracy: 0.8410\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2219 - accuracy: 0.9029 - val_loss: 0.4040 - val_accuracy: 0.8410\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2150 - accuracy: 0.9029 - val_loss: 0.4018 - val_accuracy: 0.8410\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3979 - val_accuracy: 0.8410\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3960 - val_accuracy: 0.8410\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.3921 - val_accuracy: 0.8410\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.3963 - val_accuracy: 0.8410\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2165 - accuracy: 0.8962 - val_loss: 0.4011 - val_accuracy: 0.8410\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2178 - accuracy: 0.8962 - val_loss: 0.3989 - val_accuracy: 0.8410\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2132 - accuracy: 0.9007 - val_loss: 0.3909 - val_accuracy: 0.8410\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2149 - accuracy: 0.8985 - val_loss: 0.3892 - val_accuracy: 0.8410\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2199 - accuracy: 0.8918 - val_loss: 0.4016 - val_accuracy: 0.8410\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2150 - accuracy: 0.9029 - val_loss: 0.4041 - val_accuracy: 0.8410\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2164 - accuracy: 0.8940 - val_loss: 0.3932 - val_accuracy: 0.8410\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2167 - accuracy: 0.9029 - val_loss: 0.4013 - val_accuracy: 0.8410\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2145 - accuracy: 0.9029 - val_loss: 0.3961 - val_accuracy: 0.8410\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2137 - accuracy: 0.9029 - val_loss: 0.3922 - val_accuracy: 0.8410\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.3952 - val_accuracy: 0.8410\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.3954 - val_accuracy: 0.8410\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.4020 - val_accuracy: 0.8410\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4027 - val_accuracy: 0.8410\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2148 - accuracy: 0.9007 - val_loss: 0.3909 - val_accuracy: 0.8410\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.4015 - val_accuracy: 0.8410\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2196 - accuracy: 0.9029 - val_loss: 0.4139 - val_accuracy: 0.8410\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2137 - accuracy: 0.9029 - val_loss: 0.3954 - val_accuracy: 0.8410\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2214 - accuracy: 0.9029 - val_loss: 0.4019 - val_accuracy: 0.8410\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.3966 - val_accuracy: 0.8410\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.3856 - val_accuracy: 0.8410\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.3983 - val_accuracy: 0.8410\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2175 - accuracy: 0.8985 - val_loss: 0.3990 - val_accuracy: 0.8410\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2164 - accuracy: 0.9029 - val_loss: 0.4069 - val_accuracy: 0.8410\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2166 - accuracy: 0.9029 - val_loss: 0.4013 - val_accuracy: 0.8410\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.4052 - val_accuracy: 0.8410\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2158 - accuracy: 0.9029 - val_loss: 0.4153 - val_accuracy: 0.8410\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2218 - accuracy: 0.8918 - val_loss: 0.4173 - val_accuracy: 0.8410\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2145 - accuracy: 0.9029 - val_loss: 0.4013 - val_accuracy: 0.8410\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2211 - accuracy: 0.8962 - val_loss: 0.4003 - val_accuracy: 0.8410\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4010 - val_accuracy: 0.8410\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2161 - accuracy: 0.9029 - val_loss: 0.4045 - val_accuracy: 0.8410\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4082 - val_accuracy: 0.8410\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2177 - accuracy: 0.8962 - val_loss: 0.4109 - val_accuracy: 0.8410\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2290 - accuracy: 0.9029 - val_loss: 0.4184 - val_accuracy: 0.8410\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2170 - accuracy: 0.8940 - val_loss: 0.4032 - val_accuracy: 0.8462\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2179 - accuracy: 0.8985 - val_loss: 0.4058 - val_accuracy: 0.8410\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2199 - accuracy: 0.8962 - val_loss: 0.4080 - val_accuracy: 0.8410\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2164 - accuracy: 0.9029 - val_loss: 0.4157 - val_accuracy: 0.8410\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.4022 - val_accuracy: 0.8410\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4050 - val_accuracy: 0.8410\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.4094 - val_accuracy: 0.8410\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.4099 - val_accuracy: 0.8410\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2208 - accuracy: 0.9029 - val_loss: 0.4094 - val_accuracy: 0.8410\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4158 - val_accuracy: 0.8410\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.4141 - val_accuracy: 0.8410\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4039 - val_accuracy: 0.8410\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2143 - accuracy: 0.9029 - val_loss: 0.4086 - val_accuracy: 0.8410\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.4130 - val_accuracy: 0.8410\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4147 - val_accuracy: 0.8410\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4187 - val_accuracy: 0.8410\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2315 - accuracy: 0.8918 - val_loss: 0.4154 - val_accuracy: 0.8410\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2138 - accuracy: 0.9029 - val_loss: 0.4159 - val_accuracy: 0.8410\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4103 - val_accuracy: 0.8410\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 404us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4164 - val_accuracy: 0.8410\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4151 - val_accuracy: 0.8410\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.4045 - val_accuracy: 0.8410\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2150 - accuracy: 0.9029 - val_loss: 0.4056 - val_accuracy: 0.8410\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2165 - accuracy: 0.8985 - val_loss: 0.4176 - val_accuracy: 0.8410\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2180 - accuracy: 0.8985 - val_loss: 0.3964 - val_accuracy: 0.8410\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.4001 - val_accuracy: 0.8410\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4027 - val_accuracy: 0.8410\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4023 - val_accuracy: 0.8410\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.3999 - val_accuracy: 0.8410\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2150 - accuracy: 0.9029 - val_loss: 0.4043 - val_accuracy: 0.8410\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.3933 - val_accuracy: 0.8410\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2171 - accuracy: 0.9029 - val_loss: 0.4015 - val_accuracy: 0.8410\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.3968 - val_accuracy: 0.8410\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 140us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4066 - val_accuracy: 0.8410\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4011 - val_accuracy: 0.8410\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.4078 - val_accuracy: 0.8410\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.3977 - val_accuracy: 0.8410\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2133 - accuracy: 0.9029 - val_loss: 0.4044 - val_accuracy: 0.8410\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4078 - val_accuracy: 0.8410\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4101 - val_accuracy: 0.8410\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.4122 - val_accuracy: 0.8410\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2145 - accuracy: 0.9007 - val_loss: 0.4030 - val_accuracy: 0.8410\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4111 - val_accuracy: 0.8410\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4114 - val_accuracy: 0.8410\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2133 - accuracy: 0.8985 - val_loss: 0.4086 - val_accuracy: 0.8410\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.4137 - val_accuracy: 0.8410\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4125 - val_accuracy: 0.8410\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4127 - val_accuracy: 0.8410\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2129 - accuracy: 0.8962 - val_loss: 0.4093 - val_accuracy: 0.8410\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4142 - val_accuracy: 0.8410\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2133 - accuracy: 0.9029 - val_loss: 0.4172 - val_accuracy: 0.8410\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2150 - accuracy: 0.9007 - val_loss: 0.4089 - val_accuracy: 0.8410\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2237 - accuracy: 0.8962 - val_loss: 0.4253 - val_accuracy: 0.8410\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2153 - accuracy: 0.9007 - val_loss: 0.4068 - val_accuracy: 0.8410\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.4198 - val_accuracy: 0.8410\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2140 - accuracy: 0.8985 - val_loss: 0.4212 - val_accuracy: 0.8410\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2290 - accuracy: 0.8940 - val_loss: 0.4448 - val_accuracy: 0.8359\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2154 - accuracy: 0.9007 - val_loss: 0.4141 - val_accuracy: 0.8410\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2158 - accuracy: 0.9029 - val_loss: 0.4190 - val_accuracy: 0.8410\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.4192 - val_accuracy: 0.8410\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4104 - val_accuracy: 0.8410\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2159 - accuracy: 0.9029 - val_loss: 0.4235 - val_accuracy: 0.8410\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4151 - val_accuracy: 0.8410\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4260 - val_accuracy: 0.8410\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4239 - val_accuracy: 0.8410\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2148 - accuracy: 0.9029 - val_loss: 0.4216 - val_accuracy: 0.8410\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2163 - accuracy: 0.9029 - val_loss: 0.4200 - val_accuracy: 0.8410\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4234 - val_accuracy: 0.8410\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2171 - accuracy: 0.9029 - val_loss: 0.4242 - val_accuracy: 0.8410\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4230 - val_accuracy: 0.8410\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2149 - accuracy: 0.9029 - val_loss: 0.4246 - val_accuracy: 0.8410\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.4267 - val_accuracy: 0.8410\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2157 - accuracy: 0.9029 - val_loss: 0.4291 - val_accuracy: 0.8410\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4233 - val_accuracy: 0.8410\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4278 - val_accuracy: 0.8410\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4290 - val_accuracy: 0.8410\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4274 - val_accuracy: 0.8410\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2155 - accuracy: 0.9029 - val_loss: 0.4381 - val_accuracy: 0.8410\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4242 - val_accuracy: 0.8410\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4381 - val_accuracy: 0.8410\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2163 - accuracy: 0.9007 - val_loss: 0.4378 - val_accuracy: 0.8410\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4272 - val_accuracy: 0.8410\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4311 - val_accuracy: 0.8410\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.4293 - val_accuracy: 0.8410\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4286 - val_accuracy: 0.8410\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2154 - accuracy: 0.8985 - val_loss: 0.4215 - val_accuracy: 0.8410\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4282 - val_accuracy: 0.8410\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2156 - accuracy: 0.9029 - val_loss: 0.4222 - val_accuracy: 0.8410\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4294 - val_accuracy: 0.8410\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2147 - accuracy: 0.8985 - val_loss: 0.4282 - val_accuracy: 0.8410\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4266 - val_accuracy: 0.8410\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2190 - accuracy: 0.8985 - val_loss: 0.4279 - val_accuracy: 0.8410\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.2141 - accuracy: 0.9007 - val_loss: 0.4311 - val_accuracy: 0.8410\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4261 - val_accuracy: 0.8410\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.4324 - val_accuracy: 0.8410\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 605us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4263 - val_accuracy: 0.8410\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 345us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.4271 - val_accuracy: 0.8410\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 464us/step - loss: 0.2153 - accuracy: 0.9029 - val_loss: 0.4251 - val_accuracy: 0.8410\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4293 - val_accuracy: 0.8410\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4335 - val_accuracy: 0.8410\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2164 - accuracy: 0.9029 - val_loss: 0.4256 - val_accuracy: 0.8410\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2140 - accuracy: 0.9029 - val_loss: 0.4356 - val_accuracy: 0.8410\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4301 - val_accuracy: 0.8410\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 451us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4352 - val_accuracy: 0.8410\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4320 - val_accuracy: 0.8410\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2157 - accuracy: 0.8962 - val_loss: 0.4448 - val_accuracy: 0.8410\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2150 - accuracy: 0.9029 - val_loss: 0.4436 - val_accuracy: 0.8410\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.4310 - val_accuracy: 0.8410\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.4415 - val_accuracy: 0.8410\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4374 - val_accuracy: 0.8410\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2158 - accuracy: 0.9029 - val_loss: 0.4296 - val_accuracy: 0.8410\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4344 - val_accuracy: 0.8410\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4408 - val_accuracy: 0.8410\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.4403 - val_accuracy: 0.8410\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4332 - val_accuracy: 0.8410\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2150 - accuracy: 0.8985 - val_loss: 0.4105 - val_accuracy: 0.8410\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4231 - val_accuracy: 0.8410\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2137 - accuracy: 0.9029 - val_loss: 0.4417 - val_accuracy: 0.8410\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2135 - accuracy: 0.8918 - val_loss: 0.4365 - val_accuracy: 0.8410\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4352 - val_accuracy: 0.8410\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2133 - accuracy: 0.9029 - val_loss: 0.4367 - val_accuracy: 0.8410\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4297 - val_accuracy: 0.8410\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4335 - val_accuracy: 0.8410\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.2134 - accuracy: 0.9051 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2206 - accuracy: 0.8962 - val_loss: 0.4430 - val_accuracy: 0.8410\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2184 - accuracy: 0.8985 - val_loss: 0.4449 - val_accuracy: 0.8410\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4402 - val_accuracy: 0.8410\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4342 - val_accuracy: 0.8410\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4492 - val_accuracy: 0.8410\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.4437 - val_accuracy: 0.8410\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4397 - val_accuracy: 0.8410\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2128 - accuracy: 0.9007 - val_loss: 0.4403 - val_accuracy: 0.8410\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4415 - val_accuracy: 0.8410\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4422 - val_accuracy: 0.8410\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2150 - accuracy: 0.8985 - val_loss: 0.4512 - val_accuracy: 0.8410\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4396 - val_accuracy: 0.8410\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.4450 - val_accuracy: 0.8410\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4418 - val_accuracy: 0.8410\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4418 - val_accuracy: 0.8410\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.4434 - val_accuracy: 0.8410\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4479 - val_accuracy: 0.8410\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4468 - val_accuracy: 0.8410\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4467 - val_accuracy: 0.8410\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 230us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4528 - val_accuracy: 0.8410\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4500 - val_accuracy: 0.8410\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4459 - val_accuracy: 0.8410\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2150 - accuracy: 0.8985 - val_loss: 0.4451 - val_accuracy: 0.8410\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 363us/step - loss: 0.2153 - accuracy: 0.9029 - val_loss: 0.4402 - val_accuracy: 0.8410\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4431 - val_accuracy: 0.8410\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2145 - accuracy: 0.9029 - val_loss: 0.4479 - val_accuracy: 0.8410\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4461 - val_accuracy: 0.8410\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2144 - accuracy: 0.8985 - val_loss: 0.4416 - val_accuracy: 0.8410\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.4458 - val_accuracy: 0.8410\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2137 - accuracy: 0.8985 - val_loss: 0.4451 - val_accuracy: 0.8410\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4431 - val_accuracy: 0.8410\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.4441 - val_accuracy: 0.8410\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4584 - val_accuracy: 0.8410\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2133 - accuracy: 0.9029 - val_loss: 0.4608 - val_accuracy: 0.8410\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4559 - val_accuracy: 0.8410\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4553 - val_accuracy: 0.8410\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2158 - accuracy: 0.9029 - val_loss: 0.4540 - val_accuracy: 0.8410\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4466 - val_accuracy: 0.8410\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2147 - accuracy: 0.8985 - val_loss: 0.4406 - val_accuracy: 0.8410\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4512 - val_accuracy: 0.8410\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4400 - val_accuracy: 0.8410\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4504 - val_accuracy: 0.8410\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4507 - val_accuracy: 0.8410\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4428 - val_accuracy: 0.8410\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2182 - accuracy: 0.8985 - val_loss: 0.4530 - val_accuracy: 0.8513\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2169 - accuracy: 0.8940 - val_loss: 0.4583 - val_accuracy: 0.8410\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2163 - accuracy: 0.9029 - val_loss: 0.4725 - val_accuracy: 0.8410\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4645 - val_accuracy: 0.8410\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.4515 - val_accuracy: 0.8410\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4627 - val_accuracy: 0.8410\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4641 - val_accuracy: 0.8410\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4569 - val_accuracy: 0.8410\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4668 - val_accuracy: 0.8410\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4659 - val_accuracy: 0.8410\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.4629 - val_accuracy: 0.8410\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4607 - val_accuracy: 0.8410\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4559 - val_accuracy: 0.8410\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4608 - val_accuracy: 0.8410\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2148 - accuracy: 0.8962 - val_loss: 0.4847 - val_accuracy: 0.8410\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4629 - val_accuracy: 0.8410\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 349us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4587 - val_accuracy: 0.8410\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2137 - accuracy: 0.9029 - val_loss: 0.4590 - val_accuracy: 0.8410\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2122 - accuracy: 0.8940 - val_loss: 0.4688 - val_accuracy: 0.8410\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4631 - val_accuracy: 0.8410\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2153 - accuracy: 0.8985 - val_loss: 0.4816 - val_accuracy: 0.8410\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2182 - accuracy: 0.9029 - val_loss: 0.4270 - val_accuracy: 0.8410\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 565us/step - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.4627 - val_accuracy: 0.8410\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4660 - val_accuracy: 0.8410\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4642 - val_accuracy: 0.8410\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4653 - val_accuracy: 0.8410\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.4721 - val_accuracy: 0.8410\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4767 - val_accuracy: 0.8410\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2161 - accuracy: 0.9007 - val_loss: 0.4749 - val_accuracy: 0.8410\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4767 - val_accuracy: 0.8410\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4776 - val_accuracy: 0.8410\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2135 - accuracy: 0.8940 - val_loss: 0.4784 - val_accuracy: 0.8410\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4733 - val_accuracy: 0.8410\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4750 - val_accuracy: 0.8410\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2134 - accuracy: 0.8985 - val_loss: 0.4696 - val_accuracy: 0.8410\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4814 - val_accuracy: 0.8410\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.4796 - val_accuracy: 0.8410\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2190 - accuracy: 0.8896 - val_loss: 0.4729 - val_accuracy: 0.8410\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4785 - val_accuracy: 0.8410\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4690 - val_accuracy: 0.8410\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2201 - accuracy: 0.8985 - val_loss: 0.4775 - val_accuracy: 0.8410\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2178 - accuracy: 0.9029 - val_loss: 0.4712 - val_accuracy: 0.8410\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4738 - val_accuracy: 0.8410\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2162 - accuracy: 0.9029 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2144 - accuracy: 0.8940 - val_loss: 0.4494 - val_accuracy: 0.8410\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2129 - accuracy: 0.9029 - val_loss: 0.4706 - val_accuracy: 0.8410\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4762 - val_accuracy: 0.8410\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.4800 - val_accuracy: 0.8410\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.4832 - val_accuracy: 0.8410\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2136 - accuracy: 0.9029 - val_loss: 0.4823 - val_accuracy: 0.8410\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4707 - val_accuracy: 0.8410\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.4710 - val_accuracy: 0.8410\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4913 - val_accuracy: 0.8410\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4904 - val_accuracy: 0.8410\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4824 - val_accuracy: 0.8410\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4780 - val_accuracy: 0.8410\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4824 - val_accuracy: 0.8410\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4849 - val_accuracy: 0.8410\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2166 - accuracy: 0.9029 - val_loss: 0.4880 - val_accuracy: 0.8410\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2204 - accuracy: 0.8852 - val_loss: 0.4738 - val_accuracy: 0.8410\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2167 - accuracy: 0.8985 - val_loss: 0.4659 - val_accuracy: 0.8410\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2121 - accuracy: 0.8962 - val_loss: 0.4705 - val_accuracy: 0.8410\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4797 - val_accuracy: 0.8410\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.4863 - val_accuracy: 0.8410\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4853 - val_accuracy: 0.8410\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.4737 - val_accuracy: 0.8410\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4768 - val_accuracy: 0.8410\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.4813 - val_accuracy: 0.8410\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4765 - val_accuracy: 0.8410\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4701 - val_accuracy: 0.8410\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4714 - val_accuracy: 0.8410\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4712 - val_accuracy: 0.8410\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.4757 - val_accuracy: 0.8410\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.4809 - val_accuracy: 0.8410\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2118 - accuracy: 0.9007 - val_loss: 0.4692 - val_accuracy: 0.8410\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2135 - accuracy: 0.9051 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4757 - val_accuracy: 0.8410\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4764 - val_accuracy: 0.8410\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4819 - val_accuracy: 0.8410\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.4748 - val_accuracy: 0.8410\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4720 - val_accuracy: 0.8410\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4830 - val_accuracy: 0.8410\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4841 - val_accuracy: 0.8410\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4874 - val_accuracy: 0.8410\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 117us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4882 - val_accuracy: 0.8410\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4923 - val_accuracy: 0.8410\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2114 - accuracy: 0.9007 - val_loss: 0.4835 - val_accuracy: 0.8410\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4778 - val_accuracy: 0.8410\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2179 - accuracy: 0.9007 - val_loss: 0.5083 - val_accuracy: 0.8410\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2139 - accuracy: 0.8940 - val_loss: 0.4637 - val_accuracy: 0.8410\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.4520 - val_accuracy: 0.8410\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2122 - accuracy: 0.8985 - val_loss: 0.4772 - val_accuracy: 0.8410\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4675 - val_accuracy: 0.8410\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4713 - val_accuracy: 0.8410\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4700 - val_accuracy: 0.8410\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.4780 - val_accuracy: 0.8410\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4819 - val_accuracy: 0.8410\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4876 - val_accuracy: 0.8410\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2141 - accuracy: 0.9029 - val_loss: 0.4796 - val_accuracy: 0.8410\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2161 - accuracy: 0.9029 - val_loss: 0.4868 - val_accuracy: 0.8410\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4965 - val_accuracy: 0.8410\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2110 - accuracy: 0.9051 - val_loss: 0.4816 - val_accuracy: 0.8410\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.4837 - val_accuracy: 0.8410\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4916 - val_accuracy: 0.8410\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4932 - val_accuracy: 0.8410\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4854 - val_accuracy: 0.8410\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4936 - val_accuracy: 0.8410\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2164 - accuracy: 0.8962 - val_loss: 0.4763 - val_accuracy: 0.8410\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4943 - val_accuracy: 0.8410\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2145 - accuracy: 0.8918 - val_loss: 0.5178 - val_accuracy: 0.8410\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2178 - accuracy: 0.8940 - val_loss: 0.5261 - val_accuracy: 0.8410\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2116 - accuracy: 0.8985 - val_loss: 0.5144 - val_accuracy: 0.8410\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.5141 - val_accuracy: 0.8410\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.5117 - val_accuracy: 0.8410\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.5062 - val_accuracy: 0.8410\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.5103 - val_accuracy: 0.8410\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.5136 - val_accuracy: 0.8410\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.4959 - val_accuracy: 0.8410\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.5007 - val_accuracy: 0.8410\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5049 - val_accuracy: 0.8410\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5084 - val_accuracy: 0.8410\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.5011 - val_accuracy: 0.8410\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.4992 - val_accuracy: 0.8410\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5030 - val_accuracy: 0.8410\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.5026 - val_accuracy: 0.8410\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.5015 - val_accuracy: 0.8410\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2117 - accuracy: 0.8962 - val_loss: 0.5024 - val_accuracy: 0.8410\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2135 - accuracy: 0.8962 - val_loss: 0.5019 - val_accuracy: 0.8410\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2174 - accuracy: 0.8985 - val_loss: 0.5014 - val_accuracy: 0.8410\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2142 - accuracy: 0.9029 - val_loss: 0.5055 - val_accuracy: 0.8410\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.5083 - val_accuracy: 0.8410\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.5144 - val_accuracy: 0.8410\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5091 - val_accuracy: 0.8410\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.5070 - val_accuracy: 0.8410\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.5145 - val_accuracy: 0.8410\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5035 - val_accuracy: 0.8410\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2104 - accuracy: 0.8962 - val_loss: 0.5029 - val_accuracy: 0.8410\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2143 - accuracy: 0.9029 - val_loss: 0.5070 - val_accuracy: 0.8410\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.5097 - val_accuracy: 0.8410\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.5195 - val_accuracy: 0.8410\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.5229 - val_accuracy: 0.8410\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.5184 - val_accuracy: 0.8410\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2112 - accuracy: 0.8918 - val_loss: 0.5155 - val_accuracy: 0.8410\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5143 - val_accuracy: 0.8410\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.5220 - val_accuracy: 0.8410\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2127 - accuracy: 0.9007 - val_loss: 0.5153 - val_accuracy: 0.8410\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.5085 - val_accuracy: 0.8410\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.5156 - val_accuracy: 0.8410\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.5114 - val_accuracy: 0.8410\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.5110 - val_accuracy: 0.8410\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.5131 - val_accuracy: 0.8410\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5048 - val_accuracy: 0.8410\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.5046 - val_accuracy: 0.8410\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.5092 - val_accuracy: 0.8410\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2146 - accuracy: 0.9029 - val_loss: 0.5149 - val_accuracy: 0.8410\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5062 - val_accuracy: 0.8410\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5008 - val_accuracy: 0.8410\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2136 - accuracy: 0.8940 - val_loss: 0.4936 - val_accuracy: 0.8410\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4959 - val_accuracy: 0.8410\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.5065 - val_accuracy: 0.8410\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4909 - val_accuracy: 0.8410\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.5019 - val_accuracy: 0.8410\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.5023 - val_accuracy: 0.8410\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2130 - accuracy: 0.8940 - val_loss: 0.5033 - val_accuracy: 0.8410\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.5032 - val_accuracy: 0.8410\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4988 - val_accuracy: 0.8410\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.5090 - val_accuracy: 0.8410\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5041 - val_accuracy: 0.8410\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.5095 - val_accuracy: 0.8410\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.5042 - val_accuracy: 0.8410\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.5075 - val_accuracy: 0.8410\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.5133 - val_accuracy: 0.8410\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2140 - accuracy: 0.8940 - val_loss: 0.5064 - val_accuracy: 0.8410\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.4990 - val_accuracy: 0.8410\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2152 - accuracy: 0.9029 - val_loss: 0.5023 - val_accuracy: 0.8410\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2127 - accuracy: 0.8985 - val_loss: 0.5066 - val_accuracy: 0.8410\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5059 - val_accuracy: 0.8410\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.5140 - val_accuracy: 0.8410\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5246 - val_accuracy: 0.8410\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.5177 - val_accuracy: 0.8410\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5198 - val_accuracy: 0.8410\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.5223 - val_accuracy: 0.8410\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5222 - val_accuracy: 0.8410\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5181 - val_accuracy: 0.8410\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.5212 - val_accuracy: 0.8410\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.5140 - val_accuracy: 0.8410\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2165 - accuracy: 0.9029 - val_loss: 0.5143 - val_accuracy: 0.8410\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.5133 - val_accuracy: 0.8410\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.5071 - val_accuracy: 0.8410\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.5229 - val_accuracy: 0.8410\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.5199 - val_accuracy: 0.8410\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.5032 - val_accuracy: 0.8410\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2130 - accuracy: 0.8940 - val_loss: 0.5028 - val_accuracy: 0.8410\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.5168 - val_accuracy: 0.8410\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 114us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4952 - val_accuracy: 0.8410\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.5336 - val_accuracy: 0.8410\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.5206 - val_accuracy: 0.8410\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.5187 - val_accuracy: 0.8410\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5318 - val_accuracy: 0.8410\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2133 - accuracy: 0.9029 - val_loss: 0.5183 - val_accuracy: 0.8410\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.5324 - val_accuracy: 0.8410\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.5341 - val_accuracy: 0.8410\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.5340 - val_accuracy: 0.8410\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2120 - accuracy: 0.8985 - val_loss: 0.5285 - val_accuracy: 0.8410\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2175 - accuracy: 0.9029 - val_loss: 0.5406 - val_accuracy: 0.8410\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.5190 - val_accuracy: 0.8410\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.5288 - val_accuracy: 0.8410\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.5334 - val_accuracy: 0.8410\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.5320 - val_accuracy: 0.8410\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2118 - accuracy: 0.9007 - val_loss: 0.5313 - val_accuracy: 0.8410\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.5363 - val_accuracy: 0.8410\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5219 - val_accuracy: 0.8410\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2115 - accuracy: 0.8962 - val_loss: 0.5281 - val_accuracy: 0.8410\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.5374 - val_accuracy: 0.8410\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2130 - accuracy: 0.9029 - val_loss: 0.5307 - val_accuracy: 0.8410\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.5371 - val_accuracy: 0.8410\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5411 - val_accuracy: 0.8410\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2136 - accuracy: 0.8985 - val_loss: 0.5339 - val_accuracy: 0.8410\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.5392 - val_accuracy: 0.8410\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.5333 - val_accuracy: 0.8410\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.5416 - val_accuracy: 0.8410\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5418 - val_accuracy: 0.8410\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.5463 - val_accuracy: 0.8410\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.5432 - val_accuracy: 0.8410\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.5407 - val_accuracy: 0.8410\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.5443 - val_accuracy: 0.8410\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.5490 - val_accuracy: 0.8410\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5480 - val_accuracy: 0.8410\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5450 - val_accuracy: 0.8410\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.5470 - val_accuracy: 0.8410\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2131 - accuracy: 0.8962 - val_loss: 0.5438 - val_accuracy: 0.8410\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.5232 - val_accuracy: 0.8410\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2114 - accuracy: 0.9007 - val_loss: 0.5676 - val_accuracy: 0.8410\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2145 - accuracy: 0.9029 - val_loss: 0.5704 - val_accuracy: 0.8410\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.5675 - val_accuracy: 0.8410\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.5695 - val_accuracy: 0.8410\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.5700 - val_accuracy: 0.8410\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2124 - accuracy: 0.8985 - val_loss: 0.5603 - val_accuracy: 0.8410\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.5753 - val_accuracy: 0.8410\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.5732 - val_accuracy: 0.8410\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.5738 - val_accuracy: 0.8410\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.5701 - val_accuracy: 0.8410\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.5704 - val_accuracy: 0.8410\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2141 - accuracy: 0.9007 - val_loss: 0.5761 - val_accuracy: 0.8410\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2138 - accuracy: 0.9029 - val_loss: 0.5525 - val_accuracy: 0.8410\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2126 - accuracy: 0.9007 - val_loss: 0.5511 - val_accuracy: 0.8410\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.5575 - val_accuracy: 0.8410\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2139 - accuracy: 0.9029 - val_loss: 0.5606 - val_accuracy: 0.8410\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.5649 - val_accuracy: 0.8410\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.5635 - val_accuracy: 0.8410\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 0.5674 - val_accuracy: 0.8410\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.5663 - val_accuracy: 0.8410\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.5645 - val_accuracy: 0.8410\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.5703 - val_accuracy: 0.8410\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.5660 - val_accuracy: 0.8410\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2164 - accuracy: 0.8985 - val_loss: 0.5684 - val_accuracy: 0.8410\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.5611 - val_accuracy: 0.8410\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2137 - accuracy: 0.8940 - val_loss: 0.5601 - val_accuracy: 0.8410\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.5707 - val_accuracy: 0.8410\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.5570 - val_accuracy: 0.8410\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2628 - accuracy: 0.8940 - val_loss: 0.4155 - val_accuracy: 0.8359\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2182 - accuracy: 0.8940 - val_loss: 0.4651 - val_accuracy: 0.8410\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2143 - accuracy: 0.9007 - val_loss: 0.4494 - val_accuracy: 0.8410\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4454 - val_accuracy: 0.8410\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4481 - val_accuracy: 0.8410\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4490 - val_accuracy: 0.8410\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4515 - val_accuracy: 0.8410\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2126 - accuracy: 0.8985 - val_loss: 0.4516 - val_accuracy: 0.8410\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2127 - accuracy: 0.8918 - val_loss: 0.4509 - val_accuracy: 0.8410\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.4427 - val_accuracy: 0.8410\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.4437 - val_accuracy: 0.8410\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4483 - val_accuracy: 0.8410\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4395 - val_accuracy: 0.8410\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4441 - val_accuracy: 0.8410\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4474 - val_accuracy: 0.8410\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2126 - accuracy: 0.8940 - val_loss: 0.4443 - val_accuracy: 0.8410\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4500 - val_accuracy: 0.8410\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2122 - accuracy: 0.8985 - val_loss: 0.4515 - val_accuracy: 0.8410\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4495 - val_accuracy: 0.8410\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4452 - val_accuracy: 0.8410\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4429 - val_accuracy: 0.8410\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4523 - val_accuracy: 0.8410\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2123 - accuracy: 0.9007 - val_loss: 0.4442 - val_accuracy: 0.8410\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4482 - val_accuracy: 0.8410\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4519 - val_accuracy: 0.8410\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4477 - val_accuracy: 0.8410\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.4498 - val_accuracy: 0.8410\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4531 - val_accuracy: 0.8410\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.4516 - val_accuracy: 0.8410\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4505 - val_accuracy: 0.8410\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.4488 - val_accuracy: 0.8410\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2110 - accuracy: 0.9007 - val_loss: 0.4508 - val_accuracy: 0.8410\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4503 - val_accuracy: 0.8410\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.4543 - val_accuracy: 0.8410\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2132 - accuracy: 0.9029 - val_loss: 0.4490 - val_accuracy: 0.8410\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4507 - val_accuracy: 0.8410\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2137 - accuracy: 0.9007 - val_loss: 0.4979 - val_accuracy: 0.8410\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2166 - accuracy: 0.9029 - val_loss: 0.4673 - val_accuracy: 0.8410\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4568 - val_accuracy: 0.8410\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.4591 - val_accuracy: 0.8410\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2134 - accuracy: 0.8918 - val_loss: 0.4514 - val_accuracy: 0.8410\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.4497 - val_accuracy: 0.8410\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4541 - val_accuracy: 0.8410\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.4516 - val_accuracy: 0.8410\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 118us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4529 - val_accuracy: 0.8410\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.4521 - val_accuracy: 0.8410\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4535 - val_accuracy: 0.8410\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2114 - accuracy: 0.8962 - val_loss: 0.4521 - val_accuracy: 0.8410\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2099 - accuracy: 0.8985 - val_loss: 0.4503 - val_accuracy: 0.8410\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4487 - val_accuracy: 0.8410\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4485 - val_accuracy: 0.8410\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2120 - accuracy: 0.8985 - val_loss: 0.4457 - val_accuracy: 0.8410\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4476 - val_accuracy: 0.8410\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4439 - val_accuracy: 0.8410\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4537 - val_accuracy: 0.8410\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4517 - val_accuracy: 0.8410\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.4557 - val_accuracy: 0.8410\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.4563 - val_accuracy: 0.8410\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4530 - val_accuracy: 0.8410\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2153 - accuracy: 0.9029 - val_loss: 0.4536 - val_accuracy: 0.8410\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4579 - val_accuracy: 0.8410\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4584 - val_accuracy: 0.8410\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2108 - accuracy: 0.8940 - val_loss: 0.4574 - val_accuracy: 0.8410\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2163 - accuracy: 0.8985 - val_loss: 0.4567 - val_accuracy: 0.8410\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4548 - val_accuracy: 0.8410\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4532 - val_accuracy: 0.8410\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4573 - val_accuracy: 0.8410\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2126 - accuracy: 0.8918 - val_loss: 0.4531 - val_accuracy: 0.8410\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.4529 - val_accuracy: 0.8410\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4547 - val_accuracy: 0.8410\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.4492 - val_accuracy: 0.8410\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4526 - val_accuracy: 0.8410\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2131 - accuracy: 0.8985 - val_loss: 0.4550 - val_accuracy: 0.8410\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.4559 - val_accuracy: 0.8410\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4558 - val_accuracy: 0.8410\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4587 - val_accuracy: 0.8410\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4587 - val_accuracy: 0.8410\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4591 - val_accuracy: 0.8410\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4588 - val_accuracy: 0.8410\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.4540 - val_accuracy: 0.8410\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.4575 - val_accuracy: 0.8410\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4536 - val_accuracy: 0.8410\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.4547 - val_accuracy: 0.8410\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4554 - val_accuracy: 0.8410\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.4553 - val_accuracy: 0.8410\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.4537 - val_accuracy: 0.8410\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2105 - accuracy: 0.9007 - val_loss: 0.4525 - val_accuracy: 0.8410\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.4577 - val_accuracy: 0.8410\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2123 - accuracy: 0.8985 - val_loss: 0.4564 - val_accuracy: 0.8410\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.4567 - val_accuracy: 0.8410\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.4552 - val_accuracy: 0.8410\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4571 - val_accuracy: 0.8410\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.4583 - val_accuracy: 0.8410\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4545 - val_accuracy: 0.8410\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4601 - val_accuracy: 0.8410\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4580 - val_accuracy: 0.8410\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4620 - val_accuracy: 0.8410\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2108 - accuracy: 0.8962 - val_loss: 0.4612 - val_accuracy: 0.8410\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.4545 - val_accuracy: 0.8410\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2111 - accuracy: 0.8985 - val_loss: 0.4562 - val_accuracy: 0.8410\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4628 - val_accuracy: 0.8410\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.4616 - val_accuracy: 0.8410\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2134 - accuracy: 0.9029 - val_loss: 0.4641 - val_accuracy: 0.8410\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2130 - accuracy: 0.8962 - val_loss: 0.4652 - val_accuracy: 0.8410\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4639 - val_accuracy: 0.8410\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4604 - val_accuracy: 0.8410\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4632 - val_accuracy: 0.8410\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.4601 - val_accuracy: 0.8410\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.4603 - val_accuracy: 0.8410\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4625 - val_accuracy: 0.8410\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2125 - accuracy: 0.8985 - val_loss: 0.4850 - val_accuracy: 0.8410\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2138 - accuracy: 0.9029 - val_loss: 0.4796 - val_accuracy: 0.8410\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.4710 - val_accuracy: 0.8410\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.4676 - val_accuracy: 0.8410\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4704 - val_accuracy: 0.8410\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.4704 - val_accuracy: 0.8410\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 0.4707 - val_accuracy: 0.8410\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2106 - accuracy: 0.8940 - val_loss: 0.4607 - val_accuracy: 0.8410\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.4626 - val_accuracy: 0.8410\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4664 - val_accuracy: 0.8410\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.4670 - val_accuracy: 0.8410\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2123 - accuracy: 0.8962 - val_loss: 0.4605 - val_accuracy: 0.8410\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.4607 - val_accuracy: 0.8410\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2124 - accuracy: 0.8985 - val_loss: 0.4623 - val_accuracy: 0.8410\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.4614 - val_accuracy: 0.8410\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2125 - accuracy: 0.8940 - val_loss: 0.4639 - val_accuracy: 0.8410\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.4629 - val_accuracy: 0.8410\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.4728 - val_accuracy: 0.8410\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4653 - val_accuracy: 0.8410\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4695 - val_accuracy: 0.8410\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.4644 - val_accuracy: 0.8410\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.4654 - val_accuracy: 0.8410\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.4658 - val_accuracy: 0.8410\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.4695 - val_accuracy: 0.8410\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4692 - val_accuracy: 0.8410\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2107 - accuracy: 0.8940 - val_loss: 0.4701 - val_accuracy: 0.8410\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4706 - val_accuracy: 0.8410\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.4699 - val_accuracy: 0.8410\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.4741 - val_accuracy: 0.8410\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2104 - accuracy: 0.8985 - val_loss: 0.4683 - val_accuracy: 0.8410\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4702 - val_accuracy: 0.8410\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.4703 - val_accuracy: 0.8410\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4684 - val_accuracy: 0.8410\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.4711 - val_accuracy: 0.8410\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.4672 - val_accuracy: 0.8410\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4773 - val_accuracy: 0.8410\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4766 - val_accuracy: 0.8410\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.4745 - val_accuracy: 0.8410\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.4760 - val_accuracy: 0.8410\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2120 - accuracy: 0.8940 - val_loss: 0.4802 - val_accuracy: 0.8410\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.4754 - val_accuracy: 0.8410\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.4776 - val_accuracy: 0.8410\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4763 - val_accuracy: 0.8410\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 117us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.4807 - val_accuracy: 0.8410\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.4827 - val_accuracy: 0.8410\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.4705 - val_accuracy: 0.8410\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4675 - val_accuracy: 0.8410\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2117 - accuracy: 0.9007 - val_loss: 0.4704 - val_accuracy: 0.8410\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.4687 - val_accuracy: 0.8410\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.4714 - val_accuracy: 0.8410\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.4735 - val_accuracy: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3804e390>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 61us/step\n",
      "over-sampling test accuracy: 84.10%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2,\n",
       "       1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 0, 2, 0,\n",
       "       1, 1, 1, 1, 2, 2, 0, 2, 1, 0, 2, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 0,\n",
       "       2, 2, 1, 0, 0, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 2, 1, 0, 2, 0, 2, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 1, 0, 0,\n",
       "       2, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 2, 2, 1, 0, 0, 1, 1,\n",
       "       2, 0, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2,\n",
       "       0, 0, 1, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 0, 1, 0, 1, 0, 1,\n",
       "       2, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0          312     1     0\n",
       "1    BCH-SA-12     0     0\n",
       "2       NRS209     2     2\n",
       "3     CFBRSa29     0     0\n",
       "4       NRS209     2     2\n",
       "..         ...   ...   ...\n",
       "190      CA541     1     1\n",
       "191     SR4152     1     0\n",
       "192     NRS110     2     2\n",
       "193   CFBRSa70     0     0\n",
       "194     NRS021     0     1\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.313845e-01</td>\n",
       "      <td>1.686155e-01</td>\n",
       "      <td>2.982275e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.288949e-09</td>\n",
       "      <td>9.420666e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.988474e-01</td>\n",
       "      <td>3.011526e-01</td>\n",
       "      <td>3.436671e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.288949e-09</td>\n",
       "      <td>9.420666e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    7.372800e-01  2.627200e-01  4.197748e-08\n",
       "1    8.313845e-01  1.686155e-01  2.982275e-08\n",
       "2    1.288949e-09  9.420666e-09  1.000000e+00\n",
       "3    6.988474e-01  3.011526e-01  3.436671e-09\n",
       "4    1.288949e-09  9.420666e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "190  3.723218e-01  6.276781e-01  1.945911e-08\n",
       "191  7.372800e-01  2.627200e-01  4.197748e-08\n",
       "192  4.194510e-08  7.508231e-09  1.000000e+00\n",
       "193  7.372800e-01  2.627200e-01  4.197748e-08\n",
       "194  3.943684e-01  6.056316e-01  2.843107e-08\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.6671 - val_accuracy: 0.8462\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.6818 - val_accuracy: 0.8410\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.6914 - val_accuracy: 0.8410\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.6937 - val_accuracy: 0.8410\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.6901 - val_accuracy: 0.8359\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.6860 - val_accuracy: 0.8359\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.6797 - val_accuracy: 0.8359\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.6770 - val_accuracy: 0.8410\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.6858 - val_accuracy: 0.8410\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.6767 - val_accuracy: 0.8410\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.6813 - val_accuracy: 0.8410\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.6827 - val_accuracy: 0.8410\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.6743 - val_accuracy: 0.8410\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2177 - accuracy: 0.8940 - val_loss: 0.6826 - val_accuracy: 0.8410\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.6966 - val_accuracy: 0.8359\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.6902 - val_accuracy: 0.8359\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.6824 - val_accuracy: 0.8410\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.6910 - val_accuracy: 0.8359\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 337us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.6863 - val_accuracy: 0.8410\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 375us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.6861 - val_accuracy: 0.8410\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 378us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.6989 - val_accuracy: 0.8359\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.6950 - val_accuracy: 0.8410\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 667us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.6929 - val_accuracy: 0.8410\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 348us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.6971 - val_accuracy: 0.8359\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.6923 - val_accuracy: 0.8410\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.6985 - val_accuracy: 0.8359\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.6974 - val_accuracy: 0.8359\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.6985 - val_accuracy: 0.8359\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.2110 - accuracy: 0.8985 - val_loss: 0.7003 - val_accuracy: 0.8359\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.6966 - val_accuracy: 0.8359\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.7006 - val_accuracy: 0.8359\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2112 - accuracy: 0.8940 - val_loss: 0.7025 - val_accuracy: 0.8359\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.7018 - val_accuracy: 0.8359\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.6978 - val_accuracy: 0.8359\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.6976 - val_accuracy: 0.8359\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.6997 - val_accuracy: 0.8359\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.7013 - val_accuracy: 0.8359\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.6942 - val_accuracy: 0.8410\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.7170 - val_accuracy: 0.8359\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2106 - accuracy: 0.8985 - val_loss: 0.7112 - val_accuracy: 0.8359\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.7062 - val_accuracy: 0.8359\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.7001 - val_accuracy: 0.8359\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.7062 - val_accuracy: 0.8359\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7103 - val_accuracy: 0.8359\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7110 - val_accuracy: 0.8359\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7049 - val_accuracy: 0.8359\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2147 - accuracy: 0.9029 - val_loss: 0.6996 - val_accuracy: 0.8359\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2131 - accuracy: 0.9029 - val_loss: 0.6910 - val_accuracy: 0.8462\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.7027 - val_accuracy: 0.8462\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.2143 - accuracy: 0.8918 - val_loss: 0.7044 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2122 - accuracy: 0.9007 - val_loss: 0.7110 - val_accuracy: 0.8359\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 819us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.6824 - val_accuracy: 0.8462\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 370us/step - loss: 0.2121 - accuracy: 0.8940 - val_loss: 0.7026 - val_accuracy: 0.8410\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7071 - val_accuracy: 0.8359\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 332us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.6978 - val_accuracy: 0.8410\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2133 - accuracy: 0.8940 - val_loss: 0.7060 - val_accuracy: 0.8410\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.7054 - val_accuracy: 0.8410\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.7047 - val_accuracy: 0.8410\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7108 - val_accuracy: 0.8410\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.7051 - val_accuracy: 0.8410\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.7086 - val_accuracy: 0.8410\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2109 - accuracy: 0.8962 - val_loss: 0.7101 - val_accuracy: 0.8410\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7147 - val_accuracy: 0.8410\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7131 - val_accuracy: 0.8410\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7181 - val_accuracy: 0.8410\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2106 - accuracy: 0.8940 - val_loss: 0.7226 - val_accuracy: 0.8359\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7241 - val_accuracy: 0.8359\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.7273 - val_accuracy: 0.8359\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.7307 - val_accuracy: 0.8359\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2111 - accuracy: 0.9007 - val_loss: 0.7342 - val_accuracy: 0.8359\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 384us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7342 - val_accuracy: 0.8359\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.7281 - val_accuracy: 0.8359\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.7272 - val_accuracy: 0.8359\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.7263 - val_accuracy: 0.8359\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.7328 - val_accuracy: 0.8359\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 315us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.7326 - val_accuracy: 0.8359\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7313 - val_accuracy: 0.8359\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7311 - val_accuracy: 0.8359\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2156 - accuracy: 0.8962 - val_loss: 0.7241 - val_accuracy: 0.8462\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.7325 - val_accuracy: 0.8410\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7379 - val_accuracy: 0.8359\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7343 - val_accuracy: 0.8359\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.7402 - val_accuracy: 0.8359\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.7448 - val_accuracy: 0.8359\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7395 - val_accuracy: 0.8359\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7419 - val_accuracy: 0.8359\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.7423 - val_accuracy: 0.8359\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.7425 - val_accuracy: 0.8359\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7409 - val_accuracy: 0.8359\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.7514 - val_accuracy: 0.8359\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2117 - accuracy: 0.9029 - val_loss: 0.7487 - val_accuracy: 0.8359\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7446 - val_accuracy: 0.8359\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7429 - val_accuracy: 0.8359\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7423 - val_accuracy: 0.8359\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.7476 - val_accuracy: 0.8359\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7460 - val_accuracy: 0.8359\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.7535 - val_accuracy: 0.8359\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.7499 - val_accuracy: 0.8359\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.7475 - val_accuracy: 0.8359\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.7542 - val_accuracy: 0.8359\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.7540 - val_accuracy: 0.8359\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7574 - val_accuracy: 0.8359\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7541 - val_accuracy: 0.8359\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7993 - val_accuracy: 0.8359\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2160 - accuracy: 0.9029 - val_loss: 0.7178 - val_accuracy: 0.8410\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.7574 - val_accuracy: 0.8359\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.7682 - val_accuracy: 0.8359\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 442us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.7660 - val_accuracy: 0.8359\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2126 - accuracy: 0.8918 - val_loss: 0.7644 - val_accuracy: 0.8359\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 360us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.7601 - val_accuracy: 0.8410\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 326us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7640 - val_accuracy: 0.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.7639 - val_accuracy: 0.8359\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7596 - val_accuracy: 0.8410\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 379us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7654 - val_accuracy: 0.8359\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.7638 - val_accuracy: 0.8410\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 385us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7628 - val_accuracy: 0.8410\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7575 - val_accuracy: 0.8410\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.7596 - val_accuracy: 0.8410\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.7632 - val_accuracy: 0.8410\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7748 - val_accuracy: 0.8359\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.7613 - val_accuracy: 0.8410\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.7720 - val_accuracy: 0.8359\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7697 - val_accuracy: 0.8359\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2138 - accuracy: 0.8985 - val_loss: 0.7494 - val_accuracy: 0.8462\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2147 - accuracy: 0.9029 - val_loss: 0.7669 - val_accuracy: 0.8410\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.7740 - val_accuracy: 0.8410\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.7787 - val_accuracy: 0.8410\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.7671 - val_accuracy: 0.8410\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.7709 - val_accuracy: 0.8410\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.7780 - val_accuracy: 0.8410\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.7703 - val_accuracy: 0.8410\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.7729 - val_accuracy: 0.8410\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2107 - accuracy: 0.9029 - val_loss: 0.7716 - val_accuracy: 0.8410\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7623 - val_accuracy: 0.8410\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.7564 - val_accuracy: 0.8410\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.7617 - val_accuracy: 0.8410\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7593 - val_accuracy: 0.8410\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.7501 - val_accuracy: 0.8462\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.7525 - val_accuracy: 0.8462\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2105 - accuracy: 0.8918 - val_loss: 0.7650 - val_accuracy: 0.8410\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7670 - val_accuracy: 0.8410\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.7707 - val_accuracy: 0.8410\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.7739 - val_accuracy: 0.8410\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.7810 - val_accuracy: 0.8410\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2115 - accuracy: 0.8940 - val_loss: 0.7724 - val_accuracy: 0.8410\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.7700 - val_accuracy: 0.8359\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2197 - accuracy: 0.9007 - val_loss: 0.7630 - val_accuracy: 0.8308\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2126 - accuracy: 0.8874 - val_loss: 0.7520 - val_accuracy: 0.8359\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.7417 - val_accuracy: 0.8359\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2149 - accuracy: 0.9029 - val_loss: 0.7375 - val_accuracy: 0.8359\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.7588 - val_accuracy: 0.8359\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.7497 - val_accuracy: 0.8359\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.7381 - val_accuracy: 0.8359\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2126 - accuracy: 0.8896 - val_loss: 0.7386 - val_accuracy: 0.8410\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.7376 - val_accuracy: 0.8410\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7429 - val_accuracy: 0.8359\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2134 - accuracy: 0.9007 - val_loss: 0.7397 - val_accuracy: 0.8359\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2118 - accuracy: 0.8918 - val_loss: 0.7516 - val_accuracy: 0.8359\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2114 - accuracy: 0.9029 - val_loss: 0.7429 - val_accuracy: 0.8410\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.7435 - val_accuracy: 0.8410\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.7440 - val_accuracy: 0.8410\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2119 - accuracy: 0.9029 - val_loss: 0.7447 - val_accuracy: 0.8410\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2125 - accuracy: 0.8940 - val_loss: 0.7475 - val_accuracy: 0.8410\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.7462 - val_accuracy: 0.8410\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.7544 - val_accuracy: 0.8359\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2123 - accuracy: 0.9029 - val_loss: 0.7194 - val_accuracy: 0.8410\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.7543 - val_accuracy: 0.8410\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.7631 - val_accuracy: 0.8410\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.7583 - val_accuracy: 0.8410\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.7618 - val_accuracy: 0.8410\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.7563 - val_accuracy: 0.8410\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2115 - accuracy: 0.9029 - val_loss: 0.7636 - val_accuracy: 0.8359\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.7667 - val_accuracy: 0.8359\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7647 - val_accuracy: 0.8359\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.7646 - val_accuracy: 0.8359\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7702 - val_accuracy: 0.8359\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7707 - val_accuracy: 0.8359\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7706 - val_accuracy: 0.8359\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7710 - val_accuracy: 0.8359\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.7772 - val_accuracy: 0.8359\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2102 - accuracy: 0.8985 - val_loss: 0.7758 - val_accuracy: 0.8359\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7766 - val_accuracy: 0.8359\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.7738 - val_accuracy: 0.8410\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.7794 - val_accuracy: 0.8410\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7755 - val_accuracy: 0.8410\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.7699 - val_accuracy: 0.8410\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.7829 - val_accuracy: 0.8359\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.7826 - val_accuracy: 0.8410\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7860 - val_accuracy: 0.8359\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2115 - accuracy: 0.9007 - val_loss: 0.7840 - val_accuracy: 0.8410\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.7805 - val_accuracy: 0.8410\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.7809 - val_accuracy: 0.8359\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.7844 - val_accuracy: 0.8359\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7859 - val_accuracy: 0.8359\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.7896 - val_accuracy: 0.8359\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2111 - accuracy: 0.9029 - val_loss: 0.7952 - val_accuracy: 0.8359\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.7926 - val_accuracy: 0.8410\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.7966 - val_accuracy: 0.8410\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.7967 - val_accuracy: 0.8410\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 496us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8023 - val_accuracy: 0.8410\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8024 - val_accuracy: 0.8410\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8061 - val_accuracy: 0.8410\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.7984 - val_accuracy: 0.8410\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.8080 - val_accuracy: 0.8410\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8055 - val_accuracy: 0.8410\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.7983 - val_accuracy: 0.8410\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2107 - accuracy: 0.9007 - val_loss: 0.8078 - val_accuracy: 0.8410\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2125 - accuracy: 0.8918 - val_loss: 0.8031 - val_accuracy: 0.8410\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.7926 - val_accuracy: 0.8410\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8015 - val_accuracy: 0.8410\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.7982 - val_accuracy: 0.8410\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8086 - val_accuracy: 0.8359\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8064 - val_accuracy: 0.8359\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8066 - val_accuracy: 0.8359\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8203 - val_accuracy: 0.8359\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8162 - val_accuracy: 0.8359\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.8161 - val_accuracy: 0.8359\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2121 - accuracy: 0.9029 - val_loss: 0.8146 - val_accuracy: 0.8359\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8074 - val_accuracy: 0.8359\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8065 - val_accuracy: 0.8359\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8157 - val_accuracy: 0.8359\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 223us/step - loss: 0.2110 - accuracy: 0.9029 - val_loss: 0.8278 - val_accuracy: 0.8359\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.8222 - val_accuracy: 0.8359\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8167 - val_accuracy: 0.8359\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.8230 - val_accuracy: 0.8359\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8203 - val_accuracy: 0.8359\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8160 - val_accuracy: 0.8359\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 351us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8234 - val_accuracy: 0.8359\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8203 - val_accuracy: 0.8359\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8261 - val_accuracy: 0.8359\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2113 - accuracy: 0.8985 - val_loss: 0.8260 - val_accuracy: 0.8359\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2118 - accuracy: 0.9029 - val_loss: 0.8189 - val_accuracy: 0.8359\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8643 - val_accuracy: 0.8359\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2127 - accuracy: 0.8985 - val_loss: 0.8324 - val_accuracy: 0.8359\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8303 - val_accuracy: 0.8359\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.8153 - val_accuracy: 0.8359\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.8130 - val_accuracy: 0.8359\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8188 - val_accuracy: 0.8359\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8225 - val_accuracy: 0.8359\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8272 - val_accuracy: 0.8359\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8220 - val_accuracy: 0.8359\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.8226 - val_accuracy: 0.8359\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2120 - accuracy: 0.9029 - val_loss: 0.8324 - val_accuracy: 0.8359\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8315 - val_accuracy: 0.8359\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8325 - val_accuracy: 0.8359\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8731 - val_accuracy: 0.8308\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.8542 - val_accuracy: 0.8359\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8138 - val_accuracy: 0.8410\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.8093 - val_accuracy: 0.8410\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8250 - val_accuracy: 0.8410\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2122 - accuracy: 0.9029 - val_loss: 0.8216 - val_accuracy: 0.8410\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8142 - val_accuracy: 0.8410\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8173 - val_accuracy: 0.8410\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.8272 - val_accuracy: 0.8410\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8248 - val_accuracy: 0.8410\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.8179 - val_accuracy: 0.8410\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8206 - val_accuracy: 0.8410\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8409 - val_accuracy: 0.8359\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.8355 - val_accuracy: 0.8359\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8267 - val_accuracy: 0.8359\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.8318 - val_accuracy: 0.8359\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8362 - val_accuracy: 0.8359\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8354 - val_accuracy: 0.8359\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.8348 - val_accuracy: 0.8359\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.8282 - val_accuracy: 0.8359\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8334 - val_accuracy: 0.8359\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8258 - val_accuracy: 0.8359\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8240 - val_accuracy: 0.8359\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8362 - val_accuracy: 0.8359\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8384 - val_accuracy: 0.8359\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8408 - val_accuracy: 0.8359\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8435 - val_accuracy: 0.8359\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8233 - val_accuracy: 0.8359\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.8338 - val_accuracy: 0.8359\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.8464 - val_accuracy: 0.8410\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.8484 - val_accuracy: 0.8359\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8386 - val_accuracy: 0.8359\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8430 - val_accuracy: 0.8410\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8415 - val_accuracy: 0.8410\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8501 - val_accuracy: 0.8410\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8483 - val_accuracy: 0.8410\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8495 - val_accuracy: 0.8410\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8527 - val_accuracy: 0.8410\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8521 - val_accuracy: 0.8410\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8511 - val_accuracy: 0.8410\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8541 - val_accuracy: 0.8410\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.8623 - val_accuracy: 0.8410\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2102 - accuracy: 0.8985 - val_loss: 0.8626 - val_accuracy: 0.8410\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8571 - val_accuracy: 0.8410\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8624 - val_accuracy: 0.8410\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8406 - val_accuracy: 0.8410\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8488 - val_accuracy: 0.8410\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8510 - val_accuracy: 0.8410\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 357us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8584 - val_accuracy: 0.8410\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 380us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.8578 - val_accuracy: 0.8410\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2109 - accuracy: 0.8962 - val_loss: 0.8399 - val_accuracy: 0.8410\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8472 - val_accuracy: 0.8410\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8497 - val_accuracy: 0.8410\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8566 - val_accuracy: 0.8410\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8548 - val_accuracy: 0.8410\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8517 - val_accuracy: 0.8410\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8573 - val_accuracy: 0.8410\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2102 - accuracy: 0.9007 - val_loss: 0.8433 - val_accuracy: 0.8410\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2124 - accuracy: 0.9029 - val_loss: 0.8568 - val_accuracy: 0.8410\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.8601 - val_accuracy: 0.8359\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8735 - val_accuracy: 0.8359\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2153 - accuracy: 0.8985 - val_loss: 0.8845 - val_accuracy: 0.8308\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2128 - accuracy: 0.9029 - val_loss: 0.8620 - val_accuracy: 0.8359\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8588 - val_accuracy: 0.8359\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8589 - val_accuracy: 0.8359\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8606 - val_accuracy: 0.8359\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8553 - val_accuracy: 0.8359\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8472 - val_accuracy: 0.8359\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8519 - val_accuracy: 0.8359\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8519 - val_accuracy: 0.8359\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8488 - val_accuracy: 0.8359\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8513 - val_accuracy: 0.8359\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8529 - val_accuracy: 0.8359\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8541 - val_accuracy: 0.8359\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8612 - val_accuracy: 0.8359\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8575 - val_accuracy: 0.8359\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 423us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8518 - val_accuracy: 0.8359\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8582 - val_accuracy: 0.8410\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8625 - val_accuracy: 0.8410\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.8594 - val_accuracy: 0.8410\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8602 - val_accuracy: 0.8410\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8616 - val_accuracy: 0.8410\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8571 - val_accuracy: 0.8410\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2109 - accuracy: 0.9029 - val_loss: 0.8526 - val_accuracy: 0.8410\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8552 - val_accuracy: 0.8410\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8602 - val_accuracy: 0.8410\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 158us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8661 - val_accuracy: 0.8410\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8577 - val_accuracy: 0.8410\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8621 - val_accuracy: 0.8410\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8611 - val_accuracy: 0.8410\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8620 - val_accuracy: 0.8410\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8639 - val_accuracy: 0.8410\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8668 - val_accuracy: 0.8410\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8658 - val_accuracy: 0.8410\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8658 - val_accuracy: 0.8410\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8706 - val_accuracy: 0.8410\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8690 - val_accuracy: 0.8410\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2118 - accuracy: 0.8918 - val_loss: 0.8610 - val_accuracy: 0.8410\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8543 - val_accuracy: 0.8410\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2112 - accuracy: 0.9029 - val_loss: 0.8718 - val_accuracy: 0.8410\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8805 - val_accuracy: 0.8410\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8601 - val_accuracy: 0.8410\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8636 - val_accuracy: 0.8410\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8651 - val_accuracy: 0.8410\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 497us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8665 - val_accuracy: 0.8410\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8673 - val_accuracy: 0.8410\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8726 - val_accuracy: 0.8410\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8754 - val_accuracy: 0.8410\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8706 - val_accuracy: 0.8410\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8675 - val_accuracy: 0.8410\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8712 - val_accuracy: 0.8410\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8774 - val_accuracy: 0.8410\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.8730 - val_accuracy: 0.8410\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8736 - val_accuracy: 0.8410\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2116 - accuracy: 0.9029 - val_loss: 0.8938 - val_accuracy: 0.8359\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.9420 - val_accuracy: 0.8359\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2297 - accuracy: 0.8962 - val_loss: 0.8661 - val_accuracy: 0.8359\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2234 - accuracy: 0.9007 - val_loss: 0.9863 - val_accuracy: 0.8410\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.8829 - val_accuracy: 0.8410\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8845 - val_accuracy: 0.8359\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8895 - val_accuracy: 0.8359\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8973 - val_accuracy: 0.8359\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2135 - accuracy: 0.9029 - val_loss: 0.8615 - val_accuracy: 0.8359\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8418 - val_accuracy: 0.8359\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.8494 - val_accuracy: 0.8359\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8478 - val_accuracy: 0.8359\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8486 - val_accuracy: 0.8359\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2122 - accuracy: 0.9007 - val_loss: 0.8514 - val_accuracy: 0.8359\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.8573 - val_accuracy: 0.8359\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8560 - val_accuracy: 0.8359\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8588 - val_accuracy: 0.8359\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 405us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8551 - val_accuracy: 0.8359\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 339us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8571 - val_accuracy: 0.8359\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8616 - val_accuracy: 0.8359\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8544 - val_accuracy: 0.8359\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8567 - val_accuracy: 0.8359\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8542 - val_accuracy: 0.8359\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8591 - val_accuracy: 0.8359\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8567 - val_accuracy: 0.8359\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8529 - val_accuracy: 0.8359\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8503 - val_accuracy: 0.8359\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.8479 - val_accuracy: 0.8359\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8509 - val_accuracy: 0.8359\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8486 - val_accuracy: 0.8359\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8549 - val_accuracy: 0.8359\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8536 - val_accuracy: 0.8359\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8515 - val_accuracy: 0.8359\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8568 - val_accuracy: 0.8359\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8530 - val_accuracy: 0.8359\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8520 - val_accuracy: 0.8359\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8569 - val_accuracy: 0.8359\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2098 - accuracy: 0.9029 - val_loss: 0.8563 - val_accuracy: 0.8359\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.8534 - val_accuracy: 0.8359\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8501 - val_accuracy: 0.8359\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8533 - val_accuracy: 0.8359\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8537 - val_accuracy: 0.8359\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8537 - val_accuracy: 0.8359\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8557 - val_accuracy: 0.8359\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8563 - val_accuracy: 0.8359\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8512 - val_accuracy: 0.8359\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8536 - val_accuracy: 0.8359\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8578 - val_accuracy: 0.8359\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8578 - val_accuracy: 0.8359\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2095 - accuracy: 0.9007 - val_loss: 0.8534 - val_accuracy: 0.8359\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8562 - val_accuracy: 0.8359\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8555 - val_accuracy: 0.8359\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8474 - val_accuracy: 0.8359\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8499 - val_accuracy: 0.8359\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8513 - val_accuracy: 0.8359\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8528 - val_accuracy: 0.8359\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8522 - val_accuracy: 0.8359\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2104 - accuracy: 0.9029 - val_loss: 0.8506 - val_accuracy: 0.8359\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2106 - accuracy: 0.9029 - val_loss: 0.8453 - val_accuracy: 0.8359\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.8594 - val_accuracy: 0.8359\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2108 - accuracy: 0.9029 - val_loss: 0.8739 - val_accuracy: 0.8359\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8489 - val_accuracy: 0.8359\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8511 - val_accuracy: 0.8359\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8518 - val_accuracy: 0.8359\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.8542 - val_accuracy: 0.8359\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8442 - val_accuracy: 0.8410\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8472 - val_accuracy: 0.8359\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8563 - val_accuracy: 0.8359\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8737 - val_accuracy: 0.8359\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8716 - val_accuracy: 0.8359\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8757 - val_accuracy: 0.8359\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.8740 - val_accuracy: 0.8359\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8737 - val_accuracy: 0.8359\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.8715 - val_accuracy: 0.8359\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8666 - val_accuracy: 0.8359\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8674 - val_accuracy: 0.8359\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8698 - val_accuracy: 0.8359\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8758 - val_accuracy: 0.8359\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8698 - val_accuracy: 0.8359\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8650 - val_accuracy: 0.8359\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8672 - val_accuracy: 0.8359\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8716 - val_accuracy: 0.8359\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 164us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8743 - val_accuracy: 0.8359\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2106 - accuracy: 0.8962 - val_loss: 0.8768 - val_accuracy: 0.8359\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8746 - val_accuracy: 0.8359\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8618 - val_accuracy: 0.8359\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8570 - val_accuracy: 0.8410\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8631 - val_accuracy: 0.8410\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8573 - val_accuracy: 0.8359\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8639 - val_accuracy: 0.8359\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8551 - val_accuracy: 0.8410\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8569 - val_accuracy: 0.8410\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8575 - val_accuracy: 0.8410\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8598 - val_accuracy: 0.8410\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8600 - val_accuracy: 0.8410\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8616 - val_accuracy: 0.8410\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.8612 - val_accuracy: 0.8359\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8610 - val_accuracy: 0.8410\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8641 - val_accuracy: 0.8359\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8620 - val_accuracy: 0.8359\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2103 - accuracy: 0.9029 - val_loss: 0.8619 - val_accuracy: 0.8359\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8528 - val_accuracy: 0.8359\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8611 - val_accuracy: 0.8359\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8567 - val_accuracy: 0.8359\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8555 - val_accuracy: 0.8410\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8513 - val_accuracy: 0.8410\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8568 - val_accuracy: 0.8359\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8558 - val_accuracy: 0.8410\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8576 - val_accuracy: 0.8410\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8558 - val_accuracy: 0.8410\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8627 - val_accuracy: 0.8410\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.8618 - val_accuracy: 0.8410\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8765 - val_accuracy: 0.8410\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8475 - val_accuracy: 0.8410\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8504 - val_accuracy: 0.8410\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8678 - val_accuracy: 0.8410\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8691 - val_accuracy: 0.8410\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.8676 - val_accuracy: 0.8410\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.8742 - val_accuracy: 0.8410\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.8762 - val_accuracy: 0.8410\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.8715 - val_accuracy: 0.8410\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8751 - val_accuracy: 0.8410\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8702 - val_accuracy: 0.8410\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8766 - val_accuracy: 0.8410\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8728 - val_accuracy: 0.8410\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8767 - val_accuracy: 0.8410\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8792 - val_accuracy: 0.8410\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.8793 - val_accuracy: 0.8410\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8762 - val_accuracy: 0.8410\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8769 - val_accuracy: 0.8410\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8775 - val_accuracy: 0.8410\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8695 - val_accuracy: 0.8410\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8712 - val_accuracy: 0.8410\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8725 - val_accuracy: 0.8410\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8817 - val_accuracy: 0.8410\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8759 - val_accuracy: 0.8410\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8763 - val_accuracy: 0.8410\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8844 - val_accuracy: 0.8410\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.8767 - val_accuracy: 0.8410\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.8831 - val_accuracy: 0.8410\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2113 - accuracy: 0.9029 - val_loss: 0.8781 - val_accuracy: 0.8410\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8873 - val_accuracy: 0.8410\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8774 - val_accuracy: 0.8410\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8798 - val_accuracy: 0.8410\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8886 - val_accuracy: 0.8410\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.8894 - val_accuracy: 0.8410\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.8865 - val_accuracy: 0.8410\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8813 - val_accuracy: 0.8410\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.8848 - val_accuracy: 0.8410\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.8852 - val_accuracy: 0.8410\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8818 - val_accuracy: 0.8410\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8879 - val_accuracy: 0.8410\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.8876 - val_accuracy: 0.8410\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8879 - val_accuracy: 0.8410\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8863 - val_accuracy: 0.8410\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8864 - val_accuracy: 0.8410\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.8844 - val_accuracy: 0.8410\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8916 - val_accuracy: 0.8410\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.8897 - val_accuracy: 0.8410\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.8986 - val_accuracy: 0.8410\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8952 - val_accuracy: 0.8410\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8957 - val_accuracy: 0.8410\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.8949 - val_accuracy: 0.8410\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.8965 - val_accuracy: 0.8410\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.8882 - val_accuracy: 0.8410\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8881 - val_accuracy: 0.8410\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8926 - val_accuracy: 0.8410\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9051 - val_accuracy: 0.8410\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.9090 - val_accuracy: 0.8410\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9058 - val_accuracy: 0.8410\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9098 - val_accuracy: 0.8410\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9219 - val_accuracy: 0.8410\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.9009 - val_accuracy: 0.8410\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.8981 - val_accuracy: 0.8410\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9053 - val_accuracy: 0.8410\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9092 - val_accuracy: 0.8410\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9049 - val_accuracy: 0.8410\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.9289 - val_accuracy: 0.8410\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9252 - val_accuracy: 0.8410\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.9151 - val_accuracy: 0.8410\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.9158 - val_accuracy: 0.8410\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9318 - val_accuracy: 0.8359\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2094 - accuracy: 0.9029 - val_loss: 0.9326 - val_accuracy: 0.8359\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9329 - val_accuracy: 0.8359\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.9378 - val_accuracy: 0.8359\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9353 - val_accuracy: 0.8359\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.9277 - val_accuracy: 0.8359\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9322 - val_accuracy: 0.8359\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.9357 - val_accuracy: 0.8359\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9421 - val_accuracy: 0.8359\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.9318 - val_accuracy: 0.8359\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2106 - accuracy: 0.8985 - val_loss: 0.9125 - val_accuracy: 0.8359\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 131us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9163 - val_accuracy: 0.8359\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.9161 - val_accuracy: 0.8359\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9197 - val_accuracy: 0.8359\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9213 - val_accuracy: 0.8359\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9257 - val_accuracy: 0.8359\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9259 - val_accuracy: 0.8359\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9248 - val_accuracy: 0.8359\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9250 - val_accuracy: 0.8359\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9088 - val_accuracy: 0.8359\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9159 - val_accuracy: 0.8359\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9209 - val_accuracy: 0.8359\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9308 - val_accuracy: 0.8359\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2111 - accuracy: 0.8985 - val_loss: 0.9247 - val_accuracy: 0.8359\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.9106 - val_accuracy: 0.8359\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9100 - val_accuracy: 0.8359\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9073 - val_accuracy: 0.8359\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9080 - val_accuracy: 0.8359\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9087 - val_accuracy: 0.8359\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.9115 - val_accuracy: 0.8359\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.9085 - val_accuracy: 0.8359\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9132 - val_accuracy: 0.8359\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.9193 - val_accuracy: 0.8359\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9157 - val_accuracy: 0.8359\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.9141 - val_accuracy: 0.8359\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9182 - val_accuracy: 0.8359\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9190 - val_accuracy: 0.8359\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9155 - val_accuracy: 0.8359\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9224 - val_accuracy: 0.8359\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9214 - val_accuracy: 0.8359\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9222 - val_accuracy: 0.8359\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2165 - accuracy: 0.9029 - val_loss: 0.9691 - val_accuracy: 0.8359\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2143 - accuracy: 0.9007 - val_loss: 0.8627 - val_accuracy: 0.8410\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8698 - val_accuracy: 0.8410\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8773 - val_accuracy: 0.8410\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8781 - val_accuracy: 0.8410\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.8821 - val_accuracy: 0.8410\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8794 - val_accuracy: 0.8410\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.8894 - val_accuracy: 0.8410\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8896 - val_accuracy: 0.8410\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.8922 - val_accuracy: 0.8410\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8925 - val_accuracy: 0.8410\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.8895 - val_accuracy: 0.8410\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.8903 - val_accuracy: 0.8410\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8933 - val_accuracy: 0.8410\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.8941 - val_accuracy: 0.8410\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.8983 - val_accuracy: 0.8410\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.8984 - val_accuracy: 0.8410\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.8943 - val_accuracy: 0.8410\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.8987 - val_accuracy: 0.8410\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9036 - val_accuracy: 0.8410\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9079 - val_accuracy: 0.8410\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2101 - accuracy: 0.9029 - val_loss: 0.9105 - val_accuracy: 0.8410\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9108 - val_accuracy: 0.8410\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9215 - val_accuracy: 0.8410\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9172 - val_accuracy: 0.8410\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9161 - val_accuracy: 0.8410\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9146 - val_accuracy: 0.8410\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9155 - val_accuracy: 0.8410\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.9170 - val_accuracy: 0.8410\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 0.9169 - val_accuracy: 0.8410\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.9206 - val_accuracy: 0.8410\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9181 - val_accuracy: 0.8410\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9245 - val_accuracy: 0.8410\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 0.9479 - val_accuracy: 0.8410\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.9538 - val_accuracy: 0.8410\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9451 - val_accuracy: 0.8410\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9416 - val_accuracy: 0.8410\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9419 - val_accuracy: 0.8410\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9371 - val_accuracy: 0.8410\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9342 - val_accuracy: 0.8410\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9348 - val_accuracy: 0.8410\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.9361 - val_accuracy: 0.8410\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9359 - val_accuracy: 0.8410\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9355 - val_accuracy: 0.8410\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9379 - val_accuracy: 0.8410\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9401 - val_accuracy: 0.8410\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 0.9446 - val_accuracy: 0.8410\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9346 - val_accuracy: 0.8410\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9332 - val_accuracy: 0.8410\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2105 - accuracy: 0.9029 - val_loss: 0.9359 - val_accuracy: 0.8410\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9232 - val_accuracy: 0.8410\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9272 - val_accuracy: 0.8410\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9303 - val_accuracy: 0.8410\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9288 - val_accuracy: 0.8410\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9319 - val_accuracy: 0.8410\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9297 - val_accuracy: 0.8410\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9315 - val_accuracy: 0.8410\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9311 - val_accuracy: 0.8410\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9325 - val_accuracy: 0.8410\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9264 - val_accuracy: 0.8410\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9297 - val_accuracy: 0.8410\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9285 - val_accuracy: 0.8410\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9319 - val_accuracy: 0.8410\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9365 - val_accuracy: 0.8410\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9387 - val_accuracy: 0.8410\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9341 - val_accuracy: 0.8410\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2099 - accuracy: 0.9029 - val_loss: 0.9356 - val_accuracy: 0.8410\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9332 - val_accuracy: 0.8410\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9339 - val_accuracy: 0.8410\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9335 - val_accuracy: 0.8410\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9370 - val_accuracy: 0.8410\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9396 - val_accuracy: 0.8410\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9368 - val_accuracy: 0.8410\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9348 - val_accuracy: 0.8410\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9349 - val_accuracy: 0.8410\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9354 - val_accuracy: 0.8410\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9344 - val_accuracy: 0.8410\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 0.9733 - val_accuracy: 0.8410\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2127 - accuracy: 0.8985 - val_loss: 0.9544 - val_accuracy: 0.8410\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9292 - val_accuracy: 0.8410\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 112us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 0.9374 - val_accuracy: 0.8410\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9411 - val_accuracy: 0.8410\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9411 - val_accuracy: 0.8410\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9479 - val_accuracy: 0.8410\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9448 - val_accuracy: 0.8410\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9461 - val_accuracy: 0.8410\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9467 - val_accuracy: 0.8410\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9461 - val_accuracy: 0.8410\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9472 - val_accuracy: 0.8410\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9462 - val_accuracy: 0.8410\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9624 - val_accuracy: 0.8359\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9617 - val_accuracy: 0.8359\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9611 - val_accuracy: 0.8359\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9621 - val_accuracy: 0.8359\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2104 - accuracy: 0.8985 - val_loss: 0.9529 - val_accuracy: 0.8359\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9534 - val_accuracy: 0.8359\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9518 - val_accuracy: 0.8359\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9519 - val_accuracy: 0.8359\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9539 - val_accuracy: 0.8359\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9540 - val_accuracy: 0.8359\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9491 - val_accuracy: 0.8359\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9513 - val_accuracy: 0.8359\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9535 - val_accuracy: 0.8359\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9546 - val_accuracy: 0.8359\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9548 - val_accuracy: 0.8359\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9550 - val_accuracy: 0.8359\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 0.9572 - val_accuracy: 0.8359\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9576 - val_accuracy: 0.8359\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9552 - val_accuracy: 0.8359\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9568 - val_accuracy: 0.8359\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9598 - val_accuracy: 0.8359\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2071 - accuracy: 0.9029 - val_loss: 0.9582 - val_accuracy: 0.8359\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9622 - val_accuracy: 0.8359\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9646 - val_accuracy: 0.8359\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9617 - val_accuracy: 0.8359\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9619 - val_accuracy: 0.8359\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9670 - val_accuracy: 0.8359\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 0.9677 - val_accuracy: 0.8359\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9650 - val_accuracy: 0.8359\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9631 - val_accuracy: 0.8359\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2102 - accuracy: 0.9029 - val_loss: 0.9678 - val_accuracy: 0.8359\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9725 - val_accuracy: 0.8359\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9766 - val_accuracy: 0.8359\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9760 - val_accuracy: 0.8359\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9790 - val_accuracy: 0.8359\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9784 - val_accuracy: 0.8359\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9763 - val_accuracy: 0.8359\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9723 - val_accuracy: 0.8359\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9740 - val_accuracy: 0.8359\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9717 - val_accuracy: 0.8359\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9824 - val_accuracy: 0.8359\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9828 - val_accuracy: 0.8359\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9815 - val_accuracy: 0.8359\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9806 - val_accuracy: 0.8359\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9792 - val_accuracy: 0.8359\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9795 - val_accuracy: 0.8359\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9809 - val_accuracy: 0.8359\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9782 - val_accuracy: 0.8359\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 330us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9764 - val_accuracy: 0.8359\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9757 - val_accuracy: 0.8359\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9739 - val_accuracy: 0.8359\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9700 - val_accuracy: 0.8359\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9764 - val_accuracy: 0.8359\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9811 - val_accuracy: 0.8359\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9810 - val_accuracy: 0.8359\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9790 - val_accuracy: 0.8359\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9809 - val_accuracy: 0.8359\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9837 - val_accuracy: 0.8359\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9878 - val_accuracy: 0.8359\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9873 - val_accuracy: 0.8359\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9884 - val_accuracy: 0.8359\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9857 - val_accuracy: 0.8359\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9861 - val_accuracy: 0.8359\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2097 - accuracy: 0.8962 - val_loss: 0.9832 - val_accuracy: 0.8359\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9981 - val_accuracy: 0.8359\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9967 - val_accuracy: 0.8359\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9941 - val_accuracy: 0.8359\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9995 - val_accuracy: 0.8359\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9933 - val_accuracy: 0.8359\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9882 - val_accuracy: 0.8359\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9881 - val_accuracy: 0.8359\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9932 - val_accuracy: 0.8359\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9939 - val_accuracy: 0.8359\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9939 - val_accuracy: 0.8359\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9925 - val_accuracy: 0.8359\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 0.9885 - val_accuracy: 0.8359\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9784 - val_accuracy: 0.8359\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 1.0336 - val_accuracy: 0.8359\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9784 - val_accuracy: 0.8359\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9204 - val_accuracy: 0.8410\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.9219 - val_accuracy: 0.8410\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2107 - accuracy: 0.8962 - val_loss: 0.9229 - val_accuracy: 0.8410\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9313 - val_accuracy: 0.8410\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9263 - val_accuracy: 0.8410\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 0.9264 - val_accuracy: 0.8410\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.9312 - val_accuracy: 0.8410\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9296 - val_accuracy: 0.8410\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9307 - val_accuracy: 0.8410\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9354 - val_accuracy: 0.8410\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 0.9385 - val_accuracy: 0.8410\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9415 - val_accuracy: 0.8359\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9444 - val_accuracy: 0.8359\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9426 - val_accuracy: 0.8359\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 0.9455 - val_accuracy: 0.8359\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9480 - val_accuracy: 0.8359\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9542 - val_accuracy: 0.8359\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9520 - val_accuracy: 0.8359\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9573 - val_accuracy: 0.8359\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 0.9550 - val_accuracy: 0.8359\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9513 - val_accuracy: 0.8359\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 106us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9519 - val_accuracy: 0.8359\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9533 - val_accuracy: 0.8410\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9628 - val_accuracy: 0.8410\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 0.9672 - val_accuracy: 0.8359\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9679 - val_accuracy: 0.8359\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9706 - val_accuracy: 0.8359\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9683 - val_accuracy: 0.8359\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2071 - accuracy: 0.9029 - val_loss: 0.9705 - val_accuracy: 0.8359\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9719 - val_accuracy: 0.8359\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9713 - val_accuracy: 0.8359\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9745 - val_accuracy: 0.8359\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9737 - val_accuracy: 0.8359\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9747 - val_accuracy: 0.8359\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9691 - val_accuracy: 0.8410\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9741 - val_accuracy: 0.8410\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9764 - val_accuracy: 0.8410\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9780 - val_accuracy: 0.8359\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9824 - val_accuracy: 0.8359\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9811 - val_accuracy: 0.8359\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9818 - val_accuracy: 0.8359\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 0.9868 - val_accuracy: 0.8359\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.9984 - val_accuracy: 0.8359\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9851 - val_accuracy: 0.8359\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 0.9836 - val_accuracy: 0.8359\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9719 - val_accuracy: 0.8359\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9670 - val_accuracy: 0.8410\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9725 - val_accuracy: 0.8410\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 0.9774 - val_accuracy: 0.8410\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9800 - val_accuracy: 0.8410\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 0.9795 - val_accuracy: 0.8410\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9848 - val_accuracy: 0.8359\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 0.9824 - val_accuracy: 0.8410\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 0.9786 - val_accuracy: 0.8410\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 0.9834 - val_accuracy: 0.8410\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9868 - val_accuracy: 0.8410\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 0.9853 - val_accuracy: 0.8410\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9862 - val_accuracy: 0.8410\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9860 - val_accuracy: 0.8410\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9876 - val_accuracy: 0.8410\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 0.9858 - val_accuracy: 0.8410\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2091 - accuracy: 0.9029 - val_loss: 0.9905 - val_accuracy: 0.8410\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9891 - val_accuracy: 0.8410\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9891 - val_accuracy: 0.8410\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9893 - val_accuracy: 0.8410\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 0.9914 - val_accuracy: 0.8410\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 0.9905 - val_accuracy: 0.8410\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9948 - val_accuracy: 0.8410\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 0.9961 - val_accuracy: 0.8410\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 0.9953 - val_accuracy: 0.8410\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 0.9795 - val_accuracy: 0.8462\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9709 - val_accuracy: 0.8462\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9714 - val_accuracy: 0.8462\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 0.9717 - val_accuracy: 0.8462\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9781 - val_accuracy: 0.8462\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 0.9825 - val_accuracy: 0.8410\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 0.9967 - val_accuracy: 0.8410\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 1.0044 - val_accuracy: 0.8410\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0029 - val_accuracy: 0.8410\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0069 - val_accuracy: 0.8410\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 1.0110 - val_accuracy: 0.8410\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2068 - accuracy: 0.9029 - val_loss: 0.9960 - val_accuracy: 0.8410\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 1.0021 - val_accuracy: 0.8410\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0039 - val_accuracy: 0.8410\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 1.0175 - val_accuracy: 0.8410\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 340us/step - loss: 0.2090 - accuracy: 0.9029 - val_loss: 1.0186 - val_accuracy: 0.8410\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0231 - val_accuracy: 0.8410\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 1.0231 - val_accuracy: 0.8410\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 1.0224 - val_accuracy: 0.8410\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0194 - val_accuracy: 0.8410\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 1.0147 - val_accuracy: 0.8410\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 1.0174 - val_accuracy: 0.8410\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2100 - accuracy: 0.9029 - val_loss: 1.0251 - val_accuracy: 0.8410\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2095 - accuracy: 0.9029 - val_loss: 1.0053 - val_accuracy: 0.8410\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 1.0092 - val_accuracy: 0.8410\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0168 - val_accuracy: 0.8410\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2071 - accuracy: 0.9029 - val_loss: 1.0136 - val_accuracy: 0.8410\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 334us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 1.0181 - val_accuracy: 0.8410\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0238 - val_accuracy: 0.8410\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0182 - val_accuracy: 0.8410\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0196 - val_accuracy: 0.8410\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 1.0224 - val_accuracy: 0.8410\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0088 - val_accuracy: 0.8410\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0103 - val_accuracy: 0.8410\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2067 - accuracy: 0.9029 - val_loss: 1.0147 - val_accuracy: 0.8410\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0186 - val_accuracy: 0.8410\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0202 - val_accuracy: 0.8410\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0181 - val_accuracy: 0.8410\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0232 - val_accuracy: 0.8410\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0163 - val_accuracy: 0.8410\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0058 - val_accuracy: 0.8410\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0095 - val_accuracy: 0.8410\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0087 - val_accuracy: 0.8410\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 1.0081 - val_accuracy: 0.8410\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0080 - val_accuracy: 0.8410\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2089 - accuracy: 0.9029 - val_loss: 1.0051 - val_accuracy: 0.8410\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2070 - accuracy: 0.9029 - val_loss: 1.0083 - val_accuracy: 0.8410\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0132 - val_accuracy: 0.8410\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0123 - val_accuracy: 0.8410\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0182 - val_accuracy: 0.8410\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0157 - val_accuracy: 0.8410\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0140 - val_accuracy: 0.8410\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 1.0220 - val_accuracy: 0.8410\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0210 - val_accuracy: 0.8410\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0213 - val_accuracy: 0.8410\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0246 - val_accuracy: 0.8410\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0297 - val_accuracy: 0.8410\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2070 - accuracy: 0.9029 - val_loss: 1.0262 - val_accuracy: 0.8410\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0294 - val_accuracy: 0.8410\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0265 - val_accuracy: 0.8410\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0288 - val_accuracy: 0.8410\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 109us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0268 - val_accuracy: 0.8410\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0289 - val_accuracy: 0.8410\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0189 - val_accuracy: 0.8410\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2100 - accuracy: 0.8962 - val_loss: 1.0219 - val_accuracy: 0.8410\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0127 - val_accuracy: 0.8410\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0192 - val_accuracy: 0.8410\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2086 - accuracy: 0.9029 - val_loss: 1.0194 - val_accuracy: 0.8410\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0234 - val_accuracy: 0.8410\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0233 - val_accuracy: 0.8410\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0261 - val_accuracy: 0.8410\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0275 - val_accuracy: 0.8410\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0278 - val_accuracy: 0.8410\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0268 - val_accuracy: 0.8410\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2085 - accuracy: 0.9029 - val_loss: 1.0244 - val_accuracy: 0.8410\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0358 - val_accuracy: 0.8410\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0419 - val_accuracy: 0.8410\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0417 - val_accuracy: 0.8410\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2092 - accuracy: 0.9029 - val_loss: 1.0380 - val_accuracy: 0.8410\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0418 - val_accuracy: 0.8410\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0414 - val_accuracy: 0.8410\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0421 - val_accuracy: 0.8410\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0454 - val_accuracy: 0.8410\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0503 - val_accuracy: 0.8410\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0485 - val_accuracy: 0.8410\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0502 - val_accuracy: 0.8410\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0510 - val_accuracy: 0.8410\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 1.0341 - val_accuracy: 0.8410\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2097 - accuracy: 0.9029 - val_loss: 1.0421 - val_accuracy: 0.8410\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2126 - accuracy: 0.9029 - val_loss: 1.0307 - val_accuracy: 0.8410\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2093 - accuracy: 0.9029 - val_loss: 1.0234 - val_accuracy: 0.8410\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0245 - val_accuracy: 0.8410\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0249 - val_accuracy: 0.8410\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0359 - val_accuracy: 0.8410\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0305 - val_accuracy: 0.8410\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0228 - val_accuracy: 0.8410\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0262 - val_accuracy: 0.8410\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0297 - val_accuracy: 0.8410\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0284 - val_accuracy: 0.8410\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0353 - val_accuracy: 0.8410\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0371 - val_accuracy: 0.8410\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0351 - val_accuracy: 0.8410\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 1.0335 - val_accuracy: 0.8410\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0345 - val_accuracy: 0.8410\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0366 - val_accuracy: 0.8410\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0357 - val_accuracy: 0.8410\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2087 - accuracy: 0.9029 - val_loss: 1.0465 - val_accuracy: 0.8410\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2070 - accuracy: 0.9029 - val_loss: 1.0478 - val_accuracy: 0.8410\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0461 - val_accuracy: 0.8410\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0393 - val_accuracy: 0.8410\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0416 - val_accuracy: 0.8410\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0406 - val_accuracy: 0.8410\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2070 - accuracy: 0.9029 - val_loss: 1.0386 - val_accuracy: 0.8410\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 1.0370 - val_accuracy: 0.8410\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0367 - val_accuracy: 0.8410\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 1.0288 - val_accuracy: 0.8410\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0285 - val_accuracy: 0.8410\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0299 - val_accuracy: 0.8410\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0298 - val_accuracy: 0.8410\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0466 - val_accuracy: 0.8359\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0411 - val_accuracy: 0.8359\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 1.0378 - val_accuracy: 0.8359\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0433 - val_accuracy: 0.8359\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0489 - val_accuracy: 0.8359\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0566 - val_accuracy: 0.8359\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0562 - val_accuracy: 0.8359\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0640 - val_accuracy: 0.8359\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0651 - val_accuracy: 0.8359\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0655 - val_accuracy: 0.8359\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0707 - val_accuracy: 0.8359\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0687 - val_accuracy: 0.8359\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0691 - val_accuracy: 0.8359\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0716 - val_accuracy: 0.8359\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0733 - val_accuracy: 0.8359\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0761 - val_accuracy: 0.8359\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0792 - val_accuracy: 0.8359\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0816 - val_accuracy: 0.8359\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0807 - val_accuracy: 0.8359\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0789 - val_accuracy: 0.8359\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0778 - val_accuracy: 0.8359\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0787 - val_accuracy: 0.8359\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2083 - accuracy: 0.9029 - val_loss: 1.0862 - val_accuracy: 0.8359\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2192 - accuracy: 0.8985 - val_loss: 1.0759 - val_accuracy: 0.8359\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2096 - accuracy: 0.9029 - val_loss: 1.0642 - val_accuracy: 0.8359\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2080 - accuracy: 0.9029 - val_loss: 1.0586 - val_accuracy: 0.8359\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2082 - accuracy: 0.9029 - val_loss: 1.0651 - val_accuracy: 0.8359\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2071 - accuracy: 0.9029 - val_loss: 1.0678 - val_accuracy: 0.8359\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0721 - val_accuracy: 0.8359\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0687 - val_accuracy: 0.8359\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0742 - val_accuracy: 0.8359\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0738 - val_accuracy: 0.8359\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2084 - accuracy: 0.9029 - val_loss: 1.0748 - val_accuracy: 0.8359\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0742 - val_accuracy: 0.8359\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0697 - val_accuracy: 0.8359\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0703 - val_accuracy: 0.8359\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0684 - val_accuracy: 0.8359\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0738 - val_accuracy: 0.8359\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0723 - val_accuracy: 0.8359\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0714 - val_accuracy: 0.8359\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0766 - val_accuracy: 0.8359\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2073 - accuracy: 0.9029 - val_loss: 1.0789 - val_accuracy: 0.8359\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0708 - val_accuracy: 0.8359\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2081 - accuracy: 0.9029 - val_loss: 1.0664 - val_accuracy: 0.8359\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2078 - accuracy: 0.9029 - val_loss: 1.0717 - val_accuracy: 0.8359\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0757 - val_accuracy: 0.8359\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2072 - accuracy: 0.9029 - val_loss: 1.0694 - val_accuracy: 0.8359\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2071 - accuracy: 0.9029 - val_loss: 1.0703 - val_accuracy: 0.8359\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0727 - val_accuracy: 0.8359\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2076 - accuracy: 0.9029 - val_loss: 1.0743 - val_accuracy: 0.8359\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2088 - accuracy: 0.9029 - val_loss: 1.0770 - val_accuracy: 0.8359\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2075 - accuracy: 0.9029 - val_loss: 1.0822 - val_accuracy: 0.8359\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 116us/step - loss: 0.2074 - accuracy: 0.9029 - val_loss: 1.0765 - val_accuracy: 0.8359\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2079 - accuracy: 0.9029 - val_loss: 1.0677 - val_accuracy: 0.8359\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2169 - accuracy: 0.9007 - val_loss: 1.0916 - val_accuracy: 0.8359\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2215 - accuracy: 0.8940 - val_loss: 0.9710 - val_accuracy: 0.8359\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2162 - accuracy: 0.8962 - val_loss: 1.2147 - val_accuracy: 0.8308\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2121 - accuracy: 0.9007 - val_loss: 1.1810 - val_accuracy: 0.8359\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2097 - accuracy: 0.8962 - val_loss: 1.1055 - val_accuracy: 0.8359\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2398 - accuracy: 0.8985 - val_loss: 1.0930 - val_accuracy: 0.8410\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2127 - accuracy: 0.9029 - val_loss: 1.0874 - val_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 90.25%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [6.98847400e-01, 3.01152560e-01, 3.43667070e-09],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [6.98847400e-01, 3.01152560e-01, 3.43667070e-09],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [2.33792620e-01, 7.66207400e-01, 5.95347200e-09],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [9.98750570e-01, 1.24946660e-03, 4.06917600e-13],\n",
       "       [3.72321800e-01, 6.27678100e-01, 1.94591080e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.35332600e-06, 9.99995000e-01, 5.48875050e-07],\n",
       "       [2.77235500e-06, 9.99997260e-01, 1.30482900e-12],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [2.98483840e-06, 9.99997000e-01, 1.51863880e-20],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [9.29642200e-01, 7.03577200e-02, 7.21419200e-11],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [9.99999900e-01, 1.55937870e-07, 4.84160950e-23],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.24449700e-33, 1.00000000e+00, 1.42923830e-26],\n",
       "       [1.04752650e-09, 1.00000000e+00, 4.20704500e-14],\n",
       "       [3.94368380e-01, 6.05631600e-01, 2.84310660e-08],\n",
       "       [1.40579100e-07, 9.99999900e-01, 4.79222060e-37],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.40579100e-07, 9.99999900e-01, 4.79222060e-37],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.73609470e-32, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.40579100e-07, 9.99999900e-01, 4.79222060e-37],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.61068260e-05, 9.99982700e-01, 1.22758550e-06],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [6.98847400e-01, 3.01152560e-01, 3.43667070e-09],\n",
       "       [9.99999900e-01, 1.61743540e-07, 1.98139450e-20],\n",
       "       [3.72321800e-01, 6.27678100e-01, 1.94591080e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [9.99729600e-01, 2.70446400e-04, 3.38018100e-17],\n",
       "       [2.98483840e-06, 9.99997000e-01, 1.51863880e-20],\n",
       "       [9.99941700e-01, 5.83472720e-05, 1.20157620e-16],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [3.72321800e-01, 6.27678100e-01, 1.94591080e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [9.98750570e-01, 1.24946660e-03, 4.06917600e-13],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.44232235e-08, 1.98445280e-18],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [3.94368380e-01, 6.05631600e-01, 2.84310660e-08],\n",
       "       [3.60075440e-01, 6.39924650e-01, 2.21999900e-08],\n",
       "       [3.60075440e-01, 6.39924650e-01, 2.21999900e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [2.04742380e-07, 9.99999760e-01, 4.45507570e-17],\n",
       "       [1.54305090e-04, 9.99845600e-01, 0.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [5.67814700e-04, 9.99432150e-01, 4.61764200e-16],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [9.99729600e-01, 2.70446400e-04, 3.38018100e-17],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [9.99996660e-01, 3.31263410e-06, 1.29198860e-18],\n",
       "       [3.60075440e-01, 6.39924650e-01, 2.21999900e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [9.99710400e-01, 2.89579100e-04, 2.25359340e-17],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [5.04720670e-06, 9.99995000e-01, 1.25927230e-27],\n",
       "       [6.98847400e-01, 3.01152560e-01, 3.43667070e-09],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.61755180e-10, 1.00000000e+00, 1.50583410e-16],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [2.31144780e-10, 1.00000000e+00, 0.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [3.72321800e-01, 6.27678100e-01, 1.94591080e-08],\n",
       "       [1.00000000e+00, 5.29650460e-12, 1.18715920e-28],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [2.98483840e-06, 9.99997000e-01, 1.51863880e-20],\n",
       "       [2.31144780e-10, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [9.99986650e-01, 1.33054500e-05, 1.59845460e-09],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [3.44592950e-12, 1.00000000e+00, 8.35668900e-37],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [9.99690900e-01, 3.09179400e-04, 1.66537620e-16],\n",
       "       [9.86843650e-01, 1.31563395e-02, 3.16986830e-10],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.28779220e-11, 2.27549010e-18],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.61755180e-10, 1.00000000e+00, 1.50583410e-16],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.00000000e+00, 1.44232235e-08, 1.98445280e-18],\n",
       "       [2.73554850e-02, 9.72644570e-01, 2.41474000e-08],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [8.31384500e-01, 1.68615500e-01, 2.98227470e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [2.33792620e-01, 7.66207400e-01, 5.95347200e-09],\n",
       "       [9.29642200e-01, 7.03577200e-02, 7.21419200e-11],\n",
       "       [1.61068260e-05, 9.99982700e-01, 1.22758550e-06],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.11618440e-01, 8.88381600e-01, 3.78296560e-11],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [2.23462400e-01, 7.76535750e-01, 1.86544140e-06],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [1.04752650e-09, 1.00000000e+00, 4.20704500e-14],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [1.11618440e-01, 8.88381600e-01, 3.78296560e-11],\n",
       "       [2.23462400e-01, 7.76535750e-01, 1.86544140e-06],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [9.94866130e-01, 5.13378200e-03, 2.10528640e-13],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [5.04720670e-06, 9.99995000e-01, 1.25927230e-27],\n",
       "       [1.28894920e-09, 9.42066600e-09, 1.00000000e+00],\n",
       "       [3.60075440e-01, 6.39924650e-01, 2.21999900e-08],\n",
       "       [3.72321800e-01, 6.27678100e-01, 1.94591080e-08],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [4.19451030e-08, 7.50823100e-09, 1.00000000e+00],\n",
       "       [7.37280000e-01, 2.62720000e-01, 4.19774800e-08],\n",
       "       [3.94368380e-01, 6.05631600e-01, 2.84310660e-08]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471005917159764"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471005917159764"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa119     0\n",
       "1         NRS001     1\n",
       "2         NRS074     0\n",
       "3         NRS209     2\n",
       "4          GA231     0\n",
       "..           ...   ...\n",
       "190       NRS252     0\n",
       "191       SR2852     1\n",
       "192       NRS108     1\n",
       "193       NRS202     0\n",
       "194       NRS110     2\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 475us/step - loss: 1.0587 - accuracy: 0.3996 - val_loss: 0.8505 - val_accuracy: 0.6051\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.7732 - accuracy: 0.7064 - val_loss: 0.6637 - val_accuracy: 0.7692\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.6416 - accuracy: 0.7903 - val_loss: 0.5771 - val_accuracy: 0.7846\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.5760 - accuracy: 0.7682 - val_loss: 0.5196 - val_accuracy: 0.8564\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.5138 - accuracy: 0.7837 - val_loss: 0.4645 - val_accuracy: 0.8051\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.4688 - accuracy: 0.7991 - val_loss: 0.4320 - val_accuracy: 0.8103\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.4426 - accuracy: 0.7837 - val_loss: 0.4070 - val_accuracy: 0.8359\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.4253 - accuracy: 0.7991 - val_loss: 0.3938 - val_accuracy: 0.8513\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.4012 - accuracy: 0.8190 - val_loss: 0.4099 - val_accuracy: 0.7744\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.4071 - accuracy: 0.7903 - val_loss: 0.3729 - val_accuracy: 0.8154\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.3937 - accuracy: 0.8124 - val_loss: 0.3665 - val_accuracy: 0.8154\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.3826 - accuracy: 0.7947 - val_loss: 0.3618 - val_accuracy: 0.8410\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.3764 - accuracy: 0.8079 - val_loss: 0.3694 - val_accuracy: 0.8154\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.3716 - accuracy: 0.8168 - val_loss: 0.3560 - val_accuracy: 0.8359\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.3695 - accuracy: 0.8256 - val_loss: 0.3570 - val_accuracy: 0.8205\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.3672 - accuracy: 0.8300 - val_loss: 0.3509 - val_accuracy: 0.8359\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.3629 - accuracy: 0.8124 - val_loss: 0.3456 - val_accuracy: 0.8410\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.3550 - accuracy: 0.8190 - val_loss: 0.3481 - val_accuracy: 0.8256\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.3517 - accuracy: 0.8278 - val_loss: 0.3425 - val_accuracy: 0.8308\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.3495 - accuracy: 0.8212 - val_loss: 0.3463 - val_accuracy: 0.8256\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 379us/step - loss: 0.3482 - accuracy: 0.8322 - val_loss: 0.3432 - val_accuracy: 0.8256\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.3448 - accuracy: 0.8278 - val_loss: 0.3367 - val_accuracy: 0.8410\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.3409 - accuracy: 0.8212 - val_loss: 0.3360 - val_accuracy: 0.8462\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.3392 - accuracy: 0.8278 - val_loss: 0.3336 - val_accuracy: 0.8462\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.3386 - accuracy: 0.8300 - val_loss: 0.3429 - val_accuracy: 0.8154\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.3366 - accuracy: 0.8344 - val_loss: 0.3301 - val_accuracy: 0.8308\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.3449 - accuracy: 0.8278 - val_loss: 0.3306 - val_accuracy: 0.8359\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.3354 - accuracy: 0.8256 - val_loss: 0.3282 - val_accuracy: 0.8513\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.3331 - accuracy: 0.8344 - val_loss: 0.3267 - val_accuracy: 0.8513\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.3311 - accuracy: 0.8433 - val_loss: 0.3254 - val_accuracy: 0.8359\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.3277 - accuracy: 0.8455 - val_loss: 0.3257 - val_accuracy: 0.8462\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.3276 - accuracy: 0.8366 - val_loss: 0.3237 - val_accuracy: 0.8359\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.3246 - accuracy: 0.8344 - val_loss: 0.3468 - val_accuracy: 0.8051\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.3289 - accuracy: 0.8411 - val_loss: 0.3187 - val_accuracy: 0.8564\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.3175 - accuracy: 0.8344 - val_loss: 0.3214 - val_accuracy: 0.8513\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.3244 - accuracy: 0.8455 - val_loss: 0.3212 - val_accuracy: 0.8615\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.3159 - accuracy: 0.8411 - val_loss: 0.3185 - val_accuracy: 0.8410\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.3161 - accuracy: 0.8389 - val_loss: 0.3187 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.3211 - accuracy: 0.8521 - val_loss: 0.3151 - val_accuracy: 0.8564\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.3136 - accuracy: 0.8433 - val_loss: 0.3265 - val_accuracy: 0.8410\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.3062 - accuracy: 0.8477 - val_loss: 0.3175 - val_accuracy: 0.8513\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.3074 - accuracy: 0.8477 - val_loss: 0.3171 - val_accuracy: 0.8513\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.3065 - accuracy: 0.8455 - val_loss: 0.3163 - val_accuracy: 0.8462\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.3064 - accuracy: 0.8411 - val_loss: 0.3106 - val_accuracy: 0.8564\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.3085 - accuracy: 0.8433 - val_loss: 0.3104 - val_accuracy: 0.8513\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.3020 - accuracy: 0.8322 - val_loss: 0.3120 - val_accuracy: 0.8513\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2984 - accuracy: 0.8344 - val_loss: 0.3159 - val_accuracy: 0.8410\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2970 - accuracy: 0.8521 - val_loss: 0.3096 - val_accuracy: 0.8462\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.3095 - accuracy: 0.8344 - val_loss: 0.3080 - val_accuracy: 0.8410\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2976 - accuracy: 0.8433 - val_loss: 0.3063 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2943 - accuracy: 0.8477 - val_loss: 0.3060 - val_accuracy: 0.8359\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2934 - accuracy: 0.8521 - val_loss: 0.3126 - val_accuracy: 0.8410\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2979 - accuracy: 0.8455 - val_loss: 0.3135 - val_accuracy: 0.8462\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2938 - accuracy: 0.8521 - val_loss: 0.3224 - val_accuracy: 0.8308\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2988 - accuracy: 0.8499 - val_loss: 0.3035 - val_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2918 - accuracy: 0.8411 - val_loss: 0.3045 - val_accuracy: 0.8410\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2905 - accuracy: 0.8455 - val_loss: 0.3011 - val_accuracy: 0.8615\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 315us/step - loss: 0.2881 - accuracy: 0.8543 - val_loss: 0.3018 - val_accuracy: 0.8410\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2926 - accuracy: 0.8521 - val_loss: 0.3091 - val_accuracy: 0.8410\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2921 - accuracy: 0.8587 - val_loss: 0.3000 - val_accuracy: 0.8513\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2900 - accuracy: 0.8587 - val_loss: 0.2975 - val_accuracy: 0.8615\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2871 - accuracy: 0.8477 - val_loss: 0.3016 - val_accuracy: 0.8513\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2925 - accuracy: 0.8521 - val_loss: 0.2977 - val_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2839 - accuracy: 0.8609 - val_loss: 0.3031 - val_accuracy: 0.8513\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2846 - accuracy: 0.8521 - val_loss: 0.3000 - val_accuracy: 0.8462\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2849 - accuracy: 0.8565 - val_loss: 0.3027 - val_accuracy: 0.8410\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2800 - accuracy: 0.8587 - val_loss: 0.2995 - val_accuracy: 0.8564\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2874 - accuracy: 0.8543 - val_loss: 0.2971 - val_accuracy: 0.8564\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2804 - accuracy: 0.8675 - val_loss: 0.3087 - val_accuracy: 0.8410\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2861 - accuracy: 0.8720 - val_loss: 0.3048 - val_accuracy: 0.8410\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2892 - accuracy: 0.8543 - val_loss: 0.2993 - val_accuracy: 0.8513\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2845 - accuracy: 0.8609 - val_loss: 0.3066 - val_accuracy: 0.8564\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2862 - accuracy: 0.8631 - val_loss: 0.2966 - val_accuracy: 0.8462\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2865 - accuracy: 0.8631 - val_loss: 0.2932 - val_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2791 - accuracy: 0.8565 - val_loss: 0.3015 - val_accuracy: 0.8410\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2835 - accuracy: 0.8565 - val_loss: 0.2940 - val_accuracy: 0.8615\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2778 - accuracy: 0.8587 - val_loss: 0.2983 - val_accuracy: 0.8564\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2927 - accuracy: 0.8389 - val_loss: 0.3173 - val_accuracy: 0.8308\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2842 - accuracy: 0.8631 - val_loss: 0.3008 - val_accuracy: 0.8410\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2793 - accuracy: 0.8609 - val_loss: 0.2898 - val_accuracy: 0.8564\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2749 - accuracy: 0.8631 - val_loss: 0.2924 - val_accuracy: 0.8513\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2789 - accuracy: 0.8609 - val_loss: 0.2901 - val_accuracy: 0.8564\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2783 - accuracy: 0.8543 - val_loss: 0.2890 - val_accuracy: 0.8564\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2895 - accuracy: 0.8587 - val_loss: 0.2960 - val_accuracy: 0.8410\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2790 - accuracy: 0.8565 - val_loss: 0.2972 - val_accuracy: 0.8462\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2734 - accuracy: 0.8587 - val_loss: 0.2872 - val_accuracy: 0.8615\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2751 - accuracy: 0.8653 - val_loss: 0.2945 - val_accuracy: 0.8410\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2772 - accuracy: 0.8565 - val_loss: 0.2901 - val_accuracy: 0.8462\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2726 - accuracy: 0.8653 - val_loss: 0.2862 - val_accuracy: 0.8615\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2708 - accuracy: 0.8720 - val_loss: 0.2904 - val_accuracy: 0.8513\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2775 - accuracy: 0.8587 - val_loss: 0.2871 - val_accuracy: 0.8615\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2728 - accuracy: 0.8653 - val_loss: 0.3401 - val_accuracy: 0.8205\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2865 - accuracy: 0.8565 - val_loss: 0.2880 - val_accuracy: 0.8615\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2698 - accuracy: 0.8720 - val_loss: 0.2866 - val_accuracy: 0.8615\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2728 - accuracy: 0.8653 - val_loss: 0.2843 - val_accuracy: 0.8615\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2739 - accuracy: 0.8764 - val_loss: 0.2846 - val_accuracy: 0.8615\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2712 - accuracy: 0.8565 - val_loss: 0.2863 - val_accuracy: 0.8513\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2691 - accuracy: 0.8521 - val_loss: 0.2864 - val_accuracy: 0.8615\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2693 - accuracy: 0.8675 - val_loss: 0.2984 - val_accuracy: 0.8564\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2741 - accuracy: 0.8631 - val_loss: 0.2859 - val_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2686 - accuracy: 0.8653 - val_loss: 0.2837 - val_accuracy: 0.8615\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2738 - accuracy: 0.8698 - val_loss: 0.2869 - val_accuracy: 0.8513\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2707 - accuracy: 0.8587 - val_loss: 0.2829 - val_accuracy: 0.8513\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2672 - accuracy: 0.8653 - val_loss: 0.2866 - val_accuracy: 0.8615\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2722 - accuracy: 0.8742 - val_loss: 0.2832 - val_accuracy: 0.8564\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2688 - accuracy: 0.8698 - val_loss: 0.2844 - val_accuracy: 0.8615\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2722 - accuracy: 0.8698 - val_loss: 0.2860 - val_accuracy: 0.8615\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2686 - accuracy: 0.8675 - val_loss: 0.2832 - val_accuracy: 0.8564\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2673 - accuracy: 0.8720 - val_loss: 0.2836 - val_accuracy: 0.8615\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2657 - accuracy: 0.8720 - val_loss: 0.2822 - val_accuracy: 0.8564\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2784 - accuracy: 0.8653 - val_loss: 0.2842 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2963 - accuracy: 0.8389 - val_loss: 0.2814 - val_accuracy: 0.8615\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2658 - accuracy: 0.8720 - val_loss: 0.2854 - val_accuracy: 0.8564\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2647 - accuracy: 0.8720 - val_loss: 0.2824 - val_accuracy: 0.8615\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2705 - accuracy: 0.8675 - val_loss: 0.2809 - val_accuracy: 0.8615\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2686 - accuracy: 0.8675 - val_loss: 0.2871 - val_accuracy: 0.8667\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2671 - accuracy: 0.8786 - val_loss: 0.2860 - val_accuracy: 0.8410\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2636 - accuracy: 0.8587 - val_loss: 0.2834 - val_accuracy: 0.8615\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2666 - accuracy: 0.8587 - val_loss: 0.2832 - val_accuracy: 0.8513\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2623 - accuracy: 0.8675 - val_loss: 0.2858 - val_accuracy: 0.8410\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2649 - accuracy: 0.8609 - val_loss: 0.2821 - val_accuracy: 0.8615\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2667 - accuracy: 0.8742 - val_loss: 0.2893 - val_accuracy: 0.8462\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2682 - accuracy: 0.8675 - val_loss: 0.2827 - val_accuracy: 0.8667\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2624 - accuracy: 0.8720 - val_loss: 0.2954 - val_accuracy: 0.8462\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2651 - accuracy: 0.8587 - val_loss: 0.2824 - val_accuracy: 0.8513\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2626 - accuracy: 0.8609 - val_loss: 0.2826 - val_accuracy: 0.8615\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2622 - accuracy: 0.8720 - val_loss: 0.2886 - val_accuracy: 0.8615\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2636 - accuracy: 0.8675 - val_loss: 0.2802 - val_accuracy: 0.8564\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2613 - accuracy: 0.8675 - val_loss: 0.2847 - val_accuracy: 0.8615\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2627 - accuracy: 0.8764 - val_loss: 0.2794 - val_accuracy: 0.8513\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2663 - accuracy: 0.8653 - val_loss: 0.2805 - val_accuracy: 0.8667\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2642 - accuracy: 0.8675 - val_loss: 0.2812 - val_accuracy: 0.8615\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2679 - accuracy: 0.8764 - val_loss: 0.2873 - val_accuracy: 0.8667\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2725 - accuracy: 0.8499 - val_loss: 0.2777 - val_accuracy: 0.8615\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2599 - accuracy: 0.8742 - val_loss: 0.3023 - val_accuracy: 0.8410\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2725 - accuracy: 0.8653 - val_loss: 0.2869 - val_accuracy: 0.8564\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2599 - accuracy: 0.8742 - val_loss: 0.2788 - val_accuracy: 0.8513\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2628 - accuracy: 0.8742 - val_loss: 0.2786 - val_accuracy: 0.8564\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2626 - accuracy: 0.8698 - val_loss: 0.2807 - val_accuracy: 0.8564\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2588 - accuracy: 0.8786 - val_loss: 0.3248 - val_accuracy: 0.8359\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2811 - accuracy: 0.8720 - val_loss: 0.2815 - val_accuracy: 0.8615\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2668 - accuracy: 0.8698 - val_loss: 0.2850 - val_accuracy: 0.8564\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2586 - accuracy: 0.8764 - val_loss: 0.2800 - val_accuracy: 0.8615\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2614 - accuracy: 0.8764 - val_loss: 0.2748 - val_accuracy: 0.8615\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2606 - accuracy: 0.8698 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2618 - accuracy: 0.8587 - val_loss: 0.2827 - val_accuracy: 0.8667\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2633 - accuracy: 0.8742 - val_loss: 0.2764 - val_accuracy: 0.8667\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2606 - accuracy: 0.8698 - val_loss: 0.2811 - val_accuracy: 0.8615\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2598 - accuracy: 0.8720 - val_loss: 0.2752 - val_accuracy: 0.8615\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2636 - accuracy: 0.8675 - val_loss: 0.2782 - val_accuracy: 0.8667\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2614 - accuracy: 0.8764 - val_loss: 0.2771 - val_accuracy: 0.8615\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2600 - accuracy: 0.8675 - val_loss: 0.2779 - val_accuracy: 0.8615\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2631 - accuracy: 0.8653 - val_loss: 0.2784 - val_accuracy: 0.8513\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2574 - accuracy: 0.8653 - val_loss: 0.2807 - val_accuracy: 0.8564\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2613 - accuracy: 0.8698 - val_loss: 0.2778 - val_accuracy: 0.8564\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2549 - accuracy: 0.8742 - val_loss: 0.2784 - val_accuracy: 0.8615\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2599 - accuracy: 0.8653 - val_loss: 0.2801 - val_accuracy: 0.8513\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2589 - accuracy: 0.8720 - val_loss: 0.2787 - val_accuracy: 0.8615\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2597 - accuracy: 0.8720 - val_loss: 0.2765 - val_accuracy: 0.8564\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2564 - accuracy: 0.8742 - val_loss: 0.2754 - val_accuracy: 0.8667\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2578 - accuracy: 0.8720 - val_loss: 0.2784 - val_accuracy: 0.8615\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2560 - accuracy: 0.8720 - val_loss: 0.2822 - val_accuracy: 0.8564\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2576 - accuracy: 0.8742 - val_loss: 0.2793 - val_accuracy: 0.8615\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2604 - accuracy: 0.8764 - val_loss: 0.2788 - val_accuracy: 0.8564\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2580 - accuracy: 0.8587 - val_loss: 0.2777 - val_accuracy: 0.8667\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2589 - accuracy: 0.8609 - val_loss: 0.2791 - val_accuracy: 0.8615\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2596 - accuracy: 0.8720 - val_loss: 0.3078 - val_accuracy: 0.8359\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2713 - accuracy: 0.8653 - val_loss: 0.2944 - val_accuracy: 0.8410\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2574 - accuracy: 0.8742 - val_loss: 0.2888 - val_accuracy: 0.8667\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2536 - accuracy: 0.8742 - val_loss: 0.2812 - val_accuracy: 0.8564\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2604 - accuracy: 0.8742 - val_loss: 0.2775 - val_accuracy: 0.8564\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2546 - accuracy: 0.8698 - val_loss: 0.2851 - val_accuracy: 0.8564\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2584 - accuracy: 0.8675 - val_loss: 0.2986 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2553 - accuracy: 0.8742 - val_loss: 0.2815 - val_accuracy: 0.8615\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2563 - accuracy: 0.8764 - val_loss: 0.2781 - val_accuracy: 0.8615\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2562 - accuracy: 0.8764 - val_loss: 0.2782 - val_accuracy: 0.8615\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2556 - accuracy: 0.8675 - val_loss: 0.2752 - val_accuracy: 0.8615\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2552 - accuracy: 0.8720 - val_loss: 0.2740 - val_accuracy: 0.8615\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2616 - accuracy: 0.8742 - val_loss: 0.2756 - val_accuracy: 0.8667\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2531 - accuracy: 0.8720 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2559 - accuracy: 0.8742 - val_loss: 0.2770 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2544 - accuracy: 0.8720 - val_loss: 0.2769 - val_accuracy: 0.8564\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2548 - accuracy: 0.8698 - val_loss: 0.2755 - val_accuracy: 0.8667\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2552 - accuracy: 0.8742 - val_loss: 0.2809 - val_accuracy: 0.8564\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2610 - accuracy: 0.8698 - val_loss: 0.2792 - val_accuracy: 0.8615\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2568 - accuracy: 0.8675 - val_loss: 0.2775 - val_accuracy: 0.8667\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2566 - accuracy: 0.8631 - val_loss: 0.2774 - val_accuracy: 0.8564\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2540 - accuracy: 0.8764 - val_loss: 0.2793 - val_accuracy: 0.8564\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2546 - accuracy: 0.8698 - val_loss: 0.2764 - val_accuracy: 0.8513\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2537 - accuracy: 0.8631 - val_loss: 0.2743 - val_accuracy: 0.8667\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2534 - accuracy: 0.8742 - val_loss: 0.2767 - val_accuracy: 0.8564\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2540 - accuracy: 0.8698 - val_loss: 0.2751 - val_accuracy: 0.8564\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2536 - accuracy: 0.8587 - val_loss: 0.2797 - val_accuracy: 0.8564\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2582 - accuracy: 0.8653 - val_loss: 0.2779 - val_accuracy: 0.8615\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2564 - accuracy: 0.8631 - val_loss: 0.2837 - val_accuracy: 0.8564\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2530 - accuracy: 0.8653 - val_loss: 0.2853 - val_accuracy: 0.8667\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2525 - accuracy: 0.8720 - val_loss: 0.2790 - val_accuracy: 0.8564\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2517 - accuracy: 0.8742 - val_loss: 0.2778 - val_accuracy: 0.8615\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2549 - accuracy: 0.8742 - val_loss: 0.2811 - val_accuracy: 0.8564\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2514 - accuracy: 0.8720 - val_loss: 0.2784 - val_accuracy: 0.8667\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2528 - accuracy: 0.8764 - val_loss: 0.2802 - val_accuracy: 0.8615\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2505 - accuracy: 0.8675 - val_loss: 0.2852 - val_accuracy: 0.8564\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2516 - accuracy: 0.8653 - val_loss: 0.2819 - val_accuracy: 0.8615\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2550 - accuracy: 0.8631 - val_loss: 0.2766 - val_accuracy: 0.8667\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2554 - accuracy: 0.8742 - val_loss: 0.2890 - val_accuracy: 0.8410\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2530 - accuracy: 0.8698 - val_loss: 0.2848 - val_accuracy: 0.8564\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2547 - accuracy: 0.8764 - val_loss: 0.2794 - val_accuracy: 0.8564\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2566 - accuracy: 0.8764 - val_loss: 0.2806 - val_accuracy: 0.8667\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2542 - accuracy: 0.8764 - val_loss: 0.2741 - val_accuracy: 0.8667\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2516 - accuracy: 0.8631 - val_loss: 0.2761 - val_accuracy: 0.8513\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2576 - accuracy: 0.8786 - val_loss: 0.2824 - val_accuracy: 0.8615\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2574 - accuracy: 0.8698 - val_loss: 0.2762 - val_accuracy: 0.8615\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2502 - accuracy: 0.8720 - val_loss: 0.2763 - val_accuracy: 0.8667\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2560 - accuracy: 0.8675 - val_loss: 0.2758 - val_accuracy: 0.8667\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2602 - accuracy: 0.8720 - val_loss: 0.2749 - val_accuracy: 0.8564\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2520 - accuracy: 0.8786 - val_loss: 0.2767 - val_accuracy: 0.8615\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2530 - accuracy: 0.8720 - val_loss: 0.2722 - val_accuracy: 0.8667\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2570 - accuracy: 0.8675 - val_loss: 0.2952 - val_accuracy: 0.8923\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2692 - accuracy: 0.8477 - val_loss: 0.2774 - val_accuracy: 0.8564\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2595 - accuracy: 0.8675 - val_loss: 0.2800 - val_accuracy: 0.8564\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2519 - accuracy: 0.8764 - val_loss: 0.2756 - val_accuracy: 0.8667\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 140us/step - loss: 0.2499 - accuracy: 0.8742 - val_loss: 0.2732 - val_accuracy: 0.8667\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2528 - accuracy: 0.8675 - val_loss: 0.2750 - val_accuracy: 0.8564\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2542 - accuracy: 0.8698 - val_loss: 0.2810 - val_accuracy: 0.8615\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2512 - accuracy: 0.8720 - val_loss: 0.2752 - val_accuracy: 0.8615\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2530 - accuracy: 0.8675 - val_loss: 0.2750 - val_accuracy: 0.8615\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2499 - accuracy: 0.8764 - val_loss: 0.2781 - val_accuracy: 0.8615\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2535 - accuracy: 0.8698 - val_loss: 0.2964 - val_accuracy: 0.8410\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2564 - accuracy: 0.8675 - val_loss: 0.2802 - val_accuracy: 0.8513\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2576 - accuracy: 0.8653 - val_loss: 0.2750 - val_accuracy: 0.8615\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2520 - accuracy: 0.8698 - val_loss: 0.2760 - val_accuracy: 0.8564\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2510 - accuracy: 0.8808 - val_loss: 0.2761 - val_accuracy: 0.8667\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 453us/step - loss: 0.2516 - accuracy: 0.8786 - val_loss: 0.2753 - val_accuracy: 0.8564\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2494 - accuracy: 0.8742 - val_loss: 0.2815 - val_accuracy: 0.8615\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2529 - accuracy: 0.8720 - val_loss: 0.2794 - val_accuracy: 0.8615\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2531 - accuracy: 0.8720 - val_loss: 0.2756 - val_accuracy: 0.8564\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2542 - accuracy: 0.8653 - val_loss: 0.2835 - val_accuracy: 0.8564\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2559 - accuracy: 0.8698 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2526 - accuracy: 0.8830 - val_loss: 0.2764 - val_accuracy: 0.8615\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2519 - accuracy: 0.8698 - val_loss: 0.2741 - val_accuracy: 0.8667\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2498 - accuracy: 0.8609 - val_loss: 0.2808 - val_accuracy: 0.8667\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2573 - accuracy: 0.8786 - val_loss: 0.2765 - val_accuracy: 0.8615\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2474 - accuracy: 0.8720 - val_loss: 0.2783 - val_accuracy: 0.8615\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2484 - accuracy: 0.8764 - val_loss: 0.2866 - val_accuracy: 0.8667\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2585 - accuracy: 0.8786 - val_loss: 0.2755 - val_accuracy: 0.8615\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2483 - accuracy: 0.8786 - val_loss: 0.2736 - val_accuracy: 0.8667\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2613 - accuracy: 0.8565 - val_loss: 0.2777 - val_accuracy: 0.8615\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2466 - accuracy: 0.8764 - val_loss: 0.2721 - val_accuracy: 0.8667\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2596 - accuracy: 0.8698 - val_loss: 0.2854 - val_accuracy: 0.8564\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2549 - accuracy: 0.8698 - val_loss: 0.2796 - val_accuracy: 0.8513\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2540 - accuracy: 0.8742 - val_loss: 0.2775 - val_accuracy: 0.8513\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2529 - accuracy: 0.8742 - val_loss: 0.2790 - val_accuracy: 0.8564\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2507 - accuracy: 0.8675 - val_loss: 0.2767 - val_accuracy: 0.8615\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2444 - accuracy: 0.8808 - val_loss: 0.2832 - val_accuracy: 0.8564\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2501 - accuracy: 0.8786 - val_loss: 0.2790 - val_accuracy: 0.8615\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2572 - accuracy: 0.8764 - val_loss: 0.2770 - val_accuracy: 0.8667\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2487 - accuracy: 0.8698 - val_loss: 0.2736 - val_accuracy: 0.8667\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2522 - accuracy: 0.8808 - val_loss: 0.2987 - val_accuracy: 0.8923\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2537 - accuracy: 0.8742 - val_loss: 0.2776 - val_accuracy: 0.8513\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2492 - accuracy: 0.8675 - val_loss: 0.2741 - val_accuracy: 0.8667\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2504 - accuracy: 0.8742 - val_loss: 0.2847 - val_accuracy: 0.8667\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2588 - accuracy: 0.8675 - val_loss: 0.2772 - val_accuracy: 0.8615\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2497 - accuracy: 0.8653 - val_loss: 0.2766 - val_accuracy: 0.8615\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2522 - accuracy: 0.8698 - val_loss: 0.2753 - val_accuracy: 0.8513\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2493 - accuracy: 0.8653 - val_loss: 0.2761 - val_accuracy: 0.8513\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2667 - accuracy: 0.8300 - val_loss: 0.2722 - val_accuracy: 0.8667\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2612 - accuracy: 0.8675 - val_loss: 0.2793 - val_accuracy: 0.8615\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2474 - accuracy: 0.8698 - val_loss: 0.2737 - val_accuracy: 0.8615\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2462 - accuracy: 0.8764 - val_loss: 0.2739 - val_accuracy: 0.8615\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2506 - accuracy: 0.8742 - val_loss: 0.2713 - val_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2512 - accuracy: 0.8698 - val_loss: 0.2733 - val_accuracy: 0.8667\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2481 - accuracy: 0.8742 - val_loss: 0.2713 - val_accuracy: 0.8667\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2595 - accuracy: 0.8653 - val_loss: 0.2691 - val_accuracy: 0.8667\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2532 - accuracy: 0.8653 - val_loss: 0.2684 - val_accuracy: 0.8667\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2471 - accuracy: 0.8653 - val_loss: 0.2751 - val_accuracy: 0.8615\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2470 - accuracy: 0.8808 - val_loss: 0.2767 - val_accuracy: 0.8615\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2447 - accuracy: 0.8653 - val_loss: 0.2739 - val_accuracy: 0.8615\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2499 - accuracy: 0.8764 - val_loss: 0.2749 - val_accuracy: 0.8615\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2486 - accuracy: 0.8742 - val_loss: 0.2722 - val_accuracy: 0.8615\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2500 - accuracy: 0.8830 - val_loss: 0.2742 - val_accuracy: 0.8615\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2483 - accuracy: 0.8808 - val_loss: 0.2718 - val_accuracy: 0.8667\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2490 - accuracy: 0.8764 - val_loss: 0.2728 - val_accuracy: 0.8615\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2500 - accuracy: 0.8609 - val_loss: 0.2895 - val_accuracy: 0.8564\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2495 - accuracy: 0.8808 - val_loss: 0.2727 - val_accuracy: 0.8564\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2523 - accuracy: 0.8720 - val_loss: 0.2821 - val_accuracy: 0.8564\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2459 - accuracy: 0.8720 - val_loss: 0.2711 - val_accuracy: 0.8667\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2485 - accuracy: 0.8808 - val_loss: 0.2723 - val_accuracy: 0.8667\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2449 - accuracy: 0.8720 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2470 - accuracy: 0.8764 - val_loss: 0.2739 - val_accuracy: 0.8615\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2511 - accuracy: 0.8698 - val_loss: 0.2733 - val_accuracy: 0.8615\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2504 - accuracy: 0.8720 - val_loss: 0.2719 - val_accuracy: 0.8667\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2473 - accuracy: 0.8742 - val_loss: 0.2715 - val_accuracy: 0.8667\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2464 - accuracy: 0.8764 - val_loss: 0.2731 - val_accuracy: 0.8615\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2444 - accuracy: 0.8698 - val_loss: 0.2733 - val_accuracy: 0.8513\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2573 - accuracy: 0.8720 - val_loss: 0.2779 - val_accuracy: 0.8923\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2497 - accuracy: 0.8764 - val_loss: 0.2703 - val_accuracy: 0.8667\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2466 - accuracy: 0.8720 - val_loss: 0.2762 - val_accuracy: 0.8615\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2501 - accuracy: 0.8808 - val_loss: 0.2747 - val_accuracy: 0.8513\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2459 - accuracy: 0.8764 - val_loss: 0.2706 - val_accuracy: 0.8667\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2452 - accuracy: 0.8786 - val_loss: 0.2717 - val_accuracy: 0.8615\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2481 - accuracy: 0.8742 - val_loss: 0.2716 - val_accuracy: 0.8667\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2445 - accuracy: 0.8653 - val_loss: 0.2781 - val_accuracy: 0.8513\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2474 - accuracy: 0.8675 - val_loss: 0.2857 - val_accuracy: 0.8615\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2481 - accuracy: 0.8786 - val_loss: 0.2694 - val_accuracy: 0.8667\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2452 - accuracy: 0.8786 - val_loss: 0.2708 - val_accuracy: 0.8667\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2437 - accuracy: 0.8698 - val_loss: 0.2694 - val_accuracy: 0.8667\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2439 - accuracy: 0.8742 - val_loss: 0.2752 - val_accuracy: 0.8513\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2430 - accuracy: 0.8764 - val_loss: 0.2772 - val_accuracy: 0.8615\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2482 - accuracy: 0.8653 - val_loss: 0.2730 - val_accuracy: 0.8513\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2437 - accuracy: 0.8786 - val_loss: 0.2709 - val_accuracy: 0.8667\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2450 - accuracy: 0.8742 - val_loss: 0.2877 - val_accuracy: 0.8564\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2573 - accuracy: 0.8742 - val_loss: 0.2736 - val_accuracy: 0.8615\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2515 - accuracy: 0.8653 - val_loss: 0.2687 - val_accuracy: 0.8667\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2464 - accuracy: 0.8764 - val_loss: 0.2715 - val_accuracy: 0.8667\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2469 - accuracy: 0.8720 - val_loss: 0.2801 - val_accuracy: 0.8615\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2461 - accuracy: 0.8742 - val_loss: 0.2783 - val_accuracy: 0.8513\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2432 - accuracy: 0.8808 - val_loss: 0.2721 - val_accuracy: 0.8667\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2426 - accuracy: 0.8764 - val_loss: 0.2704 - val_accuracy: 0.8615\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2507 - accuracy: 0.8698 - val_loss: 0.2725 - val_accuracy: 0.8615\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2482 - accuracy: 0.8698 - val_loss: 0.2699 - val_accuracy: 0.8667\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2470 - accuracy: 0.8653 - val_loss: 0.2727 - val_accuracy: 0.8615\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2456 - accuracy: 0.8764 - val_loss: 0.2710 - val_accuracy: 0.8667\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2442 - accuracy: 0.8808 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2446 - accuracy: 0.8742 - val_loss: 0.2704 - val_accuracy: 0.8667\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2441 - accuracy: 0.8764 - val_loss: 0.2705 - val_accuracy: 0.8667\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2433 - accuracy: 0.8742 - val_loss: 0.2713 - val_accuracy: 0.8615\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2429 - accuracy: 0.8742 - val_loss: 0.2797 - val_accuracy: 0.8615\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2479 - accuracy: 0.8786 - val_loss: 0.2753 - val_accuracy: 0.8513\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2438 - accuracy: 0.8742 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2443 - accuracy: 0.8786 - val_loss: 0.2715 - val_accuracy: 0.8667\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2445 - accuracy: 0.8764 - val_loss: 0.2726 - val_accuracy: 0.8615\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 91us/step - loss: 0.2439 - accuracy: 0.8720 - val_loss: 0.2808 - val_accuracy: 0.8513\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2559 - accuracy: 0.8631 - val_loss: 0.2845 - val_accuracy: 0.8564\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2509 - accuracy: 0.8653 - val_loss: 0.2721 - val_accuracy: 0.8667\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2428 - accuracy: 0.8786 - val_loss: 0.2699 - val_accuracy: 0.8667\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2460 - accuracy: 0.8720 - val_loss: 0.2709 - val_accuracy: 0.8615\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2418 - accuracy: 0.8764 - val_loss: 0.2700 - val_accuracy: 0.8667\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2444 - accuracy: 0.8830 - val_loss: 0.2752 - val_accuracy: 0.8513\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2439 - accuracy: 0.8742 - val_loss: 0.2718 - val_accuracy: 0.8513\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2436 - accuracy: 0.8653 - val_loss: 0.2693 - val_accuracy: 0.8667\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2447 - accuracy: 0.8764 - val_loss: 0.2693 - val_accuracy: 0.8667\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2425 - accuracy: 0.8786 - val_loss: 0.2687 - val_accuracy: 0.8667\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2557 - accuracy: 0.8720 - val_loss: 0.2690 - val_accuracy: 0.8667\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2424 - accuracy: 0.8742 - val_loss: 0.2711 - val_accuracy: 0.8615\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2441 - accuracy: 0.8742 - val_loss: 0.2835 - val_accuracy: 0.8564\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2464 - accuracy: 0.8764 - val_loss: 0.2763 - val_accuracy: 0.8615\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2434 - accuracy: 0.8742 - val_loss: 0.2692 - val_accuracy: 0.8615\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2429 - accuracy: 0.8742 - val_loss: 0.2684 - val_accuracy: 0.8667\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2433 - accuracy: 0.8720 - val_loss: 0.2734 - val_accuracy: 0.8615\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2465 - accuracy: 0.8786 - val_loss: 0.2693 - val_accuracy: 0.8615\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2556 - accuracy: 0.8675 - val_loss: 0.2805 - val_accuracy: 0.8564\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2543 - accuracy: 0.8742 - val_loss: 0.2738 - val_accuracy: 0.8615\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 0.2798 - val_accuracy: 0.8872\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2477 - accuracy: 0.8720 - val_loss: 0.2695 - val_accuracy: 0.8667\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2420 - accuracy: 0.8742 - val_loss: 0.2725 - val_accuracy: 0.8615\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2441 - accuracy: 0.8764 - val_loss: 0.2709 - val_accuracy: 0.8564\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2498 - accuracy: 0.8587 - val_loss: 0.2706 - val_accuracy: 0.8615\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2447 - accuracy: 0.8742 - val_loss: 0.2726 - val_accuracy: 0.8615\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2478 - accuracy: 0.8742 - val_loss: 0.2701 - val_accuracy: 0.8615\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2442 - accuracy: 0.8764 - val_loss: 0.2712 - val_accuracy: 0.8667\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2428 - accuracy: 0.8698 - val_loss: 0.2740 - val_accuracy: 0.8615\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2435 - accuracy: 0.8764 - val_loss: 0.2694 - val_accuracy: 0.8667\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2465 - accuracy: 0.8698 - val_loss: 0.2683 - val_accuracy: 0.8667\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2439 - accuracy: 0.8742 - val_loss: 0.2682 - val_accuracy: 0.8667\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2461 - accuracy: 0.8742 - val_loss: 0.2781 - val_accuracy: 0.8615\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2457 - accuracy: 0.8786 - val_loss: 0.2684 - val_accuracy: 0.8667\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2400 - accuracy: 0.8808 - val_loss: 0.2705 - val_accuracy: 0.8615\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2443 - accuracy: 0.8808 - val_loss: 0.2733 - val_accuracy: 0.8667\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2428 - accuracy: 0.8742 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2418 - accuracy: 0.8786 - val_loss: 0.2707 - val_accuracy: 0.8667\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2460 - accuracy: 0.8742 - val_loss: 0.2742 - val_accuracy: 0.8615\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2476 - accuracy: 0.8742 - val_loss: 0.2698 - val_accuracy: 0.8667\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2511 - accuracy: 0.8742 - val_loss: 0.2732 - val_accuracy: 0.8667\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2429 - accuracy: 0.8786 - val_loss: 0.2663 - val_accuracy: 0.8667\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2403 - accuracy: 0.8786 - val_loss: 0.2667 - val_accuracy: 0.8615\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2435 - accuracy: 0.8720 - val_loss: 0.2707 - val_accuracy: 0.8615\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2411 - accuracy: 0.8742 - val_loss: 0.2725 - val_accuracy: 0.8615\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2502 - accuracy: 0.8786 - val_loss: 0.2695 - val_accuracy: 0.8615\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2431 - accuracy: 0.8786 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2433 - accuracy: 0.8808 - val_loss: 0.2688 - val_accuracy: 0.8615\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2403 - accuracy: 0.8764 - val_loss: 0.2684 - val_accuracy: 0.8615\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2433 - accuracy: 0.8742 - val_loss: 0.2787 - val_accuracy: 0.8872\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2460 - accuracy: 0.8764 - val_loss: 0.2661 - val_accuracy: 0.8667\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2435 - accuracy: 0.8742 - val_loss: 0.2698 - val_accuracy: 0.8615\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2391 - accuracy: 0.8808 - val_loss: 0.2686 - val_accuracy: 0.8667\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2454 - accuracy: 0.8742 - val_loss: 0.2648 - val_accuracy: 0.8718\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2448 - accuracy: 0.8764 - val_loss: 0.2699 - val_accuracy: 0.8615\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2747 - val_accuracy: 0.8667\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2383 - accuracy: 0.8786 - val_loss: 0.2696 - val_accuracy: 0.8615\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2454 - accuracy: 0.8764 - val_loss: 0.2747 - val_accuracy: 0.8513\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2378 - accuracy: 0.8786 - val_loss: 0.2752 - val_accuracy: 0.8667\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2460 - accuracy: 0.8653 - val_loss: 0.2770 - val_accuracy: 0.8615\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2415 - accuracy: 0.8786 - val_loss: 0.2699 - val_accuracy: 0.8667\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2424 - accuracy: 0.8764 - val_loss: 0.2685 - val_accuracy: 0.8667\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2384 - accuracy: 0.8786 - val_loss: 0.2695 - val_accuracy: 0.8615\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2425 - accuracy: 0.8786 - val_loss: 0.2676 - val_accuracy: 0.8615\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2433 - accuracy: 0.8698 - val_loss: 0.2676 - val_accuracy: 0.8667\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2466 - accuracy: 0.8720 - val_loss: 0.2739 - val_accuracy: 0.8615\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2415 - accuracy: 0.8764 - val_loss: 0.2714 - val_accuracy: 0.8667\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2370 - accuracy: 0.8786 - val_loss: 0.2737 - val_accuracy: 0.8615\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2475 - accuracy: 0.8786 - val_loss: 0.2765 - val_accuracy: 0.8667\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2483 - accuracy: 0.8742 - val_loss: 0.2727 - val_accuracy: 0.8923\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2441 - accuracy: 0.8808 - val_loss: 0.2708 - val_accuracy: 0.8615\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2439 - accuracy: 0.8742 - val_loss: 0.2666 - val_accuracy: 0.8615\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2410 - accuracy: 0.8786 - val_loss: 0.2668 - val_accuracy: 0.8667\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2414 - accuracy: 0.8742 - val_loss: 0.2679 - val_accuracy: 0.8667\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2446 - accuracy: 0.8764 - val_loss: 0.2839 - val_accuracy: 0.8718\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2593 - accuracy: 0.8720 - val_loss: 0.2652 - val_accuracy: 0.8667\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2401 - accuracy: 0.8786 - val_loss: 0.2651 - val_accuracy: 0.8667\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2406 - accuracy: 0.8786 - val_loss: 0.2666 - val_accuracy: 0.8667\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2429 - accuracy: 0.8786 - val_loss: 0.2662 - val_accuracy: 0.8667\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2395 - accuracy: 0.8742 - val_loss: 0.2749 - val_accuracy: 0.8615\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2445 - accuracy: 0.8830 - val_loss: 0.2673 - val_accuracy: 0.8667\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2400 - accuracy: 0.8720 - val_loss: 0.2668 - val_accuracy: 0.8667\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.2704 - val_accuracy: 0.8667\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2422 - accuracy: 0.8720 - val_loss: 0.2733 - val_accuracy: 0.8615\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2690 - val_accuracy: 0.8667\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2403 - accuracy: 0.8808 - val_loss: 0.2657 - val_accuracy: 0.8923\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.2661 - val_accuracy: 0.8667\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2465 - accuracy: 0.8786 - val_loss: 0.2660 - val_accuracy: 0.8667\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2440 - accuracy: 0.8786 - val_loss: 0.2735 - val_accuracy: 0.8615\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2407 - accuracy: 0.8720 - val_loss: 0.2710 - val_accuracy: 0.8872\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2377 - accuracy: 0.8808 - val_loss: 0.2974 - val_accuracy: 0.8667\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2494 - accuracy: 0.8786 - val_loss: 0.2684 - val_accuracy: 0.8615\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.2697 - val_accuracy: 0.8667\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2403 - accuracy: 0.8675 - val_loss: 0.2691 - val_accuracy: 0.8615\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2412 - accuracy: 0.8830 - val_loss: 0.2666 - val_accuracy: 0.8667\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2428 - accuracy: 0.8808 - val_loss: 0.2744 - val_accuracy: 0.8667\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2486 - accuracy: 0.8675 - val_loss: 0.2707 - val_accuracy: 0.8872\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2434 - accuracy: 0.8631 - val_loss: 0.2638 - val_accuracy: 0.8667\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2385 - accuracy: 0.8742 - val_loss: 0.2678 - val_accuracy: 0.8615\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2454 - accuracy: 0.8808 - val_loss: 0.2784 - val_accuracy: 0.8872\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2465 - accuracy: 0.8764 - val_loss: 0.2683 - val_accuracy: 0.8667\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2420 - accuracy: 0.8675 - val_loss: 0.2662 - val_accuracy: 0.8667\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2397 - accuracy: 0.8808 - val_loss: 0.2664 - val_accuracy: 0.8667\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2425 - accuracy: 0.8720 - val_loss: 0.2711 - val_accuracy: 0.8513\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2392 - accuracy: 0.8720 - val_loss: 0.2682 - val_accuracy: 0.8667\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2729 - val_accuracy: 0.8667\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.2697 - val_accuracy: 0.8615\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2432 - accuracy: 0.8786 - val_loss: 0.2673 - val_accuracy: 0.8615\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.2674 - val_accuracy: 0.8667\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 116us/step - loss: 0.2408 - accuracy: 0.8808 - val_loss: 0.2736 - val_accuracy: 0.8667\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2507 - accuracy: 0.8653 - val_loss: 0.2656 - val_accuracy: 0.8667\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2395 - accuracy: 0.8786 - val_loss: 0.2657 - val_accuracy: 0.8615\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2425 - accuracy: 0.8808 - val_loss: 0.2670 - val_accuracy: 0.8615\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2404 - accuracy: 0.8786 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2426 - accuracy: 0.8786 - val_loss: 0.2667 - val_accuracy: 0.8615\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.2676 - val_accuracy: 0.8667\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2496 - accuracy: 0.8786 - val_loss: 0.2687 - val_accuracy: 0.8667\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2411 - accuracy: 0.8631 - val_loss: 0.2642 - val_accuracy: 0.8667\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2415 - accuracy: 0.8742 - val_loss: 0.2683 - val_accuracy: 0.8667\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2466 - accuracy: 0.8830 - val_loss: 0.2721 - val_accuracy: 0.8923\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2492 - accuracy: 0.8720 - val_loss: 0.2737 - val_accuracy: 0.8615\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 0.2645 - val_accuracy: 0.8667\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.2655 - val_accuracy: 0.8615\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2401 - accuracy: 0.8764 - val_loss: 0.2707 - val_accuracy: 0.8974\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2418 - accuracy: 0.8742 - val_loss: 0.2654 - val_accuracy: 0.8667\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2440 - accuracy: 0.8786 - val_loss: 0.2665 - val_accuracy: 0.8667\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2463 - accuracy: 0.8764 - val_loss: 0.2682 - val_accuracy: 0.8667\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2379 - accuracy: 0.8764 - val_loss: 0.2666 - val_accuracy: 0.8615\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2388 - accuracy: 0.8786 - val_loss: 0.2654 - val_accuracy: 0.8667\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2390 - accuracy: 0.8786 - val_loss: 0.2669 - val_accuracy: 0.8667\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2424 - accuracy: 0.8742 - val_loss: 0.2640 - val_accuracy: 0.8667\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2452 - accuracy: 0.8786 - val_loss: 0.2667 - val_accuracy: 0.8615\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2419 - accuracy: 0.8830 - val_loss: 0.2646 - val_accuracy: 0.8615\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8923\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2460 - accuracy: 0.8786 - val_loss: 0.2633 - val_accuracy: 0.8667\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.2670 - val_accuracy: 0.8923\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2459 - accuracy: 0.8698 - val_loss: 0.2734 - val_accuracy: 0.8872\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2413 - accuracy: 0.8786 - val_loss: 0.2654 - val_accuracy: 0.8667\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2400 - accuracy: 0.8764 - val_loss: 0.2684 - val_accuracy: 0.8718\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2389 - accuracy: 0.8720 - val_loss: 0.2790 - val_accuracy: 0.8615\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2524 - accuracy: 0.8720 - val_loss: 0.2663 - val_accuracy: 0.8667\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2472 - accuracy: 0.8720 - val_loss: 0.2724 - val_accuracy: 0.8974\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2397 - accuracy: 0.8786 - val_loss: 0.2652 - val_accuracy: 0.8615\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2378 - accuracy: 0.8808 - val_loss: 0.2678 - val_accuracy: 0.8667\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2399 - accuracy: 0.8742 - val_loss: 0.2688 - val_accuracy: 0.8615\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2446 - accuracy: 0.8742 - val_loss: 0.2707 - val_accuracy: 0.8923\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2415 - accuracy: 0.8808 - val_loss: 0.2731 - val_accuracy: 0.8615\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2383 - accuracy: 0.8764 - val_loss: 0.2631 - val_accuracy: 0.8667\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2377 - accuracy: 0.8764 - val_loss: 0.2644 - val_accuracy: 0.8615\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.2674 - val_accuracy: 0.8667\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2400 - accuracy: 0.8808 - val_loss: 0.2655 - val_accuracy: 0.8615\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.2643 - val_accuracy: 0.8667\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2398 - accuracy: 0.8764 - val_loss: 0.2649 - val_accuracy: 0.8667\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2414 - accuracy: 0.8764 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2421 - accuracy: 0.8786 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2418 - accuracy: 0.8786 - val_loss: 0.2621 - val_accuracy: 0.8667\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.2659 - val_accuracy: 0.8667\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2391 - accuracy: 0.8786 - val_loss: 0.2656 - val_accuracy: 0.8667\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2376 - accuracy: 0.8764 - val_loss: 0.2714 - val_accuracy: 0.8923\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2376 - accuracy: 0.8764 - val_loss: 0.2829 - val_accuracy: 0.8615\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2643 - val_accuracy: 0.8667\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2617 - val_accuracy: 0.8615\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2461 - accuracy: 0.8764 - val_loss: 0.2663 - val_accuracy: 0.8667\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2418 - accuracy: 0.8720 - val_loss: 0.2704 - val_accuracy: 0.8923\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2628 - val_accuracy: 0.8615\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2414 - accuracy: 0.8808 - val_loss: 0.2716 - val_accuracy: 0.8923\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2423 - accuracy: 0.8720 - val_loss: 0.2634 - val_accuracy: 0.8667\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2478 - accuracy: 0.8808 - val_loss: 0.2651 - val_accuracy: 0.8615\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2363 - accuracy: 0.8742 - val_loss: 0.2637 - val_accuracy: 0.8667\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2384 - accuracy: 0.8830 - val_loss: 0.2626 - val_accuracy: 0.8667\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2456 - accuracy: 0.8764 - val_loss: 0.2748 - val_accuracy: 0.8974\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2455 - accuracy: 0.8786 - val_loss: 0.2680 - val_accuracy: 0.8923\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2400 - accuracy: 0.8764 - val_loss: 0.2629 - val_accuracy: 0.8667\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2386 - accuracy: 0.8786 - val_loss: 0.2638 - val_accuracy: 0.8615\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2373 - accuracy: 0.8764 - val_loss: 0.2660 - val_accuracy: 0.8615\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2445 - accuracy: 0.8764 - val_loss: 0.2692 - val_accuracy: 0.8974\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2426 - accuracy: 0.8742 - val_loss: 0.2670 - val_accuracy: 0.8667\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2380 - accuracy: 0.8742 - val_loss: 0.2658 - val_accuracy: 0.8615\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2434 - accuracy: 0.8742 - val_loss: 0.2639 - val_accuracy: 0.8667\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.2646 - val_accuracy: 0.8615\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2641 - val_accuracy: 0.8667\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2371 - accuracy: 0.8764 - val_loss: 0.2633 - val_accuracy: 0.8667\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2389 - accuracy: 0.8808 - val_loss: 0.2653 - val_accuracy: 0.8615\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2396 - accuracy: 0.8742 - val_loss: 0.2652 - val_accuracy: 0.8615\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2374 - accuracy: 0.8808 - val_loss: 0.2649 - val_accuracy: 0.8667\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2387 - accuracy: 0.8742 - val_loss: 0.2643 - val_accuracy: 0.8615\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2366 - accuracy: 0.8742 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2377 - accuracy: 0.8808 - val_loss: 0.2634 - val_accuracy: 0.8667\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2619 - val_accuracy: 0.8667\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2621 - val_accuracy: 0.8667\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2372 - accuracy: 0.8786 - val_loss: 0.2619 - val_accuracy: 0.8615\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2410 - accuracy: 0.8675 - val_loss: 0.2651 - val_accuracy: 0.8615\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2385 - accuracy: 0.8742 - val_loss: 0.2648 - val_accuracy: 0.8667\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2369 - accuracy: 0.8808 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2367 - accuracy: 0.8764 - val_loss: 0.2632 - val_accuracy: 0.8615\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.2653 - val_accuracy: 0.8615\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2640 - val_accuracy: 0.8615\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.2615 - val_accuracy: 0.8667\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2614 - val_accuracy: 0.8667\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2419 - accuracy: 0.8764 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2634 - val_accuracy: 0.8615\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2397 - accuracy: 0.8720 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2368 - accuracy: 0.8764 - val_loss: 0.2632 - val_accuracy: 0.8615\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2379 - accuracy: 0.8808 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2358 - accuracy: 0.8808 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2375 - accuracy: 0.8764 - val_loss: 0.2627 - val_accuracy: 0.8667\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2391 - accuracy: 0.8808 - val_loss: 0.2658 - val_accuracy: 0.8923\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2365 - accuracy: 0.8742 - val_loss: 0.2625 - val_accuracy: 0.8615\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2383 - accuracy: 0.8786 - val_loss: 0.2632 - val_accuracy: 0.8615\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2479 - accuracy: 0.8720 - val_loss: 0.2712 - val_accuracy: 0.8923\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2493 - accuracy: 0.8786 - val_loss: 0.2709 - val_accuracy: 0.8974\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2400 - accuracy: 0.8720 - val_loss: 0.2635 - val_accuracy: 0.8615\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2372 - accuracy: 0.8742 - val_loss: 0.2629 - val_accuracy: 0.8615\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2669 - val_accuracy: 0.8615\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2450 - accuracy: 0.8742 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 114us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2621 - val_accuracy: 0.8615\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2360 - accuracy: 0.8764 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.2700 - val_accuracy: 0.8923\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2409 - accuracy: 0.8675 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2652 - val_accuracy: 0.8615\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2350 - accuracy: 0.8874 - val_loss: 0.2788 - val_accuracy: 0.8923\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2403 - accuracy: 0.8698 - val_loss: 0.2740 - val_accuracy: 0.8718\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2439 - accuracy: 0.8808 - val_loss: 0.2621 - val_accuracy: 0.8667\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2641 - val_accuracy: 0.8667\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2644 - val_accuracy: 0.8667\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2377 - accuracy: 0.8808 - val_loss: 0.2644 - val_accuracy: 0.8667\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.2627 - val_accuracy: 0.8615\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2343 - accuracy: 0.8764 - val_loss: 0.2667 - val_accuracy: 0.8923\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2391 - accuracy: 0.8786 - val_loss: 0.2634 - val_accuracy: 0.8667\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2367 - accuracy: 0.8786 - val_loss: 0.2620 - val_accuracy: 0.8615\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2635 - val_accuracy: 0.8615\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2422 - accuracy: 0.8764 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2357 - accuracy: 0.8764 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2370 - accuracy: 0.8808 - val_loss: 0.2620 - val_accuracy: 0.8615\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2350 - accuracy: 0.8808 - val_loss: 0.2642 - val_accuracy: 0.8667\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2398 - accuracy: 0.8808 - val_loss: 0.2658 - val_accuracy: 0.8923\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2367 - accuracy: 0.8764 - val_loss: 0.2611 - val_accuracy: 0.8667\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2365 - accuracy: 0.8764 - val_loss: 0.2627 - val_accuracy: 0.8615\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2360 - accuracy: 0.8764 - val_loss: 0.2628 - val_accuracy: 0.8667\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2370 - accuracy: 0.8764 - val_loss: 0.2670 - val_accuracy: 0.8974\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2387 - accuracy: 0.8698 - val_loss: 0.2656 - val_accuracy: 0.8923\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2366 - accuracy: 0.8786 - val_loss: 0.2626 - val_accuracy: 0.8615\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2376 - accuracy: 0.8808 - val_loss: 0.2614 - val_accuracy: 0.8615\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.2644 - val_accuracy: 0.8667\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2628 - val_accuracy: 0.8667\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2373 - accuracy: 0.8786 - val_loss: 0.2632 - val_accuracy: 0.8923\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.2608 - val_accuracy: 0.8615\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2614 - val_accuracy: 0.8667\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2609 - val_accuracy: 0.8615\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2366 - accuracy: 0.8764 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2645 - val_accuracy: 0.8667\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.2615 - val_accuracy: 0.8667\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2632 - val_accuracy: 0.8615\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2618 - val_accuracy: 0.8615\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.2727 - val_accuracy: 0.8923\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.2649 - val_accuracy: 0.8615\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2363 - accuracy: 0.8720 - val_loss: 0.2656 - val_accuracy: 0.8615\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2619 - val_accuracy: 0.8667\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.2637 - val_accuracy: 0.8667\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2360 - accuracy: 0.8786 - val_loss: 0.2637 - val_accuracy: 0.8615\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2374 - accuracy: 0.8764 - val_loss: 0.2642 - val_accuracy: 0.8923\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2410 - accuracy: 0.8720 - val_loss: 0.2650 - val_accuracy: 0.8923\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2404 - accuracy: 0.8764 - val_loss: 0.2724 - val_accuracy: 0.8923\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2367 - accuracy: 0.8720 - val_loss: 0.2604 - val_accuracy: 0.8667\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2361 - accuracy: 0.8698 - val_loss: 0.2636 - val_accuracy: 0.8615\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2401 - accuracy: 0.8786 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.2653 - val_accuracy: 0.8923\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2441 - accuracy: 0.8698 - val_loss: 0.2741 - val_accuracy: 0.8872\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2390 - accuracy: 0.8764 - val_loss: 0.2632 - val_accuracy: 0.8667\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2355 - accuracy: 0.8786 - val_loss: 0.2613 - val_accuracy: 0.8615\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2615 - val_accuracy: 0.8667\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2619 - val_accuracy: 0.8667\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2365 - accuracy: 0.8698 - val_loss: 0.2624 - val_accuracy: 0.8615\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2333 - accuracy: 0.8742 - val_loss: 0.2658 - val_accuracy: 0.8923\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2402 - accuracy: 0.8742 - val_loss: 0.2622 - val_accuracy: 0.8615\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2415 - accuracy: 0.8786 - val_loss: 0.2628 - val_accuracy: 0.8615\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2362 - accuracy: 0.8808 - val_loss: 0.2625 - val_accuracy: 0.8615\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2660 - val_accuracy: 0.8667\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2639 - val_accuracy: 0.8615\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.2619 - val_accuracy: 0.8615\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8764 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2371 - accuracy: 0.8720 - val_loss: 0.2761 - val_accuracy: 0.8615\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2398 - accuracy: 0.8786 - val_loss: 0.2610 - val_accuracy: 0.8667\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2383 - accuracy: 0.8742 - val_loss: 0.2629 - val_accuracy: 0.8615\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2379 - accuracy: 0.8786 - val_loss: 0.2606 - val_accuracy: 0.8667\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2635 - val_accuracy: 0.8667\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2690 - val_accuracy: 0.8615\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2492 - accuracy: 0.8675 - val_loss: 0.2671 - val_accuracy: 0.8615\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2370 - accuracy: 0.8786 - val_loss: 0.2617 - val_accuracy: 0.8923\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2380 - accuracy: 0.8764 - val_loss: 0.2650 - val_accuracy: 0.8974\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2706 - val_accuracy: 0.8923\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2355 - accuracy: 0.8742 - val_loss: 0.2623 - val_accuracy: 0.8615\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2618 - val_accuracy: 0.8615\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2343 - accuracy: 0.8786 - val_loss: 0.2634 - val_accuracy: 0.8667\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2366 - accuracy: 0.8808 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2370 - accuracy: 0.8786 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2358 - accuracy: 0.8698 - val_loss: 0.2593 - val_accuracy: 0.8615\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2609 - val_accuracy: 0.8615\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2365 - accuracy: 0.8808 - val_loss: 0.2607 - val_accuracy: 0.8615\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2344 - accuracy: 0.8764 - val_loss: 0.2607 - val_accuracy: 0.8667\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2337 - accuracy: 0.8786 - val_loss: 0.2655 - val_accuracy: 0.8615\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.2721 - val_accuracy: 0.8923\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2382 - accuracy: 0.8653 - val_loss: 0.2623 - val_accuracy: 0.8615\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2392 - accuracy: 0.8742 - val_loss: 0.2621 - val_accuracy: 0.8615\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2483 - accuracy: 0.8720 - val_loss: 0.2648 - val_accuracy: 0.8923\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2366 - accuracy: 0.8764 - val_loss: 0.2596 - val_accuracy: 0.8667\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2370 - accuracy: 0.8786 - val_loss: 0.2610 - val_accuracy: 0.8615\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2599 - val_accuracy: 0.8615\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2356 - accuracy: 0.8742 - val_loss: 0.2607 - val_accuracy: 0.8615\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2337 - accuracy: 0.8808 - val_loss: 0.2641 - val_accuracy: 0.8923\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2379 - accuracy: 0.8742 - val_loss: 0.2587 - val_accuracy: 0.8615\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.2617 - val_accuracy: 0.8615\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2831 - val_accuracy: 0.8667\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2427 - accuracy: 0.8764 - val_loss: 0.2602 - val_accuracy: 0.8718\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.2599 - val_accuracy: 0.8718\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2350 - accuracy: 0.8808 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2346 - accuracy: 0.8786 - val_loss: 0.2678 - val_accuracy: 0.8974\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2606 - val_accuracy: 0.8667\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2346 - accuracy: 0.8786 - val_loss: 0.2635 - val_accuracy: 0.8923\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.2610 - val_accuracy: 0.8615\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2619 - val_accuracy: 0.8615\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2359 - accuracy: 0.8742 - val_loss: 0.2615 - val_accuracy: 0.8615\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2345 - accuracy: 0.8764 - val_loss: 0.2627 - val_accuracy: 0.8667\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2366 - accuracy: 0.8742 - val_loss: 0.2642 - val_accuracy: 0.8667\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2343 - accuracy: 0.8675 - val_loss: 0.2753 - val_accuracy: 0.8667\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.2746 - val_accuracy: 0.8974\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2472 - accuracy: 0.8653 - val_loss: 0.2629 - val_accuracy: 0.8667\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2366 - accuracy: 0.8764 - val_loss: 0.2629 - val_accuracy: 0.8615\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2376 - accuracy: 0.8698 - val_loss: 0.2635 - val_accuracy: 0.8615\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.2698 - val_accuracy: 0.8923\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2447 - accuracy: 0.8742 - val_loss: 0.2669 - val_accuracy: 0.8667\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2361 - accuracy: 0.8764 - val_loss: 0.2624 - val_accuracy: 0.8667\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2632 - val_accuracy: 0.8667\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2664 - val_accuracy: 0.8615\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.2626 - val_accuracy: 0.8667\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2348 - accuracy: 0.8764 - val_loss: 0.2622 - val_accuracy: 0.8615\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2402 - accuracy: 0.8874 - val_loss: 0.2619 - val_accuracy: 0.8615\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2685 - val_accuracy: 0.8923\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2374 - accuracy: 0.8764 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2598 - val_accuracy: 0.8615\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2386 - accuracy: 0.8720 - val_loss: 0.2634 - val_accuracy: 0.8615\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2352 - accuracy: 0.8808 - val_loss: 0.2627 - val_accuracy: 0.8923\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2392 - accuracy: 0.8742 - val_loss: 0.2605 - val_accuracy: 0.8615\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2354 - accuracy: 0.8786 - val_loss: 0.2598 - val_accuracy: 0.8667\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2596 - val_accuracy: 0.8615\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2353 - accuracy: 0.8720 - val_loss: 0.2600 - val_accuracy: 0.8615\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2394 - accuracy: 0.8786 - val_loss: 0.2639 - val_accuracy: 0.8923\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2371 - accuracy: 0.8808 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2350 - accuracy: 0.8786 - val_loss: 0.2666 - val_accuracy: 0.8923\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2350 - accuracy: 0.8808 - val_loss: 0.2605 - val_accuracy: 0.8615\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2341 - accuracy: 0.8808 - val_loss: 0.2690 - val_accuracy: 0.8615\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2361 - accuracy: 0.8786 - val_loss: 0.2614 - val_accuracy: 0.8615\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2379 - accuracy: 0.8764 - val_loss: 0.2632 - val_accuracy: 0.8615\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2649 - val_accuracy: 0.8667\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2439 - accuracy: 0.8653 - val_loss: 0.2684 - val_accuracy: 0.8667\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2429 - accuracy: 0.8786 - val_loss: 0.2685 - val_accuracy: 0.8923\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2347 - accuracy: 0.8764 - val_loss: 0.2635 - val_accuracy: 0.8615\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.2617 - val_accuracy: 0.8667\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2342 - accuracy: 0.8764 - val_loss: 0.2654 - val_accuracy: 0.8923\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2371 - accuracy: 0.8764 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2377 - accuracy: 0.8720 - val_loss: 0.2653 - val_accuracy: 0.8615\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2371 - accuracy: 0.8852 - val_loss: 0.2622 - val_accuracy: 0.8923\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.2620 - val_accuracy: 0.8923\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2668 - val_accuracy: 0.8615\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2437 - accuracy: 0.8808 - val_loss: 0.2758 - val_accuracy: 0.8718\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2426 - accuracy: 0.8653 - val_loss: 0.2601 - val_accuracy: 0.8667\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2613 - val_accuracy: 0.8667\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2352 - accuracy: 0.8698 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2363 - accuracy: 0.8764 - val_loss: 0.2613 - val_accuracy: 0.8615\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2821 - val_accuracy: 0.8872\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2416 - accuracy: 0.8742 - val_loss: 0.2626 - val_accuracy: 0.8615\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2607 - val_accuracy: 0.8667\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2381 - accuracy: 0.8698 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2344 - accuracy: 0.8720 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 0.2685 - val_accuracy: 0.8923\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2374 - accuracy: 0.8742 - val_loss: 0.2608 - val_accuracy: 0.8615\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2618 - val_accuracy: 0.8667\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2374 - accuracy: 0.8874 - val_loss: 0.2603 - val_accuracy: 0.8667\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2355 - accuracy: 0.8742 - val_loss: 0.2585 - val_accuracy: 0.8667\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2628 - val_accuracy: 0.8923\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2374 - accuracy: 0.8808 - val_loss: 0.2599 - val_accuracy: 0.8667\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2404 - accuracy: 0.8720 - val_loss: 0.2640 - val_accuracy: 0.8615\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 0.2730 - val_accuracy: 0.8923\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2378 - accuracy: 0.8764 - val_loss: 0.2622 - val_accuracy: 0.8667\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2630 - val_accuracy: 0.8615\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2398 - accuracy: 0.8808 - val_loss: 0.2651 - val_accuracy: 0.8615\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2386 - accuracy: 0.8786 - val_loss: 0.2627 - val_accuracy: 0.8615\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.81 - 0s 108us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2599 - val_accuracy: 0.8615\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.2615 - val_accuracy: 0.8615\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2347 - accuracy: 0.8742 - val_loss: 0.2594 - val_accuracy: 0.8667\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2367 - accuracy: 0.8742 - val_loss: 0.2644 - val_accuracy: 0.8923\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.2611 - val_accuracy: 0.8667\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2594 - val_accuracy: 0.8615\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2344 - accuracy: 0.8742 - val_loss: 0.2596 - val_accuracy: 0.8667\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2594 - val_accuracy: 0.8615\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.2598 - val_accuracy: 0.8667\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2354 - accuracy: 0.8764 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.2597 - val_accuracy: 0.8615\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2355 - accuracy: 0.8742 - val_loss: 0.2631 - val_accuracy: 0.8615\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2633 - val_accuracy: 0.8667\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2363 - accuracy: 0.8764 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2329 - accuracy: 0.8764 - val_loss: 0.2613 - val_accuracy: 0.8667\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2360 - accuracy: 0.8808 - val_loss: 0.2636 - val_accuracy: 0.8923\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2328 - accuracy: 0.8764 - val_loss: 0.2615 - val_accuracy: 0.8615\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.8764 - val_loss: 0.2596 - val_accuracy: 0.8667\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.2582 - val_accuracy: 0.8667\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2385 - accuracy: 0.8764 - val_loss: 0.2597 - val_accuracy: 0.8667\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2627 - val_accuracy: 0.8667\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2340 - accuracy: 0.8698 - val_loss: 0.2605 - val_accuracy: 0.8667\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.2624 - val_accuracy: 0.8923\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.2604 - val_accuracy: 0.8615\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2641 - val_accuracy: 0.8923\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2360 - accuracy: 0.8698 - val_loss: 0.2622 - val_accuracy: 0.8667\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2624 - val_accuracy: 0.8667\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.2767 - val_accuracy: 0.8923\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2359 - accuracy: 0.8742 - val_loss: 0.2594 - val_accuracy: 0.8667\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.2617 - val_accuracy: 0.8667\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2711 - val_accuracy: 0.8923\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2584 - val_accuracy: 0.8615\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2596 - val_accuracy: 0.8667\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.2664 - val_accuracy: 0.8923\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2397 - accuracy: 0.8786 - val_loss: 0.2596 - val_accuracy: 0.8615\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2336 - accuracy: 0.8764 - val_loss: 0.2595 - val_accuracy: 0.8615\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2599 - val_accuracy: 0.8615\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2607 - val_accuracy: 0.8667\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2579 - val_accuracy: 0.8615\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2617 - val_accuracy: 0.8667\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.2602 - val_accuracy: 0.8615\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2362 - accuracy: 0.8675 - val_loss: 0.2605 - val_accuracy: 0.8615\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2607 - val_accuracy: 0.8667\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2367 - accuracy: 0.8742 - val_loss: 0.2611 - val_accuracy: 0.8667\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.2625 - val_accuracy: 0.8923\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2596 - val_accuracy: 0.8667\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2360 - accuracy: 0.8786 - val_loss: 0.2632 - val_accuracy: 0.8667\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2343 - accuracy: 0.8764 - val_loss: 0.2636 - val_accuracy: 0.8667\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2383 - accuracy: 0.8764 - val_loss: 0.2647 - val_accuracy: 0.8923\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2335 - accuracy: 0.8764 - val_loss: 0.2612 - val_accuracy: 0.8667\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2337 - accuracy: 0.8764 - val_loss: 0.2606 - val_accuracy: 0.8615\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.2620 - val_accuracy: 0.8923\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2607 - val_accuracy: 0.8667\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.2601 - val_accuracy: 0.8615\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2591 - val_accuracy: 0.8615\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.2588 - val_accuracy: 0.8615\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2630 - val_accuracy: 0.8923\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2445 - accuracy: 0.8366 - val_loss: 0.2688 - val_accuracy: 0.8667\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2487 - accuracy: 0.8808 - val_loss: 0.2590 - val_accuracy: 0.8923\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2364 - accuracy: 0.8742 - val_loss: 0.2650 - val_accuracy: 0.8923\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2339 - accuracy: 0.8742 - val_loss: 0.2589 - val_accuracy: 0.8667\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2328 - accuracy: 0.8764 - val_loss: 0.2592 - val_accuracy: 0.8667\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.2629 - val_accuracy: 0.8615\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 322us/step - loss: 0.2336 - accuracy: 0.8742 - val_loss: 0.2613 - val_accuracy: 0.8615\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2381 - accuracy: 0.8764 - val_loss: 0.2618 - val_accuracy: 0.8667\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.8742 - val_loss: 0.2606 - val_accuracy: 0.8667\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 617us/step - loss: 0.2344 - accuracy: 0.8764 - val_loss: 0.2674 - val_accuracy: 0.8923\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 0.2596 - val_accuracy: 0.8615\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 351us/step - loss: 0.2363 - accuracy: 0.8764 - val_loss: 0.2671 - val_accuracy: 0.8923\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 610us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.2338 - accuracy: 0.8742 - val_loss: 0.2604 - val_accuracy: 0.8615\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 484us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2599 - val_accuracy: 0.8667\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2639 - val_accuracy: 0.8923\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2615 - val_accuracy: 0.8667\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2376 - accuracy: 0.8631 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.2663 - val_accuracy: 0.8667\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2589 - val_accuracy: 0.8667\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2367 - accuracy: 0.8786 - val_loss: 0.2619 - val_accuracy: 0.8667\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2387 - accuracy: 0.8764 - val_loss: 0.2623 - val_accuracy: 0.8615\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.2616 - val_accuracy: 0.8667\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2611 - val_accuracy: 0.8615\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2408 - accuracy: 0.8742 - val_loss: 0.2611 - val_accuracy: 0.8667\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.2594 - val_accuracy: 0.8615\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2652 - val_accuracy: 0.8615\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2337 - accuracy: 0.8786 - val_loss: 0.2637 - val_accuracy: 0.8667\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2622 - val_accuracy: 0.8667\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2613 - val_accuracy: 0.8667\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2387 - accuracy: 0.8742 - val_loss: 0.2591 - val_accuracy: 0.8667\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2618 - val_accuracy: 0.8923\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2644 - val_accuracy: 0.8667\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2341 - accuracy: 0.8742 - val_loss: 0.2634 - val_accuracy: 0.8923\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.2605 - val_accuracy: 0.8667\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2330 - accuracy: 0.8742 - val_loss: 0.2599 - val_accuracy: 0.8667\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2597 - val_accuracy: 0.8923\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2620 - val_accuracy: 0.8667\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2614 - val_accuracy: 0.8667\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2716 - val_accuracy: 0.8564\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2347 - accuracy: 0.8720 - val_loss: 0.2624 - val_accuracy: 0.8667\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.2548 - val_accuracy: 0.8667\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2345 - accuracy: 0.8786 - val_loss: 0.2593 - val_accuracy: 0.8923\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2548 - val_accuracy: 0.8718\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2573 - val_accuracy: 0.8667\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2319 - accuracy: 0.8742 - val_loss: 0.2557 - val_accuracy: 0.8615\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2573 - val_accuracy: 0.8615\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2358 - accuracy: 0.8742 - val_loss: 0.2616 - val_accuracy: 0.8667\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2668 - val_accuracy: 0.8923\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2378 - accuracy: 0.8742 - val_loss: 0.2561 - val_accuracy: 0.8667\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.2572 - val_accuracy: 0.8667\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2563 - val_accuracy: 0.8615\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2622 - val_accuracy: 0.8667\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2334 - accuracy: 0.8786 - val_loss: 0.2623 - val_accuracy: 0.8923\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2591 - val_accuracy: 0.8667\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2391 - accuracy: 0.8764 - val_loss: 0.2608 - val_accuracy: 0.8923\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2347 - accuracy: 0.8764 - val_loss: 0.2605 - val_accuracy: 0.8615\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2330 - accuracy: 0.8742 - val_loss: 0.2598 - val_accuracy: 0.8667\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2371 - accuracy: 0.8742 - val_loss: 0.2580 - val_accuracy: 0.8667\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2374 - accuracy: 0.8808 - val_loss: 0.2597 - val_accuracy: 0.8667\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2338 - accuracy: 0.8786 - val_loss: 0.2625 - val_accuracy: 0.8923\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2599 - val_accuracy: 0.8667\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2621 - val_accuracy: 0.8667\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2677 - val_accuracy: 0.8615\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2365 - accuracy: 0.8786 - val_loss: 0.2637 - val_accuracy: 0.8667\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.2602 - val_accuracy: 0.8667\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2334 - accuracy: 0.8742 - val_loss: 0.2597 - val_accuracy: 0.8667\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2366 - accuracy: 0.8698 - val_loss: 0.2634 - val_accuracy: 0.8923\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2375 - accuracy: 0.8786 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2590 - val_accuracy: 0.8667\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2334 - accuracy: 0.8786 - val_loss: 0.2605 - val_accuracy: 0.8667\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2358 - accuracy: 0.8786 - val_loss: 0.2655 - val_accuracy: 0.8923\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2635 - val_accuracy: 0.8667\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2335 - accuracy: 0.8764 - val_loss: 0.2600 - val_accuracy: 0.8667\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2336 - accuracy: 0.8764 - val_loss: 0.2582 - val_accuracy: 0.8718\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.2604 - val_accuracy: 0.8667\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 1.00 - 0s 123us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.2625 - val_accuracy: 0.8667\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2579 - val_accuracy: 0.8718\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.2578 - val_accuracy: 0.8667\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2328 - accuracy: 0.8786 - val_loss: 0.2595 - val_accuracy: 0.8667\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2390 - accuracy: 0.8808 - val_loss: 0.2635 - val_accuracy: 0.8923\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2362 - accuracy: 0.8720 - val_loss: 0.2592 - val_accuracy: 0.8718\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2549 - val_accuracy: 0.8718\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 195us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2553 - val_accuracy: 0.8667\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2303 - accuracy: 0.8742 - val_loss: 0.2551 - val_accuracy: 0.8667\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2567 - val_accuracy: 0.8667\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.2573 - val_accuracy: 0.8667\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2355 - accuracy: 0.8720 - val_loss: 0.2555 - val_accuracy: 0.8667\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2341 - accuracy: 0.8786 - val_loss: 0.2572 - val_accuracy: 0.8667\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2335 - accuracy: 0.8720 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2586 - val_accuracy: 0.8667\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2340 - accuracy: 0.8720 - val_loss: 0.2580 - val_accuracy: 0.8667\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2333 - accuracy: 0.8698 - val_loss: 0.2600 - val_accuracy: 0.8667\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2419 - accuracy: 0.8808 - val_loss: 0.2594 - val_accuracy: 0.8667\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.2580 - val_accuracy: 0.8718\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2334 - accuracy: 0.8720 - val_loss: 0.2612 - val_accuracy: 0.8667\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2587 - val_accuracy: 0.8718\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2326 - accuracy: 0.8698 - val_loss: 0.2592 - val_accuracy: 0.8718\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2346 - accuracy: 0.8764 - val_loss: 0.2612 - val_accuracy: 0.8923\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2333 - accuracy: 0.8742 - val_loss: 0.2592 - val_accuracy: 0.8974\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2384 - accuracy: 0.8653 - val_loss: 0.2581 - val_accuracy: 0.8667\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.2479 - val_accuracy: 0.8718\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.2492 - val_accuracy: 0.8718\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2390 - accuracy: 0.8786 - val_loss: 0.2569 - val_accuracy: 0.8923\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2540 - val_accuracy: 0.8718\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2334 - accuracy: 0.8786 - val_loss: 0.2580 - val_accuracy: 0.8667\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2346 - accuracy: 0.8764 - val_loss: 0.2541 - val_accuracy: 0.8667\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.2525 - val_accuracy: 0.8718\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2556 - val_accuracy: 0.8667\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2567 - val_accuracy: 0.8667\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2549 - val_accuracy: 0.8667\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2400 - accuracy: 0.8764 - val_loss: 0.2562 - val_accuracy: 0.8667\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2581 - val_accuracy: 0.8667\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2576 - val_accuracy: 0.8667\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2341 - accuracy: 0.8786 - val_loss: 0.2566 - val_accuracy: 0.8718\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2525 - val_accuracy: 0.8718\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2332 - accuracy: 0.8742 - val_loss: 0.2558 - val_accuracy: 0.8667\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2365 - accuracy: 0.8808 - val_loss: 0.2543 - val_accuracy: 0.8718\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.2554 - val_accuracy: 0.8718\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2348 - accuracy: 0.8808 - val_loss: 0.2539 - val_accuracy: 0.8718\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2567 - val_accuracy: 0.8718\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2350 - accuracy: 0.8764 - val_loss: 0.2597 - val_accuracy: 0.8718\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2332 - accuracy: 0.8720 - val_loss: 0.2548 - val_accuracy: 0.8718\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2544 - val_accuracy: 0.8718\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2574 - val_accuracy: 0.8667\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2329 - accuracy: 0.8698 - val_loss: 0.2548 - val_accuracy: 0.8718\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.2536 - val_accuracy: 0.8667\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2371 - accuracy: 0.8764 - val_loss: 0.2534 - val_accuracy: 0.8667\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2385 - accuracy: 0.8742 - val_loss: 0.2611 - val_accuracy: 0.8667\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2555 - val_accuracy: 0.8718\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2359 - accuracy: 0.8631 - val_loss: 0.2608 - val_accuracy: 0.8667\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.2571 - val_accuracy: 0.8667\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2559 - val_accuracy: 0.8718\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2328 - accuracy: 0.8742 - val_loss: 0.2573 - val_accuracy: 0.8667\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2376 - accuracy: 0.8742 - val_loss: 0.2572 - val_accuracy: 0.8923\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2314 - accuracy: 0.8764 - val_loss: 0.2557 - val_accuracy: 0.8718\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2564 - val_accuracy: 0.8667\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2304 - accuracy: 0.8742 - val_loss: 0.2575 - val_accuracy: 0.8667\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.2563 - val_accuracy: 0.8667\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2558 - val_accuracy: 0.8974\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2561 - val_accuracy: 0.8667\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2337 - accuracy: 0.8786 - val_loss: 0.2580 - val_accuracy: 0.8667\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2379 - accuracy: 0.8764 - val_loss: 0.2558 - val_accuracy: 0.8667\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2557 - val_accuracy: 0.8718\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2571 - val_accuracy: 0.8718\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2591 - val_accuracy: 0.8974\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2378 - accuracy: 0.8675 - val_loss: 0.2603 - val_accuracy: 0.8667\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2584 - val_accuracy: 0.8974\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2364 - accuracy: 0.8742 - val_loss: 0.2579 - val_accuracy: 0.8667\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2333 - accuracy: 0.8675 - val_loss: 0.2585 - val_accuracy: 0.8667\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2333 - accuracy: 0.8742 - val_loss: 0.2579 - val_accuracy: 0.8667\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2322 - accuracy: 0.8720 - val_loss: 0.2555 - val_accuracy: 0.8974\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2662 - val_accuracy: 0.8667\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2685 - val_accuracy: 0.8923\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2398 - accuracy: 0.8720 - val_loss: 0.2585 - val_accuracy: 0.8667\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2322 - accuracy: 0.8786 - val_loss: 0.2585 - val_accuracy: 0.8718\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2576 - val_accuracy: 0.8718\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2560 - val_accuracy: 0.8718\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2340 - accuracy: 0.8786 - val_loss: 0.2576 - val_accuracy: 0.8667\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2346 - accuracy: 0.8742 - val_loss: 0.2612 - val_accuracy: 0.8667\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2605 - val_accuracy: 0.8667\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2300 - accuracy: 0.8764 - val_loss: 0.2623 - val_accuracy: 0.8667\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.2588 - val_accuracy: 0.8667\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2331 - accuracy: 0.8764 - val_loss: 0.2582 - val_accuracy: 0.8718\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2569 - val_accuracy: 0.8667\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2344 - accuracy: 0.8764 - val_loss: 0.2590 - val_accuracy: 0.8974\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2592 - val_accuracy: 0.8667\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2346 - accuracy: 0.8742 - val_loss: 0.2611 - val_accuracy: 0.8974\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2324 - accuracy: 0.8764 - val_loss: 0.2559 - val_accuracy: 0.8718\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2588 - val_accuracy: 0.8667\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2587 - val_accuracy: 0.8718\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.2606 - val_accuracy: 0.8718\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2590 - val_accuracy: 0.8667\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.2588 - val_accuracy: 0.8718\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.2591 - val_accuracy: 0.8667\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2339 - accuracy: 0.8698 - val_loss: 0.2602 - val_accuracy: 0.9026\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2355 - accuracy: 0.8698 - val_loss: 0.2615 - val_accuracy: 0.8718\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2362 - accuracy: 0.8631 - val_loss: 0.2591 - val_accuracy: 0.8667\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2336 - accuracy: 0.8742 - val_loss: 0.2633 - val_accuracy: 0.8974\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2338 - accuracy: 0.8786 - val_loss: 0.2560 - val_accuracy: 0.8718\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2572 - val_accuracy: 0.8974\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2328 - accuracy: 0.8698 - val_loss: 0.2573 - val_accuracy: 0.8718\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2317 - accuracy: 0.8742 - val_loss: 0.2556 - val_accuracy: 0.8974\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2338 - accuracy: 0.8786 - val_loss: 0.2585 - val_accuracy: 0.8667\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2326 - accuracy: 0.8786 - val_loss: 0.2580 - val_accuracy: 0.8667\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2373 - accuracy: 0.8698 - val_loss: 0.2549 - val_accuracy: 0.8718\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2569 - val_accuracy: 0.8667\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2331 - accuracy: 0.8764 - val_loss: 0.2590 - val_accuracy: 0.8718\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2339 - accuracy: 0.8653 - val_loss: 0.2567 - val_accuracy: 0.8667\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2588 - val_accuracy: 0.8974\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2421 - accuracy: 0.8675 - val_loss: 0.2587 - val_accuracy: 0.8667\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2609 - val_accuracy: 0.8667\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2348 - accuracy: 0.8808 - val_loss: 0.2646 - val_accuracy: 0.8974\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 117us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.2584 - val_accuracy: 0.8667\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2568 - val_accuracy: 0.8667\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.2560 - val_accuracy: 0.8974\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2370 - accuracy: 0.8764 - val_loss: 0.2538 - val_accuracy: 0.8667\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2332 - accuracy: 0.8698 - val_loss: 0.2516 - val_accuracy: 0.8718\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2334 - accuracy: 0.8675 - val_loss: 0.2549 - val_accuracy: 0.8667\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2540 - val_accuracy: 0.8974\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2560 - val_accuracy: 0.8667\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2548 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a385db710>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 55us/step\n",
      "over-sampling test accuracy: 87.18%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 1,\n",
       "       0, 0, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2, 0, 2, 1, 0, 1, 1,\n",
       "       2, 2, 2, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1,\n",
       "       1, 2, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 0, 2,\n",
       "       2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 2, 1, 0, 2, 2, 0, 0, 2, 2, 0, 1, 0,\n",
       "       0, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 2,\n",
       "       2, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1,\n",
       "       0, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 1, 0, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa119     0     0\n",
       "1         NRS001     1     1\n",
       "2         NRS074     0     0\n",
       "3         NRS209     2     2\n",
       "4          GA231     0     1\n",
       "..           ...   ...   ...\n",
       "190       NRS252     0     0\n",
       "191       SR2852     1     1\n",
       "192       NRS108     1     1\n",
       "193       NRS202     0     0\n",
       "194       NRS110     2     2\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111041e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.984043e-01</td>\n",
       "      <td>5.015957e-01</td>\n",
       "      <td>3.714970e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111041e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.076489e-09</td>\n",
       "      <td>4.213780e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.451807e-01</td>\n",
       "      <td>6.548194e-01</td>\n",
       "      <td>4.039059e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.052275e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111041e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    6.888959e-01  3.111041e-01  2.228958e-09\n",
       "1    4.984043e-01  5.015957e-01  3.714970e-10\n",
       "2    6.888959e-01  3.111041e-01  2.228958e-09\n",
       "3    1.076489e-09  4.213780e-08  1.000000e+00\n",
       "4    3.451807e-01  6.548194e-01  4.039059e-09\n",
       "..            ...           ...           ...\n",
       "190  7.239556e-01  2.760444e-01  1.176030e-09\n",
       "191  1.052275e-07  9.999999e-01  1.101559e-28\n",
       "192  1.540350e-17  1.000000e+00  9.011977e-16\n",
       "193  6.888959e-01  3.111041e-01  2.228958e-09\n",
       "194  1.097719e-09  4.404655e-08  1.000000e+00\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2468 - val_accuracy: 0.8667\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2485 - val_accuracy: 0.8667\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2318 - accuracy: 0.8653 - val_loss: 0.2485 - val_accuracy: 0.8718\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2482 - val_accuracy: 0.8718\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2457 - val_accuracy: 0.8667\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2468 - val_accuracy: 0.8718\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2501 - val_accuracy: 0.8974\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2308 - accuracy: 0.8720 - val_loss: 0.2454 - val_accuracy: 0.8667\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2494 - val_accuracy: 0.8718\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2347 - accuracy: 0.8720 - val_loss: 0.2482 - val_accuracy: 0.8667\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2309 - accuracy: 0.8698 - val_loss: 0.2459 - val_accuracy: 0.8667\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2478 - val_accuracy: 0.8667\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2328 - accuracy: 0.8698 - val_loss: 0.2489 - val_accuracy: 0.8718\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2304 - accuracy: 0.8764 - val_loss: 0.2464 - val_accuracy: 0.8667\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2353 - accuracy: 0.8698 - val_loss: 0.2457 - val_accuracy: 0.8667\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2470 - val_accuracy: 0.8667\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2316 - accuracy: 0.8720 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2442 - val_accuracy: 0.8667\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2480 - val_accuracy: 0.8667\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2342 - accuracy: 0.8720 - val_loss: 0.2456 - val_accuracy: 0.8667\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2491 - val_accuracy: 0.8718\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 297us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 417us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2452 - val_accuracy: 0.8667\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 440us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.2570 - val_accuracy: 0.8718\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 477us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.2520 - val_accuracy: 0.8667\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2487 - val_accuracy: 0.8667\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2521 - val_accuracy: 0.8667\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2482 - val_accuracy: 0.8667\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 633us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2520 - val_accuracy: 0.8718\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2470 - val_accuracy: 0.8667\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2347 - accuracy: 0.8764 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2351 - accuracy: 0.8786 - val_loss: 0.2471 - val_accuracy: 0.8718\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2314 - accuracy: 0.8720 - val_loss: 0.2432 - val_accuracy: 0.8667\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2441 - val_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.2477 - val_accuracy: 0.8974\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2435 - val_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2313 - accuracy: 0.8764 - val_loss: 0.2438 - val_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 754us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 759us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2485 - val_accuracy: 0.8974\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2342 - accuracy: 0.8698 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2334 - accuracy: 0.8720 - val_loss: 0.2443 - val_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.2442 - val_accuracy: 0.8974\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2362 - accuracy: 0.8764 - val_loss: 0.2424 - val_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.2441 - val_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2426 - val_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2474 - val_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.2453 - val_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2343 - accuracy: 0.8720 - val_loss: 0.2442 - val_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2310 - accuracy: 0.8698 - val_loss: 0.2483 - val_accuracy: 0.8718\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2320 - accuracy: 0.8675 - val_loss: 0.2462 - val_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2460 - val_accuracy: 0.8718\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2462 - val_accuracy: 0.8718\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2366 - accuracy: 0.8786 - val_loss: 0.2473 - val_accuracy: 0.8718\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2335 - accuracy: 0.8698 - val_loss: 0.2477 - val_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2347 - accuracy: 0.8742 - val_loss: 0.2471 - val_accuracy: 0.8718\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 320us/step - loss: 0.2315 - accuracy: 0.8742 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2439 - val_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2337 - accuracy: 0.8764 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8718\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2468 - val_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2307 - accuracy: 0.8764 - val_loss: 0.2458 - val_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.2465 - val_accuracy: 0.8718\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2299 - accuracy: 0.8742 - val_loss: 0.2513 - val_accuracy: 0.8769\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2466 - val_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2423 - val_accuracy: 0.8718\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2473 - val_accuracy: 0.8974\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.2513 - val_accuracy: 0.8718\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2341 - accuracy: 0.8764 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2301 - accuracy: 0.8720 - val_loss: 0.2487 - val_accuracy: 0.8718\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2320 - accuracy: 0.8720 - val_loss: 0.2464 - val_accuracy: 0.8718\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2311 - accuracy: 0.8742 - val_loss: 0.2457 - val_accuracy: 0.8667\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 347us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 332us/step - loss: 0.2325 - accuracy: 0.8720 - val_loss: 0.2484 - val_accuracy: 0.8769\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.2465 - val_accuracy: 0.8718\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2484 - val_accuracy: 0.8718\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2344 - accuracy: 0.8764 - val_loss: 0.2476 - val_accuracy: 0.8667\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2330 - accuracy: 0.8631 - val_loss: 0.2472 - val_accuracy: 0.8718\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.2461 - val_accuracy: 0.8718\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.2464 - val_accuracy: 0.8667\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2463 - val_accuracy: 0.8667\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2323 - accuracy: 0.8720 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2457 - val_accuracy: 0.8718\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2313 - accuracy: 0.8720 - val_loss: 0.2457 - val_accuracy: 0.8667\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 446us/step - loss: 0.2314 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.2443 - val_accuracy: 0.8718\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 466us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2479 - val_accuracy: 0.8667\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2476 - val_accuracy: 0.8718\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2468 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.2502 - val_accuracy: 0.8718\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 330us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8667\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2327 - accuracy: 0.8742 - val_loss: 0.2452 - val_accuracy: 0.8667\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 317us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2461 - val_accuracy: 0.8667\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2305 - accuracy: 0.8720 - val_loss: 0.2450 - val_accuracy: 0.8667\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8667\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8667\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2308 - accuracy: 0.8742 - val_loss: 0.2443 - val_accuracy: 0.8667\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2452 - val_accuracy: 0.8667\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2312 - accuracy: 0.8698 - val_loss: 0.2456 - val_accuracy: 0.8667\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2328 - accuracy: 0.8720 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2455 - val_accuracy: 0.8667\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2485 - val_accuracy: 0.8718\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2467 - val_accuracy: 0.8667\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.2466 - val_accuracy: 0.8769\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2353 - accuracy: 0.8764 - val_loss: 0.2463 - val_accuracy: 0.8718\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2318 - accuracy: 0.8631 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2309 - accuracy: 0.8786 - val_loss: 0.2452 - val_accuracy: 0.8667\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2306 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8667\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2312 - accuracy: 0.8698 - val_loss: 0.2452 - val_accuracy: 0.8615\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2324 - accuracy: 0.8675 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8667\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.2455 - val_accuracy: 0.8769\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2320 - accuracy: 0.8742 - val_loss: 0.2430 - val_accuracy: 0.8667\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.2499 - val_accuracy: 0.8974\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2469 - val_accuracy: 0.8667\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8667\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2464 - val_accuracy: 0.8667\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2367 - accuracy: 0.8720 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.2478 - val_accuracy: 0.8718\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 429us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2479 - val_accuracy: 0.8718\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2295 - accuracy: 0.8764 - val_loss: 0.2451 - val_accuracy: 0.8667\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2328 - accuracy: 0.8786 - val_loss: 0.2478 - val_accuracy: 0.8769\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2333 - accuracy: 0.8742 - val_loss: 0.2473 - val_accuracy: 0.8974\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 371us/step - loss: 0.2386 - accuracy: 0.8720 - val_loss: 0.2466 - val_accuracy: 0.8974\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.2303 - accuracy: 0.8742 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 407us/step - loss: 0.2324 - accuracy: 0.8720 - val_loss: 0.2474 - val_accuracy: 0.8974\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2440 - val_accuracy: 0.8667\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2327 - accuracy: 0.8742 - val_loss: 0.2444 - val_accuracy: 0.8667\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2326 - accuracy: 0.8698 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2318 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8667\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2334 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8667\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2329 - accuracy: 0.8742 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2324 - accuracy: 0.8742 - val_loss: 0.2437 - val_accuracy: 0.8667\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2304 - accuracy: 0.8764 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 550us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.88 - 0s 216us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2470 - val_accuracy: 0.8974\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2353 - accuracy: 0.8874 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2360 - accuracy: 0.8609 - val_loss: 0.2481 - val_accuracy: 0.8718\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2309 - accuracy: 0.8786 - val_loss: 0.2413 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2313 - accuracy: 0.8698 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2415 - val_accuracy: 0.8667\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2308 - accuracy: 0.8742 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 331us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.2458 - val_accuracy: 0.8769\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2307 - accuracy: 0.8720 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2329 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8667\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2305 - accuracy: 0.8764 - val_loss: 0.2439 - val_accuracy: 0.8667\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2449 - val_accuracy: 0.8667\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2403 - accuracy: 0.8698 - val_loss: 0.2507 - val_accuracy: 0.9026\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2366 - accuracy: 0.8764 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2351 - accuracy: 0.8653 - val_loss: 0.2422 - val_accuracy: 0.8667\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2324 - accuracy: 0.8742 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2347 - accuracy: 0.8720 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2425 - val_accuracy: 0.8769\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2307 - accuracy: 0.8786 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2305 - accuracy: 0.8720 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2471 - val_accuracy: 0.8667\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2358 - accuracy: 0.8720 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2467 - val_accuracy: 0.8667\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.2451 - val_accuracy: 0.8667\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2477 - val_accuracy: 0.8718\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2349 - accuracy: 0.8653 - val_loss: 0.2438 - val_accuracy: 0.8667\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2517 - val_accuracy: 0.8718\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2473 - val_accuracy: 0.8718\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2338 - accuracy: 0.8653 - val_loss: 0.2496 - val_accuracy: 0.8718\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2438 - val_accuracy: 0.8667\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2437 - val_accuracy: 0.8667\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2318 - accuracy: 0.8675 - val_loss: 0.2421 - val_accuracy: 0.8667\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2456 - val_accuracy: 0.8769\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2403 - accuracy: 0.8764 - val_loss: 0.2473 - val_accuracy: 0.9026\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2515 - val_accuracy: 0.9026\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2362 - accuracy: 0.8764 - val_loss: 0.2441 - val_accuracy: 0.8667\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2332 - accuracy: 0.8720 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8667\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2309 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2297 - accuracy: 0.8764 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 118us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2465 - val_accuracy: 0.8769\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8667\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2328 - accuracy: 0.8764 - val_loss: 0.2477 - val_accuracy: 0.8769\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2331 - accuracy: 0.8742 - val_loss: 0.2432 - val_accuracy: 0.8667\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.2462 - val_accuracy: 0.8718\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2319 - accuracy: 0.8786 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.2477 - val_accuracy: 0.8769\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2290 - accuracy: 0.8742 - val_loss: 0.2441 - val_accuracy: 0.8667\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8667\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2326 - accuracy: 0.8720 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2383 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.2482 - val_accuracy: 0.8718\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2351 - accuracy: 0.8675 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8667\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.2434 - val_accuracy: 0.8667\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2345 - accuracy: 0.8720 - val_loss: 0.2448 - val_accuracy: 0.8667\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2482 - val_accuracy: 0.8974\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2338 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.2490 - val_accuracy: 0.8718\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2323 - accuracy: 0.8698 - val_loss: 0.2460 - val_accuracy: 0.8667\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2457 - val_accuracy: 0.8718\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2318 - accuracy: 0.8742 - val_loss: 0.2461 - val_accuracy: 0.8718\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2320 - accuracy: 0.8742 - val_loss: 0.2450 - val_accuracy: 0.8667\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2335 - accuracy: 0.8764 - val_loss: 0.2427 - val_accuracy: 0.8667\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 366us/step - loss: 0.2317 - accuracy: 0.8720 - val_loss: 0.2415 - val_accuracy: 0.8769\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2454 - val_accuracy: 0.8718\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8667\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.2472 - val_accuracy: 0.8718\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2317 - accuracy: 0.8764 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2307 - accuracy: 0.8786 - val_loss: 0.2436 - val_accuracy: 0.8667\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2317 - accuracy: 0.8764 - val_loss: 0.2401 - val_accuracy: 0.8718\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2239 - accuracy: 0.8786 - val_loss: 0.2584 - val_accuracy: 0.9026\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2359 - accuracy: 0.8764 - val_loss: 0.2470 - val_accuracy: 0.8667\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2324 - accuracy: 0.8764 - val_loss: 0.2445 - val_accuracy: 0.8667\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8667\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2319 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.8667\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2334 - accuracy: 0.8786 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2477 - val_accuracy: 0.8974\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2313 - accuracy: 0.8698 - val_loss: 0.2437 - val_accuracy: 0.8667\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2317 - accuracy: 0.8698 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2298 - accuracy: 0.8698 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2445 - val_accuracy: 0.8667\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8667\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2297 - accuracy: 0.8764 - val_loss: 0.2460 - val_accuracy: 0.8718\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.8720 - val_loss: 0.2477 - val_accuracy: 0.8667\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2466 - val_accuracy: 0.8718\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 282us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2463 - val_accuracy: 0.8718\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2290 - accuracy: 0.8786 - val_loss: 0.2485 - val_accuracy: 0.8769\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8667\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2306 - accuracy: 0.8764 - val_loss: 0.2454 - val_accuracy: 0.8718\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 571us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2476 - val_accuracy: 0.8718\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2285 - accuracy: 0.8786 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.87 - 0s 105us/step - loss: 0.2321 - accuracy: 0.8675 - val_loss: 0.2436 - val_accuracy: 0.8667\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8667\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2317 - accuracy: 0.8742 - val_loss: 0.2444 - val_accuracy: 0.8667\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2454 - val_accuracy: 0.8667\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2302 - accuracy: 0.8742 - val_loss: 0.2466 - val_accuracy: 0.8718\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2456 - val_accuracy: 0.8718\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.2437 - val_accuracy: 0.8667\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2314 - accuracy: 0.8764 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2437 - val_accuracy: 0.8667\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2309 - accuracy: 0.8786 - val_loss: 0.2459 - val_accuracy: 0.8718\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2306 - accuracy: 0.8720 - val_loss: 0.2432 - val_accuracy: 0.8667\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2322 - accuracy: 0.8764 - val_loss: 0.2423 - val_accuracy: 0.8769\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8769\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8769\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2307 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2345 - accuracy: 0.8698 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2311 - accuracy: 0.8786 - val_loss: 0.2459 - val_accuracy: 0.8718\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.2476 - val_accuracy: 0.8769\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2313 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8667\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2309 - accuracy: 0.8742 - val_loss: 0.2431 - val_accuracy: 0.8769\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8718\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2330 - accuracy: 0.8742 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2438 - val_accuracy: 0.8667\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 117us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2451 - val_accuracy: 0.8667\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2452 - val_accuracy: 0.8667\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2355 - accuracy: 0.8808 - val_loss: 0.2541 - val_accuracy: 0.8667\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2343 - accuracy: 0.8720 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2473 - val_accuracy: 0.8718\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.2462 - val_accuracy: 0.8718\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2312 - accuracy: 0.8742 - val_loss: 0.2430 - val_accuracy: 0.8667\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8667\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2309 - accuracy: 0.8698 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2287 - accuracy: 0.8720 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8769\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2431 - val_accuracy: 0.8769\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2395 - val_accuracy: 0.8769\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2322 - accuracy: 0.8720 - val_loss: 0.2469 - val_accuracy: 0.8769\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2299 - accuracy: 0.8720 - val_loss: 0.2421 - val_accuracy: 0.9026\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2314 - accuracy: 0.8764 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8667\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2313 - accuracy: 0.8720 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8667\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2330 - accuracy: 0.8742 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2324 - accuracy: 0.8764 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2325 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2297 - accuracy: 0.8742 - val_loss: 0.2412 - val_accuracy: 0.8718\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8769\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8769\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2295 - accuracy: 0.8720 - val_loss: 0.2458 - val_accuracy: 0.8667\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.2456 - val_accuracy: 0.8718\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2287 - accuracy: 0.8786 - val_loss: 0.2459 - val_accuracy: 0.8769\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2307 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8720 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2369 - accuracy: 0.8786 - val_loss: 0.2517 - val_accuracy: 0.8821\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.2494 - val_accuracy: 0.8769\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.2489 - val_accuracy: 0.8718\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2485 - val_accuracy: 0.8821\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.2502 - val_accuracy: 0.8718\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.2480 - val_accuracy: 0.8769\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2317 - accuracy: 0.8742 - val_loss: 0.2465 - val_accuracy: 0.8769\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2326 - accuracy: 0.8742 - val_loss: 0.2466 - val_accuracy: 0.8769\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8769\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2481 - val_accuracy: 0.8769\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2487 - val_accuracy: 0.8718\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2337 - accuracy: 0.8720 - val_loss: 0.2491 - val_accuracy: 0.8718\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2460 - val_accuracy: 0.8769\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2473 - val_accuracy: 0.8769\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2287 - accuracy: 0.8742 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8769\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.87 - 0s 107us/step - loss: 0.2306 - accuracy: 0.8764 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2430 - val_accuracy: 0.8769\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.2425 - val_accuracy: 0.8769\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.2444 - val_accuracy: 0.8821\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.2416 - val_accuracy: 0.8769\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8565 - val_loss: 0.2432 - val_accuracy: 0.8769\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.2456 - val_accuracy: 0.8769\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.2412 - val_accuracy: 0.8769\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.2433 - val_accuracy: 0.8769\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2323 - accuracy: 0.8720 - val_loss: 0.2440 - val_accuracy: 0.8769\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2466 - val_accuracy: 0.8718\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2459 - val_accuracy: 0.8718\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2464 - val_accuracy: 0.8769\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2467 - val_accuracy: 0.8821\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2282 - accuracy: 0.8852 - val_loss: 0.2423 - val_accuracy: 0.8718\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2298 - accuracy: 0.8742 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2291 - accuracy: 0.8742 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2422 - val_accuracy: 0.8769\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2335 - accuracy: 0.8742 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.2478 - val_accuracy: 0.8769\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2308 - accuracy: 0.8720 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2307 - accuracy: 0.8764 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2353 - accuracy: 0.8764 - val_loss: 0.2472 - val_accuracy: 0.8718\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2338 - accuracy: 0.8720 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2329 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2305 - accuracy: 0.8720 - val_loss: 0.2448 - val_accuracy: 0.8769\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8718\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2307 - accuracy: 0.8698 - val_loss: 0.2449 - val_accuracy: 0.8769\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8769\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2293 - accuracy: 0.8764 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2445 - val_accuracy: 0.8769\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2322 - accuracy: 0.8786 - val_loss: 0.2392 - val_accuracy: 0.8769\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2328 - accuracy: 0.8742 - val_loss: 0.2462 - val_accuracy: 0.8718\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2364 - accuracy: 0.8720 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8667\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2315 - accuracy: 0.8742 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2354 - accuracy: 0.8720 - val_loss: 0.2495 - val_accuracy: 0.8769\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2334 - accuracy: 0.8698 - val_loss: 0.2483 - val_accuracy: 0.8718\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2470 - val_accuracy: 0.8769\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2310 - accuracy: 0.8698 - val_loss: 0.2492 - val_accuracy: 0.8769\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2465 - val_accuracy: 0.8718\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2464 - val_accuracy: 0.8769\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.2458 - val_accuracy: 0.8769\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2341 - accuracy: 0.8764 - val_loss: 0.2453 - val_accuracy: 0.8769\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2323 - accuracy: 0.8764 - val_loss: 0.2457 - val_accuracy: 0.8769\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2465 - val_accuracy: 0.8667\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2460 - val_accuracy: 0.8718\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2327 - accuracy: 0.8698 - val_loss: 0.2466 - val_accuracy: 0.8769\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2459 - val_accuracy: 0.8718\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2315 - accuracy: 0.8698 - val_loss: 0.2465 - val_accuracy: 0.8769\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2310 - accuracy: 0.8764 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2461 - val_accuracy: 0.8821\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2328 - accuracy: 0.8653 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2321 - accuracy: 0.8675 - val_loss: 0.2458 - val_accuracy: 0.8769\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.8786 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.2454 - val_accuracy: 0.8821\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2294 - accuracy: 0.8698 - val_loss: 0.2457 - val_accuracy: 0.8769\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2325 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2462 - val_accuracy: 0.8769\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2431 - val_accuracy: 0.8769\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8764 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8769\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2425 - val_accuracy: 0.8769\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2327 - accuracy: 0.8720 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2285 - accuracy: 0.8742 - val_loss: 0.2449 - val_accuracy: 0.8769\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2458 - val_accuracy: 0.8769\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2299 - accuracy: 0.8742 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2303 - accuracy: 0.8720 - val_loss: 0.2536 - val_accuracy: 0.8718\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2545 - val_accuracy: 0.8974\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2455 - val_accuracy: 0.8769\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2337 - accuracy: 0.8808 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2345 - accuracy: 0.8742 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2323 - accuracy: 0.8653 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2311 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2322 - accuracy: 0.8698 - val_loss: 0.2471 - val_accuracy: 0.8821\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2295 - accuracy: 0.8764 - val_loss: 0.2465 - val_accuracy: 0.8718\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2316 - accuracy: 0.8742 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8769\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2433 - val_accuracy: 0.8769\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2330 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2456 - val_accuracy: 0.8769\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2354 - accuracy: 0.8786 - val_loss: 0.2494 - val_accuracy: 0.8821\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2514 - val_accuracy: 0.8769\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2476 - val_accuracy: 0.8718\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2314 - accuracy: 0.8720 - val_loss: 0.2471 - val_accuracy: 0.8769\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2313 - accuracy: 0.8720 - val_loss: 0.2485 - val_accuracy: 0.8718\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 105us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.8742 - val_loss: 0.2412 - val_accuracy: 0.8769\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2437 - val_accuracy: 0.8821\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2318 - accuracy: 0.8764 - val_loss: 0.2436 - val_accuracy: 0.8821\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2407 - val_accuracy: 0.8769\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2287 - accuracy: 0.8742 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 414us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2431 - val_accuracy: 0.8769\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2286 - accuracy: 0.8764 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.2454 - val_accuracy: 0.8821\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2306 - accuracy: 0.8742 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2303 - accuracy: 0.8720 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2328 - accuracy: 0.8808 - val_loss: 0.2463 - val_accuracy: 0.8769\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2288 - accuracy: 0.8764 - val_loss: 0.2461 - val_accuracy: 0.8769\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.2449 - val_accuracy: 0.8769\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.8769\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8769\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.2458 - val_accuracy: 0.8769\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2339 - accuracy: 0.8720 - val_loss: 0.2472 - val_accuracy: 0.8718\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.93 - 0s 109us/step - loss: 0.2337 - accuracy: 0.8764 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2307 - accuracy: 0.8742 - val_loss: 0.2456 - val_accuracy: 0.8718\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2307 - accuracy: 0.8764 - val_loss: 0.2479 - val_accuracy: 0.8769\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2299 - accuracy: 0.8698 - val_loss: 0.2468 - val_accuracy: 0.8667\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2454 - val_accuracy: 0.8718\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2356 - accuracy: 0.8764 - val_loss: 0.2481 - val_accuracy: 0.8667\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8764 - val_loss: 0.2472 - val_accuracy: 0.8718\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2336 - accuracy: 0.8587 - val_loss: 0.2473 - val_accuracy: 0.8615\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.2446 - val_accuracy: 0.8667\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2477 - val_accuracy: 0.8718\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.2480 - val_accuracy: 0.8769\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8667\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2324 - accuracy: 0.8742 - val_loss: 0.2423 - val_accuracy: 0.8769\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2407 - val_accuracy: 0.8769\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2317 - accuracy: 0.8742 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2412 - val_accuracy: 0.8769\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2417 - val_accuracy: 0.8769\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2309 - accuracy: 0.8764 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2351 - accuracy: 0.8720 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2308 - accuracy: 0.8742 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2485 - val_accuracy: 0.8821\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2322 - accuracy: 0.8742 - val_loss: 0.2494 - val_accuracy: 0.8821\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2395 - accuracy: 0.8786 - val_loss: 0.2475 - val_accuracy: 0.8769\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2350 - accuracy: 0.8764 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2319 - accuracy: 0.8742 - val_loss: 0.2467 - val_accuracy: 0.8769\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2321 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8742 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2287 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2314 - accuracy: 0.8742 - val_loss: 0.2431 - val_accuracy: 0.8769\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.8764 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.2433 - val_accuracy: 0.8769\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2315 - accuracy: 0.8742 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.87 - 0s 111us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2412 - val_accuracy: 0.8769\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2423 - val_accuracy: 0.8769\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2311 - accuracy: 0.8742 - val_loss: 0.2421 - val_accuracy: 0.8769\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8769\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2304 - accuracy: 0.8742 - val_loss: 0.2443 - val_accuracy: 0.8769\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2325 - accuracy: 0.8786 - val_loss: 0.2460 - val_accuracy: 0.8769\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2478 - val_accuracy: 0.8821\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.87 - 0s 108us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2313 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2347 - accuracy: 0.8565 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.8742 - val_loss: 0.2443 - val_accuracy: 0.8718\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2445 - val_accuracy: 0.8769\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8769\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2313 - accuracy: 0.8742 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2454 - val_accuracy: 0.8718\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2438 - val_accuracy: 0.8769\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2302 - accuracy: 0.8786 - val_loss: 0.2433 - val_accuracy: 0.8769\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2342 - accuracy: 0.8764 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2413 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 662/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2405 - val_accuracy: 0.8769\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2314 - accuracy: 0.8653 - val_loss: 0.2413 - val_accuracy: 0.8769\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2403 - val_accuracy: 0.8718\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2314 - accuracy: 0.8742 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2297 - accuracy: 0.8720 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2320 - accuracy: 0.8764 - val_loss: 0.2462 - val_accuracy: 0.8667\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2309 - accuracy: 0.8698 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2306 - accuracy: 0.8742 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2454 - val_accuracy: 0.8769\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2291 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2319 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2466 - val_accuracy: 0.8769\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2346 - accuracy: 0.8720 - val_loss: 0.2452 - val_accuracy: 0.8821\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2300 - accuracy: 0.8742 - val_loss: 0.2452 - val_accuracy: 0.8718\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2453 - val_accuracy: 0.8769\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2301 - accuracy: 0.8786 - val_loss: 0.2461 - val_accuracy: 0.8769\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2295 - accuracy: 0.8742 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2308 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2317 - accuracy: 0.8786 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2287 - accuracy: 0.8808 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2312 - accuracy: 0.8720 - val_loss: 0.2451 - val_accuracy: 0.8718\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2333 - accuracy: 0.8764 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2401 - val_accuracy: 0.8718\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2412 - val_accuracy: 0.8718\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2407 - val_accuracy: 0.8718\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2300 - accuracy: 0.8698 - val_loss: 0.2409 - val_accuracy: 0.8769\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2401 - val_accuracy: 0.8718\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2286 - accuracy: 0.8786 - val_loss: 0.2458 - val_accuracy: 0.8667\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2323 - accuracy: 0.8742 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2432 - val_accuracy: 0.8667\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2309 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8667\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2293 - accuracy: 0.8764 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2302 - accuracy: 0.8786 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2353 - accuracy: 0.8764 - val_loss: 0.2427 - val_accuracy: 0.8769\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2409 - val_accuracy: 0.8718\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2318 - accuracy: 0.8698 - val_loss: 0.2457 - val_accuracy: 0.8769\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2290 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2453 - val_accuracy: 0.8769\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.8720 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8742 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.2421 - val_accuracy: 0.8769\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2481 - val_accuracy: 0.8821\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2299 - accuracy: 0.8653 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2297 - accuracy: 0.8742 - val_loss: 0.2413 - val_accuracy: 0.8769\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8769\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2391 - val_accuracy: 0.8769\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.2393 - val_accuracy: 0.8718\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.2394 - val_accuracy: 0.8769\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2299 - accuracy: 0.8742 - val_loss: 0.2394 - val_accuracy: 0.8769\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2398 - val_accuracy: 0.8769\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2408 - val_accuracy: 0.8769\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2290 - accuracy: 0.8786 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2291 - accuracy: 0.8742 - val_loss: 0.2408 - val_accuracy: 0.8769\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2300 - accuracy: 0.8698 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2287 - accuracy: 0.8764 - val_loss: 0.2407 - val_accuracy: 0.8718\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2307 - accuracy: 0.8675 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.2409 - val_accuracy: 0.8769\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2287 - accuracy: 0.8742 - val_loss: 0.2408 - val_accuracy: 0.8769\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2287 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2298 - accuracy: 0.8764 - val_loss: 0.2519 - val_accuracy: 0.8769\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2311 - accuracy: 0.8675 - val_loss: 0.2465 - val_accuracy: 0.8718\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2465 - val_accuracy: 0.8769\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2509 - val_accuracy: 0.8769\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2471 - val_accuracy: 0.8769\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2329 - accuracy: 0.8653 - val_loss: 0.2497 - val_accuracy: 0.8769\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2495 - val_accuracy: 0.8769\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2305 - accuracy: 0.8720 - val_loss: 0.2494 - val_accuracy: 0.8718\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2445 - val_accuracy: 0.8769\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2311 - accuracy: 0.8808 - val_loss: 0.2471 - val_accuracy: 0.8718\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2469 - val_accuracy: 0.8718\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.2446 - val_accuracy: 0.8718\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2423 - val_accuracy: 0.8718\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2283 - accuracy: 0.8764 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 113us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2297 - accuracy: 0.8698 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2418 - val_accuracy: 0.8769\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2303 - accuracy: 0.8698 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8769\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.2494 - val_accuracy: 0.8974\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2282 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2294 - accuracy: 0.8720 - val_loss: 0.2462 - val_accuracy: 0.8769\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2319 - accuracy: 0.8786 - val_loss: 0.2427 - val_accuracy: 0.8769\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2344 - accuracy: 0.8698 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2338 - accuracy: 0.8786 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2334 - accuracy: 0.8764 - val_loss: 0.2439 - val_accuracy: 0.8821\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2318 - accuracy: 0.8764 - val_loss: 0.2412 - val_accuracy: 0.8718\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8742 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2330 - accuracy: 0.8653 - val_loss: 0.2432 - val_accuracy: 0.8769\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2419 - val_accuracy: 0.8718\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2325 - accuracy: 0.8742 - val_loss: 0.2419 - val_accuracy: 0.8769\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2309 - accuracy: 0.8742 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2429 - val_accuracy: 0.8769\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2287 - accuracy: 0.8764 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2293 - accuracy: 0.8698 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2308 - accuracy: 0.8675 - val_loss: 0.2433 - val_accuracy: 0.8769\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2311 - accuracy: 0.8742 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2304 - accuracy: 0.8764 - val_loss: 0.2438 - val_accuracy: 0.8769\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.2421 - val_accuracy: 0.8769\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.2459 - val_accuracy: 0.8769\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2452 - val_accuracy: 0.8769\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2434 - val_accuracy: 0.8769\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.2448 - val_accuracy: 0.8769\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2315 - accuracy: 0.8764 - val_loss: 0.2432 - val_accuracy: 0.8769\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8742 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2294 - accuracy: 0.8742 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8769\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2304 - accuracy: 0.8764 - val_loss: 0.2436 - val_accuracy: 0.8821\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2333 - accuracy: 0.8764 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2291 - accuracy: 0.8764 - val_loss: 0.2442 - val_accuracy: 0.8718\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2457 - val_accuracy: 0.8769\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8718\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2310 - accuracy: 0.8631 - val_loss: 0.2463 - val_accuracy: 0.8821\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 1.00 - 0s 109us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8769\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2331 - accuracy: 0.8631 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2441 - val_accuracy: 0.8769\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2313 - accuracy: 0.8742 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2290 - accuracy: 0.8764 - val_loss: 0.2430 - val_accuracy: 0.8821\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2330 - accuracy: 0.8698 - val_loss: 0.2408 - val_accuracy: 0.8718\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.2440 - val_accuracy: 0.8821\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2304 - accuracy: 0.8720 - val_loss: 0.2417 - val_accuracy: 0.8718\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2404 - val_accuracy: 0.8718\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.2412 - val_accuracy: 0.8718\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8769\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.2413 - val_accuracy: 0.8769\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2307 - accuracy: 0.8675 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2404 - val_accuracy: 0.8718\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2494 - val_accuracy: 0.8821\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2284 - accuracy: 0.8764 - val_loss: 0.2406 - val_accuracy: 0.8718\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2424 - val_accuracy: 0.8718\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8769\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2427 - val_accuracy: 0.8718\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2336 - accuracy: 0.8698 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2302 - accuracy: 0.8742 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2422 - val_accuracy: 0.8718\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.2419 - val_accuracy: 0.8769\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2300 - accuracy: 0.8786 - val_loss: 0.2415 - val_accuracy: 0.8769\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.2441 - val_accuracy: 0.8718\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2419 - val_accuracy: 0.8769\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2300 - accuracy: 0.8742 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2284 - accuracy: 0.8808 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2455 - val_accuracy: 0.8718\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2491 - val_accuracy: 0.8718\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2310 - accuracy: 0.8675 - val_loss: 0.2464 - val_accuracy: 0.8718\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 107us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.2457 - val_accuracy: 0.8769\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8769\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2443 - val_accuracy: 0.8769\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2307 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.2471 - val_accuracy: 0.8769\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2333 - accuracy: 0.8653 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2287 - accuracy: 0.8786 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2431 - val_accuracy: 0.8718\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2327 - accuracy: 0.8720 - val_loss: 0.2447 - val_accuracy: 0.8821\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.2405 - val_accuracy: 0.8718\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2432 - val_accuracy: 0.8718\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2291 - accuracy: 0.8742 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.2425 - val_accuracy: 0.8769\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2294 - accuracy: 0.8764 - val_loss: 0.2422 - val_accuracy: 0.8769\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.8742 - val_loss: 0.2420 - val_accuracy: 0.8769\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2306 - accuracy: 0.8698 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2292 - accuracy: 0.8764 - val_loss: 0.2408 - val_accuracy: 0.8769\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2298 - accuracy: 0.8764 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2300 - accuracy: 0.8764 - val_loss: 0.2422 - val_accuracy: 0.8769\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2434 - val_accuracy: 0.8718\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8742 - val_loss: 0.2403 - val_accuracy: 0.8769\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8769\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2293 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2311 - accuracy: 0.8786 - val_loss: 0.2408 - val_accuracy: 0.8718\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8786 - val_loss: 0.2415 - val_accuracy: 0.8718\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2305 - accuracy: 0.8720 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.2413 - val_accuracy: 0.8718\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2308 - accuracy: 0.8653 - val_loss: 0.2418 - val_accuracy: 0.8769\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2425 - val_accuracy: 0.8718\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2418 - val_accuracy: 0.8769\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2314 - accuracy: 0.8742 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2406 - val_accuracy: 0.8718\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2288 - accuracy: 0.8742 - val_loss: 0.2488 - val_accuracy: 0.8821\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.2411 - val_accuracy: 0.8718\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2308 - accuracy: 0.8742 - val_loss: 0.2408 - val_accuracy: 0.8718\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8764 - val_loss: 0.2421 - val_accuracy: 0.8769\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.2479 - val_accuracy: 0.8718\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2458 - val_accuracy: 0.8718\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2462 - val_accuracy: 0.8718\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8720 - val_loss: 0.2448 - val_accuracy: 0.8769\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2292 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.8769\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8718\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2299 - accuracy: 0.8764 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2316 - accuracy: 0.8742 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2433 - val_accuracy: 0.8718\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2294 - accuracy: 0.8720 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8769\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2344 - accuracy: 0.8764 - val_loss: 0.2440 - val_accuracy: 0.8718\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2350 - accuracy: 0.8698 - val_loss: 0.2463 - val_accuracy: 0.8821\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2318 - accuracy: 0.8764 - val_loss: 0.2449 - val_accuracy: 0.8718\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2314 - accuracy: 0.8698 - val_loss: 0.2500 - val_accuracy: 0.8718\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.2470 - val_accuracy: 0.8718\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2350 - accuracy: 0.8720 - val_loss: 0.2475 - val_accuracy: 0.8769\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2316 - accuracy: 0.8764 - val_loss: 0.2422 - val_accuracy: 0.8769\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2284 - accuracy: 0.8808 - val_loss: 0.2436 - val_accuracy: 0.8769\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8742 - val_loss: 0.2428 - val_accuracy: 0.8718\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2297 - accuracy: 0.8698 - val_loss: 0.2439 - val_accuracy: 0.8718\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2340 - accuracy: 0.8786 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8718\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2409 - accuracy: 0.8698 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8769\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8718\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2285 - accuracy: 0.8764 - val_loss: 0.2454 - val_accuracy: 0.8718\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8718\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2435 - val_accuracy: 0.8769\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.2427 - val_accuracy: 0.8769\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2311 - accuracy: 0.8786 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8718\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2303 - accuracy: 0.8720 - val_loss: 0.2453 - val_accuracy: 0.8718\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2293 - accuracy: 0.8808 - val_loss: 0.2457 - val_accuracy: 0.8718\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2470 - val_accuracy: 0.8718\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2437 - val_accuracy: 0.8769\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2305 - accuracy: 0.8653 - val_loss: 0.2439 - val_accuracy: 0.8769\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.2418 - val_accuracy: 0.8718\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2302 - accuracy: 0.8764 - val_loss: 0.2414 - val_accuracy: 0.8718\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2363 - accuracy: 0.8565 - val_loss: 0.2410 - val_accuracy: 0.8718\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2308 - accuracy: 0.8720 - val_loss: 0.2413 - val_accuracy: 0.8769\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2287 - accuracy: 0.8764 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.2416 - val_accuracy: 0.8718\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.2423 - val_accuracy: 0.8718\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.2451 - val_accuracy: 0.8769\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.2445 - val_accuracy: 0.8718\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2289 - accuracy: 0.8764 - val_loss: 0.2428 - val_accuracy: 0.8769\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.2420 - val_accuracy: 0.8718\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2306 - accuracy: 0.8786 - val_loss: 0.2421 - val_accuracy: 0.8718\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2306 - accuracy: 0.8764 - val_loss: 0.2444 - val_accuracy: 0.8769\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 235us/step - loss: 0.2311 - accuracy: 0.8764 - val_loss: 0.2450 - val_accuracy: 0.8769\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.2447 - val_accuracy: 0.8718\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8786 - val_loss: 0.2438 - val_accuracy: 0.8718\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2296 - accuracy: 0.8786 - val_loss: 0.2430 - val_accuracy: 0.8718\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.2446 - val_accuracy: 0.8769\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2299 - accuracy: 0.8720 - val_loss: 0.2429 - val_accuracy: 0.8718\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.2426 - val_accuracy: 0.8718\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.2449 - val_accuracy: 0.8769\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.81 - 0s 105us/step - loss: 0.2315 - accuracy: 0.8786 - val_loss: 0.2465 - val_accuracy: 0.8769\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 87.74%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [4.98404260e-01, 5.01595740e-01, 3.71497030e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [3.45180700e-01, 6.54819370e-01, 4.03905930e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [2.77232640e-04, 9.99722800e-01, 2.69030090e-09],\n",
       "       [8.64035040e-02, 9.13596450e-01, 3.01891400e-10],\n",
       "       [6.98568860e-03, 9.93014340e-01, 1.54115170e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [5.71686500e-01, 4.28313500e-01, 6.65629000e-12],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [9.99813850e-01, 1.86203220e-04, 9.17890300e-16],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.89857260e-05, 9.99931000e-01, 1.07364910e-12],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [4.98404260e-01, 5.01595740e-01, 3.71497030e-10],\n",
       "       [1.00000000e+00, 1.35362170e-08, 3.11535220e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [9.99792900e-01, 2.07100830e-04, 2.47418320e-13],\n",
       "       [6.47801440e-03, 9.93522000e-01, 4.54275840e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.34345970e-07, 9.99999900e-01, 7.18154540e-13],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [9.10149400e-03, 9.90898550e-01, 1.03178020e-10],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.42210140e-01, 8.57789930e-01, 7.69471500e-11],\n",
       "       [9.99997740e-01, 2.29021600e-06, 1.32218680e-15],\n",
       "       [1.54035000e-17, 1.00000000e+00, 9.01197700e-16],\n",
       "       [2.21857000e-04, 9.99778200e-01, 7.33557800e-15],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [9.93138970e-01, 6.86096300e-03, 3.14178500e-08],\n",
       "       [7.52288000e-06, 9.99992500e-01, 3.60762220e-11],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.47801440e-03, 9.93522000e-01, 4.54275840e-10],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.42210140e-01, 8.57789930e-01, 7.69471500e-11],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.26233560e-07, 9.99999760e-01, 1.06021900e-07],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [9.99998450e-01, 1.59198430e-06, 1.85485820e-14],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [2.22908570e-01, 7.77091260e-01, 1.18411420e-07],\n",
       "       [9.56873000e-01, 4.31269600e-02, 9.58237500e-12],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [9.54895400e-15, 1.00000000e+00, 7.04771270e-12],\n",
       "       [2.22908570e-01, 7.77091260e-01, 1.18411420e-07],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.47801440e-03, 9.93522000e-01, 4.54275840e-10],\n",
       "       [1.00000000e+00, 1.20108280e-08, 6.48665000e-17],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [9.10149400e-03, 9.90898550e-01, 1.03178020e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.47801440e-03, 9.93522000e-01, 4.54275840e-10],\n",
       "       [1.66171110e-13, 1.00000000e+00, 2.65565530e-24],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.98568860e-03, 9.93014340e-01, 1.54115170e-09],\n",
       "       [3.34661070e-01, 6.65338930e-01, 3.62169200e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [9.90020630e-01, 9.97940000e-03, 2.40290760e-08],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.42210140e-01, 8.57789930e-01, 7.69471500e-11],\n",
       "       [9.90033300e-01, 9.96666500e-03, 1.09860926e-10],\n",
       "       [8.64035040e-02, 9.13596450e-01, 3.01891400e-10],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.56046430e-05, 9.99984400e-01, 1.40990500e-12],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [8.64035040e-02, 9.13596450e-01, 3.01891400e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.54035000e-17, 1.00000000e+00, 9.01197700e-16],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [4.98404260e-01, 5.01595740e-01, 3.71497030e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.45814000e-10, 1.00000000e+00, 4.82796460e-22],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.47399210e-03, 9.98526040e-01, 2.89906600e-13],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.34345970e-07, 9.99999900e-01, 7.18154540e-13],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [8.50647700e-01, 1.49352220e-01, 5.11010700e-09],\n",
       "       [5.71686500e-01, 4.28313500e-01, 6.65629000e-12],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.47399210e-03, 9.98526040e-01, 2.89906600e-13],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [2.32012810e-13, 1.00000000e+00, 6.27615600e-15],\n",
       "       [5.53437530e-01, 4.46562400e-01, 1.64995040e-08],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [9.90020630e-01, 9.97940000e-03, 2.40290760e-08],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.45814000e-10, 1.00000000e+00, 4.82796460e-22],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [5.53437530e-01, 4.46562400e-01, 1.64995040e-08],\n",
       "       [1.34345970e-07, 9.99999900e-01, 7.18154540e-13],\n",
       "       [1.00000000e+00, 1.20108280e-08, 6.48665000e-17],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.20108280e-08, 6.48665000e-17],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [5.72597270e-01, 4.27402820e-01, 1.25207520e-08],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [9.69961200e-01, 3.00387850e-02, 4.02893940e-10],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [8.64035040e-02, 9.13596450e-01, 3.01891400e-10],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [5.72597270e-01, 4.27402820e-01, 1.25207520e-08],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [5.71686500e-01, 4.28313500e-01, 6.65629000e-12],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [4.98404260e-01, 5.01595740e-01, 3.71497030e-10],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [2.21857000e-04, 9.99778200e-01, 7.33557800e-15],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [2.65905000e-10, 1.00000000e+00, 2.24636070e-14],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [9.66866600e-01, 3.31333600e-02, 7.79954800e-12],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [5.53437530e-01, 4.46562400e-01, 1.64995040e-08],\n",
       "       [6.25927300e-01, 3.74072670e-01, 6.69614160e-11],\n",
       "       [5.53437530e-01, 4.46562400e-01, 1.64995040e-08],\n",
       "       [2.32012810e-13, 1.00000000e+00, 6.27615600e-15],\n",
       "       [5.53437530e-01, 4.46562400e-01, 1.64995040e-08],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.66171110e-13, 1.00000000e+00, 2.65565530e-24],\n",
       "       [5.72597270e-01, 4.27402820e-01, 1.25207520e-08],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.56046430e-05, 9.99984400e-01, 1.40990500e-12],\n",
       "       [4.98404260e-01, 5.01595740e-01, 3.71497030e-10],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.07648910e-09, 4.21377950e-08, 1.00000000e+00],\n",
       "       [1.05227550e-07, 9.99999900e-01, 1.10155890e-28],\n",
       "       [7.23955600e-01, 2.76044400e-01, 1.17602990e-09],\n",
       "       [1.05227550e-07, 9.99999900e-01, 1.10155890e-28],\n",
       "       [1.54035000e-17, 1.00000000e+00, 9.01197700e-16],\n",
       "       [6.88895900e-01, 3.11104150e-01, 2.22895800e-09],\n",
       "       [1.09771880e-09, 4.40465500e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969664694280079"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969664694280079"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS218     1\n",
       "1    NRS260     1\n",
       "2    NRS162     0\n",
       "3    NRS177     0\n",
       "4    NRS209     2\n",
       "..      ...   ...\n",
       "190  NRS383     1\n",
       "191  NRS218     1\n",
       "192  NRS209     2\n",
       "193  SR2852     1\n",
       "194  NRS248     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 430us/step - loss: 1.2912 - accuracy: 0.4592 - val_loss: 0.8441 - val_accuracy: 0.5333\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.7507 - accuracy: 0.6932 - val_loss: 0.6594 - val_accuracy: 0.7487\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.6182 - accuracy: 0.7263 - val_loss: 0.5640 - val_accuracy: 0.7436\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.5431 - accuracy: 0.7550 - val_loss: 0.5057 - val_accuracy: 0.8103\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.4939 - accuracy: 0.8057 - val_loss: 0.4609 - val_accuracy: 0.8103\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.4604 - accuracy: 0.7881 - val_loss: 0.4371 - val_accuracy: 0.8205\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 309us/step - loss: 0.4401 - accuracy: 0.7947 - val_loss: 0.4219 - val_accuracy: 0.8051\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.4242 - accuracy: 0.8035 - val_loss: 0.4067 - val_accuracy: 0.8051\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.4121 - accuracy: 0.7925 - val_loss: 0.4138 - val_accuracy: 0.7795\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.4007 - accuracy: 0.8256 - val_loss: 0.3906 - val_accuracy: 0.8051\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.3886 - accuracy: 0.8278 - val_loss: 0.3850 - val_accuracy: 0.8103\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.3833 - accuracy: 0.8499 - val_loss: 0.3776 - val_accuracy: 0.8154\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.3713 - accuracy: 0.8389 - val_loss: 0.3779 - val_accuracy: 0.7897\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.3662 - accuracy: 0.8389 - val_loss: 0.3713 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.3605 - accuracy: 0.8300 - val_loss: 0.3773 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.3584 - accuracy: 0.8278 - val_loss: 0.3718 - val_accuracy: 0.7897\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.3526 - accuracy: 0.8278 - val_loss: 0.3640 - val_accuracy: 0.7949\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.3496 - accuracy: 0.8300 - val_loss: 0.3622 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.3456 - accuracy: 0.8278 - val_loss: 0.3675 - val_accuracy: 0.7897\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.3401 - accuracy: 0.8256 - val_loss: 0.3686 - val_accuracy: 0.8051\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.3414 - accuracy: 0.8190 - val_loss: 0.3584 - val_accuracy: 0.7846\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 309us/step - loss: 0.3332 - accuracy: 0.8366 - val_loss: 0.3571 - val_accuracy: 0.7846\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.3330 - accuracy: 0.8234 - val_loss: 0.3578 - val_accuracy: 0.7949\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.3274 - accuracy: 0.8256 - val_loss: 0.3663 - val_accuracy: 0.7949\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.3251 - accuracy: 0.8322 - val_loss: 0.3568 - val_accuracy: 0.7949\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.3268 - accuracy: 0.8278 - val_loss: 0.3657 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.3226 - accuracy: 0.8411 - val_loss: 0.3638 - val_accuracy: 0.7949\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.3165 - accuracy: 0.8455 - val_loss: 0.3508 - val_accuracy: 0.8154\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.3247 - accuracy: 0.8411 - val_loss: 0.3703 - val_accuracy: 0.7897\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.3172 - accuracy: 0.8433 - val_loss: 0.3602 - val_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.3128 - accuracy: 0.8389 - val_loss: 0.3566 - val_accuracy: 0.7846\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 341us/step - loss: 0.3154 - accuracy: 0.8322 - val_loss: 0.3589 - val_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 402us/step - loss: 0.3156 - accuracy: 0.8433 - val_loss: 0.3616 - val_accuracy: 0.7897\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.3074 - accuracy: 0.8455 - val_loss: 0.3541 - val_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.3103 - accuracy: 0.8389 - val_loss: 0.3582 - val_accuracy: 0.7897\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.3075 - accuracy: 0.8455 - val_loss: 0.3560 - val_accuracy: 0.7897\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.3034 - accuracy: 0.8455 - val_loss: 0.3727 - val_accuracy: 0.7897\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 293us/step - loss: 0.3043 - accuracy: 0.8433 - val_loss: 0.3562 - val_accuracy: 0.8051\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.3014 - accuracy: 0.8521 - val_loss: 0.3565 - val_accuracy: 0.7897\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2985 - accuracy: 0.8411 - val_loss: 0.3620 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2970 - accuracy: 0.8543 - val_loss: 0.3645 - val_accuracy: 0.7897\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.3009 - accuracy: 0.8521 - val_loss: 0.3552 - val_accuracy: 0.8051\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2984 - accuracy: 0.8477 - val_loss: 0.3535 - val_accuracy: 0.8051\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2949 - accuracy: 0.8587 - val_loss: 0.3547 - val_accuracy: 0.7949\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2929 - accuracy: 0.8565 - val_loss: 0.3546 - val_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2947 - accuracy: 0.8455 - val_loss: 0.3641 - val_accuracy: 0.8051\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2950 - accuracy: 0.8499 - val_loss: 0.3594 - val_accuracy: 0.8205\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2987 - accuracy: 0.8543 - val_loss: 0.3576 - val_accuracy: 0.8103\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.2927 - accuracy: 0.8698 - val_loss: 0.3544 - val_accuracy: 0.8051\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2869 - accuracy: 0.8653 - val_loss: 0.3656 - val_accuracy: 0.8051\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2872 - accuracy: 0.8631 - val_loss: 0.3550 - val_accuracy: 0.8051\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2892 - accuracy: 0.8587 - val_loss: 0.3579 - val_accuracy: 0.8051\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2850 - accuracy: 0.8631 - val_loss: 0.3554 - val_accuracy: 0.8205\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2912 - accuracy: 0.8455 - val_loss: 0.3551 - val_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2853 - accuracy: 0.8675 - val_loss: 0.3660 - val_accuracy: 0.8051\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2819 - accuracy: 0.8675 - val_loss: 0.3531 - val_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2822 - accuracy: 0.8653 - val_loss: 0.3733 - val_accuracy: 0.8051\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2832 - accuracy: 0.8675 - val_loss: 0.3638 - val_accuracy: 0.8051\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2789 - accuracy: 0.8698 - val_loss: 0.3574 - val_accuracy: 0.8308\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2807 - accuracy: 0.8543 - val_loss: 0.3583 - val_accuracy: 0.8359\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2856 - accuracy: 0.8521 - val_loss: 0.3597 - val_accuracy: 0.8308\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2802 - accuracy: 0.8675 - val_loss: 0.3525 - val_accuracy: 0.8308\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2777 - accuracy: 0.8631 - val_loss: 0.3676 - val_accuracy: 0.8205\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2879 - accuracy: 0.8543 - val_loss: 0.3625 - val_accuracy: 0.8103\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2816 - accuracy: 0.8631 - val_loss: 0.3606 - val_accuracy: 0.8308\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2773 - accuracy: 0.8653 - val_loss: 0.3704 - val_accuracy: 0.8051\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2755 - accuracy: 0.8675 - val_loss: 0.3675 - val_accuracy: 0.8103\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2756 - accuracy: 0.8631 - val_loss: 0.3617 - val_accuracy: 0.8308\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2758 - accuracy: 0.8720 - val_loss: 0.3723 - val_accuracy: 0.7949\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2753 - accuracy: 0.8720 - val_loss: 0.3694 - val_accuracy: 0.8103\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2721 - accuracy: 0.8675 - val_loss: 0.3618 - val_accuracy: 0.8308\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2744 - accuracy: 0.8675 - val_loss: 0.3660 - val_accuracy: 0.8308\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2774 - accuracy: 0.8587 - val_loss: 0.3660 - val_accuracy: 0.8359\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2718 - accuracy: 0.8653 - val_loss: 0.3752 - val_accuracy: 0.8103\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2731 - accuracy: 0.8675 - val_loss: 0.3636 - val_accuracy: 0.8308\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2707 - accuracy: 0.8631 - val_loss: 0.3620 - val_accuracy: 0.8308\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2747 - accuracy: 0.8720 - val_loss: 0.3657 - val_accuracy: 0.8308\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2709 - accuracy: 0.8675 - val_loss: 0.3700 - val_accuracy: 0.8308\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2726 - accuracy: 0.8587 - val_loss: 0.3793 - val_accuracy: 0.7949\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2687 - accuracy: 0.8653 - val_loss: 0.3669 - val_accuracy: 0.8359\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2673 - accuracy: 0.8698 - val_loss: 0.3824 - val_accuracy: 0.7949\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2668 - accuracy: 0.8675 - val_loss: 0.3637 - val_accuracy: 0.8308\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2690 - accuracy: 0.8675 - val_loss: 0.3745 - val_accuracy: 0.8308\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2688 - accuracy: 0.8675 - val_loss: 0.3659 - val_accuracy: 0.8308\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2673 - accuracy: 0.8698 - val_loss: 0.3926 - val_accuracy: 0.8051\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2707 - accuracy: 0.8565 - val_loss: 0.3648 - val_accuracy: 0.8308\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2696 - accuracy: 0.8764 - val_loss: 0.3668 - val_accuracy: 0.8359\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2716 - accuracy: 0.8698 - val_loss: 0.3750 - val_accuracy: 0.8205\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2743 - accuracy: 0.8587 - val_loss: 0.3800 - val_accuracy: 0.8308\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2670 - accuracy: 0.8742 - val_loss: 0.3783 - val_accuracy: 0.8308\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2675 - accuracy: 0.8675 - val_loss: 0.3702 - val_accuracy: 0.8308\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2676 - accuracy: 0.8631 - val_loss: 0.3749 - val_accuracy: 0.8359\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2716 - accuracy: 0.8742 - val_loss: 0.3676 - val_accuracy: 0.8359\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2685 - accuracy: 0.8675 - val_loss: 0.3831 - val_accuracy: 0.8308\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2628 - accuracy: 0.8675 - val_loss: 0.3738 - val_accuracy: 0.8308\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2646 - accuracy: 0.8698 - val_loss: 0.3887 - val_accuracy: 0.8154\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2660 - accuracy: 0.8764 - val_loss: 0.3823 - val_accuracy: 0.8308\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2649 - accuracy: 0.8698 - val_loss: 0.3741 - val_accuracy: 0.8359\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2667 - accuracy: 0.8698 - val_loss: 0.3732 - val_accuracy: 0.8359\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2635 - accuracy: 0.8742 - val_loss: 0.3740 - val_accuracy: 0.8359\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2631 - accuracy: 0.8698 - val_loss: 0.3808 - val_accuracy: 0.8154\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2639 - accuracy: 0.8675 - val_loss: 0.3853 - val_accuracy: 0.8308\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2590 - accuracy: 0.8675 - val_loss: 0.3804 - val_accuracy: 0.8308\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2629 - accuracy: 0.8675 - val_loss: 0.3787 - val_accuracy: 0.8359\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2595 - accuracy: 0.8698 - val_loss: 0.3818 - val_accuracy: 0.8308\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2612 - accuracy: 0.8698 - val_loss: 0.3701 - val_accuracy: 0.8359\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2644 - accuracy: 0.8631 - val_loss: 0.3934 - val_accuracy: 0.8359\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2587 - accuracy: 0.8698 - val_loss: 0.3736 - val_accuracy: 0.8359\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2618 - accuracy: 0.8587 - val_loss: 0.3754 - val_accuracy: 0.8308\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2599 - accuracy: 0.8698 - val_loss: 0.3867 - val_accuracy: 0.8410\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2598 - accuracy: 0.8786 - val_loss: 0.3801 - val_accuracy: 0.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2598 - accuracy: 0.8720 - val_loss: 0.3930 - val_accuracy: 0.8410\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2580 - accuracy: 0.8786 - val_loss: 0.3772 - val_accuracy: 0.8359\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2576 - accuracy: 0.8675 - val_loss: 0.3883 - val_accuracy: 0.8410\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2588 - accuracy: 0.8720 - val_loss: 0.3999 - val_accuracy: 0.8308\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2630 - accuracy: 0.8742 - val_loss: 0.3788 - val_accuracy: 0.8359\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2653 - accuracy: 0.8720 - val_loss: 0.3932 - val_accuracy: 0.8359\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2583 - accuracy: 0.8631 - val_loss: 0.4001 - val_accuracy: 0.8410\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2557 - accuracy: 0.8742 - val_loss: 0.3972 - val_accuracy: 0.8205\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2594 - accuracy: 0.8742 - val_loss: 0.4151 - val_accuracy: 0.8410\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2660 - accuracy: 0.8742 - val_loss: 0.3929 - val_accuracy: 0.8359\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2584 - accuracy: 0.8808 - val_loss: 0.3800 - val_accuracy: 0.8308\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2643 - accuracy: 0.8698 - val_loss: 0.3874 - val_accuracy: 0.8359\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2663 - accuracy: 0.8764 - val_loss: 0.3973 - val_accuracy: 0.8308\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2545 - accuracy: 0.8675 - val_loss: 0.3967 - val_accuracy: 0.8359\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2517 - accuracy: 0.8786 - val_loss: 0.4178 - val_accuracy: 0.8359\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2613 - accuracy: 0.8720 - val_loss: 0.3962 - val_accuracy: 0.8359\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2540 - accuracy: 0.8742 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2536 - accuracy: 0.8698 - val_loss: 0.3926 - val_accuracy: 0.8359\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2557 - accuracy: 0.8675 - val_loss: 0.4033 - val_accuracy: 0.8308\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2563 - accuracy: 0.8653 - val_loss: 0.3989 - val_accuracy: 0.8359\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2637 - accuracy: 0.8720 - val_loss: 0.4022 - val_accuracy: 0.8359\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2568 - accuracy: 0.8720 - val_loss: 0.4049 - val_accuracy: 0.8308\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2551 - accuracy: 0.8675 - val_loss: 0.4048 - val_accuracy: 0.8359\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2570 - accuracy: 0.8698 - val_loss: 0.4039 - val_accuracy: 0.8359\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2541 - accuracy: 0.8764 - val_loss: 0.3987 - val_accuracy: 0.8359\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2543 - accuracy: 0.8742 - val_loss: 0.4066 - val_accuracy: 0.8359\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2663 - accuracy: 0.8631 - val_loss: 0.3983 - val_accuracy: 0.8359\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2526 - accuracy: 0.8786 - val_loss: 0.4088 - val_accuracy: 0.8359\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2534 - accuracy: 0.8653 - val_loss: 0.4031 - val_accuracy: 0.8359\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2526 - accuracy: 0.8720 - val_loss: 0.4039 - val_accuracy: 0.8308\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2578 - accuracy: 0.8764 - val_loss: 0.4085 - val_accuracy: 0.8308\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2531 - accuracy: 0.8720 - val_loss: 0.4179 - val_accuracy: 0.8410\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2549 - accuracy: 0.8653 - val_loss: 0.4074 - val_accuracy: 0.8359\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2522 - accuracy: 0.8742 - val_loss: 0.4138 - val_accuracy: 0.8359\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2514 - accuracy: 0.8742 - val_loss: 0.4218 - val_accuracy: 0.8410\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2565 - accuracy: 0.8742 - val_loss: 0.4061 - val_accuracy: 0.8359\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2562 - accuracy: 0.8698 - val_loss: 0.4226 - val_accuracy: 0.8308\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2547 - accuracy: 0.8720 - val_loss: 0.4272 - val_accuracy: 0.8308\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2524 - accuracy: 0.8720 - val_loss: 0.4082 - val_accuracy: 0.8308\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2518 - accuracy: 0.8764 - val_loss: 0.4163 - val_accuracy: 0.8359\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2528 - accuracy: 0.8830 - val_loss: 0.4195 - val_accuracy: 0.8359\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2530 - accuracy: 0.8720 - val_loss: 0.4088 - val_accuracy: 0.8359\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2536 - accuracy: 0.8653 - val_loss: 0.4120 - val_accuracy: 0.8359\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2496 - accuracy: 0.8808 - val_loss: 0.4071 - val_accuracy: 0.8359\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2519 - accuracy: 0.8720 - val_loss: 0.4115 - val_accuracy: 0.8359\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2547 - accuracy: 0.8764 - val_loss: 0.4181 - val_accuracy: 0.8359\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2499 - accuracy: 0.8698 - val_loss: 0.4229 - val_accuracy: 0.8410\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2487 - accuracy: 0.8742 - val_loss: 0.4129 - val_accuracy: 0.8359\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2506 - accuracy: 0.8720 - val_loss: 0.4058 - val_accuracy: 0.8359\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2513 - accuracy: 0.8786 - val_loss: 0.4176 - val_accuracy: 0.8359\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2486 - accuracy: 0.8742 - val_loss: 0.4139 - val_accuracy: 0.8359\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2527 - accuracy: 0.8742 - val_loss: 0.4200 - val_accuracy: 0.8359\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2494 - accuracy: 0.8764 - val_loss: 0.4221 - val_accuracy: 0.8359\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2489 - accuracy: 0.8698 - val_loss: 0.4225 - val_accuracy: 0.8410\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2495 - accuracy: 0.8720 - val_loss: 0.4182 - val_accuracy: 0.8359\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2478 - accuracy: 0.8742 - val_loss: 0.4143 - val_accuracy: 0.8359\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2489 - accuracy: 0.8698 - val_loss: 0.4103 - val_accuracy: 0.8359\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2472 - accuracy: 0.8764 - val_loss: 0.4250 - val_accuracy: 0.8359\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2471 - accuracy: 0.8830 - val_loss: 0.4405 - val_accuracy: 0.8308\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2570 - accuracy: 0.8720 - val_loss: 0.4246 - val_accuracy: 0.8410\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2479 - accuracy: 0.8742 - val_loss: 0.4165 - val_accuracy: 0.8359\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2457 - accuracy: 0.8764 - val_loss: 0.4348 - val_accuracy: 0.8410\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2496 - accuracy: 0.8720 - val_loss: 0.4293 - val_accuracy: 0.8359\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2483 - accuracy: 0.8764 - val_loss: 0.4174 - val_accuracy: 0.8410\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2491 - accuracy: 0.8742 - val_loss: 0.4425 - val_accuracy: 0.8308\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2530 - accuracy: 0.8786 - val_loss: 0.4234 - val_accuracy: 0.8359\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2441 - accuracy: 0.8830 - val_loss: 0.4192 - val_accuracy: 0.8359\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2481 - accuracy: 0.8808 - val_loss: 0.4395 - val_accuracy: 0.8308\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2540 - accuracy: 0.8830 - val_loss: 0.4494 - val_accuracy: 0.8359\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2517 - accuracy: 0.8852 - val_loss: 0.4360 - val_accuracy: 0.8359\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2451 - accuracy: 0.8808 - val_loss: 0.4444 - val_accuracy: 0.8410\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2505 - accuracy: 0.8720 - val_loss: 0.4290 - val_accuracy: 0.8410\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2464 - accuracy: 0.8742 - val_loss: 0.4205 - val_accuracy: 0.8359\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2477 - accuracy: 0.8786 - val_loss: 0.4251 - val_accuracy: 0.8359\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2486 - accuracy: 0.8830 - val_loss: 0.4335 - val_accuracy: 0.8410\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2501 - accuracy: 0.8698 - val_loss: 0.4273 - val_accuracy: 0.8410\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2445 - accuracy: 0.8698 - val_loss: 0.4268 - val_accuracy: 0.8359\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2480 - accuracy: 0.8742 - val_loss: 0.4169 - val_accuracy: 0.8359\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2458 - accuracy: 0.8742 - val_loss: 0.4229 - val_accuracy: 0.8359\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2447 - accuracy: 0.8742 - val_loss: 0.4247 - val_accuracy: 0.8410\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2456 - accuracy: 0.8742 - val_loss: 0.4240 - val_accuracy: 0.8359\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2507 - accuracy: 0.8764 - val_loss: 0.4292 - val_accuracy: 0.8359\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2481 - accuracy: 0.8830 - val_loss: 0.4481 - val_accuracy: 0.8410\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2471 - accuracy: 0.8808 - val_loss: 0.4373 - val_accuracy: 0.8410\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2488 - accuracy: 0.8764 - val_loss: 0.4249 - val_accuracy: 0.8359\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2529 - accuracy: 0.8698 - val_loss: 0.4283 - val_accuracy: 0.8359\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2558 - accuracy: 0.8720 - val_loss: 0.4278 - val_accuracy: 0.8359\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2451 - accuracy: 0.8808 - val_loss: 0.4345 - val_accuracy: 0.8410\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2472 - accuracy: 0.8698 - val_loss: 0.4282 - val_accuracy: 0.8359\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2442 - accuracy: 0.8720 - val_loss: 0.4348 - val_accuracy: 0.8359\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2455 - accuracy: 0.8764 - val_loss: 0.4441 - val_accuracy: 0.8359\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2479 - accuracy: 0.8808 - val_loss: 0.4281 - val_accuracy: 0.8410\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2482 - accuracy: 0.8698 - val_loss: 0.4316 - val_accuracy: 0.8359\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2510 - accuracy: 0.8764 - val_loss: 0.4516 - val_accuracy: 0.8359\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.4456 - val_accuracy: 0.8462\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2415 - accuracy: 0.8698 - val_loss: 0.4304 - val_accuracy: 0.8410\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2430 - accuracy: 0.8808 - val_loss: 0.4382 - val_accuracy: 0.8410\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2443 - accuracy: 0.8808 - val_loss: 0.4428 - val_accuracy: 0.8359\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2422 - accuracy: 0.8808 - val_loss: 0.4396 - val_accuracy: 0.8359\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2462 - accuracy: 0.8830 - val_loss: 0.4376 - val_accuracy: 0.8359\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2468 - accuracy: 0.8808 - val_loss: 0.4430 - val_accuracy: 0.8359\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2446 - accuracy: 0.8764 - val_loss: 0.4373 - val_accuracy: 0.8359\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2517 - accuracy: 0.8720 - val_loss: 0.4441 - val_accuracy: 0.8359\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.4490 - val_accuracy: 0.8410\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2468 - accuracy: 0.8808 - val_loss: 0.4418 - val_accuracy: 0.8359\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2469 - accuracy: 0.8653 - val_loss: 0.4373 - val_accuracy: 0.8410\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2428 - accuracy: 0.8742 - val_loss: 0.4489 - val_accuracy: 0.8359\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2433 - accuracy: 0.8808 - val_loss: 0.4372 - val_accuracy: 0.8410\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2442 - accuracy: 0.8830 - val_loss: 0.4450 - val_accuracy: 0.8410\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2507 - accuracy: 0.8764 - val_loss: 0.4488 - val_accuracy: 0.8410\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 137us/step - loss: 0.2403 - accuracy: 0.8852 - val_loss: 0.4434 - val_accuracy: 0.8359\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2463 - accuracy: 0.8764 - val_loss: 0.4490 - val_accuracy: 0.8359\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2478 - accuracy: 0.8852 - val_loss: 0.4786 - val_accuracy: 0.8359\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2460 - accuracy: 0.8764 - val_loss: 0.4543 - val_accuracy: 0.8359\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2427 - accuracy: 0.8720 - val_loss: 0.4455 - val_accuracy: 0.8359\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2435 - accuracy: 0.8786 - val_loss: 0.4585 - val_accuracy: 0.8410\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2410 - accuracy: 0.8786 - val_loss: 0.4553 - val_accuracy: 0.8359\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2441 - accuracy: 0.8808 - val_loss: 0.4461 - val_accuracy: 0.8359\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2487 - accuracy: 0.8808 - val_loss: 0.4563 - val_accuracy: 0.8359\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2450 - accuracy: 0.8786 - val_loss: 0.4521 - val_accuracy: 0.8410\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2446 - accuracy: 0.8764 - val_loss: 0.4526 - val_accuracy: 0.8410\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2463 - accuracy: 0.8852 - val_loss: 0.4433 - val_accuracy: 0.8410\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2399 - accuracy: 0.8852 - val_loss: 0.4501 - val_accuracy: 0.8410\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2419 - accuracy: 0.8764 - val_loss: 0.4470 - val_accuracy: 0.8256\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2423 - accuracy: 0.8742 - val_loss: 0.4511 - val_accuracy: 0.8359\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2417 - accuracy: 0.8808 - val_loss: 0.4506 - val_accuracy: 0.8359\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2420 - accuracy: 0.8764 - val_loss: 0.4585 - val_accuracy: 0.8410\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2415 - accuracy: 0.8830 - val_loss: 0.4538 - val_accuracy: 0.8410\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2481 - accuracy: 0.8808 - val_loss: 0.4494 - val_accuracy: 0.8462\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2438 - accuracy: 0.8830 - val_loss: 0.4550 - val_accuracy: 0.8410\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2383 - accuracy: 0.8830 - val_loss: 0.4557 - val_accuracy: 0.8359\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2470 - accuracy: 0.8764 - val_loss: 0.4510 - val_accuracy: 0.8410\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2423 - accuracy: 0.8852 - val_loss: 0.4507 - val_accuracy: 0.8410\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2421 - accuracy: 0.8874 - val_loss: 0.4578 - val_accuracy: 0.8410\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2421 - accuracy: 0.8764 - val_loss: 0.4400 - val_accuracy: 0.8410\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2415 - accuracy: 0.8830 - val_loss: 0.4519 - val_accuracy: 0.8410\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 0.4531 - val_accuracy: 0.8410\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2420 - accuracy: 0.8808 - val_loss: 0.4604 - val_accuracy: 0.8410\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2407 - accuracy: 0.8808 - val_loss: 0.4505 - val_accuracy: 0.8359\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2435 - accuracy: 0.8830 - val_loss: 0.4657 - val_accuracy: 0.8359\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2444 - accuracy: 0.8742 - val_loss: 0.4533 - val_accuracy: 0.8410\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2566 - accuracy: 0.8852 - val_loss: 0.4545 - val_accuracy: 0.8410\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2434 - accuracy: 0.8830 - val_loss: 0.4424 - val_accuracy: 0.8359\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2445 - accuracy: 0.8742 - val_loss: 0.4526 - val_accuracy: 0.8410\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2432 - accuracy: 0.8720 - val_loss: 0.4515 - val_accuracy: 0.8410\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2369 - accuracy: 0.8874 - val_loss: 0.4508 - val_accuracy: 0.8410\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2400 - accuracy: 0.8808 - val_loss: 0.4564 - val_accuracy: 0.8410\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2446 - accuracy: 0.8720 - val_loss: 0.4580 - val_accuracy: 0.8410\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2371 - accuracy: 0.8896 - val_loss: 0.4713 - val_accuracy: 0.8410\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2460 - accuracy: 0.8786 - val_loss: 0.4643 - val_accuracy: 0.8359\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2454 - accuracy: 0.8808 - val_loss: 0.4530 - val_accuracy: 0.8308\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2478 - accuracy: 0.8521 - val_loss: 0.4538 - val_accuracy: 0.8359\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2451 - accuracy: 0.8698 - val_loss: 0.4652 - val_accuracy: 0.8410\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2430 - accuracy: 0.8830 - val_loss: 0.4538 - val_accuracy: 0.8359\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2427 - accuracy: 0.8698 - val_loss: 0.4672 - val_accuracy: 0.8462\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.4619 - val_accuracy: 0.8410\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2440 - accuracy: 0.8786 - val_loss: 0.4597 - val_accuracy: 0.8410\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2384 - accuracy: 0.8764 - val_loss: 0.4739 - val_accuracy: 0.8410\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2442 - accuracy: 0.8698 - val_loss: 0.4632 - val_accuracy: 0.8359\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2422 - accuracy: 0.8764 - val_loss: 0.4614 - val_accuracy: 0.8410\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.4699 - val_accuracy: 0.8410\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.4621 - val_accuracy: 0.8410\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2450 - accuracy: 0.8698 - val_loss: 0.4805 - val_accuracy: 0.8359\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2412 - accuracy: 0.8764 - val_loss: 0.4758 - val_accuracy: 0.8410\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2422 - accuracy: 0.8852 - val_loss: 0.4915 - val_accuracy: 0.8462\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.4776 - val_accuracy: 0.8359\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2470 - accuracy: 0.8830 - val_loss: 0.4889 - val_accuracy: 0.8308\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2452 - accuracy: 0.8830 - val_loss: 0.4574 - val_accuracy: 0.8410\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.4740 - val_accuracy: 0.8410\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2380 - accuracy: 0.8874 - val_loss: 0.4787 - val_accuracy: 0.8410\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2388 - accuracy: 0.8874 - val_loss: 0.4763 - val_accuracy: 0.8410\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2363 - accuracy: 0.8896 - val_loss: 0.5041 - val_accuracy: 0.8359\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2463 - accuracy: 0.8742 - val_loss: 0.4664 - val_accuracy: 0.8359\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.4761 - val_accuracy: 0.8359\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2396 - accuracy: 0.8896 - val_loss: 0.4726 - val_accuracy: 0.8410\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2388 - accuracy: 0.8786 - val_loss: 0.4673 - val_accuracy: 0.8410\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.4643 - val_accuracy: 0.8410\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2376 - accuracy: 0.8874 - val_loss: 0.4671 - val_accuracy: 0.8410\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2380 - accuracy: 0.8786 - val_loss: 0.4734 - val_accuracy: 0.8359\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 0.4905 - val_accuracy: 0.8359\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2356 - accuracy: 0.8675 - val_loss: 0.4758 - val_accuracy: 0.8410\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2390 - accuracy: 0.8786 - val_loss: 0.4863 - val_accuracy: 0.8359\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2380 - accuracy: 0.8852 - val_loss: 0.4696 - val_accuracy: 0.8410\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2363 - accuracy: 0.8874 - val_loss: 0.4779 - val_accuracy: 0.8410\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2351 - accuracy: 0.8874 - val_loss: 0.4767 - val_accuracy: 0.8410\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2392 - accuracy: 0.8764 - val_loss: 0.4856 - val_accuracy: 0.8308\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2394 - accuracy: 0.8675 - val_loss: 0.4750 - val_accuracy: 0.8410\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.4830 - val_accuracy: 0.8410\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.4705 - val_accuracy: 0.8410\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2412 - accuracy: 0.8830 - val_loss: 0.4738 - val_accuracy: 0.8410\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2390 - accuracy: 0.8874 - val_loss: 0.4790 - val_accuracy: 0.8410\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.4863 - val_accuracy: 0.8462\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 0.4827 - val_accuracy: 0.8410\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2376 - accuracy: 0.8786 - val_loss: 0.4815 - val_accuracy: 0.8410\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2367 - accuracy: 0.8918 - val_loss: 0.4791 - val_accuracy: 0.8410\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2394 - accuracy: 0.8742 - val_loss: 0.4718 - val_accuracy: 0.8410\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.4907 - val_accuracy: 0.8359\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.4907 - val_accuracy: 0.8410\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2369 - accuracy: 0.8808 - val_loss: 0.4806 - val_accuracy: 0.8410\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2417 - accuracy: 0.8808 - val_loss: 0.4992 - val_accuracy: 0.8462\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.4790 - val_accuracy: 0.8410\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2371 - accuracy: 0.8808 - val_loss: 0.4846 - val_accuracy: 0.8410\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2358 - accuracy: 0.8874 - val_loss: 0.4912 - val_accuracy: 0.8410\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2364 - accuracy: 0.8874 - val_loss: 0.4772 - val_accuracy: 0.8410\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2401 - accuracy: 0.8675 - val_loss: 0.4777 - val_accuracy: 0.8462\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.4803 - val_accuracy: 0.8410\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.4987 - val_accuracy: 0.8410\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2395 - accuracy: 0.8852 - val_loss: 0.4865 - val_accuracy: 0.8359\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2444 - accuracy: 0.8720 - val_loss: 0.5115 - val_accuracy: 0.8308\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.4677 - val_accuracy: 0.8410\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2408 - accuracy: 0.8808 - val_loss: 0.4680 - val_accuracy: 0.8410\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2418 - accuracy: 0.8874 - val_loss: 0.4788 - val_accuracy: 0.8410\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2358 - accuracy: 0.8896 - val_loss: 0.4806 - val_accuracy: 0.8410\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2421 - accuracy: 0.8742 - val_loss: 0.4797 - val_accuracy: 0.8359\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2379 - accuracy: 0.8786 - val_loss: 0.4659 - val_accuracy: 0.8513\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.4873 - val_accuracy: 0.8410\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2357 - accuracy: 0.8918 - val_loss: 0.4791 - val_accuracy: 0.8410\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2371 - accuracy: 0.8874 - val_loss: 0.5092 - val_accuracy: 0.8410\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.5038 - val_accuracy: 0.8410\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2438 - accuracy: 0.8742 - val_loss: 0.5015 - val_accuracy: 0.8410\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 108us/step - loss: 0.2412 - accuracy: 0.8764 - val_loss: 0.5032 - val_accuracy: 0.8410\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.4989 - val_accuracy: 0.8410\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.4988 - val_accuracy: 0.8410\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2381 - accuracy: 0.8786 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2371 - accuracy: 0.8808 - val_loss: 0.5006 - val_accuracy: 0.8410\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2391 - accuracy: 0.8764 - val_loss: 0.4927 - val_accuracy: 0.8410\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.4981 - val_accuracy: 0.8410\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2362 - accuracy: 0.8808 - val_loss: 0.4943 - val_accuracy: 0.8410\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2354 - accuracy: 0.8874 - val_loss: 0.4979 - val_accuracy: 0.8410\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2380 - accuracy: 0.8852 - val_loss: 0.4996 - val_accuracy: 0.8462\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2412 - accuracy: 0.8852 - val_loss: 0.4994 - val_accuracy: 0.8410\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.5017 - val_accuracy: 0.8410\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2394 - accuracy: 0.8742 - val_loss: 0.5050 - val_accuracy: 0.8462\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.4879 - val_accuracy: 0.8462\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2445 - accuracy: 0.8786 - val_loss: 0.4768 - val_accuracy: 0.8410\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2357 - accuracy: 0.8874 - val_loss: 0.4924 - val_accuracy: 0.8410\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.5081 - val_accuracy: 0.8359\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 0.4987 - val_accuracy: 0.8410\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2358 - accuracy: 0.8874 - val_loss: 0.4983 - val_accuracy: 0.8410\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2491 - accuracy: 0.8830 - val_loss: 0.5244 - val_accuracy: 0.8410\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.4905 - val_accuracy: 0.8462\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2359 - accuracy: 0.8874 - val_loss: 0.5018 - val_accuracy: 0.8410\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2369 - accuracy: 0.8874 - val_loss: 0.5013 - val_accuracy: 0.8410\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.5053 - val_accuracy: 0.8410\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 376us/step - loss: 0.2425 - accuracy: 0.8808 - val_loss: 0.4976 - val_accuracy: 0.8462\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.5306 - val_accuracy: 0.8359\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2453 - accuracy: 0.8786 - val_loss: 0.4959 - val_accuracy: 0.8410\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 0.4942 - val_accuracy: 0.8410\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2349 - accuracy: 0.8874 - val_loss: 0.4988 - val_accuracy: 0.8410\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.5039 - val_accuracy: 0.8359\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 464us/step - loss: 0.2351 - accuracy: 0.8874 - val_loss: 0.5003 - val_accuracy: 0.8462\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2346 - accuracy: 0.8874 - val_loss: 0.5117 - val_accuracy: 0.8410\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2354 - accuracy: 0.8896 - val_loss: 0.5121 - val_accuracy: 0.8410\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 546us/step - loss: 0.2381 - accuracy: 0.8786 - val_loss: 0.5142 - val_accuracy: 0.8308\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 478us/step - loss: 0.2467 - accuracy: 0.8808 - val_loss: 0.5236 - val_accuracy: 0.8308\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 575us/step - loss: 0.2428 - accuracy: 0.8742 - val_loss: 0.5157 - val_accuracy: 0.8410\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 310us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 496us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.5104 - val_accuracy: 0.8410\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 505us/step - loss: 0.2377 - accuracy: 0.8742 - val_loss: 0.5130 - val_accuracy: 0.8359\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 560us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 339us/step - loss: 0.2383 - accuracy: 0.8808 - val_loss: 0.5208 - val_accuracy: 0.8410\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 0.4988 - val_accuracy: 0.8513\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2367 - accuracy: 0.8764 - val_loss: 0.5119 - val_accuracy: 0.8462\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 423us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 0.4967 - val_accuracy: 0.8410\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 626us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.5201 - val_accuracy: 0.8410\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 524us/step - loss: 0.2335 - accuracy: 0.8764 - val_loss: 0.5135 - val_accuracy: 0.8410\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 731us/step - loss: 0.2351 - accuracy: 0.8764 - val_loss: 0.5136 - val_accuracy: 0.8410\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2377 - accuracy: 0.8874 - val_loss: 0.5183 - val_accuracy: 0.8410\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 534us/step - loss: 0.2412 - accuracy: 0.8764 - val_loss: 0.5038 - val_accuracy: 0.8513\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.5153 - val_accuracy: 0.8410\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.5270 - val_accuracy: 0.8410\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 467us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.5153 - val_accuracy: 0.8410\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 473us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.5164 - val_accuracy: 0.8410\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 551us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 416us/step - loss: 0.2410 - accuracy: 0.8852 - val_loss: 0.5164 - val_accuracy: 0.8462\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.5238 - val_accuracy: 0.8410\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.5172 - val_accuracy: 0.8462\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2378 - accuracy: 0.8896 - val_loss: 0.5215 - val_accuracy: 0.8410\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 324us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.5044 - val_accuracy: 0.8462\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.5151 - val_accuracy: 0.8462\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2339 - accuracy: 0.8786 - val_loss: 0.5274 - val_accuracy: 0.8410\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.86 - 0s 252us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.5124 - val_accuracy: 0.8462\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2387 - accuracy: 0.8764 - val_loss: 0.5116 - val_accuracy: 0.8410\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 641us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.5194 - val_accuracy: 0.8410\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 373us/step - loss: 0.2349 - accuracy: 0.8874 - val_loss: 0.5183 - val_accuracy: 0.8359\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 418us/step - loss: 0.2364 - accuracy: 0.8764 - val_loss: 0.5199 - val_accuracy: 0.8462\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.5231 - val_accuracy: 0.8359\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.5089 - val_accuracy: 0.8462\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2346 - accuracy: 0.8874 - val_loss: 0.5146 - val_accuracy: 0.8410\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 544us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.5153 - val_accuracy: 0.8410\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2339 - accuracy: 0.8808 - val_loss: 0.5149 - val_accuracy: 0.8410\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 255us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.5210 - val_accuracy: 0.8462\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5293 - val_accuracy: 0.8410\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 0.5266 - val_accuracy: 0.8359\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.5236 - val_accuracy: 0.8410\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.5169 - val_accuracy: 0.8462\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.5200 - val_accuracy: 0.8462\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.5293 - val_accuracy: 0.8462\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2361 - accuracy: 0.8720 - val_loss: 0.5321 - val_accuracy: 0.8359\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2360 - accuracy: 0.8874 - val_loss: 0.4997 - val_accuracy: 0.8462\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2410 - accuracy: 0.8764 - val_loss: 0.5135 - val_accuracy: 0.8410\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2399 - accuracy: 0.8720 - val_loss: 0.5051 - val_accuracy: 0.8410\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.5197 - val_accuracy: 0.8410\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 500us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.5237 - val_accuracy: 0.8410\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.5164 - val_accuracy: 0.8462\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2367 - accuracy: 0.8874 - val_loss: 0.5217 - val_accuracy: 0.8359\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.5178 - val_accuracy: 0.8513\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.5295 - val_accuracy: 0.8410\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2354 - accuracy: 0.8874 - val_loss: 0.5280 - val_accuracy: 0.8359\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.5275 - val_accuracy: 0.8462\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2360 - accuracy: 0.8830 - val_loss: 0.5361 - val_accuracy: 0.8410\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 0.5173 - val_accuracy: 0.8410\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2324 - accuracy: 0.8896 - val_loss: 0.5311 - val_accuracy: 0.8410\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 316us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 0.5262 - val_accuracy: 0.8513\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.5310 - val_accuracy: 0.8462\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2351 - accuracy: 0.8786 - val_loss: 0.5358 - val_accuracy: 0.8462\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2388 - accuracy: 0.8830 - val_loss: 0.5354 - val_accuracy: 0.8410\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.5332 - val_accuracy: 0.8462\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.5475 - val_accuracy: 0.8410\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2396 - accuracy: 0.8808 - val_loss: 0.5378 - val_accuracy: 0.8462\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 356us/step - loss: 0.2351 - accuracy: 0.8874 - val_loss: 0.5405 - val_accuracy: 0.8410\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.2388 - accuracy: 0.8852 - val_loss: 0.5374 - val_accuracy: 0.8410\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 451us/step - loss: 0.2344 - accuracy: 0.8742 - val_loss: 0.5461 - val_accuracy: 0.8462\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 835us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 0.5402 - val_accuracy: 0.8462\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 809us/step - loss: 0.2352 - accuracy: 0.8786 - val_loss: 0.5028 - val_accuracy: 0.8462\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 490us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.5260 - val_accuracy: 0.8410\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 358us/step - loss: 0.2423 - accuracy: 0.8675 - val_loss: 0.5263 - val_accuracy: 0.8410\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 316us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.5187 - val_accuracy: 0.8462\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 661us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.5305 - val_accuracy: 0.8462\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2400 - accuracy: 0.8742 - val_loss: 0.5316 - val_accuracy: 0.8410\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.5324 - val_accuracy: 0.8462\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 382us/step - loss: 0.2342 - accuracy: 0.8874 - val_loss: 0.5334 - val_accuracy: 0.8462\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 564us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.5365 - val_accuracy: 0.8410\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.5367 - val_accuracy: 0.8462\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 278us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.5383 - val_accuracy: 0.8462\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 387us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.5379 - val_accuracy: 0.8410\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 383us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.5306 - val_accuracy: 0.8462\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.5400 - val_accuracy: 0.8410\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 0.5495 - val_accuracy: 0.8410\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 342us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.5390 - val_accuracy: 0.8462\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2307 - accuracy: 0.8918 - val_loss: 0.5447 - val_accuracy: 0.8462\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.5346 - val_accuracy: 0.8462\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2351 - accuracy: 0.8940 - val_loss: 0.5434 - val_accuracy: 0.8462\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2351 - accuracy: 0.8742 - val_loss: 0.5459 - val_accuracy: 0.8462\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.5330 - val_accuracy: 0.8462\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.5444 - val_accuracy: 0.8462\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.5416 - val_accuracy: 0.8462\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.5518 - val_accuracy: 0.8462\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.5523 - val_accuracy: 0.8462\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 371us/step - loss: 0.2430 - accuracy: 0.8742 - val_loss: 0.5455 - val_accuracy: 0.8462\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2378 - accuracy: 0.8896 - val_loss: 0.5352 - val_accuracy: 0.8462\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 0.5363 - val_accuracy: 0.8462\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.5346 - val_accuracy: 0.8462\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2342 - accuracy: 0.8764 - val_loss: 0.5547 - val_accuracy: 0.8462\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.5483 - val_accuracy: 0.8462\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.5494 - val_accuracy: 0.8462\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2432 - accuracy: 0.8852 - val_loss: 0.5726 - val_accuracy: 0.8359\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2370 - accuracy: 0.8764 - val_loss: 0.5665 - val_accuracy: 0.8462\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 307us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.5619 - val_accuracy: 0.8462\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2418 - accuracy: 0.8808 - val_loss: 0.5587 - val_accuracy: 0.8410\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.5526 - val_accuracy: 0.8462\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 449us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.5627 - val_accuracy: 0.8462\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2346 - accuracy: 0.8874 - val_loss: 0.5533 - val_accuracy: 0.8462\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.5524 - val_accuracy: 0.8410\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 315us/step - loss: 0.2351 - accuracy: 0.8874 - val_loss: 0.5601 - val_accuracy: 0.8462\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 624us/step - loss: 0.2395 - accuracy: 0.8852 - val_loss: 0.5449 - val_accuracy: 0.8462\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2387 - accuracy: 0.8786 - val_loss: 0.5477 - val_accuracy: 0.8513\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.5352 - val_accuracy: 0.8513\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.5489 - val_accuracy: 0.8410\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2396 - accuracy: 0.8742 - val_loss: 0.5700 - val_accuracy: 0.8462\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.5714 - val_accuracy: 0.8462\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.5585 - val_accuracy: 0.8462\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.5658 - val_accuracy: 0.8462\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.5729 - val_accuracy: 0.8410\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 251us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.5694 - val_accuracy: 0.8462\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.5742 - val_accuracy: 0.8410\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.5720 - val_accuracy: 0.8462\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2393 - accuracy: 0.8808 - val_loss: 0.5751 - val_accuracy: 0.8410\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.5738 - val_accuracy: 0.8410\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 0.5780 - val_accuracy: 0.8462\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2331 - accuracy: 0.8896 - val_loss: 0.5713 - val_accuracy: 0.8410\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.5764 - val_accuracy: 0.8410\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2337 - accuracy: 0.8742 - val_loss: 0.5829 - val_accuracy: 0.8462\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.5656 - val_accuracy: 0.8462\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2358 - accuracy: 0.8874 - val_loss: 0.5722 - val_accuracy: 0.8462\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2363 - accuracy: 0.8786 - val_loss: 0.5787 - val_accuracy: 0.8462\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2361 - accuracy: 0.8874 - val_loss: 0.5729 - val_accuracy: 0.8410\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.5447 - val_accuracy: 0.8462\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.5463 - val_accuracy: 0.8410\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2336 - accuracy: 0.8764 - val_loss: 0.5673 - val_accuracy: 0.8462\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.5574 - val_accuracy: 0.8462\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2358 - accuracy: 0.8764 - val_loss: 0.5796 - val_accuracy: 0.8462\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.5772 - val_accuracy: 0.8462\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.5788 - val_accuracy: 0.8462\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2393 - accuracy: 0.8808 - val_loss: 0.5810 - val_accuracy: 0.8513\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.5751 - val_accuracy: 0.8462\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5769 - val_accuracy: 0.8462\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.5808 - val_accuracy: 0.8462\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.5757 - val_accuracy: 0.8462\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 0.5760 - val_accuracy: 0.8513\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2321 - accuracy: 0.8896 - val_loss: 0.5774 - val_accuracy: 0.8410\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.5791 - val_accuracy: 0.8462\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.5784 - val_accuracy: 0.8410\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.5848 - val_accuracy: 0.8410\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2322 - accuracy: 0.8808 - val_loss: 0.5794 - val_accuracy: 0.8410\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2347 - accuracy: 0.8874 - val_loss: 0.5789 - val_accuracy: 0.8410\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.5612 - val_accuracy: 0.8462\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2433 - accuracy: 0.8764 - val_loss: 0.5623 - val_accuracy: 0.8462\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.5704 - val_accuracy: 0.8462\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2351 - accuracy: 0.8896 - val_loss: 0.5680 - val_accuracy: 0.8462\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.5727 - val_accuracy: 0.8462\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.5757 - val_accuracy: 0.8462\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2361 - accuracy: 0.8918 - val_loss: 0.5621 - val_accuracy: 0.8462\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.5711 - val_accuracy: 0.8462\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.5816 - val_accuracy: 0.8462\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.5825 - val_accuracy: 0.8410\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.5864 - val_accuracy: 0.8462\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.5854 - val_accuracy: 0.8410\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.5838 - val_accuracy: 0.8462\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 268us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.6040 - val_accuracy: 0.8462\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 302us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.5833 - val_accuracy: 0.8462\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.5906 - val_accuracy: 0.8462\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2324 - accuracy: 0.8896 - val_loss: 0.5981 - val_accuracy: 0.8462\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.5895 - val_accuracy: 0.8410\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2332 - accuracy: 0.8764 - val_loss: 0.5982 - val_accuracy: 0.8462\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.5919 - val_accuracy: 0.8462\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.5927 - val_accuracy: 0.8410\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.5900 - val_accuracy: 0.8462\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.5985 - val_accuracy: 0.8462\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.6013 - val_accuracy: 0.8513\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2423 - accuracy: 0.8830 - val_loss: 0.5942 - val_accuracy: 0.8462\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.5849 - val_accuracy: 0.8462\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2340 - accuracy: 0.8764 - val_loss: 0.5822 - val_accuracy: 0.8462\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.5901 - val_accuracy: 0.8462\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.5904 - val_accuracy: 0.8462\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 181us/step - loss: 0.2335 - accuracy: 0.8874 - val_loss: 0.5994 - val_accuracy: 0.8410\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2341 - accuracy: 0.8874 - val_loss: 0.6061 - val_accuracy: 0.8410\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.5977 - val_accuracy: 0.8410\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.5982 - val_accuracy: 0.8462\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2331 - accuracy: 0.8896 - val_loss: 0.6090 - val_accuracy: 0.8462\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2393 - accuracy: 0.8786 - val_loss: 0.6047 - val_accuracy: 0.8462\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2347 - accuracy: 0.8742 - val_loss: 0.5936 - val_accuracy: 0.8410\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.6055 - val_accuracy: 0.8410\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.6050 - val_accuracy: 0.8462\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2316 - accuracy: 0.8786 - val_loss: 0.5918 - val_accuracy: 0.8462\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.5660 - val_accuracy: 0.8462\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.5821 - val_accuracy: 0.8462\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2344 - accuracy: 0.8896 - val_loss: 0.5864 - val_accuracy: 0.8462\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2337 - accuracy: 0.8786 - val_loss: 0.5906 - val_accuracy: 0.8462\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.5922 - val_accuracy: 0.8462\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.6071 - val_accuracy: 0.8462\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2343 - accuracy: 0.8874 - val_loss: 0.6019 - val_accuracy: 0.8462\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.6034 - val_accuracy: 0.8513\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.5990 - val_accuracy: 0.8410\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.5957 - val_accuracy: 0.8410\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.6063 - val_accuracy: 0.8410\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.6052 - val_accuracy: 0.8462\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2367 - accuracy: 0.8874 - val_loss: 0.6078 - val_accuracy: 0.8462\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2378 - accuracy: 0.8874 - val_loss: 0.6103 - val_accuracy: 0.8513\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.6014 - val_accuracy: 0.8462\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.6035 - val_accuracy: 0.8462\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.6013 - val_accuracy: 0.8410\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2409 - accuracy: 0.8830 - val_loss: 0.6089 - val_accuracy: 0.8462\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.5975 - val_accuracy: 0.8462\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.5912 - val_accuracy: 0.8410\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.6227 - val_accuracy: 0.8462\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2314 - accuracy: 0.8764 - val_loss: 0.6114 - val_accuracy: 0.8462\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.6044 - val_accuracy: 0.8462\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.6008 - val_accuracy: 0.8462\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.6027 - val_accuracy: 0.8462\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2363 - accuracy: 0.8874 - val_loss: 0.6024 - val_accuracy: 0.8462\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.6089 - val_accuracy: 0.8410\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.6101 - val_accuracy: 0.8513\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.6067 - val_accuracy: 0.8462\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.5914 - val_accuracy: 0.8462\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.6088 - val_accuracy: 0.8462\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.6175 - val_accuracy: 0.8462\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.6040 - val_accuracy: 0.8462\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2346 - accuracy: 0.8764 - val_loss: 0.6178 - val_accuracy: 0.8410\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2296 - accuracy: 0.8896 - val_loss: 0.6138 - val_accuracy: 0.8410\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.6170 - val_accuracy: 0.8410\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.5928 - val_accuracy: 0.8462\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2384 - accuracy: 0.8786 - val_loss: 0.6030 - val_accuracy: 0.8410\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 299us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.6011 - val_accuracy: 0.8462\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.2364 - accuracy: 0.8742 - val_loss: 0.6133 - val_accuracy: 0.8410\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2322 - accuracy: 0.8874 - val_loss: 0.6041 - val_accuracy: 0.8513\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2395 - accuracy: 0.8786 - val_loss: 0.6118 - val_accuracy: 0.8462\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.6151 - val_accuracy: 0.8410\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2335 - accuracy: 0.8896 - val_loss: 0.5843 - val_accuracy: 0.8462\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2338 - accuracy: 0.8896 - val_loss: 0.5799 - val_accuracy: 0.8513\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.5954 - val_accuracy: 0.8410\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.6091 - val_accuracy: 0.8462\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.6107 - val_accuracy: 0.8410\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.6073 - val_accuracy: 0.8410\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.6121 - val_accuracy: 0.8410\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.6149 - val_accuracy: 0.8410\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.6180 - val_accuracy: 0.8410\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 0.6144 - val_accuracy: 0.8410\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.6305 - val_accuracy: 0.8410\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.6273 - val_accuracy: 0.8410\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.6380 - val_accuracy: 0.8410\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.6398 - val_accuracy: 0.8462\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.6458 - val_accuracy: 0.8462\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.6342 - val_accuracy: 0.8410\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.6331 - val_accuracy: 0.8410\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 0.6460 - val_accuracy: 0.8410\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2315 - accuracy: 0.8940 - val_loss: 0.6250 - val_accuracy: 0.8462\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2406 - accuracy: 0.8874 - val_loss: 0.6343 - val_accuracy: 0.8462\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2361 - accuracy: 0.8764 - val_loss: 0.6344 - val_accuracy: 0.8410\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.6507 - val_accuracy: 0.8462\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2360 - accuracy: 0.8874 - val_loss: 0.6340 - val_accuracy: 0.8462\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.6370 - val_accuracy: 0.8462\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.6425 - val_accuracy: 0.8462\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.6423 - val_accuracy: 0.8410\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2372 - accuracy: 0.8852 - val_loss: 0.6456 - val_accuracy: 0.8410\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.6491 - val_accuracy: 0.8410\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.6495 - val_accuracy: 0.8462\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.6448 - val_accuracy: 0.8410\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.6549 - val_accuracy: 0.8462\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.6446 - val_accuracy: 0.8410\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.6491 - val_accuracy: 0.8410\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.6503 - val_accuracy: 0.8410\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.6454 - val_accuracy: 0.8410\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.6520 - val_accuracy: 0.8462\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.6546 - val_accuracy: 0.8410\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.6536 - val_accuracy: 0.8410\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2366 - accuracy: 0.8896 - val_loss: 0.6611 - val_accuracy: 0.8462\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.6542 - val_accuracy: 0.8410\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.6216 - val_accuracy: 0.8410\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2333 - accuracy: 0.8918 - val_loss: 0.6345 - val_accuracy: 0.8410\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.6266 - val_accuracy: 0.8513\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.6434 - val_accuracy: 0.8462\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.6437 - val_accuracy: 0.8410\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.6533 - val_accuracy: 0.8410\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.6535 - val_accuracy: 0.8410\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.6524 - val_accuracy: 0.8410\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2342 - accuracy: 0.8742 - val_loss: 0.6513 - val_accuracy: 0.8410\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2351 - accuracy: 0.8896 - val_loss: 0.6559 - val_accuracy: 0.8410\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.6589 - val_accuracy: 0.8410\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.6568 - val_accuracy: 0.8410\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.6454 - val_accuracy: 0.8410\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.89 - 0s 276us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.6521 - val_accuracy: 0.8462\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.6462 - val_accuracy: 0.8462\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.6455 - val_accuracy: 0.8410\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 135us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.6489 - val_accuracy: 0.8410\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.6258 - val_accuracy: 0.8410\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2324 - accuracy: 0.8786 - val_loss: 0.6289 - val_accuracy: 0.8410\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.6453 - val_accuracy: 0.8462\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 0.6521 - val_accuracy: 0.8410\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.6539 - val_accuracy: 0.8410\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.6601 - val_accuracy: 0.8462\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 0.6686 - val_accuracy: 0.8410\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.6590 - val_accuracy: 0.8462\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.6680 - val_accuracy: 0.8462\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2330 - accuracy: 0.8786 - val_loss: 0.6652 - val_accuracy: 0.8462\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.6634 - val_accuracy: 0.8410\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.6654 - val_accuracy: 0.8410\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2431 - accuracy: 0.8808 - val_loss: 0.6644 - val_accuracy: 0.8410\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.6625 - val_accuracy: 0.8410\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 288us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.6674 - val_accuracy: 0.8462\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.6762 - val_accuracy: 0.8410\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.6675 - val_accuracy: 0.8410\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.6667 - val_accuracy: 0.8410\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.6732 - val_accuracy: 0.8462\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.6764 - val_accuracy: 0.8410\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 507us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.6813 - val_accuracy: 0.8462\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.6718 - val_accuracy: 0.8462\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.6764 - val_accuracy: 0.8462\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2340 - accuracy: 0.8786 - val_loss: 0.6735 - val_accuracy: 0.8410\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2302 - accuracy: 0.8896 - val_loss: 0.6797 - val_accuracy: 0.8462\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.6663 - val_accuracy: 0.8462\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.6780 - val_accuracy: 0.8462\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 497us/step - loss: 0.2325 - accuracy: 0.8808 - val_loss: 0.6741 - val_accuracy: 0.8410\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2353 - accuracy: 0.8874 - val_loss: 0.6711 - val_accuracy: 0.8410\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 380us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.6226 - val_accuracy: 0.8513\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 343us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.6341 - val_accuracy: 0.8513\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 536us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.6439 - val_accuracy: 0.8410\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 387us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.6448 - val_accuracy: 0.8410\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.6588 - val_accuracy: 0.8462\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 321us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.6623 - val_accuracy: 0.8462\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2365 - accuracy: 0.8808 - val_loss: 0.6657 - val_accuracy: 0.8462\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2333 - accuracy: 0.8874 - val_loss: 0.6585 - val_accuracy: 0.8410\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.6678 - val_accuracy: 0.8410\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.6540 - val_accuracy: 0.8410\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.6666 - val_accuracy: 0.8410\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 319us/step - loss: 0.2420 - accuracy: 0.8896 - val_loss: 0.6758 - val_accuracy: 0.8410\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 425us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.6668 - val_accuracy: 0.8462\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 412us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.6784 - val_accuracy: 0.8410\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 415us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.6743 - val_accuracy: 0.8410\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 329us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.6691 - val_accuracy: 0.8462\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.6706 - val_accuracy: 0.8462\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.6740 - val_accuracy: 0.8462\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2378 - accuracy: 0.8874 - val_loss: 0.6684 - val_accuracy: 0.8410\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 561us/step - loss: 0.2335 - accuracy: 0.8742 - val_loss: 0.6741 - val_accuracy: 0.8462\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 658us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.6709 - val_accuracy: 0.8410\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 534us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.6634 - val_accuracy: 0.8410\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2350 - accuracy: 0.8808 - val_loss: 0.6422 - val_accuracy: 0.8564\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.6514 - val_accuracy: 0.8513\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 520us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 0.6590 - val_accuracy: 0.8462\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 290us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.6700 - val_accuracy: 0.8462\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.6772 - val_accuracy: 0.8410\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.6727 - val_accuracy: 0.8513\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.88 - 0s 195us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.6733 - val_accuracy: 0.8462\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2355 - accuracy: 0.8874 - val_loss: 0.6826 - val_accuracy: 0.8462\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 544us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.6720 - val_accuracy: 0.8462\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2315 - accuracy: 0.8896 - val_loss: 0.6559 - val_accuracy: 0.8513\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2307 - accuracy: 0.8830 - val_loss: 0.6513 - val_accuracy: 0.8462\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 736us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.6696 - val_accuracy: 0.8462\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 566us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.6688 - val_accuracy: 0.8462\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.2330 - accuracy: 0.8896 - val_loss: 0.6768 - val_accuracy: 0.8410\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 520us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.6928 - val_accuracy: 0.8462\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 392us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.6863 - val_accuracy: 0.8462\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 332us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.6970 - val_accuracy: 0.8462\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 386us/step - loss: 0.2330 - accuracy: 0.8720 - val_loss: 0.6934 - val_accuracy: 0.8410\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 405us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.7078 - val_accuracy: 0.8462\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 734us/step - loss: 0.2338 - accuracy: 0.8874 - val_loss: 0.6903 - val_accuracy: 0.8410\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 503us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.6871 - val_accuracy: 0.8462\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.7001 - val_accuracy: 0.8462\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 450us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.6923 - val_accuracy: 0.8410\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 310us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.6956 - val_accuracy: 0.8410\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 346us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.7057 - val_accuracy: 0.8462\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 0.6894 - val_accuracy: 0.8410\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 437us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.6986 - val_accuracy: 0.8462\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 267us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.7035 - val_accuracy: 0.8410\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 646us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 0.6964 - val_accuracy: 0.8410\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 338us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 0.7016 - val_accuracy: 0.8410\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 277us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.6944 - val_accuracy: 0.8410\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.7098 - val_accuracy: 0.8462\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.7014 - val_accuracy: 0.8462\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 320us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.7111 - val_accuracy: 0.8462\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.7050 - val_accuracy: 0.8462\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2336 - accuracy: 0.8874 - val_loss: 0.7030 - val_accuracy: 0.8410\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 269us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.7019 - val_accuracy: 0.8410\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.7013 - val_accuracy: 0.8410\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 234us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.7053 - val_accuracy: 0.8462\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.7015 - val_accuracy: 0.8410\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.7256 - val_accuracy: 0.8462\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 287us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.7013 - val_accuracy: 0.8410\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 315us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.6961 - val_accuracy: 0.8462\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.7115 - val_accuracy: 0.8462\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2333 - accuracy: 0.8764 - val_loss: 0.7062 - val_accuracy: 0.8462\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.6472 - val_accuracy: 0.8462\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2331 - accuracy: 0.8874 - val_loss: 0.6588 - val_accuracy: 0.8462\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.6689 - val_accuracy: 0.8462\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2300 - accuracy: 0.8764 - val_loss: 0.6852 - val_accuracy: 0.8513\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.6949 - val_accuracy: 0.8462\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2265 - accuracy: 0.8896 - val_loss: 0.6910 - val_accuracy: 0.8462\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.6854 - val_accuracy: 0.8462\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2339 - accuracy: 0.8874 - val_loss: 0.6959 - val_accuracy: 0.8513\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 304us/step - loss: 0.2431 - accuracy: 0.8786 - val_loss: 0.6873 - val_accuracy: 0.8462\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 441us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.7069 - val_accuracy: 0.8462\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.6962 - val_accuracy: 0.8462\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.6955 - val_accuracy: 0.8513\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 279us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.6996 - val_accuracy: 0.8462\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 272us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.7048 - val_accuracy: 0.8513\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.6935 - val_accuracy: 0.8513\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2316 - accuracy: 0.8742 - val_loss: 0.7032 - val_accuracy: 0.8462\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.6969 - val_accuracy: 0.8513\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2346 - accuracy: 0.8896 - val_loss: 0.7090 - val_accuracy: 0.8462\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 332us/step - loss: 0.2367 - accuracy: 0.8764 - val_loss: 0.7032 - val_accuracy: 0.8462\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.7040 - val_accuracy: 0.8462\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.7048 - val_accuracy: 0.8462\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.7075 - val_accuracy: 0.8462\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.7055 - val_accuracy: 0.8462\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.7084 - val_accuracy: 0.8462\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2355 - accuracy: 0.8918 - val_loss: 0.7139 - val_accuracy: 0.8462\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2324 - accuracy: 0.8764 - val_loss: 0.7143 - val_accuracy: 0.8513\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2293 - accuracy: 0.8918 - val_loss: 0.7045 - val_accuracy: 0.8462\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 482us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.7064 - val_accuracy: 0.8462\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2429 - accuracy: 0.8786 - val_loss: 0.6703 - val_accuracy: 0.8513\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.6719 - val_accuracy: 0.8462\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.6811 - val_accuracy: 0.8462\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 0.6977 - val_accuracy: 0.8462\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.6991 - val_accuracy: 0.8462\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.7148 - val_accuracy: 0.8513\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 260us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.7066 - val_accuracy: 0.8513\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 0.7073 - val_accuracy: 0.8462\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 0.7109 - val_accuracy: 0.8462\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.7027 - val_accuracy: 0.8513\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.7133 - val_accuracy: 0.8513\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.7102 - val_accuracy: 0.8462\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 538us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.7147 - val_accuracy: 0.8513\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 500us/step - loss: 0.2383 - accuracy: 0.8852 - val_loss: 0.7068 - val_accuracy: 0.8462\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.7155 - val_accuracy: 0.8462\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.7208 - val_accuracy: 0.8462\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.6739 - val_accuracy: 0.8564\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2328 - accuracy: 0.8742 - val_loss: 0.6803 - val_accuracy: 0.8564\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.6830 - val_accuracy: 0.8462\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 353us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.6926 - val_accuracy: 0.8462\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.6935 - val_accuracy: 0.8462\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 309us/step - loss: 0.2340 - accuracy: 0.8808 - val_loss: 0.7090 - val_accuracy: 0.8462\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.7167 - val_accuracy: 0.8513\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2355 - accuracy: 0.8786 - val_loss: 0.7307 - val_accuracy: 0.8462\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.7249 - val_accuracy: 0.8462\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.7141 - val_accuracy: 0.8462\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 265us/step - loss: 0.2335 - accuracy: 0.8896 - val_loss: 0.7270 - val_accuracy: 0.8462\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.7230 - val_accuracy: 0.8410\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.7226 - val_accuracy: 0.8410\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2292 - accuracy: 0.8896 - val_loss: 0.7280 - val_accuracy: 0.8462\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.7263 - val_accuracy: 0.8410\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.7292 - val_accuracy: 0.8410\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 543us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.7276 - val_accuracy: 0.8462\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 470us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.7294 - val_accuracy: 0.8410\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 392us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.7323 - val_accuracy: 0.8462\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 407us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.7353 - val_accuracy: 0.8462\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 382us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.7333 - val_accuracy: 0.8410\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.7334 - val_accuracy: 0.8410\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 421us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.7311 - val_accuracy: 0.8410\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 372us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.7370 - val_accuracy: 0.8410\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.7359 - val_accuracy: 0.8513\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.7355 - val_accuracy: 0.8410\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2310 - accuracy: 0.8742 - val_loss: 0.7473 - val_accuracy: 0.8410\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 274us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.7364 - val_accuracy: 0.8410\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 0.7370 - val_accuracy: 0.8410\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 256us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.7520 - val_accuracy: 0.8462\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.7471 - val_accuracy: 0.8410\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 351us/step - loss: 0.2355 - accuracy: 0.8874 - val_loss: 0.7471 - val_accuracy: 0.8462\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.7517 - val_accuracy: 0.8410\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.7466 - val_accuracy: 0.8410\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.7460 - val_accuracy: 0.8410\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.7463 - val_accuracy: 0.8410\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.7468 - val_accuracy: 0.8462\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.7526 - val_accuracy: 0.8462\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.7466 - val_accuracy: 0.8462\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.7489 - val_accuracy: 0.8410\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.7513 - val_accuracy: 0.8410\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.7528 - val_accuracy: 0.8462\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.7559 - val_accuracy: 0.8410\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.7466 - val_accuracy: 0.8410\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.7450 - val_accuracy: 0.8462\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.7497 - val_accuracy: 0.8462\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2372 - accuracy: 0.8874 - val_loss: 0.7528 - val_accuracy: 0.8410\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.7603 - val_accuracy: 0.8462\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.7490 - val_accuracy: 0.8462\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.7539 - val_accuracy: 0.8462\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.7458 - val_accuracy: 0.8513\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2333 - accuracy: 0.8896 - val_loss: 0.7617 - val_accuracy: 0.8462\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.7563 - val_accuracy: 0.8462\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.7670 - val_accuracy: 0.8462\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.7609 - val_accuracy: 0.8462\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.7573 - val_accuracy: 0.8462\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.7595 - val_accuracy: 0.8462\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.7597 - val_accuracy: 0.8462\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.7664 - val_accuracy: 0.8462\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2282 - accuracy: 0.8852 - val_loss: 0.7596 - val_accuracy: 0.8462\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.7622 - val_accuracy: 0.8462\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.7663 - val_accuracy: 0.8462\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 636us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.7713 - val_accuracy: 0.8513\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 522us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.7706 - val_accuracy: 0.8462\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 338us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.7795 - val_accuracy: 0.8462\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 521us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.7652 - val_accuracy: 0.8513\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 462us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.7723 - val_accuracy: 0.8513\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 340us/step - loss: 0.2300 - accuracy: 0.8896 - val_loss: 0.7681 - val_accuracy: 0.8462\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 353us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.7686 - val_accuracy: 0.8513\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 394us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.7737 - val_accuracy: 0.8462\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 368us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.7687 - val_accuracy: 0.8462\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.7764 - val_accuracy: 0.8462\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.7796 - val_accuracy: 0.8513\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.7705 - val_accuracy: 0.8513\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.7764 - val_accuracy: 0.8462\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.7008 - val_accuracy: 0.8462\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.7105 - val_accuracy: 0.8462\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.7377 - val_accuracy: 0.8462\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2357 - accuracy: 0.8742 - val_loss: 0.7516 - val_accuracy: 0.8462\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 112us/step - loss: 0.2367 - accuracy: 0.8786 - val_loss: 0.7566 - val_accuracy: 0.8462\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.7586 - val_accuracy: 0.8462\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.7597 - val_accuracy: 0.8462\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.7594 - val_accuracy: 0.8462\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.7604 - val_accuracy: 0.8462\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.7647 - val_accuracy: 0.8462\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.7621 - val_accuracy: 0.8462\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.7675 - val_accuracy: 0.8462\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2321 - accuracy: 0.8764 - val_loss: 0.7740 - val_accuracy: 0.8462\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.7724 - val_accuracy: 0.8462\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.7773 - val_accuracy: 0.8462\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.7782 - val_accuracy: 0.8462\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.7827 - val_accuracy: 0.8513\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.7815 - val_accuracy: 0.8513\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2308 - accuracy: 0.8896 - val_loss: 0.7723 - val_accuracy: 0.8462\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.7778 - val_accuracy: 0.8462\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.7832 - val_accuracy: 0.8462\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.7872 - val_accuracy: 0.8462\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.7975 - val_accuracy: 0.8513\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.7821 - val_accuracy: 0.8462\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.7872 - val_accuracy: 0.8462\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2370 - accuracy: 0.8808 - val_loss: 0.7876 - val_accuracy: 0.8462\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.7992 - val_accuracy: 0.8462\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.7976 - val_accuracy: 0.8513\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.7900 - val_accuracy: 0.8462\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.7939 - val_accuracy: 0.8462\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2303 - accuracy: 0.8764 - val_loss: 0.7988 - val_accuracy: 0.8513\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.7960 - val_accuracy: 0.8513\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.7966 - val_accuracy: 0.8462\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.7936 - val_accuracy: 0.8462\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.8058 - val_accuracy: 0.8462\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2354 - accuracy: 0.8675 - val_loss: 0.7975 - val_accuracy: 0.8462\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.8045 - val_accuracy: 0.8513\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.7932 - val_accuracy: 0.8462\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.8039 - val_accuracy: 0.8462\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2331 - accuracy: 0.8764 - val_loss: 0.8061 - val_accuracy: 0.8513\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.7963 - val_accuracy: 0.8462\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.7974 - val_accuracy: 0.8462\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8024 - val_accuracy: 0.8462\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.8073 - val_accuracy: 0.8462\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.8064 - val_accuracy: 0.8462\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8036 - val_accuracy: 0.8462\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2326 - accuracy: 0.8808 - val_loss: 0.7636 - val_accuracy: 0.8513\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.7511 - val_accuracy: 0.8462\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.7633 - val_accuracy: 0.8462\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.7732 - val_accuracy: 0.8462\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.7713 - val_accuracy: 0.8513\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.7807 - val_accuracy: 0.8462\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.7880 - val_accuracy: 0.8462\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.7921 - val_accuracy: 0.8513\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2296 - accuracy: 0.8896 - val_loss: 0.7931 - val_accuracy: 0.8462\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.7998 - val_accuracy: 0.8513\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2324 - accuracy: 0.8808 - val_loss: 0.7974 - val_accuracy: 0.8462\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.8036 - val_accuracy: 0.8462\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.7957 - val_accuracy: 0.8462\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.8069 - val_accuracy: 0.8462\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 0.8063 - val_accuracy: 0.8462\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2344 - accuracy: 0.8874 - val_loss: 0.8056 - val_accuracy: 0.8462\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.8106 - val_accuracy: 0.8462\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.8079 - val_accuracy: 0.8462\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.8116 - val_accuracy: 0.8462\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8109 - val_accuracy: 0.8462\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.8196 - val_accuracy: 0.8513\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.8320 - val_accuracy: 0.8462\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.8325 - val_accuracy: 0.8513\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.8320 - val_accuracy: 0.8462\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.8394 - val_accuracy: 0.8462\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2363 - accuracy: 0.8675 - val_loss: 0.8445 - val_accuracy: 0.8513\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2379 - accuracy: 0.8852 - val_loss: 0.8299 - val_accuracy: 0.8462\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 363us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.8296 - val_accuracy: 0.8462\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.8366 - val_accuracy: 0.8462\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.8492 - val_accuracy: 0.8462\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.8259 - val_accuracy: 0.8462\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.8331 - val_accuracy: 0.8513\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.8508 - val_accuracy: 0.8513\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.8288 - val_accuracy: 0.8513\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.8440 - val_accuracy: 0.8513\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.8400 - val_accuracy: 0.8462\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.8382 - val_accuracy: 0.8462\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2281 - accuracy: 0.8852 - val_loss: 0.8441 - val_accuracy: 0.8462\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 362us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.8415 - val_accuracy: 0.8462\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 312us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8416 - val_accuracy: 0.8462\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2335 - accuracy: 0.8896 - val_loss: 0.8404 - val_accuracy: 0.8462\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.8492 - val_accuracy: 0.8513\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.8385 - val_accuracy: 0.8462\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.8528 - val_accuracy: 0.8513\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.8459 - val_accuracy: 0.8462\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.8462 - val_accuracy: 0.8462\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8466 - val_accuracy: 0.8462\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.8486 - val_accuracy: 0.8462\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.8465 - val_accuracy: 0.8462\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.8423 - val_accuracy: 0.8462\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.8531 - val_accuracy: 0.8513\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.2306 - accuracy: 0.8764 - val_loss: 0.8531 - val_accuracy: 0.8462\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2307 - accuracy: 0.8830 - val_loss: 0.8611 - val_accuracy: 0.8513\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.8598 - val_accuracy: 0.8462\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.8473 - val_accuracy: 0.8462\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.8642 - val_accuracy: 0.8513\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.8558 - val_accuracy: 0.8462\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.8491 - val_accuracy: 0.8462\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2291 - accuracy: 0.8896 - val_loss: 0.8514 - val_accuracy: 0.8513\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.8555 - val_accuracy: 0.8462\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.8572 - val_accuracy: 0.8462\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.8599 - val_accuracy: 0.8462\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.8653 - val_accuracy: 0.8513\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.8607 - val_accuracy: 0.8513\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.8612 - val_accuracy: 0.8513\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.8589 - val_accuracy: 0.8462\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2305 - accuracy: 0.8786 - val_loss: 0.8579 - val_accuracy: 0.8462\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 400us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.8656 - val_accuracy: 0.8462\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 305us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.8109 - val_accuracy: 0.8462\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.7648 - val_accuracy: 0.8462\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.7886 - val_accuracy: 0.8462\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8019 - val_accuracy: 0.8462\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 318us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8095 - val_accuracy: 0.8462\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 334us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.8219 - val_accuracy: 0.8513\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8138 - val_accuracy: 0.8513\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.8283 - val_accuracy: 0.8513\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.8271 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38aae390>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 2, 2,\n",
       "       2, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0,\n",
       "       1, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 2, 2, 1, 1,\n",
       "       2, 0, 0, 2, 2, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1,\n",
       "       0, 2, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 2, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, 0, 0, 2, 1, 0,\n",
       "       2, 1, 0, 0, 1, 0, 1, 1, 0, 2, 2, 1, 0, 2, 1, 1, 1, 2, 2, 2, 0, 0,\n",
       "       2, 1, 2, 2, 1, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS218     1     1\n",
       "1    NRS260     1     1\n",
       "2    NRS162     0     0\n",
       "3    NRS177     0     0\n",
       "4    NRS209     2     2\n",
       "..      ...   ...   ...\n",
       "190  NRS383     1     0\n",
       "191  NRS218     1     1\n",
       "192  NRS209     2     2\n",
       "193  SR2852     1     1\n",
       "194  NRS248     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.616657e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.662086e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.434604e-01</td>\n",
       "      <td>1.565396e-01</td>\n",
       "      <td>4.034365e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.995130e-01</td>\n",
       "      <td>4.869479e-04</td>\n",
       "      <td>7.161992e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761375e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    6.953657e-05  9.999305e-01  3.132419e-10\n",
       "1    7.616657e-09  1.000000e+00  8.662086e-13\n",
       "2    8.434604e-01  1.565396e-01  4.034365e-09\n",
       "3    9.995130e-01  4.869479e-04  7.161992e-10\n",
       "4    2.713214e-09  6.656316e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "190  5.477194e-01  4.522807e-01  1.761375e-08\n",
       "191  6.953657e-05  9.999305e-01  3.132419e-10\n",
       "192  2.713214e-09  6.656316e-09  1.000000e+00\n",
       "193  9.956684e-12  1.000000e+00  7.441288e-26\n",
       "194  9.999998e-01  1.958189e-07  1.001001e-12\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2323 - accuracy: 0.8786 - val_loss: 0.7526 - val_accuracy: 0.8513\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.7470 - val_accuracy: 0.8513\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 222us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.7531 - val_accuracy: 0.8513\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.7586 - val_accuracy: 0.8513\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.7515 - val_accuracy: 0.8513\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.7487 - val_accuracy: 0.8513\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.7467 - val_accuracy: 0.8513\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.7501 - val_accuracy: 0.8513\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.7597 - val_accuracy: 0.8513\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 364us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.7436 - val_accuracy: 0.8513\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 525us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.7484 - val_accuracy: 0.8513\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.7545 - val_accuracy: 0.8513\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.7568 - val_accuracy: 0.8513\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.7610 - val_accuracy: 0.8513\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.7627 - val_accuracy: 0.8513\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.7703 - val_accuracy: 0.8513\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.7684 - val_accuracy: 0.8513\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.87 - 0s 112us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.7677 - val_accuracy: 0.8513\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.7696 - val_accuracy: 0.8513\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.7764 - val_accuracy: 0.8513\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.7778 - val_accuracy: 0.8513\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.7724 - val_accuracy: 0.8513\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.7792 - val_accuracy: 0.8513\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.7808 - val_accuracy: 0.8667\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.7753 - val_accuracy: 0.8513\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.7728 - val_accuracy: 0.8513\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.7743 - val_accuracy: 0.8462\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.7814 - val_accuracy: 0.8513\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.7822 - val_accuracy: 0.8462\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.7834 - val_accuracy: 0.8513\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.7846 - val_accuracy: 0.8513\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 294us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.7850 - val_accuracy: 0.8462\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 408us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.7827 - val_accuracy: 0.8462\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 306us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.7825 - val_accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 233us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.7860 - val_accuracy: 0.8513\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 381us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.7833 - val_accuracy: 0.8513\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.8005 - val_accuracy: 0.8564\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 259us/step - loss: 0.2280 - accuracy: 0.8896 - val_loss: 0.7869 - val_accuracy: 0.8462\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 311us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.7954 - val_accuracy: 0.8462\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 289us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.7822 - val_accuracy: 0.8462\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.7868 - val_accuracy: 0.8462\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.7865 - val_accuracy: 0.8462\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.7766 - val_accuracy: 0.8462\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.7824 - val_accuracy: 0.8513\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2318 - accuracy: 0.8808 - val_loss: 0.7849 - val_accuracy: 0.8462\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.7845 - val_accuracy: 0.8513\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.7897 - val_accuracy: 0.8513\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2302 - accuracy: 0.8786 - val_loss: 0.7913 - val_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.7918 - val_accuracy: 0.8462\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 326us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.7926 - val_accuracy: 0.8462\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 241us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.7962 - val_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.7922 - val_accuracy: 0.8513\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.7961 - val_accuracy: 0.8462\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.7969 - val_accuracy: 0.8462\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.7990 - val_accuracy: 0.8513\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 0.7993 - val_accuracy: 0.8513\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8035 - val_accuracy: 0.8462\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 0.8060 - val_accuracy: 0.8462\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2311 - accuracy: 0.8896 - val_loss: 0.8096 - val_accuracy: 0.8462\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.8049 - val_accuracy: 0.8462\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2350 - accuracy: 0.8786 - val_loss: 0.8028 - val_accuracy: 0.8462\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.8060 - val_accuracy: 0.8513\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8051 - val_accuracy: 0.8513\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.8044 - val_accuracy: 0.8513\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8066 - val_accuracy: 0.8462\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.8068 - val_accuracy: 0.8513\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.8105 - val_accuracy: 0.8462\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.8115 - val_accuracy: 0.8513\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.8135 - val_accuracy: 0.8513\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8091 - val_accuracy: 0.8462\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8113 - val_accuracy: 0.8462\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8140 - val_accuracy: 0.8513\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8069 - val_accuracy: 0.8462\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.8055 - val_accuracy: 0.8513\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.8125 - val_accuracy: 0.8462\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.8071 - val_accuracy: 0.8462\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8128 - val_accuracy: 0.8513\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.8123 - val_accuracy: 0.8513\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.8097 - val_accuracy: 0.8513\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.8167 - val_accuracy: 0.8513\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8177 - val_accuracy: 0.8462\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8183 - val_accuracy: 0.8462\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.8126 - val_accuracy: 0.8462\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.8144 - val_accuracy: 0.8462\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.8144 - val_accuracy: 0.8462\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.8176 - val_accuracy: 0.8513\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8150 - val_accuracy: 0.8462\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8029 - val_accuracy: 0.8462\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.8047 - val_accuracy: 0.8513\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8136 - val_accuracy: 0.8462\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8155 - val_accuracy: 0.8462\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.8090 - val_accuracy: 0.8462\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8104 - val_accuracy: 0.8513\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2329 - accuracy: 0.8874 - val_loss: 0.8117 - val_accuracy: 0.8513\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2341 - accuracy: 0.8808 - val_loss: 0.8097 - val_accuracy: 0.8513\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.8127 - val_accuracy: 0.8513\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8169 - val_accuracy: 0.8462\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.8155 - val_accuracy: 0.8462\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 0.8193 - val_accuracy: 0.8513\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.8191 - val_accuracy: 0.8513\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.8215 - val_accuracy: 0.8462\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.8230 - val_accuracy: 0.8513\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8247 - val_accuracy: 0.8513\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8239 - val_accuracy: 0.8513\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.8217 - val_accuracy: 0.8462\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.8234 - val_accuracy: 0.8513\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.8257 - val_accuracy: 0.8513\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8290 - val_accuracy: 0.8462\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.8260 - val_accuracy: 0.8513\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8261 - val_accuracy: 0.8462\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8268 - val_accuracy: 0.8462\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 115us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8265 - val_accuracy: 0.8513\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8288 - val_accuracy: 0.8462\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.8322 - val_accuracy: 0.8513\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.8268 - val_accuracy: 0.8513\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8284 - val_accuracy: 0.8462\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8274 - val_accuracy: 0.8462\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.8339 - val_accuracy: 0.8513\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.8275 - val_accuracy: 0.8513\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.8251 - val_accuracy: 0.8513\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.8252 - val_accuracy: 0.8513\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.8336 - val_accuracy: 0.8513\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8327 - val_accuracy: 0.8462\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2331 - accuracy: 0.8720 - val_loss: 0.8401 - val_accuracy: 0.8667\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2388 - accuracy: 0.8852 - val_loss: 0.8362 - val_accuracy: 0.8513\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.8338 - val_accuracy: 0.8513\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.8346 - val_accuracy: 0.8513\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8358 - val_accuracy: 0.8462\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.8392 - val_accuracy: 0.8513\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.8354 - val_accuracy: 0.8513\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.8390 - val_accuracy: 0.8667\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.8356 - val_accuracy: 0.8462\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2305 - accuracy: 0.8742 - val_loss: 0.8380 - val_accuracy: 0.8462\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2308 - accuracy: 0.8808 - val_loss: 0.8386 - val_accuracy: 0.8667\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.8395 - val_accuracy: 0.8462\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.8343 - val_accuracy: 0.8462\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.8348 - val_accuracy: 0.8513\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2275 - accuracy: 0.8830 - val_loss: 0.8372 - val_accuracy: 0.8462\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.8373 - val_accuracy: 0.8667\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.8351 - val_accuracy: 0.8667\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.8375 - val_accuracy: 0.8462\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.8398 - val_accuracy: 0.8667\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.8387 - val_accuracy: 0.8513\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 462us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.8329 - val_accuracy: 0.8410\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.8430 - val_accuracy: 0.8667\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 325us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8388 - val_accuracy: 0.8667\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.8351 - val_accuracy: 0.8667\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8277 - val_accuracy: 0.8513\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 412us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.8261 - val_accuracy: 0.8667\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.8207 - val_accuracy: 0.8513\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.8263 - val_accuracy: 0.8462\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8321 - val_accuracy: 0.8462\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.8314 - val_accuracy: 0.8667\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8323 - val_accuracy: 0.8462\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8365 - val_accuracy: 0.8667\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8383 - val_accuracy: 0.8667\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.8334 - val_accuracy: 0.8513\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2306 - accuracy: 0.8830 - val_loss: 0.8364 - val_accuracy: 0.8513\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.8358 - val_accuracy: 0.8462\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8392 - val_accuracy: 0.8462\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.8376 - val_accuracy: 0.8513\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2349 - accuracy: 0.8874 - val_loss: 0.8390 - val_accuracy: 0.8462\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.8405 - val_accuracy: 0.8667\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.8369 - val_accuracy: 0.8462\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8439 - val_accuracy: 0.8667\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8381 - val_accuracy: 0.8667\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.8433 - val_accuracy: 0.8667\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.8427 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.8434 - val_accuracy: 0.8667\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.8430 - val_accuracy: 0.8513\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.8431 - val_accuracy: 0.8667\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.8426 - val_accuracy: 0.8667\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.8418 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.8459 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8424 - val_accuracy: 0.8667\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.8445 - val_accuracy: 0.8667\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.8471 - val_accuracy: 0.8667\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.8388 - val_accuracy: 0.8667\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.8359 - val_accuracy: 0.8513\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.8371 - val_accuracy: 0.8667\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2276 - accuracy: 0.8830 - val_loss: 0.8386 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.8370 - val_accuracy: 0.8667\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.8379 - val_accuracy: 0.8667\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8402 - val_accuracy: 0.8667\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.8419 - val_accuracy: 0.8667\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.8404 - val_accuracy: 0.8667\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.8414 - val_accuracy: 0.8667\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.8414 - val_accuracy: 0.8513\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.8488 - val_accuracy: 0.8667\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.8419 - val_accuracy: 0.8667\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.8447 - val_accuracy: 0.8667\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.8435 - val_accuracy: 0.8513\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.8461 - val_accuracy: 0.8667\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.8497 - val_accuracy: 0.8667\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.8493 - val_accuracy: 0.8667\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8460 - val_accuracy: 0.8667\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2305 - accuracy: 0.8764 - val_loss: 0.8493 - val_accuracy: 0.8667\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8490 - val_accuracy: 0.8667\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.8592 - val_accuracy: 0.8667\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 353us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.8417 - val_accuracy: 0.8513\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2276 - accuracy: 0.8830 - val_loss: 0.8434 - val_accuracy: 0.8667\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.8409 - val_accuracy: 0.8667\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.8505 - val_accuracy: 0.8615\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8496 - val_accuracy: 0.8667\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.8488 - val_accuracy: 0.8667\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2265 - accuracy: 0.8830 - val_loss: 0.8439 - val_accuracy: 0.8667\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.8431 - val_accuracy: 0.8667\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 264us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.8454 - val_accuracy: 0.8667\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.8497 - val_accuracy: 0.8667\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2304 - accuracy: 0.8808 - val_loss: 0.8522 - val_accuracy: 0.8667\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.8479 - val_accuracy: 0.8667\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2300 - accuracy: 0.8830 - val_loss: 0.8537 - val_accuracy: 0.8667\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 0.8497 - val_accuracy: 0.8667\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.8526 - val_accuracy: 0.8667\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8333 - val_accuracy: 0.8667\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8385 - val_accuracy: 0.8667\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.8411 - val_accuracy: 0.8718\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.8402 - val_accuracy: 0.8667\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.8427 - val_accuracy: 0.8667\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8390 - val_accuracy: 0.8667\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.8385 - val_accuracy: 0.8667\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 170us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.8430 - val_accuracy: 0.8667\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8474 - val_accuracy: 0.8667\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 225us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8434 - val_accuracy: 0.8667\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.8449 - val_accuracy: 0.8667\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.8466 - val_accuracy: 0.8667\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8478 - val_accuracy: 0.8667\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.8521 - val_accuracy: 0.8667\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2347 - accuracy: 0.8874 - val_loss: 0.8461 - val_accuracy: 0.8667\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.8493 - val_accuracy: 0.8667\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.8465 - val_accuracy: 0.8667\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8492 - val_accuracy: 0.8667\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8467 - val_accuracy: 0.8667\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2299 - accuracy: 0.8830 - val_loss: 0.8471 - val_accuracy: 0.8667\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8474 - val_accuracy: 0.8667\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2298 - accuracy: 0.8786 - val_loss: 0.8551 - val_accuracy: 0.8667\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.8485 - val_accuracy: 0.8667\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8482 - val_accuracy: 0.8667\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.8544 - val_accuracy: 0.8667\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.8520 - val_accuracy: 0.8667\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8488 - val_accuracy: 0.8667\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.8517 - val_accuracy: 0.8667\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.8576 - val_accuracy: 0.8667\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.8592 - val_accuracy: 0.8667\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.8598 - val_accuracy: 0.8667\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.8616 - val_accuracy: 0.8667\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.8541 - val_accuracy: 0.8667\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.8594 - val_accuracy: 0.8667\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2291 - accuracy: 0.8808 - val_loss: 0.8634 - val_accuracy: 0.8667\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 312us/step - loss: 0.2281 - accuracy: 0.8808 - val_loss: 0.8575 - val_accuracy: 0.8718\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.8646 - val_accuracy: 0.8667\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2332 - accuracy: 0.8874 - val_loss: 0.8617 - val_accuracy: 0.8667\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8659 - val_accuracy: 0.8667\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.8615 - val_accuracy: 0.8667\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2280 - accuracy: 0.8852 - val_loss: 0.8619 - val_accuracy: 0.8667\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.8443 - val_accuracy: 0.8667\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.8431 - val_accuracy: 0.8615\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.8399 - val_accuracy: 0.8615\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.8399 - val_accuracy: 0.8615\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2330 - accuracy: 0.8874 - val_loss: 0.8371 - val_accuracy: 0.8615\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8424 - val_accuracy: 0.8615\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8447 - val_accuracy: 0.8615\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.8404 - val_accuracy: 0.8615\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2321 - accuracy: 0.8764 - val_loss: 0.8449 - val_accuracy: 0.8615\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8419 - val_accuracy: 0.8615\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.8439 - val_accuracy: 0.8615\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8462 - val_accuracy: 0.8615\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2337 - accuracy: 0.8896 - val_loss: 0.8363 - val_accuracy: 0.8615\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2323 - accuracy: 0.8808 - val_loss: 0.8398 - val_accuracy: 0.8667\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8451 - val_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.8478 - val_accuracy: 0.8615\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.8458 - val_accuracy: 0.8615\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8449 - val_accuracy: 0.8615\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.8515 - val_accuracy: 0.8615\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.8516 - val_accuracy: 0.8615\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2288 - accuracy: 0.8808 - val_loss: 0.8530 - val_accuracy: 0.8615\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8512 - val_accuracy: 0.8615\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2281 - accuracy: 0.8786 - val_loss: 0.8538 - val_accuracy: 0.8615\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.8529 - val_accuracy: 0.8615\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8520 - val_accuracy: 0.8615\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.8524 - val_accuracy: 0.8615\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.8534 - val_accuracy: 0.8615\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8417 - val_accuracy: 0.8667\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.8420 - val_accuracy: 0.8615\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8439 - val_accuracy: 0.8615\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.8489 - val_accuracy: 0.8615\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8515 - val_accuracy: 0.8615\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8527 - val_accuracy: 0.8615\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2290 - accuracy: 0.8786 - val_loss: 0.8503 - val_accuracy: 0.8615\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.8802 - val_accuracy: 0.8718\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.8683 - val_accuracy: 0.8667\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.8613 - val_accuracy: 0.8667\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2308 - accuracy: 0.8786 - val_loss: 0.8519 - val_accuracy: 0.8667\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.8507 - val_accuracy: 0.8667\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8488 - val_accuracy: 0.8667\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2328 - accuracy: 0.8874 - val_loss: 0.8532 - val_accuracy: 0.8667\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.8520 - val_accuracy: 0.8718\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.8288 - val_accuracy: 0.8718\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.8288 - val_accuracy: 0.8718\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2327 - accuracy: 0.8742 - val_loss: 0.8319 - val_accuracy: 0.8718\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.8314 - val_accuracy: 0.8718\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8312 - val_accuracy: 0.8718\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.8259 - val_accuracy: 0.8513\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.8302 - val_accuracy: 0.8462\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8344 - val_accuracy: 0.8513\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8370 - val_accuracy: 0.8513\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.8292 - val_accuracy: 0.8513\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8315 - val_accuracy: 0.8513\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.8392 - val_accuracy: 0.8513\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.8420 - val_accuracy: 0.8513\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2341 - accuracy: 0.8874 - val_loss: 0.8416 - val_accuracy: 0.8513\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2282 - accuracy: 0.8852 - val_loss: 0.8483 - val_accuracy: 0.8513\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.8484 - val_accuracy: 0.8513\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8511 - val_accuracy: 0.8513\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2270 - accuracy: 0.8808 - val_loss: 0.8276 - val_accuracy: 0.8513\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.8409 - val_accuracy: 0.8513\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.8442 - val_accuracy: 0.8513\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.8413 - val_accuracy: 0.8513\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.8423 - val_accuracy: 0.8513\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.8432 - val_accuracy: 0.8513\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8456 - val_accuracy: 0.8513\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2312 - accuracy: 0.8786 - val_loss: 0.8437 - val_accuracy: 0.8513\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.8443 - val_accuracy: 0.8513\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8411 - val_accuracy: 0.8462\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8423 - val_accuracy: 0.8513\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8469 - val_accuracy: 0.8513\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2347 - accuracy: 0.8874 - val_loss: 0.8440 - val_accuracy: 0.8462\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.8500 - val_accuracy: 0.8513\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.8487 - val_accuracy: 0.8462\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 243us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.8505 - val_accuracy: 0.8462\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2309 - accuracy: 0.8808 - val_loss: 0.8444 - val_accuracy: 0.8462\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 150us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8446 - val_accuracy: 0.8462\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2282 - accuracy: 0.8852 - val_loss: 0.8496 - val_accuracy: 0.8462\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8461 - val_accuracy: 0.8462\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.8457 - val_accuracy: 0.8462\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.8516 - val_accuracy: 0.8462\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.8531 - val_accuracy: 0.8462\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.8485 - val_accuracy: 0.8462\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8511 - val_accuracy: 0.8462\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.8496 - val_accuracy: 0.8462\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.8456 - val_accuracy: 0.8462\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8516 - val_accuracy: 0.8462\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2297 - accuracy: 0.8786 - val_loss: 0.8516 - val_accuracy: 0.8462\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.8530 - val_accuracy: 0.8462\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2276 - accuracy: 0.8852 - val_loss: 0.8544 - val_accuracy: 0.8462\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.8571 - val_accuracy: 0.8513\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8587 - val_accuracy: 0.8462\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.8579 - val_accuracy: 0.8462\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8578 - val_accuracy: 0.8462\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.8550 - val_accuracy: 0.8462\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8556 - val_accuracy: 0.8462\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8573 - val_accuracy: 0.8462\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8596 - val_accuracy: 0.8462\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2294 - accuracy: 0.8830 - val_loss: 0.8548 - val_accuracy: 0.8462\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.8523 - val_accuracy: 0.8462\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.8561 - val_accuracy: 0.8462\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.8577 - val_accuracy: 0.8462\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8616 - val_accuracy: 0.8462\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.8592 - val_accuracy: 0.8462\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8591 - val_accuracy: 0.8462\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8565 - val_accuracy: 0.8462\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8606 - val_accuracy: 0.8462\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.8590 - val_accuracy: 0.8462\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2276 - accuracy: 0.8852 - val_loss: 0.8557 - val_accuracy: 0.8462\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.8590 - val_accuracy: 0.8462\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8627 - val_accuracy: 0.8462\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.8611 - val_accuracy: 0.8462\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.8589 - val_accuracy: 0.8462\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.8468 - val_accuracy: 0.8462\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.8387 - val_accuracy: 0.8462\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8392 - val_accuracy: 0.8462\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8388 - val_accuracy: 0.8462\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 320us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.8576 - val_accuracy: 0.8462\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8534 - val_accuracy: 0.8462\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 346us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.8589 - val_accuracy: 0.8462\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.8568 - val_accuracy: 0.8462\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 313us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8638 - val_accuracy: 0.8462\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8654 - val_accuracy: 0.8462\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.8668 - val_accuracy: 0.8462\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.8666 - val_accuracy: 0.8462\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.8689 - val_accuracy: 0.8462\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2265 - accuracy: 0.8808 - val_loss: 0.8687 - val_accuracy: 0.8462\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.8710 - val_accuracy: 0.8462\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.8677 - val_accuracy: 0.8462\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8740 - val_accuracy: 0.8462\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.8716 - val_accuracy: 0.8462\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8715 - val_accuracy: 0.8462\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.8770 - val_accuracy: 0.8462\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.8778 - val_accuracy: 0.8462\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.8789 - val_accuracy: 0.8462\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.8751 - val_accuracy: 0.8462\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.8743 - val_accuracy: 0.8462\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.8779 - val_accuracy: 0.8462\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.8750 - val_accuracy: 0.8462\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8755 - val_accuracy: 0.8462\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.8775 - val_accuracy: 0.8462\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8769 - val_accuracy: 0.8462\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.8810 - val_accuracy: 0.8462\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.8809 - val_accuracy: 0.8462\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.8760 - val_accuracy: 0.8462\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.8877 - val_accuracy: 0.8462\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.8888 - val_accuracy: 0.8462\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8895 - val_accuracy: 0.8462\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8907 - val_accuracy: 0.8462\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.8914 - val_accuracy: 0.8462\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.8895 - val_accuracy: 0.8462\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.8946 - val_accuracy: 0.8462\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.8909 - val_accuracy: 0.8462\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8896 - val_accuracy: 0.8462\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.8933 - val_accuracy: 0.8462\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8900 - val_accuracy: 0.8462\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.8909 - val_accuracy: 0.8462\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.8898 - val_accuracy: 0.8462\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2281 - accuracy: 0.8852 - val_loss: 0.8906 - val_accuracy: 0.8462\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2282 - accuracy: 0.8786 - val_loss: 0.8906 - val_accuracy: 0.8462\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8895 - val_accuracy: 0.8462\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8902 - val_accuracy: 0.8462\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.8897 - val_accuracy: 0.8462\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2291 - accuracy: 0.8896 - val_loss: 0.8914 - val_accuracy: 0.8462\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.8974 - val_accuracy: 0.8462\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.8962 - val_accuracy: 0.8462\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.8936 - val_accuracy: 0.8462\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8924 - val_accuracy: 0.8462\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.8941 - val_accuracy: 0.8462\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.8985 - val_accuracy: 0.8462\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8975 - val_accuracy: 0.8462\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2290 - accuracy: 0.8830 - val_loss: 0.8957 - val_accuracy: 0.8462\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.8977 - val_accuracy: 0.8462\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.8962 - val_accuracy: 0.8462\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.8959 - val_accuracy: 0.8462\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9004 - val_accuracy: 0.8462\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 0.8985 - val_accuracy: 0.8462\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2272 - accuracy: 0.8852 - val_loss: 0.9013 - val_accuracy: 0.8462\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2283 - accuracy: 0.8808 - val_loss: 0.9018 - val_accuracy: 0.8462\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9042 - val_accuracy: 0.8462\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2294 - accuracy: 0.8786 - val_loss: 0.8978 - val_accuracy: 0.8462\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.9008 - val_accuracy: 0.8462\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.9001 - val_accuracy: 0.8462\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.8987 - val_accuracy: 0.8462\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9036 - val_accuracy: 0.8462\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2319 - accuracy: 0.8874 - val_loss: 0.9009 - val_accuracy: 0.8462\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 126us/step - loss: 0.2313 - accuracy: 0.8808 - val_loss: 0.9070 - val_accuracy: 0.8462\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2297 - accuracy: 0.8808 - val_loss: 0.9025 - val_accuracy: 0.8462\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.8991 - val_accuracy: 0.8462\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9065 - val_accuracy: 0.8462\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.8951 - val_accuracy: 0.8462\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2280 - accuracy: 0.8830 - val_loss: 0.8964 - val_accuracy: 0.8462\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2277 - accuracy: 0.8852 - val_loss: 0.9032 - val_accuracy: 0.8462\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2272 - accuracy: 0.8808 - val_loss: 0.9026 - val_accuracy: 0.8462\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9028 - val_accuracy: 0.8462\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.9030 - val_accuracy: 0.8462\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9040 - val_accuracy: 0.8462\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2299 - accuracy: 0.8786 - val_loss: 0.9073 - val_accuracy: 0.8462\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9018 - val_accuracy: 0.8462\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9073 - val_accuracy: 0.8462\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9028 - val_accuracy: 0.8462\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.9035 - val_accuracy: 0.8462\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2314 - accuracy: 0.8786 - val_loss: 0.8981 - val_accuracy: 0.8462\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.8962 - val_accuracy: 0.8462\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9022 - val_accuracy: 0.8462\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9029 - val_accuracy: 0.8462\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9017 - val_accuracy: 0.8462\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9038 - val_accuracy: 0.8462\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9007 - val_accuracy: 0.8462\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.9060 - val_accuracy: 0.8462\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9035 - val_accuracy: 0.8462\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9078 - val_accuracy: 0.8462\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9070 - val_accuracy: 0.8462\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9060 - val_accuracy: 0.8462\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9066 - val_accuracy: 0.8462\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2293 - accuracy: 0.8830 - val_loss: 0.9047 - val_accuracy: 0.8462\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9057 - val_accuracy: 0.8462\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9093 - val_accuracy: 0.8462\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2275 - accuracy: 0.8830 - val_loss: 0.9010 - val_accuracy: 0.8462\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.8874 - val_loss: 0.9104 - val_accuracy: 0.8462\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.9116 - val_accuracy: 0.8462\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.8912 - val_accuracy: 0.8462\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.8970 - val_accuracy: 0.8462\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2270 - accuracy: 0.8830 - val_loss: 0.9013 - val_accuracy: 0.8462\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9054 - val_accuracy: 0.8462\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.9028 - val_accuracy: 0.8462\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9034 - val_accuracy: 0.8462\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9101 - val_accuracy: 0.8462\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9087 - val_accuracy: 0.8462\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2264 - accuracy: 0.8874 - val_loss: 0.9098 - val_accuracy: 0.8462\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2290 - accuracy: 0.8896 - val_loss: 0.9107 - val_accuracy: 0.8462\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.9137 - val_accuracy: 0.8462\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.9087 - val_accuracy: 0.8513\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.9067 - val_accuracy: 0.8462\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.9092 - val_accuracy: 0.8462\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.9137 - val_accuracy: 0.8462\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2294 - accuracy: 0.8720 - val_loss: 0.9117 - val_accuracy: 0.8462\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.9125 - val_accuracy: 0.8462\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2292 - accuracy: 0.8764 - val_loss: 0.9142 - val_accuracy: 0.8462\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2274 - accuracy: 0.8852 - val_loss: 0.9151 - val_accuracy: 0.8410\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2281 - accuracy: 0.8852 - val_loss: 0.9158 - val_accuracy: 0.8462\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9191 - val_accuracy: 0.8462\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.9126 - val_accuracy: 0.8410\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9193 - val_accuracy: 0.8410\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.9163 - val_accuracy: 0.8410\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.9238 - val_accuracy: 0.8462\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9221 - val_accuracy: 0.8410\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.9244 - val_accuracy: 0.8462\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.9235 - val_accuracy: 0.8462\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9231 - val_accuracy: 0.8410\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9230 - val_accuracy: 0.8410\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.9205 - val_accuracy: 0.8410\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.9222 - val_accuracy: 0.8410\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.9273 - val_accuracy: 0.8410\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.9186 - val_accuracy: 0.8410\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.9216 - val_accuracy: 0.8410\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 223us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.9309 - val_accuracy: 0.8410\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9252 - val_accuracy: 0.8410\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.9297 - val_accuracy: 0.8462\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.9273 - val_accuracy: 0.8410\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.8997 - val_accuracy: 0.8462\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.8974 - val_accuracy: 0.8462\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.8990 - val_accuracy: 0.8462\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9021 - val_accuracy: 0.8462\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.9076 - val_accuracy: 0.8462\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.9049 - val_accuracy: 0.8462\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9108 - val_accuracy: 0.8462\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.9074 - val_accuracy: 0.8462\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.9112 - val_accuracy: 0.8462\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.9105 - val_accuracy: 0.8462\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9105 - val_accuracy: 0.8462\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.9118 - val_accuracy: 0.8462\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2296 - accuracy: 0.8764 - val_loss: 0.9144 - val_accuracy: 0.8462\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.9208 - val_accuracy: 0.8462\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2323 - accuracy: 0.8874 - val_loss: 0.9179 - val_accuracy: 0.8462\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9184 - val_accuracy: 0.8462\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2321 - accuracy: 0.8786 - val_loss: 0.9153 - val_accuracy: 0.8462\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9127 - val_accuracy: 0.8462\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9171 - val_accuracy: 0.8462\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.9178 - val_accuracy: 0.8462\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9163 - val_accuracy: 0.8462\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.9205 - val_accuracy: 0.8462\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9239 - val_accuracy: 0.8462\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9208 - val_accuracy: 0.8462\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9202 - val_accuracy: 0.8462\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9253 - val_accuracy: 0.8462\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 303us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.9238 - val_accuracy: 0.8462\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.9255 - val_accuracy: 0.8462\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9274 - val_accuracy: 0.8462\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9351 - val_accuracy: 0.8462\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 551us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.9272 - val_accuracy: 0.8462\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 375us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.9279 - val_accuracy: 0.8462\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2322 - accuracy: 0.8786 - val_loss: 0.9256 - val_accuracy: 0.8462\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.9260 - val_accuracy: 0.8462\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 455us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.9266 - val_accuracy: 0.8462\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 319us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9262 - val_accuracy: 0.8462\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 282us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9286 - val_accuracy: 0.8462\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.9265 - val_accuracy: 0.8462\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9286 - val_accuracy: 0.8462\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.9303 - val_accuracy: 0.8462\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 0.9328 - val_accuracy: 0.8462\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2258 - accuracy: 0.8874 - val_loss: 0.9361 - val_accuracy: 0.8462\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9356 - val_accuracy: 0.8462\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.9356 - val_accuracy: 0.8513\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.2284 - accuracy: 0.8830 - val_loss: 0.9367 - val_accuracy: 0.8667\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9344 - val_accuracy: 0.8462\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 283us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.9366 - val_accuracy: 0.8462\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 915us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.9332 - val_accuracy: 0.8462\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.9337 - val_accuracy: 0.8462\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.9339 - val_accuracy: 0.8462\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9387 - val_accuracy: 0.8513\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 189us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.9378 - val_accuracy: 0.8513\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.9403 - val_accuracy: 0.8513\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9394 - val_accuracy: 0.8462\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9375 - val_accuracy: 0.8462\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.9401 - val_accuracy: 0.8513\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.9375 - val_accuracy: 0.8462\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 245us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9428 - val_accuracy: 0.8667\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2298 - accuracy: 0.8808 - val_loss: 0.9377 - val_accuracy: 0.8462\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2268 - accuracy: 0.8830 - val_loss: 0.9451 - val_accuracy: 0.8513\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9449 - val_accuracy: 0.8513\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9411 - val_accuracy: 0.8513\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.9441 - val_accuracy: 0.8513\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2279 - accuracy: 0.8786 - val_loss: 0.9428 - val_accuracy: 0.8667\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 262us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9409 - val_accuracy: 0.8410\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9426 - val_accuracy: 0.8410\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9587 - val_accuracy: 0.8667\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 343us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9739 - val_accuracy: 0.8462\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 207us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9519 - val_accuracy: 0.8667\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.9313 - val_accuracy: 0.8513\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.9283 - val_accuracy: 0.8513\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 0.9329 - val_accuracy: 0.8667\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 359us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.9217 - val_accuracy: 0.8513\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.9206 - val_accuracy: 0.8667\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 328us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.9178 - val_accuracy: 0.8667\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 231us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9175 - val_accuracy: 0.8513\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 467us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.9160 - val_accuracy: 0.8513\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9169 - val_accuracy: 0.8513\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 285us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.9200 - val_accuracy: 0.8667\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.88 - 0s 552us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.9155 - val_accuracy: 0.8513\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 380us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9181 - val_accuracy: 0.8667\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9163 - val_accuracy: 0.8462\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.9162 - val_accuracy: 0.8667\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9200 - val_accuracy: 0.8667\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9193 - val_accuracy: 0.8667\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 380us/step - loss: 0.2289 - accuracy: 0.8786 - val_loss: 0.9205 - val_accuracy: 0.8513\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 292us/step - loss: 0.2310 - accuracy: 0.8874 - val_loss: 0.9223 - val_accuracy: 0.8667\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 335us/step - loss: 0.2326 - accuracy: 0.8874 - val_loss: 0.9273 - val_accuracy: 0.8667\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 598us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9222 - val_accuracy: 0.8667\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 410us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9171 - val_accuracy: 0.8667\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 314us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.9198 - val_accuracy: 0.8513\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 305us/step - loss: 0.2321 - accuracy: 0.8874 - val_loss: 0.9210 - val_accuracy: 0.8513\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 218us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9199 - val_accuracy: 0.8513\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.9175 - val_accuracy: 0.8667\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9208 - val_accuracy: 0.8667\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.9266 - val_accuracy: 0.8667\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2309 - accuracy: 0.8874 - val_loss: 0.9209 - val_accuracy: 0.8513\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2282 - accuracy: 0.8830 - val_loss: 0.9177 - val_accuracy: 0.8462\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.9266 - val_accuracy: 0.8667\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.9233 - val_accuracy: 0.8667\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2287 - accuracy: 0.8786 - val_loss: 0.9191 - val_accuracy: 0.8564\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.9215 - val_accuracy: 0.8667\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2297 - accuracy: 0.8830 - val_loss: 0.9245 - val_accuracy: 0.8667\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9211 - val_accuracy: 0.8667\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 448us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.9185 - val_accuracy: 0.8667\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.9209 - val_accuracy: 0.8667\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9209 - val_accuracy: 0.8667\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 286us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.9199 - val_accuracy: 0.8615\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 420us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.9225 - val_accuracy: 0.8667\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 235us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9216 - val_accuracy: 0.8667\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 391us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9231 - val_accuracy: 0.8667\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 0.9289 - val_accuracy: 0.8667\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9271 - val_accuracy: 0.8667\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.2285 - accuracy: 0.8830 - val_loss: 0.9271 - val_accuracy: 0.8667\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 388us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9269 - val_accuracy: 0.8667\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.9237 - val_accuracy: 0.8667\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 348us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9270 - val_accuracy: 0.8667\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 252us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9255 - val_accuracy: 0.8667\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 351us/step - loss: 0.2286 - accuracy: 0.8764 - val_loss: 0.9312 - val_accuracy: 0.8667\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.9255 - val_accuracy: 0.8667\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 250us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9248 - val_accuracy: 0.8667\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.9245 - val_accuracy: 0.8667\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 336us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9275 - val_accuracy: 0.8667\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.9256 - val_accuracy: 0.8564\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.9250 - val_accuracy: 0.8615\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9283 - val_accuracy: 0.8615\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9306 - val_accuracy: 0.8667\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9292 - val_accuracy: 0.8615\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.9309 - val_accuracy: 0.8615\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 244us/step - loss: 0.2277 - accuracy: 0.8808 - val_loss: 0.9278 - val_accuracy: 0.8615\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9279 - val_accuracy: 0.8564\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.9287 - val_accuracy: 0.8564\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.9333 - val_accuracy: 0.8615\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9314 - val_accuracy: 0.8564\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9318 - val_accuracy: 0.8564\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9327 - val_accuracy: 0.8615\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.9300 - val_accuracy: 0.8615\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2294 - accuracy: 0.8808 - val_loss: 0.9332 - val_accuracy: 0.8564\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9341 - val_accuracy: 0.8615\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9315 - val_accuracy: 0.8615\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9346 - val_accuracy: 0.8667\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2281 - accuracy: 0.8830 - val_loss: 0.9324 - val_accuracy: 0.8615\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9338 - val_accuracy: 0.8564\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9315 - val_accuracy: 0.8615\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.9307 - val_accuracy: 0.8667\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2280 - accuracy: 0.8808 - val_loss: 0.9347 - val_accuracy: 0.8564\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 125us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.9318 - val_accuracy: 0.8564\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2324 - accuracy: 0.8874 - val_loss: 0.9360 - val_accuracy: 0.8615\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9373 - val_accuracy: 0.8615\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.9323 - val_accuracy: 0.8564\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.9351 - val_accuracy: 0.8564\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9404 - val_accuracy: 0.8564\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.9412 - val_accuracy: 0.8615\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.9372 - val_accuracy: 0.8667\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.9321 - val_accuracy: 0.8667\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2285 - accuracy: 0.8808 - val_loss: 0.9320 - val_accuracy: 0.8667\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9349 - val_accuracy: 0.8667\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.9355 - val_accuracy: 0.8564\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 367us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.9319 - val_accuracy: 0.8615\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.9365 - val_accuracy: 0.8564\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.9414 - val_accuracy: 0.8667\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 597us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9430 - val_accuracy: 0.8615\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.9388 - val_accuracy: 0.8667\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.9404 - val_accuracy: 0.8667\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.9419 - val_accuracy: 0.8615\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9406 - val_accuracy: 0.8615\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9401 - val_accuracy: 0.8564\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9446 - val_accuracy: 0.8615\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2264 - accuracy: 0.8808 - val_loss: 0.9365 - val_accuracy: 0.8667\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 188us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9385 - val_accuracy: 0.8564\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9425 - val_accuracy: 0.8667\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9447 - val_accuracy: 0.8615\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9450 - val_accuracy: 0.8667\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9436 - val_accuracy: 0.8615\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.9507 - val_accuracy: 0.8615\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.9411 - val_accuracy: 0.8615\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2305 - accuracy: 0.8874 - val_loss: 0.9394 - val_accuracy: 0.8615\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9384 - val_accuracy: 0.8615\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2261 - accuracy: 0.8874 - val_loss: 0.9411 - val_accuracy: 0.8667\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2288 - accuracy: 0.8786 - val_loss: 0.9388 - val_accuracy: 0.8667\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9410 - val_accuracy: 0.8615\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9402 - val_accuracy: 0.8615\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.9426 - val_accuracy: 0.8615\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.9447 - val_accuracy: 0.8667\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9462 - val_accuracy: 0.8615\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9422 - val_accuracy: 0.8615\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2305 - accuracy: 0.8808 - val_loss: 0.9485 - val_accuracy: 0.8667\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 232us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9067 - val_accuracy: 0.8718\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 401us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.9261 - val_accuracy: 0.8564\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.9350 - val_accuracy: 0.8667\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.9319 - val_accuracy: 0.8615\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9342 - val_accuracy: 0.8667\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9387 - val_accuracy: 0.8667\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 177us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9385 - val_accuracy: 0.8667\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.9340 - val_accuracy: 0.8667\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.9337 - val_accuracy: 0.8615\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.9336 - val_accuracy: 0.8615\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.9402 - val_accuracy: 0.8667\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.9441 - val_accuracy: 0.8615\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9435 - val_accuracy: 0.8615\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9407 - val_accuracy: 0.8615\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9419 - val_accuracy: 0.8615\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9393 - val_accuracy: 0.8667\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2283 - accuracy: 0.8830 - val_loss: 0.9399 - val_accuracy: 0.8667\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9396 - val_accuracy: 0.8615\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.9361 - val_accuracy: 0.8615\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.9389 - val_accuracy: 0.8615\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 212us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.9380 - val_accuracy: 0.8667\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.9392 - val_accuracy: 0.8667\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2277 - accuracy: 0.8830 - val_loss: 0.9402 - val_accuracy: 0.8667\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2278 - accuracy: 0.8830 - val_loss: 0.9410 - val_accuracy: 0.8615\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 0.9463 - val_accuracy: 0.8667\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9491 - val_accuracy: 0.8667\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9408 - val_accuracy: 0.8667\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9388 - val_accuracy: 0.8615\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2282 - accuracy: 0.8852 - val_loss: 0.9431 - val_accuracy: 0.8667\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.9437 - val_accuracy: 0.8615\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 0.9452 - val_accuracy: 0.8615\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2261 - accuracy: 0.8874 - val_loss: 0.9489 - val_accuracy: 0.8667\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.9546 - val_accuracy: 0.8667\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 0.9463 - val_accuracy: 0.8615\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9488 - val_accuracy: 0.8615\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9503 - val_accuracy: 0.8615\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9514 - val_accuracy: 0.8615\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9567 - val_accuracy: 0.8615\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9517 - val_accuracy: 0.8615\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 199us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9507 - val_accuracy: 0.8615\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.9525 - val_accuracy: 0.8667\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.9525 - val_accuracy: 0.8667\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2298 - accuracy: 0.8742 - val_loss: 0.9508 - val_accuracy: 0.8667\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9498 - val_accuracy: 0.8615\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9488 - val_accuracy: 0.8615\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.9555 - val_accuracy: 0.8615\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2277 - accuracy: 0.8852 - val_loss: 0.9539 - val_accuracy: 0.8615\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9559 - val_accuracy: 0.8667\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 284us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.9545 - val_accuracy: 0.8615\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 342us/step - loss: 0.2293 - accuracy: 0.8852 - val_loss: 0.9536 - val_accuracy: 0.8615\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2293 - accuracy: 0.8786 - val_loss: 0.9542 - val_accuracy: 0.8615\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.9536 - val_accuracy: 0.8615\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 0.9574 - val_accuracy: 0.8667\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9567 - val_accuracy: 0.8615\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2290 - accuracy: 0.8808 - val_loss: 0.9531 - val_accuracy: 0.8615\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9528 - val_accuracy: 0.8615\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9597 - val_accuracy: 0.8615\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2316 - accuracy: 0.8874 - val_loss: 0.9620 - val_accuracy: 0.8615\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9556 - val_accuracy: 0.8667\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2307 - accuracy: 0.8874 - val_loss: 0.9567 - val_accuracy: 0.8615\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2298 - accuracy: 0.8874 - val_loss: 0.9610 - val_accuracy: 0.8615\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9566 - val_accuracy: 0.8615\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 221us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 0.9600 - val_accuracy: 0.8615\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9445 - val_accuracy: 0.8615\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9304 - val_accuracy: 0.8615\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9357 - val_accuracy: 0.8615\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2259 - accuracy: 0.8874 - val_loss: 0.9412 - val_accuracy: 0.8615\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9527 - val_accuracy: 0.8615\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9541 - val_accuracy: 0.8667\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 130us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9553 - val_accuracy: 0.8615\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.9607 - val_accuracy: 0.8615\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9518 - val_accuracy: 0.8615\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2303 - accuracy: 0.8896 - val_loss: 0.9612 - val_accuracy: 0.8615\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.9615 - val_accuracy: 0.8615\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 271us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9605 - val_accuracy: 0.8615\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 247us/step - loss: 0.2285 - accuracy: 0.8764 - val_loss: 0.9596 - val_accuracy: 0.8718\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2277 - accuracy: 0.8852 - val_loss: 0.9607 - val_accuracy: 0.8615\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.9630 - val_accuracy: 0.8615\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9641 - val_accuracy: 0.8615\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.9629 - val_accuracy: 0.8615\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2302 - accuracy: 0.8808 - val_loss: 0.9615 - val_accuracy: 0.8615\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.9596 - val_accuracy: 0.8615\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 352us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 0.9683 - val_accuracy: 0.8667\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9656 - val_accuracy: 0.8667\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.9664 - val_accuracy: 0.8615\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9676 - val_accuracy: 0.8615\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 239us/step - loss: 0.2308 - accuracy: 0.8874 - val_loss: 0.9667 - val_accuracy: 0.8615\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 446us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9711 - val_accuracy: 0.8667\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9665 - val_accuracy: 0.8615\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.9701 - val_accuracy: 0.8615\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.9673 - val_accuracy: 0.8615\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9770 - val_accuracy: 0.8667\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9746 - val_accuracy: 0.8615\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.88 - 0s 199us/step - loss: 0.2269 - accuracy: 0.8852 - val_loss: 0.9731 - val_accuracy: 0.8615\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.9711 - val_accuracy: 0.8615\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2301 - accuracy: 0.8808 - val_loss: 0.9690 - val_accuracy: 0.8615\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9685 - val_accuracy: 0.8718\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2279 - accuracy: 0.8830 - val_loss: 0.9688 - val_accuracy: 0.8615\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.9702 - val_accuracy: 0.8615\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.9783 - val_accuracy: 0.8667\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9789 - val_accuracy: 0.8667\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.9744 - val_accuracy: 0.8615\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 281us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9708 - val_accuracy: 0.8615\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9744 - val_accuracy: 0.8615\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2355 - accuracy: 0.8874 - val_loss: 0.9689 - val_accuracy: 0.8615\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9694 - val_accuracy: 0.8615\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 242us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 0.9710 - val_accuracy: 0.8615\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 447us/step - loss: 0.2301 - accuracy: 0.8874 - val_loss: 0.9795 - val_accuracy: 0.8667\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.9796 - val_accuracy: 0.8667\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 214us/step - loss: 0.2285 - accuracy: 0.8742 - val_loss: 0.9692 - val_accuracy: 0.8718\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2289 - accuracy: 0.8896 - val_loss: 0.9751 - val_accuracy: 0.8615\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9681 - val_accuracy: 0.8615\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2280 - accuracy: 0.8764 - val_loss: 0.9691 - val_accuracy: 0.8615\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9824 - val_accuracy: 0.8667\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9820 - val_accuracy: 0.8667\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9785 - val_accuracy: 0.8615\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9755 - val_accuracy: 0.8615\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2297 - accuracy: 0.8874 - val_loss: 0.9781 - val_accuracy: 0.8615\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9774 - val_accuracy: 0.8615\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9785 - val_accuracy: 0.8615\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9842 - val_accuracy: 0.8667\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2278 - accuracy: 0.8852 - val_loss: 0.9789 - val_accuracy: 0.8615\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.9796 - val_accuracy: 0.8615\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 0.9773 - val_accuracy: 0.8615\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9841 - val_accuracy: 0.8615\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.9811 - val_accuracy: 0.8615\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2283 - accuracy: 0.8764 - val_loss: 0.9812 - val_accuracy: 0.8615\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2296 - accuracy: 0.8874 - val_loss: 0.9831 - val_accuracy: 0.8615\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9818 - val_accuracy: 0.8615\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2274 - accuracy: 0.8830 - val_loss: 0.9846 - val_accuracy: 0.8615\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 275us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9887 - val_accuracy: 0.8667\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2304 - accuracy: 0.8786 - val_loss: 0.9828 - val_accuracy: 0.8667\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9819 - val_accuracy: 0.8615\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9796 - val_accuracy: 0.8615\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9735 - val_accuracy: 0.8615\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 333us/step - loss: 0.2279 - accuracy: 0.8808 - val_loss: 0.9795 - val_accuracy: 0.8615\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2298 - accuracy: 0.8764 - val_loss: 0.9874 - val_accuracy: 0.8667\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 206us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9886 - val_accuracy: 0.8667\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9835 - val_accuracy: 0.8615\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.9805 - val_accuracy: 0.8615\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2276 - accuracy: 0.8852 - val_loss: 0.9849 - val_accuracy: 0.8615\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2306 - accuracy: 0.8742 - val_loss: 0.9872 - val_accuracy: 0.8615\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9769 - val_accuracy: 0.8615\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 0.9804 - val_accuracy: 0.8615\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 155us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9917 - val_accuracy: 0.8667\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.9879 - val_accuracy: 0.8615\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9905 - val_accuracy: 0.8615\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9866 - val_accuracy: 0.8615\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2287 - accuracy: 0.8874 - val_loss: 0.9812 - val_accuracy: 0.8615\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 1.0416 - val_accuracy: 0.8667\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 1.0262 - val_accuracy: 0.8667\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 0.9578 - val_accuracy: 0.8718\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 0.9245 - val_accuracy: 0.8718\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 0.9109 - val_accuracy: 0.8718\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9156 - val_accuracy: 0.8718\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.9247 - val_accuracy: 0.8718\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9193 - val_accuracy: 0.8718\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9178 - val_accuracy: 0.8718\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9276 - val_accuracy: 0.8718\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9305 - val_accuracy: 0.8718\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9316 - val_accuracy: 0.8718\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9303 - val_accuracy: 0.8718\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 0.9329 - val_accuracy: 0.8718\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2317 - accuracy: 0.8874 - val_loss: 0.9329 - val_accuracy: 0.8718\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.9389 - val_accuracy: 0.8718\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9389 - val_accuracy: 0.8718\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 280us/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.9487 - val_accuracy: 0.8718\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.9458 - val_accuracy: 0.8718\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2268 - accuracy: 0.8874 - val_loss: 0.9448 - val_accuracy: 0.8718\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9507 - val_accuracy: 0.8718\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2294 - accuracy: 0.8874 - val_loss: 0.9445 - val_accuracy: 0.8718\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9488 - val_accuracy: 0.8718\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9535 - val_accuracy: 0.8718\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2295 - accuracy: 0.8786 - val_loss: 0.9539 - val_accuracy: 0.8718\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9539 - val_accuracy: 0.8718\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9546 - val_accuracy: 0.8718\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 0.9613 - val_accuracy: 0.8718\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9599 - val_accuracy: 0.8718\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9622 - val_accuracy: 0.8718\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 126us/step - loss: 0.2279 - accuracy: 0.8764 - val_loss: 0.9585 - val_accuracy: 0.8769\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.9629 - val_accuracy: 0.8718\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9652 - val_accuracy: 0.8718\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9622 - val_accuracy: 0.8718\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9661 - val_accuracy: 0.8718\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2278 - accuracy: 0.8808 - val_loss: 0.9674 - val_accuracy: 0.8718\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 0.9653 - val_accuracy: 0.8718\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2276 - accuracy: 0.8786 - val_loss: 0.9700 - val_accuracy: 0.8718\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9719 - val_accuracy: 0.8718\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2314 - accuracy: 0.8874 - val_loss: 0.9735 - val_accuracy: 0.8718\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2269 - accuracy: 0.8786 - val_loss: 0.9736 - val_accuracy: 0.8718\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2292 - accuracy: 0.8874 - val_loss: 0.9758 - val_accuracy: 0.8718\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.9751 - val_accuracy: 0.8718\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.9729 - val_accuracy: 0.8718\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 0.9740 - val_accuracy: 0.8718\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9785 - val_accuracy: 0.8718\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2288 - accuracy: 0.8830 - val_loss: 0.9776 - val_accuracy: 0.8718\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 0.9814 - val_accuracy: 0.8718\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9791 - val_accuracy: 0.8667\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9791 - val_accuracy: 0.8667\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.9804 - val_accuracy: 0.8718\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9791 - val_accuracy: 0.8718\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 0.9877 - val_accuracy: 0.8718\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 0.9818 - val_accuracy: 0.8667\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 0.9849 - val_accuracy: 0.8667\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 0.9825 - val_accuracy: 0.8718\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2275 - accuracy: 0.8830 - val_loss: 0.9841 - val_accuracy: 0.8718\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2269 - accuracy: 0.8874 - val_loss: 0.9856 - val_accuracy: 0.8667\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 0.9824 - val_accuracy: 0.8667\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 0.9831 - val_accuracy: 0.8667\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2310 - accuracy: 0.8786 - val_loss: 0.9905 - val_accuracy: 0.8718\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.9844 - val_accuracy: 0.8718\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2276 - accuracy: 0.8874 - val_loss: 0.9854 - val_accuracy: 0.8667\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9854 - val_accuracy: 0.8667\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2267 - accuracy: 0.8874 - val_loss: 0.9889 - val_accuracy: 0.8667\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.9975 - val_accuracy: 0.8667\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2265 - accuracy: 0.8874 - val_loss: 0.9926 - val_accuracy: 0.8667\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.9937 - val_accuracy: 0.8718\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2287 - accuracy: 0.8852 - val_loss: 0.9965 - val_accuracy: 0.8667\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 0.9918 - val_accuracy: 0.8667\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.9959 - val_accuracy: 0.8718\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 1.0038 - val_accuracy: 0.8718\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 0.9992 - val_accuracy: 0.8667\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.9958 - val_accuracy: 0.8667\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 0.9962 - val_accuracy: 0.8667\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 0.9991 - val_accuracy: 0.8667\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 1.0012 - val_accuracy: 0.8667\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 0.9974 - val_accuracy: 0.8667\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.9999 - val_accuracy: 0.8667\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 0.9980 - val_accuracy: 0.8667\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 0.9967 - val_accuracy: 0.8667\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2311 - accuracy: 0.8874 - val_loss: 0.9965 - val_accuracy: 0.8667\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2290 - accuracy: 0.8874 - val_loss: 0.9997 - val_accuracy: 0.8667\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 1.0048 - val_accuracy: 0.8667\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 1.0020 - val_accuracy: 0.8667\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 1.0008 - val_accuracy: 0.8667\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 1.0023 - val_accuracy: 0.8667\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 1.0040 - val_accuracy: 0.8667\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2266 - accuracy: 0.8874 - val_loss: 1.0043 - val_accuracy: 0.8667\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 1.0041 - val_accuracy: 0.8667\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2303 - accuracy: 0.8874 - val_loss: 1.0013 - val_accuracy: 0.8667\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2282 - accuracy: 0.8808 - val_loss: 1.0029 - val_accuracy: 0.8667\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.93 - 0s 105us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 1.0051 - val_accuracy: 0.8667\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2270 - accuracy: 0.8874 - val_loss: 1.0073 - val_accuracy: 0.8667\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 1.0063 - val_accuracy: 0.8667\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2283 - accuracy: 0.8852 - val_loss: 1.0107 - val_accuracy: 0.8667\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2295 - accuracy: 0.8874 - val_loss: 1.0059 - val_accuracy: 0.8667\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 1.0094 - val_accuracy: 0.8667\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 1.0071 - val_accuracy: 0.8667\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 1.0077 - val_accuracy: 0.8667\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 1.0122 - val_accuracy: 0.8667\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2306 - accuracy: 0.8874 - val_loss: 1.0123 - val_accuracy: 0.8667\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2312 - accuracy: 0.8874 - val_loss: 1.0129 - val_accuracy: 0.8667\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 1.0096 - val_accuracy: 0.8667\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 1.0118 - val_accuracy: 0.8667\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 1.0051 - val_accuracy: 0.8718\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2262 - accuracy: 0.8830 - val_loss: 1.0119 - val_accuracy: 0.8667\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2292 - accuracy: 0.8808 - val_loss: 1.0078 - val_accuracy: 0.8718\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2289 - accuracy: 0.8830 - val_loss: 1.0127 - val_accuracy: 0.8667\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2289 - accuracy: 0.8808 - val_loss: 1.0110 - val_accuracy: 0.8667\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 1.0103 - val_accuracy: 0.8667\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2315 - accuracy: 0.8874 - val_loss: 1.0190 - val_accuracy: 0.8667\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2283 - accuracy: 0.8874 - val_loss: 1.0153 - val_accuracy: 0.8667\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2291 - accuracy: 0.8786 - val_loss: 1.0142 - val_accuracy: 0.8667\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 1.0180 - val_accuracy: 0.8667\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2291 - accuracy: 0.8830 - val_loss: 1.0143 - val_accuracy: 0.8667\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2279 - accuracy: 0.8874 - val_loss: 1.0179 - val_accuracy: 0.8667\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 1.0159 - val_accuracy: 0.8667\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 1.0158 - val_accuracy: 0.8667\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2271 - accuracy: 0.8874 - val_loss: 1.0177 - val_accuracy: 0.8667\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 1.0203 - val_accuracy: 0.8667\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2304 - accuracy: 0.8720 - val_loss: 1.0211 - val_accuracy: 0.8667\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 1.0186 - val_accuracy: 0.8667\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 1.0137 - val_accuracy: 0.8718\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2271 - accuracy: 0.8852 - val_loss: 1.0180 - val_accuracy: 0.8667\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2284 - accuracy: 0.8874 - val_loss: 1.0207 - val_accuracy: 0.8667\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2280 - accuracy: 0.8874 - val_loss: 1.0166 - val_accuracy: 0.8667\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2278 - accuracy: 0.8874 - val_loss: 1.0201 - val_accuracy: 0.8667\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2296 - accuracy: 0.8830 - val_loss: 1.0208 - val_accuracy: 0.8667\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2295 - accuracy: 0.8830 - val_loss: 1.0192 - val_accuracy: 0.8667\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2292 - accuracy: 0.8830 - val_loss: 1.0230 - val_accuracy: 0.8667\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2262 - accuracy: 0.8874 - val_loss: 1.0207 - val_accuracy: 0.8667\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2286 - accuracy: 0.8874 - val_loss: 1.0233 - val_accuracy: 0.8667\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2272 - accuracy: 0.8874 - val_loss: 1.0248 - val_accuracy: 0.8667\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 1.0231 - val_accuracy: 0.8667\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2277 - accuracy: 0.8874 - val_loss: 1.0244 - val_accuracy: 0.8667\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2272 - accuracy: 0.8808 - val_loss: 1.0256 - val_accuracy: 0.8667\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2291 - accuracy: 0.8874 - val_loss: 1.0236 - val_accuracy: 0.8667\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2274 - accuracy: 0.8874 - val_loss: 1.0263 - val_accuracy: 0.8667\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2289 - accuracy: 0.8874 - val_loss: 1.0305 - val_accuracy: 0.8667\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2273 - accuracy: 0.8874 - val_loss: 1.0261 - val_accuracy: 0.8667\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2287 - accuracy: 0.8830 - val_loss: 1.0257 - val_accuracy: 0.8667\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2299 - accuracy: 0.8874 - val_loss: 1.0287 - val_accuracy: 0.8667\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2281 - accuracy: 0.8874 - val_loss: 1.0289 - val_accuracy: 0.8667\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2282 - accuracy: 0.8874 - val_loss: 1.0259 - val_accuracy: 0.8667\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2288 - accuracy: 0.8874 - val_loss: 1.0284 - val_accuracy: 0.8667\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2298 - accuracy: 0.8830 - val_loss: 1.0312 - val_accuracy: 0.8667\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2275 - accuracy: 0.8874 - val_loss: 1.0249 - val_accuracy: 0.8667\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2285 - accuracy: 0.8874 - val_loss: 1.0294 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=16, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.55%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9536570e-05, 9.9993050e-01, 3.1324188e-10],\n",
       "       [7.6166570e-09, 1.0000000e+00, 8.6620863e-13],\n",
       "       [8.4346040e-01, 1.5653962e-01, 4.0343653e-09],\n",
       "       [9.9951303e-01, 4.8694790e-04, 7.1619916e-10],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [9.9999833e-01, 1.6947181e-06, 4.4169048e-12],\n",
       "       [8.4346040e-01, 1.5653962e-01, 4.0343653e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.6357395e-01, 8.3642600e-01, 2.6581544e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.3267869e-11, 1.0000000e+00, 1.3901998e-10],\n",
       "       [8.6024284e-01, 1.3975719e-01, 3.1456690e-09],\n",
       "       [1.9058405e-17, 1.0000000e+00, 1.4747358e-27],\n",
       "       [9.5952930e-01, 4.0470740e-02, 1.8783513e-08],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [1.0000000e+00, 6.1502820e-11, 5.2761210e-18],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [4.6791017e-01, 5.3208980e-01, 1.9845647e-09],\n",
       "       [1.2602586e-06, 9.9999870e-01, 4.2419532e-10],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [1.2602586e-06, 9.9999870e-01, 4.2419532e-10],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [8.4346040e-01, 1.5653962e-01, 4.0343653e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [9.3926800e-08, 9.9999990e-01, 2.7540645e-09],\n",
       "       [9.5590836e-01, 4.4089620e-02, 2.0706302e-06],\n",
       "       [8.4346040e-01, 1.5653962e-01, 4.0343653e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [9.9799290e-01, 2.0070795e-03, 1.3324053e-07],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.0059919e-05, 9.9998000e-01, 3.0261463e-10],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [9.2444250e-01, 7.5557490e-02, 8.4556655e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.9058405e-17, 1.0000000e+00, 1.4747358e-27],\n",
       "       [1.5381558e-07, 9.9999990e-01, 2.0612630e-17],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [3.4617680e-05, 9.9996540e-01, 1.4335620e-08],\n",
       "       [9.3926800e-08, 9.9999990e-01, 2.7540645e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.0000000e+00, 6.1502820e-11, 5.2761210e-18],\n",
       "       [9.9694866e-01, 3.0512153e-03, 8.1681150e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [1.6357395e-01, 8.3642600e-01, 2.6581544e-09],\n",
       "       [7.6166570e-09, 1.0000000e+00, 8.6620863e-13],\n",
       "       [9.3926800e-08, 9.9999990e-01, 2.7540645e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.7670164e-01, 8.2329834e-01, 9.8231140e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [9.9999833e-01, 1.6947181e-06, 4.4169048e-12],\n",
       "       [1.8720627e-07, 9.9999976e-01, 6.9246170e-12],\n",
       "       [9.9640370e-01, 3.5963630e-03, 8.4269370e-12],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [9.2444250e-01, 7.5557490e-02, 8.4556655e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.0000000e+00, 6.1502820e-11, 5.2761210e-18],\n",
       "       [9.9999820e-01, 1.7642170e-06, 6.4009210e-11],\n",
       "       [1.2602586e-06, 9.9999870e-01, 4.2419532e-10],\n",
       "       [9.9999820e-01, 1.7565498e-06, 3.3665784e-13],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [9.9972400e-01, 2.7606788e-04, 4.8547570e-10],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.6166570e-09, 1.0000000e+00, 8.6620863e-13],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [3.4617680e-05, 9.9996540e-01, 1.4335620e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.1125399e-29, 1.0000000e+00, 6.1404340e-23],\n",
       "       [9.9998870e-01, 1.1347268e-05, 5.8761086e-12],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.2602586e-06, 9.9999870e-01, 4.2419532e-10],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.6166570e-09, 1.0000000e+00, 8.6620863e-13],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [8.4277557e-04, 9.9915720e-01, 3.2475516e-09],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [9.9999833e-01, 1.6947181e-06, 4.4169048e-12],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.3267869e-11, 1.0000000e+00, 1.3901998e-10],\n",
       "       [9.9999833e-01, 1.6947181e-06, 4.4169048e-12],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.6357395e-01, 8.3642600e-01, 2.6581544e-09],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.5381558e-07, 9.9999990e-01, 2.0612630e-17],\n",
       "       [9.9999976e-01, 2.4175608e-07, 3.8639050e-12],\n",
       "       [8.4277557e-04, 9.9915720e-01, 3.2475516e-09],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [6.8787000e-28, 1.0000000e+00, 7.4110480e-22],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [4.6791017e-01, 5.3208980e-01, 1.9845647e-09],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [1.4796349e-09, 1.0000000e+00, 4.4470464e-24],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [8.4346040e-01, 1.5653962e-01, 4.0343653e-09],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.9058405e-17, 1.0000000e+00, 1.4747358e-27],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [6.9536570e-05, 9.9993050e-01, 3.1324188e-10],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [1.8720627e-07, 9.9999976e-01, 6.9246170e-12],\n",
       "       [8.4277557e-04, 9.9915720e-01, 3.2475516e-09],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [2.1125399e-29, 1.0000000e+00, 6.1404340e-23],\n",
       "       [7.6166570e-09, 1.0000000e+00, 8.6620863e-13],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [9.5952930e-01, 4.0470740e-02, 1.8783513e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [4.7626615e-01, 5.2373374e-01, 1.3126197e-07],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [3.4117250e-01, 6.5882700e-01, 4.5945697e-07],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [1.2602586e-06, 9.9999870e-01, 4.2419532e-10],\n",
       "       [7.1770490e-01, 2.8229514e-01, 1.4094924e-08],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [3.4617680e-05, 9.9996540e-01, 1.4335620e-08],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [1.0876926e-34, 1.0000000e+00, 5.8188124e-24],\n",
       "       [6.3022670e-01, 3.6977336e-01, 7.8539990e-09],\n",
       "       [1.1604803e-08, 1.5658442e-08, 1.0000000e+00],\n",
       "       [5.4771936e-01, 4.5228067e-01, 1.7613745e-08],\n",
       "       [6.9536570e-05, 9.9993050e-01, 3.1324188e-10],\n",
       "       [2.7132139e-09, 6.6563160e-09, 1.0000000e+00],\n",
       "       [9.9566840e-12, 1.0000000e+00, 7.4412880e-26],\n",
       "       [9.9999976e-01, 1.9581888e-07, 1.0010013e-12]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393688362919131"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393688362919131"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS209     2\n",
       "1      NRS255     1\n",
       "2      NRS119     0\n",
       "3      NRS071     0\n",
       "4      NRS002     0\n",
       "..        ...   ...\n",
       "190  CFBRSa30     0\n",
       "191    NRS383     1\n",
       "192    NRS110     2\n",
       "193    NRS209     2\n",
       "194     NY439     0\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 295us/step - loss: 1.0143 - accuracy: 0.4393 - val_loss: 0.8758 - val_accuracy: 0.7231\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.8130 - accuracy: 0.7108 - val_loss: 0.7375 - val_accuracy: 0.6923\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.6968 - accuracy: 0.7263 - val_loss: 0.6457 - val_accuracy: 0.7231\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.6178 - accuracy: 0.7395 - val_loss: 0.5821 - val_accuracy: 0.7744\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.5638 - accuracy: 0.7881 - val_loss: 0.5373 - val_accuracy: 0.7795\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.5246 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7641\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.4959 - accuracy: 0.8190 - val_loss: 0.4817 - val_accuracy: 0.7949\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.4706 - accuracy: 0.8057 - val_loss: 0.4631 - val_accuracy: 0.7795\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.4528 - accuracy: 0.8190 - val_loss: 0.4450 - val_accuracy: 0.7949\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.4383 - accuracy: 0.8300 - val_loss: 0.4312 - val_accuracy: 0.8051\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.4288 - accuracy: 0.8256 - val_loss: 0.4208 - val_accuracy: 0.8000\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.4158 - accuracy: 0.8344 - val_loss: 0.4134 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.4083 - accuracy: 0.8300 - val_loss: 0.4064 - val_accuracy: 0.8000\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.3992 - accuracy: 0.8344 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.3927 - accuracy: 0.8300 - val_loss: 0.3927 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.3877 - accuracy: 0.8389 - val_loss: 0.3885 - val_accuracy: 0.8051\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.3809 - accuracy: 0.8344 - val_loss: 0.3822 - val_accuracy: 0.7949\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.3787 - accuracy: 0.8322 - val_loss: 0.3782 - val_accuracy: 0.7949\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.3737 - accuracy: 0.8300 - val_loss: 0.3753 - val_accuracy: 0.7949\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.3684 - accuracy: 0.8278 - val_loss: 0.3743 - val_accuracy: 0.7949\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.3647 - accuracy: 0.8322 - val_loss: 0.3707 - val_accuracy: 0.7949\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.3667 - accuracy: 0.8256 - val_loss: 0.3677 - val_accuracy: 0.7897\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3683 - accuracy: 0.8344 - val_loss: 0.3668 - val_accuracy: 0.8154\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.3643 - accuracy: 0.8190 - val_loss: 0.3642 - val_accuracy: 0.8051\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.3535 - accuracy: 0.8433 - val_loss: 0.3579 - val_accuracy: 0.8154\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.3495 - accuracy: 0.8455 - val_loss: 0.3597 - val_accuracy: 0.7897\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.3491 - accuracy: 0.8344 - val_loss: 0.3583 - val_accuracy: 0.7949\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.3452 - accuracy: 0.8366 - val_loss: 0.3568 - val_accuracy: 0.8205\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.3456 - accuracy: 0.8389 - val_loss: 0.3578 - val_accuracy: 0.7897\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.3486 - accuracy: 0.8278 - val_loss: 0.3551 - val_accuracy: 0.8205\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 194us/step - loss: 0.3408 - accuracy: 0.8344 - val_loss: 0.3535 - val_accuracy: 0.8205\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.3389 - accuracy: 0.8366 - val_loss: 0.3534 - val_accuracy: 0.8205\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.3382 - accuracy: 0.8389 - val_loss: 0.3543 - val_accuracy: 0.7949\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.3378 - accuracy: 0.8168 - val_loss: 0.3552 - val_accuracy: 0.7949\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.3394 - accuracy: 0.8300 - val_loss: 0.3580 - val_accuracy: 0.7846\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.3374 - accuracy: 0.8322 - val_loss: 0.3536 - val_accuracy: 0.8205\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.3350 - accuracy: 0.8344 - val_loss: 0.3526 - val_accuracy: 0.7949\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.3313 - accuracy: 0.8300 - val_loss: 0.3529 - val_accuracy: 0.7949\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.3287 - accuracy: 0.8389 - val_loss: 0.3519 - val_accuracy: 0.8205\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.3289 - accuracy: 0.8455 - val_loss: 0.3500 - val_accuracy: 0.8205\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.3283 - accuracy: 0.8455 - val_loss: 0.3519 - val_accuracy: 0.7949\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 238us/step - loss: 0.3332 - accuracy: 0.8389 - val_loss: 0.3490 - val_accuracy: 0.8205\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 249us/step - loss: 0.3260 - accuracy: 0.8477 - val_loss: 0.3464 - val_accuracy: 0.8256\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.3249 - accuracy: 0.8477 - val_loss: 0.3460 - val_accuracy: 0.8205\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.3239 - accuracy: 0.8433 - val_loss: 0.3448 - val_accuracy: 0.8205\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.3242 - accuracy: 0.8477 - val_loss: 0.3438 - val_accuracy: 0.8205\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.3232 - accuracy: 0.8477 - val_loss: 0.3408 - val_accuracy: 0.8205\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.3192 - accuracy: 0.8477 - val_loss: 0.3402 - val_accuracy: 0.8205\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.3207 - accuracy: 0.8433 - val_loss: 0.3380 - val_accuracy: 0.8205\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.3184 - accuracy: 0.8411 - val_loss: 0.3389 - val_accuracy: 0.8205\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.3163 - accuracy: 0.8411 - val_loss: 0.3382 - val_accuracy: 0.8205\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.3159 - accuracy: 0.8499 - val_loss: 0.3361 - val_accuracy: 0.8205\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.3172 - accuracy: 0.8411 - val_loss: 0.3361 - val_accuracy: 0.8205\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.3140 - accuracy: 0.8433 - val_loss: 0.3341 - val_accuracy: 0.8205\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.3156 - accuracy: 0.8455 - val_loss: 0.3381 - val_accuracy: 0.8256\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.3133 - accuracy: 0.8433 - val_loss: 0.3358 - val_accuracy: 0.8205\n",
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 152us/step - loss: 0.3124 - accuracy: 0.8433 - val_loss: 0.3363 - val_accuracy: 0.8256\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.3136 - accuracy: 0.8565 - val_loss: 0.3337 - val_accuracy: 0.8256\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.3123 - accuracy: 0.8389 - val_loss: 0.3326 - val_accuracy: 0.8256\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.3121 - accuracy: 0.8477 - val_loss: 0.3335 - val_accuracy: 0.8256\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.3091 - accuracy: 0.8455 - val_loss: 0.3320 - val_accuracy: 0.8205\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.3087 - accuracy: 0.8521 - val_loss: 0.3329 - val_accuracy: 0.8256\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.3071 - accuracy: 0.8521 - val_loss: 0.3312 - val_accuracy: 0.8205\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.3056 - accuracy: 0.8543 - val_loss: 0.3302 - val_accuracy: 0.8256\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.3059 - accuracy: 0.8433 - val_loss: 0.3324 - val_accuracy: 0.8256\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.3084 - accuracy: 0.8455 - val_loss: 0.3312 - val_accuracy: 0.8256\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.3044 - accuracy: 0.8499 - val_loss: 0.3332 - val_accuracy: 0.8205\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.3063 - accuracy: 0.8521 - val_loss: 0.3312 - val_accuracy: 0.8256\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 220us/step - loss: 0.3108 - accuracy: 0.8389 - val_loss: 0.3292 - val_accuracy: 0.8256\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 158us/step - loss: 0.3083 - accuracy: 0.8543 - val_loss: 0.3270 - val_accuracy: 0.8205\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.3046 - accuracy: 0.8389 - val_loss: 0.3289 - val_accuracy: 0.8256\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.3020 - accuracy: 0.8521 - val_loss: 0.3313 - val_accuracy: 0.8205\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.3021 - accuracy: 0.8477 - val_loss: 0.3284 - val_accuracy: 0.8256\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.3104 - accuracy: 0.8477 - val_loss: 0.3282 - val_accuracy: 0.8564\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.3028 - accuracy: 0.8565 - val_loss: 0.3247 - val_accuracy: 0.8256\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.3001 - accuracy: 0.8477 - val_loss: 0.3255 - val_accuracy: 0.8256\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.3031 - accuracy: 0.8499 - val_loss: 0.3272 - val_accuracy: 0.8256\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.3052 - accuracy: 0.8543 - val_loss: 0.3270 - val_accuracy: 0.8256\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2974 - accuracy: 0.8565 - val_loss: 0.3251 - val_accuracy: 0.8256\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2976 - accuracy: 0.8521 - val_loss: 0.3234 - val_accuracy: 0.8256\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2974 - accuracy: 0.8521 - val_loss: 0.3232 - val_accuracy: 0.8256\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2976 - accuracy: 0.8477 - val_loss: 0.3241 - val_accuracy: 0.8256\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.3030 - accuracy: 0.8499 - val_loss: 0.3281 - val_accuracy: 0.8256\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2988 - accuracy: 0.8477 - val_loss: 0.3225 - val_accuracy: 0.8256\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2950 - accuracy: 0.8499 - val_loss: 0.3192 - val_accuracy: 0.8256\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.2951 - accuracy: 0.8587 - val_loss: 0.3190 - val_accuracy: 0.8256\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2943 - accuracy: 0.8521 - val_loss: 0.3204 - val_accuracy: 0.8256\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2941 - accuracy: 0.8587 - val_loss: 0.3209 - val_accuracy: 0.8256\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2956 - accuracy: 0.8455 - val_loss: 0.3216 - val_accuracy: 0.8256\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2922 - accuracy: 0.8521 - val_loss: 0.3199 - val_accuracy: 0.8256\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2922 - accuracy: 0.8587 - val_loss: 0.3205 - val_accuracy: 0.8256\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2950 - accuracy: 0.8477 - val_loss: 0.3213 - val_accuracy: 0.8256\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2911 - accuracy: 0.8543 - val_loss: 0.3186 - val_accuracy: 0.8256\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2920 - accuracy: 0.8587 - val_loss: 0.3192 - val_accuracy: 0.8256\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2924 - accuracy: 0.8543 - val_loss: 0.3163 - val_accuracy: 0.8256\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2921 - accuracy: 0.8565 - val_loss: 0.3149 - val_accuracy: 0.8256\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2915 - accuracy: 0.8609 - val_loss: 0.3212 - val_accuracy: 0.8513\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2882 - accuracy: 0.8653 - val_loss: 0.3141 - val_accuracy: 0.8256\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2894 - accuracy: 0.8587 - val_loss: 0.3139 - val_accuracy: 0.8256\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.90 - 0s 84us/step - loss: 0.2892 - accuracy: 0.8587 - val_loss: 0.3127 - val_accuracy: 0.8256\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2870 - accuracy: 0.8433 - val_loss: 0.3193 - val_accuracy: 0.8256\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2895 - accuracy: 0.8543 - val_loss: 0.3140 - val_accuracy: 0.8256\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2911 - accuracy: 0.8389 - val_loss: 0.3135 - val_accuracy: 0.8256\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2865 - accuracy: 0.8477 - val_loss: 0.3145 - val_accuracy: 0.8256\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2851 - accuracy: 0.8587 - val_loss: 0.3145 - val_accuracy: 0.8256\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2860 - accuracy: 0.8521 - val_loss: 0.3170 - val_accuracy: 0.8513\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2890 - accuracy: 0.8521 - val_loss: 0.3173 - val_accuracy: 0.8513\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2914 - accuracy: 0.8587 - val_loss: 0.3168 - val_accuracy: 0.8256\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 196us/step - loss: 0.2851 - accuracy: 0.8587 - val_loss: 0.3130 - val_accuracy: 0.8359\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2877 - accuracy: 0.8477 - val_loss: 0.3115 - val_accuracy: 0.8308\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2858 - accuracy: 0.8587 - val_loss: 0.3153 - val_accuracy: 0.8256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.2861 - accuracy: 0.8521 - val_loss: 0.3144 - val_accuracy: 0.8513\n",
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2846 - accuracy: 0.8631 - val_loss: 0.3117 - val_accuracy: 0.8308\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2831 - accuracy: 0.8499 - val_loss: 0.3092 - val_accuracy: 0.8256\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2825 - accuracy: 0.8587 - val_loss: 0.3096 - val_accuracy: 0.8256\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.2812 - accuracy: 0.8653 - val_loss: 0.3101 - val_accuracy: 0.8256\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2798 - accuracy: 0.8675 - val_loss: 0.3094 - val_accuracy: 0.8308\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2813 - accuracy: 0.8587 - val_loss: 0.3089 - val_accuracy: 0.8256\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2817 - accuracy: 0.8631 - val_loss: 0.3089 - val_accuracy: 0.8256\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2792 - accuracy: 0.8609 - val_loss: 0.3076 - val_accuracy: 0.8256\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2823 - accuracy: 0.8631 - val_loss: 0.3074 - val_accuracy: 0.8308\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2974 - accuracy: 0.8565 - val_loss: 0.3129 - val_accuracy: 0.8769\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2937 - accuracy: 0.8477 - val_loss: 0.3047 - val_accuracy: 0.8308\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2783 - accuracy: 0.8587 - val_loss: 0.3047 - val_accuracy: 0.8564\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2802 - accuracy: 0.8609 - val_loss: 0.3046 - val_accuracy: 0.8308\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2774 - accuracy: 0.8499 - val_loss: 0.3074 - val_accuracy: 0.8256\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2771 - accuracy: 0.8587 - val_loss: 0.3042 - val_accuracy: 0.8256\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2803 - accuracy: 0.8609 - val_loss: 0.3044 - val_accuracy: 0.8308\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2790 - accuracy: 0.8653 - val_loss: 0.3018 - val_accuracy: 0.8256\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2810 - accuracy: 0.8609 - val_loss: 0.3063 - val_accuracy: 0.8564\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2781 - accuracy: 0.8720 - val_loss: 0.3066 - val_accuracy: 0.8308\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2760 - accuracy: 0.8565 - val_loss: 0.3050 - val_accuracy: 0.8615\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2799 - accuracy: 0.8587 - val_loss: 0.3176 - val_accuracy: 0.8051\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2809 - accuracy: 0.8609 - val_loss: 0.3060 - val_accuracy: 0.8667\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2746 - accuracy: 0.8653 - val_loss: 0.3022 - val_accuracy: 0.8308\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2809 - accuracy: 0.8565 - val_loss: 0.3016 - val_accuracy: 0.8256\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2822 - accuracy: 0.8543 - val_loss: 0.3020 - val_accuracy: 0.8513\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2764 - accuracy: 0.8587 - val_loss: 0.3016 - val_accuracy: 0.8308\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2728 - accuracy: 0.8675 - val_loss: 0.3049 - val_accuracy: 0.8615\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2740 - accuracy: 0.8631 - val_loss: 0.3006 - val_accuracy: 0.8615\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2840 - accuracy: 0.8587 - val_loss: 0.3047 - val_accuracy: 0.8308\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2726 - accuracy: 0.8609 - val_loss: 0.3019 - val_accuracy: 0.8667\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2751 - accuracy: 0.8565 - val_loss: 0.2993 - val_accuracy: 0.8564\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2711 - accuracy: 0.8653 - val_loss: 0.3028 - val_accuracy: 0.8667\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2735 - accuracy: 0.8653 - val_loss: 0.3000 - val_accuracy: 0.8564\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2752 - accuracy: 0.8565 - val_loss: 0.2987 - val_accuracy: 0.8615\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2739 - accuracy: 0.8565 - val_loss: 0.3016 - val_accuracy: 0.8564\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2712 - accuracy: 0.8631 - val_loss: 0.3032 - val_accuracy: 0.8564\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2710 - accuracy: 0.8698 - val_loss: 0.3034 - val_accuracy: 0.8308\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2703 - accuracy: 0.8609 - val_loss: 0.3017 - val_accuracy: 0.8308\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2697 - accuracy: 0.8653 - val_loss: 0.3038 - val_accuracy: 0.8564\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2727 - accuracy: 0.8653 - val_loss: 0.3043 - val_accuracy: 0.8564\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2687 - accuracy: 0.8698 - val_loss: 0.3021 - val_accuracy: 0.8308\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2697 - accuracy: 0.8631 - val_loss: 0.3031 - val_accuracy: 0.8359\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2733 - accuracy: 0.8631 - val_loss: 0.3024 - val_accuracy: 0.8615\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2698 - accuracy: 0.8675 - val_loss: 0.2976 - val_accuracy: 0.8256\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2684 - accuracy: 0.8609 - val_loss: 0.2992 - val_accuracy: 0.8513\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2724 - accuracy: 0.8631 - val_loss: 0.2988 - val_accuracy: 0.8513\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2695 - accuracy: 0.8653 - val_loss: 0.2976 - val_accuracy: 0.8308\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2687 - accuracy: 0.8698 - val_loss: 0.2986 - val_accuracy: 0.8513\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2715 - accuracy: 0.8653 - val_loss: 0.3001 - val_accuracy: 0.8564\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2718 - accuracy: 0.8698 - val_loss: 0.3020 - val_accuracy: 0.8718\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2664 - accuracy: 0.8675 - val_loss: 0.2956 - val_accuracy: 0.8308\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2766 - accuracy: 0.8587 - val_loss: 0.3022 - val_accuracy: 0.8564\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2685 - accuracy: 0.8653 - val_loss: 0.2940 - val_accuracy: 0.8564\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2666 - accuracy: 0.8764 - val_loss: 0.2964 - val_accuracy: 0.8615\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2779 - accuracy: 0.8300 - val_loss: 0.2962 - val_accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2704 - accuracy: 0.8675 - val_loss: 0.2971 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2699 - accuracy: 0.8653 - val_loss: 0.2950 - val_accuracy: 0.8256\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.2800 - accuracy: 0.8587 - val_loss: 0.3013 - val_accuracy: 0.8615\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2663 - accuracy: 0.8653 - val_loss: 0.2954 - val_accuracy: 0.8308\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2726 - accuracy: 0.8631 - val_loss: 0.2984 - val_accuracy: 0.8615\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2663 - accuracy: 0.8742 - val_loss: 0.2950 - val_accuracy: 0.8615\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2717 - accuracy: 0.8609 - val_loss: 0.2955 - val_accuracy: 0.8615\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2671 - accuracy: 0.8653 - val_loss: 0.2931 - val_accuracy: 0.8564\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2692 - accuracy: 0.8609 - val_loss: 0.2915 - val_accuracy: 0.8513\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2654 - accuracy: 0.8720 - val_loss: 0.2924 - val_accuracy: 0.8513\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2692 - accuracy: 0.8609 - val_loss: 0.2949 - val_accuracy: 0.8513\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2639 - accuracy: 0.8786 - val_loss: 0.2979 - val_accuracy: 0.8615\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2635 - accuracy: 0.8742 - val_loss: 0.2936 - val_accuracy: 0.8615\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2651 - accuracy: 0.8675 - val_loss: 0.2921 - val_accuracy: 0.8615\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2638 - accuracy: 0.8698 - val_loss: 0.3013 - val_accuracy: 0.8667\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2667 - accuracy: 0.8675 - val_loss: 0.2926 - val_accuracy: 0.8513\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2703 - accuracy: 0.8675 - val_loss: 0.2891 - val_accuracy: 0.8513\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2650 - accuracy: 0.8720 - val_loss: 0.2904 - val_accuracy: 0.8615\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2653 - accuracy: 0.8675 - val_loss: 0.3005 - val_accuracy: 0.8718\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2693 - accuracy: 0.8698 - val_loss: 0.2894 - val_accuracy: 0.8615\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2615 - accuracy: 0.8698 - val_loss: 0.2902 - val_accuracy: 0.8615\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.2668 - accuracy: 0.8609 - val_loss: 0.2904 - val_accuracy: 0.8564\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2648 - accuracy: 0.8698 - val_loss: 0.2908 - val_accuracy: 0.8513\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2649 - accuracy: 0.8653 - val_loss: 0.2940 - val_accuracy: 0.8513\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2613 - accuracy: 0.8720 - val_loss: 0.2917 - val_accuracy: 0.8615\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2617 - accuracy: 0.8720 - val_loss: 0.2922 - val_accuracy: 0.8615\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2621 - accuracy: 0.8675 - val_loss: 0.2897 - val_accuracy: 0.8615\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2627 - accuracy: 0.8720 - val_loss: 0.2883 - val_accuracy: 0.8513\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2610 - accuracy: 0.8675 - val_loss: 0.2881 - val_accuracy: 0.8615\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2608 - accuracy: 0.8698 - val_loss: 0.2878 - val_accuracy: 0.8513\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2616 - accuracy: 0.8698 - val_loss: 0.2917 - val_accuracy: 0.8615\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2584 - accuracy: 0.8764 - val_loss: 0.2882 - val_accuracy: 0.8513\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2563 - accuracy: 0.8764 - val_loss: 0.2908 - val_accuracy: 0.8769\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2693 - accuracy: 0.8675 - val_loss: 0.2937 - val_accuracy: 0.8256\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2679 - accuracy: 0.8653 - val_loss: 0.2939 - val_accuracy: 0.8769\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2601 - accuracy: 0.8675 - val_loss: 0.2886 - val_accuracy: 0.8564\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2620 - accuracy: 0.8698 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2571 - accuracy: 0.8742 - val_loss: 0.2872 - val_accuracy: 0.8513\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2672 - accuracy: 0.8609 - val_loss: 0.3057 - val_accuracy: 0.8615\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2638 - accuracy: 0.8609 - val_loss: 0.2941 - val_accuracy: 0.8308\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2680 - accuracy: 0.8653 - val_loss: 0.2926 - val_accuracy: 0.8667\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2607 - accuracy: 0.8786 - val_loss: 0.2877 - val_accuracy: 0.8667\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2624 - accuracy: 0.8720 - val_loss: 0.2855 - val_accuracy: 0.8615\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2661 - accuracy: 0.8653 - val_loss: 0.2901 - val_accuracy: 0.8769\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2554 - accuracy: 0.8764 - val_loss: 0.2878 - val_accuracy: 0.8615\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2582 - accuracy: 0.8786 - val_loss: 0.2879 - val_accuracy: 0.8615\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2565 - accuracy: 0.8764 - val_loss: 0.2864 - val_accuracy: 0.8615\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2657 - accuracy: 0.8653 - val_loss: 0.2878 - val_accuracy: 0.8513\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2546 - accuracy: 0.8742 - val_loss: 0.2940 - val_accuracy: 0.8615\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2566 - accuracy: 0.8742 - val_loss: 0.2877 - val_accuracy: 0.8513\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 59us/step - loss: 0.2657 - accuracy: 0.8720 - val_loss: 0.2882 - val_accuracy: 0.8615\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 61us/step - loss: 0.2588 - accuracy: 0.8764 - val_loss: 0.2906 - val_accuracy: 0.8769\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2649 - accuracy: 0.8720 - val_loss: 0.2849 - val_accuracy: 0.8513\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2564 - accuracy: 0.8764 - val_loss: 0.2931 - val_accuracy: 0.8769\n",
      "Epoch 222/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2653 - accuracy: 0.8565 - val_loss: 0.2891 - val_accuracy: 0.8256\n",
      "Epoch 223/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2687 - accuracy: 0.8720 - val_loss: 0.2889 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2636 - accuracy: 0.8698 - val_loss: 0.2911 - val_accuracy: 0.8615\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2623 - accuracy: 0.8698 - val_loss: 0.2870 - val_accuracy: 0.8615\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2570 - accuracy: 0.8764 - val_loss: 0.2868 - val_accuracy: 0.8615\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2579 - accuracy: 0.8786 - val_loss: 0.2895 - val_accuracy: 0.8513\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2554 - accuracy: 0.8764 - val_loss: 0.2892 - val_accuracy: 0.8615\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2547 - accuracy: 0.8786 - val_loss: 0.2872 - val_accuracy: 0.8615\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2629 - accuracy: 0.8742 - val_loss: 0.2873 - val_accuracy: 0.8513\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2572 - accuracy: 0.8698 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2652 - accuracy: 0.8366 - val_loss: 0.2833 - val_accuracy: 0.8513\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2571 - accuracy: 0.8675 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2527 - accuracy: 0.8786 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2543 - accuracy: 0.8808 - val_loss: 0.2838 - val_accuracy: 0.8769\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2577 - accuracy: 0.8764 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2545 - accuracy: 0.8786 - val_loss: 0.2825 - val_accuracy: 0.8769\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2546 - accuracy: 0.8742 - val_loss: 0.2828 - val_accuracy: 0.8769\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2583 - accuracy: 0.8764 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 227us/step - loss: 0.2620 - accuracy: 0.8587 - val_loss: 0.2860 - val_accuracy: 0.8513\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 228us/step - loss: 0.2658 - accuracy: 0.8653 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2585 - accuracy: 0.8786 - val_loss: 0.2817 - val_accuracy: 0.8513\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2565 - accuracy: 0.8698 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2596 - accuracy: 0.8698 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2550 - accuracy: 0.8653 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2527 - accuracy: 0.8808 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2525 - accuracy: 0.8808 - val_loss: 0.2833 - val_accuracy: 0.8769\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2543 - accuracy: 0.8764 - val_loss: 0.2806 - val_accuracy: 0.8769\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2650 - accuracy: 0.8764 - val_loss: 0.2891 - val_accuracy: 0.8769\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2662 - accuracy: 0.8631 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2549 - accuracy: 0.8698 - val_loss: 0.2800 - val_accuracy: 0.8769\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2529 - accuracy: 0.8764 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2510 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8769\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2543 - accuracy: 0.8786 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2535 - accuracy: 0.8786 - val_loss: 0.2833 - val_accuracy: 0.8769\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2541 - accuracy: 0.8830 - val_loss: 0.2810 - val_accuracy: 0.8769\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2570 - accuracy: 0.8830 - val_loss: 0.2805 - val_accuracy: 0.8769\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2514 - accuracy: 0.8830 - val_loss: 0.2873 - val_accuracy: 0.8769\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2532 - accuracy: 0.8675 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2519 - accuracy: 0.8874 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2514 - accuracy: 0.8786 - val_loss: 0.2751 - val_accuracy: 0.8769\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2761 - accuracy: 0.8808 - val_loss: 0.2923 - val_accuracy: 0.8821\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2647 - accuracy: 0.8499 - val_loss: 0.2778 - val_accuracy: 0.8718\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2559 - accuracy: 0.8786 - val_loss: 0.2812 - val_accuracy: 0.8821\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2571 - accuracy: 0.8720 - val_loss: 0.2809 - val_accuracy: 0.8769\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2507 - accuracy: 0.8786 - val_loss: 0.2826 - val_accuracy: 0.8769\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2532 - accuracy: 0.8764 - val_loss: 0.2797 - val_accuracy: 0.8667\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2503 - accuracy: 0.8808 - val_loss: 0.2788 - val_accuracy: 0.8769\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2499 - accuracy: 0.8808 - val_loss: 0.2779 - val_accuracy: 0.8769\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2499 - accuracy: 0.8808 - val_loss: 0.2781 - val_accuracy: 0.8769\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2492 - accuracy: 0.8808 - val_loss: 0.2774 - val_accuracy: 0.8769\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2545 - accuracy: 0.8742 - val_loss: 0.2816 - val_accuracy: 0.8769\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2522 - accuracy: 0.8830 - val_loss: 0.2803 - val_accuracy: 0.8769\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2570 - accuracy: 0.8698 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2685 - accuracy: 0.8764 - val_loss: 0.2857 - val_accuracy: 0.8769\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2559 - accuracy: 0.8830 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2510 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2519 - accuracy: 0.8830 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2492 - accuracy: 0.8786 - val_loss: 0.2764 - val_accuracy: 0.8769\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2498 - accuracy: 0.8698 - val_loss: 0.2821 - val_accuracy: 0.8769\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2508 - accuracy: 0.8830 - val_loss: 0.2783 - val_accuracy: 0.8769\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2479 - accuracy: 0.8830 - val_loss: 0.2748 - val_accuracy: 0.8769\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2486 - accuracy: 0.8830 - val_loss: 0.2797 - val_accuracy: 0.8769\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2513 - accuracy: 0.8852 - val_loss: 0.2785 - val_accuracy: 0.8769\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 57us/step - loss: 0.2490 - accuracy: 0.8830 - val_loss: 0.2757 - val_accuracy: 0.8769\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2522 - accuracy: 0.8830 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2525 - accuracy: 0.8698 - val_loss: 0.2788 - val_accuracy: 0.8769\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2532 - accuracy: 0.8830 - val_loss: 0.2757 - val_accuracy: 0.8667\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2536 - accuracy: 0.8698 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2495 - accuracy: 0.8786 - val_loss: 0.2757 - val_accuracy: 0.8769\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2476 - accuracy: 0.8830 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 62us/step - loss: 0.2513 - accuracy: 0.8720 - val_loss: 0.2774 - val_accuracy: 0.8667\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2504 - accuracy: 0.8764 - val_loss: 0.2822 - val_accuracy: 0.8667\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2503 - accuracy: 0.8808 - val_loss: 0.2781 - val_accuracy: 0.8769\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 60us/step - loss: 0.2496 - accuracy: 0.8698 - val_loss: 0.2794 - val_accuracy: 0.8513\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 0.2802 - val_accuracy: 0.8769\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2509 - accuracy: 0.8830 - val_loss: 0.2828 - val_accuracy: 0.8564\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 52us/step - loss: 0.2539 - accuracy: 0.8808 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2473 - accuracy: 0.8830 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2551 - accuracy: 0.8720 - val_loss: 0.2835 - val_accuracy: 0.8769\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 56us/step - loss: 0.2494 - accuracy: 0.8764 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 58us/step - loss: 0.2488 - accuracy: 0.8830 - val_loss: 0.2772 - val_accuracy: 0.8769\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2558 - accuracy: 0.8808 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.2658 - accuracy: 0.8411 - val_loss: 0.2778 - val_accuracy: 0.8667\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2481 - accuracy: 0.8764 - val_loss: 0.2798 - val_accuracy: 0.8769\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 53us/step - loss: 0.2478 - accuracy: 0.8808 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.2477 - accuracy: 0.8786 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2469 - accuracy: 0.8830 - val_loss: 0.2731 - val_accuracy: 0.8769\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 54us/step - loss: 0.2539 - accuracy: 0.8698 - val_loss: 0.2794 - val_accuracy: 0.8769\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 55us/step - loss: 0.2664 - accuracy: 0.8433 - val_loss: 0.2751 - val_accuracy: 0.8667\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2498 - accuracy: 0.8742 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2474 - accuracy: 0.8786 - val_loss: 0.2778 - val_accuracy: 0.8769\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2461 - accuracy: 0.8874 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2465 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2461 - accuracy: 0.8786 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2456 - accuracy: 0.8808 - val_loss: 0.2777 - val_accuracy: 0.8769\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2488 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8769\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2483 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8769\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2452 - accuracy: 0.8808 - val_loss: 0.2753 - val_accuracy: 0.8769\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2453 - accuracy: 0.8830 - val_loss: 0.2725 - val_accuracy: 0.8769\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2444 - accuracy: 0.8830 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2463 - accuracy: 0.8808 - val_loss: 0.2745 - val_accuracy: 0.8821\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2456 - accuracy: 0.8808 - val_loss: 0.2753 - val_accuracy: 0.8769\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2475 - accuracy: 0.8830 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 64us/step - loss: 0.2495 - accuracy: 0.8742 - val_loss: 0.2769 - val_accuracy: 0.8769\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2464 - accuracy: 0.8830 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2667 - accuracy: 0.8742 - val_loss: 0.2771 - val_accuracy: 0.8769\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2445 - accuracy: 0.8830 - val_loss: 0.2748 - val_accuracy: 0.8769\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2491 - accuracy: 0.8808 - val_loss: 0.2785 - val_accuracy: 0.8769\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.2725 - val_accuracy: 0.8769\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2480 - accuracy: 0.8786 - val_loss: 0.2745 - val_accuracy: 0.8821\n",
      "Epoch 332/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2470 - accuracy: 0.8808 - val_loss: 0.2727 - val_accuracy: 0.8769\n",
      "Epoch 333/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2434 - accuracy: 0.8830 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2486 - accuracy: 0.8808 - val_loss: 0.2725 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2495 - accuracy: 0.8786 - val_loss: 0.2769 - val_accuracy: 0.8769\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2452 - accuracy: 0.8786 - val_loss: 0.2737 - val_accuracy: 0.8821\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2457 - accuracy: 0.8808 - val_loss: 0.2736 - val_accuracy: 0.8769\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2583 - accuracy: 0.8653 - val_loss: 0.2825 - val_accuracy: 0.8769\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2518 - accuracy: 0.8808 - val_loss: 0.2750 - val_accuracy: 0.8769\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2479 - accuracy: 0.8830 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2457 - accuracy: 0.8720 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2557 - accuracy: 0.8455 - val_loss: 0.2753 - val_accuracy: 0.8769\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2453 - accuracy: 0.8742 - val_loss: 0.2771 - val_accuracy: 0.8769\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2454 - accuracy: 0.8830 - val_loss: 0.2744 - val_accuracy: 0.8769\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2461 - accuracy: 0.8830 - val_loss: 0.2769 - val_accuracy: 0.8769\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2430 - accuracy: 0.8830 - val_loss: 0.2782 - val_accuracy: 0.8769\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2430 - accuracy: 0.8830 - val_loss: 0.2765 - val_accuracy: 0.8769\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.2804 - val_accuracy: 0.8769\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2438 - accuracy: 0.8830 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2489 - accuracy: 0.8830 - val_loss: 0.2750 - val_accuracy: 0.8769\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2451 - accuracy: 0.8830 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2432 - accuracy: 0.8830 - val_loss: 0.2752 - val_accuracy: 0.8769\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2459 - accuracy: 0.8808 - val_loss: 0.2781 - val_accuracy: 0.8769\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2435 - accuracy: 0.8830 - val_loss: 0.2728 - val_accuracy: 0.8769\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2460 - accuracy: 0.8830 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2476 - accuracy: 0.8830 - val_loss: 0.2746 - val_accuracy: 0.8769\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2462 - accuracy: 0.8852 - val_loss: 0.2755 - val_accuracy: 0.8769\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2444 - accuracy: 0.8830 - val_loss: 0.2735 - val_accuracy: 0.8769\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2520 - accuracy: 0.8720 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2496 - accuracy: 0.8764 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2479 - accuracy: 0.8808 - val_loss: 0.2731 - val_accuracy: 0.8769\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2464 - accuracy: 0.8808 - val_loss: 0.2786 - val_accuracy: 0.8821\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2447 - accuracy: 0.8808 - val_loss: 0.2750 - val_accuracy: 0.8769\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2445 - accuracy: 0.8808 - val_loss: 0.2760 - val_accuracy: 0.8769\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2428 - accuracy: 0.8830 - val_loss: 0.2728 - val_accuracy: 0.8769\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2415 - accuracy: 0.8830 - val_loss: 0.2771 - val_accuracy: 0.8769\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2428 - accuracy: 0.8830 - val_loss: 0.2766 - val_accuracy: 0.8769\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2434 - accuracy: 0.8786 - val_loss: 0.2836 - val_accuracy: 0.8769\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 253us/step - loss: 0.2435 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8769\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.87 - 0s 91us/step - loss: 0.2416 - accuracy: 0.8830 - val_loss: 0.2757 - val_accuracy: 0.8769\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2454 - accuracy: 0.8786 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2482 - accuracy: 0.8808 - val_loss: 0.2733 - val_accuracy: 0.8769\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2420 - accuracy: 0.8764 - val_loss: 0.2849 - val_accuracy: 0.8769\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2455 - accuracy: 0.8830 - val_loss: 0.2751 - val_accuracy: 0.8769\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 165us/step - loss: 0.2416 - accuracy: 0.8830 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2458 - accuracy: 0.8830 - val_loss: 0.2746 - val_accuracy: 0.8769\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2440 - accuracy: 0.8764 - val_loss: 0.2754 - val_accuracy: 0.8769\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2480 - accuracy: 0.8830 - val_loss: 0.2730 - val_accuracy: 0.8769\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2448 - accuracy: 0.8764 - val_loss: 0.2750 - val_accuracy: 0.8769\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2429 - accuracy: 0.8786 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2465 - accuracy: 0.8764 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2799 - val_accuracy: 0.8769\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2493 - accuracy: 0.8786 - val_loss: 0.2727 - val_accuracy: 0.8615\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2433 - accuracy: 0.8830 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2401 - accuracy: 0.8764 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2432 - accuracy: 0.8808 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2446 - accuracy: 0.8830 - val_loss: 0.2764 - val_accuracy: 0.8769\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2473 - accuracy: 0.8675 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2567 - accuracy: 0.8830 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2431 - accuracy: 0.8786 - val_loss: 0.2748 - val_accuracy: 0.8769\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2727 - val_accuracy: 0.8769\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2425 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2429 - accuracy: 0.8830 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2493 - accuracy: 0.8764 - val_loss: 0.2803 - val_accuracy: 0.8769\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2458 - accuracy: 0.8808 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2428 - accuracy: 0.8808 - val_loss: 0.2751 - val_accuracy: 0.8769\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2441 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2429 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8769\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2404 - accuracy: 0.8830 - val_loss: 0.2708 - val_accuracy: 0.8769\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2443 - accuracy: 0.8808 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2486 - accuracy: 0.8830 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2441 - accuracy: 0.8830 - val_loss: 0.2720 - val_accuracy: 0.8769\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2402 - accuracy: 0.8830 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2408 - accuracy: 0.8830 - val_loss: 0.2727 - val_accuracy: 0.8769\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2414 - accuracy: 0.8742 - val_loss: 0.2755 - val_accuracy: 0.8769\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2447 - accuracy: 0.8830 - val_loss: 0.2724 - val_accuracy: 0.8769\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 208us/step - loss: 0.2464 - accuracy: 0.8786 - val_loss: 0.2797 - val_accuracy: 0.8769\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2452 - accuracy: 0.8830 - val_loss: 0.2719 - val_accuracy: 0.8769\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.2761 - val_accuracy: 0.8769\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2425 - accuracy: 0.8830 - val_loss: 0.2719 - val_accuracy: 0.8769\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2461 - accuracy: 0.8742 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2421 - accuracy: 0.8830 - val_loss: 0.2691 - val_accuracy: 0.8769\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2433 - accuracy: 0.8830 - val_loss: 0.2739 - val_accuracy: 0.8769\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2473 - accuracy: 0.8786 - val_loss: 0.2763 - val_accuracy: 0.8769\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.87 - 0s 124us/step - loss: 0.2432 - accuracy: 0.8830 - val_loss: 0.2691 - val_accuracy: 0.8769\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2454 - accuracy: 0.8742 - val_loss: 0.2790 - val_accuracy: 0.8769\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2482 - accuracy: 0.8742 - val_loss: 0.2687 - val_accuracy: 0.8769\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2462 - accuracy: 0.8808 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2421 - accuracy: 0.8830 - val_loss: 0.2733 - val_accuracy: 0.8769\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2406 - accuracy: 0.8830 - val_loss: 0.2769 - val_accuracy: 0.8615\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2406 - accuracy: 0.8808 - val_loss: 0.2819 - val_accuracy: 0.8615\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2513 - accuracy: 0.8609 - val_loss: 0.2749 - val_accuracy: 0.8615\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2427 - accuracy: 0.8786 - val_loss: 0.2827 - val_accuracy: 0.8769\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2406 - accuracy: 0.8830 - val_loss: 0.2746 - val_accuracy: 0.8769\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2471 - accuracy: 0.8675 - val_loss: 0.2828 - val_accuracy: 0.8769\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2704 - val_accuracy: 0.8769\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 203us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2771 - val_accuracy: 0.8769\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 434us/step - loss: 0.2438 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8821\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2730 - val_accuracy: 0.8769\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2398 - accuracy: 0.8830 - val_loss: 0.2762 - val_accuracy: 0.8769\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2403 - accuracy: 0.8786 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 258us/step - loss: 0.2419 - accuracy: 0.8830 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2432 - accuracy: 0.8808 - val_loss: 0.2720 - val_accuracy: 0.8667\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2476 - accuracy: 0.8609 - val_loss: 0.2767 - val_accuracy: 0.8769\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2376 - accuracy: 0.8764 - val_loss: 0.2714 - val_accuracy: 0.8821\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2457 - accuracy: 0.8808 - val_loss: 0.2766 - val_accuracy: 0.8821\n",
      "Epoch 442/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2442 - accuracy: 0.8830 - val_loss: 0.2696 - val_accuracy: 0.8769\n",
      "Epoch 443/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2419 - accuracy: 0.8808 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2404 - accuracy: 0.8830 - val_loss: 0.2741 - val_accuracy: 0.8769\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 92us/step - loss: 0.2450 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2448 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2810 - val_accuracy: 0.8769\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2432 - accuracy: 0.8808 - val_loss: 0.2672 - val_accuracy: 0.8769\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2459 - accuracy: 0.8808 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2476 - accuracy: 0.8786 - val_loss: 0.2844 - val_accuracy: 0.8769\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2435 - accuracy: 0.8808 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2403 - accuracy: 0.8830 - val_loss: 0.2757 - val_accuracy: 0.8769\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2766 - val_accuracy: 0.8769\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2725 - val_accuracy: 0.8769\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2425 - accuracy: 0.8808 - val_loss: 0.2830 - val_accuracy: 0.8769\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2433 - accuracy: 0.8720 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2436 - accuracy: 0.8786 - val_loss: 0.2993 - val_accuracy: 0.8718\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 257us/step - loss: 0.2509 - accuracy: 0.8499 - val_loss: 0.2670 - val_accuracy: 0.8769\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2482 - accuracy: 0.8764 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2720 - val_accuracy: 0.8769\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2420 - accuracy: 0.8764 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2403 - accuracy: 0.8786 - val_loss: 0.2718 - val_accuracy: 0.8769\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2391 - accuracy: 0.8764 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2450 - accuracy: 0.8830 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2411 - accuracy: 0.8830 - val_loss: 0.2685 - val_accuracy: 0.8769\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2453 - accuracy: 0.8808 - val_loss: 0.2711 - val_accuracy: 0.8769\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.2732 - val_accuracy: 0.8769\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2412 - accuracy: 0.8720 - val_loss: 0.2806 - val_accuracy: 0.8615\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2398 - accuracy: 0.8808 - val_loss: 0.2768 - val_accuracy: 0.8615\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2436 - accuracy: 0.8830 - val_loss: 0.2823 - val_accuracy: 0.8769\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2486 - accuracy: 0.8521 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2413 - accuracy: 0.8764 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2416 - accuracy: 0.8808 - val_loss: 0.2693 - val_accuracy: 0.8769\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2385 - accuracy: 0.8830 - val_loss: 0.2770 - val_accuracy: 0.8769\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2423 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2733 - val_accuracy: 0.8769\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2816 - val_accuracy: 0.8769\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2396 - accuracy: 0.8808 - val_loss: 0.2771 - val_accuracy: 0.8769\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2421 - accuracy: 0.8786 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2404 - accuracy: 0.8830 - val_loss: 0.2769 - val_accuracy: 0.8769\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2385 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2496 - accuracy: 0.8852 - val_loss: 0.2684 - val_accuracy: 0.8769\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2422 - accuracy: 0.8720 - val_loss: 0.2838 - val_accuracy: 0.8769\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2497 - accuracy: 0.8565 - val_loss: 0.2727 - val_accuracy: 0.8667\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2452 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8769\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2456 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2382 - accuracy: 0.8786 - val_loss: 0.2748 - val_accuracy: 0.8769\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.2691 - val_accuracy: 0.8769\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2388 - accuracy: 0.8808 - val_loss: 0.2831 - val_accuracy: 0.8769\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2445 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 0.2757 - val_accuracy: 0.8821\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2745 - val_accuracy: 0.8769\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2423 - accuracy: 0.8786 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8769\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2483 - accuracy: 0.8587 - val_loss: 0.2718 - val_accuracy: 0.8769\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2405 - accuracy: 0.8808 - val_loss: 0.2780 - val_accuracy: 0.8769\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2418 - accuracy: 0.8786 - val_loss: 0.2804 - val_accuracy: 0.8769\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2511 - accuracy: 0.8521 - val_loss: 0.2702 - val_accuracy: 0.8769\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2388 - accuracy: 0.8830 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2383 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2435 - accuracy: 0.8830 - val_loss: 0.2793 - val_accuracy: 0.8769\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2385 - accuracy: 0.8830 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2751 - val_accuracy: 0.8769\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2398 - accuracy: 0.8830 - val_loss: 0.2752 - val_accuracy: 0.8769\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 219us/step - loss: 0.2477 - accuracy: 0.8764 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2718 - val_accuracy: 0.8769\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2470 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8769\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2735 - val_accuracy: 0.8769\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.2712 - val_accuracy: 0.8769\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 0.2760 - val_accuracy: 0.8769\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2695 - val_accuracy: 0.8769\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2724 - val_accuracy: 0.8769\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8769\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2792 - val_accuracy: 0.8769\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2757 - val_accuracy: 0.8615\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2405 - accuracy: 0.8764 - val_loss: 0.2766 - val_accuracy: 0.8769\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.2730 - val_accuracy: 0.8769\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2750 - val_accuracy: 0.8769\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2413 - accuracy: 0.8830 - val_loss: 0.2743 - val_accuracy: 0.8769\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2416 - accuracy: 0.8698 - val_loss: 0.2778 - val_accuracy: 0.8769\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2774 - val_accuracy: 0.8769\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2698 - val_accuracy: 0.8769\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2733 - val_accuracy: 0.8769\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2463 - accuracy: 0.8786 - val_loss: 0.2833 - val_accuracy: 0.8769\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2890 - accuracy: 0.8124 - val_loss: 0.2743 - val_accuracy: 0.8513\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2801 - accuracy: 0.8698 - val_loss: 0.2761 - val_accuracy: 0.8513\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2855 - val_accuracy: 0.8718\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2397 - accuracy: 0.8830 - val_loss: 0.2683 - val_accuracy: 0.8769\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2416 - accuracy: 0.8764 - val_loss: 0.2706 - val_accuracy: 0.8769\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2408 - accuracy: 0.8764 - val_loss: 0.2743 - val_accuracy: 0.8769\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2482 - accuracy: 0.8786 - val_loss: 0.2714 - val_accuracy: 0.8769\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.2748 - val_accuracy: 0.8769\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
      "Epoch 552/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 553/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2387 - accuracy: 0.8742 - val_loss: 0.2764 - val_accuracy: 0.8769\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2397 - accuracy: 0.8786 - val_loss: 0.2757 - val_accuracy: 0.8615\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 69us/step - loss: 0.2368 - accuracy: 0.8764 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2381 - accuracy: 0.8675 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2783 - val_accuracy: 0.8769\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2410 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8769\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 179us/step - loss: 0.2398 - accuracy: 0.8830 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2795 - val_accuracy: 0.8718\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2695 - val_accuracy: 0.8769\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2830 - val_accuracy: 0.8718\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.2728 - val_accuracy: 0.8769\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2394 - accuracy: 0.8786 - val_loss: 0.2767 - val_accuracy: 0.8769\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2387 - accuracy: 0.8808 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2721 - val_accuracy: 0.8769\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2718 - val_accuracy: 0.8769\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2417 - accuracy: 0.8764 - val_loss: 0.2784 - val_accuracy: 0.8769\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2709 - val_accuracy: 0.8769\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.2711 - val_accuracy: 0.8769\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.93 - 0s 91us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2827 - val_accuracy: 0.8769\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.2725 - val_accuracy: 0.8769\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2522 - accuracy: 0.8477 - val_loss: 0.2651 - val_accuracy: 0.8769\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2442 - accuracy: 0.8742 - val_loss: 0.2704 - val_accuracy: 0.8769\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2397 - accuracy: 0.8808 - val_loss: 0.2674 - val_accuracy: 0.8769\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2682 - val_accuracy: 0.8769\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2657 - val_accuracy: 0.8769\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2751 - val_accuracy: 0.8769\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8769\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2731 - val_accuracy: 0.8769\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2780 - val_accuracy: 0.8769\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2739 - val_accuracy: 0.8769\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 63us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2772 - val_accuracy: 0.8718\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2395 - accuracy: 0.8786 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2726 - val_accuracy: 0.8718\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2747 - val_accuracy: 0.8718\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2372 - accuracy: 0.8786 - val_loss: 0.2709 - val_accuracy: 0.8769\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2396 - accuracy: 0.8764 - val_loss: 0.2749 - val_accuracy: 0.8718\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2358 - accuracy: 0.8808 - val_loss: 0.2845 - val_accuracy: 0.8615\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.2821 - val_accuracy: 0.8821\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2506 - accuracy: 0.8499 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2387 - accuracy: 0.8720 - val_loss: 0.2792 - val_accuracy: 0.8821\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2360 - accuracy: 0.8808 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2417 - accuracy: 0.8786 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2729 - val_accuracy: 0.8821\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2770 - val_accuracy: 0.8769\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2719 - val_accuracy: 0.8769\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2472 - accuracy: 0.8742 - val_loss: 0.2847 - val_accuracy: 0.8718\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2765 - val_accuracy: 0.8769\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2713 - val_accuracy: 0.8769\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2708 - val_accuracy: 0.8769\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2777 - val_accuracy: 0.8718\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2409 - accuracy: 0.8830 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2388 - accuracy: 0.8808 - val_loss: 0.2795 - val_accuracy: 0.8769\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2365 - accuracy: 0.8764 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2765 - val_accuracy: 0.8769\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2761 - val_accuracy: 0.8769\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2338 - accuracy: 0.8786 - val_loss: 0.2730 - val_accuracy: 0.8769\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2720 - val_accuracy: 0.8769\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2418 - accuracy: 0.8609 - val_loss: 0.2744 - val_accuracy: 0.8769\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2385 - accuracy: 0.8764 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2704 - val_accuracy: 0.8769\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2746 - val_accuracy: 0.8769\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2765 - val_accuracy: 0.8718\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2339 - accuracy: 0.8808 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2735 - val_accuracy: 0.8769\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2689 - val_accuracy: 0.8769\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2710 - val_accuracy: 0.8615\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2395 - accuracy: 0.8742 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2752 - val_accuracy: 0.8769\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2331 - accuracy: 0.8786 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.2735 - val_accuracy: 0.8769\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2352 - accuracy: 0.8786 - val_loss: 0.2722 - val_accuracy: 0.8769\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2384 - accuracy: 0.8786 - val_loss: 0.2769 - val_accuracy: 0.8718\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2731 - val_accuracy: 0.8769\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.2763 - val_accuracy: 0.8769\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2764 - val_accuracy: 0.8769\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2696 - val_accuracy: 0.8769\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2786 - val_accuracy: 0.8769\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2347 - accuracy: 0.8808 - val_loss: 0.2763 - val_accuracy: 0.8718\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.2725 - val_accuracy: 0.8821\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2377 - accuracy: 0.8808 - val_loss: 0.2676 - val_accuracy: 0.8821\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2392 - accuracy: 0.8720 - val_loss: 0.2786 - val_accuracy: 0.8769\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2457 - accuracy: 0.8720 - val_loss: 0.2747 - val_accuracy: 0.8769\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2403 - accuracy: 0.8786 - val_loss: 0.2741 - val_accuracy: 0.8769\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2736 - val_accuracy: 0.8769\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2709 - val_accuracy: 0.8769\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2776 - val_accuracy: 0.8718\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2766 - val_accuracy: 0.8821\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2766 - val_accuracy: 0.8718\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2829 - val_accuracy: 0.8718\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2735 - val_accuracy: 0.8769\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8769\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2436 - accuracy: 0.8742 - val_loss: 0.2769 - val_accuracy: 0.8718\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2395 - accuracy: 0.8852 - val_loss: 0.2707 - val_accuracy: 0.8769\n",
      "Epoch 662/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2401 - accuracy: 0.8852 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 663/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2746 - val_accuracy: 0.8769\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2736 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2741 - val_accuracy: 0.8769\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2766 - val_accuracy: 0.8769\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2717 - val_accuracy: 0.8769\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2758 - val_accuracy: 0.8615\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2738 - val_accuracy: 0.8615\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2793 - val_accuracy: 0.8769\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2691 - val_accuracy: 0.8769\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2765 - val_accuracy: 0.8718\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2357 - accuracy: 0.8808 - val_loss: 0.2748 - val_accuracy: 0.8718\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.2693 - val_accuracy: 0.8769\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2377 - accuracy: 0.8808 - val_loss: 0.2676 - val_accuracy: 0.8769\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2379 - accuracy: 0.8786 - val_loss: 0.2721 - val_accuracy: 0.8769\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2708 - val_accuracy: 0.8769\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2729 - val_accuracy: 0.8769\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2695 - val_accuracy: 0.8769\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2386 - accuracy: 0.8742 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2406 - accuracy: 0.8808 - val_loss: 0.2668 - val_accuracy: 0.8769\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2456 - accuracy: 0.8808 - val_loss: 0.2780 - val_accuracy: 0.8769\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2711 - val_accuracy: 0.8769\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2699 - val_accuracy: 0.8769\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2761 - val_accuracy: 0.8821\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2697 - val_accuracy: 0.8821\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2549 - accuracy: 0.8742 - val_loss: 0.2798 - val_accuracy: 0.8718\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2719 - val_accuracy: 0.8718\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2736 - val_accuracy: 0.8769\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2676 - val_accuracy: 0.8769\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2723 - val_accuracy: 0.8769\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2385 - accuracy: 0.8786 - val_loss: 0.2670 - val_accuracy: 0.8769\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2347 - accuracy: 0.8742 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2681 - val_accuracy: 0.8769\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2738 - val_accuracy: 0.8718\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2409 - accuracy: 0.8852 - val_loss: 0.2674 - val_accuracy: 0.8769\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2332 - accuracy: 0.8786 - val_loss: 0.2695 - val_accuracy: 0.8769\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2738 - val_accuracy: 0.8769\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2672 - val_accuracy: 0.8769\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2335 - accuracy: 0.8808 - val_loss: 0.2727 - val_accuracy: 0.8769\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2701 - val_accuracy: 0.8769\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2692 - val_accuracy: 0.8769\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2742 - val_accuracy: 0.8769\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2754 - val_accuracy: 0.8769\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2703 - val_accuracy: 0.8769\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.2734 - val_accuracy: 0.8769\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2654 - val_accuracy: 0.8769\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2698 - val_accuracy: 0.8769\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2350 - accuracy: 0.8808 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2695 - val_accuracy: 0.8769\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2412 - accuracy: 0.8742 - val_loss: 0.2791 - val_accuracy: 0.8718\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.2749 - val_accuracy: 0.8615\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2341 - accuracy: 0.8808 - val_loss: 0.2732 - val_accuracy: 0.8615\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2716 - val_accuracy: 0.8769\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.2711 - val_accuracy: 0.8821\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2695 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 0.2691 - val_accuracy: 0.8718\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2747 - val_accuracy: 0.8718\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8718\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2740 - val_accuracy: 0.8718\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2771 - val_accuracy: 0.8718\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2684 - val_accuracy: 0.8718\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.2702 - val_accuracy: 0.8718\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2380 - accuracy: 0.8808 - val_loss: 0.2699 - val_accuracy: 0.8821\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2414 - accuracy: 0.8764 - val_loss: 0.2666 - val_accuracy: 0.8769\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2660 - val_accuracy: 0.8769\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2722 - val_accuracy: 0.8718\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2768 - val_accuracy: 0.8718\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2663 - val_accuracy: 0.8769\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2438 - accuracy: 0.8565 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2779 - val_accuracy: 0.8769\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2685 - val_accuracy: 0.8821\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2683 - val_accuracy: 0.8769\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.2756 - val_accuracy: 0.8821\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.2672 - val_accuracy: 0.8769\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.2681 - val_accuracy: 0.8769\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8821\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.2713 - val_accuracy: 0.8821\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2359 - accuracy: 0.8808 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2662 - val_accuracy: 0.8769\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2352 - accuracy: 0.8808 - val_loss: 0.2686 - val_accuracy: 0.8821\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2663 - val_accuracy: 0.8769\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2679 - val_accuracy: 0.8769\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2317 - accuracy: 0.8808 - val_loss: 0.2756 - val_accuracy: 0.8718\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8821\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2377 - accuracy: 0.8764 - val_loss: 0.2861 - val_accuracy: 0.8718\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2425 - accuracy: 0.8808 - val_loss: 0.2687 - val_accuracy: 0.8769\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2668 - val_accuracy: 0.8821\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8821\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2310 - accuracy: 0.8808 - val_loss: 0.2688 - val_accuracy: 0.8769\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2353 - accuracy: 0.8764 - val_loss: 0.2669 - val_accuracy: 0.8821\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8769\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2707 - val_accuracy: 0.8821\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2669 - val_accuracy: 0.8769\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2722 - val_accuracy: 0.8821\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2412 - accuracy: 0.8852 - val_loss: 0.2812 - val_accuracy: 0.8718\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2659 - val_accuracy: 0.8769\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2412 - accuracy: 0.8764 - val_loss: 0.2730 - val_accuracy: 0.8718\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8769\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2654 - val_accuracy: 0.8769\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.2678 - val_accuracy: 0.8769\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2403 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8769\n",
      "Epoch 772/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.2724 - val_accuracy: 0.8667\n",
      "Epoch 773/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2452 - accuracy: 0.8742 - val_loss: 0.2832 - val_accuracy: 0.8769\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2379 - accuracy: 0.8808 - val_loss: 0.2704 - val_accuracy: 0.8821\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2394 - accuracy: 0.8852 - val_loss: 0.2702 - val_accuracy: 0.8821\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2358 - accuracy: 0.8742 - val_loss: 0.2761 - val_accuracy: 0.8769\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2410 - accuracy: 0.8653 - val_loss: 0.2696 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2380 - accuracy: 0.8808 - val_loss: 0.2721 - val_accuracy: 0.8821\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2686 - val_accuracy: 0.8821\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2760 - val_accuracy: 0.8769\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2352 - accuracy: 0.8786 - val_loss: 0.2690 - val_accuracy: 0.8821\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2710 - val_accuracy: 0.8769\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2393 - accuracy: 0.8852 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2686 - val_accuracy: 0.8769\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2384 - accuracy: 0.8764 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2750 - val_accuracy: 0.8718\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2741 - val_accuracy: 0.8821\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2704 - val_accuracy: 0.8821\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2701 - val_accuracy: 0.8821\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2668 - val_accuracy: 0.8821\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8821\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2699 - val_accuracy: 0.8821\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2686 - val_accuracy: 0.8769\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2368 - accuracy: 0.8852 - val_loss: 0.2663 - val_accuracy: 0.8821\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.2721 - val_accuracy: 0.8718\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.2713 - val_accuracy: 0.8821\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2482 - accuracy: 0.8808 - val_loss: 0.2739 - val_accuracy: 0.8821\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.2747 - val_accuracy: 0.8718\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2333 - accuracy: 0.8808 - val_loss: 0.2649 - val_accuracy: 0.8769\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2733 - val_accuracy: 0.8821\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2338 - accuracy: 0.8808 - val_loss: 0.2708 - val_accuracy: 0.8718\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2708 - val_accuracy: 0.8821\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2389 - accuracy: 0.8786 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2513 - accuracy: 0.8477 - val_loss: 0.2659 - val_accuracy: 0.8821\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.2702 - val_accuracy: 0.8821\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2359 - accuracy: 0.8764 - val_loss: 0.2769 - val_accuracy: 0.8615\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2344 - accuracy: 0.8808 - val_loss: 0.2753 - val_accuracy: 0.8667\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2316 - accuracy: 0.8808 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.2783 - val_accuracy: 0.8718\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2448 - accuracy: 0.8344 - val_loss: 0.2656 - val_accuracy: 0.8821\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 0.2713 - val_accuracy: 0.8718\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2676 - val_accuracy: 0.8718\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2681 - val_accuracy: 0.8821\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.2738 - val_accuracy: 0.8718\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2677 - val_accuracy: 0.8821\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2308 - accuracy: 0.8830 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.2750 - val_accuracy: 0.8821\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2477 - accuracy: 0.8499 - val_loss: 0.2692 - val_accuracy: 0.8821\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2494 - accuracy: 0.8764 - val_loss: 0.2686 - val_accuracy: 0.8821\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2314 - accuracy: 0.8808 - val_loss: 0.2735 - val_accuracy: 0.8718\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2693 - val_accuracy: 0.8821\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2356 - accuracy: 0.8786 - val_loss: 0.2697 - val_accuracy: 0.8769\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2483 - accuracy: 0.8830 - val_loss: 0.2769 - val_accuracy: 0.8718\n",
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2438 - accuracy: 0.8543 - val_loss: 0.2691 - val_accuracy: 0.8667\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2414 - accuracy: 0.8786 - val_loss: 0.2681 - val_accuracy: 0.8821\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2766 - val_accuracy: 0.8718\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.2667 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2333 - accuracy: 0.8786 - val_loss: 0.2737 - val_accuracy: 0.8769\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.2708 - val_accuracy: 0.8821\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2660 - val_accuracy: 0.8769\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.2747 - val_accuracy: 0.8821\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2740 - val_accuracy: 0.8821\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2381 - accuracy: 0.8786 - val_loss: 0.2705 - val_accuracy: 0.8769\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2697 - val_accuracy: 0.8821\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2671 - val_accuracy: 0.8821\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2724 - val_accuracy: 0.8821\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2667 - val_accuracy: 0.8821\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2713 - val_accuracy: 0.8821\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2741 - val_accuracy: 0.8821\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.2686 - val_accuracy: 0.8769\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.2684 - val_accuracy: 0.8769\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2701 - val_accuracy: 0.8821\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2721 - val_accuracy: 0.8821\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2683 - val_accuracy: 0.8821\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2744 - val_accuracy: 0.8821\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.2713 - val_accuracy: 0.8821\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 0.2712 - val_accuracy: 0.8821\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8821\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2397 - accuracy: 0.8720 - val_loss: 0.2756 - val_accuracy: 0.8769\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.2668 - val_accuracy: 0.8821\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2629 - val_accuracy: 0.8821\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2724 - val_accuracy: 0.8821\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2348 - accuracy: 0.8786 - val_loss: 0.2690 - val_accuracy: 0.8821\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2650 - val_accuracy: 0.8821\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2361 - accuracy: 0.8786 - val_loss: 0.2686 - val_accuracy: 0.8821\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2647 - val_accuracy: 0.8821\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2641 - val_accuracy: 0.8821\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8769\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2658 - val_accuracy: 0.8821\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2678 - val_accuracy: 0.8821\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.2678 - val_accuracy: 0.8821\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2348 - accuracy: 0.8808 - val_loss: 0.2680 - val_accuracy: 0.8821\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.2663 - val_accuracy: 0.8821\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.2714 - val_accuracy: 0.8821\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2395 - accuracy: 0.8808 - val_loss: 0.2704 - val_accuracy: 0.8821\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2484 - accuracy: 0.8477 - val_loss: 0.2638 - val_accuracy: 0.8821\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.2689 - val_accuracy: 0.8821\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.2761 - val_accuracy: 0.8821\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2696 - val_accuracy: 0.8667\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2740 - val_accuracy: 0.8769\n",
      "Epoch 882/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.2700 - val_accuracy: 0.8821\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2336 - accuracy: 0.8808 - val_loss: 0.2707 - val_accuracy: 0.8667\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2708 - val_accuracy: 0.8821\n",
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.2663 - val_accuracy: 0.8821\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2779 - val_accuracy: 0.8821\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2668 - val_accuracy: 0.8821\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2666 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2722 - val_accuracy: 0.8821\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2330 - accuracy: 0.8808 - val_loss: 0.2675 - val_accuracy: 0.8821\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2376 - accuracy: 0.8698 - val_loss: 0.2688 - val_accuracy: 0.8821\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2731 - val_accuracy: 0.8821\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2311 - accuracy: 0.8830 - val_loss: 0.2696 - val_accuracy: 0.8821\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2693 - val_accuracy: 0.8821\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2759 - val_accuracy: 0.8821\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2303 - accuracy: 0.8786 - val_loss: 0.2661 - val_accuracy: 0.8821\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2418 - accuracy: 0.8786 - val_loss: 0.2697 - val_accuracy: 0.8821\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2641 - val_accuracy: 0.8821\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2682 - val_accuracy: 0.8821\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.2703 - val_accuracy: 0.8821\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.2760 - val_accuracy: 0.8821\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2310 - accuracy: 0.8830 - val_loss: 0.2682 - val_accuracy: 0.8821\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2728 - val_accuracy: 0.8769\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.2660 - val_accuracy: 0.8821\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2416 - accuracy: 0.8896 - val_loss: 0.2678 - val_accuracy: 0.8769\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2350 - accuracy: 0.8874 - val_loss: 0.2687 - val_accuracy: 0.8821\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2301 - accuracy: 0.8830 - val_loss: 0.2671 - val_accuracy: 0.8821\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2690 - val_accuracy: 0.8769\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2296 - accuracy: 0.8808 - val_loss: 0.2689 - val_accuracy: 0.8821\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2698 - val_accuracy: 0.8769\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2669 - val_accuracy: 0.8821\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2735 - val_accuracy: 0.8821\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2688 - val_accuracy: 0.8821\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2343 - accuracy: 0.8786 - val_loss: 0.2777 - val_accuracy: 0.8769\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2621 - val_accuracy: 0.8821\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2354 - accuracy: 0.8720 - val_loss: 0.2679 - val_accuracy: 0.8821\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2686 - val_accuracy: 0.8821\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2341 - accuracy: 0.8786 - val_loss: 0.2698 - val_accuracy: 0.8821\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2687 - val_accuracy: 0.8821\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2438 - accuracy: 0.8764 - val_loss: 0.2765 - val_accuracy: 0.8821\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2726 - val_accuracy: 0.8821\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2672 - val_accuracy: 0.8821\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2758 - val_accuracy: 0.8769\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.2694 - val_accuracy: 0.8821\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2356 - accuracy: 0.8808 - val_loss: 0.2652 - val_accuracy: 0.8872\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.2822 - val_accuracy: 0.8769\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2408 - accuracy: 0.8808 - val_loss: 0.2661 - val_accuracy: 0.8821\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2396 - accuracy: 0.8742 - val_loss: 0.2708 - val_accuracy: 0.8821\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2358 - accuracy: 0.8786 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2692 - val_accuracy: 0.8821\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2327 - accuracy: 0.8874 - val_loss: 0.2729 - val_accuracy: 0.8718\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2411 - accuracy: 0.8742 - val_loss: 0.2695 - val_accuracy: 0.8821\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2700 - val_accuracy: 0.8769\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.2646 - val_accuracy: 0.8821\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2660 - val_accuracy: 0.8821\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2718 - val_accuracy: 0.8821\n",
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 0.2667 - val_accuracy: 0.8821\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2691 - val_accuracy: 0.8821\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2659 - val_accuracy: 0.8821\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2702 - val_accuracy: 0.8769\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.2633 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2665 - val_accuracy: 0.8821\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2706 - val_accuracy: 0.8821\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2411 - accuracy: 0.8499 - val_loss: 0.2664 - val_accuracy: 0.8821\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2379 - accuracy: 0.8720 - val_loss: 0.2653 - val_accuracy: 0.8821\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2717 - val_accuracy: 0.8821\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2642 - val_accuracy: 0.8821\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2715 - val_accuracy: 0.8821\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2314 - accuracy: 0.8830 - val_loss: 0.2633 - val_accuracy: 0.8821\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2638 - val_accuracy: 0.8821\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2639 - val_accuracy: 0.8821\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2668 - val_accuracy: 0.8821\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2654 - val_accuracy: 0.8821\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2404 - accuracy: 0.8786 - val_loss: 0.2695 - val_accuracy: 0.8821\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2327 - accuracy: 0.8808 - val_loss: 0.2660 - val_accuracy: 0.8821\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.2670 - val_accuracy: 0.8821\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2288 - accuracy: 0.8852 - val_loss: 0.2665 - val_accuracy: 0.8821\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2294 - accuracy: 0.8852 - val_loss: 0.2696 - val_accuracy: 0.8821\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.2646 - val_accuracy: 0.8821\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2682 - val_accuracy: 0.8821\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2699 - val_accuracy: 0.8821\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.2710 - val_accuracy: 0.8821\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2370 - accuracy: 0.8631 - val_loss: 0.2642 - val_accuracy: 0.8821\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2561 - accuracy: 0.8786 - val_loss: 0.2663 - val_accuracy: 0.8821\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2844 - val_accuracy: 0.8769\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.2662 - val_accuracy: 0.8821\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2674 - val_accuracy: 0.8821\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2715 - val_accuracy: 0.8769\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2652 - val_accuracy: 0.8821\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2355 - accuracy: 0.8786 - val_loss: 0.2616 - val_accuracy: 0.8821\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2397 - accuracy: 0.8852 - val_loss: 0.2670 - val_accuracy: 0.8821\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2641 - val_accuracy: 0.8821\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2615 - val_accuracy: 0.8821\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2295 - accuracy: 0.8808 - val_loss: 0.2653 - val_accuracy: 0.8821\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2303 - accuracy: 0.8830 - val_loss: 0.2678 - val_accuracy: 0.8821\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.2652 - val_accuracy: 0.8821\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2654 - val_accuracy: 0.8821\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2650 - val_accuracy: 0.8821\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2625 - val_accuracy: 0.8821\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2341 - accuracy: 0.8808 - val_loss: 0.2638 - val_accuracy: 0.8821\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2749 - val_accuracy: 0.8769\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2639 - val_accuracy: 0.8821\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.2697 - val_accuracy: 0.8821\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2286 - accuracy: 0.8808 - val_loss: 0.2653 - val_accuracy: 0.8821\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.2682 - val_accuracy: 0.8821\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2704 - val_accuracy: 0.8821\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2674 - val_accuracy: 0.8821\n",
      "Epoch 992/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2634 - val_accuracy: 0.8821\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.2683 - val_accuracy: 0.8821\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2727 - val_accuracy: 0.8821\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2685 - val_accuracy: 0.8821\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2680 - val_accuracy: 0.8821\n",
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2649 - val_accuracy: 0.8821\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2677 - val_accuracy: 0.8821\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2371 - accuracy: 0.8852 - val_loss: 0.2697 - val_accuracy: 0.8821\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2641 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38fb16d8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 87.18%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       1, 0, 1, 0, 2, 1, 2, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0,\n",
       "       2, 2, 0, 1, 2, 0, 1, 0, 0, 2, 1, 0, 2, 2, 1, 0, 1, 2, 0, 1, 2, 1,\n",
       "       0, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 2, 2, 1, 0, 1, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 2, 2, 2, 1, 0,\n",
       "       1, 2, 1, 0, 0, 2, 1, 0, 2, 0, 0, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 2, 0, 2, 1,\n",
       "       0, 0, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 1, 1, 0, 0, 2, 1, 2, 2,\n",
       "       1, 2, 1, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS209     2     2\n",
       "1      NRS255     1     1\n",
       "2      NRS119     0     1\n",
       "3      NRS071     0     0\n",
       "4      NRS002     0     1\n",
       "..        ...   ...   ...\n",
       "190  CFBRSa30     0     0\n",
       "191    NRS383     1     0\n",
       "192    NRS110     2     2\n",
       "193    NRS209     2     2\n",
       "194     NY439     0     0\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.804833e-07</td>\n",
       "      <td>9.999990e-01</td>\n",
       "      <td>1.326707e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.475308e-01</td>\n",
       "      <td>5.524690e-01</td>\n",
       "      <td>2.029845e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.475308e-01</td>\n",
       "      <td>5.524690e-01</td>\n",
       "      <td>2.029845e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    3.604249e-12  2.698129e-07  9.999998e-01\n",
       "1    9.804833e-07  9.999990e-01  1.326707e-12\n",
       "2    4.475308e-01  5.524690e-01  2.029845e-07\n",
       "3    6.129044e-01  3.870795e-01  1.601290e-05\n",
       "4    4.475308e-01  5.524690e-01  2.029845e-07\n",
       "..            ...           ...           ...\n",
       "190  7.207667e-01  2.792331e-01  2.571588e-07\n",
       "191  6.129044e-01  3.870795e-01  1.601290e-05\n",
       "192  3.260306e-07  7.910664e-07  9.999989e-01\n",
       "193  3.604249e-12  2.698129e-07  9.999998e-01\n",
       "194  7.207667e-01  2.792331e-01  2.571588e-07\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p17s.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 195 samples\n",
      "Epoch 1/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2579 - accuracy: 0.8300 - val_loss: 0.2797 - val_accuracy: 0.8462\n",
      "Epoch 2/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2644 - accuracy: 0.8698 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 3/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 4/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2804 - val_accuracy: 0.8718\n",
      "Epoch 5/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2441 - accuracy: 0.8764 - val_loss: 0.2771 - val_accuracy: 0.8718\n",
      "Epoch 6/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 7/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2856 - val_accuracy: 0.8718\n",
      "Epoch 8/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2799 - val_accuracy: 0.8718\n",
      "Epoch 9/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 10/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.2784 - val_accuracy: 0.8718\n",
      "Epoch 11/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2403 - accuracy: 0.8808 - val_loss: 0.2797 - val_accuracy: 0.8718\n",
      "Epoch 12/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2793 - val_accuracy: 0.8718\n",
      "Epoch 13/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2401 - accuracy: 0.8808 - val_loss: 0.2828 - val_accuracy: 0.8564\n",
      "Epoch 14/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 15/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2401 - accuracy: 0.8830 - val_loss: 0.2771 - val_accuracy: 0.8718\n",
      "Epoch 16/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2389 - accuracy: 0.8808 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 17/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2816 - val_accuracy: 0.8718\n",
      "Epoch 18/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 19/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2429 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 20/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2434 - accuracy: 0.8830 - val_loss: 0.2803 - val_accuracy: 0.8718\n",
      "Epoch 21/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 22/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2360 - accuracy: 0.8830 - val_loss: 0.2825 - val_accuracy: 0.8718\n",
      "Epoch 23/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2790 - val_accuracy: 0.8718\n",
      "Epoch 24/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2442 - accuracy: 0.8720 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 25/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2872 - val_accuracy: 0.8718\n",
      "Epoch 26/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2447 - accuracy: 0.8808 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 27/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2807 - val_accuracy: 0.8718\n",
      "Epoch 28/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2813 - val_accuracy: 0.8718\n",
      "Epoch 29/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2875 - val_accuracy: 0.8718\n",
      "Epoch 30/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2824 - val_accuracy: 0.8718\n",
      "Epoch 31/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2780 - val_accuracy: 0.8718\n",
      "Epoch 32/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2383 - accuracy: 0.8830 - val_loss: 0.2761 - val_accuracy: 0.8718\n",
      "Epoch 33/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2365 - accuracy: 0.8786 - val_loss: 0.2768 - val_accuracy: 0.8718\n",
      "Epoch 34/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2783 - val_accuracy: 0.8718\n",
      "Epoch 35/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2394 - accuracy: 0.8786 - val_loss: 0.2913 - val_accuracy: 0.8718\n",
      "Epoch 36/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2885 - val_accuracy: 0.8718\n",
      "Epoch 37/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2760 - val_accuracy: 0.8718\n",
      "Epoch 38/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2388 - accuracy: 0.8830 - val_loss: 0.2783 - val_accuracy: 0.8718\n",
      "Epoch 39/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 40/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2779 - val_accuracy: 0.8718\n",
      "Epoch 41/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2408 - accuracy: 0.8764 - val_loss: 0.2759 - val_accuracy: 0.8718\n",
      "Epoch 42/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2395 - accuracy: 0.8852 - val_loss: 0.2792 - val_accuracy: 0.8718\n",
      "Epoch 43/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 44/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.2780 - val_accuracy: 0.8718\n",
      "Epoch 45/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2887 - val_accuracy: 0.8718\n",
      "Epoch 46/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2871 - val_accuracy: 0.8564\n",
      "Epoch 47/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2499 - accuracy: 0.8786 - val_loss: 0.2992 - val_accuracy: 0.8718\n",
      "Epoch 48/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2552 - accuracy: 0.8256 - val_loss: 0.2757 - val_accuracy: 0.8718\n",
      "Epoch 49/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2430 - accuracy: 0.8808 - val_loss: 0.2793 - val_accuracy: 0.8718\n",
      "Epoch 50/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2435 - accuracy: 0.8720 - val_loss: 0.2781 - val_accuracy: 0.8718\n",
      "Epoch 51/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2403 - accuracy: 0.8830 - val_loss: 0.2848 - val_accuracy: 0.8718\n",
      "Epoch 52/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2393 - accuracy: 0.8830 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 53/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2402 - accuracy: 0.8786 - val_loss: 0.2768 - val_accuracy: 0.8718\n",
      "Epoch 54/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2402 - accuracy: 0.8830 - val_loss: 0.2816 - val_accuracy: 0.8718\n",
      "Epoch 55/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2402 - accuracy: 0.8830 - val_loss: 0.2847 - val_accuracy: 0.8564\n",
      "Epoch 56/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2442 - accuracy: 0.8720 - val_loss: 0.2815 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2454 - accuracy: 0.8830 - val_loss: 0.2799 - val_accuracy: 0.8718\n",
      "Epoch 58/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2774 - val_accuracy: 0.8718\n",
      "Epoch 59/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2790 - val_accuracy: 0.8718\n",
      "Epoch 60/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.2825 - val_accuracy: 0.8718\n",
      "Epoch 61/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2760 - val_accuracy: 0.8718\n",
      "Epoch 62/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2463 - accuracy: 0.8764 - val_loss: 0.2785 - val_accuracy: 0.8718\n",
      "Epoch 63/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2772 - val_accuracy: 0.8718\n",
      "Epoch 64/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2814 - val_accuracy: 0.8718\n",
      "Epoch 65/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2850 - val_accuracy: 0.8718\n",
      "Epoch 66/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2777 - val_accuracy: 0.8718\n",
      "Epoch 67/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 68/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2492 - accuracy: 0.8521 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 69/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2812 - val_accuracy: 0.8718\n",
      "Epoch 70/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2393 - accuracy: 0.8742 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 71/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8718\n",
      "Epoch 72/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2866 - val_accuracy: 0.8718\n",
      "Epoch 73/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 74/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2432 - accuracy: 0.8742 - val_loss: 0.2831 - val_accuracy: 0.8718\n",
      "Epoch 75/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2397 - accuracy: 0.8830 - val_loss: 0.2831 - val_accuracy: 0.8718\n",
      "Epoch 76/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2416 - accuracy: 0.8786 - val_loss: 0.2782 - val_accuracy: 0.8718\n",
      "Epoch 77/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2832 - val_accuracy: 0.8718\n",
      "Epoch 78/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2839 - val_accuracy: 0.8718\n",
      "Epoch 79/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.2770 - val_accuracy: 0.8718\n",
      "Epoch 80/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 81/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2418 - accuracy: 0.8808 - val_loss: 0.2857 - val_accuracy: 0.8718\n",
      "Epoch 82/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2395 - accuracy: 0.8808 - val_loss: 0.2821 - val_accuracy: 0.8718\n",
      "Epoch 83/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2542 - accuracy: 0.8742 - val_loss: 0.2828 - val_accuracy: 0.8718\n",
      "Epoch 84/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2857 - val_accuracy: 0.8718\n",
      "Epoch 85/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2399 - accuracy: 0.8808 - val_loss: 0.2792 - val_accuracy: 0.8718\n",
      "Epoch 86/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2833 - val_accuracy: 0.8718\n",
      "Epoch 87/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2862 - val_accuracy: 0.8718\n",
      "Epoch 88/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2414 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 89/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2386 - accuracy: 0.8786 - val_loss: 0.2886 - val_accuracy: 0.8718\n",
      "Epoch 90/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2453 - accuracy: 0.8609 - val_loss: 0.2828 - val_accuracy: 0.8718\n",
      "Epoch 91/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 92/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2860 - val_accuracy: 0.8718\n",
      "Epoch 93/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2844 - val_accuracy: 0.8718\n",
      "Epoch 94/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2410 - accuracy: 0.8786 - val_loss: 0.2910 - val_accuracy: 0.8718\n",
      "Epoch 95/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8718\n",
      "Epoch 96/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2786 - val_accuracy: 0.8718\n",
      "Epoch 97/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2864 - val_accuracy: 0.8718\n",
      "Epoch 98/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2362 - accuracy: 0.8786 - val_loss: 0.2744 - val_accuracy: 0.8615\n",
      "Epoch 99/1000\n",
      "453/453 [==============================] - 0s 263us/step - loss: 0.2395 - accuracy: 0.8764 - val_loss: 0.2774 - val_accuracy: 0.8718\n",
      "Epoch 100/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2368 - accuracy: 0.8808 - val_loss: 0.2778 - val_accuracy: 0.8718\n",
      "Epoch 101/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2361 - accuracy: 0.8786 - val_loss: 0.2793 - val_accuracy: 0.8718\n",
      "Epoch 102/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 0.2936 - val_accuracy: 0.8564\n",
      "Epoch 103/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.2892 - val_accuracy: 0.8564\n",
      "Epoch 104/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2829 - val_accuracy: 0.8718\n",
      "Epoch 105/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2893 - val_accuracy: 0.8718\n",
      "Epoch 106/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 107/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2813 - val_accuracy: 0.8718\n",
      "Epoch 108/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 109/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.2776 - val_accuracy: 0.8769\n",
      "Epoch 110/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2416 - accuracy: 0.8764 - val_loss: 0.2789 - val_accuracy: 0.8615\n",
      "Epoch 111/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2399 - accuracy: 0.8830 - val_loss: 0.2807 - val_accuracy: 0.8615\n",
      "Epoch 112/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2390 - accuracy: 0.8764 - val_loss: 0.2778 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "453/453 [==============================] - 0s 226us/step - loss: 0.2345 - accuracy: 0.8808 - val_loss: 0.2807 - val_accuracy: 0.8718\n",
      "Epoch 114/1000\n",
      "453/453 [==============================] - 0s 248us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 115/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 116/1000\n",
      "453/453 [==============================] - 0s 596us/step - loss: 0.2419 - accuracy: 0.8830 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 117/1000\n",
      "453/453 [==============================] - 0s 160us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.2787 - val_accuracy: 0.8718\n",
      "Epoch 118/1000\n",
      "453/453 [==============================] - 0s 210us/step - loss: 0.2383 - accuracy: 0.8830 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 119/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 120/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2406 - accuracy: 0.8720 - val_loss: 0.2804 - val_accuracy: 0.8718\n",
      "Epoch 121/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2423 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 122/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 123/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2440 - accuracy: 0.8742 - val_loss: 0.2824 - val_accuracy: 0.8718\n",
      "Epoch 124/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2426 - accuracy: 0.8786 - val_loss: 0.2778 - val_accuracy: 0.8718\n",
      "Epoch 125/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2362 - accuracy: 0.8808 - val_loss: 0.2824 - val_accuracy: 0.8718\n",
      "Epoch 126/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 127/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 128/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 129/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2805 - val_accuracy: 0.8718\n",
      "Epoch 130/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2832 - val_accuracy: 0.8718\n",
      "Epoch 131/1000\n",
      "453/453 [==============================] - 0s 159us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2821 - val_accuracy: 0.8718\n",
      "Epoch 132/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8718\n",
      "Epoch 133/1000\n",
      "453/453 [==============================] - 0s 254us/step - loss: 0.2374 - accuracy: 0.8808 - val_loss: 0.2783 - val_accuracy: 0.8718\n",
      "Epoch 134/1000\n",
      "453/453 [==============================] - 0s 273us/step - loss: 0.2416 - accuracy: 0.8698 - val_loss: 0.2782 - val_accuracy: 0.8718\n",
      "Epoch 135/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2821 - val_accuracy: 0.8718\n",
      "Epoch 136/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2799 - val_accuracy: 0.8718\n",
      "Epoch 137/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2848 - val_accuracy: 0.8718\n",
      "Epoch 138/1000\n",
      "453/453 [==============================] - 0s 157us/step - loss: 0.2497 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 139/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2470 - accuracy: 0.8742 - val_loss: 0.2832 - val_accuracy: 0.8718\n",
      "Epoch 140/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 141/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2860 - val_accuracy: 0.8718\n",
      "Epoch 142/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 143/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2853 - val_accuracy: 0.8718\n",
      "Epoch 144/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8718\n",
      "Epoch 145/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2369 - accuracy: 0.8830 - val_loss: 0.2885 - val_accuracy: 0.8718\n",
      "Epoch 146/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.2795 - val_accuracy: 0.8718\n",
      "Epoch 147/1000\n",
      "453/453 [==============================] - 0s 185us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 148/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 149/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2834 - val_accuracy: 0.8718\n",
      "Epoch 150/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 151/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 152/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2407 - accuracy: 0.8764 - val_loss: 0.2896 - val_accuracy: 0.8718\n",
      "Epoch 153/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2827 - val_accuracy: 0.8718\n",
      "Epoch 154/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 155/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2427 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 156/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2779 - val_accuracy: 0.8718\n",
      "Epoch 157/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2413 - accuracy: 0.8808 - val_loss: 0.2779 - val_accuracy: 0.8718\n",
      "Epoch 158/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2805 - val_accuracy: 0.8718\n",
      "Epoch 159/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8718\n",
      "Epoch 160/1000\n",
      "453/453 [==============================] - 0s 202us/step - loss: 0.2392 - accuracy: 0.8808 - val_loss: 0.2798 - val_accuracy: 0.8769\n",
      "Epoch 161/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 162/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 163/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 164/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2414 - accuracy: 0.8808 - val_loss: 0.2807 - val_accuracy: 0.8769\n",
      "Epoch 165/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2368 - accuracy: 0.8830 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 166/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 167/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.2813 - val_accuracy: 0.8718\n",
      "Epoch 168/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2399 - accuracy: 0.8830 - val_loss: 0.2799 - val_accuracy: 0.8718\n",
      "Epoch 169/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2816 - val_accuracy: 0.8718\n",
      "Epoch 170/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2361 - accuracy: 0.8808 - val_loss: 0.2833 - val_accuracy: 0.8718\n",
      "Epoch 171/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 172/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2835 - val_accuracy: 0.8718\n",
      "Epoch 173/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2398 - accuracy: 0.8808 - val_loss: 0.2860 - val_accuracy: 0.8718\n",
      "Epoch 174/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 175/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2848 - val_accuracy: 0.8718\n",
      "Epoch 176/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2397 - accuracy: 0.8808 - val_loss: 0.2853 - val_accuracy: 0.8564\n",
      "Epoch 177/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 178/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2755 - val_accuracy: 0.8718\n",
      "Epoch 179/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2416 - accuracy: 0.8764 - val_loss: 0.2792 - val_accuracy: 0.8718\n",
      "Epoch 180/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.2802 - val_accuracy: 0.8718\n",
      "Epoch 181/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2393 - accuracy: 0.8808 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 182/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2369 - accuracy: 0.8808 - val_loss: 0.2817 - val_accuracy: 0.8718\n",
      "Epoch 183/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 184/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2405 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8718\n",
      "Epoch 185/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2950 - val_accuracy: 0.8718\n",
      "Epoch 186/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2409 - accuracy: 0.8830 - val_loss: 0.2817 - val_accuracy: 0.8718\n",
      "Epoch 187/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2347 - accuracy: 0.8764 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 188/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2392 - accuracy: 0.8830 - val_loss: 0.2782 - val_accuracy: 0.8718\n",
      "Epoch 189/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2787 - val_accuracy: 0.8718\n",
      "Epoch 190/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2411 - accuracy: 0.8720 - val_loss: 0.2796 - val_accuracy: 0.8718\n",
      "Epoch 191/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2425 - accuracy: 0.8830 - val_loss: 0.2895 - val_accuracy: 0.8718\n",
      "Epoch 192/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2833 - val_accuracy: 0.8718\n",
      "Epoch 193/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2380 - accuracy: 0.8830 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 194/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2847 - val_accuracy: 0.8718\n",
      "Epoch 195/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2367 - accuracy: 0.8830 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 196/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2852 - val_accuracy: 0.8718\n",
      "Epoch 197/1000\n",
      "453/453 [==============================] - 0s 205us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2804 - val_accuracy: 0.8718\n",
      "Epoch 198/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2902 - val_accuracy: 0.8718\n",
      "Epoch 199/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2775 - val_accuracy: 0.8769\n",
      "Epoch 200/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2795 - val_accuracy: 0.8718\n",
      "Epoch 201/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2825 - val_accuracy: 0.8718\n",
      "Epoch 202/1000\n",
      "453/453 [==============================] - 0s 191us/step - loss: 0.2389 - accuracy: 0.8764 - val_loss: 0.2852 - val_accuracy: 0.8564\n",
      "Epoch 203/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2372 - accuracy: 0.8808 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 204/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2392 - accuracy: 0.8786 - val_loss: 0.2925 - val_accuracy: 0.8718\n",
      "Epoch 205/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 206/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2899 - val_accuracy: 0.8718\n",
      "Epoch 207/1000\n",
      "453/453 [==============================] - 0s 190us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2813 - val_accuracy: 0.8718\n",
      "Epoch 208/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2384 - accuracy: 0.8786 - val_loss: 0.2910 - val_accuracy: 0.8718\n",
      "Epoch 209/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 210/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2422 - accuracy: 0.8830 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 211/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2932 - val_accuracy: 0.8718\n",
      "Epoch 212/1000\n",
      "453/453 [==============================] - 0s 308us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2796 - val_accuracy: 0.8718\n",
      "Epoch 213/1000\n",
      "453/453 [==============================] - 0s 393us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2836 - val_accuracy: 0.8718\n",
      "Epoch 214/1000\n",
      "453/453 [==============================] - 0s 296us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 215/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2384 - accuracy: 0.8720 - val_loss: 0.2794 - val_accuracy: 0.8718\n",
      "Epoch 216/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2351 - accuracy: 0.8786 - val_loss: 0.2770 - val_accuracy: 0.8718\n",
      "Epoch 217/1000\n",
      "453/453 [==============================] - 0s 166us/step - loss: 0.2364 - accuracy: 0.8764 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 218/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2868 - val_accuracy: 0.8718\n",
      "Epoch 219/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2389 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 220/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.2818 - val_accuracy: 0.8718\n",
      "Epoch 221/1000\n",
      "453/453 [==============================] - 0s 162us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2897 - val_accuracy: 0.8718\n",
      "Epoch 222/1000\n",
      "453/453 [==============================] - 0s 149us/step - loss: 0.2360 - accuracy: 0.8830 - val_loss: 0.2888 - val_accuracy: 0.8718\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 124us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2824 - val_accuracy: 0.8718\n",
      "Epoch 224/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 225/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2796 - val_accuracy: 0.8718\n",
      "Epoch 226/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 227/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2885 - val_accuracy: 0.8718\n",
      "Epoch 228/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 229/1000\n",
      "453/453 [==============================] - 0s 193us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2832 - val_accuracy: 0.8718\n",
      "Epoch 230/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2824 - val_accuracy: 0.8718\n",
      "Epoch 231/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2402 - accuracy: 0.8830 - val_loss: 0.2839 - val_accuracy: 0.8718\n",
      "Epoch 232/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 233/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 234/1000\n",
      "453/453 [==============================] - 0s 195us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2929 - val_accuracy: 0.8718\n",
      "Epoch 235/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.2787 - val_accuracy: 0.8718\n",
      "Epoch 236/1000\n",
      "453/453 [==============================] - 0s 139us/step - loss: 0.2412 - accuracy: 0.8786 - val_loss: 0.2875 - val_accuracy: 0.8718\n",
      "Epoch 237/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8718\n",
      "Epoch 238/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2393 - accuracy: 0.8720 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 239/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 240/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2899 - val_accuracy: 0.8718\n",
      "Epoch 241/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2377 - accuracy: 0.8786 - val_loss: 0.2816 - val_accuracy: 0.8718\n",
      "Epoch 242/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.2795 - val_accuracy: 0.8718\n",
      "Epoch 243/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2402 - accuracy: 0.8786 - val_loss: 0.2873 - val_accuracy: 0.8769\n",
      "Epoch 244/1000\n",
      "453/453 [==============================] - 0s 163us/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 245/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 246/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2827 - val_accuracy: 0.8718\n",
      "Epoch 247/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 0.2933 - val_accuracy: 0.8769\n",
      "Epoch 248/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.2853 - val_accuracy: 0.8718\n",
      "Epoch 249/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8718\n",
      "Epoch 250/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2807 - val_accuracy: 0.8718\n",
      "Epoch 251/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 252/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2365 - accuracy: 0.8764 - val_loss: 0.2843 - val_accuracy: 0.8718\n",
      "Epoch 253/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2834 - val_accuracy: 0.8718\n",
      "Epoch 254/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2854 - val_accuracy: 0.8718\n",
      "Epoch 255/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2357 - accuracy: 0.8786 - val_loss: 0.2841 - val_accuracy: 0.8718\n",
      "Epoch 256/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.2839 - val_accuracy: 0.8718\n",
      "Epoch 257/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2400 - accuracy: 0.8675 - val_loss: 0.2776 - val_accuracy: 0.8718\n",
      "Epoch 258/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2417 - accuracy: 0.8742 - val_loss: 0.2754 - val_accuracy: 0.8718\n",
      "Epoch 259/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2909 - val_accuracy: 0.8718\n",
      "Epoch 260/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.2810 - val_accuracy: 0.8718\n",
      "Epoch 261/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 262/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2364 - accuracy: 0.8808 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 263/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2445 - accuracy: 0.8565 - val_loss: 0.2826 - val_accuracy: 0.8718\n",
      "Epoch 264/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2571 - accuracy: 0.8786 - val_loss: 0.2783 - val_accuracy: 0.8718\n",
      "Epoch 265/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2792 - val_accuracy: 0.8718\n",
      "Epoch 266/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2790 - val_accuracy: 0.8718\n",
      "Epoch 267/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 268/1000\n",
      "453/453 [==============================] - 0s 204us/step - loss: 0.2378 - accuracy: 0.8830 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 269/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 270/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2786 - val_accuracy: 0.8718\n",
      "Epoch 271/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 272/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2401 - accuracy: 0.8764 - val_loss: 0.2880 - val_accuracy: 0.8718\n",
      "Epoch 273/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2825 - val_accuracy: 0.8718\n",
      "Epoch 274/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2811 - val_accuracy: 0.8718\n",
      "Epoch 275/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 276/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 277/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2397 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8718\n",
      "Epoch 278/1000\n",
      "453/453 [==============================] - 0s 96us/step - loss: 0.2458 - accuracy: 0.8830 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 279/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 280/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 281/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 282/1000\n",
      "453/453 [==============================] - 0s 141us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2770 - val_accuracy: 0.8718\n",
      "Epoch 283/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 284/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 285/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2847 - val_accuracy: 0.8718\n",
      "Epoch 286/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 287/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8718\n",
      "Epoch 288/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 289/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 290/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2856 - val_accuracy: 0.8718\n",
      "Epoch 291/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2385 - accuracy: 0.8808 - val_loss: 0.2811 - val_accuracy: 0.8769\n",
      "Epoch 292/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2393 - accuracy: 0.8852 - val_loss: 0.2891 - val_accuracy: 0.8718\n",
      "Epoch 293/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2790 - val_accuracy: 0.8718\n",
      "Epoch 294/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2874 - val_accuracy: 0.8718\n",
      "Epoch 295/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2400 - accuracy: 0.8830 - val_loss: 0.2791 - val_accuracy: 0.8615\n",
      "Epoch 296/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2368 - accuracy: 0.8764 - val_loss: 0.2880 - val_accuracy: 0.8718\n",
      "Epoch 297/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8718\n",
      "Epoch 298/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2349 - accuracy: 0.8830 - val_loss: 0.2827 - val_accuracy: 0.8718\n",
      "Epoch 299/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2816 - val_accuracy: 0.8718\n",
      "Epoch 300/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 301/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2829 - val_accuracy: 0.8718\n",
      "Epoch 302/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2371 - accuracy: 0.8764 - val_loss: 0.2788 - val_accuracy: 0.8718\n",
      "Epoch 303/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2832 - val_accuracy: 0.8718\n",
      "Epoch 304/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2785 - val_accuracy: 0.8769\n",
      "Epoch 305/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2404 - accuracy: 0.8830 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
      "Epoch 306/1000\n",
      "453/453 [==============================] - 0s 168us/step - loss: 0.2411 - accuracy: 0.8852 - val_loss: 0.2899 - val_accuracy: 0.8718\n",
      "Epoch 307/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 308/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2909 - val_accuracy: 0.8718\n",
      "Epoch 309/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2360 - accuracy: 0.8830 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 310/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2391 - accuracy: 0.8808 - val_loss: 0.2800 - val_accuracy: 0.8718\n",
      "Epoch 311/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2873 - val_accuracy: 0.8718\n",
      "Epoch 312/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2367 - accuracy: 0.8808 - val_loss: 0.2914 - val_accuracy: 0.8564\n",
      "Epoch 313/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2392 - accuracy: 0.8764 - val_loss: 0.2873 - val_accuracy: 0.8564\n",
      "Epoch 314/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2376 - accuracy: 0.8808 - val_loss: 0.2789 - val_accuracy: 0.8718\n",
      "Epoch 315/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 316/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2387 - accuracy: 0.8808 - val_loss: 0.2784 - val_accuracy: 0.8718\n",
      "Epoch 317/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2419 - accuracy: 0.8808 - val_loss: 0.2828 - val_accuracy: 0.8718\n",
      "Epoch 318/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2815 - val_accuracy: 0.8718\n",
      "Epoch 319/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2441 - accuracy: 0.8764 - val_loss: 0.2781 - val_accuracy: 0.8718\n",
      "Epoch 320/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 321/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2908 - val_accuracy: 0.8718\n",
      "Epoch 322/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2890 - val_accuracy: 0.8718\n",
      "Epoch 323/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 324/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2831 - val_accuracy: 0.8718\n",
      "Epoch 325/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2397 - accuracy: 0.8764 - val_loss: 0.2817 - val_accuracy: 0.8718\n",
      "Epoch 326/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2349 - accuracy: 0.8786 - val_loss: 0.2857 - val_accuracy: 0.8769\n",
      "Epoch 327/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2373 - accuracy: 0.8808 - val_loss: 0.2830 - val_accuracy: 0.8718\n",
      "Epoch 328/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2383 - accuracy: 0.8786 - val_loss: 0.2868 - val_accuracy: 0.8718\n",
      "Epoch 329/1000\n",
      "453/453 [==============================] - 0s 246us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2870 - val_accuracy: 0.8718\n",
      "Epoch 330/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 331/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2896 - val_accuracy: 0.8718\n",
      "Epoch 332/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2351 - accuracy: 0.8808 - val_loss: 0.2912 - val_accuracy: 0.8564\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 91us/step - loss: 0.2374 - accuracy: 0.8786 - val_loss: 0.2900 - val_accuracy: 0.8718\n",
      "Epoch 334/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8718\n",
      "Epoch 335/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2924 - val_accuracy: 0.8718\n",
      "Epoch 336/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2418 - accuracy: 0.8830 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 337/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2385 - accuracy: 0.8742 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 338/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2332 - accuracy: 0.8764 - val_loss: 0.2817 - val_accuracy: 0.8718\n",
      "Epoch 339/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2894 - val_accuracy: 0.8718\n",
      "Epoch 340/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2812 - val_accuracy: 0.8718\n",
      "Epoch 341/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2835 - val_accuracy: 0.8718\n",
      "Epoch 342/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2901 - val_accuracy: 0.8718\n",
      "Epoch 343/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2888 - val_accuracy: 0.8718\n",
      "Epoch 344/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 345/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 346/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2828 - val_accuracy: 0.8718\n",
      "Epoch 347/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 348/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2352 - accuracy: 0.8786 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 349/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2394 - accuracy: 0.8808 - val_loss: 0.2827 - val_accuracy: 0.8718\n",
      "Epoch 350/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 351/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2952 - val_accuracy: 0.8718\n",
      "Epoch 352/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 353/1000\n",
      "453/453 [==============================] - 0s 169us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 354/1000\n",
      "453/453 [==============================] - 0s 153us/step - loss: 0.2407 - accuracy: 0.8830 - val_loss: 0.2836 - val_accuracy: 0.8718\n",
      "Epoch 355/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 356/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2430 - accuracy: 0.8742 - val_loss: 0.2813 - val_accuracy: 0.8718\n",
      "Epoch 357/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2827 - val_accuracy: 0.8718\n",
      "Epoch 358/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2803 - val_accuracy: 0.8718\n",
      "Epoch 359/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2858 - val_accuracy: 0.8718\n",
      "Epoch 360/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 361/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 362/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 363/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2419 - accuracy: 0.8675 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 364/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2396 - accuracy: 0.8830 - val_loss: 0.2866 - val_accuracy: 0.8718\n",
      "Epoch 365/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2901 - val_accuracy: 0.8718\n",
      "Epoch 366/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2893 - val_accuracy: 0.8718\n",
      "Epoch 367/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 368/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2387 - accuracy: 0.8830 - val_loss: 0.2838 - val_accuracy: 0.8718\n",
      "Epoch 369/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 370/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2896 - val_accuracy: 0.8718\n",
      "Epoch 371/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2386 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 372/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 373/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2879 - val_accuracy: 0.8718\n",
      "Epoch 374/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 375/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2895 - val_accuracy: 0.8718\n",
      "Epoch 376/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 377/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 378/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.2803 - val_accuracy: 0.8718\n",
      "Epoch 379/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2850 - val_accuracy: 0.8718\n",
      "Epoch 380/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2395 - accuracy: 0.8808 - val_loss: 0.2968 - val_accuracy: 0.8718\n",
      "Epoch 381/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 382/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2360 - accuracy: 0.8830 - val_loss: 0.2945 - val_accuracy: 0.8718\n",
      "Epoch 383/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2410 - accuracy: 0.8896 - val_loss: 0.2899 - val_accuracy: 0.8718\n",
      "Epoch 384/1000\n",
      "453/453 [==============================] - 0s 213us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2830 - val_accuracy: 0.8718\n",
      "Epoch 385/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2433 - accuracy: 0.8786 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 386/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2443 - accuracy: 0.8543 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 387/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2407 - accuracy: 0.8786 - val_loss: 0.2915 - val_accuracy: 0.8718\n",
      "Epoch 388/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2372 - accuracy: 0.8830 - val_loss: 0.2912 - val_accuracy: 0.8718\n",
      "Epoch 389/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2347 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8718\n",
      "Epoch 390/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2949 - val_accuracy: 0.8718\n",
      "Epoch 391/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2874 - val_accuracy: 0.8718\n",
      "Epoch 392/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2835 - val_accuracy: 0.8718\n",
      "Epoch 393/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2891 - val_accuracy: 0.8718\n",
      "Epoch 394/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 395/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.2953 - val_accuracy: 0.8718\n",
      "Epoch 396/1000\n",
      "453/453 [==============================] - 0s 187us/step - loss: 0.2319 - accuracy: 0.8830 - val_loss: 0.2808 - val_accuracy: 0.8718\n",
      "Epoch 397/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 398/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2352 - accuracy: 0.8808 - val_loss: 0.2903 - val_accuracy: 0.8769\n",
      "Epoch 399/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2395 - accuracy: 0.8808 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 400/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2883 - val_accuracy: 0.8718\n",
      "Epoch 401/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2785 - val_accuracy: 0.8718\n",
      "Epoch 402/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2354 - accuracy: 0.8786 - val_loss: 0.2809 - val_accuracy: 0.8718\n",
      "Epoch 403/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2442 - accuracy: 0.8675 - val_loss: 0.2842 - val_accuracy: 0.8718\n",
      "Epoch 404/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.2851 - val_accuracy: 0.8769\n",
      "Epoch 405/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.2951 - val_accuracy: 0.8718\n",
      "Epoch 406/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 407/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2891 - val_accuracy: 0.8718\n",
      "Epoch 408/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2340 - accuracy: 0.8830 - val_loss: 0.2933 - val_accuracy: 0.8718\n",
      "Epoch 409/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.2844 - val_accuracy: 0.8718\n",
      "Epoch 410/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2883 - val_accuracy: 0.8718\n",
      "Epoch 411/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2841 - val_accuracy: 0.8718\n",
      "Epoch 412/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2405 - accuracy: 0.8852 - val_loss: 0.2829 - val_accuracy: 0.8718\n",
      "Epoch 413/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2472 - accuracy: 0.8786 - val_loss: 0.2806 - val_accuracy: 0.8718\n",
      "Epoch 414/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 415/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2875 - val_accuracy: 0.8718\n",
      "Epoch 416/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8718\n",
      "Epoch 417/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2419 - accuracy: 0.8830 - val_loss: 0.2835 - val_accuracy: 0.8718\n",
      "Epoch 418/1000\n",
      "453/453 [==============================] - 0s 161us/step - loss: 0.2349 - accuracy: 0.8808 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 419/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2359 - accuracy: 0.8786 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 420/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2858 - val_accuracy: 0.8718\n",
      "Epoch 421/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 422/1000\n",
      "453/453 [==============================] - 0s 115us/step - loss: 0.2456 - accuracy: 0.8499 - val_loss: 0.2829 - val_accuracy: 0.8718\n",
      "Epoch 423/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 424/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2381 - accuracy: 0.8830 - val_loss: 0.2861 - val_accuracy: 0.8718\n",
      "Epoch 425/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2363 - accuracy: 0.8830 - val_loss: 0.2875 - val_accuracy: 0.8718\n",
      "Epoch 426/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2870 - val_accuracy: 0.8718\n",
      "Epoch 427/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2841 - val_accuracy: 0.8718\n",
      "Epoch 428/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 429/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 430/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2488 - accuracy: 0.8764 - val_loss: 0.2913 - val_accuracy: 0.8718\n",
      "Epoch 431/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2419 - accuracy: 0.8653 - val_loss: 0.2913 - val_accuracy: 0.8718\n",
      "Epoch 432/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2377 - accuracy: 0.8830 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 433/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 434/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2985 - val_accuracy: 0.8718\n",
      "Epoch 435/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2355 - accuracy: 0.8830 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 436/1000\n",
      "453/453 [==============================] - 0s 90us/step - loss: 0.2389 - accuracy: 0.8896 - val_loss: 0.2898 - val_accuracy: 0.8718\n",
      "Epoch 437/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8718\n",
      "Epoch 438/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2385 - accuracy: 0.8830 - val_loss: 0.2821 - val_accuracy: 0.8718\n",
      "Epoch 439/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2426 - accuracy: 0.8786 - val_loss: 0.2860 - val_accuracy: 0.8718\n",
      "Epoch 440/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2312 - accuracy: 0.8830 - val_loss: 0.2988 - val_accuracy: 0.8718\n",
      "Epoch 441/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2906 - val_accuracy: 0.8718\n",
      "Epoch 442/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2955 - val_accuracy: 0.8718\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 85us/step - loss: 0.2371 - accuracy: 0.8830 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 444/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 445/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2830 - val_accuracy: 0.8718\n",
      "Epoch 446/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2830 - val_accuracy: 0.8718\n",
      "Epoch 447/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2342 - accuracy: 0.8786 - val_loss: 0.2879 - val_accuracy: 0.8718\n",
      "Epoch 448/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 449/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2406 - accuracy: 0.8830 - val_loss: 0.2870 - val_accuracy: 0.8718\n",
      "Epoch 450/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2474 - accuracy: 0.8742 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 451/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2923 - val_accuracy: 0.8718\n",
      "Epoch 452/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2876 - val_accuracy: 0.8718\n",
      "Epoch 453/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2929 - val_accuracy: 0.8718\n",
      "Epoch 454/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2423 - accuracy: 0.8808 - val_loss: 0.2860 - val_accuracy: 0.8769\n",
      "Epoch 455/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2906 - val_accuracy: 0.8718\n",
      "Epoch 456/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2463 - accuracy: 0.8433 - val_loss: 0.2926 - val_accuracy: 0.8718\n",
      "Epoch 457/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 0.2872 - val_accuracy: 0.8718\n",
      "Epoch 458/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2382 - accuracy: 0.8830 - val_loss: 0.2884 - val_accuracy: 0.8718\n",
      "Epoch 459/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 460/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2447 - accuracy: 0.8808 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 461/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2411 - accuracy: 0.8742 - val_loss: 0.2847 - val_accuracy: 0.8718\n",
      "Epoch 462/1000\n",
      "453/453 [==============================] - 0s 97us/step - loss: 0.2474 - accuracy: 0.8521 - val_loss: 0.2869 - val_accuracy: 0.8718\n",
      "Epoch 463/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.2836 - val_accuracy: 0.8769\n",
      "Epoch 464/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2866 - val_accuracy: 0.8718\n",
      "Epoch 465/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2344 - accuracy: 0.8786 - val_loss: 0.2831 - val_accuracy: 0.8718\n",
      "Epoch 466/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 467/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2775 - val_accuracy: 0.8718\n",
      "Epoch 468/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2450 - accuracy: 0.8830 - val_loss: 0.2801 - val_accuracy: 0.8718\n",
      "Epoch 469/1000\n",
      "453/453 [==============================] - 0s 182us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2897 - val_accuracy: 0.8718\n",
      "Epoch 470/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2370 - accuracy: 0.8808 - val_loss: 0.2965 - val_accuracy: 0.8615\n",
      "Epoch 471/1000\n",
      "453/453 [==============================] - 0s 230us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2968 - val_accuracy: 0.8615\n",
      "Epoch 472/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2354 - accuracy: 0.8808 - val_loss: 0.2936 - val_accuracy: 0.8718\n",
      "Epoch 473/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2848 - val_accuracy: 0.8718\n",
      "Epoch 474/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.3013 - val_accuracy: 0.8718\n",
      "Epoch 475/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2955 - val_accuracy: 0.8718\n",
      "Epoch 476/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2855 - val_accuracy: 0.8718\n",
      "Epoch 477/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2923 - val_accuracy: 0.8718\n",
      "Epoch 478/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2352 - accuracy: 0.8830 - val_loss: 0.2861 - val_accuracy: 0.8718\n",
      "Epoch 479/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2913 - val_accuracy: 0.8718\n",
      "Epoch 480/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2873 - val_accuracy: 0.8718\n",
      "Epoch 481/1000\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.81 - 0s 84us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2866 - val_accuracy: 0.8718\n",
      "Epoch 482/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2863 - val_accuracy: 0.8718\n",
      "Epoch 483/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2881 - val_accuracy: 0.8718\n",
      "Epoch 484/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2346 - accuracy: 0.8808 - val_loss: 0.2915 - val_accuracy: 0.8718\n",
      "Epoch 485/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 486/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 487/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2375 - accuracy: 0.8830 - val_loss: 0.2948 - val_accuracy: 0.8718\n",
      "Epoch 488/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2302 - accuracy: 0.8830 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 489/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 490/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2877 - val_accuracy: 0.8718\n",
      "Epoch 491/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2359 - accuracy: 0.8830 - val_loss: 0.2942 - val_accuracy: 0.8718\n",
      "Epoch 492/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2353 - accuracy: 0.8786 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 493/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2373 - accuracy: 0.8830 - val_loss: 0.2855 - val_accuracy: 0.8718\n",
      "Epoch 494/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2912 - val_accuracy: 0.8718\n",
      "Epoch 495/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2843 - val_accuracy: 0.8718\n",
      "Epoch 496/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2391 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 497/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2338 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8718\n",
      "Epoch 498/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2955 - val_accuracy: 0.8718\n",
      "Epoch 499/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2364 - accuracy: 0.8830 - val_loss: 0.2872 - val_accuracy: 0.8718\n",
      "Epoch 500/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2335 - accuracy: 0.8786 - val_loss: 0.2887 - val_accuracy: 0.8718\n",
      "Epoch 501/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2841 - val_accuracy: 0.8718\n",
      "Epoch 502/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2354 - accuracy: 0.8808 - val_loss: 0.2915 - val_accuracy: 0.8769\n",
      "Epoch 503/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2399 - accuracy: 0.8808 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 504/1000\n",
      "453/453 [==============================] - 0s 85us/step - loss: 0.2434 - accuracy: 0.8698 - val_loss: 0.2847 - val_accuracy: 0.8615\n",
      "Epoch 505/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2331 - accuracy: 0.8808 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 506/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2334 - accuracy: 0.8830 - val_loss: 0.2818 - val_accuracy: 0.8769\n",
      "Epoch 507/1000\n",
      "453/453 [==============================] - 0s 88us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2857 - val_accuracy: 0.8718\n",
      "Epoch 508/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2909 - val_accuracy: 0.8718\n",
      "Epoch 509/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2350 - accuracy: 0.8830 - val_loss: 0.2872 - val_accuracy: 0.8718\n",
      "Epoch 510/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2341 - accuracy: 0.8830 - val_loss: 0.2938 - val_accuracy: 0.8769\n",
      "Epoch 511/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 512/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.2914 - val_accuracy: 0.8718\n",
      "Epoch 513/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8718\n",
      "Epoch 514/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2856 - val_accuracy: 0.8718\n",
      "Epoch 515/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2358 - accuracy: 0.8852 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 516/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2384 - accuracy: 0.8742 - val_loss: 0.2888 - val_accuracy: 0.8769\n",
      "Epoch 517/1000\n",
      "453/453 [==============================] - 0s 86us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 518/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2404 - accuracy: 0.8852 - val_loss: 0.2867 - val_accuracy: 0.8769\n",
      "Epoch 519/1000\n",
      "453/453 [==============================] - 0s 142us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2909 - val_accuracy: 0.8718\n",
      "Epoch 520/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8769\n",
      "Epoch 521/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 522/1000\n",
      "453/453 [==============================] - 0s 104us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2911 - val_accuracy: 0.8718\n",
      "Epoch 523/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 0.2951 - val_accuracy: 0.8718\n",
      "Epoch 524/1000\n",
      "453/453 [==============================] - 0s 105us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2860 - val_accuracy: 0.8769\n",
      "Epoch 525/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.2915 - val_accuracy: 0.8718\n",
      "Epoch 526/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2881 - val_accuracy: 0.8769\n",
      "Epoch 527/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 0.2901 - val_accuracy: 0.8718\n",
      "Epoch 528/1000\n",
      "453/453 [==============================] - 0s 106us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 529/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2351 - accuracy: 0.8830 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 530/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 531/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2390 - accuracy: 0.8852 - val_loss: 0.2947 - val_accuracy: 0.8769\n",
      "Epoch 532/1000\n",
      "453/453 [==============================] - 0s 276us/step - loss: 0.2392 - accuracy: 0.8764 - val_loss: 0.2904 - val_accuracy: 0.8718\n",
      "Epoch 533/1000\n",
      "453/453 [==============================] - 0s 307us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 0.2820 - val_accuracy: 0.8718\n",
      "Epoch 534/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2987 - val_accuracy: 0.8769\n",
      "Epoch 535/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 0.2916 - val_accuracy: 0.8769\n",
      "Epoch 536/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2340 - accuracy: 0.8874 - val_loss: 0.2849 - val_accuracy: 0.8718\n",
      "Epoch 537/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 538/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2433 - accuracy: 0.8786 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 539/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2318 - accuracy: 0.8830 - val_loss: 0.2933 - val_accuracy: 0.8769\n",
      "Epoch 540/1000\n",
      "453/453 [==============================] - 0s 192us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2880 - val_accuracy: 0.8769\n",
      "Epoch 541/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2339 - accuracy: 0.8786 - val_loss: 0.2847 - val_accuracy: 0.8769\n",
      "Epoch 542/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2907 - val_accuracy: 0.8718\n",
      "Epoch 543/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.2894 - val_accuracy: 0.8769\n",
      "Epoch 544/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2326 - accuracy: 0.8830 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 545/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2334 - accuracy: 0.8808 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 546/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2349 - accuracy: 0.8764 - val_loss: 0.2929 - val_accuracy: 0.8718\n",
      "Epoch 547/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2381 - accuracy: 0.8808 - val_loss: 0.2902 - val_accuracy: 0.8769\n",
      "Epoch 548/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2422 - accuracy: 0.8786 - val_loss: 0.2887 - val_accuracy: 0.8718\n",
      "Epoch 549/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2943 - val_accuracy: 0.8769\n",
      "Epoch 550/1000\n",
      "453/453 [==============================] - 0s 117us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 551/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 0.2927 - val_accuracy: 0.8718\n",
      "Epoch 552/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.2891 - val_accuracy: 0.8718\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 110us/step - loss: 0.2529 - accuracy: 0.8786 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 554/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2445 - accuracy: 0.8830 - val_loss: 0.2948 - val_accuracy: 0.8769\n",
      "Epoch 555/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2417 - accuracy: 0.8830 - val_loss: 0.2982 - val_accuracy: 0.8718\n",
      "Epoch 556/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 0.2862 - val_accuracy: 0.8769\n",
      "Epoch 557/1000\n",
      "453/453 [==============================] - 0s 167us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2887 - val_accuracy: 0.8718\n",
      "Epoch 558/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 0.2960 - val_accuracy: 0.8718\n",
      "Epoch 559/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2371 - accuracy: 0.8808 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 560/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2332 - accuracy: 0.8808 - val_loss: 0.2852 - val_accuracy: 0.8718\n",
      "Epoch 561/1000\n",
      "453/453 [==============================] - 0s 172us/step - loss: 0.2386 - accuracy: 0.8852 - val_loss: 0.2906 - val_accuracy: 0.8718\n",
      "Epoch 562/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2395 - accuracy: 0.8808 - val_loss: 0.2852 - val_accuracy: 0.8718\n",
      "Epoch 563/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2859 - val_accuracy: 0.8718\n",
      "Epoch 564/1000\n",
      "453/453 [==============================] - 0s 209us/step - loss: 0.2316 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8718\n",
      "Epoch 565/1000\n",
      "453/453 [==============================] - 0s 171us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.2980 - val_accuracy: 0.8769\n",
      "Epoch 566/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 567/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2411 - accuracy: 0.8742 - val_loss: 0.2920 - val_accuracy: 0.8718\n",
      "Epoch 568/1000\n",
      "453/453 [==============================] - 0s 229us/step - loss: 0.2336 - accuracy: 0.8830 - val_loss: 0.2900 - val_accuracy: 0.8769\n",
      "Epoch 569/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2915 - val_accuracy: 0.8769\n",
      "Epoch 570/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.2959 - val_accuracy: 0.8769\n",
      "Epoch 571/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.2895 - val_accuracy: 0.8769\n",
      "Epoch 572/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 573/1000\n",
      "453/453 [==============================] - 0s 131us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 574/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2376 - accuracy: 0.8764 - val_loss: 0.2929 - val_accuracy: 0.8769\n",
      "Epoch 575/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2407 - accuracy: 0.8786 - val_loss: 0.2897 - val_accuracy: 0.8769\n",
      "Epoch 576/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2342 - accuracy: 0.8808 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 577/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2356 - accuracy: 0.8830 - val_loss: 0.2867 - val_accuracy: 0.8718\n",
      "Epoch 578/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2325 - accuracy: 0.8830 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 579/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2335 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 580/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 0.2971 - val_accuracy: 0.8769\n",
      "Epoch 581/1000\n",
      "453/453 [==============================] - 0s 110us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 582/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 583/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2329 - accuracy: 0.8830 - val_loss: 0.2871 - val_accuracy: 0.8769\n",
      "Epoch 584/1000\n",
      "453/453 [==============================] - 0s 183us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2909 - val_accuracy: 0.8769\n",
      "Epoch 585/1000\n",
      "453/453 [==============================] - 0s 178us/step - loss: 0.2637 - accuracy: 0.8124 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 586/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2580 - accuracy: 0.8764 - val_loss: 0.2877 - val_accuracy: 0.8769\n",
      "Epoch 587/1000\n",
      "453/453 [==============================] - 0s 197us/step - loss: 0.2363 - accuracy: 0.8786 - val_loss: 0.2915 - val_accuracy: 0.8718\n",
      "Epoch 588/1000\n",
      "453/453 [==============================] - 0s 181us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2853 - val_accuracy: 0.8769\n",
      "Epoch 589/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2361 - accuracy: 0.8830 - val_loss: 0.2971 - val_accuracy: 0.8769\n",
      "Epoch 590/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 591/1000\n",
      "453/453 [==============================] - 0s 102us/step - loss: 0.2423 - accuracy: 0.8764 - val_loss: 0.2845 - val_accuracy: 0.8718\n",
      "Epoch 592/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2432 - accuracy: 0.8587 - val_loss: 0.3009 - val_accuracy: 0.8769\n",
      "Epoch 593/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2341 - accuracy: 0.8786 - val_loss: 0.2825 - val_accuracy: 0.8769\n",
      "Epoch 594/1000\n",
      "453/453 [==============================] - 0s 113us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2904 - val_accuracy: 0.8718\n",
      "Epoch 595/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2920 - val_accuracy: 0.8769\n",
      "Epoch 596/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 597/1000\n",
      "453/453 [==============================] - 0s 180us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 598/1000\n",
      "453/453 [==============================] - 0s 224us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2842 - val_accuracy: 0.8769\n",
      "Epoch 599/1000\n",
      "453/453 [==============================] - 0s 236us/step - loss: 0.2321 - accuracy: 0.8830 - val_loss: 0.2847 - val_accuracy: 0.8769\n",
      "Epoch 600/1000\n",
      "453/453 [==============================] - 0s 201us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.2858 - val_accuracy: 0.8769\n",
      "Epoch 601/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 602/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2454 - accuracy: 0.8720 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 603/1000\n",
      "453/453 [==============================] - 0s 176us/step - loss: 0.2357 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8718\n",
      "Epoch 604/1000\n",
      "453/453 [==============================] - 0s 175us/step - loss: 0.2362 - accuracy: 0.8830 - val_loss: 0.2920 - val_accuracy: 0.8769\n",
      "Epoch 605/1000\n",
      "453/453 [==============================] - 0s 140us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 0.2944 - val_accuracy: 0.8769\n",
      "Epoch 606/1000\n",
      "453/453 [==============================] - 0s 217us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2926 - val_accuracy: 0.8769\n",
      "Epoch 607/1000\n",
      "453/453 [==============================] - 0s 124us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 0.2900 - val_accuracy: 0.8718\n",
      "Epoch 608/1000\n",
      "453/453 [==============================] - 0s 338us/step - loss: 0.2353 - accuracy: 0.8830 - val_loss: 0.2936 - val_accuracy: 0.8769\n",
      "Epoch 609/1000\n",
      "453/453 [==============================] - 0s 266us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 610/1000\n",
      "453/453 [==============================] - 0s 240us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.2891 - val_accuracy: 0.8769\n",
      "Epoch 611/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.3004 - val_accuracy: 0.8718\n",
      "Epoch 612/1000\n",
      "453/453 [==============================] - 0s 154us/step - loss: 0.2315 - accuracy: 0.8830 - val_loss: 0.2862 - val_accuracy: 0.8718\n",
      "Epoch 613/1000\n",
      "453/453 [==============================] - 0s 272us/step - loss: 0.2395 - accuracy: 0.8830 - val_loss: 0.2852 - val_accuracy: 0.8769\n",
      "Epoch 614/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 615/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2923 - val_accuracy: 0.8769\n",
      "Epoch 616/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2922 - val_accuracy: 0.8769\n",
      "Epoch 617/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 618/1000\n",
      "453/453 [==============================] - 0s 136us/step - loss: 0.2343 - accuracy: 0.8830 - val_loss: 0.2864 - val_accuracy: 0.8718\n",
      "Epoch 619/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2939 - val_accuracy: 0.8769\n",
      "Epoch 620/1000\n",
      "453/453 [==============================] - 0s 146us/step - loss: 0.2374 - accuracy: 0.8830 - val_loss: 0.2831 - val_accuracy: 0.8769\n",
      "Epoch 621/1000\n",
      "453/453 [==============================] - 0s 114us/step - loss: 0.2324 - accuracy: 0.8830 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 622/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.2893 - val_accuracy: 0.8769\n",
      "Epoch 623/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2327 - accuracy: 0.8830 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 624/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 625/1000\n",
      "453/453 [==============================] - 0s 211us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 626/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 627/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8718\n",
      "Epoch 628/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 629/1000\n",
      "453/453 [==============================] - 0s 170us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 630/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.2905 - val_accuracy: 0.8769\n",
      "Epoch 631/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2309 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8769\n",
      "Epoch 632/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 633/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2871 - val_accuracy: 0.8718\n",
      "Epoch 634/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2935 - val_accuracy: 0.8718\n",
      "Epoch 635/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.2905 - val_accuracy: 0.8769\n",
      "Epoch 636/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 0.2881 - val_accuracy: 0.8769\n",
      "Epoch 637/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.2858 - val_accuracy: 0.8718\n",
      "Epoch 638/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2354 - accuracy: 0.8830 - val_loss: 0.2932 - val_accuracy: 0.8718\n",
      "Epoch 639/1000\n",
      "453/453 [==============================] - 0s 133us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2938 - val_accuracy: 0.8769\n",
      "Epoch 640/1000\n",
      "453/453 [==============================] - 0s 129us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2912 - val_accuracy: 0.8769\n",
      "Epoch 641/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2964 - val_accuracy: 0.8769\n",
      "Epoch 642/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2946 - val_accuracy: 0.8769\n",
      "Epoch 643/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.2958 - val_accuracy: 0.8769\n",
      "Epoch 644/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2931 - val_accuracy: 0.8718\n",
      "Epoch 645/1000\n",
      "453/453 [==============================] - 0s 123us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 646/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2331 - accuracy: 0.8764 - val_loss: 0.2907 - val_accuracy: 0.8718\n",
      "Epoch 647/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2935 - val_accuracy: 0.8769\n",
      "Epoch 648/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2933 - val_accuracy: 0.8769\n",
      "Epoch 649/1000\n",
      "453/453 [==============================] - 0s 99us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 0.2954 - val_accuracy: 0.8769\n",
      "Epoch 650/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.2881 - val_accuracy: 0.8769\n",
      "Epoch 651/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 652/1000\n",
      "453/453 [==============================] - 0s 87us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2928 - val_accuracy: 0.8769\n",
      "Epoch 653/1000\n",
      "453/453 [==============================] - 0s 101us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 654/1000\n",
      "453/453 [==============================] - 0s 94us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 655/1000\n",
      "453/453 [==============================] - 0s 164us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 656/1000\n",
      "453/453 [==============================] - 0s 298us/step - loss: 0.2365 - accuracy: 0.8786 - val_loss: 0.2859 - val_accuracy: 0.8769\n",
      "Epoch 657/1000\n",
      "453/453 [==============================] - 0s 261us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2943 - val_accuracy: 0.8769\n",
      "Epoch 658/1000\n",
      "453/453 [==============================] - 0s 327us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 659/1000\n",
      "453/453 [==============================] - 0s 200us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 660/1000\n",
      "453/453 [==============================] - 0s 173us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 661/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 662/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2348 - accuracy: 0.8830 - val_loss: 0.2936 - val_accuracy: 0.8769\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 129us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 664/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 0.2946 - val_accuracy: 0.8769\n",
      "Epoch 665/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 666/1000\n",
      "453/453 [==============================] - 0s 128us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2899 - val_accuracy: 0.8718\n",
      "Epoch 667/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 668/1000\n",
      "453/453 [==============================] - 0s 137us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2893 - val_accuracy: 0.8769\n",
      "Epoch 669/1000\n",
      "453/453 [==============================] - 0s 135us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 670/1000\n",
      "453/453 [==============================] - 0s 116us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.2893 - val_accuracy: 0.8769\n",
      "Epoch 671/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2320 - accuracy: 0.8786 - val_loss: 0.2858 - val_accuracy: 0.8769\n",
      "Epoch 672/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 0.2901 - val_accuracy: 0.8769\n",
      "Epoch 673/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 674/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2924 - val_accuracy: 0.8769\n",
      "Epoch 675/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2329 - accuracy: 0.8808 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 676/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2859 - val_accuracy: 0.8769\n",
      "Epoch 677/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2312 - accuracy: 0.8808 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 678/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2360 - accuracy: 0.8764 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 679/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2356 - accuracy: 0.8874 - val_loss: 0.2826 - val_accuracy: 0.8769\n",
      "Epoch 680/1000\n",
      "453/453 [==============================] - 0s 95us/step - loss: 0.2418 - accuracy: 0.8808 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 681/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2385 - accuracy: 0.8852 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 682/1000\n",
      "453/453 [==============================] - 0s 156us/step - loss: 0.2366 - accuracy: 0.8830 - val_loss: 0.2910 - val_accuracy: 0.8769\n",
      "Epoch 683/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.3033 - val_accuracy: 0.8769\n",
      "Epoch 684/1000\n",
      "453/453 [==============================] - 0s 150us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.2953 - val_accuracy: 0.8769\n",
      "Epoch 685/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2317 - accuracy: 0.8830 - val_loss: 0.2905 - val_accuracy: 0.8769\n",
      "Epoch 686/1000\n",
      "453/453 [==============================] - 0s 174us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 0.2986 - val_accuracy: 0.8769\n",
      "Epoch 687/1000\n",
      "453/453 [==============================] - 0s 143us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 0.2930 - val_accuracy: 0.8769\n",
      "Epoch 688/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2322 - accuracy: 0.8830 - val_loss: 0.2930 - val_accuracy: 0.8718\n",
      "Epoch 689/1000\n",
      "453/453 [==============================] - 0s 120us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2958 - val_accuracy: 0.8769\n",
      "Epoch 690/1000\n",
      "453/453 [==============================] - 0s 138us/step - loss: 0.2337 - accuracy: 0.8830 - val_loss: 0.2928 - val_accuracy: 0.8769\n",
      "Epoch 691/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 0.3044 - val_accuracy: 0.8769\n",
      "Epoch 692/1000\n",
      "453/453 [==============================] - 0s 107us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2982 - val_accuracy: 0.8769\n",
      "Epoch 693/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2975 - val_accuracy: 0.8769\n",
      "Epoch 694/1000\n",
      "453/453 [==============================] - 0s 126us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2908 - val_accuracy: 0.8769\n",
      "Epoch 695/1000\n",
      "453/453 [==============================] - 0s 216us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 0.2900 - val_accuracy: 0.8769\n",
      "Epoch 696/1000\n",
      "453/453 [==============================] - 0s 215us/step - loss: 0.2381 - accuracy: 0.8852 - val_loss: 0.2902 - val_accuracy: 0.8769\n",
      "Epoch 697/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2332 - accuracy: 0.8830 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 698/1000\n",
      "453/453 [==============================] - 0s 145us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.3025 - val_accuracy: 0.8769\n",
      "Epoch 699/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 700/1000\n",
      "453/453 [==============================] - 0s 270us/step - loss: 0.2346 - accuracy: 0.8830 - val_loss: 0.2923 - val_accuracy: 0.8769\n",
      "Epoch 701/1000\n",
      "453/453 [==============================] - 0s 198us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 0.3004 - val_accuracy: 0.8769\n",
      "Epoch 702/1000\n",
      "453/453 [==============================] - 0s 184us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2939 - val_accuracy: 0.8769\n",
      "Epoch 703/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2379 - accuracy: 0.8852 - val_loss: 0.2914 - val_accuracy: 0.8769\n",
      "Epoch 704/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2600 - accuracy: 0.8234 - val_loss: 0.2985 - val_accuracy: 0.8769\n",
      "Epoch 705/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2337 - accuracy: 0.8874 - val_loss: 0.2879 - val_accuracy: 0.8769\n",
      "Epoch 706/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2360 - accuracy: 0.8808 - val_loss: 0.2989 - val_accuracy: 0.8769\n",
      "Epoch 707/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2344 - accuracy: 0.8830 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 708/1000\n",
      "453/453 [==============================] - 0s 148us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2950 - val_accuracy: 0.8769\n",
      "Epoch 709/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2933 - val_accuracy: 0.8769\n",
      "Epoch 710/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2918 - val_accuracy: 0.8769\n",
      "Epoch 711/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.2947 - val_accuracy: 0.8769\n",
      "Epoch 712/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2923 - val_accuracy: 0.8769\n",
      "Epoch 713/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 714/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2862 - val_accuracy: 0.8769\n",
      "Epoch 715/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2953 - val_accuracy: 0.8769\n",
      "Epoch 716/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 717/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2978 - val_accuracy: 0.8769\n",
      "Epoch 718/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2862 - val_accuracy: 0.8769\n",
      "Epoch 719/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2466 - accuracy: 0.8808 - val_loss: 0.2924 - val_accuracy: 0.8769\n",
      "Epoch 720/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2898 - val_accuracy: 0.8769\n",
      "Epoch 721/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 722/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2874 - val_accuracy: 0.8769\n",
      "Epoch 723/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2955 - val_accuracy: 0.8769\n",
      "Epoch 724/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2926 - val_accuracy: 0.8769\n",
      "Epoch 725/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2343 - accuracy: 0.8808 - val_loss: 0.2890 - val_accuracy: 0.8769\n",
      "Epoch 726/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2333 - accuracy: 0.8830 - val_loss: 0.2997 - val_accuracy: 0.8769\n",
      "Epoch 727/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2916 - val_accuracy: 0.8769\n",
      "Epoch 728/1000\n",
      "453/453 [==============================] - 0s 112us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 0.2968 - val_accuracy: 0.8667\n",
      "Epoch 729/1000\n",
      "453/453 [==============================] - 0s 237us/step - loss: 0.2337 - accuracy: 0.8786 - val_loss: 0.2947 - val_accuracy: 0.8769\n",
      "Epoch 730/1000\n",
      "453/453 [==============================] - 0s 151us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2834 - val_accuracy: 0.8769\n",
      "Epoch 731/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 0.2919 - val_accuracy: 0.8769\n",
      "Epoch 732/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2894 - val_accuracy: 0.8769\n",
      "Epoch 733/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2909 - val_accuracy: 0.8769\n",
      "Epoch 734/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 0.2900 - val_accuracy: 0.8769\n",
      "Epoch 735/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.2960 - val_accuracy: 0.8769\n",
      "Epoch 736/1000\n",
      "453/453 [==============================] - 0s 92us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.2998 - val_accuracy: 0.8769\n",
      "Epoch 737/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2379 - accuracy: 0.8830 - val_loss: 0.2936 - val_accuracy: 0.8769\n",
      "Epoch 738/1000\n",
      "453/453 [==============================] - 0s 98us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2912 - val_accuracy: 0.8769\n",
      "Epoch 739/1000\n",
      "453/453 [==============================] - 0s 186us/step - loss: 0.2320 - accuracy: 0.8808 - val_loss: 0.2900 - val_accuracy: 0.8821\n",
      "Epoch 740/1000\n",
      "453/453 [==============================] - 0s 83us/step - loss: 0.2315 - accuracy: 0.8808 - val_loss: 0.2916 - val_accuracy: 0.8821\n",
      "Epoch 741/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2313 - accuracy: 0.8874 - val_loss: 0.3008 - val_accuracy: 0.8769\n",
      "Epoch 742/1000\n",
      "453/453 [==============================] - 0s 108us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
      "Epoch 743/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2903 - val_accuracy: 0.8769\n",
      "Epoch 744/1000\n",
      "453/453 [==============================] - 0s 93us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 745/1000\n",
      "453/453 [==============================] - 0s 125us/step - loss: 0.2390 - accuracy: 0.8830 - val_loss: 0.2897 - val_accuracy: 0.8769\n",
      "Epoch 746/1000\n",
      "453/453 [==============================] - 0s 147us/step - loss: 0.2363 - accuracy: 0.8808 - val_loss: 0.2925 - val_accuracy: 0.8769\n",
      "Epoch 747/1000\n",
      "453/453 [==============================] - 0s 122us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2875 - val_accuracy: 0.8769\n",
      "Epoch 748/1000\n",
      "453/453 [==============================] - 0s 121us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
      "Epoch 749/1000\n",
      "453/453 [==============================] - 0s 144us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2936 - val_accuracy: 0.8769\n",
      "Epoch 750/1000\n",
      "453/453 [==============================] - 0s 130us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2872 - val_accuracy: 0.8769\n",
      "Epoch 751/1000\n",
      "453/453 [==============================] - 0s 132us/step - loss: 0.2372 - accuracy: 0.8852 - val_loss: 0.2988 - val_accuracy: 0.8769\n",
      "Epoch 752/1000\n",
      "453/453 [==============================] - 0s 127us/step - loss: 0.2369 - accuracy: 0.8786 - val_loss: 0.2908 - val_accuracy: 0.8769\n",
      "Epoch 753/1000\n",
      "453/453 [==============================] - 0s 134us/step - loss: 0.2461 - accuracy: 0.8786 - val_loss: 0.2865 - val_accuracy: 0.8718\n",
      "Epoch 754/1000\n",
      "453/453 [==============================] - 0s 118us/step - loss: 0.2286 - accuracy: 0.8852 - val_loss: 0.2986 - val_accuracy: 0.8769\n",
      "Epoch 755/1000\n",
      "453/453 [==============================] - 0s 103us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 756/1000\n",
      "453/453 [==============================] - 0s 100us/step - loss: 0.2331 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 757/1000\n",
      "453/453 [==============================] - 0s 109us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 758/1000\n",
      "453/453 [==============================] - 0s 119us/step - loss: 0.2373 - accuracy: 0.8786 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 759/1000\n",
      "453/453 [==============================] - 0s 111us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2943 - val_accuracy: 0.8769\n",
      "Epoch 760/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.2875 - val_accuracy: 0.8769\n",
      "Epoch 761/1000\n",
      "453/453 [==============================] - 0s 65us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.2927 - val_accuracy: 0.8769\n",
      "Epoch 762/1000\n",
      "453/453 [==============================] - 0s 66us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2960 - val_accuracy: 0.8769\n",
      "Epoch 763/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 764/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 765/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 766/1000\n",
      "453/453 [==============================] - 0s 80us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2915 - val_accuracy: 0.8769\n",
      "Epoch 767/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2914 - val_accuracy: 0.8769\n",
      "Epoch 768/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2941 - val_accuracy: 0.8769\n",
      "Epoch 769/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2886 - val_accuracy: 0.8769\n",
      "Epoch 770/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2960 - val_accuracy: 0.8769\n",
      "Epoch 771/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2330 - accuracy: 0.8830 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 772/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2904 - val_accuracy: 0.8769\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 73us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2919 - val_accuracy: 0.8769\n",
      "Epoch 774/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2974 - val_accuracy: 0.8769\n",
      "Epoch 775/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2857 - val_accuracy: 0.8769\n",
      "Epoch 776/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2904 - val_accuracy: 0.8769\n",
      "Epoch 777/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2906 - val_accuracy: 0.8769\n",
      "Epoch 778/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2894 - val_accuracy: 0.8769\n",
      "Epoch 779/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2321 - accuracy: 0.8808 - val_loss: 0.2895 - val_accuracy: 0.8769\n",
      "Epoch 780/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.2891 - val_accuracy: 0.8769\n",
      "Epoch 781/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 782/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 783/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2912 - val_accuracy: 0.8769\n",
      "Epoch 784/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 785/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2920 - val_accuracy: 0.8769\n",
      "Epoch 786/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
      "Epoch 787/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2898 - val_accuracy: 0.8769\n",
      "Epoch 788/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2843 - val_accuracy: 0.8769\n",
      "Epoch 789/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2852 - val_accuracy: 0.8769\n",
      "Epoch 790/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2365 - accuracy: 0.8830 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 791/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2873 - val_accuracy: 0.8769\n",
      "Epoch 792/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2883 - val_accuracy: 0.8769\n",
      "Epoch 793/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2913 - val_accuracy: 0.8769\n",
      "Epoch 794/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.2894 - val_accuracy: 0.8769\n",
      "Epoch 795/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2872 - val_accuracy: 0.8769\n",
      "Epoch 796/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2351 - accuracy: 0.8764 - val_loss: 0.2802 - val_accuracy: 0.8769\n",
      "Epoch 797/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2409 - accuracy: 0.8786 - val_loss: 0.2858 - val_accuracy: 0.8769\n",
      "Epoch 798/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 799/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2411 - accuracy: 0.8720 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 800/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2940 - val_accuracy: 0.8769\n",
      "Epoch 801/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 802/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2319 - accuracy: 0.8808 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 803/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2953 - val_accuracy: 0.8615\n",
      "Epoch 804/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2892 - val_accuracy: 0.8769\n",
      "Epoch 805/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2881 - val_accuracy: 0.8769\n",
      "Epoch 806/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 807/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 808/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 809/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 810/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 811/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2450 - accuracy: 0.8455 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 812/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2406 - accuracy: 0.8808 - val_loss: 0.2858 - val_accuracy: 0.8769\n",
      "Epoch 813/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 0.2984 - val_accuracy: 0.8769\n",
      "Epoch 814/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2857 - val_accuracy: 0.8769\n",
      "Epoch 815/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2477 - accuracy: 0.8455 - val_loss: 0.2898 - val_accuracy: 0.8769\n",
      "Epoch 816/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2815 - val_accuracy: 0.8769\n",
      "Epoch 817/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2909 - val_accuracy: 0.8769\n",
      "Epoch 818/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2418 - accuracy: 0.8852 - val_loss: 0.2867 - val_accuracy: 0.8769\n",
      "Epoch 819/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2425 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 820/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 821/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2870 - val_accuracy: 0.8769\n",
      "Epoch 822/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2320 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8615\n",
      "Epoch 823/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 824/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2362 - accuracy: 0.8764 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 825/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 826/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2361 - accuracy: 0.8764 - val_loss: 0.2844 - val_accuracy: 0.8769\n",
      "Epoch 827/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2293 - accuracy: 0.8874 - val_loss: 0.2924 - val_accuracy: 0.8769\n",
      "Epoch 828/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 0.2875 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2318 - accuracy: 0.8786 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 830/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 0.3011 - val_accuracy: 0.8769\n",
      "Epoch 831/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2860 - val_accuracy: 0.8769\n",
      "Epoch 832/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2891 - val_accuracy: 0.8769\n",
      "Epoch 833/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 0.2922 - val_accuracy: 0.8769\n",
      "Epoch 834/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2354 - accuracy: 0.8808 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 835/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.2924 - val_accuracy: 0.8769\n",
      "Epoch 836/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2367 - accuracy: 0.8742 - val_loss: 0.2895 - val_accuracy: 0.8821\n",
      "Epoch 837/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2373 - accuracy: 0.8786 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 838/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2386 - accuracy: 0.8808 - val_loss: 0.2916 - val_accuracy: 0.8821\n",
      "Epoch 839/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2313 - accuracy: 0.8830 - val_loss: 0.2837 - val_accuracy: 0.8769\n",
      "Epoch 840/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2945 - val_accuracy: 0.8769\n",
      "Epoch 841/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 842/1000\n",
      "453/453 [==============================] - 0s 89us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 843/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 844/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2305 - accuracy: 0.8830 - val_loss: 0.2851 - val_accuracy: 0.8769\n",
      "Epoch 845/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 0.2832 - val_accuracy: 0.8769\n",
      "Epoch 846/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2806 - val_accuracy: 0.8769\n",
      "Epoch 847/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2308 - accuracy: 0.8764 - val_loss: 0.2916 - val_accuracy: 0.8769\n",
      "Epoch 848/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2366 - accuracy: 0.8742 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 849/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 850/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2907 - val_accuracy: 0.8769\n",
      "Epoch 851/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 852/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2311 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 853/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 0.2965 - val_accuracy: 0.8769\n",
      "Epoch 854/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 855/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2382 - accuracy: 0.8808 - val_loss: 0.2867 - val_accuracy: 0.8769\n",
      "Epoch 856/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.2869 - val_accuracy: 0.8769\n",
      "Epoch 857/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2370 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 858/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2327 - accuracy: 0.8786 - val_loss: 0.2868 - val_accuracy: 0.8769\n",
      "Epoch 859/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 860/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 0.2781 - val_accuracy: 0.8769\n",
      "Epoch 861/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2342 - accuracy: 0.8764 - val_loss: 0.2848 - val_accuracy: 0.8769\n",
      "Epoch 862/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2827 - val_accuracy: 0.8769\n",
      "Epoch 863/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2845 - val_accuracy: 0.8769\n",
      "Epoch 864/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 865/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 866/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 867/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2358 - accuracy: 0.8830 - val_loss: 0.2840 - val_accuracy: 0.8769\n",
      "Epoch 868/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2853 - val_accuracy: 0.8769\n",
      "Epoch 869/1000\n",
      "453/453 [==============================] - 0s 84us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2882 - val_accuracy: 0.8769\n",
      "Epoch 870/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 0.2792 - val_accuracy: 0.8769\n",
      "Epoch 871/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2861 - val_accuracy: 0.8769\n",
      "Epoch 872/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 0.2935 - val_accuracy: 0.8769\n",
      "Epoch 873/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.2841 - val_accuracy: 0.8769\n",
      "Epoch 874/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2336 - accuracy: 0.8764 - val_loss: 0.2829 - val_accuracy: 0.8769\n",
      "Epoch 875/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2877 - val_accuracy: 0.8769\n",
      "Epoch 876/1000\n",
      "453/453 [==============================] - 0s 91us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2912 - val_accuracy: 0.8769\n",
      "Epoch 877/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.2825 - val_accuracy: 0.8769\n",
      "Epoch 878/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2905 - val_accuracy: 0.8769\n",
      "Epoch 879/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.2896 - val_accuracy: 0.8769\n",
      "Epoch 880/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2914 - val_accuracy: 0.8769\n",
      "Epoch 881/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2809 - val_accuracy: 0.8769\n",
      "Epoch 882/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2903 - val_accuracy: 0.8769\n",
      "Epoch 883/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 0.2866 - val_accuracy: 0.8769\n",
      "Epoch 884/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2847 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2917 - val_accuracy: 0.8769\n",
      "Epoch 886/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2336 - accuracy: 0.8786 - val_loss: 0.2843 - val_accuracy: 0.8769\n",
      "Epoch 887/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 0.2822 - val_accuracy: 0.8769\n",
      "Epoch 888/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 0.2938 - val_accuracy: 0.8769\n",
      "Epoch 889/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 890/1000\n",
      "453/453 [==============================] - 0s 81us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 891/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2916 - val_accuracy: 0.8769\n",
      "Epoch 892/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2353 - accuracy: 0.8808 - val_loss: 0.2801 - val_accuracy: 0.8769\n",
      "Epoch 893/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 0.2899 - val_accuracy: 0.8769\n",
      "Epoch 894/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.2821 - val_accuracy: 0.8769\n",
      "Epoch 895/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2304 - accuracy: 0.8852 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 896/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 897/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2308 - accuracy: 0.8852 - val_loss: 0.2880 - val_accuracy: 0.8769\n",
      "Epoch 898/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2836 - val_accuracy: 0.8769\n",
      "Epoch 899/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2300 - accuracy: 0.8808 - val_loss: 0.2787 - val_accuracy: 0.8769\n",
      "Epoch 900/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2311 - accuracy: 0.8742 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 901/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2364 - accuracy: 0.8786 - val_loss: 0.2915 - val_accuracy: 0.8615\n",
      "Epoch 902/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2928 - val_accuracy: 0.8769\n",
      "Epoch 903/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 904/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.2809 - val_accuracy: 0.8769\n",
      "Epoch 905/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2809 - val_accuracy: 0.8769\n",
      "Epoch 906/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2822 - val_accuracy: 0.8769\n",
      "Epoch 907/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2313 - accuracy: 0.8852 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 908/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.2958 - val_accuracy: 0.8769\n",
      "Epoch 909/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 910/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2806 - val_accuracy: 0.8769\n",
      "Epoch 911/1000\n",
      "453/453 [==============================] - 0s 76us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2900 - val_accuracy: 0.8769\n",
      "Epoch 912/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 913/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2434 - accuracy: 0.8742 - val_loss: 0.2851 - val_accuracy: 0.8769\n",
      "Epoch 914/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2302 - accuracy: 0.8874 - val_loss: 0.3035 - val_accuracy: 0.8821\n",
      "Epoch 915/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2436 - accuracy: 0.8609 - val_loss: 0.2806 - val_accuracy: 0.8769\n",
      "Epoch 916/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 0.2828 - val_accuracy: 0.8769\n",
      "Epoch 917/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2314 - accuracy: 0.8852 - val_loss: 0.2846 - val_accuracy: 0.8769\n",
      "Epoch 918/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.2830 - val_accuracy: 0.8769\n",
      "Epoch 919/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 0.2833 - val_accuracy: 0.8769\n",
      "Epoch 920/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 0.2876 - val_accuracy: 0.8769\n",
      "Epoch 921/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2302 - accuracy: 0.8852 - val_loss: 0.2839 - val_accuracy: 0.8769\n",
      "Epoch 922/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2831 - val_accuracy: 0.8769\n",
      "Epoch 923/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 0.2790 - val_accuracy: 0.8769\n",
      "Epoch 924/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2341 - accuracy: 0.8808 - val_loss: 0.2865 - val_accuracy: 0.8769\n",
      "Epoch 925/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.2869 - val_accuracy: 0.8769\n",
      "Epoch 926/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2328 - accuracy: 0.8830 - val_loss: 0.2889 - val_accuracy: 0.8769\n",
      "Epoch 927/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2824 - val_accuracy: 0.8769\n",
      "Epoch 928/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.2887 - val_accuracy: 0.8769\n",
      "Epoch 929/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2293 - accuracy: 0.8852 - val_loss: 0.2859 - val_accuracy: 0.8769\n",
      "Epoch 930/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 0.2812 - val_accuracy: 0.8769\n",
      "Epoch 931/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2860 - val_accuracy: 0.8769\n",
      "Epoch 932/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2358 - accuracy: 0.8852 - val_loss: 0.2840 - val_accuracy: 0.8769\n",
      "Epoch 933/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 934/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2350 - accuracy: 0.8764 - val_loss: 0.2826 - val_accuracy: 0.8769\n",
      "Epoch 935/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2298 - accuracy: 0.8896 - val_loss: 0.2793 - val_accuracy: 0.8769\n",
      "Epoch 936/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2303 - accuracy: 0.8808 - val_loss: 0.2926 - val_accuracy: 0.8769\n",
      "Epoch 937/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.2819 - val_accuracy: 0.8769\n",
      "Epoch 938/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2293 - accuracy: 0.8852 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 939/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2306 - accuracy: 0.8808 - val_loss: 0.2846 - val_accuracy: 0.8769\n",
      "Epoch 940/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2879 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2778 - val_accuracy: 0.8769\n",
      "Epoch 942/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2299 - accuracy: 0.8808 - val_loss: 0.2843 - val_accuracy: 0.8769\n",
      "Epoch 943/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2343 - accuracy: 0.8742 - val_loss: 0.2891 - val_accuracy: 0.8769\n",
      "Epoch 944/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 945/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2312 - accuracy: 0.8852 - val_loss: 0.2809 - val_accuracy: 0.8769\n",
      "Epoch 946/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2300 - accuracy: 0.8852 - val_loss: 0.2791 - val_accuracy: 0.8769\n",
      "Epoch 947/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2817 - val_accuracy: 0.8769\n",
      "Epoch 948/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2850 - val_accuracy: 0.8769\n",
      "Epoch 949/1000\n",
      "453/453 [==============================] - 0s 75us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.2847 - val_accuracy: 0.8769\n",
      "Epoch 950/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2296 - accuracy: 0.8852 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 951/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 0.2877 - val_accuracy: 0.8769\n",
      "Epoch 952/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2304 - accuracy: 0.8874 - val_loss: 0.2855 - val_accuracy: 0.8769\n",
      "Epoch 953/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2292 - accuracy: 0.8852 - val_loss: 0.2824 - val_accuracy: 0.8769\n",
      "Epoch 954/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2885 - val_accuracy: 0.8769\n",
      "Epoch 955/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2830 - val_accuracy: 0.8769\n",
      "Epoch 956/1000\n",
      "453/453 [==============================] - 0s 82us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 0.2908 - val_accuracy: 0.8769\n",
      "Epoch 957/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 0.2811 - val_accuracy: 0.8769\n",
      "Epoch 958/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.2858 - val_accuracy: 0.8769\n",
      "Epoch 959/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2835 - val_accuracy: 0.8769\n",
      "Epoch 960/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2305 - accuracy: 0.8852 - val_loss: 0.2829 - val_accuracy: 0.8769\n",
      "Epoch 961/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2884 - val_accuracy: 0.8769\n",
      "Epoch 962/1000\n",
      "453/453 [==============================] - 0s 67us/step - loss: 0.2298 - accuracy: 0.8852 - val_loss: 0.2799 - val_accuracy: 0.8769\n",
      "Epoch 963/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 964/1000\n",
      "453/453 [==============================] - 0s 77us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 0.2880 - val_accuracy: 0.8769\n",
      "Epoch 965/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2315 - accuracy: 0.8852 - val_loss: 0.2797 - val_accuracy: 0.8769\n",
      "Epoch 966/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2284 - accuracy: 0.8852 - val_loss: 0.2898 - val_accuracy: 0.8769\n",
      "Epoch 967/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2342 - accuracy: 0.8830 - val_loss: 0.2912 - val_accuracy: 0.8821\n",
      "Epoch 968/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2342 - accuracy: 0.8874 - val_loss: 0.2880 - val_accuracy: 0.8769\n",
      "Epoch 969/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2303 - accuracy: 0.8852 - val_loss: 0.2904 - val_accuracy: 0.8769\n",
      "Epoch 970/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 0.2759 - val_accuracy: 0.8769\n",
      "Epoch 971/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 0.2920 - val_accuracy: 0.8769\n",
      "Epoch 972/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 0.2784 - val_accuracy: 0.8769\n",
      "Epoch 973/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2395 - accuracy: 0.8675 - val_loss: 0.2911 - val_accuracy: 0.8769\n",
      "Epoch 974/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 0.2842 - val_accuracy: 0.8769\n",
      "Epoch 975/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2285 - accuracy: 0.8852 - val_loss: 0.2853 - val_accuracy: 0.8769\n",
      "Epoch 976/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2290 - accuracy: 0.8852 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 977/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 0.2822 - val_accuracy: 0.8821\n",
      "Epoch 978/1000\n",
      "453/453 [==============================] - 0s 74us/step - loss: 0.2427 - accuracy: 0.8631 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 979/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2306 - accuracy: 0.8852 - val_loss: 0.2820 - val_accuracy: 0.8769\n",
      "Epoch 980/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2289 - accuracy: 0.8852 - val_loss: 0.2872 - val_accuracy: 0.8769\n",
      "Epoch 981/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2295 - accuracy: 0.8852 - val_loss: 0.2867 - val_accuracy: 0.8769\n",
      "Epoch 982/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 0.2796 - val_accuracy: 0.8769\n",
      "Epoch 983/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2312 - accuracy: 0.8764 - val_loss: 0.2789 - val_accuracy: 0.8769\n",
      "Epoch 984/1000\n",
      "453/453 [==============================] - 0s 72us/step - loss: 0.2281 - accuracy: 0.8852 - val_loss: 0.2888 - val_accuracy: 0.8769\n",
      "Epoch 985/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 0.2788 - val_accuracy: 0.8769\n",
      "Epoch 986/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2293 - accuracy: 0.8852 - val_loss: 0.2869 - val_accuracy: 0.8769\n",
      "Epoch 987/1000\n",
      "453/453 [==============================] - 0s 69us/step - loss: 0.2297 - accuracy: 0.8852 - val_loss: 0.2768 - val_accuracy: 0.8769\n",
      "Epoch 988/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2310 - accuracy: 0.8852 - val_loss: 0.2856 - val_accuracy: 0.8769\n",
      "Epoch 989/1000\n",
      "453/453 [==============================] - 0s 68us/step - loss: 0.2376 - accuracy: 0.8830 - val_loss: 0.2965 - val_accuracy: 0.8615\n",
      "Epoch 990/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2339 - accuracy: 0.8830 - val_loss: 0.2985 - val_accuracy: 0.8615\n",
      "Epoch 991/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2323 - accuracy: 0.8830 - val_loss: 0.2878 - val_accuracy: 0.8769\n",
      "Epoch 992/1000\n",
      "453/453 [==============================] - 0s 78us/step - loss: 0.2291 - accuracy: 0.8852 - val_loss: 0.2814 - val_accuracy: 0.8769\n",
      "Epoch 993/1000\n",
      "453/453 [==============================] - 0s 79us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2830 - val_accuracy: 0.8769\n",
      "Epoch 994/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2863 - val_accuracy: 0.8769\n",
      "Epoch 995/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2796 - val_accuracy: 0.8769\n",
      "Epoch 996/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2301 - accuracy: 0.8852 - val_loss: 0.2811 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2377 - accuracy: 0.8764 - val_loss: 0.2797 - val_accuracy: 0.8769\n",
      "Epoch 998/1000\n",
      "453/453 [==============================] - 0s 71us/step - loss: 0.2353 - accuracy: 0.8764 - val_loss: 0.2799 - val_accuracy: 0.8769\n",
      "Epoch 999/1000\n",
      "453/453 [==============================] - 0s 70us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 0.2862 - val_accuracy: 0.8769\n",
      "Epoch 1000/1000\n",
      "453/453 [==============================] - 0s 73us/step - loss: 0.2304 - accuracy: 0.8830 - val_loss: 0.2823 - val_accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.22%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [9.80483300e-07, 9.99999050e-01, 1.32670730e-12],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [6.12904400e-01, 3.87079540e-01, 1.60129040e-05],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [2.43007960e-05, 9.99975700e-01, 1.72223550e-08],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [6.55957400e-01, 3.44042360e-01, 2.02454000e-07],\n",
       "       [7.62772740e-01, 2.37225900e-01, 1.38607190e-06],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [8.57430100e-11, 1.00000000e+00, 5.02053550e-23],\n",
       "       [6.12904400e-01, 3.87079540e-01, 1.60129040e-05],\n",
       "       [6.55957400e-01, 3.44042360e-01, 2.02454000e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [5.01112270e-15, 1.00000000e+00, 1.74751050e-17],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [1.70934040e-01, 8.29063200e-01, 2.80964470e-06],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [2.87558040e-09, 1.00000000e+00, 7.38604100e-15],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [9.96717900e-01, 3.28214980e-03, 1.03351850e-08],\n",
       "       [5.01112270e-15, 1.00000000e+00, 1.74751050e-17],\n",
       "       [4.03930040e-01, 5.96062960e-01, 7.03177100e-06],\n",
       "       [1.77684780e-03, 9.98222900e-01, 2.87930160e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [2.43007960e-05, 9.99975700e-01, 1.72223550e-08],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [5.32510100e-08, 1.00000000e+00, 3.00340290e-09],\n",
       "       [1.73501630e-01, 8.26494900e-01, 3.52726350e-06],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [9.82933940e-01, 1.70657690e-02, 2.54447030e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.81610720e-01, 6.18389000e-01, 3.06754200e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.98687210e-01, 8.01312270e-01, 6.14111400e-07],\n",
       "       [5.92796400e-01, 4.07202840e-01, 8.45983400e-07],\n",
       "       [1.38812210e-02, 9.86118800e-01, 2.09540000e-08],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [6.12904400e-01, 3.87079540e-01, 1.60129040e-05],\n",
       "       [1.73501630e-01, 8.26494900e-01, 3.52726350e-06],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.29880050e-04, 9.99867440e-01, 2.65402880e-06],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [9.93335000e-01, 6.66502540e-03, 8.86533700e-09],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [9.95066900e-01, 4.93254300e-03, 6.25920850e-07],\n",
       "       [8.94542700e-01, 1.05457075e-01, 1.98660330e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [9.99292850e-01, 6.26044930e-04, 8.11037400e-05],\n",
       "       [4.03930040e-01, 5.96062960e-01, 7.03177100e-06],\n",
       "       [4.03930040e-01, 5.96062960e-01, 7.03177100e-06],\n",
       "       [9.92201200e-01, 7.78862600e-03, 1.02046615e-05],\n",
       "       [6.12904400e-01, 3.87079540e-01, 1.60129040e-05],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [1.39124495e-05, 9.99986050e-01, 1.54960310e-08],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [6.83072140e-05, 9.99931700e-01, 1.49341290e-08],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [9.80483300e-07, 9.99999050e-01, 1.32670730e-12],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [1.70934040e-01, 8.29063200e-01, 2.80964470e-06],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [9.80483300e-07, 9.99999050e-01, 1.32670730e-12],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.18755175e-08, 1.00000000e+00, 4.31607030e-22],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [9.97336000e-01, 2.66396900e-03, 1.14404440e-08],\n",
       "       [5.15917900e-04, 9.99479500e-01, 4.70435800e-06],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [8.69519350e-01, 1.30480500e-01, 7.04644700e-08],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [9.99800740e-01, 1.99315370e-04, 5.42663250e-09],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [1.39124495e-05, 9.99986050e-01, 1.54960310e-08],\n",
       "       [9.99474100e-01, 5.25872460e-04, 8.91480400e-09],\n",
       "       [6.55957400e-01, 3.44042360e-01, 2.02454000e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.98687210e-01, 8.01312270e-01, 6.14111400e-07],\n",
       "       [7.62772740e-01, 2.37225900e-01, 1.38607190e-06],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [8.57430100e-11, 1.00000000e+00, 5.02053550e-23],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [8.69519350e-01, 1.30480500e-01, 7.04644700e-08],\n",
       "       [1.29880050e-04, 9.99867440e-01, 2.65402880e-06],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [2.87558040e-09, 1.00000000e+00, 7.38604100e-15],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.62772740e-01, 2.37225900e-01, 1.38607190e-06],\n",
       "       [7.62772740e-01, 2.37225900e-01, 1.38607190e-06],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [8.57430100e-11, 1.00000000e+00, 5.02053550e-23],\n",
       "       [1.98687210e-01, 8.01312270e-01, 6.14111400e-07],\n",
       "       [1.98687210e-01, 8.01312270e-01, 6.14111400e-07],\n",
       "       [9.97984770e-01, 2.01527430e-03, 5.74596760e-10],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [6.55957400e-01, 3.44042360e-01, 2.02454000e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [9.99310000e-01, 6.89962240e-04, 1.87867540e-09],\n",
       "       [1.77684780e-03, 9.98222900e-01, 2.87930160e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [5.15917900e-04, 9.99479500e-01, 4.70435800e-06],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.03656730e-09, 1.00000000e+00, 3.03651020e-10],\n",
       "       [7.62772740e-01, 2.37225900e-01, 1.38607190e-06],\n",
       "       [6.50624600e-01, 3.49375280e-01, 1.86828810e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [4.47530840e-01, 5.52468960e-01, 2.02984500e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [8.57430100e-11, 1.00000000e+00, 5.02053550e-23],\n",
       "       [1.70934040e-01, 8.29063200e-01, 2.80964470e-06],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [1.70934040e-01, 8.29063200e-01, 2.80964470e-06],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.98687210e-01, 8.01312270e-01, 6.14111400e-07],\n",
       "       [3.90596930e-01, 6.09402400e-01, 6.71446860e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [9.80483300e-07, 9.99999050e-01, 1.32670730e-12],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [1.70934040e-01, 8.29063200e-01, 2.80964470e-06],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [1.03656730e-09, 1.00000000e+00, 3.03651020e-10],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07],\n",
       "       [6.12904400e-01, 3.87079540e-01, 1.60129040e-05],\n",
       "       [3.26030600e-07, 7.91066400e-07, 9.99998900e-01],\n",
       "       [3.60424880e-12, 2.69812900e-07, 9.99999760e-01],\n",
       "       [7.20766660e-01, 2.79233100e-01, 2.57158800e-07]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0017Skpresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668639053254439"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668639053254439"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557495069033531"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012848077634546077"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557495069033531"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012848077634546077"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 85.77%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.01421863569918196\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 88.69%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.009472034\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
